{"meta":{"title":"railsoil","subtitle":"railsoil知识库","description":"","author":"luyanan","url":"https://rainsoil.github.io","root":"/"},"pages":[{"title":"About","date":"2022-01-04T02:41:36.579Z","updated":"2022-01-04T02:41:36.579Z","comments":true,"path":"about/index.html","permalink":"https://rainsoil.github.io/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2022-01-04T02:41:36.579Z","updated":"2022-01-04T02:41:36.579Z","comments":true,"path":"categories/index.html","permalink":"https://rainsoil.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2022-01-04T02:41:36.583Z","updated":"2022-01-04T02:41:36.583Z","comments":true,"path":"tags/index.html","permalink":"https://rainsoil.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"mysql主从实现原理","slug":"面试题/mysql主从实现原理","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/mysql-zhu-cong-shi-xian-yuan-li/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/mysql-zhu-cong-shi-xian-yuan-li/","excerpt":"","text":"mysql主从实现原理1、什么是mysql主从同步？当master(主)库的数据发生变化的时候，变化会实时的同步到slave(从)库。 2、主从同步有什么好处？ 水平扩展数据库的负载能力。 容错，高可用。Failover(失败切换)/High Availability 数据备份。 3、主从同步的原理是什么？首先我们来了解master-slave的体系结构。 如下图： 不管是delete、update、insert，还是创建函数、存储过程，所有的操作都在master上。当master有操作的时候,slave会快速的接收到这些操作，从而做同步。 但是，这个机制是怎么实现的呢？ 在master机器上，主从同步事件会被写到特殊的log文件中(binary-log);在slave机器上，slave读取主从同步事件，并根据读取的事件变化，在slave库上做相应的更改。 如此，就实现了主从同步了！ 下面我们来详细的了解。 3.1主从同步事件有哪些上面说到： 在master机器上，主从同步事件会被写到特殊的log文件中(binary-log); 主从同步事件有3种形式:statement、row、mixed。 statement：会将对数据库操作的sql语句写入到binlog中。 row：会将每一条数据的变化写入到binlog中。 mixed：statement与row的混合。Mysql决定什么时候写statement格式的，什么时候写row格式的binlog。 3.2在master机器上的操作当master上的数据发生改变的时候，该事件(insert、update、delete)变化会按照顺序写入到binlog中。 binlog dump线程当slave连接到master的时候，master机器会为slave开启binlog dump线程。当master 的 binlog发生变化的时候，binlog dump线程会通知slave，并将相应的binlog内容发送给slave。 3.3在slave机器上的操作当主从同步开启的时候，slave上会创建2个线程。 I/O线程。该线程连接到master机器，master机器上的binlog dump线程会将binlog的内容发送给该I/O线程。该I/O线程接收到binlog内容后，再将内容写入到本地的relay log。 SQL线程。该线程读取I/O线程写入的relay log。并且根据relay log的内容对slave数据库做相应的操作。 3.4如何在master、slave上查看上述的线程？使用SHOW PROCESSLIST命令可以查看。 如图，在master机器上查看binlog dump线程。 如图，在slave机器上查看I/O、SQL线程。 4、讲了这么多，一图以蔽之","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"计算机系统知识","slug":"软考-数据库/计算机系统知识","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/ruan-kao-shu-ju-ku/ji-suan-ji-xi-tong-zhi-shi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/ruan-kao-shu-ju-ku/ji-suan-ji-xi-tong-zhi-shi/","excerpt":"","text":"计算机系统基础1. 计算机硬件组成 计算机的硬件基本系统由五大部分组成: 运算器、控制器、存储器、输入设备(如键盘鼠标)、输出设备(如显示器) 存储器分为 内部存储器(即内存, 容量小,速度快,临时存放数据) 外部存储器(即硬盘、光盘等,容量大,速度慢,长期保存数据) 输入设备和输出设备合并称为外部设备,即外设 主机: CPU+主存储器 2. 中央处理单元CPU中央处理单元组成: 运算器、控制器、寄存器和内部总线组成. 中央处理单元功能: 实现程序控制、操作控制、时间控制、数据控制功能 2.1 运算器2.1.1 运算器组成: 算数逻辑单元ALU(实现对数据的算法和逻辑运算) 累计寄存器AC(运算结果和源操作数的存放区) 数据缓冲寄存器DR(暂时存放内存的指令和数据) 状态条件寄存器PSW(保存指令运行结果的条件码内容,如溢出标识等) 2.1.2 运算器功能:​ 执行所有的算数运算,如加减乘除等；执行所有的逻辑运算并进行逻辑测试, 如与、或、非、比较等. 2.2 控制器2.2.1 控制器组成 指令寄存器IR(暂存CPU执行的指令) 程序计数器PC(存放指令的执行地址) 地址寄存器AR(保存当前CPU所访问的内存地址) 指令译码器ID(分析指令操作码) 2.2.2 控制器功能 控制整个CPU的工作,最为重要,包括程序控制,时序控制等. 3. 数据的进制转换进制的表示: 二进制、十六进制,一般二进制的符号为0B, 表示为0B0011, 十六进制的符号为Ox 或者H, 也可以表示为0x18F 或者18FH R 进制整数转十进制: 位权展开法: 用R 进制数的每一位乘以R的n次方,n是变量，从R进制数的整数最低位开始,依次为0,1,2,3,3333累加. 例如: 有6进制数5043, 此时R =6,用六进制数的每一位乘以6的n次方,n是变量，从6进制的整数最低位开始(5043 从低位到高位的排列: 3,4,0,5),n 依次为0,1,2,3,那么最终5043=3*6^0+4*6^1+0*6^3+5*6^4=1107 十进制转R进制 十进制整数（除以R倒取余数）, 用十进制整数除以R, 记录每次所得余数,若商不为0,则继续除以R,直至商为0, 而后将所有余数从下至上记录,排列成从左至右的顺序,即为转换后的R 进制. 例如: 有十进制数200,转换为6进制,此时R =6, 将200/6=33, 余数为2, 因为商不为0，因此将33/6,得商=5,余数为3, 再将5/6, 得商为0, 余数为5. 将所有余数从下到上排列为 532. m进制转n进制​ 先将m进制转换为10进制,再将10进制转换为n进制,中间需要通过十进制中转, 但是下面两种进制可以直接转换 二进制转八进制 每三位二进制数转换为一位八进制数,二进制个数不是三的倍数,则在前面补零(原则是数值不变), 如二进制数01101 有五位,前面补零的话为 001101, 每三位转换为一个八进制, 001 = 1*2^0+0*2^1+0*2^2=1, 101 =1*2^0+0*2^1+1*2^2=5,也就是结果等于15 二进制转十六进制每四位二进制转换为一位十六进制数, 二进制位数不是4的倍数则在前面补零, 如二进制101101 有六位数,则在前面补零为00101101, 每四位转换为一个十六进制,0010=0*2^0+1*2^1+0*2^2+0*2^3=2, 1101=1*2^0+0*2^1+1*2^2+1*2^3=13，13在十六进制中表示为D，则最后结果为2D 4. 数的表示机器数: 各种数值在计算机中表示的形式,其特点是使用二进制计数制,数的符号用0和1表示,小数点则隐含,不占位置. 机器数有无符号位和带符号位之分,无符号数表示正数,没有符号位. 带符号数最高位为符号位, 正数符号位为0, 负数符号位为1. 定点表示法为纯小数和纯整数两种,其中小数点不占存储位, 而是按照以下约定: 纯小数: 约定小数点的位置在机器数的最高数值位之前 纯整数: 约定小数点的位置在机器数的最低数值位之后 真值: 机器数对应的实际数值 5. 数的编码方式带符号位有下列编码方式: 原码: 一个数的正常二进制表示,最高位表示符号, 数值0的原码有两种形式: +0 (0 00000000) 和-0(1 00000000) 反码: 正数的反码即原码. 负数的反码是在原码的基础上,除符号位外,其他各位按位取反. 数值0的反码也有两种形式,+0(0 00000000)和-0(1 11111111) 补码: 正数的补码就是原码,负数的补码是在原码的基础上,除符号位外,其他各位按位取反,而后末尾+1,若有进位则产生进位,因此数值0的补码只有一种形式: +0 = -1=0 00000000 移码：用做浮点运算的阶码,无论正数负数,都是将该原码的补码的首位(符号位) 取反得到移码 机器字长为n时各种码制表示的带符号位的取值范围(差别在于0的表示: 原码和反码分别为+0和-0, 补码只有一个-0, 因此可以多表示一个) 6. 浮点数的表示浮点数: 表示方法为N=F*2^E, 其中E 成为阶码,F成为尾数; 类似于十进制的科学计数法, 如85.125=0.52125*10^2,二进制如101.011=0.101011*2^3 在浮点数的表示中,阶码为带符号的纯整数,尾数为带符号位的纯小数,要注意符号占最高位(正数0 负数1), 其表示格式如下: 阶符 阶码 数符 尾数 很明显,与科学计数法类似,一个浮点数的表示方法不是唯一的,浮点数所能表示的数值范围由阶码确定,所表示的数值精确度由尾数确定. 尾数的表示采用规格化方法,也即带符号位数的补码必须是1.0xxxx（负数）, 或者0.1xxxx(负数), 其中x可以为0或者1 浮点数的运算: 对阶:使两个数的阶码相同,小阶向大阶看齐,较小阶码增加几位,尾数就右移几位 尾数计算(相加, 若是减运算, 则加负数) 结果规格化(即尾数表示格式化,带符号尾数转换为 1.0xxxxx 或者0.1xxxx) 7. 算数运算和逻辑运算数与数之间的算数运算包括 加、减、乘、除等基本算数运算,对于二进制,还需要掌握基本逻辑运算, 包括: 逻辑与&amp; : 0和1相与，只要有一个为0结果则为0,两个都为1才为1 逻辑或|: 0和1相或,只要有一个为1则结果为1, 两个都为0则为0 异或:同0非1, 即参加运算的二进制同为0或者同为1 则结果为0, 一个为0 另外一个结果为1 则为1 逻辑非！: 0的非是1,1的非是0 逻辑左移&lt;&lt;: 二进制整体左移n位. 高位溢出则舍去, 低位补0 逻辑右移&gt;&gt;: 二进制整体右移n位,低位溢出则舍去,高位补0 8. 校验码码距: 就单个编码A: 00而言,其码距为1, 因为只需要改变一位就变成了另外一个编码. 在两个编码中,从A编码到B编码的转换所需要改变的位数称为码距. 如A： 00 要转换为B:11, 码距为2 . 一般来说,码距越大,越利于纠错和检错. 8.1 奇偶校验码奇偶校验码: 在编码中增加1位校验位来使编码中1的个数为奇数(奇校验码) 或者偶数(偶校验码),从而使得码距为2. 例如: 奇校验码: 在编码中,含有奇书个1,发送给接收方,接收方收到之后,会计算收到的编码有多少个1,如果是奇数个1,则无误. 如果是偶数个,则有误. 偶校验码同理: 只是编码中有偶数个1, 由上述奇偶校验码只能检1位错,并且无法纠错。 8.2 循环冗余校验码CRCCRC 只能检错,不能纠错,其原理是找出来一个能整除多项式的编码,因为首先要将原始报文除以多项式,将所得的余数作为校验位加在原始报文之后,作为发送数据发给接收方,其编码格式如下: 由此可知,CRC由两部分组成, 左边位信息码(原始数据), 右边为校验码,校验码是由信息码产生的,校验码位数越长,校验能力越强. 求CRC编码时,采用的是模2运算(按位运算,不发生错位和进位). 例: 原始报文为： 11011010101,其生成多项式为x^4+x^3+x+1, 对其进行CRC编码后的结果为: 解答: 首先根据多项式得到除数11011,在原始多项式后面加上多项式最高指数个数个0, 即4个0, 和除数进行模2除法, 一直上1, 最终得出四位的余数为0011, 最终编码为11001010101 0011,然后发送出去, 接收方将收到的数据11001010101 0011 与多项式的11011 进行模2运算,若余数为0,说明校验正确,数据传输正确. 8.3 海明校验码海明码, 本质也是利用奇偶性来检错和纠错的检验方式,构成方法是在数据位之间的确定位置上插入k个校验位, 通过扩大码距来实现检错和纠错. 设数据位是n位,校验位是k位,则n和k必须满足以下关系: 2^k-1&gt;=n+k 例如：求信息1011的海明码 校验位的位数和具体的数据位的位数之间的关系:所有位都编码,从最低位编号,从1开始递增,校验位处于2的n(n=0 1 2 )次方中，即处于第1,2,4,8,16,32….位上,其余位才能填充真正的数据位,若信息数据位1011, 则可知, 第1，2，4位位校验位,第3,5,6,7位为数据位,从低位开始存放1011 每一位校验码的计算公式: 需要确定每一位校验码到底校验哪些信息位,将信息位(即编号) 拆分成二进制表示,如7=4+2+1, 由第4位校验码(r2) 和第2位校验码(r1) 和第1位校验码(r0) 共同校验,同理,第6位数据位6=4+2, 第5位数据位5=4+1, 第3位数据位3=2+1, 前面知道,这些2的n次方都是校验位. 可知,第4位校验位校验第7,6,5三位数据位. 因此,第4位校验位r2等于这三位数据位的值异或, 第2位和第1位校验位计算原理同上,计算出三个校验位后,可知最终要发送的海明校验码位1010101 检错和纠错原理 接收方收到海明码后,会将每一位校验位与其校验的位数分别异或,即做如下三组运算: 如果是偶校验,那么运算得到的结果应该全部是0, 如果是奇校验,那么应该全部位1, 才是正确, 假设是偶校验,且接受到的数据位1011101(第四位出错),此时,运算的结果位: 这里不全位0,表示传输过程中有误,并且按照r2r1r0排列位二进制100, 这里指出的就是错误的位数, 表示第100,即第4位出错,纠错方法就是将该位逆转. 9 计算机体系结构分类Flynn 分类法: 如下图所示: 体系结构类型 结构 关键特性 代表 单指令单数据流SIDI 控制部分:一个处理器:一个主存模块:一个 单处理系统 单指令多数据流 控制部分:一个处理器:多个主存模块:多个 各处理器以异步的形式执行同一条指令 并行处理机阵列处理机超级向量处理机 多指令单数据流 控制部分:多个处理器:一个主存模块:多个 被证明不可能,至少是不实际 目前没有,有文献称流水线计算机为此类 多指令多数据流 主控部分:多个处理器:多个主存模块:多个 能够实现作业,任务,指令等各级并行执行 多处理机系统多计算机 10 计算机指令计算机指令的组成: 一条指令由操作码和操作数两部分组成,操作码决定要完成的操作, 操作数指参与计算的数据及其所在的单元地址. 在计算机中,操作要求和操作数地址都由二进制数码表示,分别称为操作码和地址码,整条指令以二进制编码的形式存放在存储器中. 计算机指令执行过程: 取指令-&gt;分析指令-&gt; 执行指令三个步骤,首先将程序计数器PC中的指令地址取出,送入地址总线,CPU依据指令地址去内存中取出指令内容存入指令寄存器IR, 而后由指令译码器进行分析,分析指令操作码,最后执行指令,取出指令执行所需要的源操作数. 11 指令寻址方式11.1 指令寻址方式:顺序寻址方式:当执行一段程序时,是一条指令接着一条指令的顺序执行. 跳跃寻址方式:指下一条指令的地址码不是由程序计数器给出,而是由本条指令直接给出。 程序跳跃后,按新的指令地址开始顺序执行. 因此, 程序计数器的内容也必须相应改变,以便及时跟踪新的指令地址. 11.2 指令操作数的寻址方式立即寻址方式新的地址码字段指出的不是地址,而是操作数本身 直接寻址方式:在指令的地址字段中直接指出操作数在主存中的地址 间接寻址方式指令地址码字段所指向的存储单元中存储的是操作数的地址 寄存器寻址方式指令那种的地址码是寄存器的编号 12 指令系统CISC 是复杂指令系统,兼容性强,指令繁多.长度可变,由微程序实现。 RISC 是精简指令系统,指令少,使用频率接近,主要依靠硬件实现(通用寄存器,硬布线逻辑控制) 主要区别如下: 指令系统类型 指令 寻址方式 实现方式 其他 CISC（复杂） 数量多,使用频率差别大, 可变长格式 支持多种 微程序控制技术(微码) 研制周期长 RISC(精简) 数量少,使用频率接近,定长格式,大部分为单周期指令,操作寄存器,只有Load/Store 操作内存 支持方式少 增加了通用寄存器,硬布线逻辑控制为主, 适合采用流水线 优化编译,有效支持高级语言 13 指令流水线指令流水线原理: 将指令分为不同段,每段由不同的部分去处理,因此可以产生叠加的效果, 所有的部件去处理指令的不同段,如下图所示： 14 流水线相关计算流水线周期: 指令分为不同执行段,其中执行时间最长的段位流水线周期 流水线执行时间: 1条指令的总执行时间+(总指令条数+1) *流水线周期 流水线吞吐量: 总指令条数/流水线执行时间 流水线加速比: 不使用流水线总执行时间/使用流水线总执行时间 超标量流水线技术: 常规流水线的度为1,即每条流水线阶段只执行一个部分,当度大于1时,就是超标量技术,当度为3的时候,相当于3条流水线并行执行,即取、分析、执行每段都同时执行3段指令,因此,当题目中出现度的概念时,计算时需要将: 指令条数=执行条数/度.然后再套流水线执行时间的公式. 15 存储系统计算机存储系统的层次结构,如图所示: 计算机采用分级存储体系的主要目的是为了解决存储容量、成本和速度之间的矛盾. 两级存储: Cache主存、主存-辅存(虚拟存储体系) 局部性原理: 总的来说,在CPU 运行时,所访问的数据会趋向于一个较小的局部空间地址,包括以下两个方面: 时间局部性原理: 如果一个数据项正在被访问,那么在近期他很可能会再次被访问. 即在相邻的时间里会访问同一个数据项 空间局部性原理: 在最近的将来会用到的数据的地址和现在正在访问的的数据地址很可能是相近的,即相邻的空间地址会被连续访问 16 高速缓存Cache高速缓存Cache 用来存储当前最活跃的程序和数据,直接与CPU交互,位于CPU和主存之间,容量小, 速度为内存的5-10倍, 由半导体材料构成. 其内容是主存内容的副本拷贝,对于程序员来说是透明的. Cache 由控制部分和存储器组成,存储器存储数据,控制部分判断CPU要访问的数据是否在Cache中,在则命中,不在则依据一定的算法从主存中替换. 地址映射: 在CPU工作时,送出的是主存单元的地址,而应从Cache 存储器中读/写信息. 这就需要将主存地址转换为Cache 存储器地址,这种地址的转换称为地址映像,由硬件自动完成映射, 分为下列三个方法: 直接映射将Cache 存储器等分为块,主存也等分为块并且编号,主存中的块与Cache 中的块的对应关系是固定的. 也即二者块号相同才算命中,地址变换简单但是不灵活,容易造成资源浪费. 全相联映像同样都等分为块并编号,主存中任意一块都与Cache 中的任意一块对应, 因此可以随意插入Cache 中任意位置,但是地址变换复杂,速度较慢. 因为主存可以随意插入Cache 任意块,只有当Cache 满了才会发生块冲突,是最不容易发生块冲突的映像方式. 组组相联映像前面两种方式的结合,将Cache 存储器先分块再分组,主存也同样先分块再分组,组间采用直接映像,即主存中组好与Cache 中组号相同的组才能命中,但是组内全相联映像,也即组号相同的两个组内的所有块可以任意调换 . 17 总线接口从广义上来讲,任意连接两个以上电子元器件的导线都可以称为总线,通常分为以下三类: 1. 内部总线: 内部芯片级别的总线, 芯片与处理器之间通信的总线 2. 系统总线是扳级总线,用于计算机内各部分之间的连接,具体分为 数据总线(并行数据传输位数)、 地址总线(系统可管理的内存空间的大小)、 控制总线(传达控制命令) 代表的有ISA总线、EISA 总线、PCI总线 3. 外部总线设备一级的总线, 微机和外部设备的总线,代表有RS232(串行总线)、SCCI(并行总线)、USB（通用串行总线,即插即用,支持热插拔） 18 系统可靠性分析平均无故障时间MTTF=1/失效率 平均故障修复时间MTTR=1/修复率 平均故障间隔时间MTBF=MTTF+MTTR 系统可用性=MTTF/(MTTF+MTTR)*100% 无论什么系统,都是由多个设备组成,协同工作,而这多个设备的组合方式可以是串联,也可以是并联,也可以是混合模式,假设每个设备的可靠性为R1,R2....Rn,则不同的系统的可靠性的计算公示如下: 串联系统,一个设备不可靠,整个系统崩溃R=R1*R2*R3....Rn 并联系统:所有设备都不可靠,整个系统才崩溃 R=1-(1-R1)*(1-R2)*....*(1-Rn) 混合系统: 划分并联、串联 19 信息安全和信息系统安全 信息安全系统的体系架构 X轴是安全机制, 为提供某些安全服务,利用各种安全技能和技巧,所形成的一个较为完善的机构体系 Y轴是OSI 网络参考模型 Z轴是安全服务, 就是从网络中的各个层次提供给信息应用系统所需要的安全服务支持 由X,Y,Z三个轴形成的信息安全系统三位空间就是信息系统的安全空间 随着网络逐层扩展,这个空间不仅范围逐步加大, 安全的内涵也就更丰富,达到具有认证,权限, 完整加密和不可否认五大要素,也叫做安全空间的五大属性. 信息安全含义以及属性: 保护信息的保密性、完整性、可用性,另外也包括其他属性,比如: 真实性、可核查性、不可抵赖性和可靠性. 保密性信息不被泄露给未授权的个人,实体和国策灰姑娘或不被其使用的特性,包括: 最小授权原则 防暴漏 信息加密 物理加密 完整性信息未经授权不能改变的特性,影响完整性的主要因素由设备故障、人为攻击和计算机病毒等, 保证保证性的方法包括: 协议: 通过安全协议检测除被删除、失效、被修改的字段 纠错编码方法:利用校验码完成检错和纠错功能 密码校验和方法 数字签名:能识别除发送方来源 公证: 请求系统管理或中介机构证明信息的真实性 可用性需要时,授权实体可以访问和使用的特性,一般用系统正常使用和整个工作时间之比来度量. 其他属性 真实性: 指对信息的来源进行判断, 能对伪造来源的信息予以鉴定. 可核查性:系统实体的行为可以被独一无二的追溯到该实体的特性,这个特性就是要求该实体对其行为负责,为探测和调查安全违规事件提供了可能性. 不可抵赖性: 是指建立有效的责任机制,防止用户否认其行为,这一点在电子商务中是及其重要的. 可靠性: 系统在规定的时间和给定的条件下,无故障的完成规定功能的概率. 安全需求也可划分为物理线路安全、网络安全、系统安全和应用安全,从各级安全需求字面上也可以理解. 物理线路: 物理设备、物理环境. 网络安全是值网络上的攻击和入侵 系统安全是指操作系统上的漏洞、补丁等 应用安全就是上层的应用软件,包括数据库软件. 加密技术 一个密码系统,通常简称为密码体制(Cryptosystem), 由五部分组成: 明文空间M, 它是全体明文的集合 密文空间C,他是全体密文的集合 密钥空间K, 他是全体密钥的集合,其中每一个密钥K 均由加密密钥Ke和解密密钥Kd 组成,即K=&lt;Ke,Kd&gt; 加密算法E ,他是一组由M至C的加密变换 解密算法D,他是一组由C到M的解密变换 对于明文空间M 中的每一个明文M, 加密算法E 在密钥Ke的空间下将明文M加密成密文C:C=E(M,Ke) 而解密算法D 在密钥Kd的控制下将密文C 解密出同一明文M,M=D (C, Kd ) =D (E (M, Ke),Kd) 对称加密技术数据的加密和解密的密钥(密码)是相同的,属于不公开密钥加密算法.其缺点是加密强度不高(因为密钥位数少),且密钥分发困难(因为密钥还需要传输给接收方,也要保密可靠性). 优点是加密速度快,适合加密大数据 常见的对称密钥加密算法如下: DES: 替换+yiwei, 56位密钥,64位数据快,速度快,密钥易产生 3EDS: 三种DES, 两个56位密钥K1,K2 加密: K1加密&gt;K2解密&gt;K1加密 解密: K1解密&gt;K2加密&gt;K1解密 AES是美国联邦政府采用的一种区块加密标准,这个标准用来替代原先的DES. RC-5: RSA 数据安全公司的很多产品都使用了RC-5 IDEA:128位密钥,64位数据块, 比DES的加密性好,对计算机功能要求相对低 非对称加密技术数据的加密和解密的密钥是不同的, 分为公钥和私钥,是公开密钥加密算法, 其缺点是加密速度慢,优点是安全性高,不容易破解. 非对称加密技术的原理是:发送者发送数据时,使用接收者的公钥做加密密钥,私钥做解密密钥,这样只有接收者才能解密密文得到明文,安全性高,因为无需传输密钥,但是无法保证完整性,如下: 常见的非对称加密算法如下: RSA 512位或者(1024位)密钥,计算量极大,难破解. Elgamal、 ECC(椭圆曲线算法)、背包算法、 Rabin、 D-H等 相比较可知,对称加密算法密钥一般只有56位 , 因此加密过程简单,适合加密大数据,也因此加密强度不高，而非对称加密算法密钥有1024位, 相应的解密计算量大,难以破解,却不适合加密大数据,一般用来加密对称算法的密钥,这样,就将两个技术组合使用了,这也是数字信封的原理: 数字信封原理:信是对称加密的密钥,数字信封就是对此密钥进行非对称加密,具体过程: 发送方将数据用于对称加密加密传输,而将对称密钥用接受方公钥加密发送给对方,接收方接收到数字信封,用自己的密钥解密信封,取出对称密钥解密得原文. 数字信封运行了对称加密技术和非对称加密技术,本质上是使用对称加密加密数据,非对称密钥加密对称密钥,解决了对称加密的密钥的传输问题. 信息摘要所谓信息摘要,就是一段数据的特性信息,当数据发生了改变,信息摘要也会发生改变, 发送方会将数据和信息摘要一起传给接收方,接收方会根据接受到的数据重新生成一个信息摘要,如此摘要和接受到的摘要相同,则说明数据正确. 信息摘要是由哈希函数生成的. 信息摘要的特点:不管数据多长,都会产生固定长度的信息摘要,任何不同的输入数据,都会产生不同的信息摘要. 单向性,即只能由数据生成信息摘要,不能由信息摘要还原数据. 信息摘要算法: MD5(产生128位的输出) SHA-1(安全散列算法,产生160位的输出,安全性更高) 数字签名: 唯一标识一个发送方 发送者发送数据时,使用发送者的私钥进行加密,接受者收到数据后,只能使用发送者的公钥进行解密，这样就能唯一确定发送方,这也是数字签名的过程. 但是无法保证机密性. 如下: 公钥基础设施KPI是以不对称加密技术位基础,以数据机密性、完整性、身份认证和行为不可抵赖性为安全目的,来实施和提供安全服务的具有普适性的安全基础设施. 数字证书 一个数据结构，是一种由一个可信任的权威机构签署的信息集合,在不同的应用中有不同的证书 如x509证书必须包含下列信息: 版本号 序列号 签名算法标识符 认证机构 有效期限 主题信息 认证机构的数据签名 公钥信息 公钥证书主要用于确保公钥及其用户绑定关系的安全,这个公钥就是证书标识的那个主体的合法的公钥, 任何一个用户只要知道签名机构的公钥,就能检查对证书的签名的合法性,如果检查正确,那么用户就可以相信那个证书所携带的公钥的真实性,而且这个公钥就是证书所标识的那个主体的合法的公钥 签证机构CA 负责签发证书、管理和撤销证书,是所有注册用户所信赖的权威机构,CA在给用户签发证书的时候要加上自己的数字签名,以保证证书信息的真实性,任何机构可以用CA的公钥来验证该证书的合法性.","categories":[{"name":"软考-数据库","slug":"软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"软考-数据库","slug":"软考-数据库/软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"类加载器","slug":"面试题/类加载器","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/lei-jia-zai-qi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/lei-jia-zai-qi/","excerpt":"","text":"类加载器1. Java类加载器 Java源代码.java文件通过编译成字节码.class文件后，需要被加载到Java虚拟机的内存空间中使用，这个过程就是类加载。类加载依靠的是Java类加载器 Java类加载器是Java运行时环境的一部分，负责动态加载Java类到Java虚拟机的内存空间中。类通常是按需加载的，即第一次使用该类时才加载。由于有了类加载器，Java运行时系统不需要知道文件的位置与文件系统。 2. JVM的3个默认类加载器 引导（Bootstrap）类加载器。由原生代码C语言编写，不继承java.lang.ClassLoader。负责加载核心Java库，存储在/jre/lib目录中。 扩展（Extensions）类加载器。用来在指明的目录中加载Java的扩展类。Java虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载Java类。该类由sun.misc.Launcher$ExtClassLoader实现。 Apps类加载器（也称系统类加载器）。根据Java应用程序的类路径来加载Java类。一般来说，Java应用程序的类都是由它来完成加载的，可以通过ClassLoader.getSystemClassLoader()来获取它。该类由sun.misc.Launcher$AppClassLoader来实现。 每一个类加载器都有一个父装载器（parent class loader）。 3. 如何保证一个类被加载一次 全盘负责委托机制 解释：当一个ClassLoader加载一个Class的时候，这个Class所依赖的和引用的其他Class通常也是由这个classloader负责载入的。例如加载一个普通的Demo类，Apps类加载器首先拿到这个类的class文件，先让parent（父）类加载器也就是扩展（Extensions）类加载器处理。扩展（Extensions）类加载器拿到class文件后同样先让parent（父）类加载器处理，也就是引导（Bootstrap）类加载器会先处理属于它应该加载的部分。引导类加载器处理完成后，把剩下的给扩展类加载器。扩展类加载器处理属于它的内容，将剩下的部分交给Apps类加载器，Apps类加载器会加载剩下的全部内容。 每个类加载器只会加载自己负责的部分。 这样每个类只会被加载一次。","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"待解决面试题","slug":"面试题/待解决面试题","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/dai-jie-jue-mian-shi-ti/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/dai-jie-jue-mian-shi-ti/","excerpt":"","text":"hash 碰撞jvm内存模型秒杀系统设计rpc设计","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"常见多线程面试题","slug":"面试题/常见多线程面试题","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/chang-jian-duo-xian-cheng-mian-shi-ti/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/chang-jian-duo-xian-cheng-mian-shi-ti/","excerpt":"","text":"1.启动一个线程是调用 run() 方法还是 start() 方法？启动一个线程调用的是start()方法，使线程进入到就绪状态，这就意味着它可以由JVM调度并执行，这并不意味着线程就会立马执行；run()方法是线程启动后线程要进行回调的方法。 2. 请说出同步线程及线程调度相关的方法？ wait():使一个线程处于阻塞状态，并且释放所持有的对象锁； sleep():使一个线程休眠一段时间，当时间过后线程又会恢复到以前的状态，并且在休眠状态不会释放对象锁； notify():唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关； notifyAll():唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态； 3.线程和进程的区别？ 进程：具有一定独立功能的程序关于某个数据集合上的一次运行活动，是操作系统进行资源分配和调度的一个独立单位。 线程：是进程的一个实体，是 cpu 调度和分派的基本单位，是比进程更小的可以独立运行的基本单位。 特点：线程的划分尺度小于进程，这使多线程程序拥有高并发性，进程在运行时各自内存单元相互独立，线程之间内存共享，这使多线程编程可以拥有更好的性能和用户体验 4.Java 中多线程间的通信怎么实现 ?1.共享变量：线程间通信可以通过发送信号，发送信号的一个简单方式是在共享对象的变量里设置信号值’; 2.wait/notify 机制:以资源为例，生产者生产一个资源，通知消费者就消费掉一个资源，生产者继续生产资源，消费者消费资源，以此循环; 5.什么情况下导致线程死锁，遇到线程死锁该怎么解决？死锁的定义：所谓死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进 死锁产生的原因:系统资源的竞争,进程运行推进顺序不合适 如何避免死锁: 加锁顺序（线程按照一定的顺序加锁） 加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁） 同一个类中的 2 个方法都加了同步锁，多个线程能同时访问同一个类中的这两个方法吗？ 这个问题需要考虑到Lock与synchronized 两种实现锁的不同情形。因为这种情况下使用Lock 和synchronized会有截然不同的结果。Lock 可以让等待锁的线程响应中断，Lock 获取锁，之后需要释放锁。而 synchronized 却不行，使用 synchronized 时，当我们访问同一个类对象的时候，是同一把锁，所以可以访问该对象的其他 synchronized 方法。 7.请叙述一下您对线程池的理解？ 第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 第三：提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 8.常用的线程池有哪些？ newSingleThreadExecutor：创建一个单线程的线程池，此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 newFixedThreadPool：创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。 newCachedThreadPool：创建一个可缓存的线程池，此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。 newScheduledThreadPool：创建一个大小无限的线程池，此线程池支持定时以及周期性执行任务的需求。 9.在 java 中 wait 和 和 sleep 方法的不同？最大的不同是在等待时 wait 会释放锁，而 sleep 一直持有锁。wait 通常被用于线程间交互，sleep 通常被用于暂停执行。 10.多线程的常见创建方式？一种是继承thread类，一种是实现runnable接口； 11.synchronized和lock的区别？ synchronized是一个关键字，lock是一个接口 在代码出现异常的时候，synchronized会自动的释放锁资源，lock要调用unlock方法才能释放锁资源； lock可以中断其他等待锁对象的线程，synchronized不行，线程会一直等待下去；","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"乐观锁和悲观锁","slug":"面试题/乐观锁和悲观锁","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/le-guan-suo-he-bei-guan-suo/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/le-guan-suo-he-bei-guan-suo/","excerpt":"","text":"锁机制在数据库操作过程中，为了避免两个或多个用户同时对一条数据操作，通常采用锁的机制来来解决数据冲突问题。同样，在程序流程中为了避免对多线程共享的资源的修改冲突，也采用锁的机制来避免修改冲突 锁的分类乐观锁（Optimistic Lock）所谓乐观锁，就是相信大部分场景下，不会产生数据修改冲突，所以在读取数据进行修改的时候，不对数据进行加锁，而是在最终提交修改的时候，通过version或CAS机制，检查对数据的修改是否发生了冲突。乐观锁的适用于读多写少的场景，能提供系统的处理能力，如果在冲突比较概率高的场景使用乐观锁，反而会降低系统的处理能力。 悲观锁（Pessimistic Lock）所谓悲观锁，就是认为对数据修改发生冲突的概率比较大，所以在读取数据进行修改的时候，先用“排他写锁”锁住数据，Block其他人的操作，等修改完成后，再释放锁。此模式比较适用于数据修改冲突发生概率高的场景，但会一定程度降低系统的处理能力。 数据库场景悲观锁数据的行锁、表锁、读锁、写锁都属于悲观锁，典型的就是select * from xxx where id=n for update命令。 乐观锁CAS机制（compare and swap）假设有一条订单（order）数据，ID为1，订单状态（status）是已付款，这个时候，商家打开订单列表，准备进行发货；在商家打开订单后，这时候用户在APP端取消了订单，但是商家不知道；商家执行发货的时候；这时候商家操作发货，如果只根据ID进行更新： update order set status=&#39;已发货&#39; where id=1 则会导致取消的订单被发货，此时，使用CAS机制，在更新数据的时候检查订单状态是否正确： update order set status=&#39;已发货&#39; where id=1 and status=&#39;已付款&#39; 并通过检查update语句发返回值，可以确认时数据更新是否成功。 Version机制Version机制，是在order表中增加一个数字型的version字段，每次查下数据的时候，都带上version字段。更新数据是，把version字段加1。以上述订单为例，比如： 订单创建后version为1； 付款后version为2； 此时商家准备发货，读到的version为2； 用户取消订单后，version为3； 商家发货是，更新订单状态是，发现version不是读取时的2，说明订单已经被更新，系统驳回商家的修改，并提升商家。 JAVA锁场景Java中， java.util.concurrent.atomic包下的原子变量属于使用CAS计算的乐观锁。 public class AtomicInteger extends Number implements java.io.Serializable &#123; private volatile int value; public final int get() &#123; return value; &#125; public final int getAndIncrement() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return current; &#125; &#125; public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; &#125; getAndIncrement 采用了CAS机制，每次从内存中读取数据，然后将此数据和 +1 后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。compareAndSet 利用JNI来完成CPU指令的操作： public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; unsafe.compareAndSwapInt(this, valueOffset, expect, update)逻辑类似如下： if (this == expect) &#123; this = update return true; &#125; else &#123; return false; &#125; 而synchronized关键字属于悲观锁。 CAS的问题ABA问题如线程1读取了一个变量的值为A；这时候线程2修改变量的值B；线程3有把变量值改回为A；此时，线程1再去更新此变量，会认为此变量未被其他人更新过，但其实变量已经被更新了多次。所以CAS是适用于对象子包含单个共享变量的原子操作，对于对象中包含多个共享变量的情况无法保证原子性。 锁开销对于资源竞争比较激烈的情况，CAS自旋的概率较大，会导致CPU开销增大，效率会低于synchronized。","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"【Redis】缓存穿透，缓存雪崩，缓存击穿","slug":"面试题/【Redis】缓存穿透，缓存雪崩，缓存击穿","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/redis-huan-cun-chuan-tou-huan-cun-xue-beng-huan-cun-ji-chuan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/redis-huan-cun-chuan-tou-huan-cun-xue-beng-huan-cun-ji-chuan/","excerpt":"","text":"[Redis]缓存穿透，缓存雪崩，缓存击穿缓存穿透第一次看到这个名字，会觉得是一个很高深的名词。但是和其他许多概念一样，它只是描述了一个很容易理解的现象：请求了不存在的数据。造成大量的请求没有命中缓存场景之一：数据库使用了id为正整数作为键，但是黑客使用负整数向服务器发起请求，这时所有的请求都没有在缓存中命中，从而导致大量请求数据库，如果超过了数据库的承载能力，会导致数据库服务器宏机。 解决缓存穿透的方案主要有两种：1，当查询不存在时，也将结果保存在缓存中。但是这可能会存在一种问题：大量没有查询结果的请求保存在缓存中，这时我们就可以将这些请求的key设置得更短一些。 2，提前过滤掉不合法的请求，Redis实现了布隆过滤器，我们可以使用它来达到这个目的。布隆过滤器很好理解，可以参考布隆过滤器(Bloom Filter)的原理和实现。 如上图所示是合法的请求与布隆过滤器的过滤的请求的关系，合法的请求在布隆过滤器中一定可以经过，但是布隆过滤器并不能完全拦截所有非法的请求。应用在缓存上，我们能够拦截绝大部分请求即可。 缓存雪崩缓存雪崩是指缓存大量失效，导致大量的请求都直接向数据库获取数据，造成数据库的压力。缓存大量失效的原因可能是缓存服务器宏机，或者大量Redis的键设置的过期时间相同。 解决缓存雪崩我们也有两种解决方案：1，在设置Redis键的过期时间时，加上一个随机数，这样可以避免。2，部署分布式的Redis服务，当一个Redis服务器挂掉了之后，进行故障转移。 缓存击穿缓存击穿又是一个听起来很晦涩的概念。它指的是在缓存过期的后一秒，有大量的请求并发的请求过期的键，这是因为缓存已经过期了，所有的请求都发送到数据库中了。 解决缓存击穿的方法与解决缓存穿透的方法一样。","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"spring的事务隔离级别和事务传播行为","slug":"面试题/spring的事务隔离级别和事务传播行为","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/spring-de-shi-wu-ge-chi-ji-bie-he-shi-wu-chuan-bo-xing-wei/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/spring-de-shi-wu-ge-chi-ji-bie-he-shi-wu-chuan-bo-xing-wei/","excerpt":"","text":"spring的事务隔离级别和事务传播行为事务隔离级别 DEFAULT 使用底层数据库默认的隔离级别,大部分数据库默认的隔离级别都是READ_COMMITED READ_UNCOMMITED 允许事务读取未被其他事务提交的修改、可能会出现脏读、幻读、不可重复读 READ_COMMITED 只允许事务读取已经被事务提交的更改,可以避免脏读.但不可重复读和幻读问题仍然可能出现. REPEATABLE_READ 确保事务可以多次从一个字段中读取相同的值,在这个事务持续期间, 禁止其他事务对这个字段进行更新,可以避免脏读和不可重复读, 但是幻读问题仍然存在. SERIALIZABLE 确保事务可以从一个表中读取相同的行, 在这个事务持续期间, 禁止其他事务对该表执行插入、更新、删除. 所有的并发问题都能避免, 但是性能较低. 事务的隔离级别需要底层数据库引擎的支持,而不是应用程序或者框架的支持. Oracle 支持2种事务隔离级别: READ_COMMITED，SERIALIZABLE. 默认是 READ_COMMITED Mysql 支持4种事务隔离级别, 默认是REPEATABLE_READ . msyql 查看隔离级别： select @@tx_isolation; 设置隔离级别： set session transaction isolation level serializable; 事务传播机制​ 事务方法被另一个事务方法调用的时候, 必须指定事务应该如何传播.例如方法可能继续在现有事务中运行, 也可能开启一个新的事务, 并在自己的事务运行. spring中的事务传播行为可以由传播属性指定. Spring指定了7种传播行为. REQUIRED 如何有事务在运行, 当前的方法就在这个事务中运行, 否则就重新开一个新的事务,默认传播行为. REQUIRED_NEW 当前方法必须启动新的事务, 并在自己的事务中运行, 如果有事务在运行, 则将它挂起. SUPPORTS 如果有事务在运行, 当前的方法就是在这个事务中运行, 否则可以不运行在事务中. NOT_SUPPORTED 表示该方法不应该运行在事务中, 如果存在当前事务,在该方法运行期间, 当前事务将被挂起. MANDATORY 当前的方法必须运行在事务内部,如果没有正在运行的事务,将会抛出异常. NEVER 当前方法不应该运行在事务中, 如果有运行的事务, 就抛出异常. NESTED 如果有事务在运行, 当前的方法就应该在这个事务的嵌套事务内运行. 嵌套的事务可以独立于当前事务进行单独的提交或者回滚. 如果当前事务不存在, 那么其行为与PROPAGATION_REQUIRED一样.","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"线程池与ThreadPoolExecutor类浅析","slug":"面试题/线程池与ThreadPoolExecutor类浅析","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/xian-cheng-chi-yu-threadpoolexecutor-lei-qian-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/xian-cheng-chi-yu-threadpoolexecutor-lei-qian-xi/","excerpt":"","text":"线程池与ThreadPoolExecutor类浅析一、Thread直接创建线程的弊端（1）每次new Thread新建对象，性能差。（2）线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多系统资源导致死机或OOM。（3）缺少更多的功能，如更多执行、定期执行、线程中断。（4）其他弊端，大家自行脑补，多动脑，没坏处，哈哈。 二、线程池的好处（1）重用存在的线程，减少对象创建、消亡的开销，性能佳。（2）可以有效控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞。（3）提供定时执行、定期执行、单线程、并发数控制等功能。（4）提供支持线程池监控的方法，可对线程池的资源进行实时监控。（5）其他好处，大家自行脑补，多动脑，没坏处，哈哈。 三、线程池1.线程池类结构关系线程池中的一些接口和类的结构关系如下图所示。 后文会死磕这些接口和类的底层原理和源码。 2.创建线程池常用的类——Executors Executors.newCachedThreadPool：创建一个可缓存的线程池，如果线程池的大小超过了需要，可以灵活回收空闲线程，如果没有可回收线程，则新建线程 Executors.newFixedThreadPool：创建一个定长的线程池，可以控制线程的最大并发数，超出的线程会在队列中等待 Executors.newScheduledThreadPool：创建一个定长的线程池，支持定时、周期性的任务执行 Executors.newSingleThreadExecutor: 创建一个单线程化的线程池，使用一个唯一的工作线程执行任务，保证所有任务按照指定顺序（先入先出或者优先级）执行 Executors.newSingleThreadScheduledExecutor:创建一个单线程化的线程池，支持定时、周期性的任务执行 Executors.newWorkStealingPool：创建一个具有并行级别的work-stealing线程池 3.线程池实例的几种状态 Running:运行状态，能接收新提交的任务，并且也能处理阻塞队列中的任务 Shutdown: 关闭状态，不能再接收新提交的任务，但是可以处理阻塞队列中已经保存的任务，当线程池处于Running状态时，调用shutdown()方法会使线程池进入该状态 Stop: 不能接收新任务，也不能处理阻塞队列中已经保存的任务，会中断正在处理任务的线程，如果线程池处于Running或Shutdown状态，调用shutdownNow()方法，会使线程池进入该状态 Tidying: 如果所有的任务都已经终止，有效线程数为0（阻塞队列为空，线程池中的工作线程数量为0），线程池就会进入该状态。 Terminated: 处于Tidying状态的线程池调用terminated()方法，会使用线程池进入该状态 注意：不需要对线程池的状态做特殊的处理，线程池的状态是线程池内部根据方法自行定义和处理的。 4.合理配置线程的一些建议（1）CPU密集型任务，就需要尽量压榨CPU，参考值可以设置为NCPU+1(CPU的数量加1)。（2）IO密集型任务，参考值可以设置为2*NCPU（CPU数量乘以2） 四、线程池最核心的类之一——ThreadPoolExecutor1.构造方法ThreadPoolExecutor参数最多的构造方法如下： public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler rejectHandler) 其他的构造方法都是调用的这个构造方法来实例化对象，可以说，我们直接分析这个方法之后，其他的构造方法我们也明白是怎么回事了！接下来，就对此构造方法进行详细的分析。 注意：为了更加深入的分析ThreadPoolExecutor类的构造方法，会适当调整参数的顺序进行解析，以便于大家更能深入的理解ThreadPoolExecutor构造方法中每个参数的作用。 上述构造方法接收如下参数进行初始化： （1）corePoolSize：核心线程数量。 （2）maximumPoolSize：最大线程数。 （3）workQueue：阻塞队列，存储等待执行的任务，很重要，会对线程池运行过程产生重大影响。 其中，上述三个参数的关系如下所示： 如果运行的线程数小于corePoolSize，直接创建新线程处理任务，即使线程池中的其他线程是空闲的。 如果运行的线程数大于等于corePoolSize，并且小于maximumPoolSize，此时，只有当workQueue满时，才会创建新的线程处理任务。 如果设置的corePoolSize与maximumPoolSize相同，那么创建的线程池大小是固定的，此时，如果有新任务提交，并且workQueue没有满时，就把请求放入到workQueue中，等待空闲的线程，从workQueue中取出任务进行处理。 如果运行的线程数量大于maximumPoolSize，同时，workQueue已经满了，会通过拒绝策略参数rejectHandler来指定处理策略。 根据上述三个参数的配置，线程池会对任务进行如下处理方式： 当提交一个新的任务到线程池时，线程池会根据当前线程池中正在运行的线程数量来决定该任务的处理方式。处理方式总共有三种：直接切换、使用无限队列、使用有界队列。 直接切换常用的队列就是SynchronousQueue。 使用无限队列就是使用基于链表的队列，比如：LinkedBlockingQueue，如果使用这种方式，线程池中创建的最大线程数就是corePoolSize，此时maximumPoolSize不会起作用。当线程池中所有的核心线程都是运行状态时，提交新任务，就会放入等待队列中。 使用有界队列使用的是ArrayBlockingQueue，使用这种方式可以将线程池的最大线程数量限制为maximumPoolSize，可以降低资源的消耗。但是，这种方式使得线程池对线程的调度更困难，因为线程池和队列的容量都是有限的了。 根据上面三个参数，我们可以简单得出如何降低系统资源消耗的一些措施： 如果想降低系统资源的消耗，包括CPU使用率，操作系统资源的消耗，上下文环境切换的开销等，可以设置一个较大的队列容量和较小的线程池容量。这样，会降低线程处理任务的吞吐量。 如果提交的任务经常发生阻塞，可以考虑调用设置最大线程数的方法，重新设置线程池最大线程数。如果队列的容量设置的较小，通常需要将线程池的容量设置的大一些，这样，CPU的使用率会高些。如果线程池的容量设置的过大，并发量就会增加，则需要考虑线程调度的问题，反而可能会降低处理任务的吞吐量。 接下来，我们继续看ThreadPoolExecutor的构造方法的参数。 （4）keepAliveTime：线程没有任务执行时最多保持多久时间终止当线程池中的线程数量大于corePoolSize时，如果此时没有新的任务提交，核心线程外的线程不会立即销毁，需要等待，直到等待的时间超过了keepAliveTime就会终止。 （5）unit：keepAliveTime的时间单位 （6）threadFactory：线程工厂，用来创建线程默认会提供一个默认的工厂来创建线程，当使用默认的工厂来创建线程时，会使新创建的线程具有相同的优先级，并且是非守护的线程，同时也设置了线程的名称 （7）rejectHandler：拒绝处理任务时的策略 如果workQueue阻塞队列满了，并且没有空闲的线程池，此时，继续提交任务，需要采取一种策略来处理这个任务。线程池总共提供了四种策略： 直接抛出异常，这也是默认的策略。实现类为AbortPolicy。 用调用者所在的线程来执行任务。实现类为CallerRunsPolicy。 丢弃队列中最靠前的任务并执行当前任务。实现类为DiscardOldestPolicy。 直接丢弃当前任务。实现类为DiscardPolicy。 2.ThreadPoolExecutor提供的启动和停止任务的方法（1）execute():提交任务，交给线程池执行（2）submit():提交任务，能够返回执行结果 execute+Future（3）shutdown():关闭线程池，等待任务都执行完（4）shutdownNow():立即关闭线程池，不等待任务执行完 3.ThreadPoolExecutor提供的适用于监控的方法（1）getTaskCount()：线程池已执行和未执行的任务总数（2）getCompletedTaskCount()：已完成的任务数量（3）getPoolSize()：线程池当前的线程数量（4）getCorePoolSize()：线程池核心线程数（5）getActiveCount():当前线程池中正在执行任务的线程数量","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"String、StringBuffer和StringBuilder的区别","slug":"面试题/String、StringBuffer和StringBuilder的区别","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/string-stringbuffer-he-stringbuilder-de-qu-bie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/string-stringbuffer-he-stringbuilder-de-qu-bie/","excerpt":"","text":"String、StringBuffer和StringBuilder的区别可变性 String是不可变的，它使用final关键词修饰– public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; ................... StringBuffer和StringBuilder两者都是继承自AbstractStringBuilder,AbstractStringBuilder也是用字符数组保存char value[]当时没有用final修饰，所以这两种对象是可变的 public final class StringBuffer extends AbstractStringBuilder abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; /** * The value is used for character storage. */ char[] value; 线程安全性 String的对象不可变，也就是常量，所以线程安全 StringBuffer重写了AbstractStringBuilder的方法，比如append、insert等并且加了同步锁，所以是线程安全的 @Override public synchronized int length() &#123; return count; &#125; @Override public synchronized int capacity() &#123; return value.length; &#125; @Override public synchronized void ensureCapacity(int minimumCapacity) &#123; super.ensureCapacity(minimumCapacity); &#125; 而StringBuilder就没加同步锁，所以是非线程安全的 性能每次修改String的值都会重新生成一个新的String对象，然后再将指针指向新的String对象，StringBuffer和StringBuilder每次都是对象本身进行操作，而不是生成新的对象。StringBuilder的性能会比StringBuffer好一点，不过却要冒多线程不安全的风险 总结 数据量将多用String 单线程操作大量数据用StringBuilder 多线程操作大量数据用StringBuffer","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"MySql查询性能优化","slug":"面试题/MySql查询性能优化","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/mysql-cha-xun-xing-neng-you-hua/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/mysql-cha-xun-xing-neng-you-hua/","excerpt":"","text":"MySql查询性能优化避免向数据库请求不需要的数据在访问数据库时，应该只请求需要的行和列。请求多余的行和列会消耗MySql服务器的CPU和内存资源，并增加网络开销。例如在处理分页时，应该使用LIMIT限制MySql只返回一页的数据，而不是向应用程序返回全部数据后，再由应用程序过滤不需要的行。当一行数据被多次使用时可以考虑将数据行缓存起来，避免每次使用都要到MySql查询。避免使用SELECT *这种方式进行查询，应该只返回需要的列。 查询数据的方式查询数据的方式有全表扫描、索引扫描、范围扫描、唯一索引查询、常数引用等。这些查询方式，速度从慢到快，扫描的行数也是从多到少。可以通过EXPLAIN语句中的type列反应查询采用的是哪种方式。通常可以通过添加合适的索引改善查询数据的方式，使其尽可能减少扫描的数据行，加快查询速度。例如，当发现查询需要扫描大量的数据行但只返回少数的行，那么可以考虑使用覆盖索引，即把所有需要用到的列都放到索引中。这样存储引擎无须回表获取对应行就可以返回结果了。 分解大的查询可以将一个大查询切分成多个小查询执行，每个小查询只完成整个查询任务的一小部分，每次只返回一小部分结果删除旧的数据是一个很好的例子。如果只用一条语句一次性执行一个大的删除操作，则可能需要一次锁住很多数据，占满整个事务日志，耗尽系统资源、阻塞很多小的但重要的查询。将一个大的删除操作分解成多个较小的删除操作可以将服务器上原本一次性的压力分散到多次操作上，尽可能小地影响MySql性能，减少删除时锁的等待时间。同时也减少了MySql主从复制的延迟。另一个例子是分解关联查询，即对每个要关联的表进行单表查询，然后将结果在应用程序中进行关联。下面的这个查询： SELECT * FROM tag JOIN tag_post ON tag_post.tag_id=tag.id JOIN post ON tag_post.post_id=post.id WHERE tag.tag = &#39;mysql&#39;; 可以分解成下面这些查询来代替： SELECT * FROM tag WHERE tag = &#39;mysql&#39;; SELECT * FROM tag_post WHERE tag_id = 1234; SELECT * FROM post WHERE post.id in (123,456,567,9098,8904); 将一个关联查询拆解成多个单表查询有如下有点： 让缓存的效率更高。如果缓存的是关联查询的结果，那么其中的一个表发生变化，整个缓存就失效了。而拆分后，如果只是某个表很少的改动，并不会破坏所有的缓存。 可以减少锁的竞争 更容易对数据库进行拆分，更容易做到高性能和可扩展。 查询本身的效率也有可能会有所提升。例如上面用IN()代替关联查询比随机的关联更加高效。 优化MIN()和MAX()添加索引可以优化MIN()和MAX()表达式。例如，要找到某一列的最小值，只需要查询对应B-Tree索引的最左端的记录即可。类似的，如果要查询列中的最大值，也只需要读取B-Tree索引的最后一条记录。对于这种查询，EXPLAIN中可以看到”Select tables optimized away”,表示优化器已经从执行计划中移除了该表，并以一个常数取而代之。 用IN()取代OR在MySql中，IN()先将自己列表中的数据进行排序，然后通过二分查找的方式确定列的值是否在IN()的列表中，这个时间复杂度是O(logn)。如果换成OR操作，则时间复杂度是O(n)。所以，对于IN()的列表中有大量取值的时候，用IN()替换OR操作将会更快。 优化关联查询在MySql中，任何一个查询都可以看成是一个关联查询，即使只有一个表的查询也是如此。MySql对任何关联都执行嵌套循环的关联操作，例如对于下面的SQL语句： SELECT tbl1.col1,tbl2.col2 FROM tbl1 INNER JOIN tbl2 USING(col3) WHERE tbl1.col1 IN(5,6); 下面的伪代码表示MySql将如何执行这个查询： //先从第一个表中取出符合条件的所有行 out_iter = iterator over tbl1 where col1 IN(5,6) outer_row = out_iter.next //在while循环中遍历第一个表结果集的每一行 while outer_row //对于第一个表结果集中的每一行，在第二个表中找出符合条件的所有行 inner_iter = iterator over tbl2 where col3 = outer_row.col3 inner_row = inner_iter.next while inner_row //将第一个表的结果列和第二个表的结果列拼装在一起作为结果输出 output[outer_row.col1, inner_row.col2] inner_row = inner_iter.next end //回溯，再根据第一个表结果集的下一行，继续上面的过程 outer_row = outer_iter.next end 对于单表查询，那么只需要完成上面外层的基本操作。优化关联查询，要确保ON或者USING子句中的列上有索引，并且在建立索引时需要考虑到关联的顺序。通常来说，只需要在关联顺序中的第二个表的相应列上创建索引。例如，当表A和表B用列c关联的时候，假设关联的顺序是B、A，那么就不需要在B表的c列上建立索引。没有用到的索引只会带来额外的负担。此外，确保任何的GROUP BY和ORDER BY中的表达式只涉及到一个表中的列，这样才能使用索引来优化这个过程。 临时表的概念上面提到在MySql中，任何一个查询实质上都是一个关联查询。那么对于子查询或UNION查询是如何实现关联操作的呢。对于UNION查询，MySql先将每一个单表查询结果放到一个临时表中，然后再重新读出临时表数据来完成UNION查询。MySql读取结果临时表和普通表一样，也是采用的关联方式。当遇到子查询时，先执行子查询并将结果放到一个临时表中，然后再将这个临时表当做一个普通表对待。MySql的临时表是没有任何索引的，在编写复杂的子查询和关联查询的时候需要注意这一点。临时表也叫派生表。 排序优化应该尽量让MySql使用索引进行排序。当不能使用索引生成排序结果的时候，MySql需要自己进行排序。如果数据量小于“排序缓冲区”的大小，则MySql使用内存进行“快速排序”操作。如果数据量太大超过“排序缓冲区”的大小，那么MySql只能采用文件排序，而文件排序的算法非常复杂，会消耗很多资源。无论如何排序都是一个成本很高的操作，所以从性能角度考虑，应尽可能避免排序。所以让MySql根据索引构造排序结果非常的重要。 子查询优化MySql的子查询实现的非常糟糕。最糟糕的一类查询是WHERE条件中包含IN()的子查询语句。应该尽可能用关联替换子查询，可以提高查询效率。 优化COUNT()查询COUNT()有两个不同的作用： 统计某个列值的数量，即统计某列值不为NULL的个数。 统计行数。 当使用COUNT(*)时，统计的是行数，它会忽略所有的列而直接统计所有的行数。而在括号中指定了一个列的话，则统计的是这个列上值不为NULL的个数。可以考虑使用索引覆盖扫描或增加汇总表对COUNT()进行优化。 优化LIMIT分页处理分页会使用到LIMIT，当翻页到非常靠后的页面的时候，偏移量会非常大，这时LIMIT的效率会非常差。例如对于***LIMIT 10000，20***这样的查询，MySql需要查询10020条记录，将前面10000条记录抛弃，只返回最后的20条。这样的代价非常高，如果所有的页面被访问的频率都相同，那么这样的查询平均需要访问半个表的数据。优化此类分页查询的一个最简单的办法就是尽可能地使用索引覆盖扫描，而不是查询所有的列。然后根据需要与原表做一次关联操作返回所需的列。对于偏移量很大的时候，这样的效率会提升非常大。考虑下面的查询： SELECT film_id, description FROM sakila.film ORDER BY title LIMIT 50, 5; 如果这个表非常大，那么这个查询最好改写成下面的这样子： SELECT film.film_id, film.description FROM sakila.film INNER JOIN (SELECT film_id FROM sakila.film ORDER BY title LIMIT 50,5) AS lim USING(film_id); 注意优化中关联的子查询，因为只查询film_id一个列，数据量小，使得一个内存页可以容纳更多的数据，这让MySQL扫描尽可能少的页面。在获取到所需要的所有行之后再与原表进行关联以获得需要的全部列。LIMIT的优化问题，其实是OFFSET的问题，它会导致MySql扫描大量不需要的行然后再抛弃掉。可以借助书签的思想记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就避免了使用OFFSET。可以把主键当做书签使用，例如下面的查询： SELECT * FROM sakila.rental ORDER BY rental_id DESC LIMIT 20; 假设上面的查询返回的是主键为16049到16030的租借记录，那么下一页查询就可以直接从16030这个点开始： SELECT * FROM sakila.rental WHERE rental_id &lt; 16030 ORDER BY rental_id DESC LIMIT 20; 该技术的好处是无论翻页到多么后面，其性能都会很好。此外，也可以用关联到一个冗余表的方式提高LIMIT的性能，冗余表只包含主键列和需要做排序的数据列。 优化UNION查询除非确实需要服务器消除重复的行，否则一定要使用UNION ALL。如果没有ALL关键字，MySql会给临时表加上DISTINCT选项，这会导致对整个临时表的数据做唯一性检查。这样做的代价非常高。","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"MySQL索引原理和实现","slug":"面试题/MySQL索引原理和实现","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/mysql-suo-yin-yuan-li-he-shi-xian/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/mysql-suo-yin-yuan-li-he-shi-xian/","excerpt":"","text":"MySQL索引原理和实现","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"Java之synchronized和Lock的区别","slug":"面试题/Java之synchronized和Lock的区别","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/java-zhi-synchronized-he-lock-de-qu-bie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/java-zhi-synchronized-he-lock-de-qu-bie/","excerpt":"","text":"Java之synchronized和Lock的区别 Lock是java的一个interface接口，而synchronized是Java中的关键字，synchronized是由JDK实现的，不需要程序员编写代码去控制加锁和释放；Lock的接口如下： public interface Lock &amp;#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition(); &amp;#125; synchronized修饰的代码在执行异常时，jdk会自动释放线程占有的锁，不需要程序员去控制释放锁，因此不会导致死锁现象发生；但是，当Lock发生异常时，如果程序没有通过unLock()去释放锁，则很可能造成死锁现象，因此Lock一般都是在finally块中释放锁；格式如下： Lock lock = new LockImpl; // new 一个Lock的实现类 lock.lock(); // 加锁 try&amp;#123; //todo &amp;#125;catch(Exception ex)&amp;#123; // todo &amp;#125;finally&amp;#123; lock.unlock(); //释放锁 &amp;#125; Lock可以让等待锁的线程响应中断处理，如tryLock(long time, TimeUnit unit)，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够中断，程序员无法控制； synchronized是非公平锁，Lock可以设置是否公平锁，默认是非公平锁； Lock的实现类ReentrantReadWriteLock提供了readLock()和writeLock()用来获取读锁和写锁的两个方法，这样多个线程可以进行同时读操作； Lock锁的范围有局限性，仅适用于代码块范围，而synchronized可以锁住代码块、对象实例、类； Lock可以绑定条件，实现分组唤醒需要的线程；synchronized要么随机唤醒一个，要么唤醒全部线程。","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"HashMap跟Hashtable有什么区别","slug":"面试题/HashMap跟Hashtable有什么区别","date":"2022-01-04T02:42:07.309Z","updated":"2022-01-04T02:42:07.309Z","comments":true,"path":"2022/01/04/mian-shi-ti/hashmap-gen-hashtable-you-shi-me-qu-bie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mian-shi-ti/hashmap-gen-hashtable-you-shi-me-qu-bie/","excerpt":"","text":"HashMap跟Hashtable有什么区别?HashMap和HashTable都是基于哈希表来实现键值映射的工具类,从公开的方法上来看，这两个类提供的，是一样的功能。都提供键值映射的服务，可以增、删、查、改键值对，可以对键、值、键值对提供遍历视图。支持浅拷贝，支持序列化。 从数据结构上看 : HashMap和HashTable都使用哈希表来存储键值对。在数据结构上是基本相同的，都创建了一个继承自Map.Entry的私有的内部类Entry，每一个Entry对象表示存储在哈希表中的一个键值对。可以说，有多少个键值对，就有多少个Entry对象. 得出结论，HashMap/HashTable内部用Entry数组实现哈希表，而对于映射到同一个哈希桶（数组的同一个位置）的键值对，使用Entry链表来存储(解决hash冲突)。 Entry对象唯一表示一个键值对，有四个属性： -K key 键对象 -V value 值对象 -int hash 键对象的hash值 -Entry entry 指向链表中下一个Entry对象，可为null，表示当前Entry对象在链表尾部 从继承体系上看 : 虽然都实现了Map、Cloneable、Serializable三个接口。但是HashMap继承自抽象类AbstractMap，而HashTable继承自抽象类Dictionary。其中Dictionary类是一个已经被废弃的类. 从公共方法上看 : HashMap是支持null键和null值的，而HashTable在遇到null时，会抛出NullPointerException异常。这并不是因为HashTable有什么特殊的实现层面的原因导致不能支持null键和null值，这仅仅是因为HashMap在实现时对null做了特殊处理，将null的hashCode值定为了0，从而将其存放在哈希表的第0个bucket中。在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。 从算法上看 : HashTable默认的初始大小为11，之后每次扩充为原来的2n+1。HashMap默认的初始化大小为16，之后每次扩充为原来的2倍。如果在创建时给定了初始化大小，那么HashTable会直接使用你给定的大小，而HashMap会将其扩充为2的幂次方大小。 因为哈希表的大小为素数时，简单的取模哈希的结果会更加均匀.这样设计可以减少哈希值冲突. 但是在取模计算时，如果模数是2的幂，那么我们可以直接使用位运算来得到结果，效率要大大高于做除法。hash计算的效率HashMap更胜一筹.HashMap由于使用了2的幂次方，所以在取模运算时不需要做除法，只需要位的与运算就可以了。但是由于引入的hash冲突加剧问题，HashMap在调用了对象的hashCode方法之后，又做了一些位运算在打散数据。 从线程安全上看 : Hashtable是线程安全的，它的每个方法中都加入了Synchronize方法。在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步. HashMap不是线程安全的，在多线程并发的环境下，可能会产生死锁等问题。使用HashMap时就必须要自己增加同步处理.HashMap进行同步： Map m = Collections.synchronizeMap(hashMap); 虽然HashMap不是线程安全的，但是它的效率会比Hashtable要好很多。这样设计是合理的。在我们的日常使用当中，大部分时间是单线程操作的。HashMap把这部分操作解放出来了。当需要多线程操作的时候可以使用线程安全的ConcurrentHashMap。ConcurrentHashMap虽然也是线程安全的，但是它的效率比Hashtable要高好多倍。因为ConcurrentHashMap使用了分段锁，并不对整个数据进行锁定。 从遍历方式上看 : Hashtable、HashMap都使用了 Iterator。而由于历史原因，Hashtable还使用了Enumeration的方式 . HashMap和jdk1.8以后的HashTable迭代器使用fast-fail机制 , 当有其它线程改变了HashMap的结构（增加，删除，修改元素），将会抛出ConcurrentModificationException。不过，通过Iterator的remove()方法移除元素则不会抛出ConcurrentModificationException异常。 每次在发生增删改的时候都会出现modCount++的动作。而modcount可以理解为是当前hashtable的状态。每发生一次操作，状态就向前走一步。设置这个状态，主要是由于hashtable等容器类在迭代时，判断数据是否过时时使用的。尽管hashtable采用了原生的同步锁来保护数据安全。但是在出现迭代数据的时候，则无法保证边迭代，边正确操作。于是使用这个值来标记状态。一旦在迭代的过程中状态发生了改变，则会快速抛出一个异常，终止迭代行为。 从使用角度上看 : 如果不需要线程安全，那么使用HashMap，如果需要线程安全，那么使用ConcurrentHashMap。HashTable已经被淘汰了，不要在新的代码中再使用它。 每一版本的JDK，都会对HashMap和HashTable的内部实现做优化，比如JDK 1.8的红黑树优化。所以尽可能的使用新版本的JDK，会有性能上有提升。 为什么HashTable已经淘汰了，还要优化它？因为有老的代码还在使用它，所以优化了它之后，这些老的代码也能获得性能提升。","categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[]},{"title":"程序设计语言基础知识","slug":"软考-数据库/程序设计语言基础知识","date":"2022-01-04T02:42:07.305Z","updated":"2022-01-04T02:42:07.305Z","comments":true,"path":"2022/01/04/ruan-kao-shu-ju-ku/cheng-xu-she-ji-yu-yan-ji-chu-zhi-shi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/ruan-kao-shu-ju-ku/cheng-xu-she-ji-yu-yan-ji-chu-zhi-shi/","excerpt":"","text":"程序设计语言基础知识1. 程序设计语言概述程序设计语言是为了书写计算机程序而人为设计的符号语言,用于对计算过程进行描述,组织和推导. 低级语言: 机器语言(计算机硬件只能识别0和1的指令序列),汇编语言 高级语言: 功能更强，抽象级别更高,与人们使用的自然语言比较接近. 各程序设计语言特点: 解释和编译:都是将高级语言翻译成计算机硬件认可的机器语言加以执行. 不同之处在于编译程序生成独立的可执行文件,直接运行,运行时无法控制源程序,效率高. 而解释程序不生成可执行文件,可以逐条解释运行,用于调式模式,可以控制源程序,因为还需要控制程序,因此执行速度慢,效率低. 程序设计语言组成: 语法: 一组规则 语义: 语法成分的含义 语用: 构成语言的各个记号和使用者的关系 2. 程序设计语言的基本成分数据成分: 指一种程序设计语言的数据和数据类型 数据分为常量(程序运行时不可改变)、变量(程序运行时可以改变)、全局量(存储空间在静态数据区分配)、局部量(存储空间在堆栈区分配) 数据类型有整形、字符型、双精度、单精度浮点型、布尔型. 运算成分: 指明允许使用的运算符号以及运算规则 包括: 算法运算、逻辑运算、关系运算、位运算等. 控制成分: 指明语言允许表述的控制结构. 包括顺序结构、选择结构、循环结构(初始化+循环体+循环条件) 传输成分: 指明语言允许的数据传输方式.如赋值处理、数据的输入输出等. 函数: C程序由一个或者多个函数组成,每个函数都一个名字,其中有且仅有一个名字为main 的函数作为程序运行时的起点. 函数是程序模块的主要成分,是一段具有独立功能的程序. 函数使用涉及三个概念, 函数定义、函数声明(先声明后使用)、函数调用. 传值调用: 将实参的值传递给形参,形参的改变不会导致调用点所传的实参的值的改变. 实参可以是合法的变量、常量、表达式. 传址调用: 即引用调用,将实参的地址传递给形参, 相当于实参存储单元的地址引用,因此其值改变的同时就改变了实参的值. 实参不能是常量,只能是合法的变量和表达式. 因此, 在编程中,要改变参数值,就传址, 不改变,就传值. 3. 编译程序的基本原理编译程序的功能是把某高级语言书写的源程序翻译成与之等价的目标程序(汇编语言或者机器语言), 编译程序工作过程分为6个阶段, 如下图所示: 语法分析:语法分析: 是编译过程的第一个阶段 这个阶段的任务是从左到右一个字符一个字符的读入源程序,即对构成源程序的字符串进行扫描然后根据构词规则识别单词(也称单词符号或符号) 语法分析:是编译过程的一个逻辑阶段 语法分析的任务是在词法分析的基础上将单词序列组合成各类语法短语,如“程序”、“语句”,‘“表达式’等等，语法分析程序判断源程序在结构上是否正确. 语义分析是编译过程的一个逻辑阶段 语法分析的任务是对结构上正确的源程序进行上下文有关性质的审查,进行类型审查. 如类型匹配, 除法除数不为0等. 又分为静态语义错误(在编译阶段能查出来)和动态语义错误(只能在运行时发现) 中间代码和目标代码生成: 中间代码是根据语义分析产生的,需要经过优化连接，最终生成可执行的目标代码. 引入中间代码的目的是进行与机器无法的代码优化处理. 常用的中间代码有后缀式(逆波兰式)、三元式(三地址码)、四元式和树等形式. 需要考虑三个问题: 一是如何生成较短的目标代码 二是如何充分利用计算机中的寄存器,减少目标代码访问存储单元的次数 三是如何充分利用计算机指令系统的特点,以提高目标代码的质量 表达式 主要掌握上述三种表达式即可,其实就是树的三种遍历,一般正常的表达式是中序遍历.即中缀遍历,根据其构造出树,再按照题目要求求出前缀或者后缀 简单求法: 后缀表达式是从左到右开始,先把表达式加上括号,再依次把运算符加到本层次的括号后面.","categories":[{"name":"软考-数据库","slug":"软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"软考-数据库","slug":"软考-数据库/软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"数据结构与算法","slug":"软考-数据库/数据结构与算法","date":"2022-01-04T02:42:07.301Z","updated":"2022-01-04T02:42:07.301Z","comments":true,"path":"2022/01/04/ruan-kao-shu-ju-ku/shu-ju-jie-gou-yu-suan-fa/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/ruan-kao-shu-ju-ku/shu-ju-jie-gou-yu-suan-fa/","excerpt":"","text":"数据结构与算法1. 线性结构线性结构: 每个元素最多只有一个出度和一个入度,表现为一条线状.线性表按存储方式分为顺序表和链表. 顺序存储用一组地址连续的存储单元依次存储线性表中的数据元素,使得逻辑上相邻的元素在物理上也相邻. 链式存储存储各数据元素的节点的地址并不要求是连续的,数据元素逻辑上相邻,物理上分开. 顺序存储和链表存储的对比 在空间上,因为链表还需要存储指针,因此有空间浪费的存在. 在时间方面, 由顺序表和链表的粗出方式可知,当需要对元素进行破坏性操作(插入/删除)时,链表效率更高,因此其只需要修改指针指向即可. 而顺序表因为地址是连续的, 当删除或插入一个元素后, 后面的其他节点位置都需要变动. 而当需要对元素不改变结构操作时(读取、查找),顺序表效率更高,因为其物理地址是连续的,如同数组一般,只需按索引号就可以快速定位, 而链表需要从头节点开始, 一个一个的查找下去. 1.1 单链表单链表的插入和删除 再上图中p所指向的节点后插入s所指定的节点,操作为: s->next=p>next p->next=s 同理,在单链表中删除p所指向的节点的后继节点q时, 操作为: p-&gt;next=p&gt;next-&gt;next free(p); 1.2 栈和队列队列和栈也是线性结构,结构如下图: 队列是先进先出,分对头和队尾. 栈是先进后出, 只有栈顶才能进出. 循环队列中,头指针指向第一个元素,尾指针指向最后一个元素的下一个位置,因此, 当队列空的时候,head=tail, 当队列满的时候 ，head=tail, 这样就无法区分了,因此,一般将队列少存一个元素,这样,队列满的条件就是head+1=tail,而考虑到是循环队列,必须要处于最大元素数来取余数,即(tail+1)%size=head,如上图所示的两个公式 循环队列的长度公示为(Q.tail-Q.head)%size. 优先队列:元素被赋予优先级,当访问元素时, 具有最高优先级的元素最先被删除,使用堆来存储,因为其不是按照元素进队列的顺序来决定的. 1.3 串字符串是一种特殊的线性表,其数据结构都是字符串 空串: 长度为0的字符串,没有任何字符 空格串: 由一个或者多个空格组成的串,空格是空白字符, 占一个字符长度. 字串: 串中任意长度的连续字符构成的序列称为字串.含有字串的串为主串. 串的模式匹配算法: 字串的定位操作,用于查找字串在主串中第一次出现的位置的算法. 基本的模式匹配算法:也称为布鲁特-福斯算法,其基本思想是从主串的第1各字符其与模式串的第一个字符进行比较,若相等,则继续逐个字符进行后续的比较. 否则从主串的第2个字符起与模式串的第1个字符重新比较,直至模式串中的每一个字符依次和主串中的一个连续的字符串列相等为止. 此时称为匹配成功, 否则称为匹配失败. KMP算法: 对基本模式匹配算法的改进,其改进之处在于:每当匹配过程中出现相比较的字符串不相等时,不需要回溯主串的字符位置指针,而是利用已经得到的”部分匹配” 结果将模式串 向右 滑动尽可能远的距离,再继续进行比较. 1.4 数组数组是定长线性表再维度上的扩展, 即线性表中的元素又是一个线性表. N维数组是一种同构的数据结构,其每个数据元素类型相同,结构一致. 一个m行n列的数组表示如下: 其可以表示为行向量形式或者列向量形式线性表,单个关系最多只有一个前驱和一个后继,本质上还是线性. 数组结构的特点: 数据元素数据固定,数组元素类型相同. 数组元素的下标关系具有上下界的约束且下标有序. 数组数据元素固定,一般不做插入和删除运算,适合于采用顺序结构. 数组存储地址的计算,特别是二维数组,要注意理解: 假设每个数组元素占用存储场地为len ,起始地址为a,存储地址计算如下: 1.5 矩阵1.5.1 特殊矩阵矩阵中的元素(或非0元素) 的分布有一定的规律. 常见的特殊矩阵有对称矩阵、三角矩阵、对角矩阵. 1.5.2 稀疏矩阵在一个矩阵中,若非零元素的个数远远少于零元素的个数,且非零元素的分布没有规律. 存储方式为三元组结构,即存储每个非零元素的(行、列、值) 1.6 广义表广义表是线性表的推广,是由0个或者多个单元素或者子表组成的有限序列. 广义表与线性表的区别: 线性表的元素都是结构上不可分的单元素,而广义表的元素既可以单元素,也可以是有结构的表. 广义表一般记为: LS=(a1,a2,.....an) 其中,LS是表名,ai是表元素,它可以是表(称为子表),也可以是数据元素(称为原子).其中n 是广义表的长度(也就是最外层包含的元素个数),n=0的广义表为空表,而递归定义的重数就是广义表的深度, 即定义中所含括号的重数(单边括号的个数,原子的深度为0, 空表的深度为1) head()和tail(), 取表头(广义表的第一个表元素,可以是子表也可以是单元素)和取表位(广义表中, 除了第一个表元素之外的其他所有表元素组成的表,非空广义表的表尾必定是一个表,即使表尾是单元素)操作.","categories":[{"name":"软考-数据库","slug":"软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"软考-数据库","slug":"软考-数据库/软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"设计模式之适配器模式(7)","slug":"设计模式/设计模式之适配器模式(7)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-gua-pei-qi-mo-shi-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-gua-pei-qi-mo-shi-7/","excerpt":"","text":"7. 设计模式之适配器模式(Adapter Pattren) 1. 概念Adapter 模式也叫适配器模式,是构造性模式的一种,通过Adapter模式可以改变已有类(或外部类)的接口形式.将一个类的接口转换成客户希望的另外一个接口.Apadter 模式使得原本由于接口不兼容而不能一起工作的哪些类可以一起工作. 2. 角色及其职责 Traget：Client 所使用的目标接口,可以是接口或者抽象类 Adaptee:需要适配的类接口 Adapter: 适配器,负责Adaptee的接口与Traget的接口进行适配 Client：与复合Traget接口的对象协调的类3. 分类3.1 类适配器模式原理: 通过继承来实现适配器功能&nbsp;&nbsp;Adapter 类继承Adaptee(被适配类),同时实现Traget接口(因为java不支持多继承,所以这里只能通过接口来实现多继承),在Client类中我们可以根据需要选择并创建任一符合需求的子类,来实现具体的功能被适配的类```javapackage com.formula.design.adapter; /** @author:luyanan @email:&#x6c;&#117;&#121;&#x61;&#110;&#97;&#110;&#48;&#55;&#49;&#x38;&#x40;&#49;&#x36;&#x33;&#x2e;&#x63;&#111;&#109; @date 2019/1/17 @introduce */public class Adaptee { /** * 220v的电压 */ public void v220() &#123; System.out.println(&quot;220v的电压&quot;); &#125; } 适配器 ```java package com.formula.design.adapter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/17 * @introduce **/ public class Adapter extends Adaptee &#123; public void v28() &#123; v220(); System.out.println(&quot;被适配成了18V的电压&quot;); &#125; &#125; 测试类 package com.formula.design.adapter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/17 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; // 类适配器 Adapter adapter = new Adapter(); adapter.v28(); &amp;#125; &amp;#125; 测试结果 220v的电压 被适配成了18V的电压 3.2 对象适配器(委托方式)不使用多继承或者继承的方式,而使用直接关联 被适配的类 package com.formula.design.adapter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/17 * @introduce **/ public class Adaptee &amp;#123; /** * 220v的电压 */ public void v220() &amp;#123; System.out.println(\"220v的电压\"); &amp;#125; &amp;#125; 适配器类 package com.formula.design.adapter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/17 * @introduce **/ public class Adapter2 &amp;#123; private Adaptee adaptee; public Adapter2(Adaptee adaptee) &amp;#123; this.adaptee = adaptee; &amp;#125; public void v18() &amp;#123; adaptee.v220(); System.out.println(\"被适配成了18V的电压\"); &amp;#125; &amp;#125; 测试类 package com.formula.design.adapter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/17 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; // 对象适配器 Adapter2 adapter2 = new Adapter2(new Adaptee()); adapter2.v18();; &amp;#125; &amp;#125; 测试结果 220v的电压 被适配成了18V的电压 3.3 区别类适配器的重点在于类,是通过构造一个继承Adaptee类来实现适配器功能的 对象适配器的重点在于对象,是通过在直接包含Adaptee类来实现的.当需要调用特殊功能的时候直接调用Adapter中包含的那个Adaptee对象来调用特殊功能的方法即可 4. 优缺点4.1 优点:更好的复用性:系统需要使用现用的类,而此类的接口不符合系统的需要.那么使用适配器模式就可以让这些功能得到更好的复用 更好的扩展性:在实现适配器功能的时候,可以调用自己开发的功能,从而自然的扩展系统的功能 4.2 缺点过多的使用适配器,会让系统非常的凌乱,不易整体进行把握.比如,明明看到调用的是A接口,其实内部被适配成了B接口的实现,一个系统如果太多的出现这种情况,无异于异常灾难.因为如果不是很有必要,可以不使用适配器模式,而是直接对系统进行重构. 5. 适配器模式在源码中的体现Spring中适配器模式也应用的非常广泛,例如SpringAOP中的AdvisorAdapter,他有三个实现类 AfterReturningAdviceAdapter,MethodBeforeAdviceAdapter,ThrowsAdviceAdapter,我们先看顶层接口AdvisorAdapter的实现 public interface AdvisorAdapter &amp;#123; boolean supportsAdvice(Advice var1); MethodInterceptor getInterceptor(Advisor var1); &amp;#125; 再看 ThrowsAdviceAdapter // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package org.springframework.aop.framework.adapter; import java.io.Serializable; import org.aopalliance.aop.Advice; import org.aopalliance.intercept.MethodInterceptor; import org.springframework.aop.Advisor; import org.springframework.aop.ThrowsAdvice; class ThrowsAdviceAdapter implements AdvisorAdapter, Serializable &amp;#123; ThrowsAdviceAdapter() &amp;#123; &amp;#125; public boolean supportsAdvice(Advice advice) &amp;#123; return advice instanceof ThrowsAdvice; &amp;#125; public MethodInterceptor getInterceptor(Advisor advisor) &amp;#123; return new ThrowsAdviceInterceptor(advisor.getAdvice()); &amp;#125; &amp;#125; MethodBeforeAdviceAdapter // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package org.springframework.aop.framework.adapter; import java.io.Serializable; import org.aopalliance.aop.Advice; import org.aopalliance.intercept.MethodInterceptor; import org.springframework.aop.Advisor; import org.springframework.aop.MethodBeforeAdvice; class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &amp;#123; MethodBeforeAdviceAdapter() &amp;#123; &amp;#125; public boolean supportsAdvice(Advice advice) &amp;#123; return advice instanceof MethodBeforeAdvice; &amp;#125; public MethodInterceptor getInterceptor(Advisor advisor) &amp;#123; MethodBeforeAdvice advice = (MethodBeforeAdvice)advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &amp;#125; &amp;#125; // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package org.springframework.aop.framework.adapter; import java.io.Serializable; import org.aopalliance.aop.Advice; import org.aopalliance.intercept.MethodInterceptor; import org.springframework.aop.Advisor; import org.springframework.aop.AfterReturningAdvice; class AfterReturningAdviceAdapter implements AdvisorAdapter, Serializable &amp;#123; AfterReturningAdviceAdapter() &amp;#123; &amp;#125; public boolean supportsAdvice(Advice advice) &amp;#123; return advice instanceof AfterReturningAdvice; &amp;#125; public MethodInterceptor getInterceptor(Advisor advisor) &amp;#123; AfterReturningAdvice advice = (AfterReturningAdvice)advisor.getAdvice(); return new AfterReturningAdviceInterceptor(advice); &amp;#125; &amp;#125; Spring会根据不同的AOP配置来确定使用对应的Advice,跟策略模式不同的一个方法可以同时拥有多个Advice接下来看一个Spirng MVC的HandlerAdapter,他也有多个子类AbstractHandlerMethodAdapter,HttpRequestHandlerAdapter,RequestMappingHandlerAdapter,SimpleControllerHandlerAdapter,SimpleServletHandlerAdapter.其适配调用的关键代码是在 DispatcherServlet的doDispatch 方法 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &amp;#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &amp;#123; try &amp;#123; ModelAndView mv = null; Object dispatchException = null; try &amp;#123; processedRequest = this.checkMultipart(request); multipartRequestParsed = processedRequest != request; mappedHandler = this.getHandler(processedRequest); if (mappedHandler == null) &amp;#123; this.noHandlerFound(processedRequest, response); return; &amp;#125; HandlerAdapter ha = this.getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &amp;#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (this.logger.isDebugEnabled()) &amp;#123; this.logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &amp;#125; if ((new ServletWebRequest(request, response)).checkNotModified(lastModified) &amp;&amp; isGet) &amp;#123; return; &amp;#125; &amp;#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &amp;#123; return; &amp;#125; mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &amp;#123; return; &amp;#125; this.applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &amp;#125; catch (Exception var20) &amp;#123; dispatchException = var20; &amp;#125; catch (Throwable var21) &amp;#123; dispatchException = new NestedServletException(\"Handler dispatch failed\", var21); &amp;#125; this.processDispatchResult(processedRequest, response, mappedHandler, mv, (Exception)dispatchException); &amp;#125; catch (Exception var22) &amp;#123; this.triggerAfterCompletion(processedRequest, response, mappedHandler, var22); &amp;#125; catch (Throwable var23) &amp;#123; this.triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", var23)); &amp;#125; &amp;#125; finally &amp;#123; if (asyncManager.isConcurrentHandlingStarted()) &amp;#123; if (mappedHandler != null) &amp;#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &amp;#125; &amp;#125; else if (multipartRequestParsed) &amp;#123; this.cleanupMultipart(processedRequest); &amp;#125; &amp;#125; &amp;#125; 在 doDispatch()方法中调用了getHandlerAdapter()方法, protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &amp;#123; if (this.handlerAdapters != null) &amp;#123; Iterator var2 = this.handlerAdapters.iterator(); while(var2.hasNext()) &amp;#123; HandlerAdapter ha = (HandlerAdapter)var2.next(); if (this.logger.isTraceEnabled()) &amp;#123; this.logger.trace(\"Testing handler adapter [\" + ha + \"]\"); &amp;#125; if (ha.supports(handler)) &amp;#123; return ha; &amp;#125; &amp;#125; &amp;#125; throw new ServletException(\"No adapter for handler [\" + handler + \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\"); &amp;#125; 在getHandlerAdapter()方法中循环调用了supports()方法判断是否兼容,循环迭代集合中的Adapter又是在初始化的时候早已赋值.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"elasticsratch问题","slug":"疑难杂症/elasticsratch问题","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/yi-nan-za-zheng/elasticsratch-wen-ti/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/yi-nan-za-zheng/elasticsratch-wen-ti/","excerpt":"","text":"max virtual memory areas vm.max_map_count [65530] is too low, increase to at least 修改/etc/sysctl.conf文件，增加配置vm.max_map_count=262144 vi /etc/sysctl.conf sysctl -p 执行命令sysctl -p生效 创建用户新建用户，每台服务器都要新建，ES不允许root用户运行 groupadd elsearch 新增elsearch用户组 useradd elsearch -g elsearch -p elasticsearch 创建elsearch用户 chown -R elsearch:elsearch ./elasticsearch-6.6.1 用户目录权限 3.切换到elsearch用户下，启动ES su elsearch cd /opt/dp/elasticsearch-6.6.1/bin ./elasticsearch &","categories":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"疑难杂症","slug":"疑难杂症/疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}],"tags":[]},{"title":"启动 WSL 2时警告“参考的对象类型不支持尝试的操作”","slug":"疑难杂症/启动 WSL 2时警告“参考的对象类型不支持尝试的操作”","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/yi-nan-za-zheng/qi-dong-wsl-2-shi-jing-gao-can-kao-de-dui-xiang-lei-xing-bu-zhi-chi-chang-shi-de-cao-zuo/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/yi-nan-za-zheng/qi-dong-wsl-2-shi-jing-gao-can-kao-de-dui-xiang-lei-xing-bu-zhi-chi-chang-shi-de-cao-zuo/","excerpt":"","text":"启动 WSL 2时警告“参考的对象类型不支持尝试的操作”出现图中所示错误的原因是 代理软件与 wsl2 的端口冲突。 在管理员身份模式下执行 netsh winsock reset ,可以重新启动 WSL。 此操作会导致代理软件（proxifier）无法使用，请谨慎操作。Github Issue1Github Issue2 使用 NoLsp.exe 下载链接 备用下载链接 使用管理员身份运行以下命令: NoLsp.exe C:\\Windows\\system32\\wsl.exe1参数为 wsl 的绝对路径（默认为 C:\\Windows\\system32\\wsl.exe） 问题原因及解决方案的讨论见 Gihub Issue————————————————版权声明：本文为CSDN博主「yingming006の」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/MShow006/article/details/103774672","categories":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"疑难杂症","slug":"疑难杂症/疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}],"tags":[]},{"title":"CENTOS 7 和 JDK 添加中文字体","slug":"疑难杂症/CENTOS 7 和 JDK 添加中文字体","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/yi-nan-za-zheng/centos-7-he-jdk-tian-jia-zhong-wen-zi-ti/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/yi-nan-za-zheng/centos-7-he-jdk-tian-jia-zhong-wen-zi-ti/","excerpt":"","text":"CENTOS 7 和 JDK 添加中文字体【1】在我们的 Windows 的 C:\\Windows\\Fonts 下面选择一个中文字体，如宋体，先拷贝到桌面，然后字体就变成了英文的：*SIMSUN.TTC* 备注：我这里只是写了 Windows 的，没有用过 Mac 系列的 … 【2】在服务器上面建立相关目录，为了便于区分，我们把目录名字叫做 ****zh_CN****： mkdir /usr/share/fonts/zh_CN 【3】上传我们的字体到该目录下并改名为 simsun.ttf，上传可以在 CENTOS 上面 yum 安装 lrzsz，之后我们就能直接敲 *rz* 命令或者拖拽进行交互式上传文件了： cd /usr/share/fonts/zh_CN mv SIMSUN.TTC simsun.ttf 【4】收集系统的字体，保存到相关文件，此时会在当前目录生成 fonts.scale 文件： yum -y install ttmkfdir ttmkfdir -e /usr/share/X11/fonts/encodings/encodings.dir 【5】为了不重启机器，我们手动添加配置，强迫症顺便还帮他调整了一下格式： vi /etc/fonts/fonts.conf # 内容如下 &lt;dir&gt;/usr/share/fonts/zh_CN&lt;/dir&gt; 给JDK添加中文字体 由于 JDK 添加中文字体比较简单，这里就直接给出方法： # 进入 JDK 的目录 cd /usr/local/jdk1.7.0_79/jre/lib/fonts yum install mkfontscale yum install fontconfig # 创建目录 mkdir fallback cd fallback # 将公共系统那个中文字体拷贝过来 cp /usr/share/fonts/zh_CN/simsun.ttf . # 生效 mkfontscale mkfontdi","categories":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"疑难杂症","slug":"疑难杂症/疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}],"tags":[]},{"title":"Centos安装openoffice","slug":"疑难杂症/Centos安装openoffice","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/yi-nan-za-zheng/centos-an-zhuang-openoffice/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/yi-nan-za-zheng/centos-an-zhuang-openoffice/","excerpt":"","text":"Centos 安装openoffice下载wget https://jaist.dl.sourceforge.net/project/openofficeorg.mirror/4.1.9/binaries/zh-CN/Apache_OpenOffice_4.1.9_Linux_x86-64_install-rpm_zh-CN.tar.gz --2021-04-28 10:33:26-- https://jaist.dl.sourceforge.net/project/openofficeorg.mirror/4.1.9/binaries/zh-CN/Apache_OpenOffice_4.1.9_Linux_x86-64_install-rpm_zh-CN.tar.gz 解压，得到zh-CN目录。tar -zxvf Apache_OpenOffice_4.1.9_Linux_x86-64_install-rpm_zh-CN.tar.gz 进入zh-CN文件夹下的RPMS目录下，执行yum localinstall *.rpm安装必要的包。（或者执行：rpm -Uvih *rpm）rpm -Uvih *rpm cd desktop-integration/ rpm -ivh openoffice4.1.9-redhat-menus-4.1.9-9805.noarch.rpm cd /opt/openoffice4/program/ yum install libXext.x86_64 yum groupinstall \"X Window System\" ## 启动 nohup soffice -headless -accept=\"socket,host=127.0.0.1,port=8100;urp;\" -nofirststartwizard &amp;","categories":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"疑难杂症","slug":"疑难杂症/疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}],"tags":[]},{"title":"设计模式简介","slug":"设计模式/设计模式简介","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-jian-jie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-jian-jie/","excerpt":"","text":"设计模式简介1. 设计模式简介 设计模式是一套被反复使用的,多数人只晓得,经过分类编写的,代码设计经验的总结.使用设计模式是为了重用代码,让代码更容易被他们理解,保证代码的可靠性. 2. 设计模式的设计原则 对接口编程而不是对实现编程 优先使用对象组合而不是继承3.设计模式的类型1. 创建型模式 1.1 描述这些设计模式提供了一种在创建对象的同时隐藏逻辑的方法,而不是使用new 运算符直接实例化对象.这使得程序在判断针对某个给定实例需要创建那些对象时更加灵活 1.2 包括 工厂模式(Factory Pattern) 抽象工厂模式(Abstract Factory Pattren) 单例模式(Singleton Pattren) 建造者模式(Builder Pattren) 原型模式(Prototype Pattren) 2. 结构性模式2.1 描述这些设计模式关注类和对象的组合.继承的概念被用来组合接口和定义组合对象获得新功能的方式 2.2 包括 适配器模式(Adapter Pattren) 桥接模式(Bridge Pattren) 过滤器模式(Filter,Criteria Pattren) 组合模式(Composite Pattren) 装饰器模式(Decorator Pattren) 外观模式(Facade Pattren) 享元模式(Flyweight Pattren) 代理模式(Proxy Pattren)3. 行为型模式3.1 描述这些设计模式特别关注对象之间的通信3.2 包括 责任链模式(Chain of Responblity Pattren) 命令模式(Command Pattren) 解释器模式(Interpreter Pattren) 迭代器模式(Iterator Pattren) 中介者模式(Mediator Pattren) 备忘录模式(Memento Pattren) 观察者模式(Observer Pattren) 状态模式(State Pattren) 空对象模式(Null Object Pattren) 策略模式(Strategy Pattren) 模板模式(Template Pattren) 访问者模式(Visitor Pattren)4. J2EE 模式4.1 描述这些设计模式特别关注表示层,这些模式是由Sun Java Center 鉴定的4.2 包括 MVC 模式(MVC Pattren) 业务代表模式(Business Deledate Pattren) 组合实体模式(Composite Entity Pattren) 数据访问对象模式(Data Access Object Pattren) 前端控制器模式(Front Controller Pattren) 拦截过滤器模式(Interception Filter Pattren) 服务定位器模式(Service Locator Pattren) 传输对象模式(Transfer Object Pattren)4. 设计模式的六大原则 开闭原则开闭原则的意思是:对扩展开放,对修改关闭.在程序需要进行拓展的时候,不能去修改原有的代码,实现一个热插拔的效果.简言之,是为了使程序的扩展性好,易与维护和升级.想达到这样的效果,我们就需要使用接口和抽象类 里氏代换原则 里氏代换原则是面向对象设计的基本原则之一.里氏原则中说,任何基类可以出现的地方,子类一定可以出现.LSP 是继承复用的基石,只有当派生类可以替换掉基类,且软件单位的功能不受到影响时,基类才能真正被复用,而派生类也能够在基类的基础上增加新的行为.里氏代换原则是对开闭原则的补充.实现开闭原则的关键步骤就是抽象化,而基类与子类的继承关系就是抽象化的具体实现,所以里氏代换原则是对实现抽象化的具体步骤的规范 依赖倒置原则这个原则是开闭原则的基础,具体内容:针对接口编程,依赖与抽象而不依赖与具体 接口隔离原则这个原则的意思是:使用多个隔离的接口,比使用单个接口要好.它还有另外一个意思是:降低类之间的耦合度.由此可见,其实设计模式就是从大型软件架构出发,便于维护和升级的软件设计思想,它强调降低依赖,降低耦合 迪米特法则,又称最少知道原则 最少知道原则是指: 一个实体应当尽量减少与其他实体之间发生相互作用,使得系统功能模块相对独立 合成复用原则 合成复用原则是指:尽量使用合成/聚合的方式,而不是使用继承 单一职责原则单一职责原则是指不要存在多于一个导致类变更的原因.假设我们有一个Class负责两个职责,一旦发生需求变更,修改其中一个职责的逻辑代码,有可能会导致另一个职责的功能发生故障,这样一来,这个Class存在两个导致类变更的原因 。 如何解决这个问题呢?我们就要給这两个职责分别以两个Class实现进行解耦.后期需求变更维护互不影响.这样的设计,可以降低类的复杂度,提高类的可读性,提高系统的可维护性,降低变更引起的风险.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"Spring Boot 出现Failed to decode downloaded font和OTS parsing error Failed to convert WOFF 2","slug":"疑难杂症/Spring Boot 出现Failed to decode downloaded font和OTS parsing error Failed to convert WOFF 2.0 font to SFNT","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/yi-nan-za-zheng/spring-boot-chu-xian-failed-to-decode-downloaded-font-he-ots-parsing-error-failed-to-convert-woff-2.0-font-to-sfnt/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/yi-nan-za-zheng/spring-boot-chu-xian-failed-to-decode-downloaded-font-he-ots-parsing-error-failed-to-convert-woff-2.0-font-to-sfnt/","excerpt":"","text":"Spring Boot 出现”Failed to decode downloaded font”和”OTS parsing error: Failed to convert WOFF 2.0 font to SFNT”准确来讲，应该是maven项目使用Bootstrap时，出现 “Failed to decode downloaded font“和”OTS parsing error: Failed to convert WOFF 2.0 font to SFNT“ 导致图标出不来的问题。 解决方案： 设置filter，font文件不需要filter，见下面示例： &lt;resources> &lt;resource> &lt;directory>src/main/resources&lt;/directory> &lt;filtering>true&lt;/filtering> &lt;excludes> &lt;exclude>static/fonts/**&lt;/exclude> &lt;/excludes> &lt;/resource> &lt;resource> &lt;directory>src/main/resources&lt;/directory> &lt;filtering>false&lt;/filtering> &lt;includes> &lt;include>static/fonts/**&lt;/include> &lt;/includes> &lt;/resource> &lt;/resources> 原因： 上面的xml里也写了，因为经过maven的filter，会破坏font文件的二进制文件格式，到时前台解析出错。","categories":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"疑难杂症","slug":"疑难杂症/疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}],"tags":[]},{"title":"设计模式之观察者模式(21)","slug":"设计模式/设计模式之观察者模式(21)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-guan-cha-zhe-mo-shi-21/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-guan-cha-zhe-mo-shi-21/","excerpt":"","text":"21. 设计模式之观察者模式(Observer Pattern) 1. 概念Observer模式是行为模式的一种,它的作用是当一个对象的状态发生变化的时候,能够自动的通知其他的关联对象,自动刷新对象状态.Observer模式提供给关联对象一种同步通信的手段,使某个对象与依赖他的其他对象之间保持状态同步. 2. 使用场景 侦听事件驱动程序设计中的外部事件 侦听/监视某个对象的状态变化 发布者/订阅者模式中,当一个外部事件(新的产品,消息的出现等等)被处罚的时候,通知邮件列表中的订阅者3. 角色和职责 Subject(被观察者):被观察的对象.当需要被观察的状态发生变化的时候,需要通知队列中所有的观察者对象.Subject需要维持(添加,删除,通知)一个观察者对象的队列列表. ConcreteSubject 被观察者的具体实现,包含一些基本的属性状态以及其他操作 Observer(观察者):接口或者抽象类,当Subject的状态发生变化的时候,Observer对象将通过一个callback函数得到通知. ConcreteObserver: 观察者的具体实现,得到通知后将会完成一些具体的业务逻辑处理.4. 优缺点:4.1 优点: 观察者与被观察者之间的抽象耦合的 建立一套触发机制4.2 缺点: 如果一个被观察者对象有很多的直接和间接 的观察者的话,将所有观察者都通知到会花费很多的时间. 如果在观察者和观察目标之间有循环依赖的话,观察目标会触发他们之间进行循环调用,可能导致系统崩溃. 观察者模式没有相应的机制将观察者之间所观察的目标对象是怎么发生变化的,而仅仅只是知道观察对象发生了变化.5 代码实例5.1 使用JDK自带的Observable 实现被观察类需要继承 Observable```javapackage com.formula.design.observer.jdk; import java.util.Observable; /** @author:luyanan @email:&#x6c;&#117;&#x79;&#x61;&#110;&#97;&#x6e;&#x30;&#55;&#49;&#56;&#64;&#x31;&#x36;&#x33;&#x2e;&#99;&#x6f;&#x6d; @date 2019/2/19 @introduce */public class Person extends Observable { private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.setChanged(); this.name = name; this.notifyObservers(); &#125; } 观察类的具体实现 ```java package com.formula.design.observer.jdk; import java.util.Observable; import java.util.Observer; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/19 * @introduce **/ public class MyObserver implements Observer &#123; @Override public void update(Observable o, Object arg) &#123; System.out.println(&quot;接到通知:对象发生变化&quot;); &#125; &#125; 测试类 package com.formula.design.observer.jdk; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/19 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Person person = new Person(); person.addObserver(new MyObserver()); person.setName(\"张三\"); &amp;#125; &amp;#125; 结果 接到通知:对象发生变化 5.2 自己定义接口实现package com.formula.design.observer.custom; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/19 * @introduce 定义观察者 **/ public abstract class Observer &amp;#123; public abstract void update(Object obj); public abstract void update(); &amp;#125; package com.formula.design.observer.custom; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/19 * @introduce **/ public class MyObservable implements Observable &amp;#123; //被观察者维护的一个观察者列表 private List&lt;Observer> observerList = new ArrayList&lt;>(); private String name; public MyObservable(String name) &amp;#123; this.name = name; &amp;#125; @Override public void registerObserver(Observer observer) &amp;#123; observerList.add(observer); &amp;#125; @Override public void removeObserver(Observer observer) &amp;#123; observerList.remove(observer); &amp;#125; @Override public void noifyObservers() &amp;#123; observerList.stream().forEach(observer -> &amp;#123; observer.update(name); &amp;#125;); &amp;#125; &amp;#125; package com.formula.design.observer.custom; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/19 * @introduce 被观察者 **/ public interface Observable &amp;#123; /** * 注册成观察者 * * @param observer */ void registerObserver(Observer observer); /** * 取消为观察者 * * @param observer */ void removeObserver(Observer observer); /** * 通知所有观察者 */ void noifyObservers(); &amp;#125; package com.formula.design.observer.custom; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/19 * @introduce **/ public class CustomObserver extends Observer &amp;#123; @Override public void update(Object obj) &amp;#123; &amp;#125; @Override public void update() &amp;#123; &amp;#125; &amp;#125; package com.formula.design.observer.custom; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/19 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Person person = new Person(); person.setName(\"张三\"); MyObservable observable = new MyObservable(\"\"); observable.registerObserver(person); observable.noifyObservers(); &amp;#125; &amp;#125; 名称发生变化: JDK源码中,观察者模式的应用也特别多,例如java.awt.Event 就是观察者模式的一种,接下来我们自己用代码来实现一下 package com.notes.pattern.observer.awt; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; import java.lang.reflect.Method; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce 监听器的一种包装, 标准事件源格式的定义 **/ @Data @Builder @AllArgsConstructor @NoArgsConstructor public class Event &amp;#123; /** * 事件源,事件是由谁发起的保存起来 */ private Object source; /** * 事件触发,要通知谁 */ private Object target; /** * 事件触发,要做什么动作,回调 */ private Method callBack; /** * 事件的名称,触发的是什么事件 */ private String trigger; /** * 事件触发的事件 */ private Long time; public Event(Object target, Method callBack) &amp;#123; this.target = target; this.callBack = callBack; &amp;#125; &amp;#125; package com.notes.pattern.observer.awt; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; import java.util.HashMap; import java.util.Map; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce 监听器, 它就是观察者的桥梁 **/ public class EventLisenter &amp;#123; protected Map&lt;String, Event> eventMap = new HashMap&lt;>(); /** * 事件名称和一个目标对象来触发事件 * * @param eventType * @param target */ public void addLisenter(String eventType, Object target) &amp;#123; try &amp;#123; this.addLisenter(eventType, target, target.getClass().getMethod(\"on\" + toUpperFirstCase(eventType), Event.class)); &amp;#125; catch (NoSuchMethodException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; /** * 事件名称触发 * * @param trigger */ protected void trigger(String trigger) &amp;#123; if (!this.eventMap.containsKey(trigger)) &amp;#123; return; &amp;#125; Event event = this.eventMap.get(trigger); event.setTrigger(trigger); trigger(event); &amp;#125; private void trigger(Event event) &amp;#123; event.setSource(this); event.setTime(System.currentTimeMillis()); if (event.getCallBack() != null) &amp;#123; //用反射调用它的回调函数 try &amp;#123; event.getCallBack().invoke(event.getTarget(), event); &amp;#125; catch (IllegalAccessException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (InvocationTargetException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; private void addLisenter(String eventType, Object target, Method method) &amp;#123; eventMap.put(eventType, new Event(target, method)); &amp;#125; //逻辑处理的私有方法，首字母大写 private String toUpperFirstCase(String str) &amp;#123; char[] chars = str.toCharArray(); chars[0] -= 32; return String.valueOf(chars); &amp;#125; &amp;#125; package com.notes.pattern.observer.awt; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public class Mouse extends EventLisenter &amp;#123; public void click() &amp;#123; System.out.println(\"调用单击方法\"); this.trigger(MouseEventType.ON_CLICK); &amp;#125; public void doubleClick() &amp;#123; System.out.println(\"调用双击方法\"); this.trigger(MouseEventType.ON_DOUBLE_CLICK); &amp;#125; public void up() &amp;#123; System.out.println(\"调用按下方法\"); this.trigger(MouseEventType.ON_UP); &amp;#125; public void move() &amp;#123; System.out.println(\"调用移动方法\"); this.trigger(MouseEventType.ON_MOVE); &amp;#125; public void wheel() &amp;#123; System.out.println(\"调用滚动方法\"); this.trigger(MouseEventType.ON_WHEEL); &amp;#125; public void over() &amp;#123; System.out.println(\"调用悬停方法\"); this.trigger(MouseEventType.ON_OVER); &amp;#125; public void blur() &amp;#123; System.out.println(\"调用获焦方法\"); this.trigger(MouseEventType.ON_BLUR); &amp;#125; public void focus() &amp;#123; System.out.println(\"调用失焦方法\"); this.trigger(MouseEventType.ON_FOCUS); &amp;#125; &amp;#125; package com.notes.pattern.observer.awt; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public interface MouseEventType &amp;#123; //单击 String ON_CLICK = \"click\"; //双击 String ON_DOUBLE_CLICK = \"doubleClick\"; //弹起 String ON_UP = \"up\"; //按下 String ON_DOWN = \"down\"; //移动 String ON_MOVE = \"move\"; //滚动 String ON_WHEEL = \"wheel\"; //悬停 String ON_OVER = \"over\"; //失焦 String ON_BLUR = \"blur\"; //获焦 String ON_FOCUS = \"focus\"; &amp;#125; package com.notes.pattern.observer.awt; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public class MouseEventCallback &amp;#123; public void onClick(Event e)&amp;#123; System.out.println(\"===========触发鼠标单击事件==========\" + \"\\n\" + e); &amp;#125; public void onDoubleClick(Event e)&amp;#123; System.out.println(\"===========触发鼠标双击事件==========\" + \"\\n\" + e); &amp;#125; public void onUp(Event e)&amp;#123; System.out.println(\"===========触发鼠标弹起事件==========\" + \"\\n\" + e); &amp;#125; public void onDown(Event e)&amp;#123; System.out.println(\"===========触发鼠标按下事件==========\" + \"\\n\" + e); &amp;#125; public void onMove(Event e)&amp;#123; System.out.println(\"===========触发鼠标移动事件==========\" + \"\\n\" + e); &amp;#125; public void onWheel(Event e)&amp;#123; System.out.println(\"===========触发鼠标滚动事件==========\" + \"\\n\" + e); &amp;#125; public void onOver(Event e)&amp;#123; System.out.println(\"===========触发鼠标悬停事件==========\" + \"\\n\" + e); &amp;#125; public void onBlur(Event e)&amp;#123; System.out.println(\"===========触发鼠标失焦事件==========\" + \"\\n\" + e); &amp;#125; public void onFocus(Event e)&amp;#123; System.out.println(\"===========触发鼠标获焦事件==========\" + \"\\n\" + e); &amp;#125; &amp;#125; package com.notes.pattern.observer.awt; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public class Mouse extends EventLisenter &amp;#123; public void click() &amp;#123; System.out.println(\"调用单击方法\"); this.trigger(MouseEventType.ON_CLICK); &amp;#125; public void doubleClick() &amp;#123; System.out.println(\"调用双击方法\"); this.trigger(MouseEventType.ON_DOUBLE_CLICK); &amp;#125; public void up() &amp;#123; System.out.println(\"调用按下方法\"); this.trigger(MouseEventType.ON_UP); &amp;#125; public void move() &amp;#123; System.out.println(\"调用移动方法\"); this.trigger(MouseEventType.ON_MOVE); &amp;#125; public void wheel() &amp;#123; System.out.println(\"调用滚动方法\"); this.trigger(MouseEventType.ON_WHEEL); &amp;#125; public void over() &amp;#123; System.out.println(\"调用悬停方法\"); this.trigger(MouseEventType.ON_OVER); &amp;#125; public void blur() &amp;#123; System.out.println(\"调用获焦方法\"); this.trigger(MouseEventType.ON_BLUR); &amp;#125; public void focus() &amp;#123; System.out.println(\"调用失焦方法\"); this.trigger(MouseEventType.ON_FOCUS); &amp;#125; &amp;#125; 测试类 package com.notes.pattern.observer.awt; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public class EventTest &amp;#123; public static void main(String[] args) &amp;#123; MouseEventCallback callback = new MouseEventCallback(); // 注册事件 Mouse mouse = new Mouse(); mouse.addLisenter(MouseEventType.ON_CLICK,callback); mouse.click(); &amp;#125; &amp;#125; 结果 调用单击方法 ===========触发鼠标单击事件========== Event(source=com.notes.pattern.observer.awt.Mouse@6d6f6e28, target=com.notes.pattern.observer.awt.MouseEventCallback@135fbaa4, callBack=public void com.notes.pattern.observer.awt.MouseEventCallback.onClick(com.notes.pattern.observer.awt.Event), trigger=click, time=1555483341275) 基于Guava实现观察者模式引入jar &lt;dependency> &lt;groupId>com.google.guava&lt;/groupId> &lt;artifactId>guava&lt;/artifactId> &lt;version>26.0-jre&lt;/version> &lt;/dependency> package com.notes.pattern.observer.guava; import com.google.common.eventbus.Subscribe; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public class GuavaEvent &amp;#123; @Subscribe public void subscribe(String str) &amp;#123; // 业务逻辑 System.out.println(\"执行subscribe 方法,传入的参数为---\" + str); &amp;#125; &amp;#125; 测试 package com.notes.pattern.observer.guava; import com.google.common.eventbus.EventBus; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public class GuavaEventTest &amp;#123; public static void main(String[] args) &amp;#123; EventBus eventBus = new EventBus(); GuavaEvent guavaEvent = new GuavaEvent(); eventBus.register(guavaEvent); eventBus.post(\"Guava\"); &amp;#125; &amp;#125; 结果 执行subscribe 方法,传入的参数为---Guava 5. 观察者模式在源码中的应用来看一下 Spring中的ContextLoaderListener,实现了ServletContextListener接口,ServletContextListener接口又实现了EventListener接口,在JDK中 EventListener有非常广泛的应用,我们来看一下ContextLoaderListener的代码 // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package org.springframework.web.context; import javax.servlet.ServletContextEvent; import javax.servlet.ServletContextListener; public class ContextLoaderListener extends ContextLoader implements ServletContextListener &amp;#123; public ContextLoaderListener() &amp;#123; &amp;#125; public ContextLoaderListener(WebApplicationContext context) &amp;#123; super(context); &amp;#125; public void contextInitialized(ServletContextEvent event) &amp;#123; this.initWebApplicationContext(event.getServletContext()); &amp;#125; public void contextDestroyed(ServletContextEvent event) &amp;#123; this.closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &amp;#125; &amp;#125; ServletContextListener // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package javax.servlet; import java.util.EventListener; public interface ServletContextListener extends EventListener &amp;#123; void contextInitialized(ServletContextEvent var1); void contextDestroyed(ServletContextEvent var1); &amp;#125; EventListener /* * Copyright (c) 1996, 1999, Oracle and/or its affiliates. All rights reserved. * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. */ package java.util; /** * A tagging interface that all event listener interfaces must extend. * @since JDK1.1 */ public interface EventListener &amp;#123; &amp;#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之单例模式(4)","slug":"设计模式/设计模式之单例模式(4)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-dan-li-mo-shi-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-dan-li-mo-shi-4/","excerpt":"","text":"4. 设计模式之单例模式(Singleton Pattren) 1. 概念 &nbsp;&nbsp;&nbsp;&nbsp; 单例模式是一种对象创建型模式,使用单例模式,可以保证为一个类只生成唯一的实例对象.也就是说,在整个程序空间中,该类之存在一个实例对象. &nbsp;&nbsp;&nbsp;&nbsp; 其实,Gof对单例模式的定义是:保证一个类只有一个实例的存在,同时提供能对该实例加以访问的全局访问方法 2. 为什么使用单例模式 在应用系统开发中,通常有这样的需求: 在多个线程之间,比如Servlet环境,共享同一个资源或者操作同一个对象 在整个程序空间中使用全局变量,节省资源 大规模系统中,为了性能的考虑,需要节省对象的创建时间等等.因为Singleton 模式可以保证为一个类只生成唯一的实例对象,所以这些情况下,Singleton 模式就派上了用场3. 单例模式的实现3.1. 懒汉式,线程不安全 是否Lazy初始化:是是否多线程安全:否&nbsp;&nbsp;&nbsp;&nbsp;这种方式是最基本实现方式,这种实现最大的问题是不支持多线程,因为没有加锁synchronized,所以严格意义上并不算单例模式,这种方式懒加载模式十分明显,不要求线程安全,在多线程下不能正常工作 package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/12 * @introduce 懒汉式 线程不安全 **/ public class SingletonObject1 &amp;#123; private static SingletonObject1 instance; private SingletonObject1() &amp;#123; &amp;#125; public static SingletonObject1 getInstance() &amp;#123; if (null == instance) &amp;#123; instance = new SingletonObject1(); &amp;#125; return instance; &amp;#125; &amp;#125; 3.2. 懒汉式,线程安全是否Lazy初始化:是是否多线程安全:是&nbsp;&nbsp;&nbsp;&nbsp;这种方式具备很好的懒加载,能够在多线程下很好的工作,但是效率很低,99%情况下不需要同步.优点:第一个调用才初始化,避免内存浪费缺点:必须加锁 synchronized 才能保证单例,但是加锁会影响效率 package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/12 * @introduce 懒汉式 线程安全 **/ public class SingletonObject2 &amp;#123; private static SingletonObject2 instance = null; private SingletonObject2() &amp;#123; &amp;#125; public static synchronized SingletonObject2 getInstance() &amp;#123; if (null == instance) &amp;#123; instance = new SingletonObject2(); &amp;#125; return instance; &amp;#125; &amp;#125; 3.3. 饿汉式,线程安全是否Lazy初始化:否是否多线程安全:是这种方式基于ClassLoader 机制避免了多线程的同步问题,但是比较容易产生垃圾对象,优点是没有加锁,执行效率会提高 package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/12 * @introduce 饿汉式 **/ public class SingletonObject3 &amp;#123; private static SingletonObject3 instance = new SingletonObject3(); private SingletonObject3() &amp;#123; &amp;#125; public static SingletonObject3 getInstance() &amp;#123; return instance; &amp;#125; &amp;#125; 3.4. 双重校验锁是否Lazy初始化:是是否多线程安全:是这种方式采用双锁机制,安全且在多线程情况下能保持高性能, package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/12 * @introduce 双重校验锁 **/ public class SingletonObject4 &amp;#123; private volatile static SingletonObject4 instance; private SingletonObject4() &amp;#123; &amp;#125; public static SingletonObject4 getInstance() &amp;#123; if (null == instance) &amp;#123; synchronized (SingletonObject4.class) &amp;#123; if (null == instance) &amp;#123; instance = new SingletonObject4(); &amp;#125; &amp;#125; &amp;#125; return instance; &amp;#125; &amp;#125; 3.5. 静态内部类是否Lazy初始化:是是否多线程安全:是&nbsp;&nbsp;&nbsp;&nbsp;这种方式能达到双检锁一样的效果,但是实现更简单.对静态域使用延迟初始化,应使用这种方式而不是双检锁方式.这种方式只适用于静态域的情况,双检锁方式可在实例域需要延迟初始化的时候使用.&nbsp;&nbsp;&nbsp;&nbsp;这种方式同样利用了 classloader 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是：第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。 package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/12 * @introduce 静态内部类 **/ public class SingletonObject5 &amp;#123; private SingletonObject5() &amp;#123; &amp;#125; private static class SingletonObjectHolder &amp;#123; private static final SingletonObject5 INSTANCE = new SingletonObject5(); &amp;#125; public static final SingletonObject5 getInstance() &amp;#123; return SingletonObjectHolder.INSTANCE; &amp;#125; &amp;#125; 3.6. 枚举是否Lazy初始化:是是否多线程安全:是这是实现单例模式的最佳方法,简洁,自动支持序列化,绝对防止多次序列化 package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/12 * @introduce 枚举 **/ public enum SingletonObject6 &amp;#123; INSTANCE; &amp;#125; 3.7 volatile 关键字是否Lazy初始化:是是否多线程安全:是volatile 关键字的一个作用是禁止指令重排,把instance 声明为volatile之后,对它的写操作就是有一个内存屏障,这样再它的赋值完成之前就不会调用读操作. package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/16 * @introduce 使用volatile **/ public class SingletonObject7 &amp;#123; private volatile static SingletonObject7 instance = null; private SingletonObject7() &amp;#123; &amp;#125; public static SingletonObject7 getInstance() &amp;#123; if (null == instance) &amp;#123; synchronized (SingletonObject7.class) &amp;#123; if (null == instance) &amp;#123; instance = new SingletonObject7(); &amp;#125; &amp;#125; &amp;#125; return instance; &amp;#125; &amp;#125; 3.8 使用ThreadLocal 实现单例模式是否Lazy初始化:否是否多线程安全:是ThreadLocal会为每一个线程提供一个独立的变量副本,从而隔离了多个线程对数据的访问冲突.对于多线程资源共享的问题,同步机制采用了”以时间换空间”的方式,而ThreadLocal采用了”以空间换时间”的方式.前者仅提供一份变量,让不同的线程排队访问,而后者提供为每一个线程提供了一份变量,因此可以同时访问而互不影响 package com.formula.design.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/16 * @introduce 使用ThreadLocal 实现单例 **/ public class SingletonObject8 &amp;#123; private static final ThreadLocal&lt;SingletonObject8> THREAD_LOCAL = new ThreadLocal() &amp;#123; @Override protected SingletonObject8 initialValue() &amp;#123; return new SingletonObject8(); &amp;#125; &amp;#125;; public static SingletonObject8 getInstance() &amp;#123; return THREAD_LOCAL.get(); &amp;#125; &amp;#125; 3.9 使用CAS 锁实现是否Lazy初始化:否是否多线程安全:是 package com.formula.design.singleton; import java.util.concurrent.atomic.AtomicReference; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/16 * @introduce 使用CAS 锁 **/ public class SingletonObject9 &amp;#123; private static final AtomicReference&lt;SingletonObject9> INSTANCE = new AtomicReference(); private SingletonObject9() &amp;#123; &amp;#125; public static final SingletonObject9 getInstance() &amp;#123; for (; ; ) &amp;#123; SingletonObject9 current = INSTANCE.get(); if (null != current) &amp;#123; return current; &amp;#125; current = new SingletonObject9(); if (INSTANCE.compareAndSet(null, current)) &amp;#123; return current; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 3.10 容器式单例写法spring 单例实现方式代码 package com.formula.design.singleton; import java.util.Map; import java.util.concurrent.ConcurrentHashMap; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/3/28 * @introduce 容器式单例写法 * spring 采用的方式 **/ public class ContainerSingleton &amp;#123; private void containerSingleton() &amp;#123; &amp;#125; private static Map&lt;String, Object> obj = new ConcurrentHashMap&lt;>(); public static Object getInstance(String className) &amp;#123; Object result = null; synchronized (obj) &amp;#123; if (obj.containsKey(className)) &amp;#123; result = obj.get(className); &amp;#125; else &amp;#123; //不包含的时候 try &amp;#123; result = Class.forName(className).newInstance(); obj.put(className, result); &amp;#125; catch (InstantiationException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (IllegalAccessException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; return result; &amp;#125; &amp;#125; 测试 package com.formula.design.singleton; import com.formula.utils.ConcurrentExecutor; import org.junit.Test; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/3/28 * @introduce **/ public class ContainerSingletonTest &amp;#123; @Test public void test() &amp;#123; try &amp;#123; ConcurrentExecutor.execute(new ConcurrentExecutor.RunHandler() &amp;#123; @Override public void handler() &amp;#123; Object instance = ContainerSingleton.getInstance(\"com.formula.entity.User\"); System.out.println(System.currentTimeMillis() + \"--\" + Thread.currentThread().getName() + \"---\" + instance); &amp;#125; &amp;#125;, 10, 6); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 测试结果 1553781508089--pool-1-thread-5---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-6---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-3---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-2---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-4---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-1---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-7---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-8---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-9---com.formula.entity.User@15e2eb44 1553781508089--pool-1-thread-10---com.formula.entity.User@15e2eb44 生成的地址是一样的,说明是线程安全的 7. 经验之谈：一般情况下，不建议使用第 1 种和第 2 种懒汉方式，建议使用第 3 种饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用第 5 种登记方式。如果涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。如果有其他特殊的需求，可以考虑使用第 4 种双检锁方式。 ConcurrentExecutor类 package com.formula.utils; import java.util.concurrent.CountDownLatch; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Semaphore; /** * 并发请求 */ public class ConcurrentExecutor &amp;#123; public interface RunHandler &amp;#123; void handler(); &amp;#125; /** * @param runHandler * @param executeCount 发起请求总数 * @param concurrentCount 同时并发执行的线程数 */ public static void execute( RunHandler runHandler, int executeCount, int concurrentCount) throws InterruptedException &amp;#123; ExecutorService executorService = Executors.newCachedThreadPool(); // 控制信号量，此处用于控制并发的线程数 Semaphore semaphore = new Semaphore(concurrentCount); //闭锁,可实现计数器递减 CountDownLatch countDownLatch = new CountDownLatch(executeCount); for (int i = 0; i &lt; executeCount; i++) &amp;#123; executorService.execute(() -> &amp;#123; // 执行此方法用于获取执行许可,当总计为释放的许可数量不超过executeCount时候 // 则允许通行,否则线程阻塞等待,直到获取许可 try &amp;#123; semaphore.acquire(); runHandler.handler(); //释放许可 semaphore.release(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; countDownLatch.countDown(); &amp;#125;); &amp;#125; //线程阻塞,直到闭锁值为0的时候,阻塞才释放,继续往下执行 countDownLatch.await(); executorService.shutdown(); &amp;#125; &amp;#125; 4. 破坏单例4.1 使用反射破坏单例大家有没有发现,上面介绍的单例模式的构造方法除了加上private 之外,没有做任何的处理,如果我们使用反射来调用其构造函数,然后再调用其getInstance()方法,应该就会有两个不同的实例. package com.notes.pattern.singleton; import java.lang.reflect.Constructor; import java.lang.reflect.InvocationTargetException; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/8 * @introduce 通过反射破坏单例 **/ public class DestroySingletonWithProxy &amp;#123; public static void main(String[] args) &amp;#123; Class clazz = LazyInnerClassSingleton.class; //通过反射拿到私有的构造方法 try &amp;#123; Constructor constructor = clazz.getDeclaredConstructor(null); // 强制访问 constructor.setAccessible(true); // 暴力初始化 Object instance = constructor.newInstance(); LazyInnerClassSingleton instance1 = LazyInnerClassSingleton.getInstance(); System.out.println(instance == instance1); &amp;#125; catch (NoSuchMethodException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (IllegalAccessException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (InstantiationException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (InvocationTargetException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 允许结果如下: false 显然是创建了两个不同的实例.现在,让我们在其构造方法中做一些限制,一旦出现多个重复创建,则直接抛出异常.优化后的代码如下: package com.notes.pattern.singleton; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/12 * @introduce 静态内部类 **/ public class LazyInnerClassSingleton &amp;#123; // 默认使用LazyInnerClassSingleton的时候会先初始化内存类 //如果没有使用的话,内存类是不会被加载的 private LazyInnerClassSingleton() &amp;#123; if (SingletonObjectHolder.INSTANCE != null) &amp;#123; throw new RuntimeException(\"不允许创建多个实例\"); &amp;#125; &amp;#125; private static class SingletonObjectHolder &amp;#123; private static final LazyInnerClassSingleton INSTANCE = new LazyInnerClassSingleton(); &amp;#125; public static final LazyInnerClassSingleton getInstance() &amp;#123; return SingletonObjectHolder.INSTANCE; &amp;#125; &amp;#125; 运行结果如下: java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.notes.pattern.singleton.DestroySingletonWithProxy.main(DestroySingletonWithProxy.java:24) Caused by: java.lang.RuntimeException: 不允许创建多个实例 at com.notes.pattern.singleton.LazyInnerClassSingleton.&lt;init>(LazyInnerClassSingleton.java:15) ... 5 more 4.2 使用序列化破坏单例当我们将一个单例对象创建好的时候,有时候需要将对象序列化然后写道磁盘,下次使用的时候,再从磁盘中读取到对象,反序列化转化为内存对象.反序列化后的对象会重新分配内存,即重新创建.那如果序列化后的目标的对象为单例,就违背了单例模式的初衷,相当于破坏了单例模式,接下来看一段代码:首先编写一个序列化的单例模式 package com.notes.pattern.singleton; import java.io.Serializable; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/9 * @introduce 序列化破坏单例 **/ public class SeriableSingleton implements Serializable &amp;#123; private static final SeriableSingleton INSTANCE = new SeriableSingleton(); private SeriableSingleton() &amp;#123; &amp;#125; public static SeriableSingleton getInstance() &amp;#123; return INSTANCE; &amp;#125; &amp;#125; 接下来使用序列化来破坏单例 package com.notes.pattern.singleton; import java.io.*; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/9 * @introduce **/ public class SeriableSingletonTest &amp;#123; public static void main(String[] args) &amp;#123; SeriableSingleton singleton1 = null; SeriableSingleton singleton2 = SeriableSingleton.getInstance(); FileOutputStream fos = null; try &amp;#123; fos = new FileOutputStream(\"SeriableSingleton.obj\"); ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeObject(singleton2); oos.close(); fos.close(); FileInputStream fis = new FileInputStream(\"SeriableSingleton.obj\"); ObjectInputStream ois = new ObjectInputStream(fis); singleton1 = (SeriableSingleton) ois.readObject(); ois.close(); System.out.println(singleton1); System.out.println(singleton2); System.out.println(singleton1 == singleton2); &amp;#125; catch (FileNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 运行结果: com.notes.pattern.singleton.SeriableSingleton@378bf509 com.notes.pattern.singleton.SeriableSingleton@12a3a380 false 运行结果中可以看出来,反序列化后创建的对象和手动创建的对象是不一样的,实例化了两次,违背了单例的设计初衷.那么我们保证序列化的情况下可以单例呢,只需要增加readResolver()方法修改结果 package com.notes.pattern.singleton; import java.io.Serializable; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/9 * @introduce 序列化破坏单例 **/ public class SeriableSingleton implements Serializable &amp;#123; private static final SeriableSingleton INSTANCE = new SeriableSingleton(); private SeriableSingleton() &amp;#123; &amp;#125; public static SeriableSingleton getInstance() &amp;#123; return INSTANCE; &amp;#125; private Object readResolve() &amp;#123; return INSTANCE; &amp;#125; &amp;#125; 测试结果: com.notes.pattern.singleton.SeriableSingleton@12a3a380 com.notes.pattern.singleton.SeriableSingleton@12a3a380 true 接下来我们可以看看JDK的源码来看看到底为什么我们进入ObjectInputStream的 readObject()方法中,代码如下: public final Object readObject() throws IOException, ClassNotFoundException &amp;#123; if (enableOverride) &amp;#123; return readObjectOverride(); &amp;#125; // if nested read, passHandle contains handle of enclosing object int outerHandle = passHandle; try &amp;#123; Object obj = readObject0(false); handles.markDependency(outerHandle, passHandle); ClassNotFoundException ex = handles.lookupException(passHandle); if (ex != null) &amp;#123; throw ex; &amp;#125; if (depth == 0) &amp;#123; vlist.doCallbacks(); &amp;#125; return obj; &amp;#125; finally &amp;#123; passHandle = outerHandle; if (closed &amp;&amp; depth == 0) &amp;#123; clear(); &amp;#125; &amp;#125; &amp;#125; 我们发现在 readObject中又调用了我们重写的readObject0() 方法,进入 readObject0()方法,代码如下: private Object readObject0(boolean unshared) throws IOException &amp;#123; boolean oldMode = bin.getBlockDataMode(); if (oldMode) &amp;#123; int remain = bin.currentBlockRemaining(); if (remain > 0) &amp;#123; throw new OptionalDataException(remain); &amp;#125; else if (defaultDataEnd) &amp;#123; /* * Fix for 4360508: stream is currently at the end of a field * value block written via default serialization; since there * is no terminating TC_ENDBLOCKDATA tag, simulate * end-of-custom-data behavior explicitly. */ throw new OptionalDataException(true); &amp;#125; bin.setBlockDataMode(false); &amp;#125; byte tc; while ((tc = bin.peekByte()) == TC_RESET) &amp;#123; bin.readByte(); handleReset(); &amp;#125; depth++; try &amp;#123; switch (tc) &amp;#123; case TC_NULL: return readNull(); case TC_REFERENCE: return readHandle(unshared); case TC_CLASS: return readClass(unshared); case TC_CLASSDESC: case TC_PROXYCLASSDESC: return readClassDesc(unshared); case TC_STRING: case TC_LONGSTRING: return checkResolve(readString(unshared)); case TC_ARRAY: return checkResolve(readArray(unshared)); case TC_ENUM: return checkResolve(readEnum(unshared)); case TC_OBJECT: return checkResolve(readOrdinaryObject(unshared)); case TC_EXCEPTION: IOException ex = readFatalException(); throw new WriteAbortedException(\"writing aborted\", ex); case TC_BLOCKDATA: case TC_BLOCKDATALONG: if (oldMode) &amp;#123; bin.setBlockDataMode(true); bin.peek(); // force header read throw new OptionalDataException( bin.currentBlockRemaining()); &amp;#125; else &amp;#123; throw new StreamCorruptedException( \"unexpected block data\"); &amp;#125; case TC_ENDBLOCKDATA: if (oldMode) &amp;#123; throw new OptionalDataException(true); &amp;#125; else &amp;#123; throw new StreamCorruptedException( \"unexpected end of block data\"); &amp;#125; default: throw new StreamCorruptedException( String.format(\"invalid type code: %02X\", tc)); &amp;#125; &amp;#125; finally &amp;#123; depth--; bin.setBlockDataMode(oldMode); &amp;#125; &amp;#125; 我们看到了 TC_OBJECT 中，调用了ObjectInputStream的readOrdinaryObject()方法,继续看这个方法: private Object readOrdinaryObject(boolean unshared) throws IOException &amp;#123; if (bin.readByte() != TC_OBJECT) &amp;#123; throw new InternalError(); &amp;#125; ObjectStreamClass desc = readClassDesc(false); desc.checkDeserialize(); Class&lt;?> cl = desc.forClass(); if (cl == String.class || cl == Class.class || cl == ObjectStreamClass.class) &amp;#123; throw new InvalidClassException(\"invalid class descriptor\"); &amp;#125; Object obj; try &amp;#123; obj = desc.isInstantiable() ? desc.newInstance() : null; &amp;#125; catch (Exception ex) &amp;#123; throw (IOException) new InvalidClassException( desc.forClass().getName(), \"unable to create instance\").initCause(ex); &amp;#125; passHandle = handles.assign(unshared ? unsharedMarker : obj); ClassNotFoundException resolveEx = desc.getResolveException(); if (resolveEx != null) &amp;#123; handles.markException(passHandle, resolveEx); &amp;#125; if (desc.isExternalizable()) &amp;#123; readExternalData((Externalizable) obj, desc); &amp;#125; else &amp;#123; readSerialData(obj, desc); &amp;#125; handles.finish(passHandle); if (obj != null &amp;&amp; handles.lookupException(passHandle) == null &amp;&amp; desc.hasReadResolveMethod()) &amp;#123; Object rep = desc.invokeReadResolve(obj); if (unshared &amp;&amp; rep.getClass().isArray()) &amp;#123; rep = cloneArray(rep); &amp;#125; if (rep != obj) &amp;#123; handles.setObject(passHandle, obj = rep); &amp;#125; &amp;#125; return obj; &amp;#125; 调用了 ObjectStreamClass的isInstantiable()方法 boolean isInstantiable() &amp;#123; requireInitialized(); return (cons != null); &amp;#125; 代码非常简单,就是判读了一下构造方法是否为空,构造方法不为空就返回true,意味着,只要有无参构造方法就会实例化. 再回到ObjectInputStream的readOrdinaryObject()方法继续往下看, 判断无参构造方法之后调用了hasReadResolveMethod()方法, boolean hasReadResolveMethod() &amp;#123; requireInitialized(); return (readResolveMethod != null); &amp;#125; 逻辑非常简单，就是判断 readResolveMethod 是否为空，不为空就返回 true。那么 readResolveMethod 是在哪里赋值的呢？通过全局查找找到了赋值代码在私有方法 ObjectStreamClass()方法中给 readResolveMethod 进行赋值，来看代码： readResolveMethod = getInheritableMethod( cl, \"readResolve\", null, Object.class); 上面的逻辑其实就是通过反射找到一个无参的 readResolve()方法，并且保存下来。现在 再 回 到 ObjectInputStream 的 readOrdinaryObject() 方 法 继 续 往 下 看 ， 如 果 readResolve()存在则调用 invokeReadResolve()方法，来看代码 Object invokeReadResolve(Object obj) throws IOException, UnsupportedOperationException &amp;#123; requireInitialized(); if (readResolveMethod != null) &amp;#123; try &amp;#123; return readResolveMethod.invoke(obj, (Object[]) null); &amp;#125; catch (InvocationTargetException ex) &amp;#123; Throwable th = ex.getTargetException(); if (th instanceof ObjectStreamException) &amp;#123; throw (ObjectStreamException) th; &amp;#125; else &amp;#123; throwMiscException(th); throw new InternalError(th); // never reached &amp;#125; &amp;#125; catch (IllegalAccessException ex) &amp;#123; // should not occur, as access checks have been suppressed throw new InternalError(ex); &amp;#125; &amp;#125; else &amp;#123; throw new UnsupportedOperationException(); &amp;#125; &amp;#125; 我们可以看到在 invokeReadResolve()方法中用反射调用了 readResolveMethod 方法。 通过 JDK 源码分析我们可以看出，虽然，增加 readResolve()方法返回实例，解决了单 例被破坏的问题。但是，我们通过分析源码以及调试，我们可以看到实际上实例化了两 次，只不过新创建的对象没有被返回而已。那如果，创建对象的动作发生频率增大，就 意味着内存分配开销也就随之增大,可以使用容器式单例和枚举式单例来解决问题","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"Spring中常用的设计对比","slug":"设计模式/Spring中常用的设计对比","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/spring-zhong-chang-yong-de-she-ji-dui-bi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/spring-zhong-chang-yong-de-she-ji-dui-bi/","excerpt":"","text":"spring 中常用的设计模式对比 设计模式 一句话归纳 举例 工厂模式(Factory) 只对结果负责,封装创建过程 BeanFactory,Calender 单例模式(Singleton) 保证独一无二 ApplicationContext,Calender 原型模式(Prototype) 克隆 ArrayList,PrototypeBean 代理模式(Proxy) 增强职责 ProxyFactoryBean,JDKDynamicAopFactory,CglibAopFactory 委派模式(Delegate) 干活算员工的,功劳算项目经理的 DispatcherServlet,BeanDefinitionParserDelegate 策略模式(Strategy) 用户选择,结果统一 InstantiationStrategy 模板模式(Template) 流程标准化,自己实现定制 jdbcTemplate,HttpServlet 适配器模式(Adapter) 兼容转换头 AdvisorAdapter,HandlerAdapter 装饰器模式(Decorator) 包装,同宗同源 BufferedReader,InputStream,OutputStream,HttpHeadResponseDecorator 观察者模式(Observer) 任务完成时通知 ContextLoaderListener","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"代理模式在Spring中的应用(14","slug":"设计模式/代理模式在Spring中的应用(14.3)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/dai-li-mo-shi-zai-spring-zhong-de-ying-yong-14.3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/dai-li-mo-shi-zai-spring-zhong-de-ying-yong-14.3/","excerpt":"","text":"14.3 代理模式在Spring中的应用先看ProxyFactoryBean类,核心方法为getObject(),我们来看一下源码, @Nullable public Object getObject() throws BeansException &amp;#123; this.initializeAdvisorChain(); if (this.isSingleton()) &amp;#123; return this.getSingletonInstance(); &amp;#125; else &amp;#123; if (this.targetName == null) &amp;#123; this.logger.warn(\"Using non-singleton proxies with singleton targets is often undesirable. Enable prototype proxies by setting the 'targetName' property.\"); &amp;#125; return this.newPrototypeInstance(); &amp;#125; &amp;#125; 在getObject()方法中,主要调用getSingletonInstance()方法和newPrototypeInstance()方法,在Spring的配置当中,如果不做任何的设置,那么Spring代理生成的的Bean都是单例对象.如果修改scope则每次创建一个新的原型对象.Spring利用动态代理实现AOP有两个非常重要的类,一个是JdkDynamicAopProxy类和CglibAopProxy类 Spring中大代理选择原则: 当Bean有实现接口的时候,Spring就会用JDK的动态代理 当Bean没有实现接口的时候,Spring选择CGlib Spring可以通过配置强制使用CGlib,只需要在Spring的配置文件中添加如下代码:&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt; 参考资料如下:https://docs.spring.io/spring/docs/current/spring-framework-reference/core.html","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之迭代器模式(18)","slug":"设计模式/设计模式之迭代器模式(18)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-die-dai-qi-mo-shi-18/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-die-dai-qi-mo-shi-18/","excerpt":"","text":"18. 设计模式之迭代器模式(Iterator Pattern) 1. 概念Iterator模式是行为模式的一种,它把容器中包含的内部对象的访问委让给外部类,使用iterator(遍历)按顺序进行遍历访问的设计模式 2. 应用场景&nbsp;&nbsp;&nbsp; Iterator模式就是为了搞笑的处理按顺序进行遍历访问的一种设计模式,简单的说,Iterator模式提供一种有效的方法,可以屏蔽聚合对象的容器类的实现细节而能对容器内包含的元素按顺序进行有效的遍历访问.所有,Iterator模式的应用场景可以归纳为满足以下几个条件: 访问容器内包含的内部对象 按顺序访问3. 不使用迭代器模式的应用在应用Iterator模式之前,首先应该明白Iterator模式主要用来解决什么问题或者说,如果不使用Iterator模式,会存在什么问题. 由容器自己实现顺序遍历.直接在容器类直接添加顺序遍历方法 让访问者自己实现遍历.直接暴露数据细节给外部 4. 不使用迭代模式的缺点以上方法1与方法2都可以实现对象遍历,但是这样有什么问题呢？ 容器类承担了太多的功能:一方面需要提供添加删除等本身应有的功能;一方面还要提供遍历访问功能 往往容器在实现遍历的过程中,需要保存遍历状态,当根元素的添加删除等功能夹杂在一起后,很容易引起混乱和程序运行错误等 5. 迭代模式的角色和职责 Iterator(迭代器接口) :该接口必须定义实现迭代功能的最小定义方法集.比如提供hasNext()和next()方法. ConcreteIterator(迭代器实现类):迭代器接口Iterator的实现类,可以根据具体情况加以实现 Aggregate(容器接口):定义基本功能以及提供类似Iterator iterator()的方法 ConcreateAggregate(容器实现类):容器接口的实现类,必须实现Iterator iterator()方法6. 优缺点6.1 优点: 实现功能分离,简化容器接口.让容器只实现本身的基本功能,把迭代功能委让给外部实现,复合类的设计原则. 隐藏容器的实现细节 为容器或其子容器提供了一个统一的接口,一方面方便调用,另一外面使得调用者不必关注迭代器的实现细节 可以为容器或其自容器实现不同的迭代方法或者多个迭代方法6.2 缺点由于迭代器迷失将存储数据和遍历数据的职责分离,增加新的聚合类需要对用增加新的迭代器类,类的个数成对增加,这在一定程度上增加的系统的复杂性.7. 代码示例迭代器接口```javapackage com.formula.design.iterator; /** @author:luyanan @email:&#x6c;&#117;&#x79;&#97;&#x6e;&#97;&#110;&#x30;&#55;&#x31;&#56;&#x40;&#49;&#x36;&#51;&#x2e;&#x63;&#111;&#109; @date 2019/2/16 @introduce 迭代器接口 */public interface Iterator { boolean hasNext(); Object next(); } 容器接口 ```java package com.formula.design.iterator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/16 * @introduce 容器接口 **/ public interface Aggregate &#123; void add(Object object); Object get(int index); Iterator iterator(); int getSize(); &#125; 迭代器实现 package com.formula.design.iterator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/16 * @introduce 迭代器具体实现 **/ public class ContreateInterator implements Iterator &amp;#123; private Aggregate list = null; private int index; public ContreateInterator(Aggregate list) &amp;#123; super(); this.list = list; &amp;#125; @Override public boolean hasNext() &amp;#123; if (index >= list.getSize()) &amp;#123; return false; &amp;#125; else &amp;#123; return true; &amp;#125; &amp;#125; @Override public Object next() &amp;#123; Object object = list.get(index); index++; return object; &amp;#125; &amp;#125; 容器实现 package com.formula.design.iterator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/16 * @introduce 容器实现类 **/ public class ConcreteAggregate implements Aggregate &amp;#123; private Object[] list; private int size = 0; private int index = 0; public ConcreteAggregate() &amp;#123; list = new Object[100]; size = 0; index = 0; &amp;#125; @Override public void add(Object object) &amp;#123; list[index++] = object; size++; &amp;#125; @Override public Object get(int index) &amp;#123; return list[index]; &amp;#125; @Override public Iterator iterator() &amp;#123; return new ContreateInterator(this); &amp;#125; @Override public int getSize() &amp;#123; return size; &amp;#125; &amp;#125; 测试类 package com.formula.design.iterator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/16 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Aggregate aggregate = new ConcreteAggregate(); for (int i = 0; i &lt; 10; i++) &amp;#123; aggregate.add(String.valueOf(i)); &amp;#125; Iterator iterator = aggregate.iterator(); while (iterator.hasNext()) &amp;#123; System.out.println(iterator.next()); &amp;#125; &amp;#125; &amp;#125; 结果 0 1 2 3 4 5 6 7 8 9","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之过滤器模式(9)","slug":"设计模式/设计模式之过滤器模式(9)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-guo-lu-qi-mo-shi-9/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-guo-lu-qi-mo-shi-9/","excerpt":"","text":"9. 设计模式之过滤器模式(Filter Pattren) 1.概念过滤器模式或标准模式是一种设计模式,这种模式允许开发人员使用不同的标准来过滤一组对象,通过逻辑运算以解耦的方式把他们链接起来.这种类型的设计模式属于结构性模式.它组合多个标准来获得单一标准. 2. 代码定义一个实体 package com.formula.design.filter; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/22 * @introduce **/ @Data @Builder @AllArgsConstructor @NoArgsConstructor public class Person &amp;#123; /** * 姓名 */ private String name; /** * 年龄 */ private int age; /** * 性别 */ private String sex; &amp;#125; 定义一个过滤器接口 package com.formula.design.filter; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/22 * @introduce 定义一个过滤器接口 **/ public interface Filter &amp;#123; /** * 过滤器 * * @param personList * @return */ List&lt;Person> filer(List&lt;Person> personList); &amp;#125; 男性过滤器 package com.formula.design.filter; import java.util.List; import java.util.stream.Collectors; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/22 * @introduce 男性过滤器 **/ public class MaleFilter implements Filter &amp;#123; @Override public List&lt;Person> filer(List&lt;Person> personList) &amp;#123; return personList .stream() .filter(persion -> (persion.getSex().equals(\"男\"))) .collect(Collectors.toList()); &amp;#125; &amp;#125; 女性过滤器 package com.formula.design.filter; import java.util.List; import java.util.stream.Collectors; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/22 * @introduce 女性过滤器 **/ public class FemaleFilter implements Filter &amp;#123; @Override public List&lt;Person> filer(List&lt;Person> personList) &amp;#123; return personList .stream() .filter(person -> person.getSex().equals(\"女\")) .collect(Collectors.toList()); &amp;#125; &amp;#125; 年轻人过滤 package com.formula.design.filter; import java.util.List; import java.util.stream.Collectors; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/22 * @introduce 年轻人的过滤器 **/ public class YoungFilter implements Filter &amp;#123; @Override public List&lt;Person> filer(List&lt;Person> personList) &amp;#123; return personList.stream().filter(person -> person.getAge() &lt;= 18).collect(Collectors.toList()); &amp;#125; &amp;#125; 测试类 package com.formula.design.filter; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/22 * @introduce **/ public class MailClass &amp;#123; public static void main(String[] args) &amp;#123; List&lt;Person> personList = new ArrayList&lt;>(); personList.add(Person.builder().name(\"张三\").sex(\"男\").age(18).build()); personList.add(Person.builder().name(\"李四\").sex(\"男\").age(28).build()); personList.add(Person.builder().name(\"王红\").sex(\"女\").age(18).build()); personList.add(Person.builder().name(\"佳琪\").sex(\"女\").age(28).build()); // 筛选男人 Filter male = new MaleFilter(); print(male.getClass().getSimpleName(), male.filer(personList)); // 筛选女人 Filter female = new FemaleFilter(); print(female.getClass().getSimpleName(), female.filer(personList)); // 筛选年轻人 Filter young = new YoungFilter(); print(young.getClass().getSimpleName(), young.filer(personList)); &amp;#125; private static void print(String filterName, List&lt;Person> personList) &amp;#123; personList.stream().forEach(person -> &amp;#123; System.out.println(filterName + \"----\" + person.toString()); &amp;#125;); &amp;#125; &amp;#125; 结果 MaleFilter----Person(name=张三, age=18, sex=男) MaleFilter----Person(name=李四, age=28, sex=男) FemaleFilter----Person(name=王红, age=18, sex=女) FemaleFilter----Person(name=佳琪, age=28, sex=女) YoungFilter----Person(name=张三, age=18, sex=男) YoungFilter----Person(name=王红, age=18, sex=女)","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之中介者模式(19)","slug":"设计模式/设计模式之中介者模式(19)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zhong-jie-zhe-mo-shi-19/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zhong-jie-zhe-mo-shi-19/","excerpt":"","text":"19. 设计模式之中介者模式(Mediator Pattern) 1. 概念Mediator模式是行为模式的一种,在Mediator模式中,类之间的交互行为被统一的放在Mediator的对象中,对象通过Mediator对象同其他对象交互,Mediator对象起着控制器的作用. 2. 应用场景当对象之间的交互操作很多且每个对象的行为操作都彼此依赖的时候,为防止在修改一个对象的行为时,同时涉及很多其他对象的行为,可使用中介者模式 3. 角色和职责 Mediator: 中介者类的抽象父类 concreteMediator 具体的中介者类 colleague:关联类的抽象父类 concreteCollegue:具体的关联类4. 优缺点4.1 优点: 将系统按照功能分割成更小的对象,符合类的最小设计原则. 对关联对象的集中控制 减少类之间的耦合程序,明确类之间的相互关系;当类之间的关系过于负责的时候,其中任何一个类的修改都会影响到其他的类,不符合类的设计的开闭原则,而Mediator模式将原来相互依存的多对多的类之间的关系简化为Mediator控制类与其他关联类的一对多的关系,当其中一个类修改的时候,可以对其他关联类不产生影响(即使有修改,也集中在Mediator控制类) 有利于提高类的重用性4.2 缺点:中介者会庞大,变的复杂难以维护5. 代码关联类```javapackage com.formula.design.mediator; /** @author:luyanan @email:&#108;&#x75;&#x79;&#97;&#110;&#97;&#x6e;&#48;&#55;&#49;&#56;&#x40;&#x31;&#54;&#51;&#46;&#99;&#111;&#109; @date 2019/2/18 @introduce */public class Person { private String name; private Mediator mediator; public Person(String name, Mediator mediator) &#123; this.name = name; this.mediator = mediator; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Mediator getMediator() &#123; return mediator; &#125; public void setMediator(Mediator mediator) &#123; this.mediator = mediator; &#125; } 中介抽象类 ```java package com.formula.design.mediator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/18 * @introduce 抽象中介者 **/ public abstract class Mediator &#123; public abstract void constact(String message, Person person); &#125; 关联类具体实现 package com.formula.design.mediator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/18 * @introduce **/ public class HourseOwner extends Person &amp;#123; public HourseOwner(String name, Mediator mediator) &amp;#123; super(name, mediator); &amp;#125; public void constact(String message) &amp;#123; this.getMediator().constact(message, this); &amp;#125; public void getMessage(String message) &amp;#123; System.out.println(\"房主:\" + this.getName() + \"，获取到消息为:\" + message); &amp;#125; &amp;#125; package com.formula.design.mediator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/18 * @introduce **/ public class Tenant extends Person &amp;#123; public Tenant(String name, Mediator mediator) &amp;#123; super(name, mediator); &amp;#125; public void constact(String message) &amp;#123; this.getMediator().constact(message, this); &amp;#125; public void getMessage(String message) &amp;#123; System.out.println(\"租房者:\" + this.getName() + \",获得信息:\" + message); &amp;#125; &amp;#125; 中介类具体实现 package com.formula.design.mediator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/18 * @introduce **/ public class MediatorStructure extends Mediator &amp;#123; private HourseOwner hourseOwner; private Tenant tenant; public HourseOwner getHourseOwner() &amp;#123; return hourseOwner; &amp;#125; public void setHourseOwner(HourseOwner hourseOwner) &amp;#123; this.hourseOwner = hourseOwner; &amp;#125; public Tenant getTenant() &amp;#123; return tenant; &amp;#125; public void setTenant(Tenant tenant) &amp;#123; this.tenant = tenant; &amp;#125; @Override public void constact(String message, Person person) &amp;#123; if (person == hourseOwner) &amp;#123; tenant.getMessage(message); &amp;#125; else &amp;#123; hourseOwner.getMessage(message); &amp;#125; &amp;#125; &amp;#125; 测试类 package com.formula.design.mediator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/18 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; // 一个房主,一个租房者,一个中介 Mediator mediator = new MediatorStructure(); HourseOwner hourseOwner = new HourseOwner(\"房主\", mediator); Tenant tenant = new Tenant(\"租房者\", mediator); ((MediatorStructure) mediator).setHourseOwner(hourseOwner); ((MediatorStructure) mediator).setTenant(tenant); tenant.constact(\"听说有房要出租？\"); hourseOwner.constact(\"是的\"); &amp;#125; &amp;#125; 结果 房主:房主，获取到消息为:听说有房要出租？ 租房者:租房者,获得信息:是的","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之享元模式(13)","slug":"设计模式/设计模式之享元模式(13)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-xiang-yuan-mo-shi-13/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-xiang-yuan-mo-shi-13/","excerpt":"","text":"13. 设计模式之享元模式(Flywight Pattren) 1. 概念享元通过与其他类似对象共享数据来减少内存占用. 这种类型的设计模式属于结构性模式,它提供了减少对象数量从而改善应用数量从而改善应用所需的对象结构的方式 享元模式尝试重用现有的同类对象,如果未找到匹配的对象,则创建新的对象 共享模式是支持大量细粒度对象的服用,所以享元模式要求能够共 享的对象必须是细粒度对象. 在了解享元模式之前,需要先了解两个概念:内部状态,外部状态 - **内部状态**:在享元对象内部不随外界环境改变而改变的共享部分 - **外部状态**:随着环境的改变而改变,不能够共享的状态就是外部状态 &lt;br&gt; 由于享元模式区分了内部状态和外部状态,所以我们可以通过设置不同的外部状态使得相同的对象可以具备不同的特性,而内部状态设置为相同部分.在我们的程序设计过程中,我们可能会需要大量的细粒度对象来表示对象,如果这些对象除了几个参数不同外其他部分都相同，这个时候我们就可以使用费享元模式来大大的减少应用程序当中的对象. ### 2. 角色和职责 - **抽象享元角色**: 所有具体享元角色的父类,规定一些需要实现的公共接口. - **具体享元角色**:抽象享元角色的具体实现类,并实现了抽象享元角色规定的方法 享元工厂角色:负责创建和管理享元角色3. 代码 抽象享元对象package com.formula.design.flyweight; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/25 * @introduce **/ @Data @Builder @AllArgsConstructor @NoArgsConstructor public class Person &amp;#123; private String name; private Integer age; &amp;#125; 具体享元对象package com.formula.design.flyweight; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/25 * @introduce **/ @Data @AllArgsConstructor @NoArgsConstructor public class Teacher extends Person &amp;#123; private String number; &amp;#125; 享元工厂对象package com.formula.design.flyweight; import java.util.HashMap; import java.util.List; import java.util.Map; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/25 * @introduce **/ public class TeacherPool &amp;#123; private Map&lt;String, Teacher> pool = null; public TeacherPool() &amp;#123; pool = new HashMap&lt;>(); &amp;#125; public Teacher getTeacher(String number) &amp;#123; Teacher teacher = pool.get(number); if (null == teacher) &amp;#123; teacher = new Teacher(); teacher.setName(\"张三\"); teacher.setNumber(number); pool.put(number, teacher); &amp;#125; return teacher; &amp;#125; &amp;#125; 测试类package com.formula.design.flyweight; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/25 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; // 不使用享元模式之前 TeacherPool pool = new TeacherPool(); Teacher teacher = pool.getTeacher(\"11111\"); Teacher teacher2 = pool.getTeacher(\"22222\"); Teacher teacher3 = pool.getTeacher(\"11111\"); System.out.println(teacher.toString()); System.out.println(teacher2.toString()); System.out.println(teacher3.toString()); System.out.println(teacher == teacher3); &amp;#125; &amp;#125; 结果Teacher(number=11111) Teacher(number=22222) Teacher(number=11111) true","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之原型模式(6)","slug":"设计模式/设计模式之原型模式(6)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-yuan-xing-mo-shi-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-yuan-xing-mo-shi-6/","excerpt":"","text":"6. 设计模式之原型模式(Prototype Pattren) 1. 概念Prototype 模式是一种对象创建型模式,它采用复制原型对象的方法来创建对象的实例.使用Prototype 模式创建的实例,具有和原型一样的数据 2. 原型模式的特点 由原型对象自身创建目标对象.也就是说,对象创建这一动作发自原型对象本身. 目标对象是原型镀锡的一个克隆.也就是说,通过Prototype 模式创建的对象,不仅仅与原型对象具有相同的结构,还与原型对象具有相同的数值. 根据对象克隆深度层次的不同,有浅度克隆和深度克隆之分 1 -浅度克隆:使用一个已知的实例对新创建实例的成员变量逐个赋值 2 -深度克隆:当一个类的克隆构造方法,不仅要复制对象的所有非引用成员变量值,还要为引用类型的成员白能量创建新的实例,并且初始化为形式参数实例值.3. 角色 原型角色: 定义用于复制现有实例来生成新的实例的方法 具体原型对象:实现用于复制现有实例来生成新的实例的方法 使用者角色:维护一个注册表,并提供一个找出正确实例原型的方法.最后提供一个获取新的实例的方法,用来委托复制实例的方法来生成新的实例4. 原型模式的应用场景 在创建对象的时候,我们不只是希望被创建的对象继承其基类的基本结构,还希望继承原型对象的数据. 希望对目标对象的修改不会影响既有的原型镀锡(深度克隆的时候可以完全互不影响 隐藏克隆操作的细节.很多时候,对对象本身的克隆需要设计到类本身的数据细节5. 代码浅度克隆```javapackage com.formula.design.prototype; import java.time.LocalDateTime;import java.util.ArrayList;import java.util.Date;import java.util.List; /** @author:luyanan @email:&#108;&#117;&#x79;&#x61;&#110;&#x61;&#110;&#48;&#55;&#49;&#56;&#x40;&#x31;&#54;&#x33;&#46;&#99;&#x6f;&#109; @date 2019/1/15 @introduce */public class User implements Cloneable { private String name; private Integer age; private String sex; private LocalDateTime date; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public LocalDateTime getDate() &#123; return date; &#125; public void setDate(LocalDateTime date) &#123; this.date = date; &#125; /** * 浅度克隆 * * @return */ public User shallowClone() &#123; try &#123; return (User) this.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return null; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&#39;&quot; + name + &#39;\\&#39;&#39; + &quot;, age=&quot; + age + &quot;, sex=&#39;&quot; + sex + &#39;\\&#39;&#39; + &quot;, date=&quot; + date + &#39;&#125;&#39;; &#125; } 测试类 ```java package com.formula.design.prototype; import java.time.LocalDateTime; import java.util.ArrayList; import java.util.Arrays; import java.util.Date; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/15 * @introduce **/ public class MainClass &#123; public static void main(String[] args) &#123; User user = new User(); user.setName(&quot;张三&quot;); user.setAge(25); user.setSex(&quot;男&quot;); user.setDate(LocalDateTime.now()); List&lt;String&gt; roles = new ArrayList&lt;&gt;(); roles.add(&quot;管理员&quot;); roles.add(&quot;技术部&quot;); user.setRoles(roles); // 使用浅克隆进行克隆 User shallowClone = user.shallowClone(); System.out.println(user == shallowClone); user.setAge(30); // 当对原型对象进行修改的时候,复制后的对象不会修改 System.out.println(&quot;原型对象:&quot; + user); System.out.println(&quot;复制对象:&quot; + shallowClone); &#125; 结果 false 原型对象:User&amp;#123;name='张三', age=30, sex='男', date=2019-01-15T10:01:21.231, roles=[管理员, 技术部]&amp;#125; 复制对象:User&amp;#123;name='张三', age=25, sex='男', date=2019-01-15T10:01:21.231, roles=[管理员, 技术部]&amp;#125; 问题 当对象中保存引用对象,比如 package com.formula.design.prototype; import java.time.LocalDateTime; import java.util.ArrayList; import java.util.Date; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/15 * @introduce **/ public class User implements Cloneable &amp;#123; private String name; private Integer age; private String sex; private LocalDateTime date; private List&lt;String> roles; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; public Integer getAge() &amp;#123; return age; &amp;#125; public void setAge(Integer age) &amp;#123; this.age = age; &amp;#125; public String getSex() &amp;#123; return sex; &amp;#125; public void setSex(String sex) &amp;#123; this.sex = sex; &amp;#125; public LocalDateTime getDate() &amp;#123; return date; &amp;#125; public void setDate(LocalDateTime date) &amp;#123; this.date = date; &amp;#125; public List&lt;String> getRoles() &amp;#123; return roles; &amp;#125; public void setRoles(List&lt;String> roles) &amp;#123; this.roles = roles; &amp;#125; /** * 浅度克隆 * * @return */ public User shallowClone() &amp;#123; try &amp;#123; return (User) this.clone(); &amp;#125; catch (CloneNotSupportedException e) &amp;#123; e.printStackTrace(); &amp;#125; return null; &amp;#125; @Override public String toString() &amp;#123; return \"User&amp;#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + \", sex='\" + sex + '\\'' + \", date=\" + date + \", roles=\" + roles + '&amp;#125;'; &amp;#125; &amp;#125; 测试 package com.formula.design.prototype; import java.time.LocalDateTime; import java.util.ArrayList; import java.util.Arrays; import java.util.Date; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/15 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; User user = new User(); user.setName(\"张三\"); user.setAge(25); user.setSex(\"男\"); user.setDate(LocalDateTime.now()); List&lt;String> roles = new ArrayList&lt;>(); roles.add(\"管理员\"); roles.add(\"技术部\"); user.setRoles(roles); // 使用浅克隆进行克隆 User shallowClone = user.shallowClone(); System.out.println(user == shallowClone); user.setAge(30); // 当对原型对象进行修改的时候,复制后的对象不会修改 System.out.println(\"原型对象:\" + user); System.out.println(\"复制对象:\" + shallowClone); roles.add(\"业务部\"); user.setRoles(roles); System.out.println(\"原型对象:\" + user); System.out.println(\"复制对象:\" + shallowClone); &amp;#125; 结果 false 原型对象:User&amp;#123;name='张三', age=30, sex='男', date=2019-01-15T10:02:38.420, roles=[管理员, 技术部]&amp;#125; 复制对象:User&amp;#123;name='张三', age=25, sex='男', date=2019-01-15T10:02:38.420, roles=[管理员, 技术部]&amp;#125; 原型对象:User&amp;#123;name='张三', age=30, sex='男', date=2019-01-15T10:02:38.420, roles=[管理员, 技术部, 业务部]&amp;#125; 复制对象:User&amp;#123;name='张三', age=25, sex='男', date=2019-01-15T10:02:38.420, roles=[管理员, 技术部, 业务部]&amp;#125; 浅度克隆不会克隆引用对象,这个时候,应该使用深度克隆 package com.notes.pattern.prototype; import java.io.*; import java.time.LocalDateTime; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/15 * @introduce **/ public class User implements Cloneable,Serializable &amp;#123; private String name; private Integer age; private String sex; private LocalDateTime date; private List&lt;String> roles; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; public Integer getAge() &amp;#123; return age; &amp;#125; public void setAge(Integer age) &amp;#123; this.age = age; &amp;#125; public String getSex() &amp;#123; return sex; &amp;#125; public void setSex(String sex) &amp;#123; this.sex = sex; &amp;#125; public LocalDateTime getDate() &amp;#123; return date; &amp;#125; public void setDate(LocalDateTime date) &amp;#123; this.date = date; &amp;#125; public List&lt;String> getRoles() &amp;#123; return roles; &amp;#125; public void setRoles(List&lt;String> roles) &amp;#123; this.roles = roles; &amp;#125; /** * 浅度克隆 * * @return */ public User shallowClone() &amp;#123; try &amp;#123; return (User) this.clone(); &amp;#125; catch (CloneNotSupportedException e) &amp;#123; e.printStackTrace(); &amp;#125; return null; &amp;#125; /** * 深度克隆 * * @return */ public User deepClone() &amp;#123; User user = null; try &amp;#123; user = (User) this.clone(); List&lt;String> newRoles = new ArrayList&lt;>(); this.roles.stream().forEach(role -> &amp;#123; newRoles.add(role); &amp;#125;); user.setRoles(newRoles); &amp;#125; catch (CloneNotSupportedException e) &amp;#123; e.printStackTrace(); &amp;#125; return user; &amp;#125; /** * 深度克隆 * * @return */ public User deepClone2() &amp;#123; try &amp;#123; ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); User user = (User) ois.readObject(); return user; &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; return null; &amp;#125; @Override public String toString() &amp;#123; return \"User&amp;#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + \", sex='\" + sex + '\\'' + \", date=\" + date + \", roles=\" + roles + '&amp;#125;'; &amp;#125; &amp;#125; 测试类 package com.notes.pattern.prototype; import java.time.LocalDateTime; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/15 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; User user = new User(); user.setName(\"张三\"); user.setAge(25); user.setSex(\"男\"); user.setDate(LocalDateTime.now()); List&lt;String> roles = new ArrayList&lt;>(); roles.add(\"管理员\"); roles.add(\"技术部\"); user.setRoles(roles); // // 使用浅克隆进行克隆 // User shallowClone = user.shallowClone(); // System.out.println(user == shallowClone); // user.setAge(30); // // 当对原型对象进行修改的时候,复制后的对象不会修改 // System.out.println(\"原型对象:\" + user); // System.out.println(\"复制对象:\" + shallowClone); // // roles.add(\"业务部\"); // user.setRoles(roles); // System.out.println(\"原型对象:\" + user); // System.out.println(\"复制对象:\" + shallowClone); // 使用深克隆进行克隆 User deepClone = user.deepClone(); User deepClone2 = user.deepClone2(); System.out.println(user == deepClone); user.setAge(30); // 当对原型对象进行修改的时候,复制后的对象不会修改 System.out.println(\"原型对象:\" + user); System.out.println(\"复制对象:\" + deepClone); System.out.println(\"复制对象2:\" + deepClone2); roles.add(\"业务部\"); user.setRoles(roles); System.out.println(\"原型对象:\" + user); System.out.println(\"复制对象:\" + deepClone); System.out.println(\"复制对象2:\" + deepClone2); &amp;#125; &amp;#125; 结果 false 原型对象:User&amp;#123;name='张三', age=30, sex='男', date=2019-04-10T12:53:20.474, roles=[管理员, 技术部]&amp;#125; 复制对象:User&amp;#123;name='张三', age=25, sex='男', date=2019-04-10T12:53:20.474, roles=[管理员, 技术部]&amp;#125; 复制对象2:User&amp;#123;name='张三', age=25, sex='男', date=2019-04-10T12:53:20.474, roles=[管理员, 技术部]&amp;#125; 原型对象:User&amp;#123;name='张三', age=30, sex='男', date=2019-04-10T12:53:20.474, roles=[管理员, 技术部, 业务部]&amp;#125; 复制对象:User&amp;#123;name='张三', age=25, sex='男', date=2019-04-10T12:53:20.474, roles=[管理员, 技术部]&amp;#125; 复制对象2:User&amp;#123;name='张三', age=25, sex='男', date=2019-04-10T12:53:20.474, roles=[管理员, 技术部]&amp;#125; 克隆模式破坏单例模式如果我们克隆的目标的对象是单例模式，那就意味着,深克隆会破坏单例.实际上防止克隆破坏单例模式的思路非常简单,禁止深克隆就可以了,那么就需要我们的单例类实现Cloneable接口,我们重写clone()方法,在clone方法中返回单例对象就可以了,具体代码为 @Override protected Object clone() throws CloneNotSupportedException &amp;#123; return INSTANCE; &amp;#125; 原型模式源码分析我们的ArrayList就实现了Cloneable接口,具体代码为 /** * Returns a shallow copy of this &lt;tt>ArrayList&lt;/tt> instance. (The * elements themselves are not copied.) * * @return a clone of this &lt;tt>ArrayList&lt;/tt> instance */ public Object clone() &amp;#123; try &amp;#123; ArrayList&lt;?> v = (ArrayList&lt;?>) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &amp;#125; catch (CloneNotSupportedException e) &amp;#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &amp;#125; &amp;#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之命令模式(16)","slug":"设计模式/设计模式之命令模式(16)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-ming-ling-mo-shi-16/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-ming-ling-mo-shi-16/","excerpt":"","text":"16. 设计模式之命令模式(Command Pattren) 1. 概念命令模式是行为设计模式的一种,Command 模式通过被称为commonand的类封装了堆目标对象的调用行为以及调用参数 2. 应用场景在面向对象的程序设计中,一个对象调用另外一个对象,一般情况下的调用过程是:创建目标对象实例;设置调用参数,调用目标对象的方法&nbsp;&nbsp;但是在有些情况下有必要使用一个专门的类对这种调用过程加以封装,我们把这种专门的类称作Command类. 整个调用过程比较繁杂,或者存在多出这种调用.这是,使用Command类对该调用加以封装,便于功能的再利用 调用前后需要对调用参数进行某些处理 调用前后需要进行某些额外处理,比如 日志,缓存,记录历史操作等. 系统需要在不同的时间指定请求,将请求排队和执行请求 系统都需要支持命令的撤销(Undo)操作和恢复(Redo)操作 系统需要将一组操作组合在一起,即支持宏命令 3. 角色和职责 Command:command抽象类 concreteCommand:Cpmmand的具体实现类 Receiver:需要被调用的目标对象 Invorker:通过Invorker执行Command对象.4. 优缺点 优点: 降低系统的耦合度 新的命令可以很容易的加入到系统中 可以比较同意的设计出一个命令队列和宏命令(组合命令) 可以方便的实现对请求的Undo和Redo 缺点: 使用命令模式可能会导致某些系统有过多的具体命令类.因为针对每一个命令都需要设计一个具体命令类,因此某些系统可能需要大量具体命令类,这将影响命令模式的使用5. 代码情景:我们去一家烧烤店吃饭。我们会向服务员点烧烤，服务员会拿笔记本记录我们点的菜品，然后去后厨告诉厨师要烤哪些东西。期间我们还可能会加菜或者取消一些已经点的菜，服务员肯定也会拿笔记本记下来，然后告诉后厨，最后，根据笔记本记得内容和我们算钱。 package com.formula.design.command; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/31 * @introduce **/ public class Barbecuer &amp;#123; public void bakeMutton() &amp;#123; System.out.println(\"厨师:烤个羊腿\"); &amp;#125; public void bakeChickenWing() &amp;#123; System.out.println(\"厨师:烤个鸡翅\"); &amp;#125; &amp;#125; package com.formula.design.command; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/31 * @introduce 命令类 **/ public abstract class Command &amp;#123; protected Barbecuer receiver; public Command(Barbecuer receiver) &amp;#123; this.receiver = receiver; &amp;#125; /** * 执行命令 */ public abstract void executeComand(); &amp;#125; package com.formula.design.command; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/31 * @introduce 烤鸡翅的命令 **/ public class BakeChickenWingCommand extends Command &amp;#123; public BakeChickenWingCommand(Barbecuer receiver) &amp;#123; super(receiver); &amp;#125; @Override public void executeComand() &amp;#123; receiver.bakeChickenWing(); &amp;#125; &amp;#125; package com.formula.design.command; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/31 * @introduce 烤鸡腿的命令 **/ public class BakeMuttonCommand extends Command &amp;#123; public BakeMuttonCommand(Barbecuer receiver) &amp;#123; super(receiver); &amp;#125; @Override public void executeComand() &amp;#123; receiver.bakeMutton(); &amp;#125; &amp;#125; package com.formula.design.command; import java.time.LocalDateTime; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/31 * @introduce 服务员类 **/ public class Waiter &amp;#123; /** * 订单 */ private List&lt;Command> orders = new ArrayList&lt;>(); /** * 添加订单 * * @param command */ public void addOrder(Command command) &amp;#123; orders.add(command); System.out.println(\"添加订单成功---\" + LocalDateTime.now()); &amp;#125; public void cancelOrder(Command command) &amp;#123; orders.remove(command); System.out.println(\"取消订单成功---\" + LocalDateTime.now()); &amp;#125; public void noteify() &amp;#123; orders.stream().forEach(command -> &amp;#123; command.executeComand(); &amp;#125;); &amp;#125; &amp;#125; 测试类 package com.formula.design.command; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/31 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; // 我们去一家烧烤店吃饭。我们会向服务员点烧烤，服务员会拿笔记本记录我们点的菜品， // 然后去后厨告诉厨师要烤哪些东西。期间我们还可能会加菜或者取消一些已经点的菜， // 服务员肯定也会拿笔记本记下来，然后告诉后厨，最后，根据笔记本记得内容和我们算钱。 Barbecuer customer = new Barbecuer(); Command bakeMuttonCommand1 = new BakeMuttonCommand(customer); Command bakeMuttonCommand2 = new BakeMuttonCommand(customer); Command bakeChickenWingCommand1 = new BakeChickenWingCommand(customer); Command bakeChickenWingCommand2 = new BakeChickenWingCommand(customer); Waiter waiter = new Waiter(); waiter.addOrder(bakeMuttonCommand1); waiter.addOrder(bakeMuttonCommand2); waiter.addOrder(bakeChickenWingCommand1); waiter.addOrder(bakeChickenWingCommand2); waiter.noteify(); &amp;#125; &amp;#125; 结果 添加订单成功---2019-01-31T10:03:41.316 添加订单成功---2019-01-31T10:03:41.316 添加订单成功---2019-01-31T10:03:41.316 添加订单成功---2019-01-31T10:03:41.316 厨师:烤个羊腿 厨师:烤个羊腿 厨师:烤个鸡翅 厨师:烤个鸡翅","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之备忘录模式(20)","slug":"设计模式/设计模式之备忘录模式(20)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-bei-wang-lu-mo-shi-20/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-bei-wang-lu-mo-shi-20/","excerpt":"","text":"20. 设计模式之备忘录模式(MementTo Pattern) 1. 概念备忘录模式,用来保存对象的某一个状态,以便在适当的时候恢复对象,备忘录模式属于行为型模式 2. 角色和职责 备忘录角色:负责存储”客户端发起者角色”的内部状态 备忘录发起者角色:创建一个备忘录,在需要还原的时候,还原内部状态 备忘录管理者角色:负责保存备忘录 3. 代码1. 备忘录发起者:package com.formula.design.memento; import lombok.AllArgsConstructor; import lombok.Data; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/2 * @introduce 备忘录发起者角色 **/ @Data @AllArgsConstructor public class Originator &amp;#123; private String userName; private Integer age; private String sex; /** * 创建备忘录 * * @return */ public MementTo createMementTo() &amp;#123; return new MementTo(userName, age, sex); &amp;#125; /** * 恢复 * * @param mementTo */ public void recovery(MementTo mementTo) &amp;#123; this.age = mementTo.getAge(); this.sex = mementTo.getSex(); this.userName = mementTo.getUserName(); &amp;#125; &amp;#125; 2. 备忘录角色package com.formula.design.memento; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/2 * @introduce 备忘录类 **/ @Data @AllArgsConstructor @NoArgsConstructor public class MementTo &amp;#123; private String userName; private Integer age; private String sex; &amp;#125; 3. 备忘录管理者package com.formula.design.memento; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/2 * @introduce **/ public class Caretaker &amp;#123; private List&lt;MementTo> mementToList = new ArrayList&lt;>(); public void add(MementTo mementTo) &amp;#123; mementToList.add(mementTo); &amp;#125; public MementTo get(int index) &amp;#123; return mementToList.get(index); &amp;#125; &amp;#125; 4. 主类package com.formula.design.memento; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/2 * @introduce **/ public class DesignMementToMain &amp;#123; public static void main(String[] args) &amp;#123; Caretaker caretaker = new Caretaker(); Originator originator = new Originator(\"demo\", 18, \"男\"); // 进行备份 caretaker.add(originator.createMementTo()); System.out.println(\"第一次:\" + originator.toString()); // 修改 originator.setUserName(\"demo2\"); originator.setAge(20); originator.setSex(\"女\"); System.out.println(\"修改后:\" + originator); //回滚 originator.recovery(caretaker.get(0)); System.out.println(\"回滚后:\" + originator); &amp;#125; &amp;#125; 结果第一次:Originator(userName=demo, age=18, sex=男) 修改后:Originator(userName=demo2, age=20, sex=女) 回滚后:Originator(userName=demo, age=18, sex=男)","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之责任链模式(15)","slug":"设计模式/设计模式之责任链模式(15)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-ze-ren-lian-mo-shi-15/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-ze-ren-lian-mo-shi-15/","excerpt":"","text":"15. 责任链模式(Chain of Responsibility )(COR) 1. 概念Chain of Responsibility(COR) 模式也叫作职责链模式或者责任连锁模式,是行为模式之一.该模式构造一系列分别担当不同职责的类的对象来共同完成一个任务,这些类的对象之间像链条一样紧密相连,所以被称作职责链模式 2. 应用场景例1:比如客户Client 要完成一个任务,这个任务包括a,b,c,d四个部分.首先 客户Client 需要把任务交给A，A完成a部分后,把任务交给B，B完成b部分,….，直到D 完成D部分.例2: 比如政府部分的某项工作,县政府先完成自己能处理的部分,不能处理的部分交给省政府 ,省政府再完成自己职责范围内的部分,不能处理的部分交给中央政府,中央政府最后完成该项工作.例3:软件窗口的消息传播例4:Servlet容器的过滤器(Filter)框架实现 3. 职责链模式的基本条件要实现COR 模式.需要满足该模式的基本条件: 对象链的组织,需要将某些任务的所有职责执行对象以链的形式加以组织 消息或请求的传递,将消息或请求沿着对象链传递,以让处于对象链中的对象得到处理机会 处于对象链中的对象的职责分配,不同的对象完成不同的职责. 任务的完成.处于对象链的末尾的对象结束任务并停止消息或请求的继续传递4. 角色和职责 Handler:处理类的抽象父类 ConcreteHandler:具体的处理类5. 优缺点: 优点: 责任的分担.每个类只需要处理自己该处理的工作(不该处理的传递给下一个对象),明确各类的责任范围,符合类的最小封装原则. 可以根据需要自由组合工作流程.如果工作流程发生变化,可以通过重新分配对象链便可适应新的工作流程. 类与类之间可以以松耦合的形式加以组织 缺点:因为处理时以链的形式在对象间传递消息,根据实现方式不同,有可能会影响处理的速度6. 代码实例:抽象父类```javapackage com.formula.design.cor; /** @author:luyanan @email:&#108;&#117;&#121;&#x61;&#x6e;&#97;&#x6e;&#48;&#55;&#49;&#x38;&#x40;&#49;&#54;&#51;&#46;&#99;&#111;&#x6d; @date 2019/1/30 @introduce 抽象过滤 */public abstract class AbstractFilterHandler { protected AbstractFilterHandler nextFilterHandler; /** * 过滤 * * @param str * @return */ public abstract String filter(String str); public AbstractFilterHandler addFilter(AbstractFilterHandler filterHandler) &#123; this.nextFilterHandler = filterHandler; return this.nextFilterHandler; &#125; } 具体的处理类 ```java package com.formula.design.cor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/30 * @introduce html 过滤,将字符串中出现的&quot;&lt;&gt;&quot;符号替换成&quot;[]&quot; **/ public class HTMLFilter extends AbstractFilterHandler &#123; @Override public String filter(String str) &#123; String replaceAll = str.replaceAll(&quot;&gt;&quot;, &quot;]&quot;).replaceAll(&quot;&lt;&quot;, &quot;[&quot;); if (this.nextFilterHandler != null) &#123; return nextFilterHandler.filter(replaceAll); &#125; return replaceAll; &#125; &#125; package com.formula.design.cor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/30 * @introduce 敏感词过滤 处理字符串中的敏感信息，将被就业和谐成就业 **/ public class SensitiveFilter extends AbstractFilterHandler &amp;#123; @Override public String filter(String str) &amp;#123; String replaceAll = str.replaceAll(\"被就业\", \"就业\").replaceAll(\"敏感\", \"\"); if (nextFilterHandler != null) &amp;#123; return nextFilterHandler.filter(replaceAll); &amp;#125; return replaceAll; &amp;#125; &amp;#125; package com.formula.design.cor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/30 * @introduce 表情过滤 //将字符串中出现的\":):\"转换成\"^V^\"; **/ public class FaceFilter extends AbstractFilterHandler &amp;#123; @Override public String filter(String str) &amp;#123; String replaceAll = str.replaceAll(\":\\\\):\", \"^V^\"); if (nextFilterHandler != null) &amp;#123; return nextFilterHandler.filter(replaceAll); &amp;#125; return replaceAll; &amp;#125; &amp;#125; 测试类 package com.formula.design.cor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/30 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; String str = \":):,&lt;script>,敏感,被就业,网络授课\"; //不使用责任链模式 AbstractFilterHandler htmlFilter = new HTMLFilter(); AbstractFilterHandler sensitiveFilter = new SensitiveFilter(); AbstractFilterHandler faceFilter = new FaceFilter(); htmlFilter.addFilter(sensitiveFilter) .addFilter(faceFilter); System.out.println(htmlFilter.filter(str)); &amp;#125; &amp;#125; 结果 ^V^,[script],,就业,网络授课","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之访问者模式(26)","slug":"设计模式/设计模式之访问者模式(26)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-fang-wen-zhe-mo-shi-26/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-fang-wen-zhe-mo-shi-26/","excerpt":"","text":"26. 设计模式之访问者模式(Visitor Pattern) 1. 概念访问者模式是行为模式的一种,它分离对象的数据和行为,使用Visitor模式可以不修改已有类的情况下,增加新的操作. 2. 使用场景 对象结构比较稳定,但经常需要在此对象结构上定义新的操作. 需要对一个对象结构中的对象进行很多不同的且不相关的操作,而需要避免这些操作”污染”这些对象的类,也不希望在增加新的操作时修改这些类.3. 角色与职责 访问者角色(Visitor):为该对象结构中具体元素角色声明一个访问操作接口.该操作接口的名称和参数标识了发送访问请求给具体访问者的具体元素角色.这样访问者就可以通过该元素角色的特定接口直接访问它. 具体访问者角色(Concrete Vistitor):实现每个由访问者角色(Visitor)声明的操作. 元素角色(Element):定义一个Accept操作,它以一个访问者为参数. 具体元素角色(Concrete Element):实现由元素角色提供的Accept角色 对象结构角色(Object Structure):这是使用访问者模式必备的角色.它要具备以下特征:能枚举它的元素,可以提供一个高层的接口以允许该访问者访问它的元素;可以是一个复合(组合模式)或是一个集合,如一个列表或一个无序集合.4. 优缺点4.1 优点: 符合单一职责原则 优秀的扩展性 灵活性4.2 缺点: 具体元素对访问者公布细节,违反了迪米特原则. 具体元素变更比较困难, 违反了依赖倒置原则,依赖了具体类,没有依赖抽象.5. 代码```javapackage com.formula.design.visitor; /** @author:luyanan @email:&#x6c;&#x75;&#x79;&#x61;&#110;&#x61;&#x6e;&#48;&#x37;&#x31;&#x38;&#64;&#x31;&#x36;&#x33;&#46;&#x63;&#111;&#109; @date 2019/2/26 @introduce 单个单子的接口(Element) */public interface Bill { void accept(AccountBookViewer accountBookViewer);} ```java package com.formula.design.visitor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce **/ public abstract class AbstractBill &#123; private double amount; private String item; public AbstractBill(double amount, String item) &#123; this.amount = amount; this.item = item; &#125; public double getAmount() &#123; return amount; &#125; public void setAmount(double amount) &#123; this.amount = amount; &#125; public String getItem() &#123; return item; &#125; public void setItem(String item) &#123; this.item = item; &#125; &#125; package com.formula.design.visitor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce 消费的单子 **/ public class ConsumeBill extends AbstractBill implements Bill &amp;#123; public ConsumeBill(double amount, String item) &amp;#123; super(amount, item); &amp;#125; @Override public void accept(AccountBookViewer accountBookViewer) &amp;#123; accountBookViewer.view(this); &amp;#125; &amp;#125; package com.formula.design.visitor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce 收入的单子 **/ public class IncomeBill extends AbstractBill implements Bill &amp;#123; public IncomeBill(double amount, String item) &amp;#123; super(amount, item); &amp;#125; @Override public void accept(AccountBookViewer accountBookViewer) &amp;#123; accountBookViewer.view(this); &amp;#125; &amp;#125; package com.formula.design.visitor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce 账单查看者接口(相当于Visitor) **/ public interface AccountBookViewer &amp;#123; /** * 查看消费的单子 * * @param consumeBill */ void view(ConsumeBill consumeBill); /** * 查看收入的单子 * * @param incomeBill */ void view(IncomeBill incomeBill); &amp;#125; package com.formula.design.visitor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce 老板类, 查看账本的类之一 **/ public class Boss implements AccountBookViewer &amp;#123; private double totalIncome; private double totalConsume; @Override public void view(ConsumeBill consumeBill) &amp;#123; totalConsume += consumeBill.getAmount(); &amp;#125; @Override public void view(IncomeBill incomeBill) &amp;#123; totalIncome += incomeBill.getAmount(); &amp;#125; public double getTotalIncome() &amp;#123; System.out.println(\"老板查看一共多少收入,数目是:\" + totalIncome); return totalIncome; &amp;#125; public double getTotalConsume() &amp;#123; System.out.println(\"老板查看一共多少花费,数目是:\" + totalConsume); return totalConsume; &amp;#125; &amp;#125; package com.formula.design.visitor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce 注册会计师, 查看账号的类之一 **/ public class CPA implements AccountBookViewer &amp;#123; /** * 会计在查看账本时,如果是支出,且支出是工资, 则要看是否交税 * * @param consumeBill */ @Override public void view(ConsumeBill consumeBill) &amp;#123; if (consumeBill.getItem().equals(\"工资\")) &amp;#123; System.out.println(\"注会查看账本时，如果单子的消费目的是发工资，则注会会查看有没有交个人所得税。\"); &amp;#125; &amp;#125; /** * 如果是收入，则所有的收入都要交税 * * @param incomeBill */ @Override public void view(IncomeBill incomeBill) &amp;#123; System.out.println(\"注会查看账本时，只要是收入，注会都要查看公司交税了没。\"); &amp;#125; &amp;#125; package com.formula.design.visitor; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce 账本类(相当于ObjectStruture) **/ public class AccountBook &amp;#123; /** * 单子列表 */ private List&lt;Bill> billList = new ArrayList&lt;>(); /** * 添加单子 * * @param bill */ public void add(Bill bill) &amp;#123; billList.add(bill); &amp;#125; /** * 供账本的查看者查看账本 * * @param accountBookViewer */ public void show(AccountBookViewer accountBookViewer) &amp;#123; billList.stream().forEach(bill -> &amp;#123; bill.accept(accountBookViewer); &amp;#125;); &amp;#125; &amp;#125; 测试类 package com.formula.design.visitor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/26 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; // 编写一个财务的例子 AccountBook accountBook = new AccountBook(); // 增加两条收入 accountBook.add(new IncomeBill(20000, \"卖广告位\")); accountBook.add(new IncomeBill(10000, \"卖商品\")); // 增加两条支出 accountBook.add(new ConsumeBill(5000, \"工资\")); accountBook.add(new ConsumeBill(7000, \"卖材料\")); // 两个访问者 Boss boss = new Boss(); accountBook.show(boss); boss.getTotalConsume(); boss.getTotalIncome(); CPA cpa = new CPA(); accountBook.show(cpa); &amp;#125; &amp;#125; 结果 老板查看一共多少花费,数目是:12000.0 老板查看一共多少收入,数目是:30000.0 注会查看账本时，只要是收入，注会都要查看公司交税了没。 注会查看账本时，只要是收入，注会都要查看公司交税了没。 注会查看账本时，如果单子的消费目的是发工资，则注会会查看有没有交个人所得税。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之解释器模式(17)","slug":"设计模式/设计模式之解释器模式(17)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-jie-shi-qi-mo-shi-17/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-jie-shi-qi-mo-shi-17/","excerpt":"","text":"17. 设计模式之解释器模式(Interpreter Pattern) 1. 概念解释器模式是行为模式的一种,通过建立一个解释器,对于特定的计算机程序设计语言,用来解释预先定义的文法.简单的说,Interpreter 模式是一种简单的语法解释器构架 2. 应用场景 可以将一个需要解释执行的语言中的句子表达为一个抽象语法树 一些重复出现问题可以用一种简单的语言来进行表达 文法较为简单3. 角色与职责 Context: 解释器上下文环境类,用来存储解释器的上下文环境,比如需要解释的文法等 AbstractExpression: 解释器抽象类 ConcreteExoression: 解释器具体实现类4. 优缺点4.1 优点: 可扩展性比较好,灵活 增加了新的解释表达式的方式 易于实现文法4.2 缺点: 执行效率比较低,可利用场景比较少 对于负责的文法比较难维护5. 代码解释器上下文环境```javapackage com.formula.design.interpreter; import lombok.Builder;import lombok.Data; /** @author:luyanan @email:&#108;&#117;&#x79;&#97;&#x6e;&#97;&#110;&#48;&#x37;&#49;&#x38;&#64;&#49;&#x36;&#x33;&#x2e;&#99;&#x6f;&#109; @date 2019/2/15 @introduce */@Data@Builderpublic class Context { private int input; private int output; } 抽象类解释器 ```java package com.formula.design.interpreter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/15 * @introduce 解释器抽象类 **/ public abstract class AbstractExpression &#123; public abstract void interpret(Context context); &#125; 解释器具体实现 package com.formula.design.interpreter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/15 * @introduce **/ public class DecreaseExpression extends AbstractExpression &amp;#123; @Override public void interpret(Context context) &amp;#123; System.out.println(\"递减\"); int input = context.getInput(); input--; context.setInput(input); context.setOutput(input); &amp;#125; &amp;#125; package com.formula.design.interpreter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/15 * @introduce **/ public class IncreaseExpression extends AbstractExpression &amp;#123; @Override public void interpret(Context context) &amp;#123; System.out.println(\"递增\"); int input = context.getInput(); input++; context.setInput(input); context.setOutput(input); &amp;#125; &amp;#125; 测试类 package com.formula.design.interpreter; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/15 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Context context = Context.builder().input(15).build(); AbstractExpression expression1 = new IncreaseExpression(); expression1.interpret(context); System.out.println(context.toString()); AbstractExpression expression2 = new DecreaseExpression(); expression2.interpret(context); System.out.println(context.toString()); &amp;#125; &amp;#125; 结果 递增 Context(input=16, output=16) 递减 Context(input=15, output=15)","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之装饰器模式(11)","slug":"设计模式/设计模式之装饰器模式(11)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zhuang-shi-qi-mo-shi-11/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zhuang-shi-qi-mo-shi-11/","excerpt":"","text":"11. 设计模式之装饰模式(Decorator Pattren) 1. 概念装饰模式又叫包装模式,通过一种对客户端透明的方式来扩展对象的功能,是继承关系的一个替换方案. 2. 角色和职责 抽象组件角色:一个抽象接口,是被装饰类和装饰类的父接口 具体组件角色:为抽象组件的实现类 抽象装饰角色:包含一个组件的引用,并定义了与抽象组件一致的接口 具体装饰角色:为抽象装饰角色的实现类,负责具体的装饰3. 优缺点:3.1 优点:可以提供比继承更多的灵活性,可用通过一种动态的方式来扩展一个对象的功能,并通过使用不同的具体装饰类以及这些装饰类的排列组合,可以创建出很多不同行为的组合,而且具体构建类与具体装饰类可以独立变化,用户可以根据需要增加新的具体构建类和具体装饰类3.2 缺点:使用装饰模式进行系统设计时将产生很多的小对象,而且装饰模式比继承更加易于出错,拍错也困难,对于多次装饰的对象,调试时寻找错误可能需要逐级排查,较为繁琐4.使用场景在不影响其他对象的情况下,以动态的,透明的方式给单个对象添加职责.需要动态的给一个对象添加功能,这些功能也可以动态的被撤销。当不能采用继承的方式对系统进行功能扩充或者采用继承不利于系统扩展和维护的时候4. 代码抽象组件角色```javapackage com.formula.design.decorator; /** @author:luyanan @email:&#x6c;&#x75;&#121;&#97;&#x6e;&#97;&#110;&#x30;&#55;&#x31;&#x38;&#x40;&#x31;&#x36;&#x33;&#x2e;&#99;&#111;&#109; @date 2019/1/23 @introduce 抽象组件角色 */public interface Car { void run(); void show(); } 具体组件角色 ```java package com.formula.design.decorator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/23 * @introduce 具体组件角色 **/ public class RunCar implements Car &#123; @Override public void run() &#123; System.out.println(&quot;会跑的汽车&quot;); &#125; @Override public void show() &#123; this.run(); &#125; &#125; 汽车的装饰类 package com.formula.design.decorator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/23 * @introduce 汽车的装饰类 **/ public abstract class CarDecorator implements Car &amp;#123; private Car car; public CarDecorator(Car car) &amp;#123; this.car = car; &amp;#125; public Car getCar() &amp;#123; return car; &amp;#125; @Override public void run() &amp;#123; &amp;#125; &amp;#125; 装饰实现类 package com.formula.design.decorator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/23 * @introduce 装饰实现类 **/ public class FlyCarDecorator extends CarDecorator &amp;#123; public FlyCarDecorator(Car car) &amp;#123; super(car); &amp;#125; @Override public void show() &amp;#123; this.getCar().show(); this.fly(); &amp;#125; private void fly() &amp;#123; System.out.println(\"会飞的汽车\"); &amp;#125; &amp;#125; package com.formula.design.decorator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/23 * @introduce 装饰实现类 **/ public class SwimCarDeacrator extends CarDecorator &amp;#123; public SwimCarDeacrator(Car car) &amp;#123; super(car); &amp;#125; @Override public void show() &amp;#123; this.getCar().show(); this.swim(); &amp;#125; private void swim() &amp;#123; System.out.println(\"会游泳的汽车\"); &amp;#125; &amp;#125; 测试类 package com.formula.design.decorator; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/23 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Car car = new RunCar(); car.show(); System.out.println(\"------------------\"); CarDecorator carDecorator = new FlyCarDecorator(car); carDecorator.show(); System.out.println(\"------------------\"); carDecorator = new SwimCarDeacrator(carDecorator); carDecorator.show();; &amp;#125; &amp;#125; 结果 会跑的汽车 ------------------ 会跑的汽车 会飞的汽车 ------------------ 会跑的汽车 会飞的汽车 会游泳的汽车 5. 装饰器模式在源码的应用装饰器模式在源码中应用的也非常多,在JDK中体现的最明显的类就是IO相关的类,如BufferedReader,InputStream,OutputStream.在Spring中的类TransactionAwareCacheDecorator,这个类主要是用来处理事务缓存的 ublic class TransactionAwareCacheDecorator implements Cache &amp;#123; private final Cache targetCache; public TransactionAwareCacheDecorator(Cache targetCache) &amp;#123; Assert.notNull(targetCache, \"Target Cache must not be null\"); this.targetCache = targetCache; &amp;#125; public Cache getTargetCache() &amp;#123; return this.targetCache; &amp;#125; public String getName() &amp;#123; return this.targetCache.getName(); &amp;#125; public Object getNativeCache() &amp;#123; return this.targetCache.getNativeCache(); &amp;#125; @Nullable public ValueWrapper get(Object key) &amp;#123; return this.targetCache.get(key); &amp;#125; public &lt;T> T get(Object key, @Nullable Class&lt;T> type) &amp;#123; return this.targetCache.get(key, type); &amp;#125; @Nullable public &lt;T> T get(Object key, Callable&lt;T> valueLoader) &amp;#123; return this.targetCache.get(key, valueLoader); &amp;#125; public void put(final Object key, @Nullable final Object value) &amp;#123; if (TransactionSynchronizationManager.isSynchronizationActive()) &amp;#123; TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() &amp;#123; public void afterCommit() &amp;#123; TransactionAwareCacheDecorator.this.targetCache.put(key, value); &amp;#125; &amp;#125;); &amp;#125; else &amp;#123; this.targetCache.put(key, value); &amp;#125; &amp;#125; @Nullable public ValueWrapper putIfAbsent(Object key, @Nullable Object value) &amp;#123; return this.targetCache.putIfAbsent(key, value); &amp;#125; public void evict(final Object key) &amp;#123; if (TransactionSynchronizationManager.isSynchronizationActive()) &amp;#123; TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() &amp;#123; public void afterCommit() &amp;#123; TransactionAwareCacheDecorator.this.targetCache.evict(key); &amp;#125; &amp;#125;); &amp;#125; else &amp;#123; this.targetCache.evict(key); &amp;#125; &amp;#125; public void clear() &amp;#123; if (TransactionSynchronizationManager.isSynchronizationActive()) &amp;#123; TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() &amp;#123; public void afterCommit() &amp;#123; TransactionAwareCacheDecorator.this.targetCache.clear(); &amp;#125; &amp;#125;); &amp;#125; else &amp;#123; this.targetCache.clear(); &amp;#125; &amp;#125; &amp;#125; TransactionAwareCacheDecorator 类就是对Cache的一个包装,再看MVC中的装饰器模式的类HttpHeadResponseDecorator // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package org.springframework.http.server.reactive; import java.util.function.BiFunction; import java.util.function.Consumer; import org.reactivestreams.Publisher; import org.springframework.core.io.buffer.DataBuffer; import org.springframework.core.io.buffer.DataBufferUtils; import reactor.core.publisher.Flux; import reactor.core.publisher.Mono; public class HttpHeadResponseDecorator extends ServerHttpResponseDecorator &amp;#123; public HttpHeadResponseDecorator(ServerHttpResponse delegate) &amp;#123; super(delegate); &amp;#125; public final Mono&lt;Void> writeWith(Publisher&lt;? extends DataBuffer> body) &amp;#123; return this.getDelegate().writeWith(Flux.from(body).reduce(0, (current, buffer) -> &amp;#123; int next = current + buffer.readableByteCount(); DataBufferUtils.release(buffer); return next; &amp;#125;).doOnNext((count) -> &amp;#123; this.getHeaders().setContentLength((long)count); &amp;#125;).then(Mono.empty())); &amp;#125; public final Mono&lt;Void> writeAndFlushWith(Publisher&lt;? extends Publisher&lt;? extends DataBuffer>> body) &amp;#123; return this.setComplete(); &amp;#125; &amp;#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之组合模式(10)","slug":"设计模式/设计模式之组合模式(10)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zu-he-mo-shi-10/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zu-he-mo-shi-10/","excerpt":"","text":"10 . 设计模式之组合模式(Composite Pattren) 1. 概念组合组合模式是构造性的设计模式之一.通过递归手段来实现树形的对象结构,并可以通过一个对象来访问整个对象树 2. 角色和职责 Component(树形结构的节点抽象): 为所有的对象定义统一的接口(公共属性,行为等的定义) 提供管理子节点对象的接口的方法 [可选]提供管理父节点对象的接口方法 Leaf(树形结构的叶节点) :Comoonent的实现子类 Composite(树形结构的枝节点):Component的实现子类 3. 优缺点3.1 优点: 组合模式使得客户端的代码可以一致的处理对象和对象容器,无需关系处理的单个对象,还是组合的对象容器 将客户端代码与复杂的对象容器结构 解耦 可以更容易的往组合对象中添加新的构件3.2 缺点: 使得设计更加复杂,客户端需要花更多的时间理清类之间的层次关系3.3 注意的问题: 有时候系统需要遍历一个树枝结构的子构件很多次,这个时候可以考虑把遍历子构件的结构存储到父构件里面作为缓存 客户端尽量不要直接调用树叶类的方法,而是借用其父类的多态性来完成调用,这样可以增加代码的复用性.4. 使用场景: 当想表达对象的部分-整体的层次结构的时候 希望用户忽略组合对象与单个对象的不同,用户将统一的使用组合结构中的所有对象时5. 代码```javapackage com.formula.design.composite; import java.util.List; /** @author:luyanan @email:&#108;&#x75;&#121;&#x61;&#x6e;&#x61;&#x6e;&#48;&#x37;&#49;&#56;&#x40;&#x31;&#x36;&#x33;&#46;&#x63;&#x6f;&#x6d; @date 2019/1/20 @introduce */public interface IFile { /** * 打印 */ void display(); } ```java package com.formula.design.composite; import java.util.ArrayList; import java.util.List; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/20 * @introduce 文件夹 **/ public class Folder implements IFile &#123; private String name; private List&lt;IFile&gt; childrenList; public Folder(String name) &#123; this.name = name; childrenList = new ArrayList&lt;&gt;(); &#125; @Override public void display() &#123; System.out.println(&quot;文件夹名称为--&quot;+this.name); treeClildren(this.childrenList); &#125; private static void treeClildren(List&lt;IFile&gt; childrenList) &#123; childrenList.stream().forEach(children -&gt; &#123; if (children instanceof File) &#123; // 文件 children.display(); &#125; else &#123; Folder folder = (Folder) children; folder.display(); treeClildren(folder.getChildrenList()); &#125; &#125;); &#125; public boolean add(IFile file) &#123; return this.childrenList.add(file); &#125; public boolean remove(IFile file) &#123; return this.remove(file); &#125; public List&lt;IFile&gt; getChildrenList() &#123; return childrenList; &#125; public void setChildrenList(List&lt;IFile&gt; childrenList) &#123; this.childrenList = childrenList; &#125; &#125; package com.formula.design.composite; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/20 * @introduce 文件 **/ public class File implements IFile &amp;#123; private String name; public File(String name) &amp;#123; this.name = name; &amp;#125; @Override public void display() &amp;#123; System.out.println(\"文件名称\" + this.name); &amp;#125; &amp;#125; 测试类 package com.formula.design.composite; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/20 * @introduce 主测试类 **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Folder folder = new Folder(\"C:\"); File file2 = new File(\"02.txt\"); Folder folder2 = new Folder(\"02文件夹\"); File file3 = new File(\"03.txt\"); Folder folder3 = new Folder(\"03文件夹\"); folder2.add(file3); folder2.add(folder3); folder.add(file2); folder.add(folder2); folder.display(); &amp;#125; &amp;#125; 结果 文件夹名称为--C: 文件名称02.txt 文件夹名称为--02文件夹 文件名称03.txt 文件夹名称为--03文件夹 文件名称03.txt 文件夹名称为--03文件夹","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之简单工厂模式(1)","slug":"设计模式/设计模式之简单工厂模式(1)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-jian-dan-gong-han-mo-shi-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-jian-dan-gong-han-mo-shi-1/","excerpt":"","text":"1. 设计模式之工厂模式 1. 概念 工厂模式属于类的创建型模式 又叫静态工厂方法模式.通过专门定义一个类 来负责创建其他类的实例,被创建的实例通常都具有共同的父类 2. 模式中包含的角色及其指责 工厂(Creator) 角色 工厂模式的核心,他负责实现所创建所有实例的内部逻辑.工厂类可以被外界直接调用,创建所需的产品对象 抽象(Product) 角色 工厂模式所创建的所有对象的父类,它负责描述所有实例所共有的公共接口 具体产品(Concrete Product)角色 工厂模式所创建的具体实例对象3. 优缺点 优点 在这个模式中,工厂类是整个模块的关键所在.它包含必要的判断逻辑,能够根据外界给定的信息,决定究竟应该创建哪个具体类的对象.用户在使用时可以根据工厂类去创建所需的实例,而无需了解这些对象是如何创建以及如何组织的.有利于整个软件体系结构的优化 缺点 简单工厂模式的缺点也正体现在其工厂类上,由于工厂类集中了所有实例的创建逻辑,所以”高内聚”方面做得并不好.另外,当系统中的具体产品类不断增多的时候,可能会出现要求工厂类也要做出相应的修改,扩展性不不是很好.4. 代码 1 抽象角色```javapackage com.formula.design.factory; /** @author:luyanan @email:&#x6c;&#117;&#x79;&#97;&#x6e;&#x61;&#x6e;&#x30;&#55;&#49;&#x38;&#64;&#x31;&#x36;&#51;&#46;&#x63;&#x6f;&#109; @date 2019/1/7 @introduce */public interface Fruit { /** * 采集方法 */ void collect(); } 4.2 具体产品(Concrete Product)角色 ```java package com.formula.design.factory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce 苹果 **/ public class Apple implements Fruit &#123; @Override public void collect() &#123; System.out.println(&quot;苹果采集........&quot;); &#125; &#125; package com.formula.design.factory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce 香蕉 **/ public class Banana implements Fruit &amp;#123; @Override public void collect() &amp;#123; System.out.println(\"香蕉的采集.......\"); &amp;#125; &amp;#125; package com.formula.design.factory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce 橘子 **/ public class Orange implements Fruit &amp;#123; @Override public void collect() &amp;#123; System.out.println(\"橘子的采集.........\"); &amp;#125; &amp;#125; 4.3 工厂(Creator) 角色 package com.formula.design.factory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce **/ public class FruitFactory &amp;#123; // 苹果 public static final int apple = 1; // 香蕉 public static final int banana = 2; // 橘子 public static final int orange = 3; /** * 获取实现类 * * @param type * @return */ public static Fruit getFruit(int type) &amp;#123; switch (type) &amp;#123; case apple: return new Apple(); case banana: return new Banana(); case orange: default: return new Orange(); &amp;#125; &amp;#125; &amp;#125; 4.4 主方法 package com.formula.design.factory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; // 获取苹果的实例 Fruit apple = FruitFactory.getFruit(FruitFactory.apple); apple.collect(); // 获取香蕉的实例 Fruit bannan = FruitFactory.getFruit(FruitFactory.banana); bannan.collect(); // 获取橘子的实例 Fruit orange = FruitFactory.getFruit(FruitFactory.orange); orange.collect(); &amp;#125; &amp;#125; 结果 苹果采集........ 香蕉的采集....... 橘子的采集.........","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之策略模式(24)","slug":"设计模式/设计模式之策略模式(24)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-ce-lue-mo-shi-24/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-ce-lue-mo-shi-24/","excerpt":"","text":"24. 设计模式之策略模式(Strategy Pattern) 1.概念其思想主要是针对一组算法,将每一种算法都封装到具有共同接口的独立的类中,从而使他们之间可以相互替换.策略模式最大的特点使得算法可以在不影响客户端的情况下发生变化,从而改变不同的功能2.特点策略模式主要体现了面向对象设计中的两个重要的原则: 封装变化的概念 编程中使用接口,而不是使用的是具体的实现类 3.角色和职责 抽象策略角色:一个抽象的角色,通常情况下使用接口或者抽象类去实现 具体策略角色:包装了各种策略的具体实现 环境角色:策略的外部封装类,或者说策略的容器类,根据不同的策略执行不同的行为,策略由外部条件决定4.优点 策略模式提供了管理相关的算法的方法,策略类的等级结构定义了一个算法或行为族,恰当的使用继承可以把公共的方法转移到父类里,从而避免重复的代码 策略模式提供了可以替换继承关系的办法,继承可以处理多重算法或行为.如果不是策略模式,那么使用算法或行为的环境类就可能会有一些子类,每一个子类提供不同的算法或行为,但决定使用哪一种算法或采取哪一种行为的逻辑就和算法或行为的逻辑混合在一起了,从未不可能在独立演化.继承使得动态改变算法或行为变的不可能 使用策略迷失可以避免使用多重条件转移语句,多重转移语句不易维护,他把采取哪一种算法或采取哪一种行为的逻辑混合在一起，统统列在一个多重转移语句里面,比使用集成的方法还要原始和落后4. 缺点 客户端必须知道所有的策略类,并自行决定使用哪一个策略类.这就意味着客户端必须理解这些算法之间的区别,以便适时的选择恰当的算法类.换言之,策略模式只适用于客户端知道所有的算法或行为的情况 策略模式造成很多的侧落泪,有时候可以通过把依赖于环境的状态保存到客户端里面,而将策略类设计成可共享的,这样策略类实例就可以被不同的客户端使用.换言之,可以使用 享元模式来减少对象的数量5.案例 抽象策略角色```javapackage com.formula.design.strategy; /** @author:luyanan @email:&#x6c;&#117;&#x79;&#97;&#x6e;&#x61;&#110;&#48;&#x37;&#49;&#x38;&#64;&#x31;&#x36;&#51;&#x2e;&#x63;&#111;&#x6d; @date 2019/1/3 @introduce */public interface Strategy { int doOperation(int num1, int num2); } 2. 具体策略角色 ```java package com.formula.design.strategy; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/3 * @introduce 定义加法策略 **/ public class AddStrategy implements Strategy &#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125; &#125; package com.formula.design.strategy; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/3 * @introduce 定义减法策略 **/ public class SubtractStrategy implements Strategy &amp;#123; @Override public int doOperation(int num1, int num2) &amp;#123; return num1 - num2; &amp;#125; &amp;#125; package com.formula.design.strategy; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/3 * @introduce 定义乘法策略 **/ public class MultiplyStrategy implements Strategy &amp;#123; @Override public int doOperation(int num1, int num2) &amp;#123; return num1 * num2; &amp;#125; &amp;#125; 环境角色```javapackage com.formula.design.strategy; /** @author:luyanan @email:&#x6c;&#x75;&#x79;&#97;&#110;&#97;&#x6e;&#48;&#55;&#x31;&#56;&#64;&#x31;&#54;&#x33;&#46;&#x63;&#111;&#109; @date 2019/1/3 @introduce */public class Context { private Strategy strategy; public Context(Strategy strategy) &#123; this.strategy = strategy; &#125; public int execute(int num1, int num2) &#123; return strategy.doOperation(num1, num2); &#125; } 4. 测试类 ```java package com.formula.design.strategy; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/3 * @introduce **/ public class StrategyMain &#123; public static void main(String[] args) &#123; int num1 = 10; int num2 = 5; // 加法 Context context = new Context(new AddStrategy()); System.out.println(&quot;加法:&quot; + context.execute(num1, num2)); // 减法 context = new Context(new SubtractStrategy()); System.out.println(&quot;减法:&quot; + context.execute(num1, num2)); // 乘法 context = new Context(new MultiplyStrategy()); System.out.println(&quot;乘法:&quot; + context.execute(num1, num2)); &#125; &#125; 结果 加法:15 减法:5 乘法:50 6. 策略模式在JDK中的体现首先来看一个比较常用的比较器 Comparator接口,我们看到的一个大家常用的方法 compare()方法, @FunctionalInterface public interface Comparator&lt;T> &amp;#123; int compare(T o1, T o2); Comparator抽象下面就有非常多的实现类,我们常把Comparator 作为参数作为排序策略,例如 Arrays的 parallelSort方法 public static &lt;T> void parallelSort(T[] a, Comparator&lt;? super T> cmp) &amp;#123; if (cmp == null) cmp = NaturalOrder.INSTANCE; int n = a.length, p, g; if (n &lt;= MIN_ARRAY_SORT_GRAN || (p = ForkJoinPool.getCommonPoolParallelism()) == 1) TimSort.sort(a, 0, n, cmp, null, 0, 0); else new ArraysParallelSortHelpers.FJObject.Sorter&lt;T> (null, a, (T[])Array.newInstance(a.getClass().getComponentType(), n), 0, n, 0, ((g = n / (p &lt;&lt; 2)) &lt;= MIN_ARRAY_SORT_GRAN) ? MIN_ARRAY_SORT_GRAN : g, cmp).invoke(); &amp;#125; 还有TreeMap的构造方法 public TreeMap(Comparator&lt;? super K> comparator) &amp;#123; this.comparator = comparator; &amp;#125; 接下来我们看看策略模式在Spring中的应用 package org.springframework.core.io; import java.io.File; import java.io.IOException; import java.net.URI; import java.net.URL; import java.nio.channels.Channels; import java.nio.channels.ReadableByteChannel; import org.springframework.lang.Nullable; public interface Resource extends InputStreamSource &amp;#123; boolean exists(); default boolean isReadable() &amp;#123; return true; &amp;#125; default boolean isOpen() &amp;#123; return false; &amp;#125; default boolean isFile() &amp;#123; return false; &amp;#125; URL getURL() throws IOException; URI getURI() throws IOException; File getFile() throws IOException; default ReadableByteChannel readableChannel() throws IOException &amp;#123; return Channels.newChannel(this.getInputStream()); &amp;#125; long contentLength() throws IOException; long lastModified() throws IOException; Resource createRelative(String var1) throws IOException; @Nullable String getFilename(); String getDescription(); &amp;#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之空对象模式(23)","slug":"设计模式/设计模式之空对象模式(23)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-kong-dui-xiang-mo-shi-23/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-kong-dui-xiang-mo-shi-23/","excerpt":"","text":"23. 设计模式之空对象模式(Null Object Pattern) 1.概念在空对象模式中,一个空对象取代NULL 对象实例的检查.Null对象不是检查空值,而是反应一个不做任何动作的关系.这样的Null对象也可以在数据不可用的时候提供默认行为.在空对象模式中,我们可以创建么一个指定各种要执行的操作的抽象类和扩展该类的实体类,还创建一个未对该类做任何实现的空对象类,改空对象类无缝的使用在需要检查空值的地方. 2. 代码示例package com.formula.design.nullobject; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/27 * @introduce **/ public class Optional&lt;T> &amp;#123; private T t; public T getT() &amp;#123; return t; &amp;#125; public void setT(T t) &amp;#123; this.t = t; &amp;#125; public boolean isNull() &amp;#123; if (t == null) &amp;#123; return true; &amp;#125; else &amp;#123; return false; &amp;#125; &amp;#125; &amp;#125; package com.formula.design.nullobject; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/27 * @introduce **/ @Data @Builder @AllArgsConstructor @NoArgsConstructor public class User &amp;#123; private int id; private String name; &amp;#125; package com.formula.design.nullobject; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/27 * @introduce **/ public class UserFactory &amp;#123; public static Optional&lt;User> getUser(int id) &amp;#123; Optional&lt;User> optional = new Optional&lt;>(); switch (id) &amp;#123; case 1: optional.setT(new User(id, \"admin\")); break; case 2: optional.setT(new User(id, \"张三\")); break; default: optional.setT(null); break; &amp;#125; return optional; &amp;#125; &amp;#125; 测试类 package com.formula.design.nullobject; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/27 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; for (int i = 0; i &lt; 4; i++) &amp;#123; Optional&lt;User> optional = UserFactory.getUser(i); if (optional.isNull()) &amp;#123; System.out.println(\"老兄.输入的id--\" + i + \"不存在呀\"); &amp;#125; else &amp;#123; System.out.println(optional.getT().toString()); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 结果 老兄.输入的id--0不存在呀 User(id=1, name=admin) User(id=2, name=张三) 老兄.输入的id--3不存在呀","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之状态模式(22)","slug":"设计模式/设计模式之状态模式(22)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zhuang-tai-mo-shi-22/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-zhuang-tai-mo-shi-22/","excerpt":"","text":"22. 设计模式之状态模式(State Pattern) 1. 概念状态模式是行为模式的一种,State模式允许改变对象的内部状态而改变对象的行为,这个对象表现的好像修改了他的类一样. 2. 使用场景状态模式主要解决的是当控制一个对象状态转换的条件表达式过于复杂的情况.把状态的判断逻辑转译到表现不同状态的一系列类当中,乐意把复杂的判断逻辑简化. 3.角色和职责 Context：用户对象拥有一个State类型的成员,以标识对象的当前状态. State:接口或者基类封装与Context的特定状态相关的行为. ConcreteState:接口的实现类或者子类实现了一个与Context某个状态相关的行为.4. 优缺点:4.1 优点: 封装了转换原则 枚举可能的状态,在枚举状态之间需要确定状态种类. 将所有与某个状态有关的行为放到一个类中,并且可以方便的增加新的状态,只需要修改对象状态即可改变对象的行为. 允许状态转换逻辑与状态对象合成一体,而不是某一个巨大的条件语句块. 可以让多个环境对象共享一个状态对象,从而减少系统中对象的个数.4.2 缺点 状态模式的使用必然会增加系统类和对象的个数 状态模式的实现与结构都较为复杂,如果使用不当将导致程序结构和代码的混乱. 状态模式对开闭原则的支持并不太好,对于可以切换状态的状态模式,增加新的状态类 需要修改那些负责状态转换的源代码,否则无法切换到新增状态,而且修改某个状态可的行为也需要修改对应类的源代码5. 代码```javapackage com.formula.design.state; /** @author:luyanan @email:&#x6c;&#117;&#121;&#x61;&#110;&#x61;&#110;&#48;&#55;&#x31;&#x38;&#x40;&#49;&#x36;&#x33;&#x2e;&#99;&#111;&#x6d; @date 2019/2/23 @introduce 状态接口 */public interface State { /** * 获得天气状态 * * @return */ String getState(); } ConcreteState ```java package com.formula.design.state; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/23 * @introduce **/ public class RainState implements State &#123; @Override public String getState() &#123; return &quot;下雨天&quot;; &#125; &#125; package com.formula.design.state; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/23 * @introduce **/ public class SunState implements State &amp;#123; @Override public String getState() &amp;#123; return \"晴天\"; &amp;#125; &amp;#125; Context package com.formula.design.state; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/23 * @introduce **/ public class Context &amp;#123; private State state; public State getState() &amp;#123; return state; &amp;#125; public void setState(State state) &amp;#123; this.state = state; &amp;#125; public String getStateMessage() &amp;#123; return state.getState(); &amp;#125; &amp;#125; 测试类 package com.formula.design.state; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/23 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Context context = new Context(); context.setState(new RainState()); System.out.println(context.getStateMessage()); ; context.setState(new SunState()); System.out.println(context.getStateMessage()); ; &amp;#125; &amp;#125; 结果 下雨天 晴天","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之模板模式(25)","slug":"设计模式/设计模式之模板模式(25)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-mo-ban-mo-shi-25/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-mo-ban-mo-shi-25/","excerpt":"","text":"25. 设计模式之模板模式(Template Pattern) 1. 概念模板方法是行为模式的一种,它把具体特定步骤算法中的某些必要的处理委让给抽象方法,通过子类继承对抽象方法的不同实现改变整个算法的行为. 2. 应用场景模板模式一般应用在具有以下条件的应用中: 具有统一的操作步骤或操作过程. 具有不同的操作细节 存在多个具有同样操作步骤的应用场景,但某些具体的操作细节却各不相同.3. 角色和职责 AbstractClass:抽象类的父类 ConcreteClass: 具体的实现子类.4. 优缺点:4.1 优点: 利用模板模式将相同的处理逻辑的代码放到抽象类中,可以提高代码的复用性. 将不同的代码放到不同的子类中,通过对子类的扩展增加新的行为,提高代码的扩展性. 把不变的行为写到父类上,去除子类的重复代码,提供了一个很好的代码复用平台,符合开闭原则.4.2 缺点: 类数目的增加,每一个抽象类都需要子类实现,这样导致类的个数增加. 类数目的增加,间接的增加系统实现的复杂度. 继承关系自身缺点,如果父类增加新的抽象方法,所有子类都需要改一边.5. 代码抽象类父类```javapackage com.formula.design.template; /** @author:luyanan @email:&#x6c;&#117;&#x79;&#x61;&#x6e;&#97;&#x6e;&#x30;&#x37;&#x31;&#x38;&#64;&#49;&#x36;&#51;&#46;&#x63;&#x6f;&#109; @date 2019/2/25 @introduce 操作文件上传的抽象模板类 */public abstract class FileTemplate { /** 获取文件服务器连接 /public abstract void getClient(); /** 往文件服务器上传文件 /public abstract void uploadFile(String file); /** 关闭连接 /public abstract void close(); public void upload(String file) { getClient(); uploadFile(file); close(); } } 具体的实现类 ```java package com.formula.design.template; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/25 * @introduce 基于cos实现的文件上传 **/ public class CosFileTemplate extends FileTemplate &#123; @Override public void getClient() &#123; System.out.println(&quot;获取cos文件服务器链接&quot;); &#125; @Override public void uploadFile(String file) &#123; System.out.println(&quot;往COS文件服务器上传文件--&quot; + file); &#125; @Override public void close() &#123; System.out.println(&quot;关闭COS文件服务器链接&quot;); &#125; &#125; package com.formula.design.template; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/25 * @introduce 基于OSS实现的文件操作 **/ public class OSSFileTemplate extends FileTemplate &amp;#123; @Override public void getClient() &amp;#123; System.out.println(\"获取OSS文件服务器链接\"); &amp;#125; @Override public void uploadFile(String file) &amp;#123; System.out.println(\"往OSS文件服务器上传文件--\" + file); &amp;#125; @Override public void close() &amp;#123; System.out.println(\"关闭OSS文件服务器链接\"); &amp;#125; &amp;#125; 测试类 package com.formula.design.template; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/2/25 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; FileTemplate cosFileTemplate = new CosFileTemplate(); cosFileTemplate.upload(\"01.jpg\"); System.out.println(\"-----------------------\"); FileTemplate ossFileTemplate = new CosFileTemplate(); ossFileTemplate.upload(\"02.jpg\"); &amp;#125; &amp;#125; 结果 获取cos文件服务器链接 往COS文件服务器上传文件--01.jpg 关闭COS文件服务器链接 ----------------------- 获取cos文件服务器链接 往COS文件服务器上传文件--02.jpg 关闭COS文件服务器链接 6. 模板模式在源码中的体现我们先看JDK中的AbstractList public abstract class AbstractList&lt;E> extends AbstractCollection&lt;E> implements List&lt;E> &amp;#123; /** * &amp;#123;@inheritDoc&amp;#125; * * @throws IndexOutOfBoundsException &amp;#123;@inheritDoc&amp;#125; */ abstract public E get(int index); 我们看到get()是一个抽象的方法,他的业务逻辑就是交给子类来实现的,我们大家众所周知的ArrayList就是AbstractList的子类.同理,有AbstractList 就有AbstractSet和AbstractMap.还有每天都在用的HttpServlet的service()和doGet(),doPost方法 都是模板模式的抽象实现.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之桥接模式(8)","slug":"设计模式/设计模式之桥接模式(8)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-qiao-jie-mo-shi-8/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-qiao-jie-mo-shi-8/","excerpt":"","text":"8. 设计模式之桥接模式(Bridge Pattren) 1. 概念Bridge 模式又叫桥接模式,是构造型的设计模式之一.Bridge 模式是基于类的最小设计原型,使用封装,聚合以及继承等行为来让不同的类承担不同的责任.它的主要特点是把抽象与行为实现分离开来,从而可以保证和部分的独立性以及应对他们的功能扩展 2. 角色和职责 cleint:Bridge模式的使用者 Abstraction 抽象类接口(接口或者抽象类) 维护对行为实现的引用 Refined Abstraction: Abstraction 子类 Implementor: 行为实现类接口(Abstraction 接口定义了基于Implementor 接口的更高层次的操作) ConcreteImplementeor: Implementor的子类3. 优缺点3.1 优点: 分离抽象接口以及实现部分.提供了比继承更好的解决方案 桥接模式提供了系统的可扩展性,在两个变化维度中任意扩展一个维度,都不需要修改原有的系统 实现细节对客户透明,可以对用户隐藏实现细节3.2 缺点 桥接模式的引入会增加系统的理解和设计难度,由于聚合关联关系建立在抽象层,要求开发者针对抽象进行设计与编程 桥接模式要求正确识别出系统中两个独立变化的维度,因为其使用范围具有一定的局限性.4. 使用场景 如果一个系统需要在构建的抽象画角色和具体化角色之前增加更多的灵活性,避免在两个层次之间建立静态的继承联系,通过桥接模式可以使他们在抽象层建立一个关联关系 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统,桥接模式尤为使用 一个类存在两个独立变化的维护,且这两个维度都需要进行扩展4. 代码行为接口类```javapackage com.formula.design.bridge; /** @author:luyanan @email:&#108;&#x75;&#x79;&#97;&#x6e;&#97;&#110;&#x30;&#55;&#x31;&#56;&#64;&#49;&#x36;&#x33;&#x2e;&#99;&#x6f;&#x6d; @date 2019/1/18 @introduce */public interface Engine { void installEnine();} 行为接口实现类 ```java package com.formula.design.bridge; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/18 * @introduce **/ public class Engine2000 implements Engine &#123; @Override public void installEnine() &#123; System.out.println(&quot;2000的引擎&quot;); &#125; &#125; package com.formula.design.bridge; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/18 * @introduce **/ public class Engine2200 implements Engine &amp;#123; @Override public void installEnine() &amp;#123; System.out.println(\"2200的引擎\"); &amp;#125; &amp;#125; 抽象类 package com.formula.design.bridge; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/18 * @introduce **/ public abstract class Car &amp;#123; private Engine engine; public Car(Engine engine) &amp;#123; this.engine = engine; &amp;#125; public abstract void installEngin(); public Engine getEngine() &amp;#123; return engine; &amp;#125; public void setEngine(Engine engine) &amp;#123; this.engine = engine; &amp;#125; &amp;#125; Refined Abstraction 类 package com.formula.design.bridge; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/18 * @introduce **/ public abstract class Car &amp;#123; private Engine engine; public Car(Engine engine) &amp;#123; this.engine = engine; &amp;#125; public abstract void installEngin(); public Engine getEngine() &amp;#123; return engine; &amp;#125; public void setEngine(Engine engine) &amp;#123; this.engine = engine; &amp;#125; &amp;#125; package com.formula.design.bridge; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/18 * @introduce **/ public class Jeep extends Car &amp;#123; public Jeep(Engine engine) &amp;#123; super(engine); &amp;#125; @Override public void installEngin() &amp;#123; System.out.print(\"Jeep\"); super.getEngine().installEnine(); &amp;#125; &amp;#125; 测试类 package com.formula.design.bridge; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/18 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Engine engine2000 = new Engine2000(); Engine engine2200 = new Engine2200(); // bus 2000的引擎 Car bus2000 = new Bus(engine2000); bus2000.installEngin(); Car bus2200 = new Bus(engine2200); bus2200.installEngin(); Car jeep2000 = new Jeep(engine2000); jeep2000.installEngin(); Car jeep2200 = new Jeep(engine2200); jeep2200.installEngin(); &amp;#125; &amp;#125; 结果 bus-2000的引擎 bus-2200的引擎 Jeep2000的引擎 Jeep2200的引擎","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之抽象工厂模式(3)","slug":"设计模式/设计模式之抽象工厂模式(3)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-chou-xiang-gong-han-mo-shi-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-chou-xiang-gong-han-mo-shi-3/","excerpt":"","text":"3. 设计模式之抽象工厂模式(Abstract Factory Pattren) 1. 介绍抽象工厂模式是所有形态的工厂模式中最为抽象的和最具一般性的.抽象工厂模式可以向客户端提供一个接口,使得客户端在不必指定产品的具体类型的情况下,能够创建多个产品族的产品对象 2. 角色和职责 抽象工厂角色 抽象工厂模式的核心,包含对多个产品结构的声明,任何工厂类都必须实现这个接口. 具体工厂角色具体工厂类是抽象工厂的一个实现,负责实例化某个产品族中的产品对象 抽象角色 抽象模式所创建的所有对象的父类,它负责描述所有实例共有的公共接口 具体产品角色 抽象模式所创建的具体实例对象总结:抽象工厂中方法对应产品结构,具体工厂对用产品族3. 代码 1 新建User实体```javapackage com.formula.design.abstractfactory; import lombok.Builder;import lombok.Data; /** @author:luyanan @email:&#108;&#117;&#x79;&#97;&#x6e;&#x61;&#x6e;&#x30;&#55;&#49;&#56;&#x40;&#49;&#x36;&#x33;&#x2e;&#x63;&#111;&#109; @date 2019/1/8 @introduce */@Data@Builderpublic class User { private String name; private Integer id;} 定义一个接口 ```java package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public interface IUserService &#123; void insert(User user); User getUser(Integer id); &#125; 有基于mysql数据源和oracle数据源的两个实现 package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public class MysqlUserServiceImpl implements IUserService &amp;#123; @Override public void insert(User user) &amp;#123; System.out.println(\"往mysql的user中保存信息\"); &amp;#125; @Override public User getUser(Integer id) &amp;#123; System.out.println(\"在mysql的user中根据\" + id + \"获取数据\"); return null; &amp;#125; &amp;#125; package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public class OraclelUserServiceImpl implements IUserService &amp;#123; @Override public void insert(User user) &amp;#123; System.out.println(\"往oracle的user中插入数据\"); &amp;#125; @Override public User getUser(Integer id) &amp;#123; System.out.println(\"在oracle的user中获取数据\"); return null; &amp;#125; &amp;#125; 然后新建一个登陆的实体 package com.formula.design.abstractfactory; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; import java.util.Date; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ @Data @Builder @AllArgsConstructor @NoArgsConstructor public class Login &amp;#123; private int id; private Date date; &amp;#125; 一个login的接口 package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public interface ILoginService &amp;#123; void insert(Login login); public Login getLogin(int id); &amp;#125; 基于mysql的和基于oracle的两个实现 package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public class MysqlLoginServiceImpl implements ILoginService &amp;#123; @Override public void insert(Login login) &amp;#123; System.out.println(\"在Mysql的Login 插入一条数据\"); &amp;#125; @Override public Login getLogin(int id) &amp;#123; System.out.println(\"在Mysql的Login表中获取一条数据\"); return null; &amp;#125; &amp;#125; package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public class OracleLoginServiceImpl implements ILoginService &amp;#123; @Override public void insert(Login login) &amp;#123; System.out.println(\"在oracle的login表中插入数据\"); &amp;#125; @Override public Login getLogin(int id) &amp;#123; System.out.println(\"oracle的Login表中根据\" + id + \"获取数据\"); return null; &amp;#125; &amp;#125; 定义一个抽象类 package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public abstract class AbstractFactory &amp;#123; public abstract IUserService createUser(); public abstract ILoginService createLogin(); &amp;#125; 有两个基于抽象类的两个实现类 package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public class MysqlFactory extends AbstractFactory &amp;#123; @Override public IUserService createUser() &amp;#123; return new MysqlUserServiceImpl(); &amp;#125; @Override public ILoginService createLogin() &amp;#123; return new MysqlLoginServiceImpl(); &amp;#125; &amp;#125; package com.formula.design.abstractfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public class OracleFactory extends AbstractFactory &amp;#123; @Override public IUserService createUser() &amp;#123; return new OraclelUserServiceImpl(); &amp;#125; @Override public ILoginService createLogin() &amp;#123; return new OracleLoginServiceImpl(); &amp;#125; &amp;#125; 测试方法 package com.formula.design.abstractfactory; import java.util.Date; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/8 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; User user = User.builder().id(1).name(\"张三\").build(); Login login = Login.builder().date(new Date()).id(1).build(); AbstractFactory abstractFactory = new MysqlFactory(); IUserService userService = abstractFactory.createUser(); userService.insert(user); userService.getUser(1); ILoginService loginService = abstractFactory.createLogin(); loginService.insert(login); loginService.getLogin(1); &amp;#125; &amp;#125; 结果 往mysql的user中保存信息 在mysql的user中根据1获取数据 在Mysql的Login 插入一条数据 在Mysql的Login表中获取一条数据 这里只需要将 AbstractFactory abstractFactory = new OracleFactory(); 就可以完成对数据源的切换了","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之建造者模式(5)","slug":"设计模式/设计模式之建造者模式(5)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-jian-zao-zhe-mo-shi-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-jian-zao-zhe-mo-shi-5/","excerpt":"","text":"5. 设计模式之建造者模式(Builder Pattren) 1. 概念&nbsp;&nbsp;Builder 模式也叫建造者模式或者生成器模式.&nbsp;&nbsp;Builder 模式是一种对象创建型模式之一,用来隐藏复合对象的创建过程,它把复合对象的创建过程加以抽象,通过子类继承或者重载的方式,动态的创建具有复合属性的对象 2. 模式中包含的角色及其指责 产品角色(Product):一个具体的产品对象 抽象建造者(Builder):创建一个Product对象的各个部件指定的抽象接口 具体建造者(ConcreateBuilder):实现抽象接口,构建和装配各个部件 指挥者(Director):构建一个使用Builder接口的对象,它主要是用于创建一个复杂的对象.它主要有两个作用: 一是:隔离了客户与对象的生产过程 二是:负责控制产品对象的生成过程3. 应用场景 对象的创建:Builder模式是为对象的创建而设定的模式 创建的是一个复合的对象:被创建的对象为一个具有复合属性的复合对象 关注对象创建的各部分的创建过程:不同的工厂(这里指builder生成器)对产品属性有不同的创建方法4. 代码产品对象```javapackage com.formula.design.builder; /** @author:luyanan @email:&#108;&#x75;&#x79;&#x61;&#x6e;&#x61;&#110;&#48;&#55;&#x31;&#56;&#64;&#49;&#54;&#51;&#46;&#x63;&#111;&#x6d; @date 2019/1/14 @introduce 定义一个产品(Product) */public class Room { /** * 墙壁 */ private String wall; /** * 地板 */ private String floor; /** * 屋顶 */ private String roof; public String getWall() &#123; return wall; &#125; public void setWall(String wall) &#123; this.wall = wall; &#125; public String getFloor() &#123; return floor; &#125; public void setFloor(String floor) &#123; this.floor = floor; &#125; public String getRoof() &#123; return roof; &#125; public void setRoof(String roof) &#123; this.roof = roof; &#125; @Override public String toString() &#123; return &quot;Room&#123;&quot; + &quot;wall=&#39;&quot; + wall + &#39;\\&#39;&#39; + &quot;, floor=&#39;&quot; + floor + &#39;\\&#39;&#39; + &quot;, roof=&#39;&quot; + roof + &#39;\\&#39;&#39; + &#39;&#125;&#39;; &#125; } 抽象建造者 ```java package com.formula.design.builder; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/14 * @introduce 抽象的建造者 **/ public interface Builder &#123; /** * 建造墙壁 */ void makeWall(); /** * 建造地板 */ void makeFloor(); /** * 建造屋顶 */ void makeRoof(); /** * 返回产品对象 * * @return */ public Room getRoom(); &#125; 具体建造者 package com.formula.design.builder; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/14 * @introduce 平房 * 具体建造者 **/ public class BungalowRoomBuilder implements Builder &amp;#123; private Room room = new Room(); @Override public void makeWall() &amp;#123; room.setWall(\"平房-->墙壁\"); &amp;#125; @Override public void makeFloor() &amp;#123; room.setFloor(\"平房-->地板\"); &amp;#125; @Override public void makeRoof() &amp;#123; room.setRoof(\"平房-->屋顶\"); &amp;#125; @Override public Room getRoom() &amp;#123; return room; &amp;#125; &amp;#125; 指挥者 package com.formula.design.builder; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/14 * @introduce 指挥者 **/ public class Director &amp;#123; public Room createRoom(Builder builder) &amp;#123; builder.makeFloor(); builder.makeWall(); builder.makeRoof(); return builder.getRoom(); &amp;#125; &amp;#125; 测试类 package com.formula.design.builder; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/14 * @introduce **/ public class MailClass &amp;#123; public static void main(String[] args) &amp;#123; Director director = new Director(); Room room = director.createRoom(new BungalowRoomBuilder()); System.out.println(room); &amp;#125; &amp;#125; 结果 Room&amp;#123;wall='平房-->墙壁', floor='平房-->地板', roof='平房-->屋顶'&amp;#125; 5.通过静态内部类等方式实现零件的构建package com.formula.design.builder; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/14 * @introduce 定义一个产品(Product) **/ public class Room &amp;#123; /** * 墙壁 */ private String wall; /** * 地板 */ private String floor; /** * 屋顶 */ private String roof; public String getWall() &amp;#123; return wall; &amp;#125; public void setWall(String wall) &amp;#123; this.wall = wall; &amp;#125; public String getFloor() &amp;#123; return floor; &amp;#125; public void setFloor(String floor) &amp;#123; this.floor = floor; &amp;#125; public String getRoof() &amp;#123; return roof; &amp;#125; public void setRoof(String roof) &amp;#123; this.roof = roof; &amp;#125; @Override public String toString() &amp;#123; return \"Room&amp;#123;\" + \"wall='\" + wall + '\\'' + \", floor='\" + floor + '\\'' + \", roof='\" + roof + '\\'' + '&amp;#125;'; &amp;#125; public Room(String wall, String floor, String roof) &amp;#123; this.wall = wall; this.floor = floor; this.roof = roof; &amp;#125; public Room() &amp;#123; &amp;#125; public static RoomBuilder builder() &amp;#123; return new RoomBuilder(); &amp;#125; public static class RoomBuilder &amp;#123; /** * 墙壁 */ private String wall; /** * 地板 */ private String floor; /** * 屋顶 */ private String roof; public RoomBuilder setWall(String wall) &amp;#123; this.wall = wall; return this; &amp;#125; public RoomBuilder setFloor(String floor) &amp;#123; this.floor = floor; return this; &amp;#125; public RoomBuilder setRoof(String roof) &amp;#123; this.roof = roof; return this; &amp;#125; public Room build() &amp;#123; return new Room(this.wall, this.floor, this.roof); &amp;#125; &amp;#125; &amp;#125; 测试方法 package com.formula.design.builder; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/14 * @introduce **/ public class MailClass &amp;#123; public static void main(String[] args) &amp;#123; Director director = new Director(); Room room = director.createRoom(new BungalowRoomBuilder()); System.out.println(\"平房----\" + room); Room villaRoom = Room .builder() .setFloor(\"别墅-->地板\") .setWall(\"别墅-->墙壁\") .setRoof(\"别墅-->屋顶\").build(); System.out.println(\"别墅----\" + villaRoom); &amp;#125; &amp;#125; 结果 平房----Room&amp;#123;wall='平房-->墙壁', floor='平房-->地板', roof='平房-->屋顶'&amp;#125; 别墅----Room&amp;#123;wall='别墅-->墙壁', floor='别墅-->地板', roof='别墅-->屋顶'&amp;#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之工厂方法模式(2)","slug":"设计模式/设计模式之工厂方法模式(2)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-gong-han-fang-fa-mo-shi-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-gong-han-fang-fa-mo-shi-2/","excerpt":"","text":"2. 设计模式之工厂方法模式 1. 概念 工厂方法模式同样属于类的创建型模式 又被成为多态工厂模式. 工厂方法模式的意义是定义一个创建产品对象的工厂接口,将实际创建工作推迟到子类当中.核心工厂类不再负责产品的创建,这样核心类成为一个抽象工厂角色,仅负责具体工厂子类必须实现的接口,这样进一步抽象化的好处是使得工厂方法模式可以使系统在不修改具体工厂角色的情况下引进新的产品 2. 模式中包含的角色及其职责 2.1 抽象工厂角色 工厂方法模式的核心,任何工厂类都必须实现这个接口 2.2 具体工厂角色 具体工厂类是抽象工厂的一个实现,负责实例化产品对象 2.3 抽象产品角色 工厂方模式所创建的所有对象的父类,它负责描述所产品所共有的公共接口 2.4 具体产品角色 工厂方法模式所创建的具体对象 3. 工厂方法模式和简单工厂模式的比较 工厂方法模式和简单工厂模式在结构上的不同不是很明显.工厂方法类的核心是一个抽象工厂类,而简单工厂模式是把核心放在一个具体的类上 工厂方法模式之所有有一个别名叫多态性工厂模式是因为具体工厂类都有公共的接口,或者有共同的接口 当系统扩展需要添加新的产品对象的时候,仅仅需要添加一个具体对象以及一个具体工厂对象,原有工厂对象不需要进行任何修改,也不需要修改客户端,很好的符合了”开放-封闭的”的原则,而简单工厂模式在添加新的产品对象后不得不修改工厂方法,扩展性不好4. 应用场景 一个类不知道它锁需要的对象的类:在工厂方法模式中,客户端不需要知道具体产品类的类名,只需要知道锁对应的工厂即可,具体的产品对象由具体的工厂类创建,客户端需要知道创建具体产品的工厂类. 一个类通过其子类来指定创建哪个对象:在工厂方法模式中,对于抽象工厂类,只需要提供一个创建产品的接口,而由子类来确定具体要创建的对象.5. 优缺点5.1 优点: 在工厂方法模式中,工厂方法用来创建客户所需要的产品,同时还向客户隐藏了哪种具体差您类将被实例化这一细节,用户只需要关心所需产品对应的工厂,无需关系创建细节,甚至无须只要具体产品类的类名. 在系统中加入新的产品时候,无需修改抽象工厂和抽象产品提供的接口,无需修改客户端,也无须修改其他的具体工厂和具体产品,只需要添加一个具体工厂和具体产品就可以,这样系统的可扩展性就变得非常好,符合开闭原则.5.2 缺点: 添加新的产品需要添加对应的产品类和工厂类,系统中类的个数会成对增加,一定程序上增加了系统的复杂性.6. 代码抽象产品角色```javapackage com.formula.design.methodfactory; /** @author:luyanan @email:&#108;&#x75;&#x79;&#x61;&#x6e;&#97;&#x6e;&#x30;&#x37;&#x31;&#56;&#64;&#49;&#54;&#x33;&#46;&#99;&#111;&#109; @date 2019/1/7 @introduce */public interface Fruit { /** * 采集方法 */ void collect(); } 定义具体产品角色 ```java package com.formula.design.methodfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce 苹果 **/ public class Apple implements Fruit &#123; @Override public void collect() &#123; System.out.println(&quot;苹果采集........&quot;); &#125; &#125; package com.formula.design.methodfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce 香蕉 **/ public class Banana implements Fruit &amp;#123; @Override public void collect() &amp;#123; System.out.println(\"香蕉的采集.......\"); &amp;#125; &amp;#125; 定义抽象工厂角色 package com.formula.design.methodfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/10 * @introduce **/ public interface FruitFactroy &amp;#123; Fruit getFruit(); &amp;#125; 定义具体工厂角色 package com.formula.design.methodfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/10 * @introduce **/ public class AppleFactory implements FruitFactroy &amp;#123; @Override public Fruit getFruit() &amp;#123; return new Apple(); &amp;#125; &amp;#125; package com.formula.design.methodfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/10 * @introduce **/ public class BananFactory implements FruitFactroy &amp;#123; @Override public Fruit getFruit() &amp;#123; return new Banana(); &amp;#125; &amp;#125; 主启动类 package com.formula.design.methodfactory; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/7 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; FruitFactroy appleFactory = new AppleFactory(); Fruit apple = appleFactory.getFruit(); apple.collect(); FruitFactroy bananFactory = new BananFactory(); Fruit bannan = bananFactory.getFruit(); bannan.collect(); &amp;#125; &amp;#125; 结果 苹果采集........ 香蕉的采集.......","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之委派模式(27)","slug":"设计模式/设计模式之委派模式(27)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-wei-pai-mo-shi-27/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-wei-pai-mo-shi-27/","excerpt":"","text":"27. 设计模式之委派模式(Delegate Pattern) 1. 概念委派模式不属于GOP23种设计模式中,委派模式是基本作呕也能够就是负责任务的调用和分配任务,跟代理模式很像,可以看作是一种特殊情况下的静态代理的全权代理,但是代理模式注重过程,而委派模式注重结果. 2. 角色和指责 客户端 委派者 被委派者3. 源码员工接口```javapackage com.notes.pattern.delegate; /** @author:luyanan @email:&#x6c;&#x75;&#x79;&#x61;&#110;&#97;&#x6e;&#x30;&#55;&#49;&#56;&#x40;&#49;&#54;&#x33;&#46;&#99;&#x6f;&#x6d; @date 2019/4/17 @introduce 员工接口 */public interface IEmployee { void doing(String command); } 员工A ```java package com.notes.pattern.delegate; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce 员工A **/ public class EmployeeA implements IEmployee &#123; @Override public void doing(String command) &#123; System.out.println(&quot;我是员工A，我现在开始干&quot; + command); &#125; &#125; 员工B package com.notes.pattern.delegate; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce 员工B **/ public class EmployeeB implements IEmployee &amp;#123; @Override public void doing(String command) &amp;#123; System.out.println(\"我是员工B，现在开始干\" + command); &amp;#125; &amp;#125; 项目经理 package com.notes.pattern.delegate; import java.util.HashMap; import java.util.Map; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce 项目经理 **/ public class Leader implements IEmployee &amp;#123; private Map&lt;String, IEmployee> map = new HashMap&lt;>(); public Leader() &amp;#123; map.put(\"加密\", new EmployeeA()); map.put(\"登录\", new EmployeeB()); &amp;#125; @Override public void doing(String command) &amp;#123; map.get(command).doing(command); &amp;#125; &amp;#125; BOSS package com.notes.pattern.delegate; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce BOSS **/ public class Boss &amp;#123; /** * 领导下达任务 * * @param command * @param leader */ public void doing(String command, Leader leader) &amp;#123; leader.doing(command); &amp;#125; &amp;#125; 测试类 package com.notes.pattern.delegate; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/4/17 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; Boss boss = new Boss(); boss.doing(\"加密\",new Leader()); boss.doing(\"登录\",new Leader()); &amp;#125; &amp;#125; 测试结果 我是员工A，我现在开始干加密 我是员工B，现在开始干登录 4. 优缺对内隐藏实现,易与扩展,简化调用","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"设计模式之外观模式(12)","slug":"设计模式/设计模式之外观模式(12)","date":"2022-01-04T02:42:07.297Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-wai-guan-mo-shi-12/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/she-ji-mo-shi/she-ji-mo-shi-zhi-wai-guan-mo-shi-12/","excerpt":"","text":"12. 设计模式之外观模式(Facade Pattern) 1. 概念Facade 模式也叫外观模式,是为一组具有类似功能的类群,比如类,子系统等.提供一个一致的简单界面.这个一致的简单的界面被称为Facade 2. 角色和职责: Facade:为调用方定义简单的调用接口 Clients:通过Facade 接口调用提供某功能的内部类群 Packages:功能提供者,指提供功能的类群(模块或者子系统)3. 优缺点3.1 优点: 对客户端屏蔽了子系统组件,减少了客户端所需处理的对象数目,并使得子系统使用起来更加容易.通过引入外观模式,客户端代码将变得简单,与之关联的对象也很少 它实现了子系统与客户端之间的松耦合关系 ,这使得子系统的变化不会影响到调用他的客户端,只需要调整外观类即可. 一个子系统的修改对其他子系统没有任何影响,而且子系统内部变化也不会影响到外观模式.3.2 缺点: 不能很好的限制客户端使用子系统类,如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性. 如果设计不当,增加新的子系统可能需要修改外观类的源代码,违背了开闭原则4. 使用场景 当要为访问子系列复杂的子系统提供一个简单入口的时候可以使用外观模式 客户端程序与多个子系统之间存在很大的依赖性.引入外观类可以将子系统和客户端解耦,从而提高子系统的独立性和可移植性 在层次化结构中,可以使用外观模式定义系统每一层的入口,层与层之间不直接产生联系,而是通过外观类建立联系,降低层之间的耦合度5. 代码现有三个子系统```javapackage com.formula.design.facade; /** @author:luyanan @email:&#108;&#x75;&#121;&#97;&#x6e;&#x61;&#110;&#x30;&#55;&#49;&#x38;&#x40;&#x31;&#54;&#51;&#x2e;&#99;&#x6f;&#x6d; @date 2019/1/24 @introduce A 系统 */public class SystemA { public void doSomething() &#123; System.out.println(&quot;调用A系统的方法&quot;); &#125; } ```java package com.formula.design.facade; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/24 * @introduce **/ public class SystemB &#123; public void doSomething() &#123; System.out.println(&quot;调用B系统的方法&quot;); &#125; &#125; package com.formula.design.facade; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/24 * @introduce **/ public class SystemC &amp;#123; public void doSomething() &amp;#123; System.out.println(\"调用C系统的一些方法\"); &amp;#125; &amp;#125; 外观类 package com.formula.design.facade; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/24 * @introduce **/ public class Facade &amp;#123; private SystemA systemA; private SystemB systemB; private SystemC systemC; public Facade() &amp;#123; systemA = new SystemA(); systemB = new SystemB(); systemC = new SystemC(); &amp;#125; public void doSomething() &amp;#123; systemA.doSomething(); systemB.doSomething(); systemC.doSomething(); &amp;#125; &amp;#125; 测试类 package com.formula.design.facade; /** * @author:luyanan * @email:luyanan0718@163.com * @date 2019/1/24 * @introduce **/ public class MainClass &amp;#123; public static void main(String[] args) &amp;#123; //不使用外观模式,调用SystemA,SystemB,SystemC的方法 SystemA systemA = new SystemA(); systemA.doSomething(); SystemB systemB = new SystemB(); systemB.doSomething(); SystemC systemC = new SystemC(); systemC.doSomething(); System.out.println(\"-------------------------------\"); //调用外观模式 Facade facade = new Facade(); facade.doSomething(); &amp;#125; &amp;#125; 结果 调用A系统的方法 调用B系统的方法 调用C系统的一些方法 ------------------------------- 调用A系统的方法 调用B系统的方法 调用C系统的一些方法","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"Mysql主从复制(4)","slug":"数据库/Mysql主从复制(4)","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/shu-ju-ku/mysql-zhu-cong-fu-zhi-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/shu-ju-ku/mysql-zhu-cong-fu-zhi-4/","excerpt":"","text":"Mysql主从复制1. 主从复制的含义在Mysql多服务区的架构中, 至少要有一个主节点(master),跟主节点相对的, 我们把他叫做从节点(slave). 主从复制, 就是把主节点的数据复制到一个或者多个从节点. 主服务器和从服务器可以在不同的ip上, 通过远程连接来同步数据, 这个是异步的过程. 2. 主从复制的形式一主一从/一主多从 多主一从 双主复制 级联复制 3. 主从复制的用途 数据备份: 把数据复制到不同的机器上, 以免单台服务器发生故障时数据丢失 读写分离: 让主库负责写, 从库负责读, 从而提高读写的并发度. 高可用HA: 当节点故障的时候, 自动转移到其他节点, 提高可用性. 扩展: 结合负载的机制, 均摊所有的应用访问请求, 降低单机IO 那么主从复制是怎么实现的呢? 4. binlog客户端对Mysql 数据库进行操作的时候, 包括DDL 和DML 语句, 服务端会在日志文件中用事件的形式记录所有的操作记录, 这个文件就是binlog 文件(属于逻辑日志,跟redis 的AOF 文件类似) 基于binlog, 我们可以实现主从复制和数据恢复 binlog 默认是不开启的, 需要在服务端手动配置, 而且会有一定的性能损耗. 4.1 binlog配置编辑/etc/my.cnf log-bin=/var/lib/mysql/mysql-bin server-id=1 重启Mysql服务 service mysqld stop service mysqld start ## 如果出错查看日志 vi /var/log/mysqld.log cd /var/lib/mysql 是否开启binlog show variables like 'log_bin%'; 4.2 binlog 格式STATEMENT: 记录每一条修改数据的SQL语句(减少日志量,节约IO) ROW: 记录哪条数据被修改了, 修改成什么样子了(5.7以后默认) MIXED: 结合两种方式, 一般的语句用STATEMENT, 函数之类的用ROW 查看binlog格式 show global variables like '%binlog_format%'; 查看binlog 列表 show binary logs; 查看binlog内容 show binlog events in 'mysql-bin.000001'; 用mysqlbinlog 工具, 基于时间查看binlog(注意这个是linux命令, 不是sql) /usr/bin/mysqlbinlog --start-datetime='2019-08-22 13:30:00' --stop-datetime='2019-08-22 14:01:01' -d gupao /var/lib/mysql/mysql-bin.000001 5.主从 复制的原理5.1 主从复制的配置 主库开启binlog,设置server-id 在主库创建具有复制权限的用户, 允许从库连接 GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'repl'@'192.168.8.147' IDENTIFIED BY '123456'; FLUSH PRIVILEGES; 从库/etc/my.cnf 配置, 重启数据库 server-id=2 log-bin=mysql-bin relay-log=mysql-relay-bin read-only=1 log-slave-updates=1 ​ log-slave-updates 决定了在从binlog读取数据的时候,是否记录binlog,实现双主和级联的关键 在从库执行 stop slave; change master to master_host='192.168.8.146',master_user='repl',master_password='123456',master_log_file='mysql-bin.000001', master_log_pos=4; start slave; 查看同步状态 SHOW SLAVE STATUS \\G 以下为正常 5.2 主从复制的原理 slave 服务器执行start slave , 开启主从复制开关, slave 服务器的IO线程请求从master 服务器读取binlog（如果该线程追赶上了主库, 会进入睡眠状态） master 服务器创建Log Dump线程, 把binlog 发送给slave服务器.slave服务器将读取到的binlog 日志内容写入到中继日志relay log (会记录位置信息,以便下次继续读取) slave 服务器的SQL线程会实时监测relay log 中新增的日志,把relay log 解析成SQL语句,并执行.","categories":[{"name":"数据库","slug":"数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库","slug":"数据库/数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"Zookeeper以及集群的安装","slug":"微服务/zookpeer/Zookeeper以及集群的安装","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/zookeeper-yi-ji-ji-qun-de-an-zhuang/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/zookeeper-yi-ji-ji-qun-de-an-zhuang/","excerpt":"","text":"Zookeeper单机和集群的安装1. 安装 zookeeper1. 下载通过下面地址可以下载zookeeper http://apache.fayea.com/zookeeper/ 我们先建一个zk 目录, 使用 wget http://apache.fayea.com/zookeeper/zookeeper-3.5.5/apache-zookeeper-3.5.5-bin.tar.gz 下载zookeepe 解压 tar -zxvf apache-zookeeper-3.5.6.tar.gz 解压进目录后就看到 3. 常见命令1. 启动ZK服务 bin/zkServer.sh start 2. 查看ZK 服务状态 bin/zkServer.sh status 3. 停止ZK 服务 bin/zkServer.sh stop 4. 重启ZK 服务 bin/zkServer.sh restart 5. 连接服务器 zkCli.sh -timeout 0 -r -server ip:port 单机版安装一般情况下,在开发测试环境中, 没有那么多资源的情况下, 而且也不需要特别好的稳定性的前提下, 我们可以使用单机部署. 初次使用zookeeper,需要将conf 目录下的 zoo_sample.cfg 文件copy 一份重命名为zoo.cfg,修改 datasDir 目录, dataDir 表示日志文件存放的路径 进入conf 目录 cp zoo_sample.cfg zoo.cfg 进入bin 目录下, 执行上面的命令 sh zkServer.sh start 启动 集群安装单ip 部署集群修改配置文件, 拷贝多份zookeeper程序, 例如设置三个server, 分别为 apache-zookeeper-3.5.5-bin,apache-zookeeper-3.5.5-bin_2,apache-zookeeper-3.5.5-bin_3 ,每个目录下存放一份zookeeper, 并 修改各自配置文件如下:apache-zookeeper-3.5.5-bin The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. dataDir=/web/zk/apache-zookeeper-3.5.5-bin # the port at which the clients will connect clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \"0\" to disable auto purge feature #autopurge.purgeInterval=1 server.1=192.168.91.128:2888:3888 server.2=192.168.91.128:2889:3889 server.3=192.168.91.128:2890:3890 apache-zookeeper-3.5.5-bin_2 The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. dataDir=/web/zk/apache-zookeeper-3.5.5-bin_2 # the port at which the clients will connect clientPort=2182 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \"0\" to disable auto purge feature #autopurge.purgeInterval=1 server.1=192.168.91.128:2888:3888 server.2=192.168.91.128:2889:3889 server.3=192.168.91.128:2890:3890 apache-zookeeper-3.5.5-bin_3 The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. dataDir=/web/zk/apache-zookeeper-3.5.5-bin_3 # the port at which the clients will connect clientPort=2183 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \"0\" to disable auto purge feature #autopurge.purgeInterval=1 server.1=192.168.91.128:2888:3888 server.2=192.168.91.128:2889:3889 server.3=192.168.91.128:2890:3890 注意: 同一ip上搭建多个节点的集群的时候, 必须注意端口号的问题，端口必须不一致才行. 创建多个节点集群时, 在dataDir 目录下必须创建myid文件, myid 文件用于zookeeper 验证server序列等. myid 只有一行, 并且为当前server 的序号. 例如 server.1 的myid 就是1, server.2 的myid 就是2. 多ip 集群我们这里准备三台服务器准备集群的安装 192.168.91.128 192.168.91.129 192.168.91.130 在zookeeper 集群中, 各个节点总共有三个角色,分别是leader，follower,observer.集群模式我们采用模拟3台机器来搭建zookeeper 集群. 分别复制安装包到三台机器上并解压, 同时copy 一份 zoo.cfg. 修改配置文件 修改端口 server.1=IP1:2888:3888 server.2=IP1:2888:3888 server.3=IP1:2888:3888 2888:访问zookeeper的端口; 3888 : 重新选举leader 的端口 server.A= B :C :D 其中: ​ A 是一个数字, 表示这个是第几号服务器 ​ B 是这个服务器的ip 地址 ​ C 表示是这个服务器与集群中的Leader 服务器交换信息的端口 ​ D 表示的是万一集群中的Leader 服务器挂了, 需要一个端口来重新进行选举, 选出一个新的Leader. ​ 而这个端口就是用来执行选举时服务器相互通信的端口, 如果是伪集群的配置方式, 由于B 都是一样的. 所以不同的Zookeeper 实例通信端口号不能一样, 所以要给他们分配不同的端口号. 在集群模式下, 集群中每台机器都需要感知到整个集群中是由哪几台机器组成, 在配置文件中, 按照格式server.id = host:port:port, 每一行代表一个机器配置, id: 指的是server ID，用来标识该机器在集群中的机器序号. 新建datadir 目录, 设置 myid 在每台zookeeper 机器上, 我们都需要在数据目录(dataDir)下创建一个myid, 该文件只有一行内容, 对应每台机器的server ID 数字. 比如server.1的myid 文件内容就是1. [必须确保每个服务器的myid 文件中的数字是不同的, 并且和自己所在机器的zoo.cfg 中 server.id 的id 值是一致的, id 的范围是 1到255] 启动zookeeper 启动自个服务器目录下的zookeeper就行了. 连接可以使用以下命令连接一个zk集群 bin/zkCli.sh -server 192.168.229.160:2181,192.168.229.161:2181,192.168.229.162:2181 如图则显示连接成功 从日志输入上来看, 客户端连接的进程是随机分配的.","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://rainsoil.github.io/tags/zookeeper/"}]},{"title":"分布式协调服务的zookeeper应用实战","slug":"微服务/zookpeer/分布式协调服务的zookeeper应用实战","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/fen-bu-shi-xie-diao-fu-wu-de-zookeeper-ying-yong-shi-zhan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/fen-bu-shi-xie-diao-fu-wu-de-zookeeper-ying-yong-shi-zhan/","excerpt":"","text":"分布式协调服务的zookeeper应用实战集群角色 数据模型zookeeper的视图结构和标准的文件系统非常类似, 每一个节点称之为ZNode, 是zookeeper的最小单元. 每个znode 上都可以保存数据以及挂载子节点. 构成一个层次化树形结构. 持久节点( PERSISTENT )创建后会一直存在zookeeper服务器上, 直到主动删除 持久有序节点( PERSISTENT_SEQUENTIAL )每个节点都会为它的一级子节点维护一个顺序 临时节点( EPHEMERAL )临时节点的声明周期和客户端的会话绑定在一起, 当客户端会话失效则该节点自动清理 临时有序节点( EPHEMERAL )在临时节点的基础上多了一个顺序性. CONTAINER 当子节点都被删除后, CONTAINER 也随即删除, PERSISTENT_WITH_TTL 超过TTL 未被删除,且没有子节点 PERSISTENT_SEQUENTIAL_WITH_TTL 客户端断开连接后不会主动删除Znode, 如果该Znode 没有子Znode 且在给定的TTL 时间无修改, 该Znode 将会被删除;TTL 单位是毫秒, 必须大于0 且小于或等于 EphemeralType.MAX_TTL 会话 Client 初始化连接, 状态转为 CONNECTING ( ① ) Client 与Server 成功建立连接, 状态改为 CONNECTED(②) Client 丢失了与Server 的连接或者没有接收到Server 的响应, 状态改为 CONNECTING(③) Client 连上另外的Server 或连接上了之前的Server, 状态改为 CONNECTED(②) 若会话过期(是Server 负责声明会话过期, 而不是Client),状态改为 CLOSED(⑤)， Client 也可以主动关闭会话 (④)， 状态转为 CLOSED stat 状态信息每个节点除了存储数据内容以外,还存储了数据节点本身的一些状态信息, 通过get命令可以获取状态信息的详细内容. 版本-保证分布式数据原子性zookeeper为数据节点引入了版本的概念, 每个数据节点都有三类版本信息, 对数据节点任何更新操作都会引起版本号的变化. 版本有点和我们经常使用的乐观锁类似. 这里有两个概念说一下，一个是悲观锁, 一个是乐观锁. 悲观锁:是数据库中一种非常典型且非常严格的并发控制策略. 假如一个事务A 正在对数据进行处理, 那么在整个处理过程中, 都会将数据处于锁定状态, 在这期间其他事务无法对数据进行更新操作 . 乐观锁乐观锁和悲观锁正好相反, 它假定多个事务在处理过程中不会彼此影响, 因此在事务处理过程中不需要进行加锁处理, 如果多个事务对同一数据做更改, 那么在更新请求提交之前,每个事务都会首先检查当前事务读取事务后,是否有其他事务对数据进行了修改. 如果有修改, 则回滚事务再回到zookeeper. version 属性就是用来实现乐观锁机制的”写入校验”的. Watcher 机制zookeeper 提供了分布式数据的发布/订阅功能,zookeeper 允许客户端向服务端注册一个watcher 监听, 当服务端的一些指定事件触发了watcher, 那么服务器就会向客户端发送一个事件通知. 值得注意的是, watcher 通知是一次性的,即一旦触发一次通知后,该watcher 就失效了, 因此客户端需要反复注册Wacher,即程序中在process 里面又注册了watcher , 否则, 将无法获取c3节点的创建而导致子节点变化的事件. zookeeper 基于Java 访问针对zookeeper, 比较常用的java 客户端有 zkclient、curator. 由于curator 对于zookeeper 的抽象层次比较高, 简化了zookeeper 客户端的开发量. 使得curator 逐步被广泛使用. 封装了 zookeeper client 与 zookeeper server 之间的连接处理. 提供了一套 fluent 风格的操作API. 提供了 zookeeper的各种应用场景(共享锁、leader 选举)的抽象封装. 依赖jar &lt;!-- zookeeper的jar--> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-framework&lt;/artifactId> &lt;version>4.0.0&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-recipes&lt;/artifactId> &lt;version>4.0.0&lt;/version> &lt;/dependency> 建立连接 CuratorFramework framework = CuratorFrameworkFactory .builder() // 连接信息 .connectString(connect) // 会话超时时间 .sessionTimeoutMs(5000) //失败重试机制 //ExponentialBackoffRetry //RetryOneTime 仅仅只重试一次 //RetryUntilElapsed //RetryNTimes .retryPolicy(new ExponentialBackoffRetry(1000, 3)) .build(); 重试策略:Curator 内部实现的几种重试策略: ExponentialBackoffRetry : 重试指定的次数, 且每一次重试之后停顿的时间逐渐增加. RetryNTimes : 指定最大重试次数的重试策略. RetryOneTime : 仅重试一次. RetryUntilElapsed : 一直重试直到达到规定的时间. namespace值得注意的是 session2 会话含有隔离命名空间, 即客户端对zookeeper 上数据节点 的任何操作都是相对/curator 目录进行的, 这有利于实现不同的zookeeper 的业务之间的隔离. 节点的增删改查 public static void main(String[] args) throws Exception &amp;#123; String connect = \"192.168.13.102:2181,192.168.13.103:2181,192.168.13.104:2181\"; String path = \"/data/program\"; String value = \"test\"; // 获取连接 CuratorFramework framework = createClient(connect); // 创建数据节点 createData(framework, path, value); System.out.println(\"创建的\" + path + \"节点,数据为:\" + getData(framework, path)); // 修改节点 updateData(framework, path, \"newTest\"); System.out.println(\"修改的\" + path + \"节点,数据为:\" + getData(framework, path)); // 删除节点 deleteData(framework, path); &amp;#125; /** * &lt;p>删除节点&lt;/p> * * @param framework * @param nodePath * @return &amp;#123;@link &amp;#125; * @author luyanan * @since 2019/11/6 */ public static void deleteData(CuratorFramework framework, String nodePath) throws Exception &amp;#123; Stat stat = new Stat(); String value = new String(framework.getData().storingStatIn(stat).forPath(nodePath)); framework.delete().withVersion(stat.getAversion()).forPath(nodePath); &amp;#125; /** * &lt;p>修改节点&lt;/p> * * @param framework * @param nodePath 节点 * @param value 新的值 * @return &amp;#123;@link &amp;#125; * @author luyanan * @since 2019/11/6 */ public static void updateData(CuratorFramework framework, String nodePath, String value) throws Exception &amp;#123; framework.setData().forPath(nodePath, value.getBytes()); &amp;#125; /** * &lt;p>查询节点&lt;/p> * * @param nodePath * @return &amp;#123;@link String&amp;#125; * @author luyanan * @since 2019/11/6 */ public static String getData(CuratorFramework framework, String nodePath) throws Exception &amp;#123; return new String(framework.getData().forPath(nodePath)); &amp;#125; /** * &lt;p>创建节点&lt;/p> * * @param framework * @return &amp;#123;@link &amp;#125; * @author luyanan * @since 2019/11/6 */ public static void createData(CuratorFramework framework, String nodePath, String value) throws Exception &amp;#123; framework .create() //如果没有父节点则创建 .creatingParentsIfNeeded() // 节点类型 .withMode(CreateMode.PERSISTENT) .forPath(nodePath, value.getBytes()); &amp;#125; public static CuratorFramework createClient(String connect) &amp;#123; CuratorFramework framework = CuratorFrameworkFactory .builder() // 连接信息 .connectString(connect) // 会话超时时间 .sessionTimeoutMs(5000) //失败重试机制 //ExponentialBackoffRetry //RetryOneTime 仅仅只重试一次 //RetryUntilElapsed //RetryNTimes .retryPolicy(new ExponentialBackoffRetry(1000, 3)) .build(); return framework; &amp;#125; 节点权限设置zookeeper 作为一个分布式协调框架, 内部存储了一些分布式系统运行时的状态的数据, 比如master 选举、比如分布式锁. 对这些数据的操作会直接影响到分布式系统的运行状态。 因此, 为了保证zookeeper 中的数据的安全性, 避免误操作带来的影响. zookeeper 提供了一套ACL 权限控制机制来保证数据的安全. 权限控制的案例演示给节点赋权 // 给节点赋权 List&lt;ACL> aclList = new ArrayList&lt;>(); Id id1 = new Id(\"digest\", DigestAuthenticationProvider.generateDigest(\"u1:uu\")); Id id2 = new Id(\"digest\", DigestAuthenticationProvider.generateDigest(\"u2:uu\")); // u1 有所有的权限 aclList.add(new ACL(ZooDefs.Perms.ALL, id1)); // u2 有读和删除的权限 aclList.add(new ACL(ZooDefs.Perms.READ | ZooDefs.Perms.DELETE, id2)); framework.create().withACL(aclList).forPath(\"/data\"); framework.create().withACL(ZooDefs.Ids.CREATOR_ALL_ACL).forPath(\"/data\"); 访问授权的节点 String connect = \"192.168.13.102:2181,192.168.13.103:2181,192.168.13.104:2181\"; CuratorFramework framework = CuratorFrameworkFactory.builder() .connectString(connect) // 带着用户信息创建连接 .authorization(\"digest\",\"admin:admin\".getBytes()) .retryPolicy(new ExponentialBackoffRetry(1000, 3)) .namespace(\"curator\") .build(); 修改已经存在节点的权限// 修改已经存在节点的权限 framework.setACL().withACL(aclList).forPath(\"/data\"); 权限模式 权限模式分为 Schema 和授权对象, 比如 IP地址、username:passwrod,用来确定权限验证过程中使用的验证策略 IP : 通过ip 地址粒度来进行权限控制, 例如配置 [ip:192.168.0.1],或者按照网段 [ip:192.168.0.1/24] Digest : 最常见的控制模式, 类似于 username:password, 设置的时候需要 DigestAuthenticationProvider.generateDigest() SHA- 加 密 和 base64 编码 World : 最开放的控制模式, 这种权限控制几乎没有任何作用, 数据的访问权限对所有用户开发, world:anyone Super: 超级用户, 可以对节点做任何操作. 授权对象指权限赋予的用户或者一个指定的实体, 不同的权限模式下，授权对象不同. Id ipId1 = new Id(“ip”, “192.168.190.1”); Id ANYONE_ID_UNSAFE = new Id(“world”, “anyone”); 权限指通过权限检查后的可以被允许的操作, create/delete/read/write/admin create: 允许对子节点create 操作. read: 允许对本节点getCliendren 和getData 操作. write : 允许对本节点setData 操作. delete : 允许对子节点 delete 操作. admin: 允许对本节点 setAcl 操作. 节点事件监听Watcher 监听机制是Zookeeper 中非常重要的特性, 我们基于zookeeper 上创建的节点, 可以对这些节点绑定监听事件. 比如可以监听节点数据变更、节点删除、子节点状态变更等事件.通过这个事件机制, 可以基于zookeeper 实现分布式锁、集群管理等功能. zookeeper 事件 事件含义 EventType.NodeCreated 当node-x 这个节点被创建时, 该事件被触发 EventType.NodeChildrenChanged 当node-x 这个节点的直接子节点被创建、删除、修改的时候触发 EventType.NodeDataChanged 当 node-x 这个节点的数据发生变更的时候,该事件被触发 EventType.NodeDeleted 当node-x 这个节点被删除的时候,该事件被触发 EventType.None 当zookeeper客户端的连接状态发生变更时, 被 触发 watcher 机制有一个特性,当数据发生改变的时候, 那么zookeeper 会产生一个watcher 事件并发送到客户端,但是客户端只会收到一次这样的通知，如果以后这个数据再发生变化, 那么之前设置watch】的客户端不会再收到消息. 因为他是一次性的, 如果要实现永久监听, 可以通过循环注册来实现. curator 对节点事件的监听提供了很完善的api, 接下来简单来演示一下 curator 事件监听的基本使用. curator 提供了三种Watcher 来监听节点的变化 PathChildCache: 监视一个路径下孩子节点的创建、删除、更新. NodeCache: 监视当前节点的创建、更新、删除并将节点的数据缓存在本地. TreeCache: PathChildCache 和NodeCache 的结合体, 监视路径下的创建、更新、删除事件, 并缓存路径下的所有孩子节点的数据.","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://rainsoil.github.io/tags/zookeeper/"}]},{"title":"基于Zookeeper 实现Leader选举","slug":"微服务/zookpeer/基于Zookeeper 实现Leader选举","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/ji-yu-zookeeper-shi-xian-leader-xuan-ju/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/ji-yu-zookeeper-shi-xian-leader-xuan-ju/","excerpt":"","text":"基于Zookeeper 实现Leader选举在分布式计算中,leader election 是很重要的一个功能, 这个选举过程是这样子的: 指派一个进程作为组织者, 将任务分发给各节点。 在任务开始之前, 哪个节点都不知道谁是leader 或者coordinator. 当选举算法开始执行后, 每个节点最终会得到一个唯一的节点作为任务leader. 除此之外, 选举还经常会发生在leader 意外宕机的情况下, 新的leader 要被选举出来. curatot 有两种选举recipe(Leader Latch 和Leader Election) Leader Latch参与选举的所有节点, 会创建一个顺序节点, 其中最小的节点会设置为master节点, 没抢到leader 节点的都监听前一个节点的删除事件, 在前一个节点还是删除后进行重新抢主, 当master 节点手动调用close() 方法或者master 节点挂了之后, 后续的子节点会抢占master 其中spark 使用的就是这种方法 LeaderSelectorLeaderSelector 和Leader Latch 最大的区别在于, leader 在释放领导权以后, 还可以继续参与竞争. LeaderSelector 案例演示package com.zk.demo; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.framework.recipes.leader.LeaderSelector; import org.apache.curator.framework.recipes.leader.LeaderSelectorListenerAdapter; import org.apache.curator.retry.ExponentialBackoffRetry; import java.io.Closeable; import java.io.IOException; /** * @author luyanan * @since 2019/11/12 * &lt;p>使用LeaderSelector 实现选举&lt;/p> **/ public class LeaderSelectorDemo extends LeaderSelectorListenerAdapter implements Closeable &amp;#123; private final String name; private final LeaderSelector leaderSelector; public LeaderSelectorDemo(CuratorFramework framework, String name, String path) &amp;#123; this.name = name; // 利用一个给定路径创建一个leaderSelector // 执行leader选举的的所有参与者对应的路径必须是一样的. this.leaderSelector = new LeaderSelector(framework, path, this); // 在大多数情况下, 我们会希望一个selector 放弃leader 后还要重新参与leader 选举 leaderSelector.autoRequeue(); &amp;#125; public void start() &amp;#123; leaderSelector.start(); &amp;#125; @Override public void close() throws IOException &amp;#123; leaderSelector.close(); &amp;#125; @Override public void takeLeadership(CuratorFramework client) throws Exception &amp;#123; System.out.println(this.name + \"现在是leader了\"); // 阻塞, 让当前获取leader权限的节点一直持有,直到该进程关闭. System.in.read(); &amp;#125; public static void main(String[] args) throws IOException &amp;#123; String connect = \"192.168.91.128:2181\"; CuratorFramework framework = createClient(connect); framework.start(); LeaderSelectorDemo demo = new LeaderSelectorDemo(framework, \"ClientA\", \"/leader\"); demo.start(); System.in.read(); &amp;#125; public static CuratorFramework createClient(String connect) &amp;#123; CuratorFramework framework = CuratorFrameworkFactory .builder() // 连接信息 .connectString(connect) // 会话超时时间 .sessionTimeoutMs(5000) //失败重试机制 //ExponentialBackoffRetry //RetryOneTime 仅仅只重试一次 //RetryUntilElapsed //RetryNTimes .retryPolicy(new ExponentialBackoffRetry(1000, 3)) .build(); return framework; &amp;#125; &amp;#125;","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[]},{"title":"微服务架构下的服务注册中心设计","slug":"微服务/zookpeer/微服务架构下的服务注册中心设计","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/wei-fu-wu-jia-gou-xia-de-fu-wu-zhu-ce-zhong-xin-she-ji/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/wei-fu-wu-jia-gou-xia-de-fu-wu-zhu-ce-zhong-xin-she-ji/","excerpt":"","text":"微服务架构下的服务注册中心设计这里以一个电商网站进行模拟 单体架构传统的单体架构(all in one) 分布式架构假设一个电商的下单场景,完成一笔订单入库操作,需要做以下几个操作: 创建订单 卡券抵扣 库存扣减 那么在分布式架构的调用链下, 可能是下面这种情况. 那么服务和服务之间势必会存在远程通信. 为了让大家更好的理解服务之间的通信, 我们来基于SpringBoot 模拟出上面的这种应用场景. 使用SpringBoot + RestTemplate 创建两个服务创建两个SpringBoot 工程 订单服务(order-service) 库存服务(repo-service) 分别创建 controller OrderController @Autowired RestTemplateBuilder restTemplateBuilder; @PostMapping(\"/order\") public String sayHello()&amp;#123; RestTemplate rt=restTemplateBuilder.build(); System.out.println(\"开始创建订单\"); rt.put(\"http://localhost:8081/repo/&amp;#123;1&amp;#125;\",null,10001); return \"SUCCESS\"; &amp;#125; RepoController @PutMapping(\"/repo/&amp;#123;pid&amp;#125;\") public void serverMsg(@PathVariable(\"pid\") String pid)&amp;#123; System.out.println(\"扣减库存,商品 ID:\"+pid); &amp;#125; 简单了解 RestTemplate服务与服务之间, 一定不是相互隔离的, 而是必须要互相联系进行数据通信才能实现完整的功能. 所以在刚才的案例中, 我妈们拆分出来的服务使用RestTemplate 来进行远程通信. 在了解RestTemplate 之前, 先来简单了解下HTTP Client, 我们实现对于http 服务的远程调用,常见的手段是基于Apache 提供的httpclient, 或者是Square 公司开源的Okhttp. 还有Netflix 提供的Feign等等. 简单来说,RestTemplate 是Spring 提供了用来访问REST 服务的客户端, 以前我们使用Apache HttpClient 来进行远程调用的时候, 需要些非常多的代码,还需要考虑各种资源回收的问题. 而RestTemplate 简化了Http 服务的通信, 我们只需要提供URL，RestTemplate 会帮我们搞定这一切. 另外,需要注意的是, RestTemplate 并没有重复造轮子, 而是利用现有的技术,如JDK或者Apache HttpClient、Okhttp 等实现http 远程调用. 源码RestTemplate 需要使用一个实现了 ClientHttpRequestFactory 接口的类为其提供 ClientHttpRequest 实现。 而 ClientHttpRequest 则实现封装了组装、发送HTTP消息以及解析响应的底层细节. 目前( 5.1.8.RELEASE) 的RestTemplate 主要有四种 ClientHttpRequestFactory 的实现, 他们分别是: 基于JDK HttpUrlConnection 的 SimpleClientHttpRequestFactory 基于Apache HttpComponents Client 的 HttpComponentsClientHttpRequestFactory 基于Okhttp2(Okhttp 最新版本为3, 有较大改动, 包名有变动, 不和老版本兼容)的 OkHttpClientHttpRequestFactory 基于Netty4 的 Netty4ClientHttpRequestFactory 消息读取的转化RestTemplate 对于服务端端返回消息的读取, 提供了消息转化器, 可以把目标消息转换为用户指定的格式( 通过 Class responseType 参数指定 ) 指定. 类似于写消息的处理,读消息的处理也是通过 ContentType 和 responseType 来选择的相应 HttpMessageConverter 来进 行的。 Http 和RPC框架的区别虽然现在服务间的调用越来越多的使用了RPC 和消息队列, 但是HTTP 仍然有适合它的场景. RCP 的优势在于高效的网络传输模型(常使用NIO来实现),以及针对服务调用场景专门设计协议和高效的序列化技术. HTTP的优势在于它的成熟稳定、使用简单、被广泛支持、兼容性好、防火墙友好、消息的可读性高. 所以HTTP 协议在开放API、跨平台的服务调用,对性能要求不苛刻的场景中有广泛的使用. 微服务通信带来的问题有了远程通信以后, 我们势必会考虑几个问题: 目标服务肯定会做扩容,扩容以后,客户端会带来一些变化. 客户端对于目标服务如何进行负载均衡. 客户端如何维护目标服务的地址信息 服务端的服务状态变化, 如何让客户端尽心感知. 引入注册中心服务注册中心主要用于实现服务的注册和服务的发现功能, 在微服务架构中, 它起到了非常大的作用. 注册中心的实现Dubbo 体系中的Zookeeper、SpringCloud 中的Eureka 和Consul 重新认识ZookeeperZookeeper 的前生今世Apache Zookeeper 是一个高可用的分布式协调中间件。 它是Google Chubby 的一个开源实现, 那么它主要是解决什么问题的呢? 那就得先了解 Google Chubby Google Chubby 是谷歌的一个用来解决分布式一致性问题的组件, 同时, 也是粗粒度的分布式锁服务. 分布式一致性问题什么是分布式一致性问题呢? 简单来说, 就是在一个分布式系统中, 有多个节点,每个节点都会提出一个请求,但是在所有节点中只能确定一个请求被通过.而这个通过是需要所有节点达成一致的结果. 所以所谓的一致性就是在提出的所有的请求中能够选出最终一个请求, 并且这个请求选出来以后, 所有的节点都要知道. 这个就是典型的拜占庭问题. 拜占庭将军问题说的是：拜占庭帝国军队的将军们必须通过投票达成一致来决定是否对某一个国家发起进攻. 但是这些将军在地理位置上是分开的, 并且在将军中存在叛徒. 叛徒可以通过任意行动来达到自己的目标. 欺骗某些将军采取进攻行动. 促使一个不是所有将军都同意的决定, 比如将军们本意是不希望进攻, 但是叛徒可以促成进攻行动. 迷惑将军使得他们无法做出决定. 如果叛徒达到了任意一个目标, 那么这次行动必然失败. 只有完全达成一致那么这次进攻才可能胜利. 拜占庭问题是本质是,由于网络通信存在不可靠的问题, 也就是可能存在消息丢失, 或者网络延迟. 如何在这样的背景下对某一个请求达成一致. 为了解决这个问题, 很多人提出了各种协议, 比如大名鼎鼎的Paxos. 也就是在不可信的网络环境中, 按照paxos 这个协议能够针对某个提议达成一致. 所以分布式一致性的本质就是在分布式系统中, 多个节点就某一个提议如何达成一致. 这个和Google Chubby 有什么关系呢？ 在Google 有一个GFS(Google file system), 他们有一个需求就是要从多个 GFS server中选出一个master Server . 这个就是典型的一致性问题, 5个分布在不同节点的server,需要确定一个master server,而他们要达成的一致性目标是: 确定某一个节点为master,并且所有节点要同意. 而GFS 就是使用chubby 来解决这个问题的. 实现原理: 所有的server 通过chubby 提供的通信协议到Chubby Server 上创建同一个文件, 当然, 最终只有一个server 能够获取创建的这个文件. 这个server 就成为了master, 它会在这个文件中写入自己的地址, 这样其他的server 通过读取这个文件就能知道被选出master 的地址. 分布式锁服务从另外一个层面来看, Chubby 提供了一种粗粒度的分布式锁服务, Chubby 是通过创建文件的形式来提供锁的功能. server 向chubby 中创建文件其实就表示加锁操作， 创建文件成功表示抢占到了锁. 由于Chubby 没有开源, 所以雅虎公司就基于Chubby 的思想, 开发出了一个类似的分布式协调组件Zookeeper, 后面捐赠给了Apache 所以,大家一定要了解, zookeeper 并不是作为注册中心而设计的, 而是作为分布式锁的一种设计. 而注册中心只是它能实现的一种功能而已. Zookeeper 的设计猜想基于Zookeeper 本身的一个设计目标, zookeeper主要是解决分布式环境下的服务协调问题而产生的, 我们来猜想一下, 如果我们要去设计一个zookeeper, 需要满足哪些功能呢? 防单点故障首先, 在分布式架构中, 任何的节点都不能以单点的方式存在, 因此我们需要解决单点的问题. 常见的解决单点的问题的方式就是集群. 大家来思考一下, 这个集群需要满足哪些功能? 集群中要有主节点和从节点(也就是集群要有角色) 集群要能做到数据同步, 当主节点出现故障, 从节点能够顶替主节点继续工作, 但是继续工作的前提是数据必须要主从节点保持一致. 主节点挂了以后, 从节点如何接替成为主节点, 是人工干预还是自动选举? 所以基于这几个问题, 我们先把zookeeper 的集群节点画出来. 数据同步接着上面的那个结论思考, 如果要满足这样的一个高性能集群, 我们最直观的想法应该是每个节点都能接收到请求, 并且每个节点的数据都必须要保持一致. 要实现各个节点的数据一致性, 就势必要一个leader 节点负责协调和数据同步操作. 这个我向大家知道,如果在这样一个集群中没有leader节点，每个节点都可以接受所有请求, 那么这个集群的数据同步的复杂度是非常大的. 所以, 当客户端请求过来, 需要满足,事务性数据和非事务性数据的分开处理方式, 就是leader 节点可以处理事务和非事务性数据.而follower 节点只能处理非事务性数据. 原因是: 对于数据变更的操作, 应该由一个节点来维护, 使得集群数据处理的简化. 同时,数据需要能能够通过leader 进行分发使得数据在集群中各个节点的一致性. leader节点如何与其他节点保证数据一致性,并且要求是强一致的. 在分布式系统中, 每一个机器节点虽然都能够明确知道自己进行的事务操作是成功还是失败,但是却无法直接获取其他分布式节点的操作过程. 所以当一个事务操作涉及到跨节点的时候, 就需要用到分布式事务, 分布式事务的数据一致性协议有2PC 协议和3PC协议. 关于2PC 提交(Two Phase Commitment Protocol) 当一个事务操作需要跨域多个分布式节点的时候, 为了保证事务处理的ACID 特性, 就需要引入一个”协调者”(TM)来统一调度所有分布式节点的执行逻辑,这些被调度的分布式节点被称为AP。 TM 负责调度AP的行为, 并最终决定这些AP是否要把事务真正进行提交,因为整个事务是分为两个阶段提交, 所以叫2PC。 阶段一: 提交事务请求(投票) 事务询问 协调者向所有的参与者发送事务内容, 询问是否可以执行事务提交操作, 并开始等待各参与者的响应. 执行事务 在这个阶段, 协调者会根据和参与者的反馈情况来决定最终是否可以进行事务提交操作, 正常情况下包含两种可能: 执行事务、中断事务. 角色Leader 角色Leader 服务器是整个zookeeper 集群的核心, 主要的工作是有两项: 事务请求的唯一调度和处理者, 保证集群事务处理的顺序性. 集群内部各服务器的调度者. Follower 角色Follower 角色的主要职责是: 处理客户端非事务请求, 转发事务请求给leader 服务器 参与事务请求proposal 的投票(需要半数以上服务器通过才能通知leader commit 数据, Leader 发起的提案, 要求Follower 投票) 参数Leader 选举的投票 Observer 角色Observer 是Zookeeper3.3 开始引入的一个全新的服务器角色, 从字面来理解, 该角色充当了观察者的角色。 观察Observel 集群中的最新状态变化并将这些状态变化同步到Observer 服务器上, Observer 的工作原理与follower 角色基本一致, 而它和follower 角色唯一的不同在于Observer 不参与任何形式的投票,包括事务请求Proposal 的投票和leader 选举的投票. 简单来说, observer 服务器只提供非事务请求服务, 通常在于不影响集群处理能力的前提下提升集群非事务处理能力. Leader 选举当Leader 挂了, 需要从其他follower 节点中选择一个新的节点进行处理, 这个时候就需要设计到leader 选举. 集群组成通常zookeeper 是由2n+1台server组成, 每个server 都知道彼此的存在。每个server 都维护的内存状态镜像以及持久化存储的事务日志和快照. 对于2n-1台server , 只要有 n+1 台(大多数) server 可用, 整个系统保持可用. 我们已经了解到, 一个zookeeper 集群如果要对外提供可用的服务, 那么集群中必须要有过半的集群正常工作并且彼此之间能够正常通信, 基于这个特性, 如果想搭建一个能够允许F台集群down 掉的集群, 那么就要部署2*F+1 台服务器构成的zookeeper 集群. 因此3台集群组成的zookeeper 集群能够在挂掉一台机器后仍然正常工作. 一个5台机器集群的服务,能够对2台机器坏掉的情况下进行容灾. 如果一台由6台服务构成的集群, 同样只能挂掉两台. 因此, 5台和6台在容灾能力上并没有优势, 反而增加了网络通信负担. 系统启动时, 集群中的server 会选举出一台server 为Leader, 其他的就作为follower(这里先不考虑observer 角色). 之所以要满足这样一个等式, 是因为一个节点要称为集群中的leader, 需要有超过集群过半的节点支持, 这个涉及到leader 的选举算法, 同时也涉及到事务请求的提交投票.","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://rainsoil.github.io/tags/zookeeper/"}]},{"title":"微服务的前生今世(1)","slug":"微服务/微服务的前生今世(1)","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/wei-fu-wu-de-qian-sheng-jin-shi-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/wei-fu-wu-de-qian-sheng-jin-shi-1/","excerpt":"","text":"微服务的前生今世单体架构任何一个网站在发布初期几乎都不可能立马就拥有庞大的用户流量和海量数据,都是在不停的试错过程中一步一步演变其自身架构的, 满足其自身业务. 比如现在能够抗住双十一那么大流量的淘宝,它的技术最早的是LAMP(linux + Apache + Mysql + Php). 实际上,架构越复杂, 意味着业务的体量越庞大. 对于一个刚刚起步的项目,我们会选择最简单的最快速的方式来实现。而单体架构是最好的选择, 目前很多的传统软件行业仍然采用这类的架构. 一般的实施方案是,把所有的功能模块都打包在一个(jar、war),并且部署在一个web 容器下,比如 tomcat、weblogic、jboss中运行. 集群架构一旦用户量以及流量开始增加，服务区的性能就能遇到瓶颈,这个时候必须要对系统架构做调整以及优化. 而在这个阶段主要需要解决的问题是提升业务系统的并行处理能力, 降低单机系统负载,以便支撑更多的用户访问操作. 集群就是一种很好的方式, 它可以把多台独立的服务器通过网络连接进行组合, 对外形成一个整体提供服务。当一台服务器的处理能力接近或者已超出其容量上限时,我们不会去尝试换一个一个更高性能的服务器, 因为投入产出比不高, 一般的做法就是采用集群技术, 通过增加新的服务器来分散并发访问流量, 只要业务系统能够随意支撑服务器的横向扩容, 那么从理论上来说就应该无惧任何挑战, 从而实现可伸缩性和高可用性架构. 业务垂直拆分虽然通过集群可以提升并行能力以及对于高可用的实现, 但是同时还要考虑到业务的复杂度, 如果仍然把所有的业务逻辑全部耦合到一起放到一个war 包中来管理, 那对于代码的维护和扩展来说是非常困难的. 而且如果某个业务功能出现故障, 会导致整个系统不可用。所以这个阶段要做的就是降低业务的耦合度, 提升系统的容错性. 所以这个时候可以对业务进行垂直化拆分, 简单来说, 就是可以按照系统的业务功能拆分出多个业务模块, 比如电商网站,会拆分出: 首页、用户、搜索、订单、支付、商品等子系统. 每个子系统由不同的业务团队负责. 服务化改造随着对业务系统进行垂直化改造之后, 以业务功能维度拆分出来多个子系统, 而在各个子系统中, 会存在比较多的共享业务, 比如用户信息查询, 在支付业务中会涉及到、在首页中也会涉及到. 那么势必会造成重复开发产生的非常多的冗余代码. 那么这个时候就引入了服务化改造的思想,也就是SOA. 把一些通用的、会被多个上层服务调用的模块独立拆分出来,形成一些共享的基础服务. 这些被拆分出来的共享服务相对来说是比较独立的、并且可重用的. 比如用户管理服务,包含用户注册、用户查询等功能. 比如单点登陆等服务. SOA 的核心幕目标就是通过服务的流程化来实现业务的灵活性, 而这个流程化其实就是一系列相关联的任务组成, 这一系列相关联的任务可以通过一系列的服务组合来实现具体的业务功能. SOA 面向服务架构,从语义来说, 它与面向过程、面向对象、面向组件一样,是一种软件组建以及开发的方式。所以在SOA中, 服务是最核心的抽象手段, 业务被划分为一些列粗粒度的业务服务和业务流程. SOA 中更强调ESB 企业服务总线, 企业服务总线可以使得服务之间的交互是动态的,以及服务位置是透明的. 这样的好处是服务的调用者和服务的提供者之间是高度解耦的. 从而使得服务有更高的灵活性以及隔离性. ESB: 是从面向服务架构(SOA) 发展过来的,主要是度对多个系统中的服务调用者和服务提供者的解耦. ESB 本身提供了服务暴漏、接入、协议转化、数据格式化、路由等功能. SOA 主要解决的问题: 信息孤岛 互联互通 业务重用 微服务架构业务系统实施服务化改造后, 原本共享的业务被拆分,形成可复用的服务, 可以在最大程度上避免共享业务的重复建设、资源连接瓶颈等问题出现. 那么哪些被拆分出来的服务,是否也需要以业务为维度来进行拆分,使之能够独立部署,以降低业务耦合和提升容错性呢? 微服务并不是一种新思想的方法.它更像是一种思想的精炼, 是一种服务化思想的最佳实践方向而已. 所以我认为微服务其实就是在SOA 思路下,随着各个企业对于fu’wu’hua治理上不断的完善, 以及对软件的交付链路以及基础设施逐步成熟之下的一种自然的产物. 微服务也是一种面向服务的架构模型, 只是它更强调服务的粒度. 也就是服务的职责更加单一, 更加精炼.我们也可以把SOA 看成是微服务的超集.也就是多个微服务可以组成一个SOA 服务. 微服务和SOA 架构的区别:微服务和SOA 架构有什么区别呢? 这个区别一定要从架构的发展过程来了解. 这两种架构模式, 其实本质上应该是在分布式架构这条时间线上, 基于服务化思想的不断完善, 以及基础设施的逐步成熟之下的一种升级。既然存在时间线的先后, 那也就意味着, 这两种架构模式所关注的点不一样. SOA 关注的是服务的重用性, 以及解决企业内部的信息孤岛问题. 微服务关注的是解耦, 解耦和可重用性在特定的角度看来是一样的. 但本质上是不同的. 解耦是降低业务之间的耦合度(也就是微服务关注的服务粒度),而可重用性关注的是服务的复用. 微服务会使用更轻量的通信协议, 使用Restful 风格的API. 轻量级协议可以很好的支持跨语言, 使得语言生态更加丰富. 微服务会更多的关注Devops 的持续交付, 因为服务粒度更细使得开发运维变得更加重要,所以微服务对于容器化技术的结合更加紧密. SOA 应该是微服务的超集. SpringCloud 生态提高微服务技术体系, 大家第一个想到的应该是Spring Cloud , 那么什么是SpringCloud 呢? 什么是Spring Cloud我们知道Spring Cloud 可以用来开发微服务, 但是应该很少有人真正知道Spring Cloud 是什么? 官当的解释是: Spring Cloud 提供了一些可以让开发者快速构建分布式应用的工具,这些服务可以很好的工作在任何分布式环境下. 既然提供的是一些快速构建微服务应用的工具, 那么我们需要了解微服务开发过程中需要解决哪些问题? 网关在微服务实施后，各个服务的拆分粒度很小,对于客户端来说, 做一个操作可能会涉及到后端的多个服务组件的调用, 那意味着它需要频繁的发起多次访问才能够进行数据聚合实现用户的功能. 如果我们在所有的微服务之前增加一个网关, 对于客户端来说它需要做什么功能操作直接调用网关并且告诉网关需所要做的事情即可. 网关根据请求的功能对后端的多个服务的数据进行聚合, 从而减少客户端的调用频次. 并且,由于有了网关的聚合, 我们还可以在网关层对请求进行统一鉴权和认证. 还包括实现限流、请求日志统一记录、灰度发布等. 服务的通信和服务发现服务拆分以后会涉及到服务的远程通信, 比如http 协议或者rpc 协议. 在满足基本通信基础上, 如何做到服务的统一管理以及服务的动态感知, 就需要涉及到服务的注册中心来实现服务注册和服务发现. 负载假设服务提供者为了扩大容量, 采用10台机器的集群部署,这个时候客户端从注册中心获取服务后, 应该调用哪台机器呢? 所以必然有一种负载均衡的机制, 来实现客户端请求的分发. 熔断、限流、降级在分布式架构中,各个服务节点一定要满足高可用,所以对于服务本身来说, 一方面是在有准备的情况下做好充足的扩容。另一方面,服务需要有熔断、限流、降级的功能. 当一个服务调用另外一个服务, 可能因为网络原因、或者连接池满等问题导致频繁出现错误, 需要有一种熔断机制, 来防止因为请求堆积导致整个应用雪崩. 当发现整个系统的确负载过高的时候,可以选择降级某些功能或者某些调用, 保证最重要的交易流程的通过, 以及最重要的资源全部用于保证最核心的流程. 在设置了熔断以及降级策略后, 还有一种手段来保护系统, 就是限流算法. 我们能够通过全链路压测了解到整个系统的吞吐量, 但实际上的流量可能会超过我们预期的值, 比如存在恶意攻击 或者突然的高峰流量. 在这种情况下可以通过限流来保护系统 不崩溃, 但是对于部分用户来说, 会出现被限流导致体验不好的情况. 统一配置中心服务拆分之后, 服务的数量非常多, 如果所有的配置都以配置文件的方式放在应用本地的话, 非常难以管理, 可以想象当有几百上千个进程中有一个配置出现问题, 是很难将它找出来的, 因而需要有统一的配置中心, 来管理所有的配置, 进行统一的配置下发. 在微服务中, 配置往往分为几类, 一类是几乎不变的配置, 这种配置可以直接打在容器镜像里面, 第二类是启动时就会确定的配置, 这种配置往往通过环境变量, 在容器启动的时候传入进去, 第三类是统一的配置, 需要通过配置中心进行统一的下发, 例如在大促的情况下, 有哪些服务需要降级, 哪些功能可以降级, 哪些功能不能降级,都可以在配置中心中统一配置. 微服务架构下的组件需求下面是基于一个请求进来之后, 所需要用到的组件和功能. 从图可以看到, 如果要实现微服务, 我们需要解决很多的问题,比如: 服务注册发现 远程服务调用 负载均衡 断路器 分布式消息 配置中心 链路监控 所以, Spring Cloud 提供了一些解决这类问题的工具, 比如服务注册提供了Eureka/Consoul/zookeeper;远程调用基于RestTemplate 针对http 协议调用的封装； 负载均衡采用Rabbon; 断路器采用Hystrix;分布式消息基于Kafka、rabbitMQ;配置中心基于 config; 链路监控基于 sleuth; 但是, 从这些组件中我们发现了一些问题,这些组件并不是sring 提供的, 比如 eureka、ribbon、hystrix 是netflix 开源的. 而kafka、zookeeper 是一些独立的组件, 和spring 没有关系。没错, 这就是spring 团队的强大之处, 他们很少重复造轮子, 而是他们利用别人造好的轮子来进行封装使得用户在用的时候更加方便. 举个简单的例子, 比如最早spring 只提供了IOC和AOP的核心功能,而像ORM 框架、缓存、MVC 框架,Spring 只是提供了一种兼容以及支持, 所以当时大家说spring 是万能胶, 可以把各种各样的框架整合起来。 当然, Spring 也会对一些市面上做的不好的技术进行替代, 比如 struts2. 因为当时struts2 经常出现各种漏洞, 所以 spring mvc 才会被创建出来并且很快替代了struts ,成为现在的主流框架. 所以, 对于Spring Cloud 来说也是如此, Spring Cloud 并不是一个框架, 因为Spring Cloud 的核心并没有实现服务注册、熔断、配置中心等功能, 它提供了一个标准规范.而Spring Cloud Netfilx 才是Spring Cloud 规范的一种实现. Spring Cloud 生态的构建Spring Cloud 的生态是基于Spring Boot 这个框架来构建的, 所以Spring Cloud 可以说是基于Spring Boot 来对其他框架进行整合的, 那么什么是Spring Boot 或者为什么要基于Spring Boot 来整合呢? 首先, Spring Boot 并不是一个新的技术, 它是基于Spring 框架下对于”约定大于配置(Convention Over Configuration)” 理念下的产物, 主要是帮助开发人员更容易更快速的创建独立运行和产品级别的基于Spring 框架的应用. 为什么说Spring Boot 是微框架呢? 如果大家玩过Spring Boot , 那应该很有体会, 我们只需要非常少的配置就可以快速构建一个web 项目. 而Spring Boot 中并没有新的技术, 如果大家对Spring 框架比较熟悉的话, 那么在学习Spring Boot 的时候会更加容易. 围绕Spring Boot 构建的Spring Cloud 生态下, 目前有两个比较好的实现, 一个是基于Netflix ,另一个是Alibaba Spring Cloud NetflixSpring Cloud Netflix 实际上就是基于Netflix 公司的开源组件,然后基于Spring Cloud 的标准规范, 在Spring Boot 的基础上进行整合. Spring Cloud AlibabaSpring Cloud Alibaba 在2019年4月19号发布了两个版本, 分别是0.2.2.RELEASE、0.9.9.RELEASE，分别对应 Spring Cloud Finchley 和 Greenwich. 由于Spring 官方宣布对于 Spring Cloud Edgware 在2019年8月1号之后停止维护,所以Spring Cloud Duboo 并没有提供对E 版本的支持。 在下面这个网址可以看到Spring Cloud 的版本支持, 它并不像传统意义上的版本命名,而是采用了伦敦地铁站的名称,按照字母表的顺序来对应版本时间顺序 https://spring.io/projects/spring-cloud 原因是Spring Cloud 是由多个独立项目组成的整体项目, 而每个独立的项目有不同的发布节奏, 各个子项目维护着自己的发布版本号.Spring Cloud 通过一个资源清单BOM(Bill of Materials) 来管理每个版本的子项目清单。 为了避免于子项目的发布号混淆, 所有没有采用版本号的方式, 而是通过命名的方式. 比如最最早的 Release 版本：Angel，第二个 Release 版本：Brixton，然后是 Camden、Dalston、Edgware、Finchley 、到目前的最新版本 Greenwich 当一个版本的Spring Cloud 项目的发布内容积累到临界点或者解决了一个严重bug 后, 就会发布一个”service releases” 版本, 简称SRX 版本，其中X 是一个递增的数字. 当前官网上最新的稳定版本是 Edgware.SR2，里程碑版本是 Finchley.SR2。下面这个表分别对应的是 Edgware.SR6 和 Finchley.SR2 对应各个子项目的版本号。 ➢ 对于 SpringBoot 版本的兼容如下 Greenwich 和 Spring Boot 2.1.x 兼容 Finchley 和 Spring Boot2.0.x 兼容，不支持 Spring Boot 1.5.x Edgware 和 Spring Boot 1.5.x 兼容 常见的服务组件融合在每个微服务中, 依赖其他组件并为其提供服务 Ribbon客户端负载均衡,特性有区域亲和,重试机制 Hystrix客户端容错保护, 特性有服务降级、服务熔断、请求缓存、请求合并、依赖隔离. Feign声明式服务调用, 本质上就是 Ribbon + Hystrix Stream消息驱动,有Sink、Source、Processor 三种通道, 特性有订阅发布、消费组、消息分区. BUS消息总线,配合Config 仓库修改的一种Stream 实现 Sleuth分布式服务追踪,需要搞清楚TraceID和SpanID 以及抽样, 如何与ELK整合. Eureka服务注册中心,特性有失效剔除、服务保护. DashboardHystrix 仪表盘, 监控集群模式和单点模式, 其中集群模式需要收集器Tuibine 配合 ZuulAPI 服务网关, 功能有路由分发和过滤 Config分布式配置中心.,支持本地仓库、SVN、Git、Jar包内配置 各个组件的指责每个组件都不是平白无故的产生,是为了解决某一个特定的问题而存在的. Eureka 和Ribbon 是最基本的组件, 一个是注册服务, 一个是消费服务. Hystrix 为了优化Ribbon,防止整个微服务架构因为某个服务节点的问题而导致崩溃, 是个保险丝的作用 Dashboard 是给Hystrix 统计和展示用的, 而且监控服务节点的整体压力和健康情况 turbine 是集群收集器, 服务于Dashboard 用的 Feign 是方便内部服务调用的 Zuul 是加在整个微服务最前沿的防火墙和代理器, 隐藏微服务节点IP端口信息, 加强安全保护的. Config 是为了解决所有微服务各自维护各自的配置, 设置统一的配置中心, 方便修改配置的 Bus是因为Config 修改完配置后各个节点要各自refresh 才能生效实现太麻烦, 所以交给bus来通知服务节点刷新配置的. Stream 是为了简化研发人员对MQ 使用的复杂度, 弱化MQ的差异性, 达到MQ 和程序送耦合的. Sleuth 是因为单次请求在微服务节点中跳转无法追溯,解决任务链日志追踪问题的. Spring Cloud Alibaba官方宣布 https://spring.io/blog/2018/10/30/spring-cloud-for-alibaba-0-2-0-released alibaba的Spring Cloud 生态中, 提供了微服务开发中必须用到的组件, 就像Spring Cloud 一样 ,通过这些组件以及简化的编程模型使得开发者对于微服务架构变得更简单. 目前Spring Cloud Alibaba 这个生态, 已经有了相对成熟的体系. Dubbo : 用于实现高性能的Java RPC 框架. Nacos : 服务注册发现、配置管理、服务管理. Sentinel: 流量控制、熔断降级、系统负载保护. RocketMQ: 分布式消息系统,提供低延时的, 高可靠的消息发布和订阅服务 Seata: 高性能微服务分布式事务解决方案 [商业]Alibaba Cloud OSS 阿里云对象存储(Object Storage Service,简称OSS), 是阿里云提供了海量、安全、低成本、高可靠的云存储服务. 您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据. [商业] Alibaba Cloud SchedulerX 阿里中间件团队开发的一款分布式任务调度产品, 支持周期性的任务和固定时间点触发任务. [商业]Alibaba Cloud SMS 覆盖全球的短信服务, 友好、高效、智能的互联化通讯能力, 帮助企业迅速搭建客户触达通道. 开源地址:https://github.com/spring-cloud-incubator/spring-cloud-alibaba 项目组成部分项目由两部分组成, 一部分是开源组件, 另一部分是云产品.开源产品, 它的项目前缀是 :spring-cloud-alibaba, 它有以下几个特性: 服务发现 配置管理 安全高可用 云产品项目前缀是: spring-cloud-alicloud,它有以下几个特性: 对象存储服务(OSS) 任务调度服务( SchedulerX ) 日志服务(SLS) 下一代微服务(Service Mesh)什么是Service Mesh? 简单来说, 它可以直接翻译成服务网格. 它是一个基础设施层, 用于处理服务之间的通信, 并且负责请求的可靠传输, Service Mesh 演进在第一代网络计算机系统时代, 那么时候的程序员需要完成服务的网络通信, 需要自己写代码来处理网络通信的细节, 比如数据包的顺序、流量控制.导致网络处理逻辑和业务处理逻辑混合在一起,同时对于开发人员来说要求较高. 为了解决这个问题, 把网络层的处理逻辑进行了抽象, 实现了TCP/IP技术。对于用户而言,并不需要关心底层的网络通信细节. 到了微服务时代,我们也面临了类似的问题. 业务人员在做微服务开发的的时候需要处理一些比较基础的事情, 比如 服务注册、服务发现、负载均衡、服务熔断和重试等. 这些功能对于每一个业务程序员而言都必须掌握和了解,而实际上这些跟业务功能并没有太大的关系, 它理应是一个基础组件. 所有, 有些公司就开始开发基础组件,典型的Netflix OSS 套件(eureka/hystrix/feign/ribbon/zuul).有了这些组件,开发人员就可以使用很少的代码来实现这些服务治理的功能. 而恰恰因为这个原因, 使得Spring Cloud 的普及非常快, 几乎成了微服务的代名词. 但是到了这一步之后, 就完美了吗? 其实不是, 虽然Spring Cloud 这个生态中的各种组件能够解决微服务开发中的各种问题,但是对于一个业务开发而言, 需要掌握那么多的技术组件, 门槛比较高。同时在落地的过程中任何一个组件出了问题, 都需要较长的时间来解决。 要完全吃透Spring Cloud 和Netflix OSS 的各种套件是很困难的. Spring Cloud 微服务带来的问题业务团队的痛点 对于业务开发团队而言, 最强的是技术吗? 一定不是, 业务团队最强的是对业务的理解和熟悉程度 . 而业务应用的核心价值, 就是为了实现业务场景, 而不是写微服务, 微服务只是一种实现业务的手段. 业务团队除了开发业务之外,他们所面临的最大的挑战在于, 如何保证系统的稳定性以及扩展性,如何设计一个安全的 open api. 如何对服务进行拆分、如何保证跨库的数据一致性以及对于旧系统的改造. 对于公司层面而言, 业务团队的压力还来自于时间人力的投入,我们用于被各种deadline 赶着走. 所以作为一个业务程序员, 如果在这个 deadline 之前还 需要i花很多的时间投入到Spring Cloud 这些工具的学习上, 那无疑是雪上加霜。公司对于业务团队的考核, 永远只看结果. 服务治理功能不齐全Spring Cloud 对于服务治理的功能还是不够强大, 如果需要实现企业级的微服务落地以及服务治理, 那么我们还需要基于Spring Cloud 这套体系来解决这些问题. 跨语言带来的问题微服务有一个很重要的特性就是不同的微服务可以采用自己最擅长的语言来编写程序,这种特性在企业中落地的时候又会带来一些问题. 比如公司内部会开发一些公共的类库或者框架, 也会使用第三方的类库或者框架来实现某些功能. 但是由于公司的微服务用了各种各样的语言,那意味着这些类库需要针对不同的语言开发兼容版本, 如果是主流语言还好, 如果是一些小众语言, 那么对于这些基础组件的开发者来说无疑是晴天霹雳. 总结从这些痛点中可以发现, 我们所作的所有非业务的事情都是为了把请求发送到正确地方,并且能够及时得到正确的结果。那么对于业务开发人员来说, 是否有必要去关心这些地方呢? 回到我们最开发说的一个例子, 在进行计算机网络传输的时候, 开发人员有必须去关心网络传输的细节吗? 我们在使用http协议进行网络数据传输的过程中, 关心过底层是使用的是TCP 还是UDP吗? 数据是怎么传输的? 既然我们不需要关心这些， 那对于微服务架构中的这些问题, 业务开发人员为什么一定要关系服务的通讯呢? 技术栈下沉那么对于微服务实施来说, 能不能像网络协议下沉一样, 增加一个微服务层来完成这个事情呢? 这就引出了Service Mesh 在每个服务中, 会有一个Service Mesh 实例, 客户端发起一个请求, 首先会把请求发送到本地的Service Mesh实例上, Service Mesh 实例中会完成完整的服务之间的调用流程, 比如服务的发现、负载均衡,最终发送给目标服务. 而这个Service Mesh 实例, 专业名称应该是: sidecar,简单来说就是原有的客户端和服务端之间的一个代理. 在多个服务调用中, 这种通讯的方式的表现形式就像一个网格, sidecar 之间的链接形成了一个网络,这就是Service Mesh 的由来. Service Mesh 为业务开发团队降低了门槛, 提供了稳定的基础设施, 最重要的是让业务开发团队从微服务的实现的具体细节中解放出来回归到业务中.","categories":[{"name":"微服务","slug":"微服务","permalink":"https://rainsoil.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"微服务/微服务","permalink":"https://rainsoil.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[]},{"title":"分库分表的类型和特点(2)","slug":"数据库/分库分表的类型和特点(2)","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.297Z","comments":true,"path":"2022/01/04/shu-ju-ku/fen-ku-fen-biao-de-lei-xing-he-te-dian-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/shu-ju-ku/fen-ku-fen-biao-de-lei-xing-he-te-dian-2/","excerpt":"","text":"分库分表的类型和特点从维度来说可以分为两种: 一种是垂直, 一种是水平 垂直切分: 基于表和字段划分, 表结构不同, 我们有单表的分表， 也有多库的分表. 水平切分: 基于数据切分, 表结构相同, 数据不同, 也有同库的水平切分和多库的切分 1. 垂直切分垂直分表分为两种, 一种是单库的, 一种是多库的. 1.1 单库垂直分表单库分表, 比如: 商户信息表拆分成基本信息表、联系方式表、结算信息表、附件表. 1.2 多库垂直分表多库垂直分表就是把原来存储在一个表中不同的表, 拆分在不同的数据库中. 比如: 消费金融核心数据库, 有很多客户相关的表, 这些客户的表,全部单独存放在客户的数据库中。 当我们对原来的一张表做了分库的处理, 如果某些业务系统的数据还是一个非常快的增长速度, 比如还款系统的还款历史表, 数据量达到了几十个亿, 这个时候硬件限制导致的问题还是会出现. 所以从这个角度来说垂直拆分并没有从根本上解决单库单表数据量过大的问题. 在这个时候, 我们还需要对我们的数据做一个水平的拆分. 2. 水平拆分当我们的客户表的数量已经达到数千万甚至上亿的时候, 单表的存储容量和查询效率还是会出现问题, 我们需要进一步对单张表进行水平拆分. 水平拆分的每个数据库的表结构都是一样的, 只是存储的数据不同, 比如每个库存储1000万的数据. 水平拆分也可以分为两种, 一种是单库的， 一种是多库的. 2.1 单库水平分表银行的交易流水表, 所有进出的交易记录都需要登记这种表, 因为绝大部分的时候客户都是查询当天的交易和一个月之内的交易数据, 所以我们根据使用频率将这张表拆分成三张表. 当天表: 存储当天的数据 当月表: 在夜间运行一个定时任务 , 前一天的数据, 全部迁移到当月表。 用到是insert into insert ,然后delete 历史表: 同样是通过定时任务, 把登记时间超过30天的数据,迁移到history 历史表(历史表的数据非常大, 我们按照月度, 每个月建立分区) 但是注意, 跟分区一样, 这种方式虽然可以一定程序上解决单表查询性能的问题，但是并不能解决单机存储瓶颈的问题. 2.2 多库水平分表另一种是多库的水平分表, 比如客户表,我们可以拆分到多个库存储， 表结构是完全一样的. 一般我们说的分库分表都是跨库的分表. 既然分库分表能够帮助我们解决性能的问题, 那我们是不是马上就动手去做呢? 甚至在项目设计的时候就先给他分几个库呢? 先来冷静一下，我们来看一下分库分表会带来哪些问题, 也就是我们前面说的分库分表之后带来的复杂性. 3. 分库分表带来的问题3.1 跨库关联问题比如在查询合同信息的时候要关联客户数据, 由于是合同数据和客户数据在不同的数据库, 那么我们肯定不能直接使用join 的这种方式来做关联查询. 我们有几种主要的解决方案: 字段冗余 比如我们在查询合同库的合同表的时候要关联客户库的客户表, 我们可以直接把一些经常关联查询的客户字段放到合同表, 通过这种方式来避免跨库关联查询的问题 数据同步 比如商户系统要查询产品系统的产品表, 我们干脆在商户系统里面创建一张产品部, 通过ELK 或者其他定时任务的方式定时同步产品数据. 全局表(广播表) 比如行名行号等被很多业务系统用到, 如果我们放在核心系统 , 每个系统都要去关联查询, 这个时候我们可以在所有的数据库中都存储相同的基础数据. ER表(绑定表) 我们有些表的数据是存在逻辑的主外键关系的, 比如订单表order_info, 存的是汇总的商品数, 商品金额, 订单明细表order_detail, 是每个商品的价格, 个数等. 或者叫做从属关系, 父表和子表的关系. 他们之间会经常有关联查询的操作, 如果父表的数据和子表的数据分别存储在不同的数据库, 跨库关联查询也比较麻烦, 所以我们能不能把父表的数据和从属于父表的数据落到同一个节点上呢? 比如order_id=1001的数据在node1, 他所有的明细数据也放到node1, order_id=1002的数据在node2, 他所有的明细数据都放在node2, 这样的关联查询的时候依然是在一个数据库. 上面的思路都是通过合理的数据分布避免跨距关联查询, 实际上在我们的业务中, 也是尽量不要使用跨库关联查询, 如果出现了这种情况, 就要分析一下业务或者数据拆分是不是合理, 如果还是出现了需要跨库关联的情况, 那我们就只能用最后一种办法了. 系统层组装. 在不同的数据库节点把符合条件的数据查询出来, 然后重新组装, 返回给客户端. 3.2 分布式事务比如在一个贷款的流程里面, 合同系统登记了数据, 放款系统也必须生成放款记录, 如果两个不同的动作不是同时成功或者同时失败, 就会出现数据不一致的问题. 如果在一个数据库里面,我们可以用本地事务来控制, 但是在不同的数据库里面就不行了，所以分布式环境里面的事务, 我们也需要一些方案来解决. 这里需要说一下分布式系统的基本是CAP 理论. C (一致性）Consistency: 对某个指定的客户端来说, 读操作能返回最新的写操作,对于数据分布在不同节点上的数据来说,如果某个节点更新了数据, 那么在其他节点如果都读取到了这个最新的数据,. 那么就称为强一致, 如果有某个节点没有读取到, 那么就是分布式不一致. A（可用心）Availability: 非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应), 可用性的两个关键一个是合理的时间, 一个是合理的响应. 合理的时间指的是请求不能被无限的阻塞,应该在合理的时间内给予返回. 合理的响应指的是系统应该明确返回结果并且结果是正确的. P(分区容错性)Partition tolerance : 当出现网络分区后, 系统能够继续工作, 打个比方, 这里集群有多台机器, 有台机器的网路出现了问题, 但是这个集群然然可以正常的工作. CAP 三者是不能共有的, 只能同时满足其中的两点, 基于AP, 我们就有了BASE 理论. - **基本可用`(Basically Available)`:** 分布式系统在出现故障时,允许损失部分可用功能， 保证核心功能可用. - **软状态(`(Soft state)`):** 允许系统中存在中间状态,这个状态不影响系统可用性, 这里指的是`CAP` 中的不一致。 - **最终一致(`Eventually consistent`):** 最终一致性是指经过一段时间后, 所有的节点数据都会达到一致. 分布式事务有几种场景的解决方案: 全局事务(比如XA 两阶段提交:应用、事务管理器(TM)、资源管理器(DB)), 例如Atomikos 基于可靠消息服务的分布式事务 柔性事务TTC （Try-Confirm-Cancel）tcc-transaction 最大努力通知, 通过消息中间件向其他消息发送消息(重复投递+定时校对) 3.3 排序、翻页、函数计算问题跨节点多库查询进行查询, 会出现limit分页, order by 排序的问题, 比如有两个节点， 节点上存的是奇数id = 1,3,5,7,9…..; 节点2上存的是id = 2,4,6,8,10… 执行select * from user_info order by id limit 0,10 需要在两个节点上各取出10条, 然后合并数据, 重新排序. max、min、sum、count 之类的函数在进行计算的时候, 也需要先在每个分片上执行相应的函数, 然后将各个分片的结果集进行汇总和再次计算, 最终将结果返回. 3.4 全局主键避重问题MYSQL 的数据库里面字段有一个自增的属性, Oracle 也有Sequence 序列. 如果是一个数据库, 那么可以保证ID是不重复的, 但是水平分表后, 每个表都按照自己的规律自增, 肯定会出现ID重复的问题, 这个时候我们就不能用本地自增的方式. 我们有几种常见的解决方案: 1. UUID （Universally Unique Identifier 通用唯一识别码） UUID 标准形式包含32个16 进制数字, 分为5段, 形式为8-4-4-4-12 的36个字符, 例如:c4e7956c-03e7-472c-8909-d733803e79a9 Name Length (Bytes) Length (Hex Digits) Contents time_low 4 8 integer giving the low 32 bits of the time time_mid 2 4 integer giving the middle 16 bits of the time time_hi_and_version 2 4 4-bit &quot;version&quot; in the most significant bits, followed by the high 12 bits of the time clock_seq_hi_and_resclock_seq_low 2 4 1-3 bit &quot;variant&quot; in the most significant bits, followed by the 13-15 bit clock sequence node 6 12 the 48-bit node id xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx M 表示UUID的版本,目前只有5个版本,即指挥出现1,2,3,4,5 , 数字N 的一至三个最高有效位标识UUID 变体, 目前指挥出现8,9,a,b 四种情况。 基于时间和MAC地址的UUID 基于第一版却更加安全的DCE UUID 基于md5 散列算法的uuid 基于随机数的UUID, 用的最多, JDK里面是4 基于SHA1散列算法的UUID UUID 是主键的最简单的方案, 本地生成, 性能高, 没有网络的消耗. 但是缺点也很明显, 由于uuid 非常长,会占用大量的存储空间;另外, 作为主键建立索引和基于索引进行查询时都会存在性能问题, 在InnoDB 中, UUID的无序性会引起数据位置频繁变动, 导致分页. 2. 基于数据库把序号维护在数据库的一张表中, 这张表记录了全局主键的类型、位数、起始值、当前值.当其他应用需要获取全局ID时, 先for update锁行, 取到值+1后并且更新后返回, 并发性比较差. 3. redis基于redis 的int 自增的特性, 使用批量的方式降低数据库的写压力, 每次获取一段区间的ID号段, 用完之后再去数据库获取, 可以大大减轻数据库的压力. 4. 雪花算法Snowflake(64bit) 核心思想: 使用41bit作为毫秒数, 可以使用69年 10bit作为机器的id(5bit是数据中心, 5bit的机器id), 支持1024个节点 12bit 作为毫秒内的流水号(在每个节点上每毫秒可以产生4096个ID) 最后还有一个符号位, 永远是0 优点: 毫秒数在高位, 生成的ID 整体上按照时间趋势递增, 不依赖第三方系统, 稳定性和效率较高, 理论上QPS 约为409.6w/s(1000*2^12), 并且分布式环境中不会产生ID 碰撞, 可根据自身业务灵活分配bit位. 不足在于:强依赖机器的时钟, 如果时钟回拨, 则可能导致生成ID 重复. 但我们对数据做了切分， 分布在不同的节点上存储的时候, 是不是就意味着产生多个数据源呢? 既然有了多个数据源, 那么我们的项目中就要配置多个数据源了. 现在问题来了, 我们在执行一条sql 语句的时候, 比如插入, 他应该是在哪个数据库节点上执行呢? 又比如查询, 如果只是在其中的一个节点上面, 我怎么知道在哪个节点呢? 是不是要在所有的数据库节点上都查询一遍才能拿到结果? 那么, 从客户端到服务端， 我们可以在哪些层面解决这些问题呢? 4. 多数据源/读写数据源的解决方案我们先要分析一下SQL执行经过的流程. DAO——Mapper（ORM）——JDBC——代理——数据库服务 4.1 客户端DAO层第一个就是在我们的客户端代码,比如DAO层, 在我们连接到某一个 数据源之前, 我们先根据配置的分片规则, 判断需要连接到哪些节点, 再建立连接. Spring中提供了一个抽象类, AbstractRoutingDataSource 可以实现数据源的动态切换. 步骤如下: 在application文件中定义多个数据源 创建@TargetDataSource 注解, 定义需要切换的数据源 创建DynamicDataSource 继承AbstractRoutingDataSource 多数据源配置类DynamicDataSourceConfig 创建切面类DataSourceAspect, 添加对@TargetDataSource 注解的类进行拦截设置数据源 在启动类上自动装配数据源配置@Import(&#123;DynamicDataSourceConfig.class&#125;) 在实现类上加上注解, 如@TargetDataSource(name = DataSourceNames.SECOND) 调用. 代码实例： application server.port=8082 spring.datasource.type=com.alibaba.druid.pool.DruidDataSource spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver # 数据源1 spring.datasource.druid.first.url=jdbc:mysql://localhost:3306/ds0?allowMultiQueries=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8 spring.datasource.druid.first.username=root spring.datasource.druid.first.password=123456 # 数据源2 spring.datasource.druid.second.url=jdbc:mysql://localhost:3306/ds1?allowMultiQueries=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8 spring.datasource.druid.second.username=root spring.datasource.druid.second.password=123456 TargetDataSource 注解 /** * 多数据源注解 * &lt;p/> * 指定要使用的数据源 * */ @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface TargetDataSource &amp;#123; String name() default \"\"; &amp;#125; DynamicDataSource /** * 扩展 Spring 的 AbstractRoutingDataSource 抽象类，重写 determineCurrentLookupKey 方法 * 动态数据源 * determineCurrentLookupKey() 方法决定使用哪个数据源 * */ public class DynamicDataSource extends AbstractRoutingDataSource &amp;#123; private static final ThreadLocal&lt;String> CONTEXT_HOLDER = new ThreadLocal&lt;>(); /** * 决定使用哪个数据源之前需要把多个数据源的信息以及默认数据源信息配置好 * * @param defaultTargetDataSource 默认数据源 * @param targetDataSources 目标数据源 */ public DynamicDataSource(DataSource defaultTargetDataSource, Map&lt;Object, Object> targetDataSources) &amp;#123; super.setDefaultTargetDataSource(defaultTargetDataSource); super.setTargetDataSources(targetDataSources); super.afterPropertiesSet(); &amp;#125; @Override protected Object determineCurrentLookupKey() &amp;#123; return getDataSource(); &amp;#125; public static void setDataSource(String dataSource) &amp;#123; CONTEXT_HOLDER.set(dataSource); &amp;#125; public static String getDataSource() &amp;#123; return CONTEXT_HOLDER.get(); &amp;#125; public static void clearDataSource() &amp;#123; CONTEXT_HOLDER.remove(); &amp;#125; &amp;#125; DynamicDataSourceConfig ** * 配置多数据源 */ @Configuration public class DynamicDataSourceConfig &amp;#123; @Bean @ConfigurationProperties(\"spring.datasource.druid.first\") public DataSource firstDataSource()&amp;#123; return DruidDataSourceBuilder.create().build(); &amp;#125; @Bean @ConfigurationProperties(\"spring.datasource.druid.second\") public DataSource secondDataSource()&amp;#123; return DruidDataSourceBuilder.create().build(); &amp;#125; @Bean @Primary public DynamicDataSource dataSource(DataSource firstDataSource, DataSource secondDataSource) &amp;#123; Map&lt;Object, Object> targetDataSources = new HashMap&lt;>(5); targetDataSources.put(DataSourceNames.FIRST, firstDataSource); targetDataSources.put(DataSourceNames.SECOND, secondDataSource); return new DynamicDataSource(firstDataSource, targetDataSources); &amp;#125; &amp;#125; DataSourceAspect /** * 多数据源，切面处理类 */ @Slf4j @Aspect @Component public class DataSourceAspect implements Ordered &amp;#123; @Pointcut(\"@annotation(com.dynamic.datasource.TargetDataSource)\") public void dataSourcePointCut() &amp;#123; &amp;#125; @Around(\"dataSourcePointCut()\") public Object around(ProceedingJoinPoint point) throws Throwable &amp;#123; MethodSignature signature = (MethodSignature) point.getSignature(); Method method = signature.getMethod(); TargetDataSource ds = method.getAnnotation(TargetDataSource.class); if (ds == null) &amp;#123; DynamicDataSource.setDataSource(DataSourceNames.FIRST); log.debug(\"set datasource is \" + DataSourceNames.FIRST); &amp;#125; else &amp;#123; DynamicDataSource.setDataSource(ds.name()); log.debug(\"set datasource is \" + ds.name()); &amp;#125; try &amp;#123; return point.proceed(); &amp;#125; finally &amp;#123; DynamicDataSource.clearDataSource(); log.debug(\"clean datasource\"); &amp;#125; &amp;#125; @Override public int getOrder() &amp;#123; return 1; &amp;#125; &amp;#125; 启动类 @SpringBootApplication(exclude = &amp;#123;DataSourceAutoConfiguration.class&amp;#125;) @Import(&amp;#123;DynamicDataSourceConfig.class&amp;#125;) public class DatabaseDynamicApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(DatabaseDynamicApplication.class, args); &amp;#125; &amp;#125; 调用 /** * &lt;p> * 系统用户 服务实现类 * &lt;/p> * */ @Service public class SysUserServiceImpl extends ServiceImpl&lt;SysUserMapper, SysUser> implements SysUserService &amp;#123; @Override public SysUser findUserByFirstDb(long id) &amp;#123; return this.baseMapper.selectById(id); &amp;#125; @TargetDataSource(name = DataSourceNames.SECOND) @Override public SysUser findUserBySecondDb(long id) &amp;#123; return this.baseMapper.selectById(id); &amp;#125; &amp;#125; 在DAO层实现的优势: 不需要依赖ORM框架, 即使替换了ORM 框架也不受影响, 实现简单(不需要解析SQL 和路由规则), 可以灵活的定制, 缺点: 不能复用, 不能跨语言. 4.2 ORM 框架层第二个是在框架层, 比如我们用Mybatis连接数据库, 也可以指定数据源, 我们可以基于Mybatis 插件的拦截机制(拦截query和update), 实现数据源的选择. 例如: https://github.com/colddew/shardbatis https://docs.jboss.org/hibernate/stable/shards/reference/en/html_single/ 4.3 驱动层不管是Mybatis 还是Hobernate 还是Spring jdbcTemplate , 本质上都是对jdbc的封装, 所以第三层就是驱动层. 比如Sharding-JDBC,就是对JDBC 的对象进行了封装. JDBC 的核心对象: DataSource: 数据源 Connection: 数据库连接 Statement: 语句对象 ResultSet: 结果集. 那我们只要对这几个对象进行拦截或者代理, 就可以实现分片的操作. 3.4 代理层前三种都是在客户端实现的, 也就是说不同的项目都要做同样的改动, 不同的编程语言也有不同的实现. 所以我们能不能把这种选择数据源和实现路由的逻辑提取出来, 做成一个公共的服务给所有的客户端使用呢? 这个就是第四层, 代理层. 比如Mycat、Sharding-Proxy,都是属于这一层. 3.5 数据库服务最后一层就是在数据库服务上实现, 也就是服务层, 某些特定的数据库或者数据库的特定版本可以实现这个功能.","categories":[{"name":"数据库","slug":"数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库","slug":"数据库/数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"zookeeper之watcher原理分析","slug":"微服务/zookpeer/zookeeper之watcher原理分析","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/zookeeper-zhi-watcher-yuan-li-fen-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/zookeeper-zhi-watcher-yuan-li-fen-xi/","excerpt":"","text":"zookeeper原理之watcher源码分析watcher 的基本流程zookeeper 的watcher 机制, 总的来说分为三个过程: 客户端注册watcher、服务端处理watcher和客户端回调watcher . 基于zk客户端发起一个数据操作 public static void main(String[] args) throws IOException, KeeperException, InterruptedException &amp;#123; ZooKeeper zooKeeper = new ZooKeeper(\"192.168.9.22:2181\", 4000, new Watcher() &amp;#123; @Override public void process(WatchedEvent watchedEvent) &amp;#123; System.out.println(\"event.type:\" + watchedEvent.getType()); &amp;#125; &amp;#125;); String path = \"/watcher\"; // 创建节点 zooKeeper.create(path, \"0\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); // 注册监听 zooKeeper.exists(path, true); // 修改节点的值触发监听 zooKeeper.setData(path, \"1\".getBytes(), -1); System.in.read(); &amp;#125; 在创建一个zookeeper 客户端对象实例的时候. 我们通过new Watcher 向构造方法中传入一个默认的watcher, 这个watcher 将作为整个整个zookeeper 会话期间默认的watcher,会一直被保存在客户端 ZKWatchManager 的 defaultWatcher 中, 代码如下: public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly, HostProvider aHostProvider, ZKClientConfig clientConfig) throws IOException &amp;#123; LOG.info(\"Initiating client connection, connectString=\" + connectString + \" sessionTimeout=\" + sessionTimeout + \" watcher=\" + watcher); if (clientConfig == null) &amp;#123; clientConfig = new ZKClientConfig(); &amp;#125; this.clientConfig = clientConfig; this.watchManager = this.defaultWatchManager(); // 这里将watcher 设置到ZKWatchManager this.watchManager.defaultWatcher = watcher; ConnectStringParser connectStringParser = new ConnectStringParser(connectString); this.hostProvider = aHostProvider; this.cnxn = new ClientCnxn(connectStringParser.getChrootPath(), this.hostProvider, sessionTimeout, this, this.watchManager, this.getClientCnxnSocket(), canBeReadOnly); this.cnxn.start(); &amp;#125; ClientCnxn : 是zookeeper 客户端和zookeeper 服务端进行通信和事件通知处理的主要类, 它主要包含两个类: SendThread : 负责客户端和服务端的数据通信, 也包括事件信息的传输 EventThread : 主要在客户端回调注册的watcher 进行通知处理. ClientCnxn 初始化 public ClientCnxn(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) &amp;#123; this.authInfo = new CopyOnWriteArraySet(); this.pendingQueue = new LinkedList(); this.outgoingQueue = new LinkedBlockingDeque(); this.sessionPasswd = new byte[16]; this.closing = false; this.seenRwServerBefore = false; this.eventOfDeath = new Object(); this.xid = 1; this.state = States.NOT_CONNECTED; this.zooKeeper = zooKeeper; this.watcher = watcher; this.sessionId = sessionId; this.sessionPasswd = sessionPasswd; this.sessionTimeout = sessionTimeout; this.hostProvider = hostProvider; this.chrootPath = chrootPath; this.connectTimeout = sessionTimeout / hostProvider.size(); this.readTimeout = sessionTimeout * 2 / 3; this.readOnly = canBeReadOnly; //初始化sendThread this.sendThread = new ClientCnxn.SendThread(clientCnxnSocket); // 初始化eventThread this.eventThread = new ClientCnxn.EventThread(); this.clientConfig = zooKeeper.getClientConfig(); &amp;#125; public void start() &amp;#123; // 启动两个线程 this.sendThread.start(); this.eventThread.start(); &amp;#125; 服务端接收请求处理流程服务端有一个 NIOServerCnxn 类, 有来处理客户端发送过来的请求 NIOServerCnxnZookeeperServer.processPacket(this, bb); public void processPacket(ServerCnxn cnxn, ByteBuffer incomingBuffer) throws IOException &amp;#123; // We have the request, now process and setup for next InputStream bais = new ByteBufferInputStream(incomingBuffer); BinaryInputArchive bia = BinaryInputArchive.getArchive(bais); RequestHeader h = new RequestHeader(); h.deserialize(bia, \"header\"); // Through the magic of byte buffers, txn will not be // pointing // to the start of the txn incomingBuffer = incomingBuffer.slice(); // 判断当前操作类型, 如果是auth操作, 就直接以下代码 if (h.getType() == OpCode.auth) &amp;#123; LOG.info(\"got auth packet \" + cnxn.getRemoteSocketAddress()); AuthPacket authPacket = new AuthPacket(); ByteBufferInputStream.byteBuffer2Record(incomingBuffer, authPacket); String scheme = authPacket.getScheme(); AuthenticationProvider ap = ProviderRegistry.getProvider(scheme); Code authReturn = KeeperException.Code.AUTHFAILED; if(ap != null) &amp;#123; try &amp;#123; authReturn = ap.handleAuthentication(cnxn, authPacket.getAuth()); &amp;#125; catch(RuntimeException e) &amp;#123; LOG.warn(\"Caught runtime exception from AuthenticationProvider: \" + scheme + \" due to \" + e); authReturn = KeeperException.Code.AUTHFAILED; &amp;#125; &amp;#125; if (authReturn!= KeeperException.Code.OK) &amp;#123; if (ap == null) &amp;#123; LOG.warn(\"No authentication provider for scheme: \" + scheme + \" has \" + ProviderRegistry.listProviders()); &amp;#125; else &amp;#123; LOG.warn(\"Authentication failed for scheme: \" + scheme); &amp;#125; // send a response... ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.AUTHFAILED.intValue()); cnxn.sendResponse(rh, null, null); // ... and close connection cnxn.sendBuffer(ServerCnxnFactory.closeConn); cnxn.disableRecv(); &amp;#125; else &amp;#123; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Authentication succeeded for scheme: \" + scheme); &amp;#125; LOG.info(\"auth success \" + cnxn.getRemoteSocketAddress()); ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.OK.intValue()); cnxn.sendResponse(rh, null, null); &amp;#125; return; &amp;#125; else &amp;#123; if (h.getType() == OpCode.sasl) &amp;#123; Record rsp = processSasl(incomingBuffer,cnxn); ReplyHeader rh = new ReplyHeader(h.getXid(), 0, KeeperException.Code.OK.intValue()); cnxn.sendResponse(rh,rsp, \"response\"); // not sure about 3rd arg..what is it? return; &amp;#125; else &amp;#123; // 最终进入这个代码块进行处理 // 封装请求对象 Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(), h.getType(), incomingBuffer, cnxn.getAuthInfo()); si.setOwner(ServerCnxn.me); submitRequest(si); &amp;#125; &amp;#125; cnxn.incrOutstandingRequests(h); &amp;#125; submitRequest负责在服务端提交当前请求. public void submitRequest(Request si) &amp;#123; if (firstProcessor == null) &amp;#123; synchronized (this) &amp;#123; try &amp;#123; // Since all requests are passed to the request // processor it should wait for setting up the request // processor chain. The state will be updated to RUNNING // after the setup. while (state == State.INITIAL) &amp;#123; wait(1000); &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; LOG.warn(\"Unexpected interruption\", e); &amp;#125; if (firstProcessor == null || state != State.RUNNING) &amp;#123; throw new RuntimeException(\"Not started\"); &amp;#125; &amp;#125; &amp;#125; try &amp;#123; touch(si.cnxn); // 判断是否合法 boolean validpacket = Request.isValid(si.type); if (validpacket) &amp;#123; // 调用firstProcessor 发起请求, firstProcessor 是一个接口, 有多个实现类, firstProcessor.processRequest(si); if (si.cnxn != null) &amp;#123; incInProcess(); &amp;#125; &amp;#125; else &amp;#123; LOG.warn(\"Received packet at server of unknown type \" + si.type); new UnimplementedRequestProcessor().processRequest(si); &amp;#125; &amp;#125; catch (MissingSessionException e) &amp;#123; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Dropping request: \" + e.getMessage()); &amp;#125; &amp;#125; catch (RequestProcessorException e) &amp;#123; LOG.error(\"Unable to process request:\" + e.getMessage(), e); &amp;#125; &amp;#125; firstProcessor 请求链组成 firstProcessor 的初始化是在 ZookeeperServer 的 setupRequestProcessor 中完成的, 代码如下: protected void setupRequestProcessors() &amp;#123; RequestProcessor finalProcessor = new FinalRequestProcessor(this); RequestProcessor syncProcessor = new SyncRequestProcessor(this, finalProcessor); ((SyncRequestProcessor)syncProcessor).start(); firstProcessor = new PrepRequestProcessor(this, syncProcessor); ((PrepRequestProcessor)firstProcessor).start(); &amp;#125; 从上面我们可以看到 firstProcessor 的实例是一个PrepRequestProcessor, 而这个构造方法中又传递到了一个Processor 构成一个调用链. RequestProcessor syncProcessor = new SyncRequestProcessor(this, finalProcessor); 而syncProcessor 的构造方法传递的又是一个Processor , 对应的是 FinalRequestProcessor . 所以整个调用链是 PrepRequestProcessor -&gt; SyncRequestProcessor - &gt;FinalRequestProcessor PredRequestProcessor.processRequest(si);通过上面了解到调用链关系后, 我们继续往下看 firstProcessor.processRequest(si)； , 会调用到 PrepRequestProcessor . public void processRequest(Request request) &amp;#123; // request.addRQRec(\">prep=\"+zks.outstandingChanges.size()); submittedRequests.add(request); &amp;#125; processRequest 只是把request 添加到 submittedRequests 中, 这是一个异步操作, submittedRequests 是一个阻塞队列. LinkedBlockingQueue&lt;Request&gt; submittedRequests = new LinkedBlockingQueue&lt;Request&gt;(); 而 PrepRequestProcessor 这个类又继承了线程类, 因此我们直接找到当前类中的run方法如下: public void run() &amp;#123; try &amp;#123; while (true) &amp;#123; Request request = submittedRequests.take(); long traceMask = ZooTrace.CLIENT_REQUEST_TRACE_MASK; if (request.type == OpCode.ping) &amp;#123; traceMask = ZooTrace.CLIENT_PING_TRACE_MASK; &amp;#125; if (LOG.isTraceEnabled()) &amp;#123; ZooTrace.logRequest(LOG, traceMask, 'P', request, \"\"); &amp;#125; if (Request.requestOfDeath == request) &amp;#123; break; &amp;#125; pRequest(request); &amp;#125; &amp;#125; catch (RequestProcessorException e) &amp;#123; if (e.getCause() instanceof XidRolloverException) &amp;#123; LOG.info(e.getCause().getMessage()); &amp;#125; handleException(this.getName(), e); &amp;#125; catch (Exception e) &amp;#123; handleException(this.getName(), e); &amp;#125; LOG.info(\"PrepRequestProcessor exited loop!\"); &amp;#125; pRequest protected void pRequest(Request request) throws RequestProcessorException &amp;#123; // LOG.info(\"Prep>>> cxid = \" + request.cxid + \" type = \" + // request.type + \" id = 0x\" + Long.toHexString(request.sessionId)); request.hdr = null; request.txn = null; try &amp;#123; switch (request.type) &amp;#123; case OpCode.create: CreateRequest createRequest = new CreateRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, createRequest, true); break; case OpCode.delete: DeleteRequest deleteRequest = new DeleteRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, deleteRequest, true); break; case OpCode.setData: SetDataRequest setDataRequest = new SetDataRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, setDataRequest, true); break; case OpCode.setACL: SetACLRequest setAclRequest = new SetACLRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, setAclRequest, true); break; case OpCode.check: CheckVersionRequest checkRequest = new CheckVersionRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, checkRequest, true); break; case OpCode.multi: MultiTransactionRecord multiRequest = new MultiTransactionRecord(); try &amp;#123; ByteBufferInputStream.byteBuffer2Record(request.request, multiRequest); &amp;#125; catch(IOException e) &amp;#123; request.hdr = new TxnHeader(request.sessionId, request.cxid, zks.getNextZxid(), Time.currentWallTime(), OpCode.multi); throw e; &amp;#125; List&lt;Txn> txns = new ArrayList&lt;Txn>(); //Each op in a multi-op must have the same zxid! long zxid = zks.getNextZxid(); KeeperException ke = null; //Store off current pending change records in case we need to rollback HashMap&lt;String, ChangeRecord> pendingChanges = getPendingChanges(multiRequest); int index = 0; for(Op op: multiRequest) &amp;#123; Record subrequest = op.toRequestRecord() ; /* If we've already failed one of the ops, don't bother * trying the rest as we know it's going to fail and it * would be confusing in the logfiles. */ if (ke != null) &amp;#123; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(Code.RUNTIMEINCONSISTENCY.intValue()); &amp;#125; /* Prep the request and convert to a Txn */ else &amp;#123; try &amp;#123; pRequest2Txn(op.getType(), zxid, request, subrequest, false); &amp;#125; catch (KeeperException e) &amp;#123; ke = e; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(e.code().intValue()); LOG.info(\"Got user-level KeeperException when processing \" + request.toString() + \" aborting remaining multi ops.\" + \" Error Path:\" + e.getPath() + \" Error:\" + e.getMessage()); request.setException(e); /* Rollback change records from failed multi-op */ rollbackPendingChanges(zxid, pendingChanges); &amp;#125; &amp;#125; //FIXME: I don't want to have to serialize it here and then // immediately deserialize in next processor. But I'm // not sure how else to get the txn stored into our list. ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); request.txn.serialize(boa, \"request\") ; ByteBuffer bb = ByteBuffer.wrap(baos.toByteArray()); txns.add(new Txn(request.hdr.getType(), bb.array())); index++; &amp;#125; request.hdr = new TxnHeader(request.sessionId, request.cxid, zxid, Time.currentWallTime(), request.type); request.txn = new MultiTxn(txns); break; //create/close session don't require request record case OpCode.createSession: case OpCode.closeSession: pRequest2Txn(request.type, zks.getNextZxid(), request, null, true); break; //All the rest don't need to create a Txn - just verify session case OpCode.sync: case OpCode.exists: case OpCode.getData: case OpCode.getACL: case OpCode.getChildren: case OpCode.getChildren2: case OpCode.ping: case OpCode.setWatches: zks.sessionTracker.checkSession(request.sessionId, request.getOwner()); break; default: LOG.warn(\"unknown type \" + request.type); break; &amp;#125; &amp;#125; catch (KeeperException e) &amp;#123; if (request.hdr != null) &amp;#123; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(e.code().intValue()); &amp;#125; LOG.info(\"Got user-level KeeperException when processing \" + request.toString() + \" Error Path:\" + e.getPath() + \" Error:\" + e.getMessage()); request.setException(e); &amp;#125; catch (Exception e) &amp;#123; // log at error level as we are returning a marshalling // error to the user LOG.error(\"Failed to process \" + request, e); StringBuilder sb = new StringBuilder(); ByteBuffer bb = request.request; if(bb != null)&amp;#123; bb.rewind(); while (bb.hasRemaining()) &amp;#123; sb.append(Integer.toHexString(bb.get() &amp; 0xff)); &amp;#125; &amp;#125; else &amp;#123; sb.append(\"request buffer is null\"); &amp;#125; LOG.error(\"Dumping request buffer: 0x\" + sb.toString()); if (request.hdr != null) &amp;#123; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(Code.MARSHALLINGERROR.intValue()); &amp;#125; &amp;#125; request.zxid = zks.getZxid(); nextProcessor.processRequest(request); &amp;#125; 前面的N行代码都是根据当前的OP 类型进行判断和做相应的处理, 这个方法中的最后一行中, 我们会看到 nextProcessor.processRequest(request); SyncRequestProcessor. processRequest public void processRequest(Request request) &amp;#123; // request.addRQRec(\">sync\"); queuedRequests.add(request); &amp;#125; 这个方法的代码也是一样, 基于差异化操作, 把请求添加到queuedRequests中, 我们继续在当前类中找到run方法 public void run() &amp;#123; try &amp;#123; int logCount = 0; // we do this in an attempt to ensure that not all of the servers // in the ensemble take a snapshot at the same time setRandRoll(r.nextInt(snapCount/2)); while (true) &amp;#123; Request si = null; if (toFlush.isEmpty()) &amp;#123; si = queuedRequests.take(); &amp;#125; else &amp;#123; si = queuedRequests.poll(); if (si == null) &amp;#123; flush(toFlush); continue; &amp;#125; &amp;#125; if (si == requestOfDeath) &amp;#123; break; &amp;#125; if (si != null) &amp;#123; // track the number of records written to the log if (zks.getZKDatabase().append(si)) &amp;#123; logCount++; if (logCount > (snapCount / 2 + randRoll)) &amp;#123; setRandRoll(r.nextInt(snapCount/2)); // roll the log zks.getZKDatabase().rollLog(); // take a snapshot if (snapInProcess != null &amp;&amp; snapInProcess.isAlive()) &amp;#123; LOG.warn(\"Too busy to snap, skipping\"); &amp;#125; else &amp;#123; snapInProcess = new ZooKeeperThread(\"Snapshot Thread\") &amp;#123; public void run() &amp;#123; try &amp;#123; zks.takeSnapshot(); &amp;#125; catch(Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); &amp;#125; &amp;#125; &amp;#125;; snapInProcess.start(); &amp;#125; logCount = 0; &amp;#125; &amp;#125; else if (toFlush.isEmpty()) &amp;#123; // optimization for read heavy workloads // iff this is a read, and there are no pending // flushes (writes), then just pass this to the next // processor if (nextProcessor != null) &amp;#123; nextProcessor.processRequest(si); if (nextProcessor instanceof Flushable) &amp;#123; ((Flushable)nextProcessor).flush(); &amp;#125; &amp;#125; continue; &amp;#125; toFlush.add(si); if (toFlush.size() > 1000) &amp;#123; flush(toFlush); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; handleException(this.getName(), t); running = false; &amp;#125; LOG.info(\"SyncRequestProcessor exited!\"); &amp;#125; FinalRequestProcessor. processRequest FinalRequestProcessor. processRequest 方法根据request方法中的操作更新内容中session 信息或者znode数据。 这块代码又300行, 就不全部贴出来了, 我们直接定位到关键代码，根据客户端的OP 类型找到如下代码: case OpCode.exists: &amp;#123; lastOp = \"EXIS\"; // TODO we need to figure out the security requirement for this! // 反序列化(将byteBuffer反序列化为ExistsRequest, 这个就是我们在客户端请求的时候传过来的request对象) ExistsRequest existsRequest = new ExistsRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, existsRequest); String path = existsRequest.getPath(); if (path.indexOf('\\0') != -1) &amp;#123; throw new KeeperException.BadArgumentsException(); &amp;#125; // 终于找到一个很关键的代码, 判断请求的getwatch 是否存在, 如果存在,则传入 cnxn // 对于exits 请求, 需要监听data 变化事件, 添加watch Stat stat = zks.getZKDatabase().statNode(path, existsRequest .getWatch() ? cnxn : null); // 在服务端内存数据库中根据路径得到结果进行封装, 设置为ExistsResponse rsp = new ExistsResponse(stat); break; 客户端接收服务端处理完成的响应 ClientCnxnSocketNIO.doIO 服务端处理完成后, 会通过 NIOServerCnxn.sendResponse 发送返回的响应信息, 客户端会在 ClientCnxnSocketNIO.doIO 接收服务端的返回. 注意一下 SendThread.readResponse ,接收服务端的信息机进行读取. void doIO(List&lt;Packet> pendingQueue, LinkedList&lt;Packet> outgoingQueue, ClientCnxn cnxn) throws InterruptedException, IOException &amp;#123; SocketChannel sock = (SocketChannel) sockKey.channel(); if (sock == null) &amp;#123; throw new IOException(\"Socket is null!\"); &amp;#125; if (sockKey.isReadable()) &amp;#123; int rc = sock.read(incomingBuffer); if (rc &lt; 0) &amp;#123; throw new EndOfStreamException( \"Unable to read additional data from server sessionid 0x\" + Long.toHexString(sessionId) + \", likely server has closed socket\"); &amp;#125; if (!incomingBuffer.hasRemaining()) &amp;#123; incomingBuffer.flip(); if (incomingBuffer == lenBuffer) &amp;#123; recvCount++; readLength(); &amp;#125; else if (!initialized) &amp;#123; readConnectResult(); enableRead(); if (findSendablePacket(outgoingQueue, cnxn.sendThread.clientTunneledAuthenticationInProgress()) != null) &amp;#123; // Since SASL authentication has completed (if client is configured to do so), // outgoing packets waiting in the outgoingQueue can now be sent. enableWrite(); &amp;#125; lenBuffer.clear(); incomingBuffer = lenBuffer; updateLastHeard(); initialized = true; &amp;#125; else &amp;#123; sendThread.readResponse(incomingBuffer); lenBuffer.clear(); incomingBuffer = lenBuffer; updateLastHeard(); &amp;#125; &amp;#125; &amp;#125; if (sockKey.isWritable()) &amp;#123; synchronized(outgoingQueue) &amp;#123; Packet p = findSendablePacket(outgoingQueue, cnxn.sendThread.clientTunneledAuthenticationInProgress()); if (p != null) &amp;#123; updateLastSend(); // If we already started writing p, p.bb will already exist if (p.bb == null) &amp;#123; if ((p.requestHeader != null) &amp;&amp; (p.requestHeader.getType() != OpCode.ping) &amp;&amp; (p.requestHeader.getType() != OpCode.auth)) &amp;#123; p.requestHeader.setXid(cnxn.getXid()); &amp;#125; p.createBB(); &amp;#125; sock.write(p.bb); if (!p.bb.hasRemaining()) &amp;#123; sentCount++; outgoingQueue.removeFirstOccurrence(p); if (p.requestHeader != null &amp;&amp; p.requestHeader.getType() != OpCode.ping &amp;&amp; p.requestHeader.getType() != OpCode.auth) &amp;#123; synchronized (pendingQueue) &amp;#123; pendingQueue.add(p); &amp;#125; &amp;#125; &amp;#125; &amp;#125; if (outgoingQueue.isEmpty()) &amp;#123; // No more packets to send: turn off write interest flag. // Will be turned on later by a later call to enableWrite(), // from within ZooKeeperSaslClient (if client is configured // to attempt SASL authentication), or in either doIO() or // in doTransport() if not. disableWrite(); &amp;#125; else if (!initialized &amp;&amp; p != null &amp;&amp; !p.bb.hasRemaining()) &amp;#123; // On initial connection, write the complete connect request // packet, but then disable further writes until after // receiving a successful connection response. If the // session is expired, then the server sends the expiration // response and immediately closes its end of the socket. If // the client is simultaneously writing on its end, then the // TCP stack may choose to abort with RST, in which case the // client would never receive the session expired event. See // http://docs.oracle.com/javase/6/docs/technotes/guides/net/articles/connection_release.html disableWrite(); &amp;#125; else &amp;#123; // Just in case enableWrite(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; SendThread. readResponse这个方法里面主要流程如下: 读取head, 如果其xid ==2, 表明是一个ping 的reponse,return 如果xid == 4,表明是一个 AuthPacket 的 response return 如果xid ==1, 表明是一个 notification , 此时要继续读取并构造一个event, 通过 EventThread.queueEvent , 并return. 其他情况下: 从 pendingQueue 中拿出一个 Packet，校验后更新 packet 信息. void readResponse(ByteBuffer incomingBuffer) throws IOException &amp;#123; ByteBufferInputStream bbis = new ByteBufferInputStream( incomingBuffer); BinaryInputArchive bbia = BinaryInputArchive.getArchive(bbis); ReplyHeader replyHdr = new ReplyHeader(); // 反序列化header replyHdr.deserialize(bbia, \"header\"); if (replyHdr.getXid() == -2) &amp;#123; // -2 is the xid for pings if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got ping response for sessionid: 0x\" + Long.toHexString(sessionId) + \" after \" + ((System.nanoTime() - lastPingSentNs) / 1000000) + \"ms\"); &amp;#125; return; &amp;#125; if (replyHdr.getXid() == -4) &amp;#123; // -4 is the xid for AuthPacket if(replyHdr.getErr() == KeeperException.Code.AUTHFAILED.intValue()) &amp;#123; state = States.AUTH_FAILED; eventThread.queueEvent( new WatchedEvent(Watcher.Event.EventType.None, Watcher.Event.KeeperState.AuthFailed, null) ); &amp;#125; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got auth sessionid:0x\" + Long.toHexString(sessionId)); &amp;#125; return; &amp;#125; // 表示当前的消息类型为一个notification(意味着是服务端的一个响应事件) if (replyHdr.getXid() == -1) &amp;#123; // -1 means notification if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got notification sessionid:0x\" + Long.toHexString(sessionId)); &amp;#125; WatcherEvent event = new WatcherEvent(); // 反序列化响应信息 event.deserialize(bbia, \"response\"); // convert from a server path to a client path if (chrootPath != null) &amp;#123; String serverPath = event.getPath(); if(serverPath.compareTo(chrootPath)==0) event.setPath(\"/\"); else if (serverPath.length() > chrootPath.length()) event.setPath(serverPath.substring(chrootPath.length())); else &amp;#123; LOG.warn(\"Got server path \" + event.getPath() + \" which is too short for chroot path \" + chrootPath); &amp;#125; &amp;#125; WatchedEvent we = new WatchedEvent(event); if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got \" + we + \" for sessionid 0x\" + Long.toHexString(sessionId)); &amp;#125; eventThread.queueEvent( we ); return; &amp;#125; // If SASL authentication is currently in progress, construct and // send a response packet immediately, rather than queuing a // response as with other packets. if (clientTunneledAuthenticationInProgress()) &amp;#123; GetSASLRequest request = new GetSASLRequest(); request.deserialize(bbia,\"token\"); zooKeeperSaslClient.respondToServer(request.getToken(), ClientCnxn.this); return; &amp;#125; Packet packet; synchronized (pendingQueue) &amp;#123; if (pendingQueue.size() == 0) &amp;#123; throw new IOException(\"Nothing in the queue, but got \" + replyHdr.getXid()); &amp;#125; // 因为当前的数据包已经收到了响应,所以将他从pendingQueue 中移除了. packet = pendingQueue.remove(); &amp;#125; /* * Since requests are processed in order, we better get a response * to the first request! */ // 校验 数据包信息, 校验成功后将数据包信息进行更新(替换为服务端信息) try &amp;#123; if (packet.requestHeader.getXid() != replyHdr.getXid()) &amp;#123; packet.replyHeader.setErr( KeeperException.Code.CONNECTIONLOSS.intValue()); throw new IOException(\"Xid out of order. Got Xid \" + replyHdr.getXid() + \" with err \" + + replyHdr.getErr() + \" expected Xid \" + packet.requestHeader.getXid() + \" for a packet with details: \" + packet ); &amp;#125; packet.replyHeader.setXid(replyHdr.getXid()); packet.replyHeader.setErr(replyHdr.getErr()); packet.replyHeader.setZxid(replyHdr.getZxid()); if (replyHdr.getZxid() > 0) &amp;#123; lastZxid = replyHdr.getZxid(); &amp;#125; if (packet.response != null &amp;&amp; replyHdr.getErr() == 0) &amp;#123; // 获取服务端的响应, 反序列化之后设置到packet.response 属性中, 所以我们可以在exits方法的最后一行中通过packet.response 拿到该请求的返回结果 packet.response.deserialize(bbia, \"response\"); &amp;#125; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Reading reply sessionid:0x\" + Long.toHexString(sessionId) + \", packet:: \" + packet); &amp;#125; &amp;#125; finally &amp;#123; // 最后调用finishPacket 方法完成处理 finishPacket(packet); &amp;#125; &amp;#125; finishPacket 方法主要功能是把从packet 中取出对应的Watcher 注册到 ZKWatchManager 中. private void finishPacket(Packet p) &amp;#123; if (p.watchRegistration != null) &amp;#123; // 将事件注册到 zkwatchermanage 中 // watchRegistration, 在组装请求的时候,我们初始化了这个对象, 把 watchRegistration 子类里面的 // watcher 实例放到了ZKWatcherMananage 的exists watches 中存储起来 p.watchRegistration.register(p.replyHeader.getErr()); &amp;#125; // cb 就是AsnycCallback，如果为null, 表明是同步调用地方接口,不需要异步回调, 因为直接notifyAll if (p.cb == null) &amp;#123; synchronized (p) &amp;#123; p.finished = true; p.notifyAll(); &amp;#125; &amp;#125; else &amp;#123; p.finished = true; eventThread.queuePacket(p); &amp;#125; &amp;#125; watchRegistration.register public void register(int rc) &amp;#123; if (shouldAddWatch(rc)) &amp;#123; // 通过子类的实现取得 ZKWatchManager 中的 existsWatches Map&lt;String, Set&lt;Watcher>> watches = getWatches(rc); synchronized(watches) &amp;#123; Set&lt;Watcher> watchers = watches.get(clientPath); if (watchers == null) &amp;#123; watchers = new HashSet&lt;Watcher>(); watches.put(clientPath, watchers); &amp;#125; // 将watcher 对象放到到 ZKWatchManager 中的 existsWatches 里面 watchers.add(watcher); &amp;#125; &amp;#125; &amp;#125; 下面这段代码是客户端存储watcher的几个map 集合, 分别对应三种注册监听事件. private static class ZKWatchManager implements ClientWatchManager &amp;#123; private final Map&lt;String, Set&lt;Watcher>> dataWatches = new HashMap&lt;String, Set&lt;Watcher>>(); private final Map&lt;String, Set&lt;Watcher>> existWatches = new HashMap&lt;String, Set&lt;Watcher>>(); private final Map&lt;String, Set&lt;Watcher>> childWatches = new HashMap&lt;String, Set&lt;Watcher>>(); 总的来说, 当使用zookeeper 构造方法或者使用getData、exits和getChildren 三个接口来向zookeeper 服务器注册watcher 的时候, 首先将此消息传递给服务端, 传递成功后, 服务端会通知客户端, 然后客户端将该路径和watcher 对应关系存储起来备用. EventThread.queuePacket() finishPacket 方法最终会调用 EventThread.queuePacket() , 将当前的数据包添加到等待事件通知的队列中. public void queuePacket(Packet packet) &amp;#123; if (wasKilled) &amp;#123; synchronized (waitingEvents) &amp;#123; if (isRunning) waitingEvents.add(packet); else processEvent(packet); &amp;#125; &amp;#125; else &amp;#123; waitingEvents.add(packet); &amp;#125; &amp;#125; 事件触发通过那么长的说明, 只是为了清晰的说明事件的注册流程, 最终的触发, 还得需要通过事务性操作来完成. 在我们最开始的案例中,通过如下代码来完成事件的触发: zooKeeper.setData(path, “1”.getBytes(), -1); 前面的客户端和服务端对戒的流程就不重复讲解了, 交互流程是一样的, 唯一的差别就是在于事件触发了. 服务端的事件响应 DataTree.setData() public Stat setData(String path, byte data[], int version, long zxid, long time) throws KeeperException.NoNodeException &amp;#123; Stat s = new Stat(); DataNode n = nodes.get(path); if (n == null) &amp;#123; throw new KeeperException.NoNodeException(); &amp;#125; byte lastdata[] = null; synchronized (n) &amp;#123; lastdata = n.data; n.data = data; n.stat.setMtime(time); n.stat.setMzxid(zxid); n.stat.setVersion(version); n.copyStat(s); &amp;#125; // now update if the path is in a quota subtree. String lastPrefix; if((lastPrefix = getMaxPrefixWithQuota(path)) != null) &amp;#123; this.updateBytes(lastPrefix, (data == null ? 0 : data.length) - (lastdata == null ? 0 : lastdata.length)); &amp;#125; // 触发对应节点的NodeDataChanged 事件 dataWatches.triggerWatch(path, EventType.NodeDataChanged); return s; &amp;#125; WatcherManager. triggerWatch public Set&lt;Watcher> triggerWatch(String path, EventType type) &amp;#123; return triggerWatch(path, type, null); &amp;#125; public Set&lt;Watcher> triggerWatch(String path, EventType type, Set&lt;Watcher> supress) &amp;#123; // 根据事件类型、连接状态、节点路径创建WatchedEvent WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); HashSet&lt;Watcher> watchers; synchronized (this) &amp;#123; // 从watcher 中移除path, 并返回其对应的watcher 集合. watchers = watchTable.remove(path); if (watchers == null || watchers.isEmpty()) &amp;#123; if (LOG.isTraceEnabled()) &amp;#123; ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, \"No watchers for \" + path); &amp;#125; return null; &amp;#125; // 遍历watcher 集合 for (Watcher w : watchers) &amp;#123; // 根据watcher 从watcher 表中取出路径集合 HashSet&lt;String> paths = watch2Paths.get(w); if (paths != null) &amp;#123; // 移除路径 paths.remove(path); &amp;#125; &amp;#125; &amp;#125; // 遍历watcher 集合 for (Watcher w : watchers) &amp;#123; if (supress != null &amp;&amp; supress.contains(w)) &amp;#123; continue; &amp;#125; w.process(e); &amp;#125; return watchers; &amp;#125; w.process(e);还记得我们在服务端绑定事件的时候，watcher 绑定的是什么吗? 是 ServerCnxn， 所以w.process(e); , 其实就是调用的是 ServerCnxn 的process 方法, 而ServerCnxn 又是一个抽象方法, 分别是 NIOServerCnxn 和 NettyServerCnxn。那接下来我们扒开 NettyServerCnxn这个类的process 方法看看究竟. @Override public void process(WatchedEvent event) &amp;#123; ReplyHeader h = new ReplyHeader(-1, -1L, 0); if (LOG.isTraceEnabled()) &amp;#123; ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, \"Deliver event \" + event + \" to 0x\" + Long.toHexString(this.sessionId) + \" through \" + this); &amp;#125; // Convert WatchedEvent to a type that can be sent over the wire WatcherEvent e = event.getWrapper(); try &amp;#123; // 这个地方发送了一个事件,事件对象为WatchedEvent sendResponse(h, e, \"notification\"); &amp;#125; catch (IOException e1) &amp;#123; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Problem sending to \" + getRemoteSocketAddress(), e1); &amp;#125; close(); &amp;#125; &amp;#125; 那接下来, 客户端会受到这个response, 触发SendThread.readResponse 方法 客户端处理事件响应SendThread.readResponsewatcher.materializwatcher.materializ这块代码已经贴过了, 我们只挑选当前流程的代码进行讲解, 按照我们前面讲到的, notifacation 通知消息的xid 为-1, u意味着直接找到-1的判断进行分析 void readResponse(ByteBuffer incomingBuffer) throws IOException &amp;#123; ByteBufferInputStream bbis = new ByteBufferInputStream( incomingBuffer); BinaryInputArchive bbia = BinaryInputArchive.getArchive(bbis); ReplyHeader replyHdr = new ReplyHeader(); // 反序列化header replyHdr.deserialize(bbia, \"header\"); if (replyHdr.getXid() == -2) &amp;#123; // -2 is the xid for pings if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got ping response for sessionid: 0x\" + Long.toHexString(sessionId) + \" after \" + ((System.nanoTime() - lastPingSentNs) / 1000000) + \"ms\"); &amp;#125; return; &amp;#125; if (replyHdr.getXid() == -4) &amp;#123; // -4 is the xid for AuthPacket if(replyHdr.getErr() == KeeperException.Code.AUTHFAILED.intValue()) &amp;#123; state = States.AUTH_FAILED; eventThread.queueEvent( new WatchedEvent(Watcher.Event.EventType.None, Watcher.Event.KeeperState.AuthFailed, null) ); &amp;#125; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got auth sessionid:0x\" + Long.toHexString(sessionId)); &amp;#125; return; &amp;#125; // 表示当前的消息类型为一个notification(意味着是服务端的一个响应事件) if (replyHdr.getXid() == -1) &amp;#123; // -1 means notification if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got notification sessionid:0x\" + Long.toHexString(sessionId)); &amp;#125; WatcherEvent event = new WatcherEvent(); // 反序列化响应信息 event.deserialize(bbia, \"response\"); // convert from a server path to a client path if (chrootPath != null) &amp;#123; String serverPath = event.getPath(); if(serverPath.compareTo(chrootPath)==0) event.setPath(\"/\"); else if (serverPath.length() > chrootPath.length()) event.setPath(serverPath.substring(chrootPath.length())); else &amp;#123; LOG.warn(\"Got server path \" + event.getPath() + \" which is too short for chroot path \" + chrootPath); &amp;#125; &amp;#125; WatchedEvent we = new WatchedEvent(event); if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Got \" + we + \" for sessionid 0x\" + Long.toHexString(sessionId)); &amp;#125; eventThread.queueEvent( we ); return; &amp;#125; // If SASL authentication is currently in progress, construct and // send a response packet immediately, rather than queuing a // response as with other packets. if (clientTunneledAuthenticationInProgress()) &amp;#123; GetSASLRequest request = new GetSASLRequest(); request.deserialize(bbia,\"token\"); zooKeeperSaslClient.respondToServer(request.getToken(), ClientCnxn.this); return; &amp;#125; Packet packet; synchronized (pendingQueue) &amp;#123; if (pendingQueue.size() == 0) &amp;#123; throw new IOException(\"Nothing in the queue, but got \" + replyHdr.getXid()); &amp;#125; // 因为当前的数据包已经收到了响应,所以将他从pendingQueue 中移除了. packet = pendingQueue.remove(); &amp;#125; /* * Since requests are processed in order, we better get a response * to the first request! */ // 校验 数据包信息, 校验成功后将数据包信息进行更新(替换为服务端信息) try &amp;#123; if (packet.requestHeader.getXid() != replyHdr.getXid()) &amp;#123; packet.replyHeader.setErr( KeeperException.Code.CONNECTIONLOSS.intValue()); throw new IOException(\"Xid out of order. Got Xid \" + replyHdr.getXid() + \" with err \" + + replyHdr.getErr() + \" expected Xid \" + packet.requestHeader.getXid() + \" for a packet with details: \" + packet ); &amp;#125; packet.replyHeader.setXid(replyHdr.getXid()); packet.replyHeader.setErr(replyHdr.getErr()); packet.replyHeader.setZxid(replyHdr.getZxid()); if (replyHdr.getZxid() > 0) &amp;#123; lastZxid = replyHdr.getZxid(); &amp;#125; if (packet.response != null &amp;&amp; replyHdr.getErr() == 0) &amp;#123; // 获取服务端的响应, 反序列化之后设置到packet.response 属性中, 所以我们可以在exits方法的最后一行中通过packet.response 拿到该请求的返回结果 packet.response.deserialize(bbia, \"response\"); &amp;#125; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Reading reply sessionid:0x\" + Long.toHexString(sessionId) + \", packet:: \" + packet); &amp;#125; &amp;#125; finally &amp;#123; // 最后调用finishPacket 方法完成处理 finishPacket(packet); &amp;#125; &amp;#125; eventThread.queueEvent SendThread 接受到服务端的通知事件, 会通过调用 EventThread 类的queueEvent 方法将事件传给 EventThread 线程, queueEvent 方法根据该通知事件, 从 ZKWatchManager 中取出所有相关的watcher, 如果获取到相应的watcher, 就会让watcher 移除失效. public void queueEvent(WatchedEvent event) &amp;#123; if (event.getType() == EventType.None &amp;&amp; sessionState == event.getState()) &amp;#123; // 判断类型 return; &amp;#125; sessionState = event.getState(); // materialize the watchers based on the event // 封装 WatcherSetEventPair 对象, 添加到waitingEvents 队列中 WatcherSetEventPair pair = new WatcherSetEventPair( watcher.materialize(event.getState(), event.getType(), event.getPath()), event); // queue the pair (watch set &amp; event) for later processing waitingEvents.add(pair); &amp;#125; watcher.materializ通过 dataWatches 或者 existWatches 或者 childWatches 的 remove 取出对应的watch, 表明客户端watch 也是注册一次就移除. 同时需要根据 keeperState、eventType 和 path 返回应该被通知的watcher 集合. @Override public Set&lt;Watcher> materialize(Watcher.Event.KeeperState state, Watcher.Event.EventType type, String clientPath) &amp;#123; Set&lt;Watcher> result = new HashSet&lt;Watcher>(); switch (type) &amp;#123; case None: result.add(defaultWatcher); boolean clear = ClientCnxn.getDisableAutoResetWatch() &amp;&amp; state != Watcher.Event.KeeperState.SyncConnected; synchronized(dataWatches) &amp;#123; for(Set&lt;Watcher> ws: dataWatches.values()) &amp;#123; result.addAll(ws); &amp;#125; if (clear) &amp;#123; dataWatches.clear(); &amp;#125; &amp;#125; synchronized(existWatches) &amp;#123; for(Set&lt;Watcher> ws: existWatches.values()) &amp;#123; result.addAll(ws); &amp;#125; if (clear) &amp;#123; existWatches.clear(); &amp;#125; &amp;#125; synchronized(childWatches) &amp;#123; for(Set&lt;Watcher> ws: childWatches.values()) &amp;#123; result.addAll(ws); &amp;#125; if (clear) &amp;#123; childWatches.clear(); &amp;#125; &amp;#125; return result; case NodeDataChanged: case NodeCreated: synchronized (dataWatches) &amp;#123; addTo(dataWatches.remove(clientPath), result); &amp;#125; synchronized (existWatches) &amp;#123; addTo(existWatches.remove(clientPath), result); &amp;#125; break; case NodeChildrenChanged: synchronized (childWatches) &amp;#123; addTo(childWatches.remove(clientPath), result); &amp;#125; break; case NodeDeleted: synchronized (dataWatches) &amp;#123; addTo(dataWatches.remove(clientPath), result); &amp;#125; // XXX This shouldn't be needed, but just in case synchronized (existWatches) &amp;#123; Set&lt;Watcher> list = existWatches.remove(clientPath); if (list != null) &amp;#123; addTo(list, result); LOG.warn(\"We are triggering an exists watch for delete! Shouldn't happen!\"); &amp;#125; &amp;#125; synchronized (childWatches) &amp;#123; addTo(childWatches.remove(clientPath), result); &amp;#125; break; default: String msg = \"Unhandled watch event type \" + type + \" with state \" + state + \" on path \" + clientPath; LOG.error(msg); throw new RuntimeException(msg); &amp;#125; return result; &amp;#125; &amp;#125; waitingEvents.add最后一步, 接近真相了. waitingEvents 是 EventThread 这个线程的祖寺啊队列, 很明显, 又是我们在第一步操作的时候实例化的一个线程. 从名字可以知道, waitingEvents 是一个待处理的watcher 的队列, EventThread 的run() 方法 会不断的从队列中取数据,交由 processEvent 方法处理 public void run() &amp;#123; try &amp;#123; isRunning = true; while (true) &amp;#123; // 从待处理的事件队列中取出事件 Object event = waitingEvents.take(); if (event == eventOfDeath) &amp;#123; wasKilled = true; &amp;#125; else &amp;#123; // 执行事件处理 processEvent(event); &amp;#125; if (wasKilled) synchronized (waitingEvents) &amp;#123; if (waitingEvents.isEmpty()) &amp;#123; isRunning = false; break; &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; LOG.error(\"Event thread exiting due to interruption\", e); &amp;#125; LOG.info(\"EventThread shut down for session: 0x&amp;#123;&amp;#125;\", Long.toHexString(getSessionId())); &amp;#125; processEvent private void processEvent(Object event) &amp;#123; try &amp;#123; // 判断事件类型, if (event instanceof WatcherSetEventPair) &amp;#123; // each watcher will process the event // 得到WatcherSetEventPair WatcherSetEventPair pair = (WatcherSetEventPair) event; // 拿到符合触发机制的所有watcher列表， 循环调用. for (Watcher watcher : pair.watchers) &amp;#123; try &amp;#123; // 调用客户端的回调process watcher.process(pair.event); &amp;#125; catch (Throwable t) &amp;#123; LOG.error(\"Error while calling watcher \", t); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; Packet p = (Packet) event; int rc = 0; String clientPath = p.clientPath; if (p.replyHeader.getErr() != 0) &amp;#123; rc = p.replyHeader.getErr(); &amp;#125; if (p.cb == null) &amp;#123; LOG.warn(\"Somehow a null cb got to EventThread!\"); &amp;#125; else if (p.response instanceof ExistsResponse || p.response instanceof SetDataResponse || p.response instanceof SetACLResponse) &amp;#123; StatCallback cb = (StatCallback) p.cb; if (rc == 0) &amp;#123; if (p.response instanceof ExistsResponse) &amp;#123; cb.processResult(rc, clientPath, p.ctx, ((ExistsResponse) p.response) .getStat()); &amp;#125; else if (p.response instanceof SetDataResponse) &amp;#123; cb.processResult(rc, clientPath, p.ctx, ((SetDataResponse) p.response) .getStat()); &amp;#125; else if (p.response instanceof SetACLResponse) &amp;#123; cb.processResult(rc, clientPath, p.ctx, ((SetACLResponse) p.response) .getStat()); &amp;#125; &amp;#125; else &amp;#123; cb.processResult(rc, clientPath, p.ctx, null); &amp;#125; &amp;#125; else if (p.response instanceof GetDataResponse) &amp;#123; DataCallback cb = (DataCallback) p.cb; GetDataResponse rsp = (GetDataResponse) p.response; if (rc == 0) &amp;#123; cb.processResult(rc, clientPath, p.ctx, rsp .getData(), rsp.getStat()); &amp;#125; else &amp;#123; cb.processResult(rc, clientPath, p.ctx, null, null); &amp;#125; &amp;#125; else if (p.response instanceof GetACLResponse) &amp;#123; ACLCallback cb = (ACLCallback) p.cb; GetACLResponse rsp = (GetACLResponse) p.response; if (rc == 0) &amp;#123; cb.processResult(rc, clientPath, p.ctx, rsp .getAcl(), rsp.getStat()); &amp;#125; else &amp;#123; cb.processResult(rc, clientPath, p.ctx, null, null); &amp;#125; &amp;#125; else if (p.response instanceof GetChildrenResponse) &amp;#123; ChildrenCallback cb = (ChildrenCallback) p.cb; GetChildrenResponse rsp = (GetChildrenResponse) p.response; if (rc == 0) &amp;#123; cb.processResult(rc, clientPath, p.ctx, rsp .getChildren()); &amp;#125; else &amp;#123; cb.processResult(rc, clientPath, p.ctx, null); &amp;#125; &amp;#125; else if (p.response instanceof GetChildren2Response) &amp;#123; Children2Callback cb = (Children2Callback) p.cb; GetChildren2Response rsp = (GetChildren2Response) p.response; if (rc == 0) &amp;#123; cb.processResult(rc, clientPath, p.ctx, rsp .getChildren(), rsp.getStat()); &amp;#125; else &amp;#123; cb.processResult(rc, clientPath, p.ctx, null, null); &amp;#125; &amp;#125; else if (p.response instanceof CreateResponse) &amp;#123; StringCallback cb = (StringCallback) p.cb; CreateResponse rsp = (CreateResponse) p.response; if (rc == 0) &amp;#123; cb.processResult(rc, clientPath, p.ctx, (chrootPath == null ? rsp.getPath() : rsp.getPath() .substring(chrootPath.length()))); &amp;#125; else &amp;#123; cb.processResult(rc, clientPath, p.ctx, null); &amp;#125; &amp;#125; else if (p.response instanceof MultiResponse) &amp;#123; MultiCallback cb = (MultiCallback) p.cb; MultiResponse rsp = (MultiResponse) p.response; if (rc == 0) &amp;#123; List&lt;OpResult> results = rsp.getResultList(); int newRc = rc; for (OpResult result : results) &amp;#123; if (result instanceof ErrorResult &amp;&amp; KeeperException.Code.OK.intValue() != (newRc = ((ErrorResult) result).getErr())) &amp;#123; break; &amp;#125; &amp;#125; cb.processResult(newRc, clientPath, p.ctx, results); &amp;#125; else &amp;#123; cb.processResult(rc, clientPath, p.ctx, null); &amp;#125; &amp;#125; else if (p.cb instanceof VoidCallback) &amp;#123; VoidCallback cb = (VoidCallback) p.cb; cb.processResult(rc, clientPath, p.ctx); &amp;#125; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; LOG.error(\"Caught unexpected throwable\", t); &amp;#125; &amp;#125; &amp;#125; 服务端接受数据请求.服务端收到的数据包应该在哪里呢? zookee 启动的时候, 通过下面的代码中构建了一个 ServerCnxnFactory cnxnFactory = ServerCnxnFactory.createFactory(); ServerCnxnFactory ,它实现类 Thread, 所以在启动的时候, 会在run 方法中不断循环接受客户端的请求进行分发. NIOServerCnxnFactory.run public void run() &amp;#123; while (!ss.socket().isClosed()) &amp;#123; try &amp;#123; // 获取client 的连接请求 selector.select(1000); Set&lt;SelectionKey> selected; synchronized (this) &amp;#123; selected = selector.selectedKeys(); &amp;#125; ArrayList&lt;SelectionKey> selectedList = new ArrayList&lt;SelectionKey>( selected); Collections.shuffle(selectedList); for (SelectionKey k : selectedList) &amp;#123; if ((k.readyOps() &amp; SelectionKey.OP_ACCEPT) != 0) &amp;#123; SocketChannel sc = ((ServerSocketChannel) k .channel()).accept(); InetAddress ia = sc.socket().getInetAddress(); int cnxncount = getClientCnxnCount(ia); if (maxClientCnxns > 0 &amp;&amp; cnxncount >= maxClientCnxns)&amp;#123; LOG.warn(\"Too many connections from \" + ia + \" - max is \" + maxClientCnxns ); sc.close(); &amp;#125; else &amp;#123; LOG.info(\"Accepted socket connection from \" + sc.socket().getRemoteSocketAddress()); sc.configureBlocking(false); SelectionKey sk = sc.register(selector, SelectionKey.OP_READ); NIOServerCnxn cnxn = createConnection(sc, sk); sk.attach(cnxn); addCnxn(cnxn); &amp;#125; // 处理客户端的读写请求 &amp;#125; else if ((k.readyOps() &amp; (SelectionKey.OP_READ | SelectionKey.OP_WRITE)) != 0) &amp;#123; NIOServerCnxn c = (NIOServerCnxn) k.attachment(); // 处理IO操作 c.doIO(k); &amp;#125; else &amp;#123; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Unexpected ops in select \" + k.readyOps()); &amp;#125; &amp;#125; &amp;#125; selected.clear(); &amp;#125; catch (RuntimeException e) &amp;#123; LOG.warn(\"Ignoring unexpected runtime exception\", e); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Ignoring exception\", e); &amp;#125; &amp;#125; closeAll(); LOG.info(\"NIOServerCnxn factory exited run method\"); &amp;#125; NIOServerCnxn.doIO void doIO(SelectionKey k) throws InterruptedException &amp;#123; try &amp;#123; if (isSocketOpen() == false) &amp;#123; LOG.warn(\"trying to do i/o on a null socket for session:0x\" + Long.toHexString(sessionId)); return; &amp;#125; // 处理读请求, 表示接受 if (k.isReadable()) &amp;#123; int rc = sock.read(incomingBuffer); if (rc &lt; 0) &amp;#123; throw new EndOfStreamException( \"Unable to read additional data from client sessionid 0x\" + Long.toHexString(sessionId) + \", likely client has closed socket\"); &amp;#125; if (incomingBuffer.remaining() == 0) &amp;#123; boolean isPayload; if (incomingBuffer == lenBuffer) &amp;#123; // start of next request incomingBuffer.flip(); isPayload = readLength(k); incomingBuffer.clear(); &amp;#125; else &amp;#123; // continuation isPayload = true; &amp;#125; if (isPayload) &amp;#123; // not the case for 4letterword readPayload(); &amp;#125; else &amp;#123; // four letter words take care // need not do anything else return; &amp;#125; &amp;#125; &amp;#125; if (k.isWritable()) &amp;#123; // ZooLog.logTraceMessage(LOG, // ZooLog.CLIENT_DATA_PACKET_TRACE_MASK // \"outgoingBuffers.size() = \" + // outgoingBuffers.size()); if (outgoingBuffers.size() > 0) &amp;#123; // ZooLog.logTraceMessage(LOG, // ZooLog.CLIENT_DATA_PACKET_TRACE_MASK, // \"sk \" + k + \" is valid: \" + // k.isValid()); /* * This is going to reset the buffer position to 0 and the * limit to the size of the buffer, so that we can fill it * with data from the non-direct buffers that we need to * send. */ ByteBuffer directBuffer = factory.directBuffer; directBuffer.clear(); for (ByteBuffer b : outgoingBuffers) &amp;#123; if (directBuffer.remaining() &lt; b.remaining()) &amp;#123; /* * When we call put later, if the directBuffer is to * small to hold everything, nothing will be copied, * so we've got to slice the buffer if it's too big. */ b = (ByteBuffer) b.slice().limit( directBuffer.remaining()); &amp;#125; /* * put() is going to modify the positions of both * buffers, put we don't want to change the position of * the source buffers (we'll do that after the send, if * needed), so we save and reset the position after the * copy */ int p = b.position(); directBuffer.put(b); b.position(p); if (directBuffer.remaining() == 0) &amp;#123; break; &amp;#125; &amp;#125; /* * Do the flip: limit becomes position, position gets set to * 0. This sets us up for the write. */ directBuffer.flip(); int sent = sock.write(directBuffer); ByteBuffer bb; // Remove the buffers that we have sent while (outgoingBuffers.size() > 0) &amp;#123; bb = outgoingBuffers.peek(); if (bb == ServerCnxnFactory.closeConn) &amp;#123; throw new CloseRequestException(\"close requested\"); &amp;#125; int left = bb.remaining() - sent; if (left > 0) &amp;#123; /* * We only partially sent this buffer, so we update * the position and exit the loop. */ bb.position(bb.position() + sent); break; &amp;#125; packetSent(); /* We've sent the whole buffer, so drop the buffer */ sent -= bb.remaining(); outgoingBuffers.remove(); &amp;#125; // ZooLog.logTraceMessage(LOG, // ZooLog.CLIENT_DATA_PACKET_TRACE_MASK, \"after send, // outgoingBuffers.size() = \" + outgoingBuffers.size()); &amp;#125; synchronized(this.factory)&amp;#123; if (outgoingBuffers.size() == 0) &amp;#123; if (!initialized &amp;&amp; (sk.interestOps() &amp; SelectionKey.OP_READ) == 0) &amp;#123; throw new CloseRequestException(\"responded to info probe\"); &amp;#125; sk.interestOps(sk.interestOps() &amp; (~SelectionKey.OP_WRITE)); &amp;#125; else &amp;#123; sk.interestOps(sk.interestOps() | SelectionKey.OP_WRITE); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (CancelledKeyException e) &amp;#123; LOG.warn(\"CancelledKeyException causing close of session 0x\" + Long.toHexString(sessionId)); if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"CancelledKeyException stack trace\", e); &amp;#125; close(); &amp;#125; catch (CloseRequestException e) &amp;#123; // expecting close to log session closure close(); &amp;#125; catch (EndOfStreamException e) &amp;#123; LOG.warn(e.getMessage()); if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"EndOfStreamException stack trace\", e); &amp;#125; // expecting close to log session closure close(); &amp;#125; catch (IOException e) &amp;#123; LOG.warn(\"Exception causing close of session 0x\" + Long.toHexString(sessionId) + \": \" + e.getMessage()); if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"IOException stack trace\", e); &amp;#125; close(); &amp;#125; &amp;#125; NIOServerCnxn.readRequest读取客户端的请求, 进行具体的处理 private void readRequest() throws IOException &amp;#123; zkServer.processPacket(this, incomingBuffer); &amp;#125; ZookeeperServer.processPacket这个方法根据数据包的类型来处理不同的数据包，对于读写请求, 我们主要关注下面这块代码即可. // 最终进入这个代码块进行处理 // 封装请求对象 Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(), h.getType(), incomingBuffer, cnxn.getAuthInfo()); si.setOwner(ServerCnxn.me); submitRequest(si);","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[]},{"title":"为什么要分库分表(1)","slug":"数据库/为什么要分库分表(1)","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/shu-ju-ku/wei-shi-me-yao-fen-ku-fen-biao-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/shu-ju-ku/wei-shi-me-yao-fen-ku-fen-biao-1/","excerpt":"","text":"为什么要分库分表1. 数据库性能瓶颈的出现对于应用来说, 如果是数据库性能出现问题, 要么是无法获取连接, 是因为在高并发的情况下连接数不够了。要么是操作数据变慢了, 数据库处理数据的效率出现了问题. 要么是存储出现了问题, 比如单机存储的数据量太大了, 存储的问题也可能会导致性能的问题. 归根结底都是收到了硬件的影响, 比如CPU、内存、磁盘、网络等等. 但是我们优化肯定不可能直接从扩展硬件出手, 因为带来的收益和投入比例太差. 所以我们先来分析一下, 当我们处理数据出现无法连接,或者变慢的时候, 我们可以从哪些层面入手呢? 2. 数据库优化方案对比数据库优化有很多层面 2.1 SQL 和索引因为SQL 语句是在我们应用端编写, 所以第一步,我们可以在程序中对SQL 语句进行优化, 最终的目标就是使用索引, 这个是最容易也是最常见的手段. 2.2 表与存储引擎第二步, 数据是存放在表里的,表又是以不同的格式存放在存储引擎的, 所以我们可以选用特定的存储引擎, 或者对表进行分区, 对表结构进行拆分或者冗余处理, 或者对表结构比如字段的定义进行优化. 2.3 架构第三步, 对于数据库的服务, 我们可以对他的架构进行优化. 如果只有一台数据库的服务, 我们可以运行多个实例, 做集群的方案, 做负载均衡. 或者基于主从复制实现读写分离, 让写的服务都访问master 服务器, 读的请求都访问从服务器，slave 服务器自动从master 主服务器同步数据. 或者在数据库前加一层缓存, 做到减少数据库压力, 提升访问数据库的目的. 为了分散数据库服务的存储压力和访问压力, 我们也可以把不同的数据分布到不同的服务节点, 这个就是分库分表(scale out) 注意主从(replicate)和分片(shard)的区别: 主从通过数据冗余实现高可用, 和实现读写分离 分片通过拆分数据分散存储和访问压力. 2.4 配置第四步, 是数据库配置的优化, 比如连接数、缓冲区大小等等, 优化配置的目的都是为了更高效的利用硬件. 2.5 操作系统和硬件最后一步的操作系统和硬件. 从上往下, 成本收益慢慢的在增加, 所以肯定不是查询一慢就堆硬件的, 堆硬件叫做向上的扩展. 什么时候才需要分库分表呢? 我们的评判标准是什么呢? 如果是数据量的话, 一张表存储了多少数据才需要考虑分库分表呢? 如果是数据增长速度, 每天产生多少数据,才需要考虑分库分表呢? 如果是应用的访问情况, 查询超过了多少时间, 有多少请求无法获取连接, 才需要分库分表? 这是一个值得思考的问题. 1.3 架构演进和分库分表3.1 单应用单数据库当开始的时候, 使用的都是单体架构, 单体架构的特点就是将所有的代码都放在一个工程里面,打成一个war 包部署到tomcat, 最后运行在一个工程中. 为了适用业务的发展, 当这套系统不断的修改, 当代码量越来越大的时候, 系统就变得越来越臃肿. 为了优化系统, 搭集群、负载均衡、优化数据库、加缓存、优化数据库、优化业务代码,但是都应对不了系统的压力. 所以这个时候拆分系统就势在必行了, 我们将以前的一套系统拆分成很多的子系统, 比如用户系统、管理系统等等, 但是所有的系统都是公用一个数据库. 3.2 多应用单数据库对代码进行了解耦,.职责进行了拆分, 生产环境出了问题, 可以很快的排查和解决. 但是这种子系统共用一个DB 还是会出现问题的, 无论是从性能还是存储的角度来说,都是满足不了需求的。随着我们的业务继续膨胀, 我们又会增加更多的系统来访问核心数据库, 但是一个物理数据库能够支撑的并发量是有限的, 所有的业务系统之间还是会产生竞争, 最终导致应用的性能下降, 甚至拖垮业务系统. 3.3 多应用独立数据库所以这个时候, 我们必须要对各个子系统的数据库也做一个拆分, 这个时候每个业务系统都用了自己的数据库, 不同的业务系统就可以用不同的存储方案. 所以,分库其实是我们在解决系统性能瓶颈问题的过程中, 对系统进行拆分的时候带来的一个必然的结果. 现在的微服务架构也是一样的 ,只拆分应用不拆分数据库, 不能解决根本的问题. 3.4 什么时候分表呢?当我们对原来的一个数据库的表做了拆分之后, 其中的一个表的数据还是在以很快的速度增长, 这个时候查询也已经出现了非常明显的效率下降. 所以, 在分库之后 , 还需要进一步进行分表. 当然, 我们最开始想到的可能是在一个数据库中进行拆分, 分区或者分表, 到后面才是切分到多个数据库. 分表主要是为了减少单表的大小, 解决单表数据量带来的性能问题. 我们需要清楚的是, 分库分表会提升系统的复杂度, 如果在近期或者未来一段时间内必须要解决存储或者性能的问题, 就不要去做超前的设计和过度设计. 就像我们搭建项目, 从快速实现的角度来说, 肯定是从单体项目起步的,在业务丰富完善之前, 也用不到微服务架构. 如果我们创建的表结构合理, 字段不是太多, 并且索引创建正确的情况下, 单张表存储几千万的数据是完全没有问题的, 这个还是以应用的实际情况为准。当前我们也会对未来一段时间的业务发展做一个预判.","categories":[{"name":"数据库","slug":"数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库","slug":"数据库/数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"基于Zookeeper实现分布式锁","slug":"微服务/zookpeer/基于Zookeeper实现分布式锁","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/ji-yu-zookeeper-shi-xian-fen-bu-shi-suo/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/ji-yu-zookeeper-shi-xian-fen-bu-shi-suo/","excerpt":"","text":"基于Zookeeper 实现分布式锁分布式锁的基本场景如果在多线程并行情况下去访问某一个共享资源,比如说共享变量, 那么势必会造成线程安全问题. 那么我们可以用很多种方法来解决, 比如synchronized、比如Lock 之类的锁操作来解决线程问题, 那么在分布式架构下,涉及到多个进程访问某一个共享资源的情况下, 比如说在电商平台中商品库存问题, 在库存中只有10个的情况下进来100个用户, 如果能够避免超卖呢? 所以这个时候就要一个互斥的手段来防止彼此之间的干扰. 然后在分布式情况下, synchronized 或者Lock 之类的锁只能控制单一进程的资源访问, 在多进程架构下, 这些API就没办法解决我们的问题了, 怎么办呢? 用Zookeeper 来实现分布式锁我们可以利用zoookeeper 的特性来实现独占锁, 就是同级节点的唯一性,多个进程往zookeeper的指定节点下创建一个相同名称的节点, 只有一个能成功, 另外一个是创建失败. 创建失败的节点全部通过zookeeper的watcher 机制来监听zookeeper 这个子节点的变化, 一旦监听到子节点的删除事件, 则再次触发所有进程去写锁. 这种实现方式很简单, 但是会产生”惊群效应”,简单来说, 就是如果存在修多的客户端在等待获取锁, 当成功获取到锁的进程释放该节点后, 所有处于等待状态的客户端都会被唤醒, 这个时候zookeeper 在短时间内发送大量子节点变更事件给所有待获取锁的客户端, 然后实际情况是只会有一个客户端获取锁. 如果在集群规模比较大的情况下, 会对zookeeper 服务器的性能产生比较大的影响. 利用有序节点来实现分布式锁我们可以通过有序节点来实现分布式锁, 每个客户端都往指定的节点下注册一个临时有序节点, 越早创建的节点, 节点的顺序编号就越小, 那么我们可以判断子节点中最小的节点设置为获取锁. 如果自己的节点不是所有子节点中最小的, 意味着还没有获取锁. 这个锁的实现和前面单节点的实现的差异在于, 每个节点只需要监听比自己小的节点, 当比自己小的节点删除以后, 客户端会受到watcher 事件, 此时再次判断自己的节点是不是所有子节点中最小的, 如果是则获取锁, 否则就不断重复这个过程, 这样就不会导致”惊群效应”,因为每个客户端只需要监听一个节点. curator 分布式锁的基本使用curator 对于锁这块做了一些封装, curator 提供了 InterProcessMutex 这样一个API。除了分布式锁之外, 还提供了Leader 选举,、分布式队列等常用的功能. InterProcessMutex：分布式可重入排它锁 InterProcessSemaphoreMutex：分布式排它锁 InterProcessReadWriteLock：分布式读写锁 package com.zk.demo; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.framework.recipes.locks.InterProcessLock; import org.apache.curator.framework.recipes.locks.InterProcessMultiLock; import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.retry.ExponentialBackoffRetry; /** * @author luyanan * @since 2019/11/11 * &lt;p>分布式锁&lt;/p> **/ public class LockDemo &amp;#123; public static void main(String[] args) &amp;#123; String connect = \"192.168.91.128:2181\"; CuratorFramework framework = createClient(connect); framework.start(); final InterProcessMutex lock = new InterProcessMutex(framework, \"/locks\"); for (int i = 0; i &lt; 10; i++) &amp;#123; new Thread(() -> &amp;#123; System.out.println(Thread.currentThread().getName() + \": 尝试获得锁\"); try &amp;#123; lock.acquire(); System.out.println(Thread.currentThread().getName() + \": 已经获得锁\"); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; try &amp;#123; Thread.sleep(4000); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; try &amp;#123; lock.release(); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; System.out.println(Thread.currentThread().getName() + \": 释放锁\"); &amp;#125;, \"thread-\" + i).start(); &amp;#125; &amp;#125; public static CuratorFramework createClient(String connect) &amp;#123; CuratorFramework framework = CuratorFrameworkFactory .builder() // 连接信息 .connectString(connect) // 会话超时时间 .sessionTimeoutMs(5000) //失败重试机制 //ExponentialBackoffRetry //RetryOneTime 仅仅只重试一次 //RetryUntilElapsed //RetryNTimes .retryPolicy(new ExponentialBackoffRetry(1000, 3)) .build(); return framework; &amp;#125; &amp;#125; curator 实现分布式锁的基本原理构造函数 public InterProcessMutex(CuratorFramework client, String path) &amp;#123; // Zookeeper 利用path 创建临时顺序节点, 实现公平锁的核心 this(client, path, new StandardLockInternalsDriver()); &amp;#125; public InterProcessMutex(CuratorFramework client, String path, LockInternalsDriver driver) &amp;#123; // maxLeases =1 表示可以获取分布式锁的线程数量(跨JVM)为1, 即为互斥锁 this(client, path, \"lock-\", 1, driver); &amp;#125; InterProcessMutex(CuratorFramework client, String path, String lockName, int maxLeases, LockInternalsDriver driver) &amp;#123; this.threadData = Maps.newConcurrentMap(); this.basePath = PathUtils.validatePath(path); // internals 的类型为 LockInternals, InterProcessMutex 将分布式锁的申请和释放操作委托给 internals 执行 this.internals = new LockInternals(client, driver, path, lockName, maxLeases); &amp;#125; InterProcessMutex.acquire(); 获取锁// 无限等待 public void acquire() throws Exception &amp;#123; if (!this.internalLock(-1L, (TimeUnit)null)) &amp;#123; throw new IOException(\"Lost connection while trying to acquire lock: \" + this.basePath); &amp;#125; &amp;#125; // 限时等待 public boolean acquire(long time, TimeUnit unit) throws Exception &amp;#123; return this.internalLock(time, unit); &amp;#125; InterProcessMutex.internalLock(); private boolean internalLock(long time, TimeUnit unit) throws Exception &amp;#123; Thread currentThread = Thread.currentThread(); InterProcessMutex.LockData lockData = (InterProcessMutex.LockData)this.threadData.get(currentThread); if (lockData != null) &amp;#123; // 实现可重入 // 同一个线程再次 acquire, 首先判断当前的映射表内(threadData) 是否有该线程的锁信息, 如果有, 则原子+1, 然后返回. lockData.lockCount.incrementAndGet(); return true; &amp;#125; else &amp;#123; // 映射表中没有对应的锁信息, 尝试通过LockInternals 获取锁. String lockPath = this.internals.attemptLock(time, unit, this.getLockNodeBytes()); if (lockPath != null) &amp;#123; // 成功获取锁, 记录信息到映射表 InterProcessMutex.LockData newLockData = new InterProcessMutex.LockData(currentThread, lockPath); this.threadData.put(currentThread, newLockData); return true; &amp;#125; else &amp;#123; return false; &amp;#125; &amp;#125; &amp;#125; // 映射表 // 记录线程与锁信息的映射关系 private final ConcurrentMap&lt;Thread, InterProcessMutex.LockData> threadData; // 锁信息 // Zookeeper 中一个临时顺序节点对应一个锁, 但让锁生效激活需要排队(公平锁),下面会继续分析 private static class LockData &amp;#123; final Thread owningThread; final String lockPath; // 分布式锁重入次数 final AtomicInteger lockCount; private LockData(Thread owningThread, String lockPath) &amp;#123; this.lockCount = new AtomicInteger(1); this.owningThread = owningThread; this.lockPath = lockPath; &amp;#125; &amp;#125; InterProcessMutex.attemptLock// 尝试获取锁, 并返回锁对应的zookeeper 临时顺序节点的路径 String attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception &amp;#123; long startMillis = System.currentTimeMillis(); // 无限等待时, millisToWait 为null Long millisToWait = unit != null ? unit.toMillis(time) : null; // 创建ZNode 节点时的数据内容, 无关紧要, 这里为null, 采用默认值(ip地址) byte[] localLockNodeBytes = this.revocable.get() != null ? new byte[0] : lockNodeBytes; // 当前已经重试次数, 与 CuratorFramework的重试策略有关. int retryCount = 0; // 在zookeeper 中创建的临时顺序节点的路径相当于一把待激活的分布式锁. // 激活条件: 同级目录下子节点, 名字排序最小(排队、公平锁) String ourPath = null; // 是否已经持有分布式锁. boolean hasTheLock = false; // 是否已经完成了尝试获取分布式锁的操作 boolean isDone = false; while(!isDone) &amp;#123; isDone = true; try &amp;#123; // 从InterProcessMutex 的构造函数可知实际driver 为StandardLockInternalsDriver 的实例. // 在zookeeper 中创建顺序临时节点. ourPath = this.driver.createsTheLock(this.client, this.path, localLockNodeBytes); // 循环等待来激活分布式锁, 实现锁的公平性 hasTheLock = this.internalLockLoop(startMillis, millisToWait, ourPath); &amp;#125; catch (NoNodeException var14) &amp;#123; // 容错处理 // 因为绘会话过期等原因,StandardLockInternalsDriver 因为无法找到创建的临时顺序节点而抛出NoNodeException 异常. if ( client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper()) ) &amp;#123; // 满足重试策略尝试重新获取锁 isDone = false; &amp;#125; else &amp;#123; // 不满足重试策略则继续抛出 NoNodeException 异常. throw e; &amp;#125; &amp;#125; &amp;#125; if ( hasTheLock ) &amp;#123; // 成功获取分布式锁, 返回临时顺序节点的路径, 上层将其封装成锁信息记录在映射表中, 方便锁重入 return ourPath; &amp;#125; // 获取分布式锁失败, 返回null return null; &amp;#125; createsTheLock @Override // 在zookeeper中创建临时顺序节点 public String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception &amp;#123; String ourPath; if ( lockNodeBytes != null ) &amp;#123; // lockNodeBytes 不为null 则作为数据节点内容, 否则采用默认内容(ip地址) // creatingParentContainersIfNeeded: 用于创建父节点, 如果不支持 CreateMode.CONTAINER // 那么将采用 CreateMode.PERSISTENT // withProtection: 临时子节点会添加 GUID 前缀 ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, lockNodeBytes); // CreateMode.EPHEMERAL_SEQUENTIAL: 临时顺序节点, zookeeper 能保证在节点产生的顺序性. // 依据顺序来激活分布式锁, 从而实现了分布式锁的公平性, &amp;#125; else &amp;#123; ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path); &amp;#125; return ourPath; &amp;#125; LockInternals.internalLockLoop// 循环等待来激活分布式锁,实现锁的公平性. private boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception &amp;#123; // 是否已经持有分布式锁 boolean haveTheLock = false; // 是否需要删除子节点 boolean doDelete = false; try &amp;#123; if ( revocable.get() != null ) &amp;#123; client.getData().usingWatcher(revocableWatcher).forPath(ourPath); &amp;#125; while ( (client.getState() == CuratorFrameworkState.STARTED) &amp;&amp; !haveTheLock ) &amp;#123; // 获取排序后的子节点的顺序 List&lt;String> children = getSortedChildren(); // 获取前面自己创建的临时顺序子节点的名称 String sequenceNodeName = ourPath.substring(basePath.length() + 1); // +1 to include the slash // 实现锁的公平性的核心逻辑. PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); if ( predicateResults.getsTheLock() ) &amp;#123; // 获取了锁, 中断循环, 继续返回上层 haveTheLock = true; &amp;#125; else &amp;#123; // 没有获取锁, 监听上一临时顺序节点 String previousSequencePath = basePath + \"/\" + predicateResults.getPathToWatch(); synchronized(this) &amp;#123; try &amp;#123; // use getData() instead of exists() to avoid leaving unneeded watchers which is a type of resource leak // exists 会导致资源泄露, 因此exists() 可以监听不存在的ZNode, 因为采用 getData // 上一临时顺序节点如果被删除, 会唤醒当前线程继续竞争锁,正常情况下能直接获得锁, 因为锁是公平的. client.getData().usingWatcher(watcher).forPath(previousSequencePath); if ( millisToWait != null ) &amp;#123; millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if ( millisToWait &lt;= 0 ) &amp;#123; // 获取锁超时, 标记删除之前创建的临时顺序节点 doDelete = true; // timed out - delete our node break; &amp;#125; // 等待被唤醒, 限时等待 wait(millisToWait); &amp;#125; else &amp;#123; // 等待被唤醒, 无限等待 wait(); &amp;#125; &amp;#125; catch ( KeeperException.NoNodeException e ) &amp;#123; // 容错处理, // client.getData() 可能调用时抛出 NoNodeException，原因可能是锁被释放或会话过期(连接丢失)等. // 这里并没有做任何处理, 因为外层是while 循环, 再次执行driver.getsTheLock 会调用 validateOurIndex // 此时会抛出NoNodeException, 从而进入下面的catch 和finally 逻辑, 重新抛出上层尝试重试获取锁并删除临时顺序节点 // it has been deleted (i.e. lock released). Try to acquire again &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch ( Exception e ) &amp;#123; ThreadUtils.checkInterrupted(e); // 标记删除, 在finally 删除之前创建的临时顺序节点(后台不断尝试) doDelete = true; // 重新抛出,尝试重新获取锁. throw e; &amp;#125; finally &amp;#123; if ( doDelete ) &amp;#123; deleteOurPath(ourPath); &amp;#125; &amp;#125; return haveTheLock; &amp;#125; getsTheLock @Override public PredicateResults getsTheLock(CuratorFramework client, List&lt;String> children, String sequenceNodeName, int maxLeases) throws Exception &amp;#123; // 之前创建的临时顺序节点在排序后的子节点中的索引 int ourIndex = children.indexOf(sequenceNodeName); // 校验之前创建的临时顺寻节点是否有效 validateOurIndex(sequenceNodeName, ourIndex); // 锁公平性的核心逻辑 // 由InterProcessMutex 的构造函数可知,maxLeases 为1, 即只有ourIndex 为0时, 线程才能持有锁, 或者说该线程创建的临时顺序节点激活了锁. // Zookeeper 的临时顺序节点特性能够保证跨多个JVM 的线程并发创建节点的顺序性, 越早创建临时顺序节点成功的线程会更早的激活锁或获取锁. boolean getsTheLock = ourIndex &lt; maxLeases; // 如果 已经获取到锁, 则无需监听任何节点, 否则需要监听上一个顺序节点(ourIndex -1) // 因为锁是公平的, 因为无需监听除了(ourIndex -1) 以外 的所有节点, 这时为了减少羊群效应, 非常巧妙的涉及. String pathToWatch = getsTheLock ? null : children.get(ourIndex - maxLeases); // 返回获取锁的结果, 交由上层继续处理(添加监听等操作) return new PredicateResults(pathToWatch, getsTheLock); &amp;#125; static void validateOurIndex(String sequenceNodeName, int ourIndex) throws KeeperException &amp;#123; if ( ourIndex &lt; 0 ) &amp;#123; // 容错处理 // 由于会话过期或连接丢失等原因, 该线程创建的临时顺序节点被zookee 服务端删除, 往外抛出NoNodeException // 如果在重试策略允许范围内, 则进行重新禅师获取锁, 这会重新生成临时顺序节点 throw new KeeperException.NoNodeException(\"Sequential path not found: \" + sequenceNodeName); &amp;#125; &amp;#125; 释放锁 InterProcessMutex.release(); @Override public void release() throws Exception &amp;#123; /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); if ( lockData == null ) &amp;#123; // 无法从映射表中获取锁信息, 不持有锁. throw new IllegalMonitorStateException(\"You do not own the lock: \" + basePath); &amp;#125; int newLockCount = lockData.lockCount.decrementAndGet(); if ( newLockCount > 0 ) &amp;#123; // 锁是可重入的, 初始值为1 原子为-1 到0, 锁才释放. return; &amp;#125; if ( newLockCount &lt; 0 ) &amp;#123; // 理论上无法执行该路径 throw new IllegalMonitorStateException(\"Lock count has gone negative for lock: \" + basePath); &amp;#125; try &amp;#123; // lockData != null &amp;&amp; newLockCount == 0，释放锁资源 internals.releaseLock(lockData.lockPath); &amp;#125; finally &amp;#123; // 最后从映射表中移除当前线程的锁信息. threadData.remove(currentThread); &amp;#125; &amp;#125; LockInternals.releaseLock final void releaseLock(String lockPath) throws Exception &amp;#123; client.removeWatchers(); revocable.set(null); // 删除临时顺序节点, 只会触发后一顺序节点去获取锁, 理论上不存在竞争, 只排队, 非抢占, 公平锁.先到先得 deleteOurPath(lockPath); &amp;#125; private void deleteOurPath(String ourPath) throws Exception &amp;#123; try &amp;#123; // 后台不断尝试删除. client.delete().guaranteed().forPath(ourPath); &amp;#125; catch ( KeeperException.NoNodeException e ) &amp;#123; // 已经删除(可能会话过期到期),不做处理. // ignore - already deleted (possibly expired session, etc.) &amp;#125; &amp;#125;","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[]},{"title":"分库分表之Sharding-JDBC(5)","slug":"数据库/分库分表之Sharding-JDBC(5)","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/shu-ju-ku/fen-ku-fen-biao-zhi-sharding-jdbc-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/shu-ju-ku/fen-ku-fen-biao-zhi-sharding-jdbc-5/","excerpt":"","text":"分库分表之Sharding-JDBC1. 架构与核心概念1.1 发展历史它是从当当网的内部架构ddframe 里面的一个分库分表的模块脱胎出来的, 用来解决当当的分库分表问题, 把跟业务相关的敏感的代码剥离后, 就得到了Sharding-JDBC. 它是一个工作在客户端的分库分表的解决方案. DubboX、Elastic-job 也是当当开源出来的产品. 2018年5月份, 因为增加了Proxy 版本的和Sharding-Sidecar(尚未发布), Sharding-JDBC 更名为Sharding-Sphere, 从一个客户端的组件变成了一个套件. 2018年11月,Sharding-Sphere 正式进入Apache 基金孵化器, 这也是对Sharding-Sphere的质量和影响力的认可. 不过现在还没有毕业(名字带incubator), 一般我们用的还是io.shardingsphere的包. 现在Sharding-Sphere 已经不属于当当网了, 也不属于作者张亮个人了. 因为更名后和捐献给Apache 之后的groupId 都不一样, 所以在引入依赖的时候千万要注意. 主体功能是相同的, 但是在某些类的用法上有些差异, 如果要升级的话, import 要全部修改, 有些类和方法也要修改. 1.2 基本特性Sharding-JDBC是怎么工作的呢? https://shardingsphere.apache.org/document/current/cn/overview/ 我们来看一下官网的定义: 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据 库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完 全兼容 JDBC 和各种 ORM 框架。 在maven 工程里面, 我们使用它的方式是引入依赖, 然后进行配置就可以了, 不用像Mycat 一样独立的运行一个服务, 客户端不需要修改任何一行代码, 原来是SSM 连接数据库, 现在还是SSM, 因为它是支持Mybatis的. 1.3 架构我们在项目中引入Sharding-JDBC的依赖, 我们的业务代码在操作数据库的时候, 就会通过Sharding-JDBC的代码连接到数据库. 分库分表的一些核心动作, 比如SQL解析、路由、执行、结果处理, 都是由它完成的, 它工作在客户端. 在Sharding-Sphere 里面同样提供了代理Proxy的版本, 跟Mycat 的作用是一样的.Sharding-Sphere 是一个Kubernetes 的云原生数据库代理, 正在开发中. Sharding-JDBC Sharding-Proxy Sharding-Sidecar 数据库 任何 Mysql Mysql 连接消耗数 高 低 低 异构语言 仅java 任意 任意 性能 损耗低 损耗略高 损耗低 无中心化 是 否 是 静态入口 无 有 有 1.4 功能分库分表后的几大问题: 跨库关联查询、分布式事务、排序翻页计算、全局主键. 1.4.1 数据分片 分库&amp; 分表 读写分离 https://shardingsphere.apache.org/document/current/cn/features/read-write-split/ 分片策略定制化 无中心化分布式主键(包括UUID、雪花、LAF) https://shardingsphere.apache.org/document/current/cn/features/sharding/other-features/key-generator/ 1.4.2 分布式事务https://shardingsphere.apache.org/document/current/cn/features/transaction/ 标准化事务接口 XA 强一致性事务 弱性事务 1.5 核心概念https://shardingsphere.apache.org/document/current/cn/features/sharding/concept/sql/ 逻辑表、真实表、分片键、数据节点、动态表、广播表、绑定表 1.5.1 主要概念 逻辑表会在SQL 解析和路由时被替换成真实的表名 分片键不一定是主键, 也不一定有业务含义. 1.5.2 动态表 1.5.3 广播表跟Mycat的全局表对应 1.5.4 绑定表跟Mycat 的ER表对应 1.6 使用规范不支持的SQL https://shardingsphere.apache.org/document/current/cn/features/sharding/use-norms/sql/ 分页的说明 https://shardingsphere.apache.org/document/current/cn/features/sharding/use-norms/pagination/ 2. Sharding-JDBC实战快速入门 https://shardingsphere.apache.org/document/current/cn/quick-start/sharding-jdbc-quick-start/ 2.1 引入依赖注意, 在SpringBoot 中使用Sharding-JDBC ,可以直接引入sharding-jdbc的依赖,注意组织名称(groupId)的区别 https://mvnrepository.com/artifact/io.shardingjdbc: 更名之前 https://mvnrepository.com/artifact/io.shardingsphere: 更名之后 https://mvnrepository.com/artifact/org.apache.shardingsphere: 捐献给Apache 之后 包名和某些类有差异,如果替换需要注意, import 的包名都需要修改. 核心依赖是(artifactId): sharding-jdbc-core 和 sharding-core 前两个groupId在SpringBoot 中还提供了starter, Apache的暂时没有 2.2 原生JDBC使用package com.database.jdbc; import io.shardingsphere.api.config.rule.ShardingRuleConfiguration; import io.shardingsphere.api.config.rule.TableRuleConfiguration; import io.shardingsphere.api.config.strategy.InlineShardingStrategyConfiguration; import io.shardingsphere.shardingjdbc.api.ShardingDataSourceFactory; import org.apache.commons.dbcp.BasicDataSource; import javax.sql.DataSource; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; import java.util.HashMap; import java.util.Map; import java.util.Properties; /** * @author luyanan * @since 2020/4/7 * &lt;p>jdbc&lt;/p> **/ public class ShardJDBCTest &amp;#123; public static void main(String[] args) throws SQLException &amp;#123; // 配置普通的数据源 Map&lt;String, DataSource> dataSourceMap = new HashMap&lt;>(); // 配置第一个数据源 BasicDataSource dataSource1 = createDataSource(\"jdbc:mysql://localhost:3306/shard0\"); // 配置第二个数据源 BasicDataSource dataSource2 = createDataSource(\"jdbc:mysql://localhost:3306/shard1\"); dataSourceMap.put(\"ds0\", dataSource1); dataSourceMap.put(\"ds1\", dataSource2); // 配置Order 表规则 TableRuleConfiguration orderTableRuleConfig = new TableRuleConfiguration(); orderTableRuleConfig.setLogicTable(\"order\"); orderTableRuleConfig.setActualDataNodes(\"ds$&amp;#123;0..1&amp;#125;.order$&amp;#123;0..1&amp;#125;\"); // 配置分库+分表策略 orderTableRuleConfig.setDatabaseShardingStrategyConfig( new InlineShardingStrategyConfiguration(\"order_id\", \"ds$&amp;#123;order_id % 2&amp;#125;\")); orderTableRuleConfig.setTableShardingStrategyConfig( new InlineShardingStrategyConfiguration(\"order_id\", \"order$&amp;#123;order_id % 2&amp;#125;\")); // 配置分片规则 ShardingRuleConfiguration shardingRuleConfiguration = new ShardingRuleConfiguration(); shardingRuleConfiguration.getTableRuleConfigs().add(orderTableRuleConfig); Map&lt;String, Object> map = new HashMap&lt;>(); // 获取数据源 DataSource dataSource = ShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfiguration, map, new Properties()); String sql = \"select * from order where user_id = ?\"; Connection connection = dataSource.getConnection(); PreparedStatement preparedStatement = connection.prepareStatement(sql); preparedStatement.setInt(1, 2673); try (ResultSet rs = preparedStatement.executeQuery()) &amp;#123; while (rs.next()) &amp;#123; // %2结果，路由到 shard1.order1 System.out.println(\"order_id---------\" + rs.getInt(1)); System.out.println(\"user_id---------\" + rs.getInt(2)); System.out.println(\"create_time---------\" + rs.getTime(3)); System.out.println(\"total_price---------\" + rs.getInt(4)); &amp;#125; &amp;#125; &amp;#125; private static BasicDataSource createDataSource(String url) &amp;#123; BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(url); dataSource.setUsername(\"root\"); dataSource.setPassword(\"rootroot\"); return dataSource; &amp;#125; &amp;#125; 总结: ShardingRuleConfiguration 可以包含多个TableRuleConfiguration(多张表), 也可以设置默认的分库和分表策略 每个TableRuleConfiguration 可以针对表设置 ShardingStrategyConfiguration, 包括分库分表策略 ShardingStrategyConfiguration 有5种实现(标准、行内、复合、Hint、无) ShardingDataSourceFactory 利用了 ShardingStrategyConfiguration 创建数据源 有了数据源, 就可以走JDBC的流程了. 在JDBC中使用,我们可以直接创建数据源, 如果在Spring 中使用, 我们自定义的数据源怎么定义呢? 可以通过注解或者xml 配置文件注入. 2.3 Spring 使用先来总结一下, 因为我们要使用Sharding-JDBC 去访问数据库,所以我们不再使用ORM框架或者容器去定义数据源, 而是注入到Sharding-JDBC 自定义的数据源, 这样才能保证动态的选择数据源。 第二个, 因为Sharding-JDBC 是工作在客户端, 所以我们要在客户端配置分库分表的策略,跟Mycat 不一样的是, Sharding-JDBC 没有内置各种分片策略和算法,需要我们通过表达式或者自定义的配置文件实现。我们创建的数据源中包含了分片的策略. 总体上, 需要配置的就是这两个,数据源和分片策略。当然分片策略又包含分库策略和分表的策略. 配置的方式是各种各样的. https://shardingsphere.apache.org/document/current/cn/manual/sharding-jdbc/configuration/config-java/ 位置: 4 用户手册-?&gt; 4.1 Sharding-JDBC -&gt; 4.1.2 配置手册 2.3.1 java配置第一种是把数据源和分片策略都写在Java Config 中,它的特点是非常灵活的, 我们可以实现各种定义的分片策略。但是缺点是, 如果把数据源和策略都配置在Java Config 中, 就出现了硬编码, 在修改的时候就比较麻烦. @Configuration public class ShardingJDBCDataSourceConfig &amp;#123; @Bean @Primary public DataSource shardingDataSource() throws SQLException &amp;#123; ShardingRuleConfiguration src = new ShardingRuleConfiguration(); // 默认的分库策略 src.setDefaultDatabaseShardingStrategyConfig(new StandardShardingStrategyConfiguration(\"user_id\", DBShardAlgo.class.getName())); // 默认的分表策略 src.setDefaultTableShardingStrategyConfig(new StandardShardingStrategyConfiguration(\"user_id\", TblPreShardAlgo.class.getName(), TblRangeShardAlgo.class.getName())); // 为user_info表设置分库分表策略、算法 // src.getTableRuleConfigs().add(getUserTableRuleConfiguration()); // 数据源名和数据源的映射表 return new ShardingDataSource(src.build(createDataSourceMap())); &amp;#125; // 配置数据源 private Map&lt;String, DataSource> createDataSourceMap() &amp;#123; Map&lt;String, DataSource> result = new HashMap&lt;>(); result.put(\"shard0\", createDataSource(\"jdbc:mysql://localhost:3306/shard0?characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC\")); result.put(\"shard1\", createDataSource(\"jdbc:mysql://localhost:3306/shard1?characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC\")); return result; &amp;#125; // 根据数据源地址创建 DataSource private DataSource createDataSource(final String dataSourceName) &amp;#123; BasicDataSource result = new BasicDataSource(); result.setDriverClassName(\"com.mysql.jdbc.Driver\"); result.setUrl(dataSourceName); result.setUsername(\"root\"); result.setPassword(\"123456\"); return result; &amp;#125; // 事务管理器 @Bean public DataSourceTransactionManager transactitonManager(DataSource shardingDataSource) &amp;#123; return new DataSourceTransactionManager(shardingDataSource); &amp;#125; // 为user_info表设置分库分表策略、算法 public TableRuleConfiguration getUserTableRuleConfiguration() &amp;#123; TableRuleConfiguration userTableRuleConfig = new TableRuleConfiguration(); userTableRuleConfig.setLogicTable(\"user_info\"); userTableRuleConfig.setActualDataNodes(\"ds0.user_info, ds1.user_info\"); userTableRuleConfig.setDatabaseShardingStrategyConfig(new StandardShardingStrategyConfiguration(\"user_id\", DBShardAlgo.class.getName())); userTableRuleConfig.setTableShardingStrategyConfig(new StandardShardingStrategyConfiguration(\"user_id\", TblPreShardAlgo.class.getName(), TblRangeShardAlgo.class.getName())); return userTableRuleConfig; &amp;#125; &amp;#125; 2.3.2 SpringBoot 配置第二种是直接使用SpringBoot的application.properties 来配置, 这个要基于start 模块, ，org.apache.shardingsphere的包还没有starter,只有o.shardingsphere的包有starter 把数据源和分库分表的策略都配置在application.properties文件中, 这种方式配置简单, 但是不能实现复杂的分片策略, 不够灵活. # 数据源配置 sharding.jdbc.datasource.names=shard0,shard1 sharding.jdbc.datasource.ds0.type=com.alibaba.druid.pool.DruidDataSource sharding.jdbc.datasource.ds0.driver-class-name=com.mysql.jdbc.Driver sharding.jdbc.datasource.ds0.url=jdbc:mysql://localhost:3306/shard0 sharding.jdbc.datasource.ds0.username=root sharding.jdbc.datasource.ds0.password=rootroot sharding.jdbc.datasource.ds1.type=com.alibaba.druid.pool.DruidDataSource sharding.jdbc.datasource.ds1.driver-class-name=com.mysql.jdbc.Driver sharding.jdbc.datasource.ds1.url=jdbc:mysql://localhost:3306/shard1 sharding.jdbc.datasource.ds1.username=root sharding.jdbc.datasource.ds1.password=rootroot #sharding.jdbc.config.sharding.default-database-strategy.inline.sharding-column=user_id #sharding.jdbc.config.sharding.default-database-strategy.inline.algorithm-expression=ds$&amp;#123;user_id % 2&amp;#125; # 分库算法 user_info，多库分表 # 单库内没有分表，注释了分表策略 sharding.jdbc.config.sharding.tables.user_info.actual-data-nodes=ds$->&amp;#123;0..1&amp;#125;.user_info sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.inline.shardingColumn=user_id sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.inline.algorithm-expression=ds$&amp;#123;user_id % 2&amp;#125; ###sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.standard.shardingColumn=user_id ###sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.standard.preciseAlgorithmClassName=com.gupaoedu.config.DBShardAlgo ###sharding.jdbc.config.sharding.tables.user_info.tableStrategy.standard.shardingColumn=user_id ###sharding.jdbc.config.sharding.tables.user_info.tableStrategy.standard.preciseAlgorithmClassName=com.gupaoedu.config.TblPreShardAlgo ###sharding.jdbc.config.sharding.tables.user_info.tableStrategy.standard.rangeAlgorithmClassName=com.gupaoedu.config.TblRangeShardAlgo ##sharding.jdbc.config.sharding.tables.user_info.table-strategy.inline.sharding-column=user_id ##sharding.jdbc.config.sharding.tables.user_info.table-strategy.inline.algorithm-expression=user_info # 分库算法 t_order 多库分表 sharding.jdbc.config.sharding.tables.t_order.databaseStrategy.inline.shardingColumn=order_id sharding.jdbc.config.sharding.tables.t_order.databaseStrategy.inline.algorithm-expression=ds$&amp;#123;order_id % 2&amp;#125; sharding.jdbc.config.sharding.tables.t_order.actual-data-nodes=ds$->&amp;#123;0..1&amp;#125;.t_order # 分库算法 t_order_item 多库分表 sharding.jdbc.config.sharding.tables.t_order_item.databaseStrategy.inline.shardingColumn=order_id sharding.jdbc.config.sharding.tables.t_order_item.databaseStrategy.inline.algorithm-expression=ds$&amp;#123;order_id % 2&amp;#125; sharding.jdbc.config.sharding.tables.t_order_item.actual-data-nodes=ds$->&amp;#123;0..1&amp;#125;.t_order_item # 绑定表规则列表，防止关联查询出现笛卡尔积 sharding.jdbc.config.sharding.binding-tables[0]=t_order,t_order_item # 广播表 sharding.jdbc.config.sharding.broadcast-tables=t_config 2.3.3 yml配置第三种是Spring Boot的yml配置, 也要依赖starter模块, 当然我们也可以结合不同的配置方法, 比如把分片策略放在Java Config中, 数据源配置在yml 中或者properties 中. 2.4 Spring案例验证这里验证的是切分到本地的两个库shard0和shard1 两个库里面都是相同的四张表(user_info，t_order，t_order_item，t_config) 这些表必须提前创建, 中见表不会帮助我们生成的. 然后我们用Mybatis的generator 生成相应的实体类、Mapper接口和映射器 对数据库的基本的SSM的操作弄完了, 接下来就是分库分表的配置, 一个是数据源, 一个是分片策略. 我们先来看一下我们的数据源的配置application.properties sharding.jdbc.datasource 如果用Spring 管理数据源 spring.datasource.url=jdbc:mysql://192.168.8.168:8066/shard1 spring.datasource.username=root spring.datasource.password=rootroot spring.datasource.driver-class-name=com.mysql.jdbc.Driver 但我们使用了Sharding-JDBC的数据源之后, 对于数据的操作就会交给Sharding-JDBC的代码处理. 分片策略从维度上分为两种: 一种是分库, 一种是分表. 我们可以定义默认的分库分表策略,例如用user_id 作为分片键, 这里用到了一种分片策略的实现 ,叫做行内表达式. 我们对user_id取模, 然后选择数据库. 如果 模等于0, 在第一个数据库中,模等于1, 在第二个数据库中. 数据源名称是行内表达式组装出来的 sharding.jdbc.config.sharding.default-database-strategy.inline.sharding-column=user_id sharding.jdbc.config.sharding.default-database-strategy.inline.algorithm-expression=ds$&amp;#123;user_id % 2&amp;#125; 对于不同的表, 也可以单独配置分库策略(databaseStrategy) 和分表策略(tableStrategy), 使用以下配置打印路由信息 sharding.jdbc.config.sharding.props.sql.show=true 2.4.1 取模分片我们用user_info 表来验证取模分片,根据user_id, 把用户数据划分到两个数据节点上. 在本地创建两个数据库shard0和shard1, 都创建user_info表. CREATE TABLE `user_info` ( `user_id` bigint(19) NOT NULL, `user_name` varchar(45) DEFAULT NULL, `account` varchar(45) NOT NULL, `password` varchar(45) DEFAULT NULL, PRIMARY KEY (`user_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 这里只定义了分库策略, 没有定义单库内的分表策略, 两个库都是相同的表. 路由的结果 ：ds0.user_info，ds1.user_info 如果定义了分库策略, 两个库里面都有两张表, 那么路由的结果可能有4种: ds0.user_info0， ds0.user_info1； ds1. user_info0, ds1. user_info1 sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.inline.shardingColumn=user_id sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.inline.algorithm-expression=ds$&amp;#123;user_id % 2&amp;#125; #sharding.jdbc.config.sharding.tables.user_info.table-strategy.inline.sharding-column=user_id #sharding.jdbc.config.sharding.tables.user_info.table-strategy.inline.algorithm-expression=user_info sharding.jdbc.config.sharding.tables.user_info.actual-data-nodes=ds$->&amp;#123;0..1&amp;#125;.user_info @MapperScan(\"com.database.dao\") @SpringBootTest @RunWith(SpringRunner.class) public class UserShardingTest &amp;#123; @Autowired UserInfoService userInfoService; public void insert() &amp;#123; userInfoService.insert(); &amp;#125; @Test public void select() &amp;#123; UserInfo userInfo1 = userInfoService.getUserInfoByUserId(1L); System.out.println(\"------userInfo1:\" + userInfo1); UserInfo userInfo2 = userInfoService.getUserInfoByUserId(2L); System.out.println(\"------userInfo2:\" + userInfo2); &amp;#125; &amp;#125; @Service public class UserInfoService &amp;#123; @Resource private UserInfoMapper userInfoMapper; public static Long userId = 1L; public void insert() &amp;#123; for (int i = 0; i &lt; 100; i++) &amp;#123; UserInfo userInfo = new UserInfo(); userInfo.setUserId(userId); userInfo.setAccount(\"account\" + i); userInfo.setPassword(\"password\" + i); userInfo.setUserName(\"name\" + i); userId++; userInfoMapper.insert(userInfo); &amp;#125; &amp;#125; public UserInfo getUserInfoByUserId(Long id) &amp;#123; return userInfoMapper.selectByPrimaryKey(id); &amp;#125; public List&lt;UserInfo> selectByRange(Long firstId, Long lastId) &amp;#123; return userInfoMapper.selectByRange(firstId, lastId); &amp;#125; &amp;#125; 演示结果: 我们看一下插入的结果, user_id 为偶数的数据, 都落到了第一个库,user_id为奇数的库,都落到了第二个库. 执行select() 测一下查询, 看看数据分布到两个节点的时候 ,我们用程序查询, 能不能取回正确的数据. 2.4.2 绑定表第二种是绑定表, 也就是父表和子表有关联关系, 主表和子表使用相同的分片策略. CREATE TABLE `t_order` ( `order_id` int(11) NOT NULL, `user_id` int(11) NOT NULL, PRIMARY KEY (`order_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE `t_order_item` ( `item_id` int(11) NOT NULL, `order_id` int(11) NOT NULL, `user_id` int(11) NOT NULL, PRIMARY KEY (`item_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 除了定义分库和分表的算法之外, 我们还需要多定义一个binding-tables. 绑定表将使用主表的分片策略. sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.inline.shardingColumn=user_id sharding.jdbc.config.sharding.tables.user_info.databaseStrategy.inline.algorithm-expression=ds$&amp;#123;user_id % 2&amp;#125; #sharding.jdbc.config.sharding.tables.user_info.table-strategy.inline.sharding-column=user_id #sharding.jdbc.config.sharding.tables.user_info.table-strategy.inline.algorithm-expression=user_info sharding.jdbc.config.sharding.tables.user_info.actual-data-nodes=ds$->&amp;#123;0..1&amp;#125;.user_info # 分库算法 t_order 多库分表 sharding.jdbc.config.sharding.tables.t_order.databaseStrategy.inline.shardingColumn=order_id sharding.jdbc.config.sharding.tables.t_order.databaseStrategy.inline.algorithm-expression=ds$&amp;#123;order_id % 2&amp;#125; sharding.jdbc.config.sharding.tables.t_order.actual-data-nodes=ds$->&amp;#123;0..1&amp;#125;.t_order # 分库算法 t_order_item 多库分表 sharding.jdbc.config.sharding.tables.t_order_item.databaseStrategy.inline.shardingColumn=order_id sharding.jdbc.config.sharding.tables.t_order_item.databaseStrategy.inline.algorithm-expression=ds$&amp;#123;order_id % 2&amp;#125; sharding.jdbc.config.sharding.tables.t_order_item.actual-data-nodes=ds$->&amp;#123;0..1&amp;#125;.t_order_item # 绑定表规则列表 sharding.jdbc.config.sharding.binding-tables[0]=t_order,t_order_item 绑定表不使用分片键查询时, 会出现笛卡尔积。 什么叫笛卡尔积,假如有2个数据库, 两张表要相互关联, 两张表又各有分表, 那么SQL的执行路径就是是 2*2*2=8 种 2.4.3 广播表 /** * @author luyanan * @since 2020/4/7 * &lt;p>广播表的分库分表策略&lt;/p> **/ @SpringBootTest @RunWith(SpringRunner.class) @MapperScan(basePackages = \"com.database.dao\") public class ConfigShardingTest &amp;#123; @Resource ConfigService configService; @Test public void insert()&amp;#123; configService.insert(); &amp;#125; @Test public void update()&amp;#123; configService.update(1); &amp;#125; @Test public void select()&amp;#123; Config config1 = configService.geConfigById(1); System.out.println(\"------config1:\"+config1); Config config2 = configService.geConfigById(2); System.out.println(\"------config2:\"+config2); &amp;#125; &amp;#125; 插入和更新都会在所有的节点上执行 如果我们需要更加复杂的分片策略, properties 文件内行内表达式的这种方式肯定满足不了 , 实际上properties 里面的分片策略都可以指定, 比如user_info 表的分库和分表策略. sharding.jdbc.config.sharding.tables.user_info.tableStrategy.standard.shardingColumn= sharding.jdbc.config.sharding.tables.user_info.tableStrategy.standard.preciseAlgorithmClassName= sharding.jdbc.config.sharding.tables.user_info.tableStrategy.standard.rangeAlgorithmClassName= 这个时候我们需要了解Sharding-JDBC 中几种不同的分片策略. 3. 分片策略详解https://shardingsphere.apache.org/document/current/cn/features/sharding/concept/sharding/ Sharding-JDBC中的分片策略有两个维度,分库(数据源分片)策略和分表策略. 分库策略表示数据路由到物理目标数据源, 分表分片策略表示数据被路由到的目的表。 分表策略是依赖分库策略的, 也就是说要先分库再分表, 当然也可以不分库只分表 跟Mycat 不一样的是, Sharding-jdbc 没有提供内置的分片算法, 而是通过抽象成接口, 让开发者自行去实现, 这样可以根据业务实际情况灵活地实现. 3.1 分片策略包含分片键和分片算法, 分片算法是需要自定义的, 可以用于分库, 也可以用于分表. Sharding-JDBC 提供了5种分片策略, 这些策略全部继承自ShardingStrategy 3.1.1 行表达式分片策略对应InlineShardingStrategy 类,只支持单分片键, 提供对+和IN操作的支持, 行内表达式 的配置比较简单. 例如: $&#123;begin..end&#125;: 表示范围区间 $&#123;[unit1, unit2, unit_x]&#125;: 表示枚举值 t_user_$-&gt;&#123;u_id % 8&#125;: 表示t_user 表根据u_id模8, 而分成8张表,表名称为t_user_0到t_user_8 行表达式中如果出现连续多个个$&#123; expression &#125;或$-&gt;&#123; expression &#125; 表达式, 整个表达式最终的结果将会根据每个子表达式的结果进行笛卡尔积. 例如: 以下行表达式 $&#123;[&#39;db1&#39;, &#39;db2&#39;]&#125;_table$&#123;1..3&#125;最终会解析为: db1_table1, db1_table2, db1_table3, db2_table1,db2_table2,db2_table3 3.1.2 标准分片策略对应StandardShardingStrategy 类 标准分片策略只支持单分片键, 提供了提供PreciseShardingAlgorithm 和 RangeShardingAlgorithm 两个分片算法,分别对应SQL 语句中的=、IN和BETWEEN AND 如果要使用标准分片策略, 必须实现PreciseShardingAlgorithm, 用来处理=和IN的分片上。RangeShardingAlgorithm 是可选的, 如果没有实现,SQL语句会发到所有的数据节点上执行. 3.1.3 符合分片策略比如: 根据日期和ID两个字段分片,每个月3张表,先根据日期, 再根据id取模, 对应ComplexShardingStrategy 类, 可以支持等值查询和范围查询. 符合分片策略支持多分片键, 提供了ComplexKeysShardingAlgorithm,分片算法需要自己实现. 3.1.4 Hint 分片策略对应HintShardingStrategy. 通过Hint 而非SQL解析的方式分片的策略, 有点类似于Mycat 的指定分片注解. https://shardingsphere.apache.org/document/current/cn/manual/sharding-jdbc/usage/hint/ 3.1.5 不分片策略对应NoneShardingStrategy, 不分片的策略 3.2 分片算法创建了分片策略之后, 还需要实现分片算法, Sharding-JDBC 目前提供了4种分片算法. 3.2.1 精确分片算法对应PreciseShardingAlgorithm,用于处理使用单一键作为分片键的=与IN 进行分片的场景,需要配合StandardShardingStrategy 使用. 3.2.2 范围分片算法对应RangeShardingAlgorithm ,用于处理使用单一键作为分片键的BETWEEN AND 进行分片的场景, 需要配合StandardShardingStrategy 使用. 如果不配置范围分片算法, 范围查询默认会路由到所有的节点. 3.2.3 复合分片算法对应ComplexKeysShardingAlgorithm, 用于处理使用多键作为分片键进行分片的场景, 包含多个分片键的逻辑较为复杂，需要应用开发者自行处理其中的复杂度,需要配合ComplexShardingStrategy 使用. 3.2.4 Hint 分片算法对应HintShardingAlgorithm, 用于处理使用Hint 行分片的场景, 需要配合HintShardingStrategy 使用. https://shardingsphere.apache.org/document/current/cn/manual/sharding-jdbc/usage/hint/ 3.2.5 算法实现所有的算法都需要实现对应的接口, 实现doSharding() 方法. 例如: PreciseShardingAlgorithm 传入分片键,返回一个精确的分片(数据源名称) String doSharding(Collection&lt;String> availableTargetNames, PreciseShardingValue&lt;T> shardingValue); RangeShardingAlgorithm 传入分片键, 返回多个数据源名称 Collection&lt;String> doSharding(Collection&lt;String> availableTargetNames, RangeShardingValue&lt;T> shardingValue); ComplexKeysShardingAlgorithm 传入多个分片键,返回多个数据源名称 Collection&lt;String> doSharding(Collection&lt;String> availableTargetNames, Collection&lt;ShardingValue> shardingValues); 4.分布式事务4.1 事务概况https://shardingsphere.apache.org/document/current/cn/features/transaction/ 4.2 两阶段事务-XA添加依赖 &lt;!--xa分布式事务--> &lt;dependency> &lt;groupId>io.shardingsphere&lt;/groupId> &lt;artifactId>sharding-transaction-2pc-xa&lt;/artifactId> &lt;version>3.1.0&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>io.shardingsphere&lt;/groupId> &lt;artifactId>sharding-transaction-spring-boot-starter&lt;/artifactId> &lt;version>3.1.0&lt;/version> &lt;/dependency> 默认用atomikos 实现的. 在Server 类上加上注解 @ShardingTransactionType(TransactionType.XA) @Transactional(rollbackFor = Exception.class) 其他的事务类型:Local、BASE 模拟在两个节点上操作,id=12673,id=12674 路由到两个节点,第二个节点上插入两个相同的对象,发生主键冲突,会发现回滚. /** * 测试跨库事务 */ @ShardingTransactionType(TransactionType.XA) @Transactional(rollbackFor = Exception.class) public void testTransactional() &amp;#123; User user1 = new User(12673, \"张三\", 12); this.userDao.addOne(user1); User user2 = new User(12674, \"张三\", 12); // 主键冲突 this.userDao.addOne(user2); this.userDao.addOne(user2); &amp;#125; XA 的实现类 ShardingTransactionManager -&gt; XATransactionManager-&gt; AtomikosTransactionManager 4.3 柔性事务ShardingSphere 的柔性事务已经过第三方SPI实现Sega事务,Sega 引擎使用Servicecomb-Saga 参考官方的这篇文章《分布式事务在 Sharding-Sphere 中的实现》 &lt;dependency> &lt;groupId>io.shardingsphere&lt;/groupId> &lt;artifactId>sharding-transaction-2pc-spi&lt;/artifactId> &lt;version>3.1.0&lt;/version> &lt;/dependency> 4.4 柔性事务Seatahttps://github.com/seata/seata https://github.com/seata/seata-workshop https://mp.weixin.qq.com/s/xfUGep5XMcIqRTGY3WFpgA GTS 的社区版本叫 Fescar（Fast &amp; Easy Commit And Rollback），Fescar 改名后 叫 Seata AT（Simple Extensible Autonomous Transaction Architecture）。 需要额外部署Seata-server 服务进行分支事务的协调. 官方的demo中有一个例子: https://github.com/apache/incubator-shardingsphere-example incubator-shardingsphere-example-dev\\sharding-jdbc-example\\transaction -example\\transaction-base-seata-raw-jdbc-example 5. 分布式全局ID我们可以使用key-generator-column-name 配置, 生成一个18位的ID properties的配置 sharding.jdbc.config.sharding.default-key-generator-class-name= sharding.jdbc.config.sharding.tables.t_order.keyGeneratorColumnName= sharding.jdbc.config.sharding.tables.t_order.keyGeneratorClassName= Java Config的配置 tableRuleConfig.setKeyGeneratorColumnName(\"order_id\"); tableRuleConfig.setKeyGeneratorClass(\"io.shardingsphere.core.keygen.DefaultKeyGenerator\") keyGeneratorColumnName: 指定需要ID的实例 KeyGenerotorClass：指定生成器类，默认是 DefaultKeyGenerator.java, 里面使用了雪花算法. 6. Sharding-JDBC 工作流程内核剖析 Sharding-JDBC的原理总结起来很简单 SQL解析-&gt; 执行器优化-&gt;SQL路由 -&gt;SQL改写 -&gt;SQL执行 -&gt; 结果归并 6.1 SQL解析SQL解析主要是词法和语法的解析,目前常见的sql解析器有fdb、jsqlparser和Druid.Shard-JDBC 1.4x之前的版本使用的是Druid 作为sql解析器, 从 1.5X版本开始, Sharding-JDBC 采用完全自研的SQL解析引擎. 6.2 SQL路由 SQL路由是根据分片规则配置以及解析上下文的分片条件, 将SQL 定位至真正的数据源, 它又分为直接路由、简单路由和笛卡尔积路由. 直接路由,使用Hint方式. Binding 表是指使用同样的分片键和分片规则的一组表,也就是说任何情况下, Binding 表的分片结果应该与主表一致. 例如order_info 表和order_item 表, 都根据order_id 分片, 结果应该是order_1与order_item_1 成对出现. 这样的关联查询和单表查询复杂度和性能相当,如果分片条件不是等于, 而是BETWEEN 或者IN,则路由结果不一定落入单库(表)，因此一条逻辑sql最终可能拆分成多条SQL 语句. 笛卡尔积查询最为复杂,因为无法根据Binding 关系定位分片规则的一致性, 所以非Binding 表的关联查询需要拆解为笛卡尔积组合执行. 查询性能较低, 而且数据库连接比较高, 需谨慎使用, 6.3 SQL 改写例如: 将逻辑表名称改写成真实表的名称, 优化分页查询等. 6.4 SQL执行.因为可能连接到多个真实的数据源,Sharding-JDBC将采用多线程并发执行SQL. 6.5 结果归总例如数据的组装、分页、排序等等 . 7. Sharding-JDBC 实现原理我们知道JDBC的四大核心对象 DataSource、Connection、Statement（PS）、ResulstSet。Sharding-JDBC 封装了这四个核心类,在类名前面加上了Sharding. 如果说带Sharding的类要替换JDBC的对象，那么一定要找到创建和调用他们的地方.ShardingDataSource 我们就不说了, 系统启动的时候就创建好了. 问题就在于, 我们是什么时候用ShardingDataSource 获取一个ShardingConnection 的? 没有看过Mybatis的源码的同学一定要去看看,我们的查询方法最终会走到SimpleExecutor 的doQuery() 方法, 这个是我们的前提知识, 那我们直接在doQuery()打断点. doQuery() 方法里面调用了prepareStatement() 创建连接. private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &amp;#123; Connection connection = this.getConnection(statementLog); Statement stmt = handler.prepare(connection, this.transaction.getTimeout()); handler.parameterize(stmt); return stmt; &amp;#125; 它经过以下两个方法, 返回一个ShardingConnection DataSourceUtil.fetchConnection() Connection con = dataSource.getConnection(); 基于这个ShardingConnection，最终得到一个 ShardingStatement stmt = handler.prepare(connection, transaction.getTimeout()); 接下来就是执行 return handler.query(stmt, resultHandler); 再调用了ShardingStatement的execute() public &lt;E> List&lt;E> query(Statement statement, ResultHandler resultHandler) throws SQLException &amp;#123; PreparedStatement ps = (PreparedStatement) statement; ps.execute(); return resultSetHandler.handleResultSets(ps); &amp;#125; 最终调用的是ShardingPreparedStatement 的execute 方法 public boolean execute() throws SQLException &amp;#123; try &amp;#123; clearPrevious(); sqlRoute(); initPreparedStatementExecutor(); return preparedStatementExecutor.execute(); &amp;#125; finally &amp;#123; refreshTableMetaData(connection.getShardingContext(), routeResult.getSqlStatement()); clearBatch(); &amp;#125; &amp;#125; SQL的解析路由就是在这一步完成的。 8. Sharding-Proxy 介绍下载地址 https://github.com/sharding-sphere/sharding-sphere-doc/raw/master/dist/sharding-proxy-3.0.0.tar.gz lib 目录就是sharding-proxy 核心代码,以及依赖的jar bin目录就是存在启停脚本的地方 conf 目录就是存放所有配置文件,包括sharding-proxy 服务的配置文件、数据源以及sahrding 规则配置文件和项目日志配置文件. linux 运行start.sh 文件(window用start.bat) ,默认端口为3307 需要的自定义分表算法, 只需要将他编译成class文件, 然后放到conf目录下,也可以打成jar 包放到lib 目录 9. 与Mycat 对比 Sharding-JDBC Mycat 工作层面 JDBC协议 Mysql协议JDBC协议 运行方式 jar包, 客户端 独立服务, 服务端 开发方式 代码/配置改动 连接地址(数据源) 运维方式 无 管理独立服务,运维成本高 性能 多线程并发操作, 性能高 独立服务+网络开销,存在性能损失风险 功能范围 协议层面 包括分布式事务、数据迁移 适用操作 OLTP OLTP+OLAP 支持数据库 基于JDBC协议的数据库 mysql 和其他支持JDBC协议的数据库 支持语言 java项目中使用 支持JDBC协议 从易用性和功能完善的角度来看看,Mycat 似乎比Sharding-JDBC 要好, 因为有现成的分片规则, 也提供了4种ID生成方式, 通过注解可以支持高级功能, 比如跨库关联查询. 建议: 小型项目, 分片规则简单的项目用sharding-JDBC.大型项目, 可以用Mycat","categories":[{"name":"数据库","slug":"数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库","slug":"数据库/数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"分库分表之Mycat(3)","slug":"数据库/分库分表之Mycat(3)","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/shu-ju-ku/fen-ku-fen-biao-zhi-mycat-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/shu-ju-ku/fen-ku-fen-biao-zhi-mycat-3/","excerpt":"","text":"分库分表之Mycat官网: http://www.mycat.io/ Mycat 概要介绍： https://github.com/MyCATApache/Mycat-Server 入门指南: https://github.com/MyCATApache/Mycat-doc/tree/master/%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97 1.Mycat介绍和核心概念1.1 基本介绍历史:从阿里的cobar升级而来, 由开源组织维护, 2.0 正在开发中. 定位：运行在应用和数据库之间, 可以当作一个mysql 服务器使用,实现对Mysql数据库的分库分表, 也可以通过JDBC 支持其他的数据库. Mycat 的关键特性: 可以当作一个MYSQL 数据库使用 支持Mysql之外的数据库, 通过JDBC实现. 解决了我们提到的很多问题, 多表join、分布式事务、全局序列号、翻页排序等. 支持ZK配置,带监控mycat-web 2.0 正在开发中. 1.2 核心概念 概念 含义 主机 物理主机, 一台服务器、一个数据库、一个3306端口 物理数据库 真实的数据库 物理表 真实存在的表 分片 将原来单个数据库的数据切分后分散在不同的数据库节点 分片节点 分片以后数据存储的节点 分片键 分片依据的字段,例如order 表中以id为依据分片, id就是分片键, 通常为主键 分片算法 分片的规则, 例如随机、取模、范围、哈希、枚举以及各种组合算法 逻辑表 相当于物理表,是分片表聚合后的结果,对于客户端来说跟真实的表没有区别 逻辑数据库 相当于物理数据库, 是数据节点聚合后的结果, 下载, 解压Mycat(有window版本, 可以在本地数据库测试) http://dl.mycat.io/ wget http://dl.mycat.io/1.6.7.3/20190927161129/Mycat-server-1.6.7.3-release-20190927161129-linux.tar.gz tar -xzvf Mycat-server-1.6.7.3-release-20190927161129-linux.tar.gz Mycat解压之后有5个目录, 目录 作用 bin 启动目录 catlet 空目录 conf 配置目录 lib jar包依赖 logs 日志目录 2. Mycat 配置详解主要的配置文件有server.xml、schema.xml、rule.xml 和具体的分片规则文件. 2.1 server.xml包含系统配置信息, System标签: 例如字符集、线程数、心跳、分布式事务开关等. user标签: 配置登录用户和权限 &lt;user name=\"root\" defaultAccount=\"true\"> &lt;property name=\"password\">123456&lt;/property> &lt;property name=\"schemas\">catmall&lt;/property> &lt;/user> Mycat对密码加密 java -cp Mycat-server-1.6.7.3-release.jar io.mycat.util.DecryptUtil 0:root:123456 2.2 schema.xmlhttps://dev.mysql.com/doc/refman/5.7/en/glossary.html schema 在Mysql 里面跟数据库是等价的. schema.xml 里面包含逻辑库、表、分片规则、分片节点和数据源, 可以定义多个schema 这里面有三个主要的标签(table、tableNode、dataHost) &lt;/table&gt;表名和库名最好小写, 定义了逻辑表以及逻辑表分布的节点和分片规则 &lt;schema name=\"catmall\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"> &lt;!-- 范围分片 --> &lt;table name=\"customer\" primaryKey=\"id\" dataNode=\"dn1,dn2,dn3\" rule=\"rang-long-cust\" /> &lt;!-- 取模分片 --> &lt;table name=\"order_info\" dataNode=\"dn1,dn2,dn3\" rule=\"mod-long-order\" > &lt;!-- ER 表 --> &lt;childTable name=\"order_detail\" primaryKey=\"id\" joinKey=\"order_id\" parentKey=\"order_id\"/> &lt;/table> &lt;!-- 全局表 --> &lt;table name=\"student\" primaryKey=\"sid\" type=\"global\" dataNode=\"dn1,dn2,dn3\" /> &lt;/schema> 配置 作用 primaryKey 执行该逻辑表对应的真实表的主键,Mycat 会缓存主键(通过primaryKey 属性配置)与具体的dataNode的信息当分片规则(rule) 使用非主键进行分片时, 那么在使用主键进行查询时,Mycat 就会通过缓存先确定记录在哪个dataNode上, 然后再在该dataNode 上执行查询. 如果没有缓存/缓存并没有命中的话,还是会发送所有语句给dataNode dataNode 数据分片的节点 autoIncrement 自增长(全局序列)、true代表主键使用自增长策略 type 全局表:global, 其他： 不配置 &lt;dataNode&gt;&lt;dataNode name=\"dn1\" dataHost=\"host1\" database=\"mycat\" /> 数据节点与物理数据库的对应关系. &lt;dataHost/&gt;配置物理主机的信息， readHost是从属于writeHost的 &lt;dataHost name=\"host1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"> &lt;heartbeat>select user()&lt;/heartbeat> &lt;!-- can have multi write hosts --> &lt;writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\"> &lt;!-- can have multi read hosts --> &lt;readHost host=\"hostS2\" url=\"192.168.8.146:3306\" user=\"root\" password=\"xxx\"/> &lt;/writeHost> &lt;writeHost host=\"hostS1\" url=\"localhost:3316\" user=\"root\" password=\"123456\"/> &lt;!-- &lt;writeHost host=\"hostM2\" url=\"localhost:3316\" user=\"root\" password=\"123456\"/> --> &lt;/dataHost> balance: 负载的配置, 决定select语句的负载. 值 作用 0 不开启读写分离机制,所有读操作都发送到当前可用的writeHost 上 1 所有的读操作都随机的发送到当前的writeHost 对应的readHost和备用的writeHost上. 2 所有的读操作都随机发送到所有的writeHost和readHost上. 3 所有的读操作都只发送到writeHost的readHost上. writeType : 读写分离的配置, 决定update、delete、insert 语句的负载. 值 作用 0 所有的写操作都发送到可用的writeHost上(默认第一个,第一个挂了以后发送到第二个) 1 所有的写操作都随机的发送到writeHost上 switchType: 主从切换的配置 值 作用 -1 表示不自动切换 1 默认值, 表示自动切换 2 基于Mysql主从切换的状态决定是否切换, 心跳语句show slave status 3 基于Mysql galary cluster 的切换机制（适合集群）（1.4.1），心跳语句为 show status like &#39;wsrep%&#39;。 2.3 rule.xml定义了分片规则和算法 分片规则: &lt;tableRule name=\"rang-long-cust\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>func-rang-long-cust&lt;/algorithm> &lt;/rule> &lt;/tableRule> 分片算法 &lt;function name=\"func-rang-long-cust\" class=\"io.mycat.route.function.AutoPartitionByLong\"> &lt;property name=\"mapFile\">rang-long-cust.txt&lt;/property> &lt;/function> 分片配置:rang-long-cust.txt 10001-20000=1 0-10000=0 20001-100000=2 2.4 ZK配置https://www.cnblogs.com/leeSmall/p/9551038.html Mycat 也支持zk配置(用于管理配置和生成全局ID), 执行bin目录下的init_zk_data.sh, 会自动将zkconf下的所有配置文件上传到zk(先拷贝到这个目录) cd /usr/local/soft/mycat/conf cp *.txt *.xml *.properties zkconf/ cd /usr/local/soft/mycat/bin ./init_zk_data.sh 启用zk配置 mycat/conf/myid.properties loadZk=true zkURL=127.0.0.1:2181 clusterId=010 myid=01001 clusterSize=1 clusterNodes=mycat_01 #server booster ; booster install on db same server,will reset all minCon to 2 type=server boosterDataHosts=dataHost1 注意如果指定init_zk_data.sh 脚本报错的话, 代表未写入成功, 此时不要启动zk配置并重启,否则本地文件会被覆盖, 启动的时如果oadzk=true 启动时, 会自动从zk下载配置文件并覆盖到本地配置. 在这种情况下如果修改配置, 需要先修改conf 目录的配置, copy到zkconf, 再执行上传. 2.5 启动停止进入mycat/bin 目录(主要要先启动物理数据库) 操作 命令 启动 ./mycat start 停止 ./mycat stop 重启 ./mycat restart 查看状态 ./mycat status 前台运行 /mycat console 连接 mysql -uroot -p123456 -h 192.168.8.151 -P8066 catmall 3. Mycat 分片验证explain 可以用来看路由结果 在三个数据库中建表 CREATE TABLE `customer` ( `id` int(11) DEFAULT NULL, `name` varchar(255) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE `order_info` ( `order_id` int(11) NOT NULL COMMENT '订单 ID', `uid` int(11) DEFAULT NULL COMMENT '用户 ID', `nums` int(11) DEFAULT NULL COMMENT '商品数量', `state` int(2) DEFAULT NULL COMMENT '订单状态', `create_time` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间', `update_time` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', PRIMARY KEY (`order_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE `order_detail` ( `order_id` int(11) NOT NULL COMMENT '订单号', `id` int(11) NOT NULL COMMENT '订单详情', `goods_id` int(11) DEFAULT NULL COMMENT '货品 ID', `price` decimal(10,2) DEFAULT NULL COMMENT '价格', `is_pay` int(2) DEFAULT NULL COMMENT '支付状态', `is_ship` int(2) DEFAULT NULL COMMENT '是否发货', `status` int(2) DEFAULT NULL COMMENT '订单详情状态', PRIMARY KEY (`order_id`,`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE `student` ( `sid` int(8) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `qq` varchar(255) DEFAULT NULL, PRIMARY KEY (`sid`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; schema.xml &lt;table name=\"customer\" dataNode=\"dn1,dn2,dn3\" rule=\"rang-long-cust\" primaryKey=\"id\"/> &lt;table name=\"order_info\" dataNode=\"dn1,dn2,dn3\" rule=\"mod-long-order\"> &lt;childTable name=\"order_detail\" joinKey=\"order_id\" parentKey=\"order_id\" primaryKey=\"id\"/> &lt;/table> &lt;table name=\"student\" dataNode=\"dn1,dn2,dn3\" primaryKey=\"sid\" type=\"global\"/> 数据节点配置 &lt;dataNode name=\"dn1\" dataHost=\"host1\" database=\"mycat\"/> &lt;dataNode name=\"dn2\" dataHost=\"host2\" database=\"mycat\"/> &lt;dataNode name=\"dn3\" dataHost=\"host3\" database=\"mycat\"/> &lt;dataHost balance=\"0\" maxCon=\"1000\" minCon=\"10\" name=\"host1\" writeType=\"0\" switchType=\"1\" slaveThreshold=\"100\" dbType=\"mysql\" dbDriver=\"native\"> &lt;heartbeat>select user()&lt;/heartbeat> &lt;writeHost host=\"hostM1\" url=\"192.168.8.146:3306\" password=\"123456\" user=\"root\"/> &lt;/dataHost> &lt;dataHost balance=\"0\" maxCon=\"1000\" minCon=\"10\" name=\"host2\" writeType=\"0\" switchType=\"1\" slaveThreshold=\"100\" dbType=\"mysql\" dbDriver=\"native\"> &lt;heartbeat>select user()&lt;/heartbeat> &lt;writeHost host=\"hostM1\" url=\"192.168.8.150:3306\" password=\"123456\" user=\"root\"/> &lt;/dataHost> &lt;dataHost balance=\"0\" maxCon=\"1000\" minCon=\"10\" name=\"host3\" writeType=\"0\" switchType=\"1\" slaveThreshold=\"100\" dbType=\"mysql\" dbDriver=\"native\"> &lt;heartbeat>select user()&lt;/heartbeat> &lt;writeHost host=\"hostM1\" url=\"192.168.8.151:3306\" password=\"123456\" user=\"root\"/> &lt;/dataHost> schema——rule.xml——分片配置 3.1 范围分片&lt;tableRule name=\"rang-long-cust\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>rang-long-cust&lt;/algorithm> &lt;/rule> &lt;/tableRule> &lt;function name=\"rang-long-cust\" class=\"io.mycat.route.function.AutoPartitionByLong\"> &lt;property name=\"mapFile\">rang-long-cust.txt&lt;/property> &lt;/function> customer INSERT INTO `customer` (`id`, `name`) VALUES (6666, '赵先生'); INSERT INTO `customer` (`id`, `name`) VALUES (7777, '钱先生'); INSERT INTO `customer` (`id`, `name`) VALUES (16666, '孙先生'); INSERT INTO `customer` (`id`, `name`) VALUES (17777, '李先生'); INSERT INTO `customer` (`id`, `name`) VALUES (26666, '周先生'); INSERT INTO `customer` (`id`, `name`) VALUES (27777, '吴先生'); 3.2 取模分片(ER表)order_info &lt;tableRule name=\"mod-long-order\"> &lt;rule> &lt;columns>order_id&lt;/columns> &lt;algorithm>mod-long&lt;/algorithm> &lt;/rule> &lt;/tableRule> &lt;function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\"> &lt;property name=\"count\">3&lt;/property> &lt;/function> INSERT INTO `order_info` (`order_id`, `uid`, `nums`, `state`, `create_time`, `update_time`) VALUES (1, 1000001, 1, 2, '2019-9-23 14:35:37', '2019-9-23 14:35:37'); INSERT INTO `order_info` (`order_id`, `uid`, `nums`, `state`, `create_time`, `update_time`) VALUES (2, 1000002, 1, 2, '2019-9-24 14:35:37', '2019-9-24 14:35:37'); INSERT INTO `order_info` (`order_id`, `uid`, `nums`, `state`, `create_time`, `update_time`) VALUES (3, 1000003, 3, 1, '2019-9-25 11:35:49', '2019-9-25 11:35:49'); order_detail INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (3, 20180001, 85114752, 19.99, 1, 1, 1); INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (1, 20180002, 25411251, 1280.00, 1, 1, 0); INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (1, 20180003, 62145412, 288.00, 1, 1, 2); INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (2, 20180004, 21456985, 399.00, 1, 1, 2); INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (2, 20180005, 21457452, 1680.00, 1, 1, 2); INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (2, 20180006, 65214789, 9999.00, 1, 1, 3); 3.3 全局表student &lt;table name=\"student\" dataNode=\"dn1,dn2,dn3\" primaryKey=\"sid\" type=\"global\"/> INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (1, '黑白', '166669999'); INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (2, 'AV 哥', '466669999'); INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (3, '最强菜鸟', '368828888'); INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (4, '加载中', '655556666'); INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (5, '猫老公', '265286999'); INSERT INTO `student` (`sid`, `name`, `qq`) VALUES (6, '一个人的精彩', '516895555'); 3.4 Mycat全局idMycat 全局序列实现方式主要有4种: 本地文件方式、数据库方式、本地时间戳算法、ZK。 也可以自定义业务序列. 主要获取全局ID的前缀都是MYCATSEQ_ 3.4.1 本地文件方式配置文件件 server.xml sequnceHandlerType的值: 0:文件、1:数据库、2:本地时间戳、3: ZK &lt;property name=\"sequnceHandlerType\">0&lt;/property> 文件方式:配置conf/sequence_conf.properties CUSTOMER.HISIDS= CUSTOMER.MINID=10000001 CUSTOMER.MAXID=20000000 CUSTOMER.CURID=10000001 语法: select next value for MYCATSEQ_CUSTOMER INSERT INTO `customer` (`id`, `name`) VALUES (next value for MYCATSEQ_CUSTOMER, 'zhangsan'); 优点: 本地加载, 读取速度快. 缺点: 当Mycat 重新发布后, 配置文件中的sequence 需要替换. Mycat 不能做集群部署. 3.4.2 数据库方式&lt;property name=\"sequnceHandlerType\">1&lt;/property> 配置: sequence_db_conf.properties 把这张表创建在146上, 所以是db1 #sequence stored in datanode GLOBAL=dn1 CUSTOMER=dn1 在第一个数据库节点上创建MYCAT_SEQUENCE 表: DROP TABLE IF EXISTS MYCAT_SEQUENCE; CREATE TABLE MYCAT_SEQUENCE ( name VARCHAR(50) NOT NULL, current_value INT NOT NULL, increment INT NOT NULL DEFAULT 1, remark varchar(100), PRIMARY KEY(name)) ENGINE=InnoDB; 注：可以在schema.xml 配置文件中配置这张表, 供外部访问 &lt;table name=\"mycat_sequence\" dataNode=\"dn1\" autoIncrement=\"true\" primaryKey=\"id\">&lt;/table> 创建存储过程, 获取当前的sequence的值 DROP FUNCTION IF EXISTS `mycat_seq_currval`; DELIMITER ;; CREATE DEFINER=`root`@`%` FUNCTION `mycat_seq_currval`(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET latin1 DETERMINISTIC BEGIN DECLARE retval VARCHAR(64); SET retval=\"-999999999,null\"; SELECT concat(CAST(current_value AS CHAR),\",\",CAST(increment AS CHAR) ) INTO retval FROM MYCAT_SEQUENCE WHERE name = seq_name; RETURN retval ; END ;; DELIMITER ; 创建存储过程, 获取下一个sequence DROP FUNCTION IF EXISTS `mycat_seq_nextval`; DELIMITER ;; CREATE DEFINER=`root`@`%` FUNCTION `mycat_seq_nextval`(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET latin1 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = current_value + increment WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END ;; DELIMITER ; 创建存储过程, 设置sequence DROP FUNCTION IF EXISTS `mycat_seq_setval`; DELIMITER ;; CREATE DEFINER=`root`@`%` FUNCTION `mycat_seq_setval`(seq_name VARCHAR(50), value INTEGER) RETURNS varchar(64) CHARSET latin1 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = value WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END ;; DELIMITER ; 插入记录 INSERT INTO MYCAT_SEQUENCE(name,current_value,increment,remark) VALUES ('GLOBAL', 1, 100,''); INSERT INTO MYCAT_SEQUENCE(name,current_value,increment,remark) VALUES ('ORDERS', 1, 100,'订单表使 用'); 测试 select next value for MYCATSEQ_ORDERS 3.4.3 本地时间戳方式ID= 64 位二进制 (42(毫秒)+5(机器 ID)+5(业务编码)+12(重复累加) ，长度为 18 位 &lt;property name=\"sequnceHandlerType\">2&lt;/property> 配置文件sequence_time_conf.properties #sequence depend on TIME WORKID=01 DATAACENTERID=01 验证: select next value for MYCATSEQ_GLOBAL 3.4.5 ZK方式修改conf/myid.properties设置loadZk=true（启动时会从zk加载配置, 一定要注意备份配置文件, 并且先用bin/init_zk_data.sh,把配置文件写入到zk） &lt;property name=\"sequnceHandlerType\">3&lt;/property> 配置文件: sequence_distributed_conf.properties # 代表使用 zk INSTANCEID=ZK # 与 myid.properties 中的 CLUSTERID 设置的值相同 CLUSTERID=010 复制配置文件 cd /usr/local/soft/mycat/conf cp *.txt *.xml *.properties zkconf/ chown -R zkconf/ cd /usr/local/soft/mycat/bin ./init_zk_data.sh 验证: select next value for MYCATSEQ_GLOBAL 3.5 使用在schema.xml 的 table 标签上配置 autoIncrement=&quot;true&quot;,不需要获取和指定序列的情况下, 就可以使用全局ID 4. Mycat 监控和日志监控4.1 监控4.1.1 命令行监控连接到管理端口9066,注意必须带ip mysql -uroot -h127.0.0.1 -p123456 -P9066 全部命令 mysql>show @@help; 命令 作用 show @@server 查看服务器状态, 包括占用内存 show @@database 查看数据库 show @@datanode 查看数据节点 show @@datasource 查看数据源 show @@connection 该命令用于获取Mycat的前端连接状态, 即应用与mycat 的连接 show @@cache 查看缓存使用情况 SQLRouteCache：sql 路由缓存。 TableID2DataNodeCache ： 缓存表主键与分 片对应关系。 ER_SQL2PARENTID ：缓存 ER 分片中子表与 父表关系 reload @@config 重新加载配置文件, 使用这个命令时mycat服务不可用 show @@sysparam 查看参数 show @@sql.high 执行频率高的sql show @@sql.slow 慢SQL设置慢SQL的命令:reload @@sqlslow=5 ; show @@backend 查看后端连接状态 4.1.2 命令行监控 mycatweb 监控https://github.com/MyCATApache/Mycat-download/tree/master/mycat-web-1.0 mycat-web是mycat 提供的一个监控工具, 他依赖于zk 本地必须要运行一个zk, 必须先启动zk 下载mycat-web cd /usr/local/soft wget http://dl.mycat.io/mycat-web-1.0/Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz tar -xzvf Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz 启动mycat-web cd mycat-web nohup ./start.sh &amp; 停止 ：kill start.jar 相关的进程 访问端口8082 http://192.168.8.151:8082/mycat/ mycat server.xml的配置 &lt;!-- 1 为开启实时统计、0 为关闭 --> &lt;property name=\"useSqlStat\">1&lt;/property> 重启mycat 服务生效 4.2 日志log4j的level 配置要改成debug 4.2.1 wrapper.log 日志wrapper.log 日志: mycat 启动、停止、添加服务等都会被记录到此文件, 如果系统环境配置错误或者缺少配置时, 导致mycat无法启动,可以通过查看wrapper.log 定位具体错误原因. 4.2.2 mycat.log 日志mycat.log 为mycat的主要日志文件, 记录了启动时分配的相关buffer 信息， 数据源连接信息, 连接池、动态类加载信息等等. 在conf/log4j2.xml 文件中进行相关配置, 如保留个数、大小、字符集、日志文件大小等. 以select 为例 5. Mycat 高可用目前Mycat 没有实现对多Mycat 集群的支持, 可以暂时使用HAProxy来做负载. 思路：HAProxy 对Mycat 进行负载. Keepalived 实现VIP 6.Mycat注解6.1 注解的作用当关联的数据不再同一个节点的时候, Mycat是无法实现跨库join的. 举例: 如果直接在150节点插入主表数据,151插入明细表数据, 此时关联查询无法查询出来数据. -- 150 节点插入 INSERT INTO `order_info` (`order_id`, `uid`, `nums`, `state`, `create_time`, `update_time`) VALUES (9, 1000003, 2673, 1, '2019-9-25 11:35:49', '2019-9-25 11:35:49'); -- 151 节点插入 INSERT INTO `order_detail` (`order_id`, `id`, `goods_id`, `price`, `is_pay`, `is_ship`, `status`) VALUES (9, 20180001, 2673, 19.99, 1, 1, 1); 在mycat 数据库查询, 直接查询没有查到结果 select a.order_id,b.price from order_info a, order_detail b where a.nums = b.goods_id; Mycat 作为一个中间件,有很多自身不支持的SQL语句,比如存储过程,但是这些语句在实际的数据库节点上是可以执行的. 有没有办法让Mycat 做一层透明的代理转发,直接找到目标数据节点去执行这些SQL语句呢? 那我们必须有一种方式来告诉Mycat 应该在那些节点上执行. 这个就是Mycat 的注解, 我们在需要执行的SQL 语句前面加上一段代码, 帮助Mycat 找到我们的目标节点. 6.2 注解的用法注解的形式是: /*!mycat: sql=注解 SQL 语句*/ 注解的使用方式: /*!mycat: sql=注解 SQL 语句*/ 真正执行的 SQL 使用时, 将= 号后面的”注解SQL语句”, 替换为需要的SQL语句即可. 使用注解有一些限制, 或者注意的地方 原始SQL 注解SQL select 如果需要分片,则使用能确定分片的注解, 比如/*!mycat: sql=select * from users where user_id=1*/如果要在所有的分片上执行则可以不加能确定分片的条件 insert 使用insert的表作为注解SQL,必须能确定到某个分片原始SQL插入的字段必须包含分片字段非分片字段(只在某个节点上): 需要能确定到某个分片 delete 使用delete的表作为注解SQL update 使用update的表作为注解SQL 使用注解并不会额外增加Mycat的执行时间,从解析复杂度以及性能考虑, 注解SQL 应该尽量简单,因为它只是用来做路由的. 注解可以帮我们解决什么问题呢? 6.3 注解使用案例6.3.1 创建表或存储过程customer.id=1 全部路由到146 -- 存储过程 /*!mycat: sql=select * from customer where id =1 */ CREATE PROCEDURE test_proc() BEGIN END ; -- 表 /*!mycat: sql=select * from customer where id =1 */ CREATE TABLE test2(id INT); 6.3.2 特殊语句自定义分片Mycat 本身不支持insert,select, 通过注解支持 /*!mycat: sql=select * from customer where id =1 */ INSERT INTO test2(id) SELECT id FROM order_detail; 6.3.3 多表shareJoin/*!mycat:catlet=io.mycat.catlets.ShareJoin */ select a.order_id,b.price from order_info a, order_detail b where a.nums 6.3.4 读写分离读写分离:配置Mycat读写分离后, 默认查询都会从读节点获取数据, 但是有些场景需要获取实时数据, 如果从读节点获取数据可能因延时而无法实现实时, Mycat 支持通过注解/*balance*/ 来强制从写节点(write host) 查询数据. /*balance*/ select a.* from customer a where a.id=6666; 读写分离数据库选择(1.6版本之后) /*!mycat: db_type=master */ select * from customer; /*!mycat: db_type=slave */ select * from customer; /*#mycat: db_type=master */ select * from customer; /*#mycat: db_type=slave */ select * from customer; 支持直接的! 不被mysql 单库兼容 注解支持# 不被Mybatis兼容 6.4 注解原理Mycat 在执行SQL 之前会先解析SQL语句, 在获取分片信息后再到对应的物理节点上执行。如果SQL 无法解析,则不能被执行. 如果语句有注解, 则会先会解析注解的内容获取分片信息,再把真正需要执行的SQL语句发送到对应的物理节点上. 所以我们在使用注解的时候, 应该清楚的知道目标SQL 应该在哪个节点上执行, 注解的SQL 也指向这个分片,这样才能使用. 如果注解没有使用正确的条件, 会导致原始SQL 被发送到所有的节点上执行, 造成数据错误. 7. 分片策略详解分片的目标是将大量的数据和访问请求均分分布在多个节点上, 通过这种方式提升数据服务的存储和负载能力. 总体上分为连续分片和离散分片, 还有一种是连续分片和离散分片的结合, 例如先范围后取模. 比如范围分片(id或者时间)就是典型的连续分片, 单个分区的数量和边界是确定的. 离散分片的分区总数量和边界是确定的, 例如对key 进行哈希运算, 或者再取模。 关键词: 范围查询、热点数据、扩容. 连续分片优点: 范围条件查询消耗资源少(不需要汇总数据) 扩容无需迁移数据(分片固定) 连续分片缺点: 存在热点数据的可能性 并发访问能力受限于单一或者少量DataNode(访问集中) 离散分片优点: 并发访问能力增强(负载到不同的节点) 范围条件查询能力提升(并行计算) 离散分片缺点: 数据扩容比较困难,设计到数据迁移问题 数据库连接消耗比较多 7.1 连续分片范围分片&lt;tableRule name=\"auto-sharding-long\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>rang-long&lt;/algorithm> &lt;/rule> &lt;/tableRule> &lt;function name=\"rang-long\" class=\"io.mycat.route.function.AutoPartitionByLong\"> &lt;property name=\"mapFile\">autopartition-long.txt&lt;/property> &lt;/function> # range start-end ,data node index # K=1000,M=10000. 0-500M=0 500M-1000M=1 1000M-1500M=2 特点: 容易出现冷热数据 按自然月分片建表语句 CREATE TABLE `sharding_by_month` ( `create_time` timestamp NULL DEFAULT NULL ON UPDATE `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 逻辑表 &lt;schema name=\"catmall\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"> &lt;table name=\"sharding_by_month\" dataNode=\"dn1,dn2,dn3\" rule=\"qs-sharding-by-month\" /> &lt;/schema> 分片规则 &lt;tableRule name=\"sharding-by-month\"> &lt;rule> &lt;columns>create_time&lt;/columns> &lt;algorithm>qs-partbymonth&lt;/algorithm> &lt;/rule> &lt;/tableRule> 分片算法 &lt;function name=\"qs-partbymonth\" class=\"io.mycat.route.function.PartitionByMonth\"> &lt;property name=\"dateFormat\">yyyy-MM-dd&lt;/property> &lt;property name=\"sBeginDate\">2019-10-01&lt;/property> &lt;property name=\"sEndDate\">2019-12-31&lt;/property> &lt;/function> columns 标识将要分片的表字段, 字符串类型, 与dataformat格式一致 algorithm:为分片函数, dataFormat: 为日期字符串格式 sBeginDate为开始日期 sEndDate: 为结束日期 注意: 节点个数要大于月份的个数 测试语句 INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2019-10-16', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2019-10-27', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2019-11-04', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2019-11-11', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2019-12-25', database()); INSERT INTO sharding_by_month (create_time,db_nm) VALUES ('2019-12-31', database()); 另外还有按天分片(可以指定多少天一个分片)、按小时分片 7.2 离散分片枚举分片将所有可能出现的值列举出来,指定分片.例如: 全局34个省, 要将不同的省的数据存放在不同的节点, 可用枚举 的方式 建表语句 CREATE TABLE `sharding_by_intfile` ( `age` int(11) NOT NULL, `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 逻辑表 &lt;table name=\"sharding_by_intfile\" dataNode=\"dn$1-3\" rule=\"qs-sharding-by-intfile\" /> 分片规则 &lt;tableRule name=\"sharding-by-intfile\"> &lt;rule> &lt;columns>sharding_id&lt;/columns> &lt;algorithm>hash-int&lt;/algorithm> &lt;/rule> &lt;/tableRule> 分片算法 &lt;function name=\"hash-int\" class=\"org.opencloudb.route.function.PartitionByFileMap\"> &lt;property name=\"mapFile\">partition-hash-int.txt&lt;/property> &lt;property name=\"type\">0&lt;/property> &lt;property name=\"defaultNode\">0&lt;/property> &lt;/function> type: 默认值为0, 0表示Integer,非零表示String PartitionByFileMap.java 通过map实现 策略文件: partition-hash-int.txt 16=0 17=1 18=2 插入数据测试: INSERT INTO `sharding_by_intfile` (age,db_nm) VALUES (16, database()); INSERT INTO `sharding_by_intfile` (age,db_nm) VALUES (17, database()); INSERT INTO `sharding_by_intfile` (age,db_nm) VALUES (18, database()) 特点: 适用于枚举值固定的场景. 一致性哈希一致性hash 有效的解决了分布式数据的扩容问题 建表语句 CREATE TABLE `sharding_by_murmur` ( `id` int(10) DEFAULT NULL, `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 逻辑表 &lt;schema name=\"test\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"> &lt;table name=\"sharding_by_murmurhash\" primaryKey=\"id\" dataNode=\"dn$1-3\" rule=\"sharding-by-murmur\" /> &lt;/schema> 分片规则 &lt;tableRule name=\"sharding-by-murmur\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>qs-murmur&lt;/algorithm> &lt;/rule> &lt;/tableRule> 分片算法 &lt;function name=\"qs-murmur\" class=\"io.mycat.route.function.PartitionByMurmurHash\"> &lt;property name=\"seed\">0&lt;/property> &lt;property name=\"count\">3&lt;/property> &lt;property name=\"virtualBucketTimes\">160&lt;/property> &lt;/function> 测试语句 INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (1, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (2, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (3, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (4, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (5, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (6, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (7, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (8, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (9, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (10, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (11, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (12, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (13, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (14, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (15, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (16, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (17, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (18, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (19, database()); INSERT INTO `sharding_by_murmur` (id,db_nm) VALUES (20, database()); 特点: 可以一定程序上 减少数据的迁移. 十进制取模分片根据分片键进行十进制求模运算. &lt;tableRule name=\"mod-long\"> &lt;rule> &lt;columns>sid&lt;/columns> &lt;algorithm>mod-long&lt;/algorithm> &lt;/rule> &lt;/tableRule> &lt;function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\"> &lt;!-- how many data nodes --> &lt;property name=\"count\">3&lt;/property> &lt;/function> 特点: 分布均匀, 但是迁移工作量比较大. 固定分片哈希这是先求模得到逻辑分片号, 再根据逻辑分片号直接映射到物理分片的一种散列算法 建表语句 CREATE TABLE `sharding_by_long` ( `id` int(10) DEFAULT NULL, `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 逻辑表 &lt;schema name=\"test\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"> &lt;table name=\"sharding_by_long\" dataNode=\"dn$1-3\" rule=\"qs-sharding-by-long\" /> &lt;/schema> 分片规则 &lt;tableRule name=\"qs-sharding-by-long\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>qs-sharding-by-long&lt;/algorithm> &lt;/rule> &lt;/tableRule> 平均分成8片(%1024的余数, 1024=128*8) &lt;function name=\"qs-sharding-by-long\" class=\"io.mycat.route.function.PartitionByLong\"> &lt;property name=\"partitionCount\">8&lt;/property> &lt;property name=\"partitionLength\">128&lt;/property> &lt;/function> partitionCount: 为指定分片个数列表 partitionLength: 为分片范围列表 第二个例子: 两个数组,分成不均匀的3个节点(%1024的余数,1024=2*256+1*512) &lt;function name=\"qs-sharding-by-long\" class=\"io.mycat.route.function.PartitionByLong\"> &lt;property name=\"partitionCount\">2,1&lt;/property> &lt;property name=\"partitionLength\">256,512&lt;/property> &lt;/function> 3个节点, 对1024取模余数的分布 测试语句 INSERT INTO `sharding_by_long` (id,db_nm) VALUES (222, database()); INSERT INTO `sharding_by_long` (id,db_nm) VALUES (333, database()); INSERT INTO `sharding_by_long` (id,db_nm) VALUES (666, database()); 特点: 在一定范围内id是连续分布的. 取模范围分布逻辑表 &lt;schema name=\"test\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"> &lt;table name=\"sharding_by_pattern\" primaryKey=\"id\" dataNode=\"dn$0-10\" rule=\"qs-sharding-by-pattern\" /> &lt;/schema> 建表语句 CREATE TABLE `sharding_by_pattern` ( `id` varchar(20) DEFAULT NULL, `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 分片规则 &lt;tableRule name=\"sharding-by-pattern\"> &lt;rule> &lt;columns>user_id&lt;/columns> &lt;algorithm>sharding-by-pattern&lt;/algorithm> &lt;/rule> &lt;/tableRule> 分片算法 &lt;function name=\"sharding-by-pattern\" class=\" io.mycat.route.function.PartitionByPattern\"> &lt;property name=\"patternValue\">100&lt;/property> &lt;property name=\"defaultNode\">0&lt;/property> &lt;property name=\"mapFile\">partition-pattern.txt&lt;/property> &lt;/function> patternValue 取模基数, 这里设置成100 partition-pattern.txt , 一共三个节点 id=19%100=19，在 dn1； id=222%100=22，dn2； id=371%100=71，dn3 # id partition range start-end ,data node index ###### first host configuration 1-20=0 21-70=1 71-100=2 0-0=0 测试语句: INSERT INTO `sharding_by_pattern` (id,db_nm) VALUES (19, database()); INSERT INTO `sharding_by_pattern` (id,db_nm) VALUES (222, database()); INSERT INTO `sharding_by_pattern` (id,db_nm) VALUES (371, database()); 特点: 可以调整节点的数据分布 范围取模分片建表语句 CREATE TABLE `sharding_by_rang_mod` ( `id` bigint(20) DEFAULT NULL, `db_nm` varchar(20) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 逻辑表 &lt;schema name=\"test\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"> &lt;table name=\"sharding_by_rang_mod\" dataNode=\"dn$1-3\" rule=\"qs-sharding-by-rang-mod\" /> &lt;/schema> 分片规则 &lt;tableRule name=\"qs-sharding-by-rang-mod\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>qs-rang-mod&lt;/algorithm> &lt;/rule> &lt;/tableRule> 分片算法 &lt;function name=\"qs-rang-mod\" class=\"io.mycat.route.function.PartitionByRangeMod\"> &lt;property name=\"mapFile\">partition-range-mod.txt&lt;/property> &lt;/function> partition-range-mod.txt # range start-end ,data node group size 0-20000=1 20001-40000=2 解读: 先范围后取模, id在20000以内的, 全部分布到dn1, id在20001-40000的, %2分布到dn2、dn3. 插入数据 INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (666, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (6667, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (16666, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (21111, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (22222, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (23333, database()); INSERT INTO `sharding_by_rang_mod` (id,db_nm) VALUES (24444, database()); 特点:扩容的时候旧数据无需迁移. 其他分片规则应用指定分片: PartitionDirectBySubString 日期范围哈希: PartitionByRangeDateHash 冷热数据分片： PartitionByHotDate 也可以自定义分片规则: extends AbstractPartitionAlgorithm implements RuleAlgorithm。 7.3 切分规则的选择步骤: 找到需要切分的大表, 和关联的表 确定分片的字段(尽量使用主键),一般是用最频繁使用的查询条件 考虑单个分片的存储容量和请求,数据增长(业务特性)、扩容和数据迁移问题 例如： 按照什么递增? 序号还是日期?主键是否还有业务意义? 一般来说,分片数要比当前规划的节点数要大 总结: 根据业务场景, 合理的选择分片规则 8. Mycat 离线扩缩容当我们规划了数据分片, 而数据已经超过了单个节点的存储上限或者需要下线节点的时候, 就需要对数据进行重新分片. 8.1 Mycat 自带的工具8.1.1 准备工作 mycat 所在环境安装mysql 客户端 mycat 的lib 目录下添加mysql的jdbc 驱动 对扩缩容的表所有节点进行备份, 以免迁移失败后的数据恢复 8.1.2 步骤以取模分片sharding-by-mod 缩容为例. 复制 schema.xml、rule.xml 重命名为newSchema.xml、newRule.xml 放于conf目录下 修改newSchema.xml 和 newRule.xml 配置文件为扩缩容后的mycat 配置参数(表的节点数、数据源、路由规则) 注意： 只有节点变化的表才会进行迁移,仅分片配置变化不会迁移. newSchema.xml &lt;table name=\"sharding_by_mod\" dataNode=\"dn1,dn2,dn3\" rule=\"qs-sharding-by-mod\" /> 改成(减少了一个节点) &lt;table name=\"sharding_by_mod\" dataNode=\"dn1,dn2\" rule=\"qs-sharding-by-mod\" /> newRule.xml 修改count 的个数 &lt;function name=\"qs-sharding-by-mod-long\" class=\"io.mycat.route.function.PartitionByMod\"> &lt;property name=\"count\">2&lt;/property> &lt;/function> 修改conf 目录下的migrateTables.properties 的配置文件,告诉工具那些表需要进行扩容或者缩容, 没有出现在此配置文件的schema 表 不会进行数据迁移, 格式: 注意: 不迁移的表, 不要修改dn的个数, 否则会出错 ER表,因为只有主表有分片规则, 字表不会进行迁移 catmall=sharding-by-mod dataMigrate.sh 中这个配置必须配置 通过命令 &quot;find / -name mysqldump&quot; 查找mysqldump 路径为：/usr/bin/mysqldump,指定#mysql bin 路径为/usr/bin #mysql bin 路径 RUN_CMD=\"$RUN_CMD -mysqlBin= /usr/bin/ 停止mycat 服务 执行bin/ dataMigrate.sh 脚本 必须要配置java 环境变量, 不能用openjdk 脚本执行完成, 如果最后的数据迁移验证通过, 就可以将之前的newSchema.xml 和 newRule.xml 替换之前的 schema.xml 和 rule.xml 文 件，并重启 mycat 即可。 注意事项： 保证分片表迁移数据前后路由规则一直(取模-取模) 保证分片表迁移数据前后分片字段一致 全局表将被忽略 不要将非分片表配置到 migrateTables.properties 文件中., 暂时只支持分片表使用Mysql 作为数据源的扩容缩容 migrate 限制比较多, 还可以使用mysqldump 方法 8.2 mysqldump 方式系统第一次上线, 把单张表迁移到mycat,也可以用mysqldump Mysql 导出 mysqldump -uroot -p123456 -h127.0.0.1 -P3306 -c -t --skip-extended-insert gpcat > mysql-1017.sql -c 代表带列名 -t 代表只要数据, 不要建表语句 –skip-extended-insert 代表生成多行 insert（mycat childtable 不支持多行插入 咕泡出品，必属精品 www.gupaoedu.com 28 ChildTable multi insert not provided） Mycat导入 mysql -uroot -p123456 -h127.0.0.1 -P8066 catmall < mysql-1017.sql Mycat导出 mysqldump -h192.168.8.151 -uroot -p123456 -P8066 -c -t --skip-extended-insert catmall customer > mycat-cust.sql 其他导入方式: load data local infile &#39;/mycat/customer.txt&#39; into table customer; source sql &#39;/mycat/customer.sql&#39;; 9. 核心流程总结官网的架构图 9.1 启动 mycatServer 启动, 解析配置文件, 包括服务器、分片规则 创建工作线程, 建立前端连接和后端连接 9.2 执行SQL 前端连接接受MYSQL 命令 解析MYSQL, mycat 用的是Druid 的 DruidParser 获取路由 改写MYSQL,例如两个条件在两个节点, 则变成两条单独的SQL 例如： select * from customer where id in(5000001, 10000001); 改写成 select * from customer where id = 5000001；（dn2 执行） select * from customer where id = 10000001；（dn3 执行） 与后盾数据库建立连接 发送SQL语句到MYSQL 执行 获取返回结果 处理返回结果, 例如排序、计算等等 返回给客户端 10 源码下载和调试环境搭建10.1 下载源代码, 导入工程git clone https://github.com/MyCATApache/Mycat-Server 10.2 配置schema.xml &lt;?xml version=\"1.0\"?> &lt;!DOCTYPE mycat:schema SYSTEM \"schema.dtd\"> &lt;mycat:schema xmlns:mycat=\"http://io.mycat/\"> &lt;schema name=\"TESTDB\" checkSQLschema=\"true\" sqlMaxLimit=\"100\"> &lt;table name=\"travelrecord\" dataNode=\"dn1,dn2,dn3\" rule=\"auto-sharding-long\" /> &lt;table name=\"company\" primaryKey=\"ID\" type=\"global\" dataNode=\"dn1,dn2,dn3\" /> &lt;table name=\"hotnews\" primaryKey=\"ID\" autoIncrement=\"true\" dataNode=\"dn1,dn2,dn3\" rule=\"mod-long\" /> &lt;/schema> &lt;dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"db1\" /> &lt;dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"db2\" /> &lt;dataNode name=\"dn3\" dataHost=\"localhost1\" database=\"db3\" /> &lt;dataHost name=\"localhost1\" maxCon=\"20\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"> &lt;heartbeat>select user()&lt;/heartbeat> &lt;writeHost host=\"hostM1\" url=\"127.0.0.1:3306\" user=\"root\" password=\"123456\"> &lt;/writeHost> &lt;/dataHost> &lt;/mycat:schema> 10.3 表结构本地数据库创建db1、db2、db3 数据库, 全部执行建表脚本 CREATE TABLE `company` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(64) DEFAULT '', `market_value` bigint(20) DEFAULT '0', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4; CREATE TABLE `hotnews` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `title` varchar(64) DEFAULT '', `content` varchar(512) DEFAULT '0', `time` varchar(8) DEFAULT '', `cat_name` varchar(10) DEFAULT '', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; CREATE TABLE `travelrecord` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `city` varchar(32) DEFAULT '', `time` varchar(8) DEFAULT '', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 10.4逻辑表配置travelrecord 表配置 &lt;table name=\"travelrecord\" dataNode=\"dn1,dn2,dn3\" rule=\"auto-sharding-long\" /> &lt;tableRule name=\"auto-sharding-long\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>rang-long&lt;/algorithm> &lt;/rule> &lt;/tableRule> &lt;function name=\"rang-long\" class=\"io.mycat.route.function.AutoPartitionByLong\"> &lt;property name=\"mapFile\">autopartition-long.txt&lt;/property> &lt;/function> hotnews 表配置 &lt;table name=\"hotnews\" primaryKey=\"ID\" autoIncrement=\"true\" dataNode=\"dn1,dn2,dn3\" rule=\"mod-long\" /> &lt;tableRule name=\"mod-long\"> &lt;rule> &lt;columns>id&lt;/columns> &lt;algorithm>mod-long&lt;/algorithm> &lt;/rule> &lt;/tableRule> &lt;function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\"> &lt;!-- how many data nodes --> &lt;property name=\"count\">3&lt;/property> &lt;/function> company 表配置 &lt;table name=\"company\" primaryKey=\"ID\" type=\"global\" dataNode=\"dn1,dn2,dn3\" /> 10.5 debug 方式启动debug方式启动`main 方式 Mycat-Server-1.6.5-RELEASE\\src\\main\\java\\io\\mycat\\MycatStartup.java 10.6 连接本地Mycat 服务测试语句 insert into travelrecord(`id`, `city`, `time`) values(1, '长沙', '20191020'); insert into hotnews(`title`, `content`) values('新闻', 'aaaa'); insert into company(`name`, `market_value`) values('spring', 100); 10.7 调试入口连接入口 io.mycat.net.NIOAcceptor#accept SQL入口 io.mycat.server.ServerQueryHandler#query","categories":[{"name":"数据库","slug":"数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库","slug":"数据库/数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"Zookeeper原理之Leader选举源码分析","slug":"微服务/zookpeer/Zookeeper原理之Leader选举源码分析","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/zookeeper-yuan-li-zhi-leader-xuan-ju-yuan-ma-fen-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/zookeeper-yuan-li-zhi-leader-xuan-ju-yuan-ma-fen-xi/","excerpt":"","text":"Zookeeper原理之Leader选举源码分析Zookeeper 的一致性Zookeeper 的来源对于zookeeper的一致性问题, 我们再从来源问题梳理一遍一致性的问题. 我们知道zookeeper的来源, 是来自于Google chubby, 为了分布式环境下, 如何从多个server 中选举出master server. 那么这么多个server 就需要涉及到一致性问题, 这个一致性体现的是多个server 就master 这个投票在分布式环境下达成一致性. 简单来说, 就是最终听谁的. 但是在网络环境中由于网络环境的不可靠性, 会存在消息丢失或者被篡改等问题. 所以如何在这样一个环境中快速并且正确的在多个server 中对某一个数据达成一致性并且保证无论发生任何异常, 都不会破坏整个系统一致性呢? 所以Lampot大神设计了一套Paxos算法, 多个server 基于这个算法就可以达成一致性。而Google chubby 就是基于paxos 算法的实现, 用来实现分布式锁服务. 并且提供了master 选举的服务. Paxos 在chubby 中的应用也许大家会有疑问, Chubby 于paxos 算法有什么关系呢? Chubby 本来应该被设计成一个包含Paxos 算法的协议库, 使得应用程序可以基于这个库方便的使用paxos 算法, 但是它并没有这么做, 而是把chubby 设计成了一个需要访问中心化节点的分布式锁服务. 既然是 一个服务, 那么它肯定需要是一个高可靠的服务. 所以Chubby 被构建成了一个集群, 集群中存在一个中心节点(master), 采用paxos协议, 通过投票的方式来选举一个获取过半皮票数的服务器作为master, 在chubby集群中, 每个服务器都会维护一份数据的副本, 在实际运行的过程中, 只有master 服务器能执行事务操作, 其他服务器都是使用paxos 协议从master 节点同步最新的数据, 而zookeeper 是chubby 的开源实现, 所以实现原理和chubby 基本是一致性的. zookeeper 的一致性是什么情况呢?zookeeper的一致性, 体现的是什么一致性呢? 根据前面讲的zab 协议的同步流程, 在zookeeper 集群内部的数据副本同步,是基于过半提交的策略,意味着他是最终一致性, 并不满足强一致性的要求. 其实正确来说, zookeeper是一个顺序一致性模型. 由于zookeeper 设计出来是提供分布式锁服务, 那么意味着它本身需要实现顺序一致性 （ http://zookeeper.apache.org/doc/r3.5.5/zookeeperProgrammers.ht ml#ch_zkGuarantees ） 顺序一致性是在分布式环境下实现分布式锁的基本要求, 比如当一个多个程序来争抢锁, 如果ClientA 获得锁后,后续所有来挣钱锁的程序看到的锁的状态都应该是被ClientA 锁定了, 而不是其他状态. 什么是顺序一致性在讲顺序一致性之前, 咱们先思考一个问题, 假如说zookeeper是 一个最终一致性模型, 那么它会发生什么情况? ClientA/B/C 假设只串行执行, ClientA 更新zookeeper 上的一个值x. ClientB 和ClientC 分别读取集群中的不同副本, 返回的x 的值是不一样的. ClientC 的读取操作是发生在clientB 之后, 但是却读到了过期的值. 很明显, 这是一种弱一致性模型. 如果用它来实现锁机制是有问题的. 顺序一致性提供了更强的一致性保证, 我们来观察下面这个图, 从时间轴来看, B0 发生在A0之前, 读取的值是0, B2 发生在A0之后，读取到的x 的值为1, 而读操作B1/C0/C1 和写操作A0 在时间轴上有重叠, 因此他们可能读的旧的值为0, 也有可能读取到新的值1, 但是在强顺序一致性模型中, 如果B1得到的x的值为1, 那么C1看到的值也一定为1. 需要注意的是,由于网络的延迟以及系统本身执行请求的不确定性, 会导致请求发起的客户端不一定会在服务端执行的早。最终以服务端执行的结果为准. 简单来说: 顺序一致性是针对单个操作, 单个数据对象. 属于CAP中C 这个范畴. 一个数据被更新后, 能够立马被后续的操作读到. 但是zookeeper的 顺序一致性实现是缩水版本, 在下面的这个网页中,可以看到官网对于一致性的这块做了解释. http://zookeeper.apache.org/doc/r3.5.5/zookeeperProgrammers.html#ch_zkGuarantees zookeeper 不保证在每个实例中, 两个不同的客户端具有相同的zookeeper 数据视图, 由于网络延迟等因素, 一个客户端可能会在另外一个客户端收到更改通知之前执行更新, 考虑到2个客户端A 和B 的场景, 如果A 把znode /a 的值从0设置为1, 然后告诉客户端B 读取/a, 则客户端B 可能读取到旧的值0, 具体取决于他连接到的服务器, 如果客户端A 和B 要读取 必须要读取到想听的值, 那么ClientB 在读取操作之前要执行sync方法. 除此之外, zookeeper 基于zxid 以及阻塞队列的方式来实现请求的顺序一致性. 如果client 连接到一个最新的follower 上, 那么它read 读取到了最近的数据, 然后client 由于网络原因重新连接到zookeeper 节点, 而这个时候连接到一个还没有完成数据同步的follower节点, 那么这一次读取到的数据不就是旧的数据了吗? 实际上zookeeper 处理了这种情况, client 会记录自己已经读取到的最大的zxid, 如果client 重连到server 发现client 的zxid 比自己的大. 连接会失败. Single System Image 的理解 zookeeper 官网还说它保证了 “Single System Image “, 其解释为 “ A client will see the same view of the service regardless of the server that it connects to ”. 实际上看来这个解释还是有一点误导性的. 其实由上面的zxid 原理就可以看出来, 它表达的意思是 client 只要连接过一次zookeeper, 就不会有历史的倒退. https://github.com/apache/zookeeper/pull/931 Leader选举的原理接下来我们基于源码来分析leader 选举的整个过程, Leader 选举存在两个阶段, 一个是服务器启动时的leader 选举, 另一个是运行过程中leader 节点宕机导致的leader 选举。 在开始分析选举的原理之前, 先了解几个重要的参数。 服务器id(myid)​ 比如有三台服务器, 编号分别是1,2,3 ​ 编号越大在选择算法中的权重越大 ​ zxid 事务id 值越大说明数据越新,在选举算法中的权重也越大 逻辑时钟(epoch - logicalclock)或者叫投票的次数, 同一轮投票过程中的逻辑时钟值是相同的. 每投完一票这个数据就会增加, 然后与接收到的其他服务器返回的投票信息中的数值相比,根据不同的值做出不同的判断. 选举状态​ LOOKING: 竞选状态。 ​ FOLLOWING: 随从状态, 同步leader 状态, 参与投票 ​ OBSERVING : 观察状态, 同步leader 状态, 不参与投票. ​ LEADING : 领导者状态 服务器启动的时候leader 选举每个节点启动的时候状态都是LOOKING ,处于观望状态, 接下来就进行选主流程. 若进行leader选举, 则至少需要两台机器, 这里选取3台机器组成的服务器集群为例. 在集群初始化阶段,当有一台服务器server1 启动时, 其单独无法进行和完成leader 选举。 当第二台服务器server2 启动的时候, 此时两台机器可以相互通信,每台机器都试图找到leader, 于是进入leader 选举过程. 选举过程如下: 每个server 发出一个投票, 由于是初始情况, server1 和server2 都会将自己作为leader 服务器来进行投票, 每次投票都会包含所推荐的服务器的myid 和zxid、rpoch,使用(myid,zxid,epoch)来标识, 此时server1 的投票为(1,0),server2 的投票为(2,0),然后各自将这个投票发送给集群中的其他机器. 接受来自各个服务器的投票, 集群的每个服务器收到投票后, 首先判断该投票的有效性, 如检查是否为本轮投票(epoch)、是否来自 LOOKING 状态的服务器. 处理投票, 针对每一个投票, 服务器都需要将别人的投票来自己的投票进行PK,PK 规则如下: 优先比较 epoch 其次检查zxid, zxid 比较大的服务器优先为leader 如果zxid 相同, 那么比较myid, myid 较大的服务器作为leader 服务器. 对于server1 而言,它的投票是(1,0), 接受server2 的投票 为(2,0), 首先会比较两者的zxid,均为0, 再比较myid, 此时server2 的myid 最大, 于是更新自己的投票为(2,0), 然后重新开始投票, 对于server2而言, 其无需更新自己的投票, 只是再次向集群中所有寄去发出上一个投票信息即可. 统计投票 每次投票后, 服务器都会统计投票信息, 判断是否已经有过接受到相同的投票信息, 对于server1 、server2而言, 都统计出集群中已经有2台机器接受了(2,0) 的投票信息, 此时便认为已经选出了leader. 改变服务器状态 一旦确定了leader, 每个服务器都会更新自己的状态, 如果是follower, 那么就变更为following, 如果是leader, 就变更为leading. 运行过程中的leader 选举当集群中的leader 服务器出现宕机或者不可用的情况下, 那么整个集群将无法对外提供服务, 而是进入新一轮的leader 选举, 服务器运行期间的leader 选举和启动时候的leader 选举基本过程是一致的. 变更状态 Leader 挂后, 余下的废Observer 服务器都会将自己的服务器状态变更为LOOKING，然后进入到leader 选举过程. 每个server 会发出一个投票, 在运行期间, 每个服务器的zxid 可能不同, 此时假设server1 的zxid 为123, server3的zxid 为122, 在第一轮的投票中,server1 和server3 都投自己, 产生投票(1,123),(3,122), 然后各自将投票发送给集群中所有机器. 接受来自各个服务器的投票,与启动时过程相同. 处理投票, 与启动时过程相同, 此时， server1 将会成为leader 统计投票.与启动时过程相同. 改变服务器状态 Leader 选举的源码分析源码分析, 最关键是要好一个入口, 对于zk 的leader 选举, 并不是由客户端触发的, 而是在启动的时候会触发一次选举. 所以我们们可以直接去看启动脚本 zkServer.sh 中的命令. ZOOMAIN 就是QuorumPeerMain,我们基于这个入口来看 nohup \"$JAVA\" $ZOO_DATADIR_AUTOCREATE \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \\\"-Dzookeeper.log.file=$&#123;ZOO_LOG_FILE&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" \\-XX:+HeapDumpOnOutOfMemoryError -XX:OnOutOfMemoryError='kill -9 %p' \\-cp \"$CLASSPATH\" $JVMFLAGS $ZOOMAIN \"$ZOOCFG\" > \"$_ZOO_DAEMON_OUT\" 2>&1 < /dev/null & QuorumPeerMain 的main方法main方法中,调用了initializeAndRun() 方法进行初始化并且运行. protected void initializeAndRun(String[] args) throws ConfigException, IOException, AdminServerException &amp;#123; // 设置配置参数, 如果args 不为0, 可以基于外部的配置路径来进行解析 QuorumPeerConfig config = new QuorumPeerConfig(); if (args.length == 1) &amp;#123; config.parse(args[0]); &amp;#125; // Start and schedule the the purge task // 这里启动了一个线程, 来定时对日志进行清理 DatadirCleanupManager purgeMgr = new DatadirCleanupManager(config .getDataDir(), config.getDataLogDir(), config .getSnapRetainCount(), config.getPurgeInterval()); purgeMgr.start(); // 如果是集群模式, 会调用runFromConfig servers 其实就是我们在zoo.cfg 中配置的集群节点 if (args.length == 1 &amp;&amp; config.isDistributed()) &amp;#123; runFromConfig(config); &amp;#125; else &amp;#123; LOG.warn(\"Either no config or no quorum defined in config, running \" + \" in standalone mode\"); // there is only server in the quorum -- run as standalone ZooKeeperServerMain.main(args); &amp;#125; &amp;#125; runFromConfig(config)从名字可以看出, 是基于配置文件来进行启动。 所以整个方法都是对参数进行解析和设置, 直接看核心的代码quorumPeer.start();,启动一个线程, 那么从这句代码可以看出来 QuorumPeerMain 其实是继承了一个Thread, 那么这里面一定有一个run方法. public void runFromConfig(QuorumPeerConfig config) throws IOException, AdminServerException &amp;#123; try &amp;#123; ManagedUtil.registerLog4jMBeans(); &amp;#125; catch (JMException e) &amp;#123; LOG.warn(\"Unable to register log4j JMX control\", e); &amp;#125; LOG.info(\"Starting quorum peer\"); try &amp;#123; ServerCnxnFactory cnxnFactory = null; ServerCnxnFactory secureCnxnFactory = null; if (config.getClientPortAddress() != null) &amp;#123; cnxnFactory = ServerCnxnFactory.createFactory(); cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns(), false); &amp;#125; if (config.getSecureClientPortAddress() != null) &amp;#123; secureCnxnFactory = ServerCnxnFactory.createFactory(); secureCnxnFactory.configure(config.getSecureClientPortAddress(), config.getMaxClientCnxns(), true); &amp;#125; quorumPeer = getQuorumPeer(); quorumPeer.setTxnFactory(new FileTxnSnapLog( config.getDataLogDir(), config.getDataDir())); quorumPeer.enableLocalSessions(config.areLocalSessionsEnabled()); quorumPeer.enableLocalSessionsUpgrading( config.isLocalSessionsUpgradingEnabled()); //quorumPeer.setQuorumPeers(config.getAllMembers()); quorumPeer.setElectionType(config.getElectionAlg()); quorumPeer.setMyid(config.getServerId()); quorumPeer.setTickTime(config.getTickTime()); quorumPeer.setMinSessionTimeout(config.getMinSessionTimeout()); quorumPeer.setMaxSessionTimeout(config.getMaxSessionTimeout()); quorumPeer.setInitLimit(config.getInitLimit()); quorumPeer.setSyncLimit(config.getSyncLimit()); quorumPeer.setConfigFileName(config.getConfigFilename()); quorumPeer.setZKDatabase(new ZKDatabase(quorumPeer.getTxnFactory())); quorumPeer.setQuorumVerifier(config.getQuorumVerifier(), false); if (config.getLastSeenQuorumVerifier() != null) &amp;#123; quorumPeer.setLastSeenQuorumVerifier(config.getLastSeenQuorumVerifier(), false); &amp;#125; quorumPeer.initConfigInZKDatabase(); quorumPeer.setCnxnFactory(cnxnFactory); quorumPeer.setSecureCnxnFactory(secureCnxnFactory); quorumPeer.setSslQuorum(config.isSslQuorum()); quorumPeer.setUsePortUnification(config.shouldUsePortUnification()); quorumPeer.setLearnerType(config.getPeerType()); quorumPeer.setSyncEnabled(config.getSyncEnabled()); // 投票决定方式, 默认超过半数就通过. quorumPeer.setQuorumListenOnAllIPs(config.getQuorumListenOnAllIPs()); if (config.sslQuorumReloadCertFiles) &amp;#123; quorumPeer.getX509Util().enableCertFileReloading(); &amp;#125; // sets quorum sasl authentication configurations quorumPeer.setQuorumSaslEnabled(config.quorumEnableSasl); if (quorumPeer.isQuorumSaslAuthEnabled()) &amp;#123; quorumPeer.setQuorumServerSaslRequired(config.quorumServerRequireSasl); quorumPeer.setQuorumLearnerSaslRequired(config.quorumLearnerRequireSasl); quorumPeer.setQuorumServicePrincipal(config.quorumServicePrincipal); quorumPeer.setQuorumServerLoginContext(config.quorumServerLoginContext); quorumPeer.setQuorumLearnerLoginContext(config.quorumLearnerLoginContext); &amp;#125; quorumPeer.setQuorumCnxnThreadsSize(config.quorumCnxnThreadsSize); quorumPeer.initialize(); // 启动主线程. quorumPeer.start(); quorumPeer.join(); &amp;#125; catch (InterruptedException e) &amp;#123; // warn, but generally this is ok LOG.warn(\"Quorum Peer interrupted\", e); &amp;#125; &amp;#125; quorumPeer.start() quorumPeer.start() 方法,重写了Thread.start() 方法, 也就是在线程启动之前，会做以下操作: 通过loadDataBase() 恢复快照数据 cnxnFactory.start() 启动zkServer, 相当于用户可以通过2181 这个端口号进行通信了. @Override public synchronized void start() &amp;#123; if (!getView().containsKey(myid)) &amp;#123; throw new RuntimeException(\"My id \" + myid + \" not in the peer list\"); &amp;#125; // 恢复快照数据 loadDataBase(); // 启动zk服务 startServerCnxnFactory(); try &amp;#123; adminServer.start(); &amp;#125; catch (AdminServerException e) &amp;#123; LOG.warn(\"Problem starting AdminServer\", e); System.out.println(e); &amp;#125; startLeaderElection(); super.start(); &amp;#125; private void startServerCnxnFactory() &amp;#123; if (cnxnFactory != null) &amp;#123; cnxnFactory.start(); &amp;#125; if (secureCnxnFactory != null) &amp;#123; secureCnxnFactory.start(); &amp;#125; &amp;#125; startLeaderElection()leader 选举的方法 synchronized public void startLeaderElection() &amp;#123; try &amp;#123; // 构建一个票据, 用于投票 currentVote = new Vote(myid, getLastLoggedZxid(), getCurrentEpoch()); &amp;#125; catch (IOException e) &amp;#123; RuntimeException re = new RuntimeException(e.getMessage()); re.setStackTrace(e.getStackTrace()); throw re; &amp;#125; // 这个 getView() 返回是在配置文件中配置的server.myid=ip:port:port for (QuorumServer p : getView().values()) &amp;#123; // 获得当前zkserver myid 对应的ip地址 if (p.id == myid) &amp;#123; myQuorumAddr = p.addr; break; &amp;#125; &amp;#125; if (myQuorumAddr == null) &amp;#123; throw new RuntimeException(\"My id \" + myid + \" not in the peer list\"); &amp;#125; // 根据electionType 匹配对应的选举算法, electionType 默认值为3, 可以在配置文件中动态生成. if (electionType == 0) &amp;#123; try &amp;#123; udpSocket = new DatagramSocket(myQuorumAddr.getPort()); responder = new ResponderThread(); responder.start(); &amp;#125; catch (SocketException e) &amp;#123; throw new RuntimeException(e); &amp;#125; &amp;#125; this.electionAlg = createElectionAlgorithm(electionType); &amp;#125; QuorumPeer.createElectionAlgorithm根据对应的标识创建选举算法 protected Election createElectionAlgorithm(int electionAlgorithm) &amp;#123; Election le = null; //TODO: use a factory rather than a switch switch (electionAlgorithm) &amp;#123; case 0: le = new LeaderElection(this); break; case 1: le = new AuthFastLeaderElection(this); break; case 2: le = new AuthFastLeaderElection(this, true); break; case 3: qcm = createCnxnManager(); QuorumCnxManager.Listener listener = qcm.listener; if (listener != null) &amp;#123; // 启动监听 listener.start(); // 初始化 FastLeaderElection le = new FastLeaderElection(this, qcm); &amp;#125; else &amp;#123; LOG.error(\"Null listener when initializing cnx manager\"); &amp;#125; break; default: assert false; &amp;#125; return le; &amp;#125; FastLeaderElection初始化FastLeaderElection , QuorumCnxManager 是一个很核心的对象, 用来实现 领导选举中的网络连接管理功能, public FastLeaderElection(QuorumPeer self, QuorumCnxManager manager)&amp;#123; this.stop = false; this.manager = manager; starter(self, manager); &amp;#125; FastLeaderElection.starterstarter 方法里面, 设置了一些成员属性, 并且构建了两个阻塞队列, 分别是 sendQueue 和 recvqueue . 并且实例化了一个Messenger private void starter(QuorumPeer self, QuorumCnxManager manager) &amp;#123; this.self = self; proposedLeader = -1; proposedZxid = -1; sendqueue = new LinkedBlockingQueue&lt;ToSend>(); recvqueue = new LinkedBlockingQueue&lt;Notification>(); this.messenger = new Messenger(manager); &amp;#125; Messenger在 Messenger 中构建了两个线程, 一个是WorkerSender, 一个是WorkerReceiver. 这两个线程是分别用来发送和接受消息的线程. Messenger(QuorumCnxManager manager) &amp;#123; this.ws = new WorkerSender(manager); Thread t = new Thread(this.ws, \"WorkerSender[myid=\" + self.getId() + \"]\"); t.setDaemon(true); t.start(); this.wr = new WorkerReceiver(manager); t = new Thread(this.wr, \"WorkerReceiver[myid=\" + self.getId() + \"]\"); t.setDaemon(true); t.start(); &amp;#125; 阶段性提交分析到这里,先做一个简单的总结, 通过一个流程图把前面部分的功能串联起来。 getView() 的解析过程 public Map&lt;Long, QuorumPeer.QuorumServer> getView() &amp;#123; return Collections.unmodifiableMap(this.quorumPeers); &amp;#125; getView() 里面实际上返回是一个quorumPeers, 就是参与本次投票的成员有哪些? 这个属性在哪里赋值呢? QuorumPeerMain.runFromConfig设置了一个值为config.getServers(), quorumPeer.setQuorumPeers(config.getServers()); config 这个配置信息又是通过 initializeAndRun 方法中初始化的. // 设置配置参数, 如果args 不为0, 可以基于外部的配置路径来解析 QuorumPeerConfig config = new QuorumPeerConfig(); if (args.length == 1) &#123; config.parse(args[0]); &#125; QuorumPeerConfig.parse这里会根据一个外部的文件去解析, 然后其中一段是这样的, 解析对应的集群信息放到servers 这个集合中. &amp;#125; else if (key.startsWith(\"server.\")) &amp;#123; int dot = key.indexOf('.'); long sid = Long.parseLong(key.substring(dot + 1)); String parts[] = splitWithLeadingHostname(value); if ((parts.length != 2) &amp;&amp; (parts.length != 3) &amp;&amp; (parts.length !=4)) &amp;#123; LOG.error(value + \" does not have the form host:port or host:port:port \" + \" or host:port:port:type\"); &amp;#125; LearnerType type = null; String hostname = parts[0]; Integer port = Integer.parseInt(parts[1]); Integer electionPort = null; if (parts.length > 2)&amp;#123; electionPort=Integer.parseInt(parts[2]); &amp;#125; if (parts.length > 3)&amp;#123; if (parts[3].toLowerCase().equals(\"observer\")) &amp;#123; type = LearnerType.OBSERVER; &amp;#125; else if (parts[3].toLowerCase().equals(\"participant\")) &amp;#123; type = LearnerType.PARTICIPANT; &amp;#125; else &amp;#123; throw new ConfigException(\"Unrecognised peertype: \" + value); &amp;#125; &amp;#125; if (type == LearnerType.OBSERVER)&amp;#123; observers.put(Long.valueOf(sid), new QuorumServer(sid, hostname, port, electionPort, type)); &amp;#125; else &amp;#123; servers.put(Long.valueOf(sid), new QuorumServer(sid, hostname, port, electionPort, type)); &amp;#125; Zookeeper 服务启动的逻辑在讲leader 选举的时候, 有一个 cnxnFactory.start() 方法来启动zk 服务, 这块具体做了什么呢? 我们来分析看看 QuorumPeerMain.runFromConfig在runFromConfig中， 构建了一个ServerCnxnFactory public void runFromConfig(QuorumPeerConfig config) throws IOException &amp;#123; try &amp;#123; ManagedUtil.registerLog4jMBeans(); &amp;#125; catch (JMException e) &amp;#123; LOG.warn(\"Unable to register log4j JMX control\", e); &amp;#125; LOG.info(\"Starting quorum peer\"); try &amp;#123; ServerCnxnFactory cnxnFactory = ServerCnxnFactory.createFactory(); cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns()); ... &amp;#125; 这个明显是一个工厂模式, 基于这个工厂类创建什么呢? 打开createFactory() 方法看看就知道了. ServerCnxnFactory.createFactory()这个方法里面是根据ZOOKEEPER_SERVER_CNXN_FACTORY 来决定创建NIO Server 还是Netty Server 而默认情况下, 应该是创建一个 NIOServerCnxnFactory static public ServerCnxnFactory createFactory() throws IOException &amp;#123; String serverCnxnFactoryName = System.getProperty(ZOOKEEPER_SERVER_CNXN_FACTORY); if (serverCnxnFactoryName == null) &amp;#123; serverCnxnFactoryName = NIOServerCnxnFactory.class.getName(); &amp;#125; try &amp;#123; ServerCnxnFactory serverCnxnFactory = (ServerCnxnFactory) Class.forName(serverCnxnFactoryName) .getDeclaredConstructor().newInstance(); LOG.info(\"Using &amp;#123;&amp;#125; as server connection factory\", serverCnxnFactoryName); return serverCnxnFactory; &amp;#125; catch (Exception e) &amp;#123; IOException ioe = new IOException(\"Couldn't instantiate \" + serverCnxnFactoryName); ioe.initCause(e); throw ioe; &amp;#125; &amp;#125; quorumPeer.start();因此, 我们再回到 quorumPeer.start(); 方法中, cnxnFactory.start()， 应该会调用NIOServerCnxnFactory 这个类去启动一个线程. @Override public synchronized void start() &amp;#123; // 恢复快照数据 loadDataBase(); // 启动zk 服务 cnxnFactory.start(); startLeaderElection(); super.start(); &amp;#125; NIOServerCnxnFactory.start()这里通过thread.start 启动一个线程, 那thread 是一个什么对象呢? @Override public void start() &amp;#123; // ensure thread is started once and only once if (thread.getState() == Thread.State.NEW) &amp;#123; thread.start(); &amp;#125; &amp;#125; NIOServerCnxnFactory.configurethread 其实构建的是一个zookeeperThread 线程, 并且线程的参数为this, 表示当前NIOServerCnxnFactory 也是实现了线程的类, 那么它必须要重写run() 方法, NIOServer 的初始化以及启动过程就完成的. 并且对2181 这个端口号进行监听, 一旦发现有请求进来, 就执行相应的处理即可. Thread thread; @Override public void configure(InetSocketAddress addr, int maxcc) throws IOException &amp;#123; configureSaslLogin(); thread = new ZooKeeperThread(this, \"NIOServerCxn.Factory:\" + addr); thread.setDaemon(true); maxClientCnxns = maxcc; this.ss = ServerSocketChannel.open(); ss.socket().setReuseAddress(true); LOG.info(\"binding to port \" + addr); ss.socket().bind(addr); ss.configureBlocking(false); ss.register(selector, SelectionKey.OP_ACCEPT); &amp;#125; 选举流程分析接下来我们正式分析leader 选举的过程. @Override public synchronized void start() &amp;#123; // 恢复快照数据 loadDataBase(); // 启动zk 服务 cnxnFactory.start(); startLeaderElection(); super.start(); &amp;#125; 很明显,super.start() 表示当前类QuorumPeer 继承了线程, 线程必须要重写run() 方法, 所以我们可以在 QuorumPeer 中找到一个run方法 QuorumPeer.run()这段代码的逻辑比较长, 粗略看一下结构, 好像也不难 PeerState 有几种状态, 分别是: LOOKING : 竞选状态 FOLLOWING: 随从状态. 同步leader 状态, 参与投票 OBSERVING : 观察状态, 同步leader 状态, 不参与投票. LEADING : 领导者状态. 对于选举来说, 默认都是 LOOKING 状态. 只有 LOOKING 状态才会去执行选举算法, 每个服务器在启动的时候都会选择自己作为领导，然后将投票信息发送出去, 循环一直到选举出领导为止. @Override public void run() &amp;#123; setName(\"QuorumPeer\" + \"[myid=\" + getId() + \"]\" + cnxnFactory.getLocalAddress()); LOG.debug(\"Starting quorum peer\"); try &amp;#123; jmxQuorumBean = new QuorumBean(this); MBeanRegistry.getInstance().register(jmxQuorumBean, null); for (QuorumServer s : getView().values()) &amp;#123; ZKMBeanInfo p; if (getId() == s.id) &amp;#123; p = jmxLocalPeerBean = new LocalPeerBean(this); try &amp;#123; MBeanRegistry.getInstance().register(p, jmxQuorumBean); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); jmxLocalPeerBean = null; &amp;#125; &amp;#125; else &amp;#123; p = new RemotePeerBean(s); try &amp;#123; MBeanRegistry.getInstance().register(p, jmxQuorumBean); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); jmxQuorumBean = null; &amp;#125; try &amp;#123; /* * Main loop */ // 根据选举状态, 选择不同的处理方式 while (running) &amp;#123; switch (getPeerState()) &amp;#123; case LOOKING: LOG.info(\"LOOKING\"); // 判断是否为只读模式, 通过readonlymode.enabled 开启 if (Boolean.getBoolean(\"readonlymode.enabled\")) &amp;#123; LOG.info(\"Attempting to start ReadOnlyZooKeeperServer\"); // 只读模式的启动流程 // Create read-only server but don't start it immediately final ReadOnlyZooKeeperServer roZk = new ReadOnlyZooKeeperServer( logFactory, this, new ZooKeeperServer.BasicDataTreeBuilder(), this.zkDb); // Instead of starting roZk immediately, wait some grace // period before we decide we're partitioned. // // Thread is used here because otherwise it would require // changes in each of election strategy classes which is // unnecessary code coupling. Thread roZkMgr = new Thread() &amp;#123; public void run() &amp;#123; try &amp;#123; // lower-bound grace period to 2 secs sleep(Math.max(2000, tickTime)); if (ServerState.LOOKING.equals(getPeerState())) &amp;#123; roZk.startup(); &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; LOG.info(\"Interrupted while attempting to start ReadOnlyZooKeeperServer, not started\"); &amp;#125; catch (Exception e) &amp;#123; LOG.error(\"FAILED to start ReadOnlyZooKeeperServer\", e); &amp;#125; &amp;#125; &amp;#125;; try &amp;#123; roZkMgr.start(); setBCVote(null); // 设置当前的投票, 通过策略模式来决定当前用哪个选举算法来进行领导选举 setCurrentVote(makeLEStrategy().lookForLeader()); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); setPeerState(ServerState.LOOKING); &amp;#125; finally &amp;#123; // If the thread is in the the grace period, interrupt // to come out of waiting. roZkMgr.interrupt(); roZk.shutdown(); &amp;#125; &amp;#125; else &amp;#123; try &amp;#123; setBCVote(null); setCurrentVote(makeLEStrategy().lookForLeader()); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); setPeerState(ServerState.LOOKING); &amp;#125; &amp;#125; break; case OBSERVING: try &amp;#123; LOG.info(\"OBSERVING\"); setObserver(makeObserver(logFactory)); observer.observeLeader(); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); &amp;#125; finally &amp;#123; observer.shutdown(); setObserver(null); setPeerState(ServerState.LOOKING); &amp;#125; break; case FOLLOWING: try &amp;#123; LOG.info(\"FOLLOWING\"); setFollower(makeFollower(logFactory)); follower.followLeader(); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); &amp;#125; finally &amp;#123; follower.shutdown(); setFollower(null); setPeerState(ServerState.LOOKING); &amp;#125; break; case LEADING: LOG.info(\"LEADING\"); try &amp;#123; setLeader(makeLeader(logFactory)); leader.lead(); setLeader(null); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); &amp;#125; finally &amp;#123; if (leader != null) &amp;#123; leader.shutdown(\"Forcing shutdown\"); setLeader(null); &amp;#125; setPeerState(ServerState.LOOKING); &amp;#125; break; &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; LOG.warn(\"QuorumPeer main thread exited\"); try &amp;#123; MBeanRegistry.getInstance().unregisterAll(); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to unregister with JMX\", e); &amp;#125; jmxQuorumBean = null; jmxLocalPeerBean = null; &amp;#125; &amp;#125; FastLeaderElection .lookForLeader()开始发起投票流程 public Vote lookForLeader() throws InterruptedException &amp;#123; try &amp;#123; self.jmxLeaderElectionBean = new LeaderElectionBean(); MBeanRegistry.getInstance().register( self.jmxLeaderElectionBean, self.jmxLocalPeerBean); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); self.jmxLeaderElectionBean = null; &amp;#125; if (self.start_fle == 0) &amp;#123; self.start_fle = Time.currentElapsedTime(); &amp;#125; try &amp;#123; HashMap&lt;Long, Vote> recvset = new HashMap&lt;Long, Vote>(); HashMap&lt;Long, Vote> outofelection = new HashMap&lt;Long, Vote>(); int notTimeout = finalizeWait; synchronized (this) &amp;#123; // 更新逻辑时钟, 用来判断是否在同一轮选举周期 logicalclock.incrementAndGet(); // 初始化选票数据, 这里其实就是把当前节点的myid,zxid,epoch 更新到本地的成员属性 updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); &amp;#125; LOG.info(\"New election. My id = \" + self.getId() + \", proposed zxid=0x\" + Long.toHexString(proposedZxid)); // 异步发送选举消息 sendNotifications(); /* * Loop in which we exchange notifications until we find a leader */ // 不断循环, 根据投票信息进行leader 选举 while ((self.getPeerState() == ServerState.LOOKING) &amp;&amp; (!stop)) &amp;#123; /* * Remove next notification from queue, times out after 2 times * the termination time */ // 从 recvqueue 中获取消息 Notification n = recvqueue.poll(notTimeout, TimeUnit.MILLISECONDS); /* * Sends more notifications if haven't received enough. * Otherwise processes new notification. */ // 如果没有获取到外部的投票, 有可能是集群之间的节点没有真正连接上 if (n == null) &amp;#123; // 判断发送队列是否由数据,如果发送队列为空,再发一次自己的选票 if (manager.haveDelivered()) &amp;#123; sendNotifications(); &amp;#125; else &amp;#123; // 再次发起集群节点之间的连接 manager.connectAll(); &amp;#125; /* * Exponential backoff */ int tmpTimeOut = notTimeout * 2; notTimeout = (tmpTimeOut &lt; maxNotificationInterval ? tmpTimeOut : maxNotificationInterval); LOG.info(\"Notification time out: \" + notTimeout); ... &amp;#125; 选票的判断逻辑(核心代码) // 判断收到的选票中的sid 和选举的leader 的sid 是否存在与我们集群锁配置的myid 范围. &amp;#125; else if (validVoter(n.sid) &amp;&amp; validVoter(n.leader)) &amp;#123; // 判断接受到的投票者的状态, 默认是LOOKING 状态, 说明当前发起投票的服务器也是找leader /* * Only proceed if the vote comes from a replica in the * voting view for a replica in the voting view. */ switch (n.state) &amp;#123; case LOOKING: // 说明当前发起投票的服务器也是在找leader // 如果收到的投票的逻辑时钟大于当前的节点的逻辑时钟 // If notification > current, replace and send messages out if (n.electionEpoch > logicalclock.get()) &amp;#123; // 更新成新一轮的逻辑时钟 logicalclock.set(n.electionEpoch); recvset.clear(); // 比较接收到的投票和当前节点的细腻些进行比较,比较的顺序 // epoch、zxid、myid,如果返回的为true, 在更新当前节点大票据 // (sid、zxid、epoch) //那么下一次再发起投票的时候, 就不再选自己了 if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, getInitId(), getInitLastLoggedZxid(), getPeerEpoch())) &amp;#123; updateProposal(n.leader, n.zxid, n.peerEpoch); &amp;#125; else &amp;#123; // 否则, 说明当前节点的票据优先级更高, 再次更新自己的票据 updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); &amp;#125; // 再次发送消息把当前的票据发出去,告诉大家要选择n.leader 为leader sendNotifications(); &amp;#125; else if (n.electionEpoch &lt; logicalclock.get()) &amp;#123; // 如果小于, 说明收到的票据已经过期,直接把这张票丢掉 if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Notification election epoch is smaller than logicalclock. n.electionEpoch = 0x\" + Long.toHexString(n.electionEpoch) + \", logicalclock=0x\" + Long.toHexString(logicalclock.get())); &amp;#125; break; // 这个判断表示收到的票据epoch 是想同的, 那么按照epoch、zxid、myid顺序进行比较,比较成功后,把对方的票据信息更新到自己的节点 &amp;#125; else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) &amp;#123; updateProposal(n.leader, n.zxid, n.peerEpoch); sendNotifications(); &amp;#125; if (LOG.isDebugEnabled()) &amp;#123; LOG.debug(\"Adding vote: from=\" + n.sid + \", proposed leader=\" + n.leader + \", proposed zxid=0x\" + Long.toHexString(n.zxid) + \", proposed election epoch=0x\" + Long.toHexString(n.electionEpoch)); &amp;#125; // 将收到的投票信心放入到投票的集合recvset中, 用来做最终的\"过半原则\" 判断 recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); if (termPredicate(recvset, new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch))) &amp;#123; // 进入这个判断, 说明选票进入到了leader 选举的要求 // 在更新状态之前, 服务器会等待finalizeWait 毫秒时间来接受新的选票,以防止漏下来关键的选票 // 如果收到可能改变leader 的选票, 则重新进行计票 // Verify if there is any change in the proposed leader while ((n = recvqueue.poll(finalizeWait, TimeUnit.MILLISECONDS)) != null) &amp;#123; if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) &amp;#123; recvqueue.put(n); break; &amp;#125; &amp;#125; /* * This predicate is true once we don't read any new * relevant message from the reception queue */ // 如果Notification为空,说明leader 节点是已经确定好了 if (n == null) &amp;#123; // 设置当前节点的状态(判断leader 节点不是我自己, 如果是, 直接更新当前节点的 state 为LEADING) // 否则,根据当前节点的特性进行判断,决定是FOLLOWING 还是OBSERVING self.setPeerState((proposedLeader == self.getId()) ? ServerState.LEADING : learningState()); // 组装生成这次leader 选举最终投票的结果. Vote endVote = new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch); // 清空 recvqueue leaveInstance(endVote); // 返回最终的票据 return endVote; &amp;#125; &amp;#125; break; case OBSERVING: // OBSERVING 不参与Leader 的选举 LOG.debug(\"Notification from observer: \" + n.sid); break; case FOLLOWING: case LEADING: /* * Consider all notifications from the same epoch * together. */ if (n.electionEpoch == logicalclock.get()) &amp;#123; recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); if (ooePredicate(recvset, outofelection, n)) &amp;#123; self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING : learningState()); Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote; &amp;#125; &amp;#125; /* * Before joining an established ensemble, verify * a majority is following the same leader. */ outofelection.put(n.sid, new Vote(n.version, n.leader, n.zxid, n.electionEpoch, n.peerEpoch, n.state)); if (ooePredicate(outofelection, outofelection, n)) &amp;#123; synchronized (this) &amp;#123; logicalclock.set(n.electionEpoch); self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING : learningState()); &amp;#125; Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote; &amp;#125; break; default: LOG.warn(\"Notification state unrecognized: &amp;#123;&amp;#125; (n.state), &amp;#123;&amp;#125; (n.sid)\", n.state, n.sid); break; &amp;#125; &amp;#125; else &amp;#123; if (!validVoter(n.leader)) &amp;#123; LOG.warn(\"Ignoring notification for non-cluster member sid &amp;#123;&amp;#125; from sid &amp;#123;&amp;#125;\", n.leader, n.sid); &amp;#125; if (!validVoter(n.sid)) &amp;#123; LOG.warn(\"Ignoring notification for sid &amp;#123;&amp;#125; from non-quorum member sid &amp;#123;&amp;#125;\", n.leader, n.sid); &amp;#125; &amp;#125; &amp;#125; return null; &amp;#125; finally &amp;#123; try &amp;#123; if (self.jmxLeaderElectionBean != null) &amp;#123; MBeanRegistry.getInstance().unregister(self.jmxLeaderElectionBean); &amp;#125; &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to unregister with JMX\", e); &amp;#125; self.jmxLeaderElectionBean = null; LOG.debug(\"Number of connection processing threads: &amp;#123;&amp;#125;\", manager.getConnectionThreadCount()); &amp;#125; &amp;#125; /** * Check if a given sid is represented in either the current or * the next voting view * * @param sid Server identifier * @return boolean */ private boolean validVoter(long sid) &amp;#123; return self.getVotingView().containsKey(sid); &amp;#125; 投票处理的流程图 termPredicate这个方法是使用过半原则来判断选举是否结束的, 如果返回true, 说明能够选出leader 服务器. votes 表示收到的外部选票的集合 vote 表示当前服务器的选票 protected boolean termPredicate(HashMap&lt;Long, Vote> votes, Vote vote) &amp;#123; HashSet&lt;Long> set = new HashSet&lt;Long>(); /* * First make the views consistent. Sometimes peers will have * different zxids for a server depending on timing. */ // 遍历接受到的所有票据数据 for (Map.Entry&lt;Long, Vote> entry : votes.entrySet()) &amp;#123; // 对选票进行归纳, 就是把所有选票数据中和当前节点的票据相同的票据进行统计. if (vote.equals(entry.getValue())) &amp;#123; set.add(entry.getKey()); &amp;#125; &amp;#125; // 对票据进行判断 return self.getQuorumVerifier().containsQuorum(set); &amp;#125; QuorumMaj.containsQuorum public boolean containsQuorum(Set&lt;Long> set)&amp;#123; return (set.size() > half); &amp;#125; 这个half 的值是多少呢? 可以在 QuorumPeerConfig. parseProperties 这个方法中, 找到如下源码: LOG.info(\"Defaulting to majority quorums\"); quorumVerifier = new QuorumMaj(servers.size()); 也就是说, 在构建QuorumMaj的时候,传递了当前集群节点的数量, 这里是3. 那么half = 3/2= 1 public QuorumMaj(int n)&amp;#123; this.half = n/2; &amp;#125; 那么 set.size()&gt;1 ,意味着至少有两个节点的票据是选择你当leader , 否则, 还得继续投. 投票的网络通信过程通信流程图 接受数据 Notification 和发送数据 ToSend 字段 Notification ToSend leader 被推荐的服务器sid 被推荐的服务器sid zxid 被推荐的服务器当前最新的事务id 被推荐的服务器当前的事务id peerEpoch 被推荐的服务器当前所处的epoch 被推荐的服务器当前所处的epoch electionepoch 当前服务器所处的epoch 当前服务器所处的epoch state 当前服务器状态 选举服务器当前服务器状态 sid 接受消息的服务器sid(myid) 选举服务器的sid 通信过程源码分析每个zk 服务启动后创建socket 监听 protected Election createElectionAlgorithm(int electionAlgorithm) &amp;#123; Election le = null; //TODO: use a factory rather than a switch switch (electionAlgorithm) &amp;#123; case 0: le = new LeaderElection(this); break; case 1: le = new AuthFastLeaderElection(this); break; case 2: le = new AuthFastLeaderElection(this, true); break; case 3: qcm = createCnxnManager(); QuorumCnxManager.Listener listener = qcm.listener; if (listener != null) &amp;#123; // 启动监听,listener 实现了线程,所以在run方法, 可以看到构建serverSocket 的请求 // 这里专门用来接受其他zkServer 的投票请求 listener.start(); // 初始化 FastLeaderElection le = new FastLeaderElection(this, qcm); &amp;#125; else &amp;#123; LOG.error(\"Null listener when initializing cnx manager\"); &amp;#125; break; default: assert false; &amp;#125; return le; &amp;#125; /** * Sleeps on accept(). */ @Override public void run() &amp;#123; int numRetries = 0; InetSocketAddress addr; while((!shutdown) &amp;&amp; (numRetries &lt; 3))&amp;#123; try &amp;#123; ss = new ServerSocket(); ss.setReuseAddress(true); if (listenOnAllIPs) &amp;#123; int port = view.get(QuorumCnxManager.this.mySid) .electionAddr.getPort(); addr = new InetSocketAddress(port); &amp;#125; else &amp;#123; addr = view.get(QuorumCnxManager.this.mySid) .electionAddr; &amp;#125; LOG.info(\"My election bind port: \" + addr.toString()); setName(view.get(QuorumCnxManager.this.mySid) .electionAddr.toString()); ss.bind(addr); while (!shutdown) &amp;#123; Socket client = ss.accept(); setSockOpts(client); LOG.info(\"Received connection request \" + client.getRemoteSocketAddress()); // Receive and handle the connection request // asynchronously if the quorum sasl authentication is // enabled. This is required because sasl server // authentication process may take few seconds to finish, // this may delay next peer connection requests. if (quorumSaslAuthEnabled) &amp;#123; receiveConnectionAsync(client); &amp;#125; else &amp;#123; receiveConnection(client); &amp;#125; numRetries = 0; &amp;#125; &amp;#125; catch (IOException e) &amp;#123; LOG.error(\"Exception while listening\", e); numRetries++; try &amp;#123; ss.close(); Thread.sleep(1000); &amp;#125; catch (IOException ie) &amp;#123; LOG.error(\"Error closing server socket\", ie); &amp;#125; catch (InterruptedException ie) &amp;#123; LOG.error(\"Interrupted while sleeping. \" + \"Ignoring exception\", ie); &amp;#125; &amp;#125; &amp;#125; LOG.info(\"Leaving listener\"); if (!shutdown) &amp;#123; LOG.error(\"As I'm leaving the listener thread, \" + \"I won't be able to participate in leader \" + \"election any longer: \" + view.get(QuorumCnxManager.this.mySid).electionAddr); &amp;#125; &amp;#125; FastLeaderElection.lookForLeader这个方法前面分析过, 里面会调用 sendNotifications 来发送投票请求 public Vote lookForLeader() throws InterruptedException &amp;#123; try &amp;#123; self.jmxLeaderElectionBean = new LeaderElectionBean(); MBeanRegistry.getInstance().register(self.jmxLeaderElectionBean, self.jmxLocalPeerBean); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); self.jmxLeaderElectionBean = null; &amp;#125; if (self.start_fle == 0) &amp;#123; self.start_fle = Time.currentElapsedTime(); &amp;#125; try &amp;#123; HashMap&lt;Long, Vote> recvset = new HashMap&lt;Long, Vote>(); HashMap&lt;Long, Vote> outofelection = new HashMap&lt;Long, Vote>(); int notTimeout = finalizeWait; synchronized (this) &amp;#123; // 更新逻辑时钟, 用来判断是否在同一轮选举周期 logicalclock.incrementAndGet(); // 初始化选票数据, 这里其实就是把当前节点的myid,zxid,epoch 更新到本地的成员属性 updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); &amp;#125; LOG.info(\"New election. My id = \" + self.getId() + \", proposed zxid=0x\" + Long.toHexString(proposedZxid)); // 异步发送选举消息 sendNotifications(); ... &amp;#125; FastLeaderElection.sendqueuesendqueue 这个队列的数据, 是通过 WorkerSender 来进行获取并发送的, 而这个 WorkerSender 线程, 在构建 fastLeaderElection 的时候会启动. class WorkerSender extends ZooKeeperThread &amp;#123; volatile boolean stop; QuorumCnxManager manager; WorkerSender(QuorumCnxManager manager) &amp;#123; super(\"WorkerSender\"); this.stop = false; this.manager = manager; &amp;#125; public void run() &amp;#123; while (!stop) &amp;#123; try &amp;#123; // 从队列中获取ToSend 对象. ToSend m = sendqueue.poll(3000, TimeUnit.MILLISECONDS); if (m == null) continue; process(m); &amp;#125; catch (InterruptedException e) &amp;#123; break; &amp;#125; &amp;#125; LOG.info(\"WorkerSender is down\"); &amp;#125; /** * Called by run() once there is a new message to send. * * @param m message to send */ void process(ToSend m) &amp;#123; ByteBuffer requestBuffer = buildMsg(m.state.ordinal(), m.leader, m.zxid, m.electionEpoch, m.peerEpoch); // 这里就是调用 QuorumCnxManager 进行消息发送. manager.toSend(m.sid, requestBuffer); &amp;#125; &amp;#125; QuorumCnxManager.toSend public void toSend(Long sid, ByteBuffer b) &amp;#123; /* * If sending message to myself, then simply enqueue it (loopback). */ // 如果接收者是自己, 直接放置到接受队列 if (this.mySid == sid) &amp;#123; b.position(0); addToRecvQueue(new Message(b.duplicate(), sid)); /* * Otherwise send to the corresponding thread to send. */ &amp;#125; else &amp;#123; /* * Start a new connection if doesn't have one already. */ // 否则发送到对应的发送队列上 ArrayBlockingQueue&lt;ByteBuffer> bq = new ArrayBlockingQueue&lt;ByteBuffer>(SEND_CAPACITY); // 判断当前的sid 是否已经存在与发送队列, 如果是, 则直接把已经存在的数据发送出去. ArrayBlockingQueue&lt;ByteBuffer> bqExisting = queueSendMap.putIfAbsent(sid, bq); if (bqExisting != null) &amp;#123; addToSendQueue(bqExisting, b); &amp;#125; else &amp;#123; addToSendQueue(bq, b); &amp;#125; // 连接申请 调用链 connectOne->initiateConnection-> startConnection // startConnection 就是发送方启动入口 connectOne(sid); &amp;#125; &amp;#125; startConnection private boolean startConnection(Socket sock, Long sid) throws IOException &amp;#123; DataOutputStream dout = null; DataInputStream din = null; try &amp;#123; // Sending id and challenge dout = new DataOutputStream(sock.getOutputStream()); dout.writeLong(this.mySid); dout.flush(); din = new DataInputStream(new BufferedInputStream(sock.getInputStream())); &amp;#125; catch (IOException e) &amp;#123; LOG.warn(\"Ignoring exception reading or writing challenge: \", e); closeSocket(sock); return false; &amp;#125; // authenticate learner authLearner.authenticate(sock, view.get(sid).hostname); // If lost the challenge, then drop the new connection if (sid > this.mySid) &amp;#123; // 为了防止重复建立连接, 只需要sid 大的主动连接sid 小的. LOG.info(\"Have smaller server identifier, so dropping the \" + \"connection: (\" + sid + \", \" + this.mySid + \")\"); closeSocket(sock); // Otherwise proceed with the connection &amp;#125; else &amp;#123; // 构建一个发送线程和接受线程, 负责针对当前连接的数据传输, SendWorker sw = new SendWorker(sock, sid); RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if (vsw != null) vsw.finish(); senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer>(SEND_CAPACITY)); sw.start(); rw.start(); return true; &amp;#125; return false; &amp;#125; SendWorker SendWorker 会监听对应sid 的阻塞队列, 启动的时候, 如果队列为空时会重新发送一次消息最前最后的消息, 以防止上一次处理是服务器异常退出, 造成上一条消息未处理成功; 然后就是不停监听队列, 发现有消息时调用send 方法. RecvWorker RecvWorker 不停监听socket 的inputstream ,读取消息放到消息接收队列中, 消息放入队列中, qcm的流程就完毕了. QuorumCnxManager.Listenerlistener 监听到客户端请求后, 开始处理消息. @Override public void run() &amp;#123; int numRetries = 0; InetSocketAddress addr; while ((!shutdown) &amp;&amp; (numRetries &lt; 3)) &amp;#123; try &amp;#123; ss = new ServerSocket(); ss.setReuseAddress(true); if (listenOnAllIPs) &amp;#123; int port = view.get(QuorumCnxManager.this.mySid).electionAddr.getPort(); addr = new InetSocketAddress(port); &amp;#125; else &amp;#123; addr = view.get(QuorumCnxManager.this.mySid).electionAddr; &amp;#125; LOG.info(\"My election bind port: \" + addr.toString()); setName(view.get(QuorumCnxManager.this.mySid).electionAddr.toString()); ss.bind(addr); while (!shutdown) &amp;#123; Socket client = ss.accept(); setSockOpts(client); LOG.info(\"Received connection request \" + client.getRemoteSocketAddress()); // Receive and handle the connection request // asynchronously if the quorum sasl authentication is // enabled. This is required because sasl server // authentication process may take few seconds to finish, // this may delay next peer connection requests. if (quorumSaslAuthEnabled) &amp;#123; receiveConnectionAsync(client); &amp;#125; else &amp;#123; // 接受客户端请求 receiveConnection(client); &amp;#125; numRetries = 0; &amp;#125; &amp;#125; catch (IOException e) &amp;#123; LOG.error(\"Exception while listening\", e); numRetries++; try &amp;#123; ss.close(); Thread.sleep(1000); &amp;#125; catch (IOException ie) &amp;#123; LOG.error(\"Error closing server socket\", ie); &amp;#125; catch (InterruptedException ie) &amp;#123; LOG.error(\"Interrupted while sleeping. \" + \"Ignoring exception\", ie); &amp;#125; &amp;#125; &amp;#125; LOG.info(\"Leaving listener\"); if (!shutdown) &amp;#123; LOG.error(\"As I'm leaving the listener thread, \" + \"I won't be able to participate in leader \" + \"election any longer: \" + view.get(QuorumCnxManager.this.mySid).electionAddr); &amp;#125; &amp;#125; QuorumCnxManager.receiveConnection public void receiveConnection(final Socket sock) &amp;#123; DataInputStream din = null; try &amp;#123; // 获取客户端的数据包 din = new DataInputStream(new BufferedInputStream(sock.getInputStream())); handleConnection(sock, din); &amp;#125; catch (IOException e) &amp;#123; LOG.error(\"Exception handling connection, addr: &amp;#123;&amp;#125;, closing server connection\", sock.getRemoteSocketAddress()); closeSocket(sock); &amp;#125; &amp;#125; QuorumCnxManager.handleConnection private void handleConnection(Socket sock, DataInputStream din) throws IOException &amp;#123; Long sid = null; try &amp;#123; // Read server id sid = din.readLong(); if (sid &lt; 0) &amp;#123; // this is not a server id but a protocol version (see ZOOKEEPER-1633) // 获取客户端的sid,也就是myid sid = din.readLong(); // next comes the #bytes in the remainder of the message // note that 0 bytes is fine (old servers) int num_remaining_bytes = din.readInt(); if (num_remaining_bytes &lt; 0 || num_remaining_bytes > maxBuffer) &amp;#123; LOG.error(\"Unreasonable buffer length: &amp;#123;&amp;#125;\", num_remaining_bytes); closeSocket(sock); return; &amp;#125; byte[] b = new byte[num_remaining_bytes]; // remove the remainder of the message from din int num_read = din.read(b); if (num_read != num_remaining_bytes) &amp;#123; LOG.error(\"Read only \" + num_read + \" bytes out of \" + num_remaining_bytes + \" sent by server \" + sid); &amp;#125; &amp;#125; if (sid == QuorumPeer.OBSERVER_ID) &amp;#123; /* * Choose identifier at random. We need a value to identify * the connection. */ sid = observerCounter.getAndDecrement(); LOG.info(\"Setting arbitrary identifier to observer: \" + sid); &amp;#125; &amp;#125; catch (IOException e) &amp;#123; closeSocket(sock); LOG.warn(\"Exception reading or writing challenge: \" + e.toString()); return; &amp;#125; // do authenticating learner LOG.debug(\"Authenticating learner server.id: &amp;#123;&amp;#125;\", sid); authServer.authenticate(sock, din); //If wins the challenge, then close the new connection. // // 为了防止重复建立连接, 只允许sid 大的主动连接sid 小的 if (sid &lt; this.mySid) &amp;#123; /* * This replica might still believe that the connection to sid is * up, so we have to shut down the workers before trying to open a * new connection. */ SendWorker sw = senderWorkerMap.get(sid); if (sw != null) &amp;#123; sw.finish(); &amp;#125; /* * Now we start a new connection */ LOG.debug(\"Create new connection to server: \" + sid); // 关闭连接 closeSocket(sock); // 向sid 发起连接 connectOne(sid); // Otherwise start worker threads to receive data. &amp;#125; else &amp;#123; // 同样, 构建一个SendWorker 和RecvWorker 进行发送数据和接受数据 SendWorker sw = new SendWorker(sock, sid); RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if (vsw != null) vsw.finish(); senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer>(SEND_CAPACITY)); sw.start(); rw.start(); return; &amp;#125; &amp;#125; Leader 选举完成之后的处理逻辑通过 lookForLeader 方法选举完成后, 会设置当前节点的 PeerState， , 要么为Leading, 要么就是 FOLLOWER，或者Observer, 到这里, 只是表示当前的leader 选举出来了, 但是 QuorumPeer.run 方法还没有执行完, 我们再回过头来看看后续的处理过程. QuorumPeer.run分别来看看 case 为Follower 和Leading 会做什么事情呢? @Override public void run() &amp;#123; setName(\"QuorumPeer\" + \"[myid=\" + getId() + \"]\" + cnxnFactory.getLocalAddress()); LOG.debug(\"Starting quorum peer\"); try &amp;#123; jmxQuorumBean = new QuorumBean(this); MBeanRegistry.getInstance().register(jmxQuorumBean, null); for (QuorumServer s : getView().values()) &amp;#123; ZKMBeanInfo p; if (getId() == s.id) &amp;#123; p = jmxLocalPeerBean = new LocalPeerBean(this); try &amp;#123; MBeanRegistry.getInstance().register(p, jmxQuorumBean); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); jmxLocalPeerBean = null; &amp;#125; &amp;#125; else &amp;#123; p = new RemotePeerBean(s); try &amp;#123; MBeanRegistry.getInstance().register(p, jmxQuorumBean); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Failed to register with JMX\", e); jmxQuorumBean = null; &amp;#125; try &amp;#123; /* * Main loop */ // 根据选举状态, 选择不同的处理方式 while (running) &amp;#123; switch (getPeerState()) &amp;#123; case LOOKING: LOG.info(\"LOOKING\"); // 判断是否为只读模式, 通过readonlymode.enabled 开启 if (Boolean.getBoolean(\"readonlymode.enabled\")) &amp;#123; LOG.info(\"Attempting to start ReadOnlyZooKeeperServer\"); // 只读模式的启动流程 // Create read-only server but don't start it immediately final ReadOnlyZooKeeperServer roZk = new ReadOnlyZooKeeperServer( logFactory, this, new ZooKeeperServer.BasicDataTreeBuilder(), this.zkDb); // Instead of starting roZk immediately, wait some grace // period before we decide we're partitioned. // // Thread is used here because otherwise it would require // changes in each of election strategy classes which is // unnecessary code coupling. Thread roZkMgr = new Thread() &amp;#123; public void run() &amp;#123; try &amp;#123; // lower-bound grace period to 2 secs sleep(Math.max(2000, tickTime)); if (ServerState.LOOKING.equals(getPeerState())) &amp;#123; roZk.startup(); &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; LOG.info(\"Interrupted while attempting to start ReadOnlyZooKeeperServer, not started\"); &amp;#125; catch (Exception e) &amp;#123; LOG.error(\"FAILED to start ReadOnlyZooKeeperServer\", e); &amp;#125; &amp;#125; &amp;#125;; try &amp;#123; roZkMgr.start(); setBCVote(null); // 设置当前的投票, 通过策略模式来决定当前用哪个选举算法来进行领导选举 setCurrentVote(makeLEStrategy().lookForLeader()); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); setPeerState(ServerState.LOOKING); &amp;#125; finally &amp;#123; // If the thread is in the the grace period, interrupt // to come out of waiting. roZkMgr.interrupt(); roZk.shutdown(); &amp;#125; &amp;#125; else &amp;#123; try &amp;#123; setBCVote(null); setCurrentVote(makeLEStrategy().lookForLeader()); &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Unexpected exception\", e); setPeerState(ServerState.LOOKING); &amp;#125; &amp;#125; break; ... &amp;#125; makeFollower初始化一个 Follower 对象, 构建一个 FollowerZookeeperServer ,表示follower 节点的请求处理服务 protected Follower makeFollower(FileTxnSnapLog logFactory) throws IOException &amp;#123; return new Follower(this, new FollowerZooKeeperServer(logFactory, this, new ZooKeeperServer.BasicDataTreeBuilder(), this.zkDb)); &amp;#125; follower.followLeader(); void followLeader() throws InterruptedException &amp;#123; self.end_fle = Time.currentElapsedTime(); long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); LOG.info(\"FOLLOWING - LEADER ELECTION TOOK - &amp;#123;&amp;#125;\", electionTimeTaken); self.start_fle = 0; self.end_fle = 0; fzk.registerJMX(new FollowerBean(this, zk), self.jmxLocalPeerBean); try &amp;#123; // 根据sid 找到对应的leader, 拿到lead 连接信息 QuorumServer leaderServer = findLeader(); try &amp;#123; // 连接到leader connectToLeader(leaderServer.addr, leaderServer.hostname); // 将Follower 的zxid和myid 等信息封装好发送到leader, 同步epoch // 也就是意味着接下来 follower节点 只同步新的epoch 的数据信息 long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); //check to see if the leader zxid is lower than ours //this should never happen but is just a safety check // 如果 leader 的epoch 比当前follower 节点的epoch 还小, 抛异常 long newEpoch = ZxidUtils.getEpochFromZxid(newEpochZxid); if (newEpoch &lt; self.getAcceptedEpoch()) &amp;#123; LOG.error(\"Proposed leader epoch \" + ZxidUtils.zxidToString(newEpochZxid) + \" is less than our accepted epoch \" + ZxidUtils.zxidToString(self.getAcceptedEpoch())); throw new IOException(\"Error: Epoch of leader is lower\"); &amp;#125; // 和leader 进行数据同步 syncWithLeader(newEpochZxid); QuorumPacket qp = new QuorumPacket(); // 接受 leader 消息, 执行并反馈给leader, 线程在此自旋 while (this.isRunning()) &amp;#123; // 从 leader 读取数据包 readPacket(qp); // 处理packet processPacket(qp); &amp;#125; &amp;#125; catch (Exception e) &amp;#123; LOG.warn(\"Exception when following the leader\", e); try &amp;#123; sock.close(); &amp;#125; catch (IOException e1) &amp;#123; e1.printStackTrace(); &amp;#125; // clear pending revalidations pendingRevalidations.clear(); &amp;#125; &amp;#125; finally &amp;#123; zk.unregisterJMX((Learner) this); &amp;#125; &amp;#125; makeLeader初始化一个Leader 对象, 构建一个 LeaderZookeeperServer , 用于标识leader 节点的请求处理服务 protected Leader makeLeader(FileTxnSnapLog logFactory) throws IOException &amp;#123; return new Leader(this, new LeaderZooKeeperServer(logFactory, this, new ZooKeeperServer.BasicDataTreeBuilder(), this.zkDb)); &amp;#125; leader.lead();在Leader 端, 则通过lead() 来处理与follower 的交互.","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[]},{"title":"zookeeper 核心原理","slug":"微服务/zookpeer/zookeeper 核心原理","date":"2022-01-04T02:42:07.293Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/zookpeer/zookeeper-he-xin-yuan-li/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/zookpeer/zookeeper-he-xin-yuan-li/","excerpt":"","text":"zookeeper 核心原理Zookeeper 数据的同步流程我们知道, zookeeper 是通过三种不同的集群角色来组成整个高性能集群的, 在zookeeper 中, 客户端会随机连接到 zookeeper 集群中的一个节点, 如果是读请求, 就直接从当前节点中读取数据, 如果是写请求, 那么请求会被转发给leader 提交事务. 然后leader 会传播事务, 只要有超过半数的节点写入成功, 那么写请求就会被提交.(类似于2PC 事务). 那么问题来了? 集群中的leader 节点是如何选举出来的? leader 节点崩溃后, 整个集群无法处理写请求, 如何快速的从其他节点中选举出新的leader 呢? leader节点和各个follower 节点的数据一致性如何保证. ZAB 协议ZAB(Zookeeper Atomic Broadcase) 协议是为分布式协调服务Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议. 在Zookeeper中, 主要依赖ZAB 协议来实现分布式数据一致性, 基于该协议, zookee实现了一种主备协议的系统架构来保持集群中各个副本之间的数据一致性. ZAB 协议介绍ZAB 协议包含两种基本模式: 包括: 崩溃恢复 原子广播 当整个集群在启动时,或者当leader节点出现网络中断、崩溃等情况时, ZAB协议会进入恢复模式并选举产生新的Leader, 当leader 服务器选举出来后, 并且集群中由过半的机器和该leader 节点完成数据同步后(同步指的是数据同步, 用来保证集群中过半的机器能够和leader服务器的数据状态保持一致),ZAB 协议就会退出恢复模式. 当集群中已经有过半的Follower 节点完成了和leader 节点状态同步以后, 那么整个集群模式就进去了消息广播模式. 这个时候, 在leader 节点正常工作时, 启动一台新的服务器加入到集群, 那这个服务器会直接进入数据恢复模式,和leader节点进行数据同步. 同步完成后即可正常对外提供非事务请求的处理 . 需要注意的是: leader 节点可以处理事务请求和非事务请求, follower 节点只能处理非事务请求, 如果follower节点接收到事务请求, 就会把这个请求转发到 leader 节点 . 消息广播的实现原理消息广播其实就是一个简化版本的二节点提交过程。 leader 接收到消息请求后, 将消息赋予一个全局唯一的64位自增id, 叫zxid, 通过zxid 的大小比较可以实现因果有序这个特征. leader 为每个follower准备了一个FIFO 队列(通过TCP协议来实现, 以实现了全局有序这个特点)将带有zxid 的消息作为一个提案(proposal) 分发给所有的follower 当follower 接受到 proposal , 先把 proposal 写到磁盘, 写入成功以后再想leader 回复一个ack 当leader 接收到合法数量(超过半数节点)的ACK后, leader 就会向这些follower发送 commit 命令, 同时也会在本地执行该消息. 当follower 收到消息的commit 命令后, 会提交该消息. 和完整的2pc事务不一样的地方在于, zab 协议不能终止事务, follower节点要么ACK 给leader, 要么抛弃leader, 只需要保证过半的节点响应了这个消息并提交了即可.虽然在某一个时刻 follower节点和leader 节点的状态会不一致, 但是这个特性提升了集群的整体性能. 当然这种数据不一致的问题, zab协议提供了一种恢复模式来进行数据恢复. 这里需要注意的: leader 的投票过程,不需要Observer 的ack,也就是Observer 不需要参与投票过程, 但是Observer 必须要同步Leader 的数据从而在处理请求的时候保证数据的一致性. 崩溃恢复的实现原理我们知道 ZAB 协议是基于原子广播协议的消息广播过程, 在正常情况下是没有任何问题的, 但是一旦leader 节点崩溃或者由于网络问题导致Leader 服务器事务了过半的follower 的节点的联系()leader 失去与过半的follower节点联系, 可能是leader 节点和follower节点之间产生了网络分区, 那么此时的leader 已经不再是合法的leader了),那么就会进入到崩溃恢复模式. 崩溃恢复模式下ZAB协议需要做两件事情: 选举出新的leader 数据同步. 我们知道, ZAB 协议的消息广播机制是简化版本的2PC协议, 这种协议只需要集群中过半的节点响应提交即可. 但是它无法处理Leader 服务器崩溃带来的数据不一致问题, 因此在ZAB 协议中添加了一个”崩溃恢复模式” 来解决这个问题. 那么ZAB协议中的崩溃恢复需要保证, 如果一个事务Proposal 在一台机器上被处理成功, 哪怕是出现故障, 为了达到这个目的, 我们先来设想一下, 在zookeeper 中会有哪些场景导致数据不一致性, 以及针对这个场景, zab协议中的崩溃恢复应该怎么处理. 已经被处理的消息不能丢当leader 收到合法数量follower的ACK 后, 就向各个follower 广播 commit 命令, 同时也会在本地执行 commit 并向连接的客户端返回[成功]. 但是如果在各个 follower 在收到commit 命令前leader 就挂了, 导致剩下的服务器并没有执行这条消息. 图中是C2就是一个典型的例子, 在集群正常运行过程的某一个时刻, server1 是leader 服务器, 先后广播了消息P1、P2、C1、P3 和C2。 其中当leader 服务器把消息C2(commit 事务proposal2) 发出后就立即崩溃退出了, 那么针对这种情况, ZAB协议就需要确保事务Proposal2 最终能够在所有的服务器上都能被提交成功, 否则将会出现不一致. 被丢弃的下次不能再次出现当leader 接收到消息请求生成proposal 后就挂了, 其他follower 并没有收到此proposa,因此经过恢复模式重新选了leader 后, 这条消息是被跳过的. 之前挂了的leader 重新启动并注册成了follower, 它保留了被跳过消息的proposal状态, 与整个系统的状态是不一致的. 需要将其删除. ZAB协议需要满足上面两种情况, 就必须设计一个leader 选举算法，能够确保已经被leader 提交的事务proposal 能够提交, 同时丢弃已经被跳过的事务Proposal. 针对这个要求: 如果leader 选举算法能够保证新选举出来的leader 服务器拥有集群中所有寄去最高编号(zxid最大) 事务Proposal, 那么就可以保证这个新选举出来的leader 一定具有已经提交的提案. 因为所有提案被commit 之前必须有超过半数的follower ACK,即必须有超过半数的节点的服务器的事务日志上有该提案的proposal. 因此, 只要有合法数量的节点正常工作, 就必然有一个节点保存了所有被Commit 消息的proposal 状态. 另外一个, zxid 是64位, 高32位是epoch编号, 每经过一次leader 选举产生一个新的leader, 新的leader 会将epoch 号 +1, 低32位是 消息计数器, 每接收到一条消息这个值+1,新的leader 选举后这个值重置为0, 这样设计的好处在于老的leader 挂了以后重启, 它不会被选举为leader, 因此此时它的zxid 肯定小于当前新的leader.当老的leader 作为follower 接入新的leader 后, 新的leader 会让他将所有的拥有旧的epoch 号的未被 commit 的proposal 清除. 关于zxid前面一直提到zxid, 也就是事物id, 那么这个id 具体起什么作用呢? 以及这个id 是如何生成的呢? 简单给大家解释一下, 为了保证事务的顺序一致性, zookeeper 采用了递增的事务id 号(zxid)来标识事务, 所有的提议(proposal)都在被提出的时候加上了zxid. 实现中zxid 是一个64位的数字, 它高32位是epoch(ZAB协议通过epoch 编号来区分leader 周期变化的策略)用来标识leader 关系是否改变, 每次一个leader 被选出来后, 它都会有一个新的epoch=（原来的epoch +1）,标识当前属于哪个leader 的统治时期. 低32 用于递增计数. epoch: 可以理解为当前集群所处的年代或者周期, 每个leader 就像皇帝, 都有自己的年号,所以每次改朝换代,leader 变更之后, 都会在前一个年代的基础上加上1. 这样就算旧的leader 崩溃恢复后, 也没人听她的了. 因为follower 只听从当前年代的leader 的命令.","categories":[{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"}],"tags":[]},{"title":"分布式消息通信之Kafka的基本应用","slug":"微服务/kafka/分布式消息通信之Kafka的基本应用","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/kafka/fen-bu-shi-xiao-xi-tong-xin-zhi-kafka-de-ji-ben-ying-yong/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/kafka/fen-bu-shi-xiao-xi-tong-xin-zhi-kafka-de-ji-ben-ying-yong/","excerpt":"","text":"分布式消息通信之Kafka的基本应用消息中间件的背景分析场景分析我们可以使用阻塞队列+线程池的方式来实现生产者和消费者的模式 . 比如在一个应用中, A 方法调用B方法去执行一些任务处理, 我们可以同步调用, 但是如果这个时候请求比较多的情况下, 同步调用会比较耗时会导致请求阻塞. 我们会使用阻塞队列+线程池的方式来实现异步任务的处理. 那么问题来了, 在分布式系统用中, 两个服务之间需要通过这种异步的队列的方式来处理任务, 那么单进程级别的队列就无法解决这个问题了. 因此, 引入了消息中间件, 也就是把消息交给第三方的服务, 这个服务能够实现数据的存储以及传输, 使得在分布式架构下实现跨进程的远程消息通信. 所以,简单来说: 消息中间件是指利用高效的消息传输机制进行平台无关的数据交流, 并且基于数据通信来是进行分布式系统的集成. 思考一下消息中间件的设计可以先从基本的需求开始考虑 最基本的是要能支持消息的发送和接受, 需要设计到网络通信就一定会涉及到NIO 消息中心的消息存储(持久化/ 非持久化) 消息的序列化和非序列化 是否跨语言 消息的确认机制, 如何避免重复消费 高级功能 消息的有序性 是否支持事务消息 消息收发的性能,对高并发大数据的支持 是否支持集群 消息的可靠性存储 是否支持多协议. 这个思考的过程其实就是做需求的整理, 然后再使用已有的技术体系进行技术的实现. 而我们所目前阶段去了解的, 无非就是别人根据实际需求进行实现后, 我们如何使用它们提供的API 进行应用而已,但是有了这样一个全局的思考, 那么对于后续的学习这个技术本身而言, 也显得很容易了. 发展过程实际上消息中间件的发展也是挺有意思的, 我们直到任何一个技术的出现都是为了解决实际问题，这个问题是通过一种通过通用的软件”总线” 也就是一种通信系统, 解决应用程序之间繁重的信息通讯工作. 最早的小白鼠就是金融领域, 因为在当时这个领域中, 交易员需要通过不同的终端完成交易, 每台终端显示不同的信息, 如果接入消息总线, 那么交易员只需要在一台终端上操作, 然后订阅其他终端感兴趣的消息,于是就诞生了发布订阅模型(pubsub). 同时诞生了世界上以第一个现代消息队列软件(TIB) The information Bus, TIB 允许开发者建立一系列规则去描述消息内容, 只要消息按照这些规则发布出去,任何消费者应用都能订阅自己感兴趣的消息. 随着TIB 带来的甜头被广泛的应用在各大领域, IBM 也开始研究开发自己的消息中间件, 3年之后IBM 的消息队列 IBM MQ 产品系列发布, 之后的一段时间MQ系列进入成了 WebSphere MQ 统治商业消息队列平台市场. 包括后期微软也研发了自己的消息队列(MSMQ) 各大厂商纷纷研究自己的MQ,但是他们是以商业化的模式运营自己的MQ软件, 商业MQ 想要解决的是应用互通的问题, 而不是创建标准的接口来允许不同的MQ 互通, 所有有些大型的金融公司可能会使用多个供应商的MQ产品, 来服务企业内部的不同的应用. 那么问题来了, 如果应用已经订阅了TIB MQ的消息然后突然需要消费IBM MQ的消息, 那么整个实现过程就会很麻烦了. 为了解决这个问题, 在2001 年诞生了Java Message Service(JMS), JMS 通过提供公共的java API方式, 隐藏单独MQ产品供应商的实现接口, 从而跨域了不同MQ消费和解决互通问题. 从技术层面来说, Java应用程序只需要针对JMS API 编程, 选择合适的MQ驱动即可. JMS 会处理其他部分, 这种方案其实是通过单独标准化接口来整个很多不同的接口, 效果还是不错的. **但是碰到了互用性的问题, 两套使用不同编程语言的程序如何通过它们的异步消息传递机制相互通信呢? 这个时候就需要定义一个异步消息的通用标准. ** 所以AMQP（Advanced Message Queuing Protocol） 高级消息队列就产生了, 它使用一套标准的底层协议, 加入了许多其他特征来支持互用性, 为现代应用丰富了消息传递需求, 针对标准编码的任何人都可以和任何AMQP 供应商提供的MQ 服务器进行交互. 除了JMS和AMQP 规范以外, 还有一种MQTT(Message Queueing Telemetry[特莱米缺] Transport)， 他是专门为小设备设计的, 因为计算性能不高的设备不能适应AMQP的基本要求, 而如今, MQTT是互联网(IOT）生态系统中的主要成分之一. 今天讲解的Kafka, 它并没有遵循上面所说的协议规范, 注重吞吐量, 类似udp和tcp. Kafka 的介绍什么是KafkaKafka是一款分布式消息发布和订阅系统, 他的特点是高性能、高吞吐量. 最早设计的目的是作为 LinkedIn的活动流和运营数据的处理管道, 这些数据主要用来对用户做用户画像分析以及服务器性能的一些监控. 所以Kafka 一开始设计的目标就是作为一个高性能、高吞吐量的消息系统, 所以适合运用在大数据传输场景. Kafka 的应用场景由于Kafka具有更好的吞吐量、内置分区、冗余和容错性的优点(Kafka每秒可以处理几十万消息), 让Kafka 成为了一个很好的大规模消息处理应用的解决方案, 所以在企业级应用场景,主要会应用于如下几个方面: 行为追踪Kafka 可以用于追踪用户浏览页面、搜索以及其他行为, 通过发布、订阅模式实时记录到对应的topic中, 通过后端大数据平台接入处理分析, 并作更进一步的实时处理和监控. 日志收集日志收集方面, 有很多比较优秀的产品, 比如 Apache Flume, 很多公司使用Kafka 代理日志聚合, 日志聚合表示从服务器上收集日志文件, 然后放到一个集中的平台(文件服务器)进行处理. 在实际应用开发中, 我们应用程序的log 都会输出到本地的磁盘上, 排查问题的话通过linux 命令来搞定. 如果应用程序组成了负载均衡集群, 并且集群的数量有几十台以上, 那么想通过日志快速定位到问题 , 就是很麻烦的问题. 所以一般都会做一个日志统一收集平台管理log日志用来快速查询重要应用的问题. 所以很多公司的套路都是把应用日志集中到Kafka上, 然后分别导入到ES和HSFS上, 用来做实时检索和离线统计数据备份等. 而另一方面,Kafka 本身就提供了很好的api 来集成日志并且做日志收集 . Kafka 本身的架构一个典型的Kafka 集群包含若干 Produce（可以是应用节点产生的消息, 也可以是通过Flume 收集日志产生的事件）, 若干个Broker(Kafka支持水平扩展), 若干个Consumer Group以及一个zookeeper 集群. Kafka 通过zookeeper 管理集群配置和服务协同. Produce 使用push模式将消息发布到broker, consumer 通过监听使用pull 模式从 broker 订阅并消费消息 多个broker 协同工作, produce和consumer 部署在各个业务逻辑中,三者通过 zookeeper 管理协调请求和转发, 这样就组成了一个高性能的分布式消息发布和订阅系统. 图上有一个细节是和其他mq中间件不同的点是, produce 发送消息到 broker 的过程是push, 而consumer 是从broker 消费消息的过程是pull, 主动去拉数据. 而不是broker 把数据主动发送给 consumer. 名词解释brokerKafka集群包含一个或者多个服务器, 这种服务器被称为 broker. broker 端不维护数据的消费状态, 提升了性能. 直接使用磁盘进行存储, 线性读写速度快, 避免了数据在JVM内存和系统内存之间的复制, 减少了耗性能的创建对象和垃圾回收. Produce负责发布消息到Kafka broker Consumer消息消费者,向Kafka broker 读取消息的客户端, consumer 从broker 拉取(pull) 数据并进行处理. Topic每条发布到Kafka 集群的消息都有一个类别, 每个类别被称为Topic,(物理上不同Topic 的消息分开存储, 逻辑上一个Topic 的消息虽然保存于一个或者多个broker上, 但用户只需要指定消息的Topic 即可生产或者消费数据而不必关心数据存于何处). PartitionPartition 是物理上的概念, 每个Topic 包含一个或者多个Partition Consumer Group每个Consumer 属于一个特定的 Consumer Group(可为每个Consumer 指定group name,若不指定group name 则属于默认的group) Topic &amp; PartitionTopic 在逻辑上可以被认为是一个queue, 每条消费者都必须指定它的topic, 可以简单理解为必须指明把这条消息放进哪个queue.为了使得kafka 的吞吐率可以线性提高, 物理上把topic 分为一个或者多个Partition, 每个Partition 在物理上对应一个文件夹, 该文件夹下存储这个Partition 的所有消息和索引文件. 若创建 topic1和topic2两个topic, 且分别有13个分区和19个分区, 则整个集群上会相应生成共32个文件夹(本文所有集群共8个节点,此处topic1和topic2 replication-factor均为1). Kafka 的安装部署单机部署下载Kafkahttps://archive.apache.org/dist/kafka/2.0.0/kafka_2.11-2.0.0.tgz 安装 过程安装过程非常简单, 只需要解压就行, 因为这个是编译好之后的可执行程序. tar -zxvf kafka_2.11-2.0.0.tgz 配置zookeeper因为Kafka 依赖于zookeeper 来做master 选举以及其他数据的维护, 所以需要先启动zookeeper 节点, Kafka 内置了zookeeper的服务, 所以 在bin目录下提供了这些脚本. zookeeper-server-start.sh zookeeper-server-stop.sh 在config 目录下, 存在一些配置文件 zookeeper.properties server.properties 所以我们可以通过下面的脚来启动zk服务。当然也可以自己搭建zk 的集群来实现. sh zookeeper-server-start.sh -daemon ../config/zookeeper.properties 启动和停止Kafka 修改 server.properties , 增加zookeeper 的配置 zookeeper.connect=localhost:2181 启动kafka ./kafka-server-start.sh -daemon ../config/server.properties 停止Kafka sh kafka-server-stop.sh -daemon config/server.properties Kafka的基本操作创建Topic sh kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 – partitions 1 –topic test Replication-factor 表示该topic 需要在不同的broker 中保存几份, 这里设置为1, 表示在两个broker 中保存两份. Partitions 分区数 查看Topic sh kafka-topics.sh –list –zookeeper localhost:2181 查看Topic的属性 sh kafka-topics.sh –describe –zookeeper localhost:2181 –topic first_topic 消费消息 sh kafka-console-consumer.sh –bootstrap-server 192.168.13.106:9092 –topic test –from-beginning 发送消息 sh kafka-console-producer.sh –broker-list 192.168.244.128:9092 –topic first_topic 集群安装环境准备 准备三台虚拟机 分别把kafka 的安装包部署在三台机器上. 修改配置以下配置修改均为 server.properties 分别修改三台机器的server.properties 配置, 同一个集群中的每个机器的id必须唯一. broker.id=0 broker.id=1 broker.id=2 修改zookeeper 的连接配置 zookeeper.connect=192.168.86.128:2181 修改 listeners配置 如果配置了listeners, 那么消息生产者和消费者会使用 listeners的配置来进行消息的收发, 否则, 会使用 localhost PLAINTEXT 表示协议, 默认是明文, 可以选择其他加密协议. listeners=PLAINTEXT://192.168.86.128:9092 分别启动三台服务器 sh kafka-server-start.sh -daemon ../config/server.properties","categories":[{"name":"kafka","slug":"kafka","permalink":"https://rainsoil.github.io/categories/kafka/"},{"name":"微服务","slug":"kafka/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"kafka/微服务/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"kafka","slug":"kafka/微服务/微服务/kafka","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/kafka/"}],"tags":[]},{"title":"SpringBoot与Dubbo的整合","slug":"微服务/dubbo/SpringBoot与Dubbo的整合","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/springboot-yu-dubbo-de-zheng-he/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/springboot-yu-dubbo-de-zheng-he/","excerpt":"","text":"SpringBoot 与Dubbo 的整合新建项目我们先新建一个基于Springboot 的项目 jar包添加dubbo 和zookeeper 的jar &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-recipes&lt;/artifactId> &lt;version>4.0.0&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-framework&lt;/artifactId> &lt;version>4.0.0&lt;/version> &lt;/dependency> &lt;!-- https://mvnrepository.com/artifact/org.apache.dubbo/dubbo-spring-boot-starter --> &lt;dependency> &lt;groupId>org.apache.dubbo&lt;/groupId> &lt;artifactId>dubbo-spring-boot-starter&lt;/artifactId> &lt;version>2.7.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.dubbo&lt;/groupId> &lt;artifactId>dubbo&lt;/artifactId> &lt;version>2.7.2&lt;/version> &lt;/dependency> 编写接口和实现类package com.dubbo.spring; /** * @author luyanan * @since 2019/11/20 * &lt;p>对外暴漏一个接口&lt;/p> **/ public interface UserApi &amp;#123; String info(String id); &amp;#125; import com.dubbo.spring.UserApi; import org.apache.dubbo.config.annotation.Reference; import org.apache.dubbo.config.annotation.Service; /** * @author luyanan * @since 2019/11/20 * &lt;p>&lt;/p> **/ // @Service Dubbo 的注解 @Service public class UserApiImpl implements UserApi &amp;#123; @Override public String info(String id) &amp;#123; System.out.println(\"info 请求\"); return \"张三:\" + id; &amp;#125; &amp;#125; 编写controller/** * @author luyanan * @since 2019/11/20 * &lt;p>&lt;/p> **/ @RestController @RequestMapping(\"user\") public class UserController &amp;#123; // dubbo 提供了注入的方法 @Reference private UserApi userApi; @GetMapping(\"info/&amp;#123;id&amp;#125;\") public String info(@PathVariable(\"id\") String id) &amp;#123; return userApi.info(id); &amp;#125; &amp;#125; 添加dubbo 的配置文件## dubbo 项目名称 dubbo.application.name=dubbo-spring-server ## dubbo 扫描路径 dubbo.scan.base-packages=com.dubbo.spring ## 注册中心地址 dubbo.registry.address=zookeeper://192.168.86.128:2181 运行后, 我们访问 http://localhost:8080/user/info/100000 张三:100000","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"RabbitMQ工作模型与java编程(2)","slug":"微服务/rabbitMQ/RabbitMQ工作模型与java编程(2)","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/rabbitmq/rabbitmq-gong-zuo-mo-xing-yu-java-bian-cheng-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rabbitmq/rabbitmq-gong-zuo-mo-xing-yu-java-bian-cheng-2/","excerpt":"","text":"3. Spring AMQP3.1 Spring AMQP 介绍思考： Java API 方式编程, 有什么问题? Spring 封装RabbitMQ的时候, 它做了什么呢? 管理对象(队列,交换机、绑定) 封装方法(发送消息、接收消息) ​ Spring AMQP 是对Spring 基于AMQP 的消息收发解决方案, 它是一个抽象层, 不依赖特定的AMQP Broker 实现和客户端的抽象, 所以我们可以很方便的替换. 我们我们可以使用spring-rabbit 来实现. 3.2 Spring AMQP 核心组件3.2.1 ConnectionFactory​ Spring AMQP 的连接工厂接口, 用于创建连接, CachingConnectionFactory 是ConnectionFactory的一个实现类. 3.2.2 RabbitAdmin​ RabbitAdmin 是AmqpAdmin的实现, 封装了对RabbitMQ的基础管理操作, 比如对交换机、队列、绑定的声明和删除等. ​ 编写配置类 package com.rabbitmq.rabbitspring.admin; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.connection.ConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitAdmin; import org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer; import org.springframework.amqp.support.ConsumerTagStrategy; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @author luyanan * @since 2020/1/8 * &lt;p>&lt;/p> **/ @Configuration public class AdminConfig &amp;#123; @Bean public ConnectionFactory connectionFactory() &amp;#123; CachingConnectionFactory factory = new CachingConnectionFactory(); factory.setUri(\"amqp://guest:guest@127.0.0.1:5672\"); return factory; &amp;#125; @Bean public RabbitAdmin rabbitAdmin(ConnectionFactory connectionFactory) &amp;#123; RabbitAdmin rabbitAdmin = new RabbitAdmin(connectionFactory); return rabbitAdmin; &amp;#125; @Bean public SimpleMessageListenerContainer container(ConnectionFactory connectionFactory) &amp;#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory); container.setConsumerTagStrategy(new ConsumerTagStrategy() &amp;#123; @Override public String createConsumerTag(String s) &amp;#123; return null; &amp;#125; &amp;#125;); return container; &amp;#125; &amp;#125; 测试类 package com.rabbitmq.rabbitspring.admin; import org.springframework.amqp.core.Binding; import org.springframework.amqp.core.DirectExchange; import org.springframework.amqp.core.Queue; import org.springframework.amqp.rabbit.core.RabbitAdmin; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import org.springframework.context.annotation.ComponentScan; /** * @author luyanan * @since 2020/1/8 * &lt;p>&lt;/p> **/ @ComponentScan(\"com.rabbitmq.rabbitspring.admin\") public class AdminTest &amp;#123; public static void main(String[] args) &amp;#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(AdminTest.class); RabbitAdmin rabbitAdmin = applicationContext.getBean(RabbitAdmin.class); // 声明一个交换机 rabbitAdmin.declareExchange(new DirectExchange(\"ADMIN_EXCHANGE\", false, false)); // 声明一个队列 rabbitAdmin.declareQueue(new Queue(\"ADMIN_QUEUE\", false, false, false)); // 声明一个绑定 rabbitAdmin.declareBinding(new Binding(\"ADMIN_QUEUE\", Binding.DestinationType.QUEUE, \"ADMIN_EXCHANGE\", \"admin\", null)); &amp;#125; &amp;#125; ​ 为什么我们在配置文件(Spring) 或者配置类(SpringBoot) 里面定义了交换机、队列、绑定关系,并没有直接调用Channel 的declare方法, Spring 在启动的时候就可以帮我们创建这些元数据? 这些数据就是由RabbitAdmin 完成的. ​ RabbitAdmin 实现了InitializingBean 接口,里面由一个唯一的方法 afterPropertiesSet(),这个方法会在RabbitAdmin 的属性值设置完的时候被调用. ​ 在afterPropertiesSet() 方法中, 调用了一个initialize() 方法, 这里面创建了三个Collection,用来盛放交换机、队列、绑定关系. ​ 最后依次声明返回类型为Exchange、Queue和Binding的这些Bean, 底层还是调用了Channel 的declare方法. ```java declareExchanges(channel, exchanges.toArray(new Exchange[exchanges.size()]));declareQueues(channel, queues.toArray(new Queue[queues.size()]));declareBindings(channel, bindings.toArray(new Binding[bindings.size()])); ``` 3.2.3 Message Message 是Spring AMQP 对消息的封装. 两个重要的属性: body: 消息内容 messageProperties: 消息属性 3.2.4 RabbitTemplate 消息模板​ RabbitTemplate 是AmqpTemplate 的一个实现(目前到此为止也是唯一的实现), 用来简化消息的收发,支持消息的确认(Configm)与返回(Return). 跟JDBCTemplate 一样, 它封装了建立连接、创建消息信道、收发消息、消息合适转换(ConvertAndSend -&gt;Message)、关闭信道、关闭连接等等操作. 对于多个服务器连接, 可以定义多个Template, 可以注入到任何需要收发消息的地方使用. 确认与回发 @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) &amp;#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMandatory(true); // 回发 rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &amp;#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &amp;#123; System.out.println(\"回发的消息：\"); System.out.println(\"replyCode: \" + replyCode); System.out.println(\"replyText: \" + replyText); System.out.println(\"exchange: \" + exchange); System.out.println(\"routingKey: \" + routingKey); &amp;#125; &amp;#125;); rabbitTemplate.setChannelTransacted(true); // 确认 rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &amp;#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &amp;#123; if (!ack) &amp;#123; System.out.println(\"发送消息失败：\" + cause); throw new RuntimeException(\"发送异常：\" + cause); &amp;#125; &amp;#125; &amp;#125;); return rabbitTemplate; &amp;#125; 3.2.5 MessageListener 消息侦听MessageListener :​ MessageListener 是Spring AMQP 异步消息投递的监听器接口, 它只有一个方法onMessage,用于处理消息队列送来的消息, 作用类似于Java API 中的Comsumer. ​ MessageListenerContainer​ MessageListenerContainer 可以理解为MessageListener 的容器, 一个Contailer 只有一个listener, 但是可以生成多个线程使用的MessageListener同时消费消息. ​ Contailer 可以管理Listener 的生命周期, 可以用于对于消费者进行配置. 例如: 动态添加队列、对消费者进行设置,例如ConsumerTag、Arguments、并发、消费者数量、消息确认模式等. @Bean public SimpleMessageListenerContainer container(ConnectionFactory connectionFactory) &amp;#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory); // 设置监听的队列 container.setQueues(getSecondQueue(), getThirdQueue()); // 最小消费数 container.setConcurrentConsumers(1); //最大的消费者数量 container.setMaxConcurrentConsumers(5); // 是否重回队列 container.setDefaultRequeueRejected(false); //签收模式 container.setAcknowledgeMode(AcknowledgeMode.AUTO); container.setExposeListenerChannel(true); container.setConsumerTagStrategy(new ConsumerTagStrategy() &amp;#123; @Override public String createConsumerTag(String s) &amp;#123; return null; &amp;#125; &amp;#125;); return container; &amp;#125; 在SpringBoot 2.0 中新增了一个DirectMessageListenerContainer。 DirectMessageListenerContainerSpring 整合IBM MQ、JMS、Kafka 也是这么做的. @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory connectionFactory) &amp;#123; SimpleRabbitListenerContainerFactory containerFactory = new SimpleRabbitListenerContainerFactory(); containerFactory.setConnectionFactory(connectionFactory); containerFactory.setMessageConverter(new Jackson2JsonMessageConverter()); containerFactory.setAcknowledgeMode(AcknowledgeMode.NONE); containerFactory.setAutoStartup(true); return containerFactory; &amp;#125; 可以在消费者上指定, 当我们需要监听多个RabbitMQ 的服务器的时候, 指定不同的MessageListenerContainerFactory @Component @RabbitListener(queues = \"first_queue\", containerFactory = \"rabbitListenerContainerFactory\") public class FirstConsumer &amp;#123; @RabbitHandler public void process(@Payload Object message) &amp;#123; System.out.println(\"First_queue received mes : \" + message); &amp;#125; &amp;#125; 产生关系与继承关系 整合代码 public class ContainerSender &amp;#123; public static void main(String[] args) throws URISyntaxException &amp;#123; ConnectionFactory factory = new CachingConnectionFactory(new URI(RabbitConfig.rabbitUrl)); SimpleRabbitListenerContainerFactory containerFactory = new SimpleRabbitListenerContainerFactory(); containerFactory.setConnectionFactory(factory); SimpleMessageListenerContainer container = containerFactory.createListenerContainer(); // 不用工厂模式也可以创建 container.setConcurrentConsumers(1); container.setQueueNames(\"BASIC_SECOND_QUEUE\"); container.setMessageListener(new MessageListener() &amp;#123; @Override public void onMessage(Message message) &amp;#123; System.out.println(\"收到消息:\" + message); &amp;#125; &amp;#125;); container.start(); AmqpTemplate template = new RabbitTemplate(factory); template.convertAndSend(\"BASIC_SECOND_QUEUE\", \"msg1\"); &amp;#125; &amp;#125; 3.2.6 转换器MessageConvertorMessageConvertor 的作用?​ RabbitMQ的消息在网络传输中需要转换成byte[]（字节数组）进行发送, 消费者需要对字节数组进行解析. ​ 在Spring AMQP 中, 消息会被封装为org.springframework.amqp.core.Message 对象. 消息的序列化和反序列化, 就是处理Message 的消息体body 对象. 如果消息已经是byte[] 格式,就不需要转换. 如果是String, 会转换成byte[]. 如果是Java 对象,会使用JDK 序列化对象转换为byte. 在调用RabbitTemplate 的convertAndSend() 方法发送消息的时候, 会使用MessageConvertor 进行消息的序列化,默认使用SimpleMessageConverter. ​ 在某些情况下,我们需要选择其他的高效的序列化工具.如果我们不想在每次发送消息的时候自己处理消息,就可以直接定义一个 MessageConverter. @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) &amp;#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter()); return rabbitTemplate; &amp;#125; MessageConvertor 如何工作的?​ 调用了RabbitTemplate 的 convertAndSend() 方法时会使用对应的MessageConvertor 进行消息的序列化和反序列化. ​ 序列化: Object-&gt; json-&gt; Message(body)-&gt; byte[] ​ 反序列化: byte[] -&gt; Message -&gt; json -&gt; Object 有哪些MessageConvertor?​ 在Spring 中提供一个默认的转换器: SimpleMessageConverter. ​ Jackson2JsonMessageConverter(RabbitMQ自带): 将对象转换为json, 然后再转换成字节数字进行传递. 如何自定义MessageConvertor 例如: 我们要使用Gson 格式化消息. 创建一个类, 实现MessageConverter 接口，重写 toMessage()和 fromMessage() 方法。 toMessage(): Java 对象转换为Message fromMessage(): Message 对象转换为Java 对象 3.3 Spring 集成RabbitMQ 配置解读&lt;rabbit:connection-factory id=\"connectionFactory\" virtual-host=\"/\" username=\"guest\" password=\"guest\" host=\"127.0.0.1\" port=\"5672\" /> &lt;rabbit:admin id=\"connectAdmin\" connection-factory=\"connectionFactory\" /> &lt;rabbit:queue name=\"MY_FIRST_QUEUE\" durable=\"true\" auto-delete=\"false\" exclusive=\"false\" declared-by=\"connectAdmin\" /> &lt;rabbit:direct-exchange name=\"MY_DIRECT_EXCHANGE\" durable=\"true\" auto-delete=\"false\" declared-by=\"connectAdmin\"> &lt;rabbit:bindings> &lt;rabbit:binding queue=\"MY_FIRST_QUEUE\" key=\"FirstKey\"> &lt;/rabbit:binding> &lt;/rabbit:bindings> &lt;/rabbit:direct-exchange> &lt;bean id=\"jsonMessageConverter\" class=\"org.springframework.amqp.support.converter.Jackson2JsonMessageConverter\" /> &lt;rabbit:template id=\"amqpTemplate\" exchange=\"$&amp;#123;exchange&amp;#125;\" connection-factory=\"connectionFactory\" message-converter=\"jsonMessageConverter\" /> &lt;bean id=\"messageReceiver\" class=\"com.consumer.FirstConsumer\">&lt;/bean> &lt;rabbit:listener-container connection-factory=\"connectionFactory\"> &lt;rabbit:listener queues=\"MY_FIRST_QUEUE\" ref=\"messageReceiver\" /> &lt;/rabbit:listener-container> 3.4 SpringBoot集成RabbitMQ在SpringBoot工程中, 为什么没有定义Spring AMQP的任何一个对象, 也能实现消息的收发? SpringBoot 做了什么? 我们这里模拟: ​ 3个交换机与4个队列绑定. 4个消费者分别监听4个队列. ​ 生产者发送4条消息,4个队列收到5条消息. 消费者打印出5条消息. 3.4.1 配置文件 定义交换机、队列 package com.rabbitmq.rabbitspring.springboot; import org.springframework.amqp.core.*; import org.springframework.amqp.rabbit.config.SimpleRabbitListenerContainerFactory; import org.springframework.amqp.rabbit.connection.ConnectionFactory; import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.concurrent.Executors; /** * @author luyanan * @since 2020/1/9 * &lt;p>&lt;/p> **/ @Configuration public class RabbitConfig &amp;#123; public static final String direct_exchange = \"DIRECT_EXCHANGE\"; public static final String topicexchange = \"topicexchange\"; public static final String fanoutexchange = \"fanout_exchange\"; public static final String firstqueue = \"first_queue\"; public static final String secondqueue = \"second_queue\"; public static final String thirdqueue = \"third_queue\"; public static final String fourthqueue = \"fourth_queue\"; // 创建三个交换机 @Bean public DirectExchange directExchange() &amp;#123; return new DirectExchange(direct_exchange); &amp;#125; @Bean public TopicExchange topicExchange() &amp;#123; return new TopicExchange(topicexchange); &amp;#125; @Bean public FanoutExchange fanoutExchange() &amp;#123; return new FanoutExchange(fanoutexchange); &amp;#125; // 创建四个队列 @Bean public Queue firstqueue() &amp;#123; return new Queue(firstqueue); &amp;#125; @Bean public Queue secondqueue() &amp;#123; return new Queue(secondqueue); &amp;#125; @Bean public Queue thirdqueue() &amp;#123; return new Queue(thirdqueue); &amp;#125; @Bean public Queue fourthqueue() &amp;#123; return new Queue(fourthqueue); &amp;#125; // 定义绑定关系 @Bean public Binding firstBind(@Qualifier(\"firstqueue\") Queue queue, @Qualifier(\"directExchange\") DirectExchange directExchange) &amp;#123; return BindingBuilder.bind(queue).to(directExchange).with(\"best\"); &amp;#125; @Bean public Binding secondBind(@Qualifier(\"secondqueue\") Queue queue, @Qualifier(\"topicExchange\") TopicExchange topicExchange) &amp;#123; return BindingBuilder.bind(queue).to(topicExchange).with(\"*.test.*\"); &amp;#125; @Bean public Binding threadBind(@Qualifier(\"thirdqueue\") Queue queue, @Qualifier(\"fanoutExchange\") FanoutExchange fanoutExchange) &amp;#123; return BindingBuilder.bind(queue).to(fanoutExchange); &amp;#125; @Bean public Binding fourthBind(@Qualifier(\"fourthqueue\") Queue queue, @Qualifier(\"fanoutExchange\") FanoutExchange fanoutExchange) &amp;#123; return BindingBuilder.bind(queue).to(fanoutExchange); &amp;#125; @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory connectionFactory) &amp;#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setMessageConverter(new Jackson2JsonMessageConverter()); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); factory.setAutoStartup(true); return factory; &amp;#125; &amp;#125; 3.4.2 消费者这里定义4个消费者分别消费4个队列的消息 package com.rabbitmq.rabbitspring.springboot; import org.springframework.amqp.rabbit.annotation.RabbitHandler; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; /** * @author luyanan * @since 2020/1/9 * &lt;p>&lt;/p> **/ @Component @RabbitListener(queues = RabbitConfig.firstqueue, containerFactory = \"rabbitListenerContainerFactory\") public class FirstConsumer &amp;#123; @RabbitHandler public void process(String msg) &amp;#123; System.out.println(\"First queue received msg:\" + msg); &amp;#125; &amp;#125; 其他消费者类似 3.4.3 生产者配置文件package com.rabbitmq.rabbitspring.springboot; import org.springframework.amqp.rabbit.connection.ConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; /** * @author luyanan * @since 2020/1/9 * &lt;p>&lt;/p> **/ @Configuration public class ProducerConfig &amp;#123; public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) &amp;#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter()); return rabbitTemplate; &amp;#125; &amp;#125; 3.4.4 生产者发送消息package com.rabbitmq.rabbitspring.springboot; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import java.util.HashMap; import java.util.Map; /** * @author luyanan * @since 2020/1/9 * &lt;p>&lt;/p> **/ @Component public class RabbitSender &amp;#123; private final static String directroutingkey = \"java.best\"; private final static String topicroutingkey1 = \"shanghai.test.teacher\"; private final static String topicroutingkey2 = \"changsha.test.student\"; @Autowired RabbitTemplate rabbitTemplate; public void send() throws JsonProcessingException &amp;#123; rabbitTemplate.convertAndSend(RabbitConfig.direct_exchange, \"direct msg\", \"北京市\"); rabbitTemplate.convertAndSend(topicroutingkey1, \"topic msg: shanghai.test.teacher\"); rabbitTemplate.convertAndSend(topicroutingkey2, \"topic msg: changsha.test.student\"); Map&lt;String, Object> map = new HashMap&lt;>(); map.put(\"11\", \"111\"); ObjectMapper mapper = new ObjectMapper(); String value = mapper.writeValueAsString(map); rabbitTemplate.convertAndSend(RabbitConfig.fanoutexchange, \"\", value); &amp;#125; &amp;#125; 3.5 SpringBoot 参数解析https://docs.spring.io/spring-boot/docs/2.1.6.RELEASE/reference/html/common-application-properties.html https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html 注: 前缀spring.rabbitmq 全部省略 全部配置总体上分为三类: 连接类、消息消费类、消息发送类. 基于SpringBoot 2.1.5 属性值 说明 默认值 addres 客户端连接的地址, 有多个的时候可以使用逗号分隔,该地址可以是ip和port的结合 host RabbitMQ的主机地址 localhost port RabbitMQ的端口号 virtual-host 连接到 RabbitMQ 的虚拟主机 username 登录到 RabbitMQ 的用户名 password 登录到 RabbitMQ 的密码 ssl.enabled 启动SSL 支持 false ssl.key-store 保存SSL证书的地址 ssl.key-store-password ·访问SSL证书的地址使用的密码 ssl.trust-store SSL的可信地址 ssl.trust-store-password 访问SSL可信地址的密码 ssl.algorithm SSL算法, 默认使用Rabbit 的客户端算法库 cache.channel.checkout-timeout 当缓存已满的时候, 获取Channel 的等待时间,单位为毫秒 cache.channel.size 缓存中保存的channel 的数量 cache.connection.mode 连接缓存的模式 CHANNEL cache.connection.size 缓存的连接数 connnection-timeout 连接超时参数单位为毫秒,设置为0代表无穷大 dynamic 默认创建一个AmqpAdmin的Bean true listener.simple.acknowledge-mode 容器的acknowledge模式 listener.simple.auto-startup 启动的时候自动启动容器 true listener.simple.concurrency 消费者的最小数量 listener.simple.default-requeue-rejected 投递消息失败时是否重新排队 true listener.simple.max-concurrency 消费者的最大数量 listener.simple.missing-queues-fata 容器上声明的队列不可用时是否失败 listener.simple.prefetch 在当个请求中处理的消息个数,它应该大于等于事务数量 listener.simple.retry.enabled 无论是不是重试的发布 false listener.simple.retry.initial-interval 第一次投递和第二次投递尝试的时间间隔 1000ms listener.simple.retry.max-attempts 尝试投递消息的最大数量 3 listener.simple.retry.max-interval 两次尝试的最大时间间隔 10000ms listener.simple.retry.multiplier 上一次尝试时间间隔的乘数 1.0 listener.simple.retry.stateless 重试是有状态的还是无状态的 true listener.simple.transaction-size 在一个事务中处理的消息数量,为了获取最佳消化, 该值应设置为小于等于每个请求中处理的消息个数,即listener.prefetch 的值 publisher-confirms 开启 Publisher Confirm 值 publisher-returns 开启Publisher Return机制 template.mandatory 启动强制信息 false template.receive-timeout receive() 方法的超时时间 0 template.reply-timeout sendAndReceive() 方法的超时时间 5000 template.retry.enabled 设置为true的时候RabbitTemplate 能够实现重试 false template.retry.initial-interval 第一次发布与第二次发布消息的时间间隔 1000 template.retry.max-attempts 尝试发布消息的最大数量 3 template.retry.max-interval 尝试发布消息的最大时间间隔 10000 template.retry.multiplier 上一次尝试时间间隔的乘数 1.0","categories":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/"},{"name":"微服务","slug":"rabbitMQ/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"rabbitMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"rabbitMQ","slug":"rabbitMQ/微服务/微服务/rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/rabbitMQ/"}],"tags":[]},{"title":"RabbitMQ可靠性投递和实践经验","slug":"微服务/rabbitMQ/RabbitMQ可靠性投递和实践经验","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/rabbitmq/rabbitmq-ke-kao-xing-tou-di-he-shi-jian-jing-yan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rabbitmq/rabbitmq-ke-kao-xing-tou-di-he-shi-jian-jing-yan/","excerpt":"","text":"RabbitMQ可靠性投递和实践经验1. 可靠性投递在RabbitMQ里面提供了很多保证可靠投递的机制, 这也是RbabitMQ的一个特性. ​ 我们在讲可靠性投递的时候,必须要明确一个问题,因为效率与可靠性是无法兼得的, 如果要保证每一个环节都成功, 势必会对消息的收发效率造成影响. 所以如果是一些业务实时一致性不是特别高的场景, 可以牺牲一些可靠性换取效率. ​ 比如发送通知或者记录日志的这种场景, 如果用户没有收到通知,不会造成业务影响,只要再次发送就可以了. ​ 我们再来回顾一下RabbitMQ的工作模型 在我们使用RabbitMQ 收发消息的时候, 有几个主要环节: 代表消息从生产者发送Broker, 生产者把消息发到Broker 之后, 怎么知道自己的消息有没有被Broker 成功接收呢? 代表消息从Exchange 路由到Queue Exchange 是一个绑定列表,如果消息没有办法路由到正确的队列,会发生什么事情? 怎么处理呢? 代表消息在Queue 中存储. 队列是一个独立运行的服务,有自己的数据库(Mnesina),它是真正用来存储消息的. 如果还没有消费者来消息, 那么消息要一直存储到队列里面. 如果队列出了问题, 消息肯定会丢失. 怎么保证消息在队列稳定的存储呢? 代表消费者订阅Queue 并消费消息呢? 队列的特性是什么? FOFI. 队列里面的消息是一条一条投递的,也就是说, 只有上一条消息被消费者接收以后, 才能把这一条消息从数据库删除,继续投递下一条消息. 那么问题来了, Broker 怎么知道消费者已经接收到了消息呢? 1.1 消息发送到RabbitMQ 服务器​ 第一个环节是生产者发送消息到Broker. 可能以为网络或者Broker 的问题导致消息发送失败,生产者不能确定Broker 有没有正常的接收. ​ 在RabbitMQ 里面提供了两种机制 服务端确认机制,也就是在生产者发送消息给RabbitMQ的服务端的时候, 服务端会通过某种方式返回一个应答,只要生产者收到了这个应答, 就知道消息发送成功了. ​ 第一种是Transaction(事务),第二种Confirm(确认)模式。 1.1.1 Transaction(事务)模式​ 事务模式怎么使用呢? 我们通过一个channel.txSelect() 的方法把信道设置成事务模式,然后就可以发布消息给RabbitMQ了,如果channel.txCommit() 方法调用成功, 就说明事务提交成功, 则消息一定达到了RabbitMQ中. ​ 如果在事务提交执行以前由于RabbitMQ 异常崩溃或者其他原因导致抛出异常, 这个时候我们便可以将其捕获, 进而通过执行channel.txRollback() 方法来实现事务回滚. ```java public static void main(String[] args) throws NoSuchAlgorithmException, KeyManagementException, URISyntaxException, IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setUri(RabbitMQConfig.rabbitMQUrl); // 建立连接 Connection connection = factory.newConnection(); //创建消息通道 Channel channel = connection.createChannel(); String msg = &quot;Hello World&quot;; // 声明交换机 channel.queueDeclare(&quot;TRANSACTION_QUEUE&quot;, false, false, false, null); try &#123; channel.txSelect(); channel.basicPublish(&quot;&quot;, &quot;TRANSACTION_QUEUE&quot;, null, msg.getBytes()); channel.txCommit(); System.out.println(&quot;消息发送成功&quot;); &#125; catch (IOException e) &#123; channel.txRollback(); System.out.println(&quot;消息发送失败, 回滚&quot;); &#125; channel.close(); connection.close(); &#125; ``` ​ AMQP 协议抓包示意 ​ 在事务模式里面, 只有收到了服务器端的Commit-OK的指令, 才能提交成功. 所以可以解决生产者和服务端确认的问题. 但是事务模式有一个特点, 它是阻塞的, 一条消息没有发送完毕,不能发送下一条消息,它会榨干RabbitMQ服务器的性能. 所以不建议大家在生产环境中使用. ​ SpingBoot 中的配置 rabbitTemplate.setChannelTransacted(true); ​ 那么有没有其他可以保证消息被Broker 接收,但是又不大量消耗性能的方式呢? 这个就是第二种模式, 叫做确认(Confirm)模式. Confirm(确认)模式​ 确认模式有三种, 一种是普通确认模式. ​ 这生产者这边通过调用 channel.confirmSelect() 方法将信道设置为Confirm 模式, 然后发送消息. 一旦消息被投递到所有匹配的队列之后, RabbitMQ就会发送一个确认(Basic.ACK) 给生产者,也就是调用 channel.waitForConfirms() 返回true, 这样生产者就知道消息被服务端接受了. ​ 这种发送一条消息确认一条消息的方式效率还是不太高,所以我们还有一种批量确认的方式. 批量确认就是在开启Confirm 模式后, 只要channel.waitForConfirmsOrDie(); 方法没有抛出异常,就代表哦消息都被服务端接受了. ​ 批量确认的方式比单条确认的方式效率要高,但是也有两个问题,第一个就是批量的数量的确认,对于不同的业务, 到底发送多少条消息确认一次? 数量太少, 效率提升不上去. 数量多的话, 又会带来另外一个问题. 比如我们发1000条消息才确认一次, 如果前面999条消息都被服务端接受了,如果第1000条消息被拒绝了,那么前面所有的消息都要被重发. 有没有一种方式,可以一边发送一边确认呢? 这个就是异步的确认模式. ​ 异步确认模式需要添加一个ConfirmListener, 并且用一个SortedSet 来维护没有被确认的消息. ​ Confirm 模式是在Channel 上开启的,因为RabbitTemplate 对Channel 进行封装,叫做ConfimrCallback. ​ rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &amp;#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &amp;#123; if (!ack) &amp;#123; System.out.println(\"发送消息失败：\" + cause); throw new RuntimeException(\"发送异常：\" + cause); &amp;#125; &amp;#125; &amp;#125;); 1.2 消息从交换机路由到队列​ 第二个环节就是消息从交换机路由到队列. 在什么情况下, 消息会无法路由到正确的队列呢? 可能是因为路由键错误或者队列不存在. ​ 我们这里有两种方式处理无法路由的消息,一种就是让服务端重发给生产者, 一种是让交换机路由到另一个备份的交换机, 消息回发的方式: 使用mandatory 参数和 ReturnListener（在 Spring AMQP 中是 ReturnCallback）。 rabbitTemplate.setMandatory(true); rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback()&amp;#123; public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey)&amp;#123; System.out.println(\"回发的消息：\"); System.out.println(\"replyCode: \"+replyCode); System.out.println(\"replyText: \"+replyText); System.out.println(\"exchange: \"+exchange); System.out.println(\"routingKey: \"+routingKey); &amp;#125; &amp;#125;); 消息路由到备份交换机的方式,在创建交换机的时候, 从属性中指定备份交换机. Map&lt;String,Object> arguments = new HashMap&lt;String,Object>(); arguments.put(\"alternate-exchange\",\"ALTERNATE_EXCHANGE\"); // 指定交换机的备份交换机 channel.exchangeDeclare(\"TEST_EXCHANGE\",\"topic\", false, false, false, arguments); 注意区别: 队列可以指定死信交换机,交换机可以指定备份交换机. 1.3 消息在队列中存储. 第三个环节是消息对队列中存储,如果没有消费者的话,队列一直存在在数据库中. ​ 如果RabbitMQ 的服务或者硬件发生故障,比如系统宕机、重启、关闭等等, 可能会导致内存中的消息丢失, 所以我们要本消息本身和元数据(队列、交换机、绑定) 都保存到磁盘 解决方案: 1.3.1 队列持久化@Bean(\"Queue\") public Queue Queue() &amp;#123; // queueName, durable, exclusive, autoDelete, Properties return new Queue(\"TEST_QUEUE\", true, false, false, new HashMap&lt;>()); &amp;#125; 1.3.2 交换机持久化@Bean(\"Exchange\") public DirectExchange exchange() &amp;#123; // exchangeName, durable, exclusive, autoDelete, Properties return new DirectExchange(\"TEST_EXCHANGE\", true, false, new HashMap&lt;>()); &amp;#125; 1.3.3 消息持久化MessageProperties messageProperties = new MessageProperties(); messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT); Message message = new Message(\"持久化消息\".getBytes(), messageProperties); rabbitTemplate.send(\"TEST_EXCHANGE\", \"test\", message); 1.3.4 集群如果只有一个RabbitMQ的节点, 即使交换机、队列、消息做了持久化, 如果服务崩溃或者硬件发生故障,RabbitMQ 的服务一样是不可用的, 所以为了提高MQ服务的可用性, 保障消息的传输, 我们需要有多个RabbitMQ 的节点 . 1.4 消息投递到消费者​ 如果消费者受到消息后没来得及处理即发生异常,或者处理过程中发生了异常, 会导致失败。 服务端应该以某种方式得知消费者对消息的接收情况,并决定是否重新投递这条消息给其他消费者. ​ RabbitMQ 提供了消费者的消息确认机制(message acknowledgement), 消费者可以自动或者手动的发送ACK 给服务端. ​ 没有收到ACK 的消息, 消费者断开连接后, RabbitMQ 会把这条消息发送给其他消费者, 如果没有其他消费者, 消费者重启后会重新消费这条消息,重复执行业务逻辑. ​ 消费者在订阅队列时,可以指定 autoAck参数, 当autoAck 参数等于false的时候, RabbitMQ 会等待消费者显式的回复确认信号后才从队列中移除消息. ​ 如何设置手动Ack? ​ SimpleRabbitListenerContainer 或者 SimpleRabbitListenerContainerFactory factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); application.peroperties spring.rabbitmq.listener.direct.acknowledge-mode=manual spring.rabbitmq.listener.simple.acknowledge-mode=manual 注意这三个值的区别: NONE: 自动ACK MANUAL: 手动ACK AUTO: 如果方法未抛出异常,则发送ACK 当抛出AmqpRejectAndDontRequeueException 异常的时候,则消息会被拒绝, 则不重新入队. 当抛出ImmediateAcknowledgeAmqpException 异常, 则消费者会发送ACK, 其他的异常,则消息会拒绝, 且 requeue=true 会重新入队. 在SpringBoot 中, 消费者又怎么调用ACK,或者说怎么获得Cahnenl 的参数呢? public class SecondConsumer &amp;#123; @RabbitHandler public void process(String msgContent,Channel channel, Message message) throws IOException &amp;#123; System.out.println(\"Second Queue received msg : \" + msgContent ); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &amp;#125; &amp;#125; ​ 如果消息无法处理或者消费失败, 也有两种拒绝的方式,Basic.Reject() 拒绝单条, Basic.Nack() 批量拒绝. 如果requeue 参数设置为true ,可以把这条消息重新存入队列, 以便发给下一个消费者(当然, 只有一个消费者的时候, 这种方式可能会出现无限循环重复消费的情况, 可以投递到新的队列或者只打印异常日志). ​ 思考: 服务端收到了ACK 或者Nack , 生产者会知道吗? 即使消费者没有接受到消息, 或者消费时出现了异常,生产者也是完全不知情的. ​ 例如: 我们寄出去一个快递，是怎么知道收件人有没有收到的? 因为有物流追踪和签收反馈,所以寄件人可以知道. 在没有用上电话的年代, 我们寄出去一封信, 是怎么知道收信人有没有收到信件? 只有收到回信,才知道寄出去的信被收到了. 所以,这个是生产者最终确定消费者有没有消费成功的两种方式: 消费者收到消息,处理完毕后, 调用生产者的API 消费者收到消息, 处理完毕后, 发送一条响应给生产者. 1.5 消费者回调1.5.1 调用生产者API​ 例如: 提单系统给其他系统分别发送了碎屏保信息后， 其他系统必须在处理完消息后调用提单系统提供的API,来修改提单系统中的数据. 只要API没有被调用,数据状态没有被修改,提单系统就认为下游系统没有收到这条消息. 1.5.2 发送响应消息给生产者​ 例如：商业银行与人民银行二代支付通信, 无论是人行收到了商业银行的消息还是商业银行收到了人行的消息, 都必须发送一条响应消息(叫做回执报文)。 1.6 补偿机制 如果生产者的API就是没有被调用, 也就是没有收到消费者的响应消息, 怎么办? ​ 不要着急, 可能是消费者处理时间太长或者网络超时. ​ 生产者与消费者之间应该约定一个超时时间,比如5分钟,对于超过这个时间没有得到响应的消息, 可以设置一个定时重发的机制, 但是要控制发送的间隔和控制次数, 比如每隔2分钟发送一次, 最多重发三次,否则会造成消息堆积. 重发可以通过消息落库+定时任务来实现. ​ 重发, 是否发送一模一样的消息. ​ ATM机上运行的系统叫C端(ATMC),前置系统叫P端(ATMP), 它接受ATMC 的消息, 再转发给卡系统或者核心系统. - 如果客户存款, 没有收到核心系统的应答, 不知道有没有记账成功,最多发送5条存款确认报文, 因为已经吞钞了, 所以要保证成功. - 如果客户取款, ATMC未得到应答,最多发送5次存款冲正报文, 因为没有吐钞, 所以要保证失败。 1.7 消息幂等性​ 如果消费者每一个接收生产者的消息都成功了, 只是在响应或者调用API的时候出了问题, 会不会出现消息的重复处理? 例如: 存款100元,ATM重发了5次, 核心系统一共处理了6次,余额会增加了600元. ​ 所以, 为了避免相同消息的重复处理, 必须要采取一定的措施,RabbitMQ 服务端是没有这种控制的(同一批的消息有个递增的DeliveryTag), 它不知道你是不是就是要把一条消息发送两次, 只能在消费端控制. ​ 如何避免消息的重复消费? ​ 消息出现重复可能会有两个原因: 生产者的问题,环节1重复发送消息, 比如在开启了Confirm 模式但未收到确认,消费者重复投递. 环节4出现了问题, 由于消费者未发送ACK 或者其他原因, 消息重复投递. 生产者代码或者网络问题 . 对于重复发送的消息, 可以对每一条消息生成一个唯一的业务ID, 通过日志或者消息落库来做重复控制. 1.8 最终一致​ 如果确实是消费者宕机了或者代码出现了BUG 导致无法正常消息, 在我们尝试多次重发以后, 消息最终也没有得到处理,怎么办? ​ 例如存款的场景, 客户的钱已经被吞了, 但是余额没有增加, 这个时候银行出现了脏款, 应该怎么处理呢? 如果客户没有主动通知银行, 这个问题是怎么发现的? 银行最终是怎么把这个账务做平的? 在我们的金融系统中, 都会有双方对账或者多放对账的操作, 通常是在一天的业务结束之后, 第二天营业之前. 我们会约定一个标准, 比如ATM 跟核心系统对账, 肯定是以核心系统为准.ATMC 获取到核心的对账文件, 然后解析,登记成数据, 然后跟自己记录的流水比较, 找出核心有, ATM没有的, 或者ATM有,核心没有的. 或者两边都有大那是金额不一致的数据. 对账以后,我们再手工平账.比如取款记了账但是没吐钞的, 做一笔冲正.存款吞了钞但是没记账的, 那么把钱退给客户, 要么补一笔账. 1.9 消息的顺序性 消息的顺序性指的是消费者消费消息的顺序跟生产者生产消息的顺序是一致的. 例如:商户信息同步到其他系统,有三个业务操作: 1. 新增门店 2: 绑定产品； 3: 激活门店. 这种情况下消息消费顺序不能颠倒(门店不存在时无法绑定产品和激活). 又比如: 1. 发送微博 2:发表评论;3:: 删除微博, 顺序不能颠倒. 在RabbitMQ 中, 一个队列有多个消费者时，由于不同的消费者消费消息的速度是不一样的, 顺序无法保证。 只有一个队列仅有一个消费者的情况下才能保证顺序消费(不同的业务消息发送到不同的专用队列上). 2 集群和高可用2.1 为什么要做集群?​ 集群主要用以实现高可用于负载均衡. 高可用: 如果集群中的某些MQ 服务器不可用, 客户端还可以连接其他MQ 服务器. 负载均衡: 在高并发的场景下, 单台MQ 服务器能处理的消息是有限的. 可以分发给多台MQ服务器. ​ RabbitMQ 有两种集群模式: 普通集群模式和镜像队列模式. 2.2 RabbitMQ 如何支持集群? 应用做集群,需要面对数据同步和通信的问题.因为Erling天生具备分布式的特性, 所以RabbitMQ 天然支持集群, 不需要通过引入ZK或者数据库来实现数据同步. RabbitMQ 通过/var/lib/rabbitmq/.erlang.cookie 来验证身份, 需要在所有节点上保持一致. 2.3 RabbitMQ的节点类型? 集群有两种节点类型,一种是磁盘节点(Disc Node),一种是内存节点(RAM Node). 磁盘节点 : 将元数据(包括队列名称属性、交换机的类型名字属性、绑定、vhost)放在磁盘中. 内存节点: 将元数据放在内存中. 内存节点会将磁盘节点下的地址存放在磁盘中(不然重启就没办法同步数据了), 如果是持久化的消息, 会同时存在在内存和磁盘 集群中至少需要一个磁盘节点来持久化元数据,否则全部内存节点崩溃时, 就无法同步元数据. 未指定类型的情况下, 默认为磁盘节点. 我们一般把应用连接到内存节点(读写快), 磁盘节点用来备份. 集群通过25672 端口两两通信, 需要开放防火墙的端口. 需要注意是的: RabbitMQ 集群无法搭建在广域网上, 除非使用federation 或者 shovel等插件(没必要, 在同一个机房做集群). 集群的配置步骤 配置hosts 同步erlang.cookie 加入集群(join cluster) 2.4普通集群普通集群模式下, 不同的节点之间只会相互同步元数据 疑问: 为什么不直接把队列的内容(消息) 在所有节点上复制一份呢? 主要是出于存储和同步数据的网络开销的考虑,如果所有节点都存储相同的数据,就无法达到线性的增加性能和存储容量的目的(堆机器). ​ 假如生产者连接的是节点3, 要将消息通过交换机A 路由到队列1, 最终消息还是会转发到节点1上存储, 吨位队列1的内容只是在节点1上. ​ 同理,如果消费者连接的是节点2, 要从队列1上拉取消息, 消息会从节点1转发到节点2上。其他节点起到一个路由的作用,类似于指针 . ​ 普通集群模式不能保证队列的高可用性, 因为队列内容不会复制, 如果节点失效将导致相关队列不可用, 因此我们需要第二种集群模式. 2.5 镜像集群第二种集群模式叫做镜像对垒. 镜像队列模式下, 消息内容会在镜像节点间同步, 可用性更高. 不过也有一定的副作用, 系统性能会降低, 节点过多的情况下同步的代价比较大. ​ 2.6 高可用​ 集群搭建成功后, 如果有多个内存节点, 那么生产者和消费者应该连接到哪个节点呢? 如果在我们的代码中根据一定的策略来选择要使用的服务器, 那每个地方都要修改,客户端的代码就会出现很多的重复, 修改起来也比较麻烦. ​ 所以需要一个负载均衡的组件(例如HAProxy、LVS、Nginx) ,由负载的组件来做路由。这个时候, 只需要俩呢及到负载组件的IP地址就可以了. ​ 负载分为四层负载和四层负载. 四层负载:工作在OSI模式的第四层, 即传输层(TCP位于第四层),它是根据IP端口进行转发(LVS 支持四层负载). RabbltMQ 是TCP的5672端口. 七层负载: 工作在第七层,应用层(HTTP层位于第七层). 可以根据请求资源类型分配到后端服务器(Nginx支持七层负载, HAProxy 支持四层负载和七层负载). 但是如果这个负载的组件也挂了呢? 客户端就无法连接到任意一台MQ 的服务器了.所以负载软件本身也需要做一个集群.新的问题又来了, 如果有两台负载的软件,客户端应该连哪个呢? ​ 负载之上再负载? 陷入死循环了. 这个时候我们就要换个思路了. 我们应该需要这样一个组件: 它本身有路由(负载)功能, 可以监控集群中节点的状态(比如监控HAProxy), 如果某个节点出现异常或者发生了故障，就把它剔除掉. 为了提高可用性,它也可以部署多个服务, 但是只有一个自动选举出来的Master 服务器(叫做主路由器), 通过广播心跳消息实现. Master 服务器对外一个虚拟的IP, 提供各种网络功能. 也就是谁抢占到了VIP, 就由谁对外提供网络服务. 应用端只需要连接到这一个IP就行了. 这个协议叫做做 VRRP 协议（虚拟路由冗余协议 Virtual Router Redundancy Protocol），这个组件就是 Keepalived，它具有 Load Balance 和 High Availability 的功能。 3. 实践经验总结3.1 资源管理到底是在消费者创建还是在生产者创建呢? ​ 如果A项目和B项目有互相发送和接收消息,应该创建几个vhost，几个exchange呢? 交换机和队列, 实际上是作为资源, 由运维管理员创建的. 3.2 配置文件与命名规范 元数据的命名集中放在properties 文件中,不需要硬编码 . 如果有多个系统,可以配置多个xxx_mq.properties. 命名体现元数据类型 虚拟机命名: _VHOST 交换机命名:XXX_Exchange 队列命名:XXX_QUEUE. 命名体现数据来源和去向 例如： 销售系统发往产品系统的交换机: SALE_TO_PRODUCT_EXCHANGE。做到 见名知义，不用去查文档（当然注释是必不可少的）。 3.3 调用封装在项目中,可以对Template 做进一步封装,简化消息的发送., 例如:如果交换机、路由键是固定的, 封装之后就只需要一个参数: 消息内容. 另外,如果想要平滑的迁移不同的MQ(如果有这种需求),也可以再做一层简单的封装. 3.4 信息落库+定时任务​ 将需要发送的消息保存在数据库中,可以实现消息的可追溯和重复控制,需要配合定时任务来实现. 将需要发送的消息登记在消息表中. 定时任务一分钟或者半分钟扫描一次,将未发送的消息发送到MQ 服务器,并且修改状态为已发送. 如果需要重发消息, 将制定消息的状态修改为未发送即可. 副作用:降低效率,浪费存储空间. 3.5 生产环境运维监控虽然RabbitMQ 提供了一个简单的管理界面,但是如果对于系统性能、高可用和其他参数有一定定制化的监控需求的话,我们就需要通过其他的方式来实现监控了. ​ 主要关注:磁盘、内存和连接数. 3.6 日志追踪​ RabbitMQ 可以通过Firehose 功能来记录消息的流入流出的情况, 用于调试、排错. ​ 它是通过创建一个TOPIC 类型的交换机(amq.rabbitmq.trace), 把生产者发送给Broker 的消息或者Broker 发送给消费者的消息发送到这个默认的交换机上来实现的. ​ 另外RabbitMQ 也提供了一个个 Firehose 的 GUI 版本，就是 Tracing 插件. ​ 启动Tracing 插件管理界面右侧选项卡会多一个Tracing, 可以添加相应的策略. ​ RabbitMQ 还提供了其他的插件来增强功能. https://www.rabbitmq.com/firehose.html https://www.rabbitmq.com/plugins.html 3.7 如何减少连接数 在发送大批量消息的情况下, 创建和释放连接依然有不小的开销. 我们可以跟接收方约定批量消息的格式,比如支持JSON 数组的格式,通过合同消息内容,可以减少生产者/消费者与Broker 的连接.","categories":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/"},{"name":"微服务","slug":"rabbitMQ/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"rabbitMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"rabbitMQ","slug":"rabbitMQ/微服务/微服务/rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/rabbitMQ/"}],"tags":[]},{"title":"分布式消息通信之Kafka 的实现原理2","slug":"微服务/kafka/分布式消息通信之Kafka 的实现原理2","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/kafka/fen-bu-shi-xiao-xi-tong-xin-zhi-kafka-de-shi-xian-yuan-li-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/kafka/fen-bu-shi-xiao-xi-tong-xin-zhi-kafka-de-shi-xian-yuan-li-2/","excerpt":"","text":"分布式消息通信之Kafka 的实现原理2分区的副本机制我们已经知道kafka的每个topic 都可以分为多个partition, 并且多个partition 会均匀分布在集群中的各个节点下.虽然这种方式能够有效的对数据进行分片, 但是对于每个partition而言, 都是单点的. 当其中某个partition不可用的时候, 那么这部分消息就没办法消费. 所以kafka为了提高partition 的可靠性而提供了副本的概念(Replica),通过副本机制来实现冗余备份. 每个分区可以有多个副本, 并且在副本集合中会存在一个leader 的副本, 所有的读写请求都是由leader 副本来进行处理. 剩余的其他副本都作为follower 副本. follower 副本会从leader 副本同步消息日志. 这个有点类似于zookeeper 中的leader 和follower 的概念. 但是具体的实现方式还是有比较大的差异的. 所以我们可以认为，副本集会存在一主多从的关系. 一般情况下,同一个分区的多个副本会被均匀的分配到集群中的不同broker 上. 当leader 副本所在的broker 出现故障后, 可以重新选举新的leader 副本继续对外提供服务. 通过这样的副本机制来提高kafka 集群的可用性. 创建一个带副本机制的topic通过下面的命令去创建带2个副本的topic sh kafka-topics.sh –create –zookeeper 192.168.86.128:2181 –replication-factor 3 –partitions 3 –topic secondTopic 然后我们可以在/tmp/kafka-logs 路径下看到对应topic 的副本信息, 我们通过一个图形的方式来表达. 针对secondTopic 这个topic 的3个分区对应的3个副本 如何知道各个分区中对应的leader是谁呢?在zookeeper 的服务器上, 通过如下命令去获取对应分区的信息, 比如下面这个是获取secondTopic 的第一个分区的状态信息 get /brokers/topics/secondTopic/partitions/1/state {“controller_epoch”:12,”leader”:0,”version”:1,”leader_epoch”:0,”isr”:[0,1]} 或通过这个命令 sh kafka-topics.sh –zookeeper 192.168.86.128:2181 –describe –topictest_partition leader表示当前分区的leader 是哪个broker_id, 下图中,绿色线条的表示该分区中的leader 节点. 其他节点就是follower. 需要注意是是: kafka 集群中的一个broker 中最多只能有一个副本,leader 副本所在的broker 节点的分区叫leader 节点, follower 副本所在的broker 节点的分区叫follower 节点. 副本的leader 选举kafka 提供了数据复制算法保证, 如果leader 副本所在的broker 节点宕机或者出现故障,或者分区的leader节点发生了故障, 这个时候怎么处理呢? 那么, kafka 必须要保证从follower 副本中选择一个新的leader 副本. 那么kafka 是如何实现选举的呢？ 要了解leader 选举, 我们需要了解几个概念 kafka 分区下有可能有多个副本(replica)用于实现冗余, 从而进一步实现高可用. 副本根据角色的不同可分为3类: leader 副本: 响应clients 端读写请求的副本. follower副本: 被动的备份leader 副本中的数据, 不能响应clients 端读写请求. ISR副本: 包含了leader 副本和所有和leader 副本保持同步的follower 副本 如何判定是否与leader 同步后面会提到 每个kafka 副本对象都有两个重要的属性: LEO和HW. 注意是所有的副本, 而不是只有leader 副本. LEO: 即日志末端位移(log end offset) , 记录了该副本底层日志(log) 中下一条消息的位移值, 注意是下一条消息. 也就是说, 如果LEO =10, 那么表示该副本中保存了10条消息, 位移值范围是[0,9].另外, leader LEO和 follower LEO的更新是有区别的. HW: 即前面提到的水位值. 对于同一个副本对象而言, 其HW值不会大于LEO值, 小于等于HW值的所有消息都被认为是”已备份”的(relicated). 同理, leader 副本和follower 副本的HW更新是有区别的. 从生产者发出的一条消息首先会被写入分区的leader 副本,不过还需要等待ISR集合中的所有follower 副本都同步完成之后, 才能被认为已经提交. 之后才会更新分区的HW， 进而消费者可以消费到这条消息. 副本协同机制刚刚提到了, 消息的读写操作都只会由leader 节点来接受和处理. follower 副本只负责同步数据以及当leader 副本所在的broker 挂了之后, 会从follower 副本中选择新的leader . 写请求首先由leader 副本处理,之后follower 副本会从leader 副本上拉取写入的消息, 这个过程就有一定的延迟,导致follower 副本中保存的消息略少于leader 副本,但是只要没有超过阈值就可以容忍. 但是如果一个follower 副本出现了异常,比如宕机、网络断开等原因长时间没有同步到消息, 那这个时候, leader 就会把它踢出去. kafka 通过维护ISR集合来维护一个分区副本信息. 一个新leader 被选举并被接受客户端的消息成功写入. kafka 确保从同步副本列表中选举一个副本为leader, leader负责维护和跟踪ISR(in-Sync replicas ， 副本同步队列)中所有follower 滞后的状态. 当producer 发送一条消息到broker 后, leader写入消息并复制到所有的follower. 消息提交之后才被成功复制到所有的同步副本. ISRISR 表示目前”可用且消息量与leader 相差不多的副本集合. 这是整个副本集合的一个子集. “ 怎么去理解可用和相差不多这两个词呢? 具体来说, ISR 集合中的副本必须满足两个条件: 副本所在节点必须维护着与zookeeper的连接 副本最后一条消息的offset 与leader 副本的最后一条消息的offset 之间的差值不能超过指定的阈值(replica.lag.time.max.ms) replica.lag.time.max.ms：如果该follower 在此时间间隔内一直没有追上过leader 的所有消息, 则该follower 就会被剔除ISR列表. ISR 数据保存在Zookeeper的 /brokers/topics//partitions//state 节点中 follower 副本把leader 副本LEO 之前的日志全部同步完成时, 则认为follower 副本已经追赶上了leader 副本, 这个时候会更新这个副本的 lastCaughtUpTimeMs 标识, kafka 副本管理器会启动 一个副本过期检查的定时任务, 这个任务会定期检查当前时间和副本的 lastCaughtUpTimeMs 的差值是否大于参数 replica.lag.time.max.ms的值, 如果大于,则将这个副本剔除ISR集合. 在ISR 中至少有一个follower 时, kafka 可以确保已经commit 的数据不丢失, 但是如果某个partition 的所有Replica 都宕机了, 就无法保证数据不丢失了. 等待ISR 中的任一个Replica “活”过来,并且选择它为leader. 选择第一个”活”过来的Replica(不一定是ISR中的) 作为leader. 这就需要在可用性和一致性当中做出一个简单的折中 如果一定要等待ISR 中的Relica “活”过来, 那不可用的时间可能会相对较长。而且如果ISR 中的所有Replica 都无法”活”过来, 或者数据都丢失了,这个Partition 将永远不可用. 选择第一个”活”过来的partition 作为Leader, 而这个Replica 不是ISR 中的Replica, 那即是它并不保证已经包含了所有已经commit的消息, 它也会成为leader 而作为consumer 的数据源. 副本数据同步原理了解了副本的协同过程后,还有一个最重要的机制, 就是数据的同步过程, 它需要解决: 怎么传播消息 在向消息发送端返回ack 之前需要保证多少个Replica 已经接受到了这个消息. 数据的处理过程下图中, 深红色部分表示test_replica分区的leader 副本, 另外另个节点上浅色部分表示 follower 副本. producer在发布消息到某个Partition时: 先通过zookeeper 找到该Partition 的leader(get /brokers/topics//partitions/2/state) 然后无论Topic 的Relicaiton Factor为多少(也就是该Partition 有多少个Relica),producer 只将该消息发送到该Partition的Leader, Leader 会将该消息写入其本地Log,每个Follower 都从Leader pull 数据. 这种方式上, Follower 存储的数据顺序与Leader 保持一致 Follower 在收到该消息并写入其Log 后, 向Leader 发送ACK。 一旦Leader 收到了ISR 中的所有Replica的ACK,该消息就被认为已经commit, Leader 将增加HW(HighWatermark) 并且向Producer 发送ACK。 LEO： 即日志末端位移(log end offset), 记录了该副本底层日志(log)中下一条消息的位移值. 注意是下一条消息. 也就是说, 如果LEO =10, 那么表示该副本保存了10条消息, 位移值范围是[0,9].另外, Leader LEO和follower LEO 的更新是有区别的. HW: 即上面提到的水位值(Hight Water). 对于同一个副本对象而言，其HW值不会大于LEO值, 小于等于HW值的所有消费者都被认为是”已备份”的(reolicaed).同理, leader 副本和follower 副本的HW更新是有区别的. 通过下面这幅图来表达LEO、HW的含义. 随着Follower 副本不断和Leader副本进行数据同步, follower 副本的LEO会逐渐后以并且追赶上leader 副本, 这个追赶的判断标准化是当前副本的LEO 是否大于或者等于leader 副本的HW， 这个追赶上也会使得被剔除的follower 副本重新加入到ISR集合中. 另外,假如说下图中的最右侧的follower 副本被踢出ISR集合, 也会导致整个分区的HW发生变化, 变成了3 初始状态初始状态下, leader和follower 的HW和LEO 都是0, leader 副本会保存 remote_LEO, 表示所有follower LE0也会被初始化为0. 这个时候, producer 没有发送消息. follower 会不断的向leader 发送fetch请求,但是因为没有数据 ,这个请求会被leader 寄存, 当在指定的时间之后会强制完成请求,这个时间的配置是 replica.fetch.wait.max.ms. 如果在指定的时间内producer 有消息发送过来, 那么kafka 会唤醒fetch 请求， 让leader 继续处理. fetch的是,当没有消息的时候会阻塞, 根据replica.fetch.wait.max.ms参数来设定阻塞时间 数据的同步处理会分为两种情况, 这两种情况下处理方式是不一样的. 第一种是leader 处理完producer 请求之后, follower 发送一个fetch 请求过来. 第二种是follower 阻塞在leader 指定的时间之内, leader 副本收到producer 的请求. 第一种情况生产者发送一条消息leader 处理完producer请求之后, follower 发送一个fetch 请求过来.状态图如下: leader 副本收到请求以后, 会做几件事情 把消息追加到log 文件,同时更新leader 副本的LEO 尝试更新leader HW值, 这个时候由于follower 副本还没有发送fetch 请求, 那么leader 的remote_LEO 仍然是0。 leader会比较自己的LEO 以及remote_LEO 的值发现最小值是0, 与HW的值相同, 所以不会更新HW。 follower fetch消息 **Follower 发送fetch 请求, leader 副本的处理逻辑是: ** 读取log数据, 更新 remote_LEO=0(follower还没有写入这条消息, 这个值是根据follower 的fetch 请求中的offset来决定的) 尝试更新HW, 因为这个时候LEO 和remote_LEO 还是不一致, 所以仍然是HW=0 把消息内容和当前分区的HW值发送给follower 副本. follower 副本收到response后 将消息写入到本地log, 同时更新follower 到LEO 更新follower HW，本地的LEO和leader 返回的HW进行比较取小的值, 所以仍然是0 第一次交互结束以后, HW 仍然是0, 这个值会在下一次follower 发起fetch 请求的时候被更新. fetch 发第二次fetch请求, leader 收到请求以后 读取log 数据 更新remote_LEO =1, 因为这次fetch 携带的是offset 是1. 更新当前分区的HW,这个时候leader_LEO 和remote_LEO 都是1, 所以HW 的值也更新为1. 把数据和当前分区的HW的值返回给follower 副本, 这个时候如果没有数据, 则返回为空. follower 副本收到response 以后 如果有数据则写入本地日志, 并且更新LEO 更新follower 的HW的值 到目前为止, 数据的同步就完成了, 意味着消费者能够消费offset = 1 这条消息. 第二种情况前面说过, 由于leader 副本暂时没有数据过来, 所以follower 的fetch 会被阻塞, 直到等待超时或者leader 接收到新的数据。 当leader 收到请求以后会唤醒处于阻塞的fetch 请求 . 处理过程基本上跟前面说的一致. leader 将消息写入到本地日志, 更新leader 的LEO 唤醒follower 的fetch 请求 更新HW kafka 使用HW和LEO 的方式来实现副本数据的同步, 本身是一个很好的设计, 但是这个地方就存在一个数据丢失的问题, 当然这个丢失只出现在特定的情况下。我们回想一下， HW的值是在新一轮 fetch 中才会被更新, 我们分析一下这个过程为什么会出现数据丢失. 数据丢失的问题 前提 min.insync.replicas=1 设定ISR中的最小副本数是多少? 默认为1(在server.properties中配 置), 并且acks 参数设置为-1(表示需要所有副本都确认)时, 此参数才生效. 表达的含义是, 至少需要多少个副本同步才能表示消息是提交的.所以当 min.insync.replicas=1 的时候, 一旦消息被写入leader 端log 即被认为是”已提交”,而延迟一轮 fetch rpc更新HW值的设计使得follower HW值是异步延迟更新的, 倘若这这个过程中leader 发生了变更, 那么称为新的leader 的follower 的HW值就有可能是过期的, 使得clients 端认为是成功提交的消息被删除. producer 的ackacks 配置表示producer 发送消息到broker 上以后的确认值, 有三个可选项 0 :表示producer 不需要等待broker 的消息确认, 这个选项时延最小但是同时风险最大(因为当server 宕机时, 数据会丢失) 1: 表示producer 只需要获得kafka 集群中的leader 节点确认即可, 这个选择时延较小同时确保了leader 节点确保接受成功. all(-1): 需要ISR 中所有的replica 给与接受确认, 速度最慢, 安全性最高. 但是由于ISR 可能会缩小到仅包含一个Replica, 所以设置参数为all 并不一定能避免数据丢失. 数据丢失的解决方案在kafka 0.11.0.0 版本之后, 引入一个leader epoch 来解决这个问题, 所谓的leader epoch 实际上是一对值(epoch offset),epoch 表示leader 的版本号, 从0开始递增, 当leader 发生过变更, epoch 就+1, 而offset 则是对应这个epoch 版本的leader 写入第一条数据的offset, 比如 (0,0),(1,50) 表示第一个leader 从offset = 0写入消息,一共写了50条. 第二个leader 版本号是1, 从offset = 50 开始写, 这个信息会持久化在对应的分区的本地磁盘上, 文件名是 /tmp/kafkalog/topic/leader-epoch-checkpoint. leader broker 中会保存这样一个缓存, 并且定时写入到 checkpoint 文件中. 当leader 写log时它会尝试更新整个缓存, 如果这个leader 首次写消息, 则会在缓存中增加一个条目; 否则就不做更新. 而每次副本重新成为leader时会查询这部分缓存, 获取出对应leader 版本的offset. 我们基于同样的情况来分析, follower 宕机并且恢复之后, 有两种情况,如果这个时候leader 副本没有挂, 也就是意味着没有发生leader 选举,那么follower 恢复之后并不会去截断自己的日志, 而是先发送一个OffsetsForLeaderEpochRequest请求给到leader 副本, Leader 副本收到请求之后返回自己的LEO 如果follower 副本的leaderEpoch 和leader副本的epoch 相同, leader 的LEO 只可能的大于或者等于follower 副本的LEO的值, 所以这个时候不会发生截断. 如果follower 副本和leader 副本的epoch 的值并不相同, 那么leader副本会查找follower 副本传过来的epoch+1在本地文件中存储的StartOffset 返回的follower 副本, 也就是新leader副本的LEO. 这样也避免了数据丢失的问题. 如果leader 副本宕机了重新选举新的leader, 那么原本的follower 副本就会变成leader, 意味着epoch 从0变成了1, 使得原本follower 副本中的LEO 的值得到了保留. Leader 副本的选举过程 kafkaController 会监听zookeeper的/broker/ids 节点路径, 一旦发生有broker 挂了, 执行下面的逻辑,这里暂时不考虑KfkaController 挂了的情况, KafkaController 挂了，各个broker 会重新leader 选举出新的KafkaController. leader 副本在该broker 上的分区就要重新进行leader 选举, 目前的选举策略是: 优先从ISR 列表中选出第一个作为leader 副本, 这个叫优先副本, 理想情况下优先副本就是该分区的leader 副本. 如果ISR列表为空, 则查看该topic 的unclean.leader.election.enable 配置. unclean.leader.election.enable 配置为true 则代表允许选用非ISR 列表的副本作为leade, 那么此时就意味着数据可能丢失. 为false的话, 则不允许, 直接抛出NoReplicaOnlineException 异常, 造成leader 副本选举失败. 如果上述的配置为true, 则从其他副本中选出一个作为leader 副本, 并且ISR 列表中只包含该leader 副本, 一旦选举成功则将选举后的leader 和ISR 的其他副本信息写入该分区的对应的zk路径上. 消息的存储​ 消息发送端发送消息到broker 后, 消息说如何持久化的呢? 那么接下来去分析下消息的存储. 首先我们需要了解的是, kafka 是使用日志文件的方式来保存生产者和消费者发送的消息, 每条消息都有一个offset 值来表示它在分区中的偏移量. kafka 中存储的一般都是海量的消息数据，为了避免日志文件过大，log并不是直接对应在一个磁盘上的日志文件, 而是对应磁盘的一个目录, 这个目录的命名为 &lt;topic_name&gt;_&lt;partition_id&gt; 消息的文件存储机制 一个topic 的多个partition 在物理磁盘上的保存路径, 路径保存在 /tmp/kafka-logs/topic_partition ,包含日志文件、索引文件和时间索引文件和时间索引文件. ​ kafka 是通过分段的方式将log 分为多个LogSegment, LogSegment 是一个逻辑上的概念, 一个LogSegment 对应磁盘上的一个日志文件和一个索引文件, 其中日志文件是用来记录消息的. 索引文件是用来保存消息的索引的. 那么这个 LogSegment 是什么呢? LogSegment​ 假设kafka 是以partition 为最小存储单位的, 我们可以想象一下 当kafka producre 不断发送消息, 必然会引起partition 的无限扩展, 这样对应消息文件的维护以及被消息的消息的清理带来非常大的挑战, 所以kafka 以 segment 为单位又把partition 进行细分, 每个partition 相当于一个巨型文件被平均分配到多个大小相等的segment 的数据文件中(每个segment 文件中的消息并不一定相等), 这种特性方便已经被消费的消息的清理,提高磁盘的利用率. log.segment.bytes=107370 (设置分段大小), 默认是1gb, 我们把这个值调小以后, 可以看到日志分段的效果. 抽取其中3个分段进行分析. ​ segment file 由2大部分组成, 分别为 index file和data file, 此2个文件一一对应, 成对出现,后缀”.index”和”.log” 分别表示为segment 索引文件和数据文件. ​ segment 文件命名规则: partition 全局的第一个 segment 从0开始, 后续每个segment 文件名为上一个segment 文件最后一条消息的offset 值进行递增。数据最大为64位long 大小, 20位数据字符长度, 没有数字用0 填充. 查看Segment 文件命名规则通过下面这条命令可以看到kafka 消息日志的内容.sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test0/00000000000000000000.log --print-data-log ​ 假如第一个log文件的最后一个offset为:5376,所以下一个segment的文件命名为: 00000000000000005376.log。对应的index为00000000000000005376.index segment 中index和log 的对应关系从所有分段中, 找一个分段进行分析 ​ 为了提高查找消息的性能, 为每一个日志文件添加2个索引文件: OffsetIndex 和 TimeIndex,分别对应.index和.timeindex. timeindex 索引文件格式: 它是映射时间戳和相对offset ​ 查看索引文件内容 sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test0/00000000000000000000.index --print-data-log 如图所示. index 中存储了索引以及物理偏移量.log 存储了消息的内容. 索引文件的元数据执行对应数据文件中message的物理偏移量. 举个简单的例子, 以[4053,80899]为例, 在log文件中, 对应的是第4053条记录, 物理偏移量(position)为80899, position 是ByteBuffer 的指针位置. 在Partition 中如何通过offset查找message查找的算法是: 根据offset 的值, 查找segment 段中的index索引文件. 由于索引文件命名是以上一个文件的最后一个offset 进行命名的, 所以, 使用二分法 查找算法能够根据offset 快速定位到指定的索引文件. 找到索引文件后, 根据offset 进行定位, 找到索引文件中符合范围的索引(kafka采用稀疏索引的方式来提高查找性能) 得到position 后, 再找到对应的log文件中，从position处开始查找offset 对应的消息, 将每条消息offset 与目标offset 进行比较, 直到找到消息. 比如说,我们要查找offset = 2490 这条消息, 那么先找到00000000000000000000.index,然后找到[2487,49111] 这个索引, 再回到log文件中, 根据49111 这个position 开始查找, 比较每条消息的offset 是否大于等于2490, 最后查找到对应的消息以后返回. Log文件的消息内容分析前面我们通过kafka 的命名,可以查看二进制的日志文件信息, 一条消息, 会包含很多字段 offset: 5371 position: 102124 CreateTime: 1531477349286 isvalid: true keysize: -1 valuesize: 12 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: false headerKeys: [] payload: message_5371 offset 和position 这两个前面已经讲过了, createTime 表示创建时间、、keysize和valuesize 表示key 和value 的大小, compresscodec 表示压缩编码、payload 表示消息的具体内容 日志的清除策略以及压缩策略日志清除策略前面提到过, 日志的分段存储, 一方面能够减少单个文件内容的大小, 另一方面, 方便kafka 进行日志的清理. 日志的清理策略有两个: 根据消息的保留时间, 当消息在kafka 中保存的时间超过了指定的时间, 就会触发清理过程. 根据topic 存储的数据大小, 当topic 所占的日志文件大于一定的阈值, 则开始删除最旧的消息. kafka 会启动一个后台线程, 定时检查是否存在可以删除的消息. 通过log.retention.bytes和log.retention.hours 这两个参数来设置, 当其中任意一个达到要求, 都会执行删除. 默认的保留时间是7天. 日志压缩策略​ kafka 还提供了日志压缩”Log Compaction” 功能, 通过这个功能可以有效地减少日志文件的大小, 缓解磁盘紧张的情况, 在很多应用场景中, 消息的key 和value的值之间的对应关系是不断变化的, 就像数据库的数据会不断被修改一样. 消息者只关心key 对应的最新的value 值. 因此我们可以开启kafka 的日志压缩功能, 服务端会在后台启动Cleaner 线程, 定期将相同的key 进行合并, 只保留最近的value值, 日志的压缩原理是: 磁盘存储的性能问题磁盘存储的性能优化​ 我们现在大部分企业仍然使用的是机械结构的磁盘, 如果把消息以随机的方式写入到磁盘,那么首先磁盘要做的就是寻址, 也就是定位到数据所在的物理地址, 在磁盘上就要找到对应的柱面、磁头以及对应的扇区; 这个过程相对于内存来说会消耗大量的时间. 为了规避随机读写带来的时间消耗, Kafka 采用顺序写的方式存储数据. 即使是这样, 但是频繁的io操作仍然会造成磁盘的性能瓶颈. 零拷贝消息从发送到落地保存, Broker 维护的消息日志本身就是文件目录, 每个文件都是二进制保存, 生产者和消费者使用相同的格式来出处理. 在消费者获取消息时,服务器先从磁盘读取数据到内存, 然后把内存中是数据原封不动的通过socket 发送给消费者。虽然这个操作描述起来很简单, 但实际上经历了很多步骤. 操作系统将数据从磁盘读入到内核空间的页缓存. 应用程序将数据从内核空间读入到用户空间缓存中. 应用程序将数据写回到内核空间到socket 缓存中. 操作系统将数据从socket 缓存区复制到网卡缓存区, 以便将数据经网络发出. 通过”零拷贝”技术, 可以去掉这些没必须的数据复制操作,同时也会减少上下文切换次数. 现在的linux 操作系统提供一个优化的代码路径, 用于将数据从页缓存传输到socket ; 在linux 中, 是通过sendfile 系统调用来完成。 Java 提供了访问这个系统调用的方法 FileChannel.transferTo API. 使用 sendfile , 只需要一次拷贝就行, 允许操作系统将数据直接从页缓存发送到网络上, 所以在这个优化的路径中, 只有最后一步将数据拷贝到网卡缓存中是需要的. 页缓存页缓存是操作系统实现的一种主要的磁盘缓存, 但凡涉及到缓存的, 基本都是为了提升io性能, 所以页缓存是用来减少磁盘io操作的. 磁盘高速缓存有两个重要因素: 第一,访问磁盘的速度要远低于访问内存的速度, 若从处理器L1和L2 高速缓存访问速度更快. 第二, 数据一旦被访问, 就有可能短时间内再次被访问。 正是由于基于访问内存比磁盘块的多， 所以磁盘的内存缓存将给系统存储性能带来质的飞跃. 当一个进程准备读取磁盘上的文件内容时,操作系统会先查看待读取的数据所在的页(page)是否在页缓存(pagecache)中, 如果存在(命中)则直接返回数据, 从而避免了对物理磁盘的io操作 ;如果没有命中, 则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存, 之后再将数据返回给进程. ​ 同样, 如果一个进程需要将数据写入磁盘, 那么操作系统也会检测数据对应的页是否在页缓存, 如果不存在, 则会先在页缓存中添加相应的页, 最后将数据写入对应的页。被修改过后的页也就变成了脏页, 操作系统会在合适的时间把脏页中的数据写入磁盘,保证数据的一致性. ​ Kafka 中大量使用了页缓存, 这是kafka 实现高吞吐量的重要因素之一。虽然消息都是先被写入页缓存,然后由操作系统负责具体的刷盘任务,但是kafka 中同样提供了同步刷盘以及间断性强制刷盘(fsync),可以通过log.flush.interval.messages 和 log.flush.interval.ms参数来控制. 同步刷盘能够保证消息的可靠性, 避免因为宕机导致页缓存数据还未完成同步时造成的数据丢失, 但是实际使用上, 我们没必要去考虑这样的因素以及这种问题带来的损失, 消息可靠性可以由多副本机制来解决. 同步刷盘会带来性能的影响, 刷盘的操作由操作系统去完成即可. Kafka 消息的可靠性没有一个中间件能够做到百分之百的完全可靠, 可靠性更多的还是基于几个9的衡量标准. 比如4个9、5个9.软件系统的可靠性只能无限的去接近100%, 但不可能达到100%. 所以kafka 如何实现最大可能的可靠性呢? 分区副本,你可以创建更多的分区来提供可靠性, 但是分区数过多也会带来性能上的开销. 一般来说, 3个副本就能满足大部分场景的可靠性要求. acks, 生产者发送消息的可靠性. 也就是我要保证这个消息一定是到了broker 并且完成了多副本的持久化, 但这种要求也会带来性能上的开销. 它由几个可选项: 1,生产者把消息发送到leader 副本, leader 副本在成功写入到本地日志之后就告诉生产者消息提交成功,但是如果ISR 集合中的follower 副本还没来得及同步leader 副本的消息, leader 挂了之后, 就会造成消息的丢失. -1 ,消息不仅仅写入到了leader 副本, 并且还被ISR集合中所有副本同步完成之后才告诉生产者已经提交成功,这个时候即使leader挂了也不会造成数据丢失. 0, 表示producer 不需要等待broker 的消息确认, 这个选项时延最小但同时风险最大(因为当server 宕机时, 数据将会丢失) 保障消息到了broker 之后, 消费者也需要有一定的保证, 因为消费者也可能出现某些问题导致消息没有消费到. enable.auto.commit 默认为true, 也就是自动提交offset. 自动提交是批量执行的, 有一个时间窗口, 这种方式会带来重复提交或者消息丢失的问题. 所以对于高可靠性要求的程序, 需要使用手动提交. 对于高可靠性要求的应用来说, 宁愿重复消费也不应该因为消费异常而导致消息丢失.","categories":[{"name":"kafka","slug":"kafka","permalink":"https://rainsoil.github.io/categories/kafka/"},{"name":"微服务","slug":"kafka/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"kafka/微服务/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"kafka","slug":"kafka/微服务/微服务/kafka","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/kafka/"}],"tags":[]},{"title":"微服务治理之Apache Dubbo 的基本认识","slug":"微服务/dubbo/微服务治理之Apache Dubbo 的基本认识","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/wei-fu-wu-zhi-li-zhi-apache-dubbo-de-ji-ben-ren-shi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/wei-fu-wu-zhi-li-zhi-apache-dubbo-de-ji-ben-ren-shi/","excerpt":"","text":"微服务治理之Apache Dubbo 的基本认识为什么要使用dubbo远程通信背景技术架构的发展从单体到分布式，是一种顺势而为的架构演进,也是一种被逼无奈的技术变革. 架构的复杂度能够体现公司的业务的复杂度,也能从侧面体现公司的产品的发展势头是向上的. 和传统的单体架构相比,分布式多了一个远程服务之间的通信,不管是soa还是微服务,他们本质上都是对于业务服务的提炼和复用. 那么远程服务之间的调用才是实现分布式的关键因素. 而在远程通信这个领域, 其实有很多的技术,比如JAVA 的RMI、webService、Hessian 、Dubbo、Thrift 等RPC 框架. 现在我们接触的比较多的应该就是RPC 框架Dubbo 以及应用协议Http. 其实每一个技术都是在某一个阶段产生它的价值,随着架构的变化以及需求的变化, 技术的解决方案也在变. 我们知道RPC 的底层原理, 服务与服务之间的调用无非就是跨进程通信而已. 我们可以使用socket 来实现通信,也可以使用nio来实现高性能通信. 我们不用这些开源的RPC 框架, 也可以完成通信的过程. 但是为什么要用现成的框架呢? 原因是: 如果我们自己去开发一个网络通信,需要考虑到: 底层网络通信协议的处理 序列化和反序列化的处理工作. 但是这些工作本身应该是通用的, 应该是一个中间件服务. 为整个公司提供远程通信的服务. 而不应该由业务开发人员来自己实现, 所以才有了这样的rpc框架，使得我们调用远程方法的时候就想调用本地方法那么简单,不需要关心底层通信逻辑. 大规模化服务对于服务治理的要求我认为到目前为止, 还只是满足了通信的基本需求, 但是当企业开始大规模的服务化以后, 远程通信带来的弊端就越来越明显了,比如说: 服务链路变长, 如何实现对服务链路的跟踪和监控. 服务的大规模集群使得服务之间需要依赖第三方注册中心来解决服务的发现和服务的感知问题. 服务通信之间的异常, 需要有一种保护机制防止一个节点故障引发大规模的系统故障, 所以要有容错机制. 服务大规模集群会使得客户端需要引负载均衡机制来实现转发. 而这些对于服务治理的要求, 传统的PRC技术在这样的场景中显得有点力不从心, 因为很多的企业开始研发自己的PRC 框架, 比如阿里的HFS、Dubbo;京东的JSF框架、当当的dubbox 、新浪的motan、蚂蚁金服的sofa等. 有技术输出能力的公司,都会研发适合自己场景的rpc框架, 要么从0带1开发, 要么是基于现有的思路结合公司的业务进行改造 . 而没有技术输出能力的公司, 遇到服务治理的需求, 会优先选择哪些比较成熟的开源框架,而Dubbo 就是其中的一个. duboo 主要是一个分布式服务治理解决方案, 那么什么是服务治理呢? 服务治理主要是针对大规模服务化以后, 服务之间的路由、负载均衡、容错机制、服务降级这些问题的解决方案, 而Dubbo 实现的不仅仅是远程通信, 并且还解决了服务路由、负载、降级、容错等功能. dubbo 的发展历史Dubbo 是阿里内部使用的一个分布式服务治理框架,2012年开源, 因为Dubbo 在公司内部经过了很多的验证相对来说比较成熟,所以在很短的时间内就被很多互联网公司使用, 再加上阿里出来的很多技术大牛进入各个创业公司担仁技术架构后,都以Dubbo 作为主推的RPC框架使得dubbo 很快成为了很多互联网公司的首要选择. 并且很多公司在应用dubbo时, 会基于自身业务特性进行优化和改进, 所以也衍生了很多的把本. 比如京东的JSF、比如新浪的Motan、比如当当的dubbox. 在2014年10月份, dubbo 停止了维护, 在后来的2017年的9月份, 阿里宣布重启dubbo, 并且对于dubbo 做好了长期投入的准备,并且在这段时间内dubbo 进行了非常多的更新,目前的版本已经达到了2.7 . 2018年1月8号, Dubbo 创始人之一梁飞在Dubbo 交流群里透漏了Dubbo 3.0 正在动工的消息, Dubbo 3.0 内核于Dubbo 2.0 完全不同, 但兼容Dubbo 2.0 。Dubbo 3.0 将支持可选Service Mesh. 2018年2月份, Dubbo 捐给了Apache. 另外, 阿里巴巴对于Spring Cloud Alibaba 生态的完善, 以及Spring Cloud 团队对于 alibaba 整个服务治理生态的支持, 所以Dubbo 未来仍然是国内绝大部分公司的首要选择. Dubbo 的基本使用.我们基于dubbo 的最新版本2.7 来开始讲解, 首先还是基于一个demo 使用dubbo 完成基本的远程通信 创建三个项目, 一个server, 一个client,最后一个对外提供的api 项目 接口项目我们在接口项目里面编写一个api类, 作为对外提供的接口 package com.dubbo.simple; /** * @author luyanan * @since 2019/11/20 * &lt;p>用户api&lt;/p> **/ public interface UserApi &amp;#123; String info(String id); &amp;#125; 服务端项目添加 dubbo、logback 和 上面我们编写的api 项目的jar 依赖 pom jar 依赖 &lt;dependency> &lt;groupId>com.dubbo.simple&lt;/groupId> &lt;artifactId>dubbo-simple-api&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.dubbo&lt;/groupId> &lt;artifactId>dubbo&lt;/artifactId> &lt;version>2.7.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.slf4j&lt;/groupId> &lt;artifactId>slf4j-api&lt;/artifactId> &lt;version>1.7.29&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>ch.qos.logback&lt;/groupId> &lt;artifactId>logback-classic&lt;/artifactId> &lt;version>1.2.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactId>junit&lt;/artifactId> &lt;version>4.11&lt;/version> &lt;scope>test&lt;/scope> &lt;/dependency> 接下来我们实现UserApi,并且配置dubbo 相关的东西 接口实现package com.dubbo.simple; /** * @author luyanan * @since 2019/11/20 * &lt;p>接口实现&lt;/p> **/ public class UserApiImpl implements UserApi &amp;#123; @Override public String info(String id) &amp;#123; return \"张三:\" + id; &amp;#125; &amp;#125; 创建配置文件发布服务在resulrces/META-INF/spring 下创建 application.xml 文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"> &lt;!-- 提供方应用信息,用于计算依赖关系--> &lt;dubbo:application name=\"dubbo-simple-server\"/> &lt;!-- 使用multicast 广播注册中心暴露服务地址 --> &lt;dubbo:registry address=\"N/A\"/> &lt;!-- 用dubbo 协议在20880 端口暴露服务 --> &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/> &lt;!-- 声明需要暴露的服务接口 --> &lt;dubbo:service interface=\"com.dubbo.simple.UserApi\" ref=\"userApi\"/> &lt;!-- 和本地bean 一样实现服务 --> &lt;bean id=\"userApi\" class=\"com.dubbo.simple.UserApiImpl\"/> &lt;/beans> 添加日志支持 logback.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;configuration> &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"> &lt;pattern>%date&amp;#123;ISO8601&amp;#125; %-5level [%thread] %logger&amp;#123;32&amp;#125; - %message%n&lt;/pattern> &lt;/layout> &lt;/appender> &lt;root> &lt;level value=\"DEBUG\"/> &lt;appender-ref ref=\"STDOUT\"/> &lt;/root> &lt;/configuration> 启动服务 Main.main(args); 客户端服务添加配置文件在resources 下 创建 application.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"> &lt;!-- 提供方应用信息,用于计算依赖关系--> &lt;dubbo:application name=\"dubbo-simple-server\"/> &lt;!-- 使用multicast 广播注册中心暴露服务地址 --> &lt;dubbo:registry address=\"N/A\"/> &lt;dubbo:reference interface=\"com.dubbo.simple.UserApi\" id=\"userApi\" url=\"dubbo://192.168.86.1:20880/com.dubbo.simple.UserApi\"/> &lt;/beans> 其中 , dubbo:reference 中的url 地址就是 userApi 接口暴露出来的地址，我们可以在server 端启动的时候从日志中找出. 启动clientpublic class App &amp;#123; public static void main(String[] args) &amp;#123; ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(new String[]&amp;#123;\"application.xml\"&amp;#125;); UserApi userApi = applicationContext.getBean(UserApi.class); System.out.println(userApi.info(\"111\")); &amp;#125; &amp;#125; 运行之后, 我们就可以看到 张三:111 关于DubboMain 启动的真相我们刚刚使用 Main.main(args); 来启动dubbo 服务, 到底是如何实现的呢? 正常情况下. 我们会认为服务的发布, 需要tomcat或者jetty 这类的容器支持, 但是只用dubbo 后, 我们并不需要这样重的容器去支持, 同时也会增加复杂性和浪费资源,Dubbo 提供了几种容器让我们去启动和发布服务. 容器类型： Spring Container : 自动加载 META-INF/spring 目录下的所有spring 配置. logback Container: 自动装配 logback 日志 Log4j Container: 自动配置log4j 的配置 Dubbo 提供了一个Main.main 快速启动相应的容器, 默认情况下, 只会启动spring 容器. 原理分析默认情况下, spring 容器本质上就是加载spring ioc 容器, 然后启动一个netty 服务实现服务的发布, 下面是spring 容器启动的代码: public void start() &amp;#123; String configPath = ConfigUtils.getProperty(\"dubbo.spring.config\"); if (StringUtils.isEmpty(configPath)) &amp;#123; configPath = \"classpath*:META-INF/spring/*.xml\"; &amp;#125; context = new ClassPathXmlApplicationContext(configPath.split(\"[,\\\\s]+\"), false); context.refresh(); context.start(); &amp;#125; 基于注册中心的Dubbo 服务作为主流的服务治理组件, Dubbo 提供了很多丰富的功能, 那么最根本的就是要解决大规模集群之后的服务注册和发现的问题, 而dubbo 中对于注册中心这块是使用zookeeper 来支持的, 当前在目前最新的版本中, dubbo 能支持的注册中心有: consul、etcd、nacos、sofa、zookeeper、redis、multicast. 使用zookeeper 作为注册中心pom修改在服务端和客户端代码里面添加zookeeper 的jar &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-recipes&lt;/artifactId> &lt;version>4.0.0&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-framework&lt;/artifactId> &lt;version>4.0.0&lt;/version> &lt;/dependency> 服务端修改修改application.xml 配置文件 &lt;dubbo:registry address=&quot;zookeeper://192.168.86.128:2181&quot;/&gt;&lt;!--如果是集群, 则配置的方式是 address=”zookeeper://ip:host?backup=ip:host,ip:host” --&gt; 客户端修改修改application.xml 配置文件 &lt;dubbo:registry address=\"zookeeper://192.168.86.128:2181\"/> &lt;dubbo:reference interface=\"com.dubbo.simple.UserApi\" id=\"userApi\"/> dubbo 集成 zookeeper 的实现原理 dubbo 缓存配置中心在消费端的配置文件中指定如下路径 &lt;dubbo:registry address=&quot;zookeeper://192.168.86.128:2181&quot; file=&quot;d:/dubbo-server&quot;/&gt; 多注册中心支持Dubbo 中可以支持多注册中心, 有的时候， 客户端需要用调用的远程服务不在同一个注册中心, 那么客户端就需要配置多个注册中心来访问, 演示一个案例. 配置多个注册中心 &lt;dubbo:registry id=\"reg1\" address=\"zookeeper://192.168.86.128:2181\"/> &lt;dubbo:registry id=\"reg2\" address=\"zookeeper://192.168.86.129:2181\"/> 将服务注册到不同的注册中心通过registry 设置注册中心的id &lt;dubbo:service interface=\"com.dubbo.simple.UserApi\" ref=\"userApi\" register=\"reg1\"/> 消费端配置多个注册中心, 实现代码和服务端一样. 注册中心的其他支持 当设置 &lt;dubbo:registry check=&quot;false&quot;/&gt; 时, 记录失败注册和订阅请求, 后台定时重试. 可通过 &lt;dubbo:registry username=&quot;admin&quot; password=&quot;1234&quot;/&gt; 设置zookeeper 登录信息 可通过 &lt;dubbo:registry group=&quot;dubbo&quot;/&gt; 设置zookeeper 的根节点, 默认使用dubbo 作为dubbo 服务注册的namespace Dubbo 仅仅是一个RPC框架到目前为止, 我么了解到Dubbo 的核心功能, 提供服务注册和服务发现, 以及基于Dubbo协议的远程通信, 我想, 大家以后不仅仅只认为Dubbo 是一个RPC 框架吧。 Dubbo 从另一个方面来看也可以认为是一个服务治理生态, 从目前已经讲过的内容上可以看到. Dubbo 可以支持市面上主流的注册中心 Dubbo 提供了 Container 的支持, 默认提供了3种 Container ,我们还可以自行扩展. Dubbo 对于RPC 通信协议的支持, 不仅仅是原生的Dubbo协议, 它还围绕着rmi、hessian、http、webservice、thrift、rest. 有了多协议的支持,使得其他rpc 框架的应用程序可以快速的切入到dubbo 生态中。同时, 对于多协议的支持, 是的不同应用场景的服务, 可以选择合适的协议来发布服务, 并不一定使用dubbo 提供的长连接方式. 集成 webservice 协议webservice 是一个短连接 并且是基于http协议的方式来实现的rpc 框架 jar 依赖&lt;dependency> &lt;groupId>org.apache.cxf&lt;/groupId> &lt;artifactId>cxf-rt-frontend-simple&lt;/artifactId> &lt;version>3.3.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.cxf&lt;/groupId> &lt;artifactId>cxf-rt-transports-http&lt;/artifactId> &lt;version>3.3.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.eclipse.jetty&lt;/groupId> &lt;artifactId>jetty-server&lt;/artifactId> &lt;version>9.4.19.v20190610&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.eclipse.jetty&lt;/groupId> &lt;artifactId>jetty-servlet&lt;/artifactId> &lt;version>9.4.19.v20190610&lt;/version> &lt;/dependency> 修改application.xml &lt;dubbo:protocol name=\"webservice\" port=\"8080\" server=\"jetty\"/> &lt;!-- 声明需要暴露的服务接口 --> &lt;dubbo:service interface=\"com.dubbo.simple.UserApi\" ref=\"userApi\" protocol=\"dubbo,webservice\"/> 添加多协议支持, 一个服务可以发布多种协议的支持,也可以实现不同服务发布不同的协议 启动服务之后, 可以使用 http://localhost:8080/com.dubbo.simple.UserApi?wsdl 来获取到 webservice 的wsdl 描述文档 客户端使用webservice 请求服务 客户端的配置jar依赖 配置多个协议支持, 实现方式和服务端一样. Dubbo 对于REST 协议的支持Dubbo 中的REST(表述性资源转移)支持, 是基于 于 JAX-RS2.0(Java API for RESTful Web Services) 来实现的. REST 是一种架构风格, 简单来说就是对于api 接口的约束, 基于URL 定位资源, 使用http 动词(GET/POST/PUT/DELETE) 来描述操作. JAX-RS协议说明REST 很早就提出来了, 在早期的开发人员为了实现REST, 会使用各种工具来实现, 比如Servlets 就经常用来开发RESTful 的程序,随着REST 被越来越多的开发人员采用, 所以 JCP(Java community process) 提出了 JAX-RS 规范, 并且提供了一种新的基于注解的方式来开发RESTful 服务. 有了这样的一个规范, 使得开发人员不需要通讯层的东西, 只需要关注资源以及数据对象. JAX-RS 规范的实现有：Apache CXF、Jersey(由 Sun 公司提供的 JAX-RS 的 参考实现)、RESTEasy( jboss 实现)等。 而Dubbo 里面实现的REST 就是基于JBoss 提供的 RESTEasy 框架来实现的, Spring MVC 中的RESTful 实现我们用的比较多, 它也是 JAX-RS 规范的一种实现. jar 依赖&lt;dependency> &lt;groupId>org.jboss.resteasy&lt;/groupId> &lt;artifactId>resteasy-jaxrs&lt;/artifactId> &lt;version>3.8.0.Final&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jboss.resteasy&lt;/groupId> &lt;artifactId>resteasy-client&lt;/artifactId> &lt;version>3.8.0.Final&lt;/version> &lt;/dependency> 添加新的协议支持 &lt;dubbo:protocol name=”rest” port=”8080” server=”jetty”/&gt; 提供新的服务@Path(“user”): 指定访问UserApi 的url 的相对路径是 /user,即http://localhost:8080/user @Path(“info/{id}”) 指定访问info 方法的url 相对路径为/info,再结合上一个@Path 为 UserApi 指定的路径, 则调用UserApi.info() 的完整路径为 http://localhost:8080/user/info @GET: 指定访问info 方法用HTTP GET 方法 @Path(\"user\") public interface UserApi &amp;#123; @GET @Path(\"info/&amp;#123;id&amp;#125;\") String info(@PathParam(\"id\") String id); &amp;#125; 客户端配置 &lt;dubbo:reference interface=&quot;com.dubbo.simple.UserApi&quot; id=&quot;userApi&quot; protocol=&quot;rest&quot;/&gt; 在服务接口获取上下文的方式既然是http 协议的REST 接口, 那么我们想要获取请求的上下文, 怎么做呢? 第一种, HttpServletRequest request=(HttpServletRequest)RpcContext.getContext().getRequest(); 通过注解的方式 @Path(\"user\") public interface UserApi &amp;#123; @GET @Path(\"info/&amp;#123;id&amp;#125;\") String info(@PathParam(\"id\") String id, @Context HttpServletRequest servletRequest); &amp;#125; Dubbo 监控平台的安装Dubbo 的监控平台也做了更新, 不过目前的功能还没有完善, 在这个网站上 下载 Dubbo-Admin 的包. https://github.com/apache/dubbo-admin 修改 dubbo-admin-server/src/main/resources/application.properties 中的配置信息 mvn clean package 进行构建 mvn –projects dubbo-admin-server spring-boot:run 访问 localhost:808 Dubbo 的终端操作方法.Dubbo 中提供了一种基于终端操作的方法来实现服务治理. 使用 telnet localhost 20880 连接到服务对应的端口. 常见命令ls ls: 显示服务列表 ls -l: 显示服务详细信息列表 ls XxxService: 显示服务的方法列表 ls -l XxxService: 显示服务的方法详细信息列表 ps ps: 显示服务端口列表 ps -l: 显示服务地址列表 ps 20880: 显示端口上的连接信息 ps -l 20880: 显示端口上的连接详细信息 cd cd XxxService: 改变缺省服务，当设置了缺省服务，凡是需要输入服务名作 为参数的命令，都可以省略服务参数 cd /: 取消缺省服务 pwd pwd: 显示当前缺省服务 count count XxxService: 统计 1 次服务任意方法的调用情况 count XxxService 10: 统计 10 次服务任意方法的调用情况 count XxxService xxxMethod: 统计 1 次服务方法的调用情况 count XxxService xxxMethod 10: 统计 10 次服务方法的调用情况","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"Dubbo性能调优","slug":"微服务/dubbo/Dubbo性能调优","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/dubbo-xing-neng-diao-you/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/dubbo-xing-neng-diao-you/","excerpt":"","text":"Dubbo 性能调优常用的性能调优参数 参数名 作用范围 默认值 说明 备注 threads provider 200 业务处理线程大小 iothreads provider cpu个数+1 io线程池大小 queues provider 0 线程池队列大小,当线程池满的时候, 排队等待执行的队列大小, 建议不要设置，当线程池满时,应该立即失败,重试其他服务提供机器,而不是排队,除非有特殊的要求 coeections consumer 0 对每个提供者的最大连接数,rmi、http、hessian等短连接协议表示限制连接数, Dubbo 等长连接协议表示建立的长连接个数 Dubbo协议默认共享一个长连接 actives consumer 0 每个服务消费者每个服务每个方法最大并发调用数 0 表示不限制 accepts provider 0 服务提供方最大可接受连接数 0 表示不限制 executes provider 0 服务提供者每服务每方法最大可并行执行请求数 0 表示不限制 ​ 每个参数的作用 当concumer 发起一个请求时, 首先经过active limit(参数actives) 进行方法级别的限制, 其实现方式为CHM 中存放计数器(AtomicInteger), 请求时加1, 请求完成(包括异常)减1, 如果超过 actives 则等待有其他请求完后重试或者超时后失败; 从多个连接（connections ） 中选择一个连接发送数据, 对于默认的netty实现来说, 由于可以复用连接, 默认一个连接就可以, 不过如果你在压测, 且只有一个consumer、一个provider ,此时适当的加大 connections 却很少能够增强网络传输能力. 但是线上业务由于有多个 consumer多个provider , 因此不建议增加 connections参数. 连接到达provider时(如dubbo初次连接),首先会判断总连接是否超限(acceps),超过限制连接将被拒绝. 连接成功后, 具体的请求交给 io thread处理, io threads 虽然是处理数据的读写, 但io部分为异步, 更多的消耗的是cpu, 因此iothreads 默认cpu个数+1 是比较合理的设置, 不建议调整此参数. 数据读取并反序列化后，交给业务线程池处理,默认情况下线程池为 fixed, 且排队队列为0(queues),这种情况下,最大并发等于业务线程池大小(threads), 如果希望有请求的堆积能力, 可以调整queues 参数, 如果希望快速失败由其他节点处理(官方推荐方式), 则不修改queues, 只调整 threads. execute limit （参数 executes）是方法级别的并发限制, 原理和 activies 类似,只是少了等待的过程, 受限制后立即失败.","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"RabbitMQ工作模型与java编程(1)","slug":"微服务/rabbitMQ/RabbitMQ工作模型与java编程(1)","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/rabbitmq/rabbitmq-gong-zuo-mo-xing-yu-java-bian-cheng-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rabbitmq/rabbitmq-gong-zuo-mo-xing-yu-java-bian-cheng-1/","excerpt":"","text":"RabbitMQ工作模型与java编程1. MQ入门1.1 MQ的诞生历程我们要去用MQ, 先来了解一下MQ是怎么诞生的,这样对于它解决了什么问题理解会更加深刻.大家知不知道世界上第一个MQ叫什么名字,是什么时候诞生的? ​ 1983年的时候, 有个在MIT工作的印度小伙伴突发奇想,以前我们的软件相互通信,都是点对点的,而且要实现相同的协议, 能不能有一种专门用来通信的中间件,就想主板(BUS)一样,把不同的软件集成起来呢? 于是它搞了一家公司(Tekneron),开发了世界上第一个消息队列软件The Information Bus(TIB). 最开始的时候, 它被高盛这些公司用在了金融交易里面。 因为TIB 实现了发布订阅(Publish/Subscrbe)模型, 信息的生产者和消费者完全解耦,这个特性引起了电信行业特别是新闻机构的注意. 1994年路透社收购了Teknekron. TIB 的成功马上引起了业界大佬IBM的注意, 他们研发了自己的IBM MQ(IBM Wesphere). 后面微软也加入了这场战斗, 研发了MSMQ. 这个时候,每个厂商的产品是孤立的. 大家都有自己的技术壁垒. 比如一个应用订阅了IBM MQ的消息, 如果又要订阅MSMQ的消息, 因为协议、API不同,又要重复去实现,为什么大家都不愿意去创建标准接口,来实现不同的MQ产品的互通呢? 跟现在微信里面不能打开淘宝页面是一个道理(商业竞争). ​ JDBC 协议大家非常熟悉吧? J2EE 制定了JDBC的规范,那么各个数据库厂商自己去实现协议, 提供jar, 在java里面即可以使用相同的API做操作不同的数据库了. MQ产品的问题也是一样的，2001年的时候,SUM公司发布了JMS 规范,它想要在各大厂商的MQ上面统一包装一层java 的规范,大家都只需要针对API变成就可以了,不需要关注使用了什么样的消息中间件,只要选择合适的MQ驱动.但是JMS 只适用于java语言,它是跟语言绑定的,没有从根本上解决这个问题(只是一个API)。 ​ 所以在06年的时候,AMQP规范发布了.它是跨语言和跨平台的, 真正的促进了消息队列的繁荣发展. ​ 07年的时候, Rabbit技术公司基于AMQP 开发了BabbitMQ 1.0.为什么要用Erlang语言呢? 因为Erlang 是作者Matthias 擅长的开发语言. 第二个家就是Erlang是为了电话交换机编写的语言, 天生适合分布式和高并发. ​ 为什么要取Rabbit Technologies 这个名字呢? 因为兔子跑得快，而且繁殖起来很疯狂. ​ 从最开始用于金融行业里面,现在RabbitMQ 已经在世界各地的公司中遍地开花. 国内的绝大部分大厂都在用BabbitMQ，包括头条、美团、滴滴、去哪儿、艺龙、淘宝等. 1.1.2 什么是MQ(Message Queue) MQ的本质是什么呢? ​ 消息队列,又叫消息中间件.是指用高效可靠的消息传递机制进行与平台无关的数据交流,并基于数据通信来进行分布式系统的集成. 通过提供消息传递和消息队列模型,可以在分布式坏境下扩展进程的通信(维基百科). ​ 基于以上的描述(MQ是用来解决通信的问题), 我们知道, MQ的几个主要特点: 是一个独立运行的服务。生产者发送消息,消费者接受消息, 需要先跟服务器建立连接. 采用队列作为数据结构,有先进先出的特点. 具有发布订阅的模型,消费者可以获取自己需要的消息. ​ ​ 我们可以把RabbitMQ比喻成邮局和邮差, 它是用来帮我们存储和转发消息的. 问题: 如果仅仅是解决消息消费的问题, java里面已经有了那么多的队列的实现,为什么不用他们了呢? 这个问题的答案就跟有了HashMap 之后, 为什么还要Redis 作缓存是一样的. 因为Queue 不能跨进程, 不能在分布系统中使用,并且没有持久化机制等等. 1.1.3 为什么要使用MQ呢?​ 我们已经知道MQ是什么了, 那在什么地方可以用MQ,或者说，为什么要使用MQ呢? 这是一个很常见的面试题,如果你的项目中使用了MQ,还不知道这个问题的答案,说明你自己从来没有思考总结过,因为这个项目是别人架构设计的,你可能只是做了一些维护的工作.有一天你自己去做架构的时候, 你搞一个MQ进去,理由就是以前的项目也是这么干的,这就很危险了. 1.1.3.1 实现异步通信​ 同步的通信的什么样呢? 发出一个调用请求后, 在没有得到结果之前, 就不返回. 由调用者主动等待这个调用的结果. 而异步是相反的, 调用在发出之后, 这个调用就直接返回了, 所以没有返回结果. 也就是说, 当一个异步过程调用发出后, 调用者不会马上得到结果.而是在调用发出后, 被调用者通过状态, 通知来通知调用者,或通过回调函数来处理这个调用. ​ 举个例子: 大家都用过手机银行的跨行转账功能。大家用APP的转账功能 的时候, 有一个实时模式, 有一个非实时模式. ​ 实时转账实际上是异步通信, 因为这里面涉及的机构比较多, 调用链路比较长, 本行做了一系列处理之后, 转发给银联或者人民银行的支付系统,再转发给接受行, 接受行处理以后再原路返回. ​ 所以转账以后会有一行小字提示: 具体到账时间以对方行处理为准. 也就是说转出行只保证这个转账的消息发出。那为什么到账时间又那么快呢? 很多时间我们转账之后, 不用几秒钟对方就收到了,是因为大部分的MQ都有一个低延迟的特性, 能够在短时间内处理非常多的消息. ​ 很多理财软件体现也是一样的, 先提交申请, 到账时间不定. 这个是用MQ实现系统间异步通信的一个场景. 1.1.3.2 实现系统解耦​ 第二个主要的功能是用来实现系统解耦.既然说到解耦,那我们先来了解一下耦合的概念. ​ 耦合是系统内部或者系统之间存在相互作用,相互影响和相互依赖. ​ 在我们的分布式系统中, 一个业务流程涉及到多个系统的时候, 他们之间就会形成一个依赖关系. ​ 比如我们以12306网站退票为例,在传统的通信方式中, 订单系统发生了退货的动作, 那么要依次调用所有下游系统的API,比如调用库存系统的API恢复库存,因为这张火车票还要释放出去给其他乘客购买;调用支付系统的API,不管是支付宝还是微信还是银行卡,要把手续费扣掉之后, 原路返回给消费者. 调用通知系统API通知用户退货成功. // 伪代码 public void returnGoods()&amp;#123; stockService.updateInventory (); payService.refund(); noticeService.notice(); &amp;#125; ​ 这个过程是串行执行的, 如果在恢复库存的时候发生了异常, 那么后面的代码都不会执行. 由于这一系列的动作, 恢复库存、资金退还、发送通知,本质上没有一个严格的先后顺序,也没有直接的依赖关系, 也就是说, 只要用户提交了退货的请求, 后面的这些动作都是要完成的.库存有没有恢复成功, 不影响资金的退还和发送通知. ​ 如果把串行改成并行, 我们有什么思路? ​ (多线程） 多线程或者线程池是可以实现的, 但是每一个需要并行执行的地方都引入线程,又会带来线程或者线程池的管理问题. ​ 所以, 这种情况下, 我们可以引入MQ实现系统之间依赖关系的解耦合. ​ 引入MQ后: ​ ​ 订单系统只需要把退货的消息发送到消息队列上, 由各个下游的业务系统自己创建队列, 然后监听队列消费消息. ​ 在这种情况下,订单系统里面不需要配置其他系统的IP、端口号、接口地址了. 因为它不需要关心消费者在网络上的什么位置, 所以下游系统该IP没有任何影响. 甚至不需要关系消费者有没有消费成功, 它只需要把消费者发到消息队列的服务器上就可以了. ​ 这样, 我们就实现了系统之间依赖关系的解耦. 1.1.3.3 实现流量削峰​ 第三个主要的功能是,实现流量削峰. 在很多的电商系统里面, 有一个瞬间流量达到峰值的情况, 比如京东的618、淘宝的双11、小米抢购.普通的硬件服务器肯定支撑不了这种百万或者千万级别的并发量, 就像2012年的小米一样, 动不动就服务器崩溃. ​ 如果通过堆硬件的方式去解决, 那么在流量峰值过去之后就会出现巨大的资源浪费, 那要怎么办呢? 如果说要保护我们的应用服务器和数据库, 限流也是可以的,但是这样又会导致订单的丢失, 没有达到我们的目的. ​ 为了解决这个问题, 我们就可以引入MQ,MQ既然的队列, 一定有队列特性，我们知道队列的特定是什么? 先入先出(FIFO) ​ 这样我们就可以先把所有的流量都承接下来, 转换成MQ消息发送到消息队列服务器上, 业务层就可以根据自己的消费速率去处理这些消息,处理完成后再返回结果.就像我们在火车站排队一样, 大家只能一个一个单独买票,不会因为人多就导致售票员忙不过来. 如果要处理的快一点, 大不了多开几个窗口(增加几个消费者). ​ 这个是我们利用MQ实现流量削峰的一个案例. 总结起来: 对于数据量大或者处理耗时长的操作, 我们可以引入MQ实现异步通信, 减少客户端的等待, 提升响应速度. 对于改动影响大的系统之间, 可以引入MQ实现解耦, 减少系统之间的直接依赖. 对于会出现瞬间的流量峰值的系统, 我们可以引入MQ实现流量削峰, 达到保护应用和数据库的目的. ​ 所以对于一些特定的业务场景, MQ对于优化我们的系统还是有很大的帮助的, 那么大家想一下, 把传统的RPC通信改成MQ通信会不会带来一些问题呢? 1.1.4 实现消息队列带来的问题​ 系统可用性降低: 原来是两个节点的通信, 现在还需要独立运行一个服务,如果MQ 服务器或者通信网络出现一些问题, 就会导致请求失败. ​ 系统复杂度提高: 为什么说复杂, 第一个就是你必须理解相关的模型和概念,才能正确的配置和使用MQ.第二个就是使用MQ发送消息必须要考虑消息丢失和消息重复消息的问题. 一旦消费没有被正确的消费,就会带来数据一致性问题. ​ 所以我们在做系统架构的时候一定要根据实际情况来分析, 不要因为我们说了这么多MQ能解决的问题, 就盲目的引入MQ. 1.2 RabbitMQ 简介1.2.1 基本特性 官网: https://www.rabbitmq.com/getstarted.html 高可靠: RabbitMQ提供了多种多样的特性让你在可靠性和性能之间做出权衡, 包括持久化、发送应答、发布确认以及高可用性. 灵活的路由: 通过交换机(Exchange) 实现消息的灵活路由. 支持多客户端: 对主流开发语言(Python、Java、Ruby、C#、JavaScript、GO、Elixir、Objective-C、Swift等) 都有客户端实现 集群和扩展性: 多个节点组成一个逻辑的服务器, 实现负载均衡. 高可用队列: 通过镜像队列实现队列中数据的复制. 权限管理: 通过用户与虚拟机实现权限管理. 插件系统: 支持各种丰富的插件扩展,同时也支持自定义插件. 与Spring集成: Spring 对AMQP 进行了封装. 1.2.2 AMQP协议1.2.2.1 总体介绍http://www.amqp.org/sites/amqp.org/files/amqp.pdf AMQP: 高级消息队列协议, 是一个工作于应用层的协议, 最新的版本是1.0版本. ​ 除了RabbitMQ之外, AMQP的实现还有 OpenAMQ、Apache Qpid、Redhat Enterprise MRG、AMQP Infrastructure 、ØMQ、Zyre。 ​ 除了AMQP之外, RabbitMQ支持多种协议. STOMP、MQTT、HTTP 和Websocket. ​ 可以使用 WireShark 等工具对 RabbitMQ 通信的 AMQP 协议进行抓包。 1.2.2.2 工作模型由于RabbitMQ 实现了AMQP协议, 所以BabbitMQ 的工作模式也是基于AMQP 的. 理解这种图片至关重要. 1. Broker​ 我们要使用RabbitMQ 来收发消息, 必须安装一个RabbitMQ的服务, 可以安装在window上也可以安装在linux上, 默认是5672端口号。这台BabbitMQ 的服务器我们把它叫做Broker, 中文翻译是代理/中介. 因为MQ 服务器帮助我们做的事情就是存储、转发消息. 2. Connection​ 无论是生产者发送消息或者消费者接收消息, 都必须要跟broker 之间建立一个连接, 这个连接是一个TCP的长连接. 3. Channel​ 如果所有的生产者发送消息和消费者接收消息, 都直接创建和释放TCP连接的话, 对于Broker 来说肯定会造成很大的性能损耗,因为TCP 连接是非常宝贵的资源,创建和释放也要消耗时间. ​ 所有在AMQP 里面引入了Channel 的概念,它是一个虚拟的连接.我们把它翻译成通道,或者消费信道. 这样我们就可以在保持的TCP长连接里面去创建和释放Channel, 大大减少了资源消耗. 另外一个需要注意的是,Channel 是RabbitMQ 原生API里面最重要的编程接口,也就是我们定义交换机、队列、绑定关系、发送消息、消费消息,调用的都是Channel 接口上的方法. ​ https://stackoverflow.com/questions/18418936/rabbitmq-and-relationship-between-channel-and-connection 4. Queue​ 现在我们已经连接到Broker了, 可以收发消息了.在其他一些MQ里面,比如ActiviteMQ和Kafka, 我们的消息都是发送到队列上. ​ 队列是真正用来存储消息的, 是一个独立运行的进程, 有自己的数据库(Mnesia). ​ 消费者获取消息的模式有两种模式,一种是push模式, 只要生产者发到服务器上, 就马上推送到消费者. 另一个是pull模式, 消息存放在服务端, 只有消费端主动获取才能拿到消息. 消费者需要写 一个while循环不断的从队列获取消息吗? 不需要,我们可以基于事件机制,实现消费者对队列的监听. ​ 由于队列有FIFO的特性, 只有确定前一条消息被消费者接收之后, 才会把这条消息从数据库删除,继续投递下一条消息. 5. Exchange​ 在RabbitMQ 里面永远不会出现消息直接发送到队列的情况. 因为在AMQP 里面引入了交换机(Exchange) 的概念, 用来实现消息的灵活路由. ​ 交换机是一个绑定列表, 用来查找匹配的绑定关系. ​ 队列使用绑定建(Binging Key) 跟交换机建立绑定关系. ​ 生产者发送的消息需要携带路由键(Routing Key), 交换机收到消息时会会根据它保存到绑定列表,决定将消息路由到哪些与他绑定的队列上. ​ 注意: 交换机与队列、队列与消费者都是多对多的关系. 6. Vhost​ 我们每个需要实现基于RabbitMQ的异步通信系统, 都需要在服务器上创建自己要用到的交换机、队列和他们的绑定关系. 如果某个业务系统不想跟别人混用一个系统,怎么办? 再采购一台硬件服务器单独安装一个RabbitMQ 服务? 这种方式成本太高了. 在同一个硬件服务器上安装多个BabbitMQ的服务呢? 比如再运行一个5673的端口? 没有必要,因为RabbitMQ 提供了虚拟主机Vhost. ​ Vhost 除了可以提高硬件资源的利用率之外, 还可以实现资源的隔离和权限的控制.它的作用类似于编程语言中的namespace 和package,不同的Vhost 中可以有同名的Exchange 和Queue, 他们是完全透明的. ​ 这个时候,我们可以为不同的业务系统创建不同的用户(User), 然后给这些用户分给Vhost权限.比如给风控系统的用户分配风控系统的Vhost的权限, 这个用户就可以访问里面的交换机和队列. 给超级管理员分配所有Vhost 的权限. ​ 我们说到RabbitMQ 引入Exchange 是为了实现消息的灵活路由,到底有哪些路由方式呢? 1.2.2.3 路由方式直连Direct​ 队列与直连的交换机绑定,需指定一个精确的绑定键. ​ 生产者发送消息时会携带一个路由键.只有当路由键与其中的某个绑定键完全匹配的时候,这条消息才会从交换机路由到满足路由关系的此队列上. 例如: channel.basicPublish(“MY_DIRECT_EXCHANGE”,”spring”,”msg 1”); 只有第一个队列能收到消息 主题Topic队列与主图类型的交换机绑定时, 可以在绑定键中使用通配符.两个通配符: # 0个或者多个单词 * 不多不少一个单词 单词(word) 指的是用英文的点 “.” 隔开的字符. 例如 abc.def 是两个单词. 解析: 第一个队列支持路由键以 spring开头的消息路由, 后面可以有单词, 也可以没有. ​ 第二个队列支持路由键以netty 开头, 而且后面是一个单词的消息路由. ​ 第三个队列支持路由键以mysql 结尾, 而且前面是一个单词的消息路由. 例如: channel.basicPublish(“MY_TOPIC_EXCHANGE”,”spring.fjd.klj”,”msg 2”); 只有 第一个队列能收到消息。 channel.basicPublish(“MY_TOPIC_EXCHANGE”,”spring.jvm”, “msg 3”); 第 一 个队列和第三个队列能收到消息。 广播Fanout​ 主题类型的交换机与队列绑定的时候,不需要指定绑定键. 因此生产者发送消息到广播类型的交换机上, 也不需要携带路由键. 消息达到交换机的时候, 所有与之绑定了的队列, 都会收到相同的消息的副本. ​ 例如: channel.basicPublish(“MY_FANOUT_EXCHANGE”, “”, “msg 4”); 三个队列都会 收到 msg 4。 1.3 基本使用1.3.1 安装这里使用Docker 进行安装 获取镜像 #指定版本，该版本包含了web控制页面 docker pull rabbitmq:management 运行镜像 #方式一：默认guest 用户，密码也是 guest docker run -d --hostname my-rabbit --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq:management #方式二：设置用户名和密码 docker run -d --hostname my-rabbit --name rabbit -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password -p 15672:15672 -p 5672:5672 rabbitmq:manageent 访问url http://localhost:15672/ 1.3.2 Java API编程1.3.2.1 添加依赖 &lt;dependency> &lt;groupId>com.rabbitmq&lt;/groupId> &lt;artifactId>amqp-client&lt;/artifactId> &lt;version>5.6.0&lt;/version> &lt;/dependency> 1.3.2.2 生产者package com.mq.rabbit; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; import java.io.IOException; import java.util.concurrent.TimeoutException; /** * @author luyanan * @since 2020/1/8 * &lt;p>生产者&lt;/p> **/ public class MyProducer &amp;#123; /** * &lt;p>交换机&lt;/p> * * @author luyanan * @since 2020/1/8 */ private final static String EXCHANGE_NAME = \"SIMPLE_EXCHANGE\"; public static void main(String[] args) throws IOException, TimeoutException &amp;#123; ConnectionFactory factory = new ConnectionFactory(); // 连接ip factory.setHost(\"192.168.86.128\"); // 端口号 factory.setPort(5672); //定义虚拟机 factory.setVirtualHost(\"/\"); // 用户 factory.setUsername(\"guest\"); // 密码 factory.setPassword(\"guest\"); // 建立连接 Connection connection = factory.newConnection(); //创建消息通道 Channel channel = connection.createChannel(); // 发送消息 for (int i = 0; i &lt; 10; i++) &amp;#123; String msg = \"Hello World ->\" + i; // String exchange, String routingKey, BasicProperties props, byte[] body channel.basicPublish(EXCHANGE_NAME, \"test\", null, msg.getBytes()); &amp;#125; channel.close(); connection.close(); &amp;#125; &amp;#125; 1.3.2.3 消费者package com.mq.rabbit; import com.rabbitmq.client.*; import java.io.IOException; import java.util.concurrent.TimeoutException; /** * @author luyanan * @since 2020/1/8 * &lt;p>消费者&lt;/p> **/ public class MyConsumer &amp;#123; /** * &lt;p>交换机&lt;/p> * * @author luyanan * @since 2020/1/8 */ private final static String EXCHANGE_NAME = \"SIMPLE_EXCHANGE\"; /** * &lt;p>队列&lt;/p> * * @author luyanan * @since 2020/1/8 */ private final static String SIMPLE_QUEUE = \"SIMPLE_QUEUE\"; public static void main(String[] args) throws IOException, TimeoutException &amp;#123; ConnectionFactory factory = new ConnectionFactory(); // 连接ip factory.setHost(\"192.168.86.128\"); // 端口号 factory.setPort(5672); //定义虚拟机 factory.setVirtualHost(\"/\"); // 用户 factory.setUsername(\"guest\"); // 密码 factory.setPassword(\"guest\"); // 建立连接 Connection connection = factory.newConnection(); //创建消息通道 Channel channel = connection.createChannel(); // 声明交换机 // String exchange, String type, boolean durable, boolean autoDelete, Map&lt;String, Object> arguments channel.exchangeDeclare(EXCHANGE_NAME, \"direct\", false, false, null); // 声明队列 // String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object> arguments channel.queueDeclare(SIMPLE_QUEUE, false, false, false, null); System.out.println(\"waiting for message...\"); // 绑定队列和交换机 channel.queueBind(SIMPLE_QUEUE, EXCHANGE_NAME, \"test\"); // 创建消费者 Consumer consumer = new DefaultConsumer(channel) &amp;#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &amp;#123; String msg = new String(body, \"UTF-8\"); System.out.println(\"Received message : '\" + msg + \"'\"); System.out.println(\"consumerTag : \" + consumerTag); System.out.println(\"deliveryTag : \" + envelope.getDeliveryTag()); &amp;#125; &amp;#125;; while (true) &amp;#123; // 开始获取消息 channel.basicConsume(SIMPLE_QUEUE, true, consumer); &amp;#125; &amp;#125; &amp;#125; 1.3.2.4 参数详解 声明交换机 String type: 交换机的类型,direct、topic、fanout 中的一种. boolean durable: 是否持久化,代表交换机在服务器重启后是否还存在 声明队列的参数 boolean durable: 是否持久化,代表队列在服务器重启后是否还存在. boolean exclusive: 是否排他性队列. 排他性队列只能声明它的connection 中使用(可以在同一个connection的不同channel中使用),连接断开时自动删除. boolean autoDelete: 是否自动删除. 如果为true, 至少有一个消费者连接到这个队列,之后所有与这个队列连接的消费者都断开时, 队列会自动删除. Map&lt;String,Object&gt; arguments: 队列中的其他属性., 例如 属性 含义 x-message-ttl 队列中消息的存活时间, 单位是毫秒 x-expires 队列在多久没消费者访问以后会被删除 x-max-length 队列的最大消息数 x-max-length-bytes 队列的最大容量, 单位Byte x-dead-letter-exchange 队列的死信交换机 x-dead-letter-routing-key 死信交换机的路由键 x-max-priority 队列中消息的最大优先级,消息的优先级不能超过它 消息属性 BasicProperties 以下列举了一些主要的参数 参数 释义 Map&lt;String,Object&gt; headers 消息的其他自定义参数 Integer deliveryMode 2 持久化,其他: 瞬态 Integer priority 消息的优先级 String correlationId 关联ID,方便RPC相应的与请求关联 String replyTo 回调队列 String expiration TTL,消息过期时间, 单位毫秒 1.3.3 UI管理界面的使用​ RabbitMQ可以通过命令(RabbitMQ Cli)、HTTP API管理, 也可以通过可视化的界面去管理,这个网页就是managment 插件. 1.3.3.1 启用管理插件 Windows启动管理插件 cd C:\\Program Files\\RabbitMQ Server\\rabbitmq_server-3.6.6\\sbin rabbitmq-plugins.bat enable rabbitmq_management Linux 启动管理插件 cd /usr/lib/rabbitmq/bin ./rabbitmq-plugins enable rabbitmq_management 1.3.3.2 管理界面访问端口​ 默认端口号为15672, 默认用户是guest,密码是 guest ​ guest 用户默认只能在本地访问,远程用户需要创建其他的用户. 1.3.3.3 虚拟机 在Admin 选项卡中 默认的虚拟机是/,可以创建自定义的虚拟机 1.3.3.4 Linux 创建RabbitMQ 用户、权限假如创建用户 admin，密码 admin,授权访问所有的vhost firewall-cmd --permanent --add-port=15672/tcp firewall-cmd --reload rabbitmqctl add_user admin admin rabbitmqctl set_user_tags admin administrator rabbitmqctl set_permissions -p / admin \".*\" \".*\" \".*\" 2.RabbitMQ 进阶知识2.1 TTL(Time To Live)2.1.1 消息的过期时间 有两种设置方式: 通过队列属性设置消息过期时间 所有队列中的消息超过时间未被消费, 都会过期. @Bean(\"ttlQueue\") public Queue ttlQueue() &amp;#123; Map&lt;String, Object> map = new HashMap&lt;>(); // 队列中的消息未被消费10秒后过期 map.put(\"x-message-ttl\", 10000); // 队列30秒没有使用以后会被删除 map.put(\"x-expire\", 30000); return new Queue(\"TTL_QUEUE\", true, true, false, map); &amp;#125; 设置单条消息的过期时间 在发送消息的时候指定消息属性 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(TtlSender.class); RabbitAdmin rabbitAdmin = applicationContext.getBean(RabbitAdmin.class); RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class); MessageProperties messageProperties = new MessageProperties(); // 消息的过期属性(单位ms) messageProperties.setExpiration(\"4000\"); messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT); Message message = new Message(\"这条消息4秒后过期\".getBytes(), messageProperties); rabbitTemplate.send(\"TTL_EXCHANGE\", \"ttl\", message); // 随队列的过期时间属性,单位ms rabbitTemplate.convertAndSend(\"TTL_EXCHANGE\", \"ttl\", \"这条消息\"); 同时指定了Message TTL 和Queue TTL,则小的那个时间生效. 2.2 死信队列2.2.1 消息在某些情况下会变成死信(Dead letter) 队列在创建的时候可以指定一个死信交换机DLX(Dead Letter Exchange).死信交换机绑定的队列被为死信队列DLQ(Dead Letter Queue),DLX 实际上也就是普通的交换机,DLQ 也是普通的队列(例如替补球员也是普通的球员). ​ 2.2.2 什么情况下会变成死信? 消息被消费者拒绝并且未设置重回队列: (NACK || Reject ) &amp;&amp; requeue == false 消息过期. 队列达到最长长度,超过了Max Length(消息数) 或者Max Length Bytes (字节数), 最先入队的消息会被发送到 2.2.3 死信队列如何使用2.2.3.1 声明原交换机,原队列相互绑定​ 队列中的消息10秒后过期,因为没有消费者,会变成死信。指定原队列的死信交换机 private final static String ORI_USER_EXCHANGE = \"ORI_USER_EXCHANGE\"; private final static String ORI_USER_QUEUE = \"ORI_USER_QUEUE\"; // 死信交换机 private final static String DEAD_LETTER_EXCHANGE = \"DEAD_LETTER_EXCHANGE\"; // 私信队列 private final static String DEAD_LETTER_QUEUE = \"DEAD_LETTER_QUEUE\"; @Bean(\"oriUserExchange\") public DirectExchange exchange() &amp;#123; return new DirectExchange(ORI_USER_EXCHANGE, true, false, new HashMap&lt;>()) &amp;#125; @Bean(\"oriUserQueue\") public Queue queue() &amp;#123; Map&lt;String, Object> map = new HashMap&lt;>(); map.put(\"x-message-ttl\", 10000); // 10 秒钟后成为死信 map.put(\"x-dead-letter-exchange\", \"DEAD_LETTER_EXCHANGE\"); // 队列中的消息变成死信后，进入死信交换机 return new Queue(ORI_USER_QUEUE, true, false, false, map); &amp;#125; @Bean public Binding binding(@Qualifier(\"oriUserQueue\") Queue queue, @Qualifier(\"oriUserExchange\") DirectExchange exchange) &amp;#123; return BindingBuilder.bind(queue).to(exchange).with(\"ori.user\"); &amp;#125; 2.2.3.2 声明死信交换机、死信队列, 相互绑定 @Bean(\"deadLetterExchange\") public TopicExchange deadLetterExchange() &amp;#123; return new TopicExchange(DEAD_LETTER_EXCHANGE, true, false, new HashMap&lt;>()); &amp;#125; @Bean(\"deadLetterQueue\") public Queue deadLetterQueue() &amp;#123; return new Queue(DEAD_LETTER_QUEUE, true, false, false, new HashMap&lt;>()); &amp;#125; @Bean public Binding bingDead(@Qualifier(\"deadLetterQueue\") Queue queue, @Qualifier(\"deadLetterExchange\") TopicExchange topicExchange) &amp;#123; // 无条件路由 return BindingBuilder.bind(queue).to(topicExchange).with(\"#\"); &amp;#125; 2.2.3.3 最终消费者监听死信队列2.2.3.4 生产者发送消息 2.3 延迟队列​ 我们在实际业务中有一些需要延迟发送消息的场景,例如: 家里有一台智能热水器,需要在30分钟后启动 未付款的订单, 15分钟后关闭. RabbitMQ 本身不支持延时队列,总的来说有三种实现方案: 先存储到数据库, 用定时任务扫描. 利用RabbitMQ的死信队列(Dead Letter Queue) 实现. 利用rabbitmq-delayed-message-exchange 插件. 2.3.1 TTL + DLX 的实现 基于消息TTL,我们来看一下如何利用死信队列(DLQ) 实现延迟队列 总体步骤: 创建一个交换机 创建一个队列,与上述交换机绑定,并且通过属性指定队列的死信交换机. 创建一个死信交换机 创建一个死信队列 将死信交换机绑定到死信队列 消费者监听死信队列. ​ 消息的流转流程: 生产者-&gt; 原交换机-&gt; 原队列(超过TTL之后)-&gt; 死信交换机-&gt; 死信队列-&gt; 最终消费者. 使用死信队列实现延迟消息的缺点: 如果统一用队列来设置消息的TTL,当梯度非常多的情况下, 比如1分钟、2分钟、5分钟、10分钟、20分钟、30分钟… 需要创建很多交换机和队列来路由消息. 如果单独设置消息的TTL, 则可能造成队列中的消息阻塞,前一条消息没有出队(没有被消费), 后面的消息无法投递(比如前一条消息的过期TTL是30min, 第二条消息的TTL 是10min. 10min后, 即使第二条消息应该投递了,但是由于第一条消息还未出队,所以无法投递) 可能存在一定的时间误差 2.3.2 基于延迟队列插件的实现(linux)​ 在RabbitMQ 3.5.7 以及以后的版本提供了一个插件(rabbitmq-delayed-message-exchange) 来实现延迟队列功能. 同时插件依赖 Erlang/OPT 18.0以及以上. ​ 插件源码地址: https://github.com/rabbitmq/rabbitmq-delayed-message-exchange 插件下载地址: https://bintray.com/rabbitmq/community-plugins/rabbitmq_delayed_message_exchange 2.3.2.1 进入插件目录whereis rabbitmq cd /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.12/plugins 2.3.2.2 下载插件wget https://bintray.com/rabbitmq/community-plugins/download_file?file_path=rabbitmq_delayed_message_exchange-0.0.1.ez mv download_file?file_path=rabbitmq_delayed_message_exchange-0.0.1.ez rabbitmq_delayed_message_exchange-0.0.1.ez 2.3.2.3 启动插件 rabbitmq-plugins enable rabbitmq_delayed_message_exchange 2.3.2.4 停用插件 rabbitmq-plugins disable rabbitmq_delayed_message_exchange 2.3.2.5 插件的使用​ 通过声明一个x-delayed-message 类型的Exchange来使用delayed-messaging 特性. x-delayed-message 是插件提供的类型,并不是rabbitmq本身的(区别与direct、topic、fanout、headers). ```java // 死信交换机 private final static String DEAD_LETTER_EXCHANGE = &quot;DEAD_LETTER_EXCHANGE&quot;; // 私信队列 private final static String DEAD_LETTER_QUEUE = &quot;DEAD_LETTER_QUEUE&quot;; public TopicExchange exchange() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;x-delayed-type&quot;, &quot;direct&quot;); return new TopicExchange(DEAD_LETTER_EXCHANGE, true, false, map); &#125; ``` 生产者: ​ 消息属性中指定 x-delay 参数 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(TtlSender.class); RabbitAdmin rabbitAdmin = applicationContext.getBean(RabbitAdmin.class); RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class); MessageProperties messageProperties = new MessageProperties(); // 延迟的间隔时间, 目标时间减去当前时刻 messageProperties.setHeader(\"x-delay\", \"目标时刻\" - System.currentTimeMillis()); Message message = new Message(\"这条消息4秒后过期\".getBytes(), messageProperties); rabbitTemplate.send(\"DELAY_EXCHANGE\", \"#\", message); 2.4 服务端流控(Flow Control)https://www.rabbitmq.com/configure.html https://www.rabbitmq.com/flow-control.html https://www.rabbitmq.com/memory.html https://www.rabbitmq.com/disk-alarms.html ​ 当RabbitMQ 生产MQ消息的速度远大于消费消息的速度时,会产生大量的消息堆积, 占用系统资源, 导致机器的性能下降. 我们想要控制服务端接受消息的数量, 应该怎么做呢? ​ 队列有两个控制长度的属性: x-max-length： 队列中最大存储最大消息数, 超过这个数量, 队头的消息会被丢弃. x-max-length-bytes: 队列中存储的最大消息容量(单位bytes), 超过这个容量, 队头的消息会被丢弃. 需要注意的是: 设置队列长度只能消息堆积的情况下有意思,而且会删除先入队的消息,不能真正的实现服务端限流. ​ 有没有其他办法实现服务端限流吗? 2.4.1 内存控制​ RabbitMQ 会在启动时检测机器的物理内存数值.默认当MQ 占用40%以上内存时, MQ会主动抛出一个内存警告并阻塞所有连接(Connections). 可以通过修改rabbitmq.config 文件来调整内存阈值,默认值是0.4,如下所示: [{rabbit, [{vm_memory_high_watermark, 0.4}]}]. ​ 也可以用命令动态设置,如果设置为0, 则所有的消息都不能发布. rabbitmqctl set_vm_memory_high_watermark 0.3 2.4.2 磁盘控制​ 另一种方式是通过磁盘来控制消息的发布. 当磁盘空间低于指定的值时(默认50MB)，触发流控措施. ​ 例如: 指定为磁盘的30% 或者2GB. https://www.rabbitmq.com/configure.html disk_free_limit.relative = 3.0 disk_free_limit.absolute = 2GB 2.5 消费端限流https://www.rabbitmq.com/consumer-prefetch.html ​ 默认情况下, 如果不进行配置, RabbitMQ 会尽可能的把队列中的消息发送到消费者. 因为消费者会在本地缓存消息, 如果消息数量过多,可能回导致OOM 或者影响其他进程的正常运行. ​ 在消费者处理能力有限, 例如消费者数量太少, 或者单条消息的处理时间过长的情况下, 如果我们希望在一定数量的消息消费完之前, 不再推送消息过来, 就要用到消费段的流量控制措施. ​ 可以基于Consumer 或者channel 设置prefetch count的值,含义为 Consumer 端的最大的unacked messages 数目. 当超过这个数值的消息未被确认, RabbitMQ 会停止投递新的消息给该消费者. channel.basicQos(2); // 如果超过 2 条消息没有发送 ACK，当前消费者不再接受队列消息 channel.basicConsume(QUEUE_NAME, false, consumer); SimpleMessageListenerContainer container.setPrefetchCount(2); SpringBoot 配置 spring.rabbitmq.listener.simple.prefetch=2 举例: channel 的 prefetch count 设置为5, 当消费者有5条消息没有给Broker 发送ACK后, RabbitMQ 不再给这个消费者投递消息.","categories":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/"},{"name":"微服务","slug":"rabbitMQ/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"rabbitMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"rabbitMQ","slug":"rabbitMQ/微服务/微服务/rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/rabbitMQ/"}],"tags":[]},{"title":"Nacos长轮询和集群分析","slug":"微服务/nacos/Nacos长轮询和集群分析","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/nacos/nacos-chang-lun-xun-he-ji-qun-fen-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/nacos/nacos-chang-lun-xun-he-ji-qun-fen-xi/","excerpt":"","text":"长轮询的时间间隔我们知道客户端会有一个长训轮的任务去检查服务器端的配置是否发生了变化, 如果发生了变更, 那么客户端会拿到变更的groupKey 再根据 groupKey 去获取配置项的最新值 跟新到本地的缓存以及文件中,那么这种每次都靠客户端去请求, 那请求的时间间隔设置多少合适呢? 如果间隔时间设置的太长的话有可能无法及时获取服务端的变更, 如果间隔时间设置的太短的话, 那么频繁的请求对于服务端来说无疑也是一种负担,所以最好的方式是客户端每隔一段长度适中的时间去服务端请求, 而在这期间如果配置发生了变更, 服务端能够主动将变更后的结果推送给客户端, 这样既能够保证客户端能够实时感知到配置的变化, 也降低了服务端的压力, 我们来看看nacos 设置的间隔时间是多久? 长轮询的概念那么在讲解原理之前, 先给大家解释一下什么叫长轮询. 客户端发起一个请求到服务端, 服务端收到客户端的请求后, 并不会立即响应给客户端, 而是先把请求hold住, 然后服务端会在hold 住的这段时间内检查数据是否有更新, 如果有, 则响应给客户端. 如果一直没有数据变更, 则达到一定时间(长轮询时间间隔)才返回. 长轮询典型的场景有: 扫码登陆、扫码支付. 客户端长轮询我们在 ClientWorker 这个类中, 找到checkUpdateConfigStr 这个方法, 这里面就是去服务端查询发生变化的 groupKey /** * 从Server获取值变化了的DataID列表。返回的对象里只有dataId和group是有效的。 保证不返回NULL。 */ List&lt;String> checkUpdateConfigStr(String probeUpdateString, boolean isInitializingCacheList) &amp;#123; List&lt;String> params = Arrays.asList(Constants.PROBE_MODIFY_REQUEST, probeUpdateString); long timeout = TimeUnit.SECONDS.toMillis(30L); List&lt;String> headers = new ArrayList&lt;String>(2); headers.add(\"Long-Pulling-Timeout\"); headers.add(\"\" + timeout); // told server do not hang me up if new initializing cacheData added in if (isInitializingCacheList) &amp;#123; headers.add(\"Long-Pulling-Timeout-No-Hangup\"); headers.add(\"true\"); &amp;#125; if (StringUtils.isBlank(probeUpdateString)) &amp;#123; return Collections.emptyList(); &amp;#125; try &amp;#123; HttpResult result = agent.httpPost(Constants.CONFIG_CONTROLLER_PATH + \"/listener\", headers, params, agent.getEncode(), timeout); if (HttpURLConnection.HTTP_OK == result.code) &amp;#123; setHealthServer(true); return parseUpdateDataIdResponse(result.content); &amp;#125; else &amp;#123; setHealthServer(false); if (result.code == HttpURLConnection.HTTP_INTERNAL_ERROR) &amp;#123; log.error(\"NACOS-0007\", LoggerHelper.getErrorCodeStr(\"Nacos\", \"Nacos-0007\", \"环境问题\", \"[check-update] get changed dataId error\")); &amp;#125; log.error(agent.getName(), \"NACOS-XXXX\", \"[check-update] get changed dataId error, code=&amp;#123;&amp;#125;\", result.code); &amp;#125; &amp;#125; catch (IOException e) &amp;#123; setHealthServer(false); log.error(agent.getName(), \"NACOS-XXXX\", \"[check-update] get changed dataId exception, msg=&amp;#123;&amp;#125;\", e.toString()); &amp;#125; return Collections.emptyList(); &amp;#125; 这个方法最终会发起http请求, 注意这里面有个 timeout 属性. HttpResult result = agent.httpPost(Constants.CONFIG_CONTROLLER_PATH + \"/listener\", headers, params, agent.getEncode(), timeout); timeout 是在init这个方法中赋值的, 默认情况下是30秒, 可以通过 configLongPollTimeout 进行修改, private void init(Properties properties) &amp;#123; timeout = Math.max(NumberUtils.toInt(properties.getProperty(PropertyKeyConst.CONFIG_LONG_POLL_TIMEOUT), Constants.CONFIG_LONG_POLL_TIMEOUT), Constants.MIN_CONFIG_LONG_POLL_TIMEOUT); taskPenaltyTime = NumberUtils.toInt(properties.getProperty(PropertyKeyConst.CONFIG_RETRY_TIME), Constants.CONFIG_RETRY_TIME); enableRemoteSyncConfig = Boolean.parseBoolean(properties.getProperty(PropertyKeyConst.ENABLE_REMOTE_SYNC_CONFIG)); &amp;#125; 所有从这里得出的一个基本结论是: 客户端发起一个轮询请求,超时时间是 30s, 那么客户端为什么要等待30s 才超时呢？不是越快越好吗? 客户端长轮询的时间间隔我们可以在nacos 的日志目录下 $NACOS_HOME/nacos/logs/config-client-request.log 文件中: 2019-08-04 13:22:19,736|0|nohangup|127.0.0.1|polling|1|55|0 2019-08-04 13:22:49,443|29504|timeout|127.0.0.1|polling|1|55 2019-08-04 13:23:18,983|29535|timeout|127.0.0.1|polling|1|55 2019-08-04 13:23:48,493|29501|timeout|127.0.0.1|polling|1|55 2019-08-04 13:24:18,003|29500|timeout|127.0.0.1|polling|1|55 2019-08-04 13:24:47,509|29501|timeout|127.0.0.1|polling|1|55 可以看到一个现象, 在配置没有发生变化的情况下, 客户端会等待29.5s以上, 才请求到服务端的结果. 然后客户端拿到服务器端的结果后, 在做后续的操作. 如果在配置发生变更的情况下, 由于客户端基于长轮询的连接保持, 所以返回的时间会非常短. 我摁可以做个小实验, 在nacos console 中频繁修改数据在观察一下: 2019-08-04 13:30:17,016|0|inadvance|127.0.0.1|polling|1|55|example+DEFAULT_GROUP 2019-08-04 13:30:17,022|3|null|127.0.0.1|get|example|DEFAULT_GROUP||e10e4d5973c497e490a8d7a 9e4e9be64|unknown 2019-08-04 13:30:20,807|10|true|0:0:0:0:0:0:0:1|publish|example|DEFAULT_GROUP||81360b7e732a 5dbb37d62d81cebb85d2|null 2019-08-04 13:30:20,843|0|inadvance|127.0.0.1|polling|1|55|example+DEFAULT_GROUP 2019-08-04 13:30:20,848|1|null|127.0.0.1|get|example|DEFAULT_GROUP||81360b7e732a5dbb37d62d8 1cebb85d2|unknown 服务端的处理分析完客户端之后, 随着好奇心的驱使, 服务端是如何处理客户端的请求呢? 那么同样, 我们需要思考几个问题: 客户端的长轮询响应时间是受到哪些因素的影响 客户端的超时时间为什么要设置30s 客户端发送请求的地址是 /v1/cs/configs/listener, 找到服务端对应的方法. ConfigControllernacos 是使用 spring mvc 提供的rest api, 这里会调用inner.doPollingConfig 进行处理. /** * 比较MD5 */ @RequestMapping(value = \"/listener\", method = RequestMethod.POST) public void listener(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &amp;#123; request.setAttribute(\"org.apache.catalina.ASYNC_SUPPORTED\", true); String probeModify = request.getParameter(\"Listening-Configs\"); if (StringUtils.isBlank(probeModify)) &amp;#123; throw new IllegalArgumentException(\"invalid probeModify\"); &amp;#125; probeModify = URLDecoder.decode(probeModify, Constants.ENCODE); Map&lt;String, String> clientMd5Map; try &amp;#123; clientMd5Map = MD5Util.getClientMd5Map(probeModify); &amp;#125; catch (Throwable e) &amp;#123; throw new IllegalArgumentException(\"invalid probeModify\"); &amp;#125; // do long-polling inner.doPollingConfig(request, response, clientMd5Map, probeModify.length()); &amp;#125; doPollingConfig这个方法中,兼容了长轮询和短轮询的逻辑, 我们只需要关注长轮询的部分, 再次进入到 longPollingService.addLongPollingClient /** * 轮询接口 */ public String doPollingConfig(HttpServletRequest request, HttpServletResponse response, Map&lt;String, String> clientMd5Map, int probeRequestSize) throws IOException, ServletException &amp;#123; // 长轮询 if (LongPollingService.isSupportLongPolling(request)) &amp;#123; longPollingService.addLongPollingClient(request, response, clientMd5Map, probeRequestSize); return HttpServletResponse.SC_OK + \"\"; &amp;#125; // else 兼容短轮询逻辑 List&lt;String> changedGroups = MD5Util.compareMd5(request, response, clientMd5Map); // 兼容短轮询result String oldResult = MD5Util.compareMd5OldResult(changedGroups); String newResult = MD5Util.compareMd5ResultString(changedGroups); String version = request.getHeader(Constants.CLIENT_VERSION_HEADER); if (version == null) &amp;#123; version = \"2.0.0\"; &amp;#125; int versionNum = Protocol.getVersionNumber(version); /** * 2.0.4版本以前, 返回值放入header中 */ if (versionNum &lt; START_LONGPOLLING_VERSION_NUM) &amp;#123; response.addHeader(Constants.PROBE_MODIFY_RESPONSE, oldResult); response.addHeader(Constants.PROBE_MODIFY_RESPONSE_NEW, newResult); &amp;#125; else &amp;#123; request.setAttribute(\"content\", newResult); &amp;#125; // 禁用缓存 response.setHeader(\"Pragma\", \"no-cache\"); response.setDateHeader(\"Expires\", 0); response.setHeader(\"Cache-Control\", \"no-cache,no-store\"); response.setStatus(HttpServletResponse.SC_OK); return HttpServletResponse.SC_OK + \"\"; &amp;#125; longPollingService.addLongPollingClient从方法的名字上可以推出, 这个方法应该是把客户端的长轮询请求添加到某个任务中. 获得客户端传递过来的超时时间, 并且进行本地计算, 提前500s 返回响应, 这就能解释为什么客户端响应超时时间是29.5+了, 当然如果 isFixedPolling=true 的情况下, 不会提前返回响应. 根据客户端请求过来的md5和服务端对应的group 下对应内容的md5 进行比较, 如果不一致, 则通过generateResponse 将结果返回. 如果配置文件没有发生变化, 则通过 scheduler.execute 启动了一个定时任务, 将客户端的长轮询请求封装成一个叫 ClientLongPolling 的任务, 交给 scheduler 去执行. public void addLongPollingClient(HttpServletRequest req, HttpServletResponse rsp, Map&lt;String, String> clientMd5Map, int probeRequestSize) &amp;#123; String str = req.getHeader(LongPollingService.LONG_POLLING_HEADER); String noHangUpFlag = req.getHeader(LongPollingService.LONG_POLLING_NO_HANG_UP_HEADER); String appName = req.getHeader(RequestUtil.CLIENT_APPNAME_HEADER); String tag = req.getHeader(\"Vipserver-Tag\"); int delayTime = SwitchService.getSwitchInteger(SwitchService.FIXED_DELAY_TIME, 500); /** * 提前500ms返回响应，为避免客户端超时 @qiaoyi.dingqy 2013.10.22改动 add delay time for LoadBalance */ long timeout = Math.max(10000, Long.parseLong(str) - delayTime); if (isFixedPolling()) &amp;#123; timeout = Math.max(10000, getFixedPollingInterval()); // do nothing but set fix polling timeout &amp;#125; else &amp;#123; long start = System.currentTimeMillis(); List&lt;String> changedGroups = MD5Util.compareMd5(req, rsp, clientMd5Map); if (changedGroups.size() > 0) &amp;#123; generateResponse(req, rsp, changedGroups); LogUtil.clientLog.info(\"&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;\", System.currentTimeMillis() - start, \"instant\", RequestUtil.getRemoteIp(req), \"polling\", clientMd5Map.size(), probeRequestSize, changedGroups.size()); return; &amp;#125; else if (noHangUpFlag != null &amp;&amp; noHangUpFlag.equalsIgnoreCase(TRUE_STR)) &amp;#123; LogUtil.clientLog.info(\"&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;\", System.currentTimeMillis() - start, \"nohangup\", RequestUtil.getRemoteIp(req), \"polling\", clientMd5Map.size(), probeRequestSize, changedGroups.size()); return; &amp;#125; &amp;#125; String ip = RequestUtil.getRemoteIp(req); // 一定要由HTTP线程调用，否则离开后容器会立即发送响应 final AsyncContext asyncContext = req.startAsync(); // AsyncContext.setTimeout()的超时时间不准，所以只能自己控制 asyncContext.setTimeout(0L); scheduler.execute( new ClientLongPolling(asyncContext, clientMd5Map, ip, probeRequestSize, timeout, appName, tag)); &amp;#125; ClientLongPolling我们来分析一下, ClientLongPolling 到底做了什么操作? 或者说我们可以先猜测一下应该会做什么事情? 这个任务是要阻塞 29.5s 才能执行, 以为立马执行没有任何意思, 毕竟前面已经执行过一次了 如果在29.5s+ 之内, 数据发生变化, 需要提前通知, 需要有一种监控机制. 基于这些猜想, 我们来看看他的实现过程. 从代码粗粒度来看 ，它的实现似乎跟我们的猜想一致, 在run方法中, 通过scheduler.schedule 实现了一个定时任务, 它的delay 时间正好是前面计算的29.5s. 在这个任务中, 会通过MD5Util.compareMd5 来进行计算. 那另外一个, 当数据发生变化以后, 肯定不能得到 29.5s 之后才通知呀, 那怎么办呢? 我们发现有一个 allsubs 的东西, 它似乎和发布订阅有关系,那是不是有可能当前的clientLongPolling 订阅了数据变化的时间呢? @Override public void run() &amp;#123; asyncTimeoutFuture = scheduler.schedule(new Runnable() &amp;#123; @Override public void run() &amp;#123; try &amp;#123; getRetainIps().put(ClientLongPolling.this.ip, System.currentTimeMillis()); /** * 删除订阅关系 */ allSubs.remove(ClientLongPolling.this); if (isFixedPolling()) &amp;#123; LogUtil.clientLog.info(\"&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;\", (System.currentTimeMillis() - createTime), \"fix\", RequestUtil.getRemoteIp((HttpServletRequest)asyncContext.getRequest()), \"polling\", clientMd5Map.size(), probeRequestSize); List&lt;String> changedGroups = MD5Util.compareMd5( (HttpServletRequest)asyncContext.getRequest(), (HttpServletResponse)asyncContext.getResponse(), clientMd5Map); if (changedGroups.size() > 0) &amp;#123; sendResponse(changedGroups); &amp;#125; else &amp;#123; sendResponse(null); &amp;#125; &amp;#125; else &amp;#123; LogUtil.clientLog.info(\"&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;\", (System.currentTimeMillis() - createTime), \"timeout\", RequestUtil.getRemoteIp((HttpServletRequest)asyncContext.getRequest()), \"polling\", clientMd5Map.size(), probeRequestSize); sendResponse(null); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; LogUtil.defaultLog.error(\"long polling error:\" + t.getMessage(), t.getCause()); &amp;#125; &amp;#125; &amp;#125;, timeoutTime, TimeUnit.MILLISECONDS); allSubs.add(this); &amp;#125; allSubsallSubs 是一个队列, 队列里面存放了 ClientLongPolling 这个对象, 这个队列似乎和配置变更有某种关联关系. /** * 长轮询订阅关系 */ final Queue&lt;ClientLongPolling> allSubs; 那这个时候, 我的第一想法是, 先去看一下当前类的类图, 发现 LongPollingService 继承了AbstractEventListener,事件监听. AbstractEventListener这里面有个抽象的onEvent方法, 明显是用来处理事件的方法, 而抽象方法必须由子类实现, 所以意味着LongPollingService 里面肯定实现了onEvent 方法. static public abstract class AbstractEventListener &amp;#123; public AbstractEventListener() &amp;#123; /** * automatic register */ EventDispatcher.addEventListener(this); &amp;#125; /** * 感兴趣的事件列表 * * @return event list */ abstract public List&lt;Class&lt;? extends Event>> interest(); /** * 处理事件 * * @param event event */ abstract public void onEvent(Event event); &amp;#125; LongPollingService.onEvent这个事件的实现方法中: 判断事件类型是否为LocalDataChangeEvent 通过scheduler.execute 执行 DataChangeTask 这个任务. @Override public void onEvent(Event event) &amp;#123; if (isFixedPolling()) &amp;#123; // ignore &amp;#125; else &amp;#123; if (event instanceof LocalDataChangeEvent) &amp;#123; LocalDataChangeEvent evt = (LocalDataChangeEvent)event; scheduler.execute(new DataChangeTask(evt.groupKey, evt.isBeta, evt.betaIps)); &amp;#125; &amp;#125; &amp;#125; DataChangeTask.run从名字来看, 这个是数据变化的任务, 最让人兴奋的是, 这里面有一个循环迭代器, 从 allsubs 里面获取ClientLongPolling 最后通过clientSub.sendResponse把数据返回到客户端, 所以这也就能理解为啥数据变化能够实时触发更新了. @Override public void run() &amp;#123; try &amp;#123; ConfigService.getContentBetaMd5(groupKey); for (Iterator&lt;ClientLongPolling> iter = allSubs.iterator(); iter.hasNext(); ) &amp;#123; ClientLongPolling clientSub = iter.next(); if (clientSub.clientMd5Map.containsKey(groupKey)) &amp;#123; // 如果beta发布且不在beta列表直接跳过 if (isBeta &amp;&amp; !betaIps.contains(clientSub.ip)) &amp;#123; continue; &amp;#125; // 如果tag发布且不在tag列表直接跳过 if (StringUtils.isNotBlank(tag) &amp;&amp; !tag.equals(clientSub.tag)) &amp;#123; continue; &amp;#125; getRetainIps().put(clientSub.ip, System.currentTimeMillis()); iter.remove(); // 删除订阅关系 LogUtil.clientLog.info(\"&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;|&amp;#123;&amp;#125;\", (System.currentTimeMillis() - changeTime), \"in-advance\", RequestUtil.getRemoteIp((HttpServletRequest)clientSub.asyncContext.getRequest()), \"polling\", clientSub.clientMd5Map.size(), clientSub.probeRequestSize, groupKey); clientSub.sendResponse(Arrays.asList(groupKey)); &amp;#125; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; LogUtil.defaultLog.error(\"data change error:\" + t.getMessage(), t.getCause()); &amp;#125; &amp;#125; 那么接下来的一个疑问是, 数据变化之后是如何触发事件的呢? 所以我们定位到数据变化的请求类中, 在 configController 这个类中, 找到POST 请求的方法. 找到配置变更的位置, 发现数据持久化之后 , 会通过EventDispatcher 进行事件发布, EventDispatcher.fireEvent. 但这个事件似乎不是我们所关心的时间, 原因是这里发布的事件是 ConfigDataChangeEvent,而LongPollingService 最感兴趣的事件是 LocalDataChangeEvent. /** * 增加或更新非聚合数据。 * * @throws NacosException */ @RequestMapping(method = RequestMethod.POST) @ResponseBody public Boolean publishConfig(HttpServletRequest request, HttpServletResponse response, @RequestParam(\"dataId\") String dataId, @RequestParam(\"group\") String group, @RequestParam(value = \"tenant\", required = false, defaultValue = StringUtils.EMPTY) String tenant, @RequestParam(\"content\") String content, @RequestParam(value = \"tag\", required = false) String tag, @RequestParam(value = \"appName\", required = false) String appName, @RequestParam(value = \"src_user\", required = false) String srcUser, @RequestParam(value = \"config_tags\", required = false) String configTags, @RequestParam(value = \"desc\", required = false) String desc, @RequestParam(value = \"use\", required = false) String use, @RequestParam(value = \"effect\", required = false) String effect, @RequestParam(value = \"type\", required = false) String type, @RequestParam(value = \"schema\", required = false) String schema) throws NacosException &amp;#123; final String srcIp = RequestUtil.getRemoteIp(request); String requestIpApp = RequestUtil.getAppName(request); ParamUtils.checkParam(dataId, group, \"datumId\", content); ParamUtils.checkParam(tag); Map&lt;String, Object> configAdvanceInfo = new HashMap&lt;String, Object>(10); if (configTags != null) &amp;#123; configAdvanceInfo.put(\"config_tags\", configTags); &amp;#125; if (desc != null) &amp;#123; configAdvanceInfo.put(\"desc\", desc); &amp;#125; if (use != null) &amp;#123; configAdvanceInfo.put(\"use\", use); &amp;#125; if (effect != null) &amp;#123; configAdvanceInfo.put(\"effect\", effect); &amp;#125; if (type != null) &amp;#123; configAdvanceInfo.put(\"type\", type); &amp;#125; if (schema != null) &amp;#123; configAdvanceInfo.put(\"schema\", schema); &amp;#125; ParamUtils.checkParam(configAdvanceInfo); if (AggrWhitelist.isAggrDataId(dataId)) &amp;#123; log.warn(\"[aggr-conflict] &amp;#123;&amp;#125; attemp to publish single data, &amp;#123;&amp;#125;, &amp;#123;&amp;#125;\", RequestUtil.getRemoteIp(request), dataId, group); throw new NacosException(NacosException.NO_RIGHT, \"dataId:\" + dataId + \" is aggr\"); &amp;#125; final Timestamp time = TimeUtils.getCurrentTime(); String betaIps = request.getHeader(\"betaIps\"); ConfigInfo configInfo = new ConfigInfo(dataId, group, tenant, appName, content); if (StringUtils.isBlank(betaIps)) &amp;#123; if (StringUtils.isBlank(tag)) &amp;#123; persistService.insertOrUpdate(srcIp, srcUser, configInfo, time, configAdvanceInfo, false); EventDispatcher.fireEvent(new ConfigDataChangeEvent(false, dataId, group, tenant, time.getTime())); &amp;#125; else &amp;#123; persistService.insertOrUpdateTag(configInfo, tag, srcIp, srcUser, time, false); EventDispatcher.fireEvent(new ConfigDataChangeEvent(false, dataId, group, tenant, tag, time.getTime())); &amp;#125; &amp;#125; else &amp;#123; // beta publish persistService.insertOrUpdateBeta(configInfo, betaIps, srcIp, srcUser, time, false); EventDispatcher.fireEvent(new ConfigDataChangeEvent(true, dataId, group, tenant, time.getTime())); &amp;#125; ConfigTraceService.logPersistenceEvent(dataId, group, tenant, requestIpApp, time.getTime(), LOCAL_IP, ConfigTraceService.PERSISTENCE_EVENT_PUB, content); return true; &amp;#125; 后来我发现, 在 Nacos中有一个 DumpService, 它会定时把变更后的数据 dump 到磁盘上, DumpService 在spring 启动后, 会调用init 方法 启动几个 dump任务, 然后在任务结束后, 会触发一个 LocalDataChangeEvent 的事件. @PostConstruct public void init() &amp;#123; LogUtil.defaultLog.warn(\"DumpService start\"); DumpProcessor processor = new DumpProcessor(this); DumpAllProcessor dumpAllProcessor = new DumpAllProcessor(this); DumpAllBetaProcessor dumpAllBetaProcessor = new DumpAllBetaProcessor(this); DumpAllTagProcessor dumpAllTagProcessor = new DumpAllTagProcessor(this); dumpTaskMgr = new TaskManager( \"com.alibaba.nacos.server.DumpTaskManager\"); dumpTaskMgr.setDefaultTaskProcessor(processor); dumpAllTaskMgr = new TaskManager( \"com.alibaba.nacos.server.DumpAllTaskManager\"); dumpAllTaskMgr.setDefaultTaskProcessor(dumpAllProcessor); Runnable dumpAll = new Runnable() &amp;#123; @Override public void run() &amp;#123; dumpAllTaskMgr.addTask(DumpAllTask.TASK_ID, new DumpAllTask()); &amp;#125; &amp;#125;; Runnable dumpAllBeta = new Runnable() &amp;#123; @Override public void run() &amp;#123; dumpAllTaskMgr.addTask(DumpAllBetaTask.TASK_ID, new DumpAllBetaTask()); &amp;#125; &amp;#125;; Runnable clearConfigHistory = new Runnable() &amp;#123; @Override public void run() &amp;#123; log.warn(\"clearConfigHistory start\"); if (ServerListService.isFirstIp()) &amp;#123; try &amp;#123; Timestamp startTime = getBeforeStamp(TimeUtils.getCurrentTime(), 24 * getRetentionDays()); int totalCount = persistService.findConfigHistoryCountByTime(startTime); if (totalCount > 0) &amp;#123; int pageSize = 1000; int removeTime = (totalCount + pageSize - 1) / pageSize; log.warn(\"clearConfigHistory, getBeforeStamp:&amp;#123;&amp;#125;, totalCount:&amp;#123;&amp;#125;, pageSize:&amp;#123;&amp;#125;, removeTime:&amp;#123;&amp;#125;\", new Object[] &amp;#123;startTime, totalCount, pageSize, removeTime&amp;#125;); while (removeTime > 0) &amp;#123; // 分页删除，以免批量太大报错 persistService.removeConfigHistory(startTime, pageSize); removeTime--; &amp;#125; &amp;#125; &amp;#125; catch (Throwable e) &amp;#123; log.error(\"clearConfigHistory error\", e); &amp;#125; &amp;#125; &amp;#125; &amp;#125;; try &amp;#123; dumpConfigInfo(dumpAllProcessor); // 更新beta缓存 LogUtil.defaultLog.info(\"start clear all config-info-beta.\"); DiskUtil.clearAllBeta(); if (persistService.isExistTable(BETA_TABLE_NAME)) &amp;#123; dumpAllBetaProcessor.process(DumpAllBetaTask.TASK_ID, new DumpAllBetaTask()); &amp;#125; // 更新Tag缓存 LogUtil.defaultLog.info(\"start clear all config-info-tag.\"); DiskUtil.clearAllTag(); if (persistService.isExistTable(TAG_TABLE_NAME)) &amp;#123; dumpAllTagProcessor.process(DumpAllTagTask.TASK_ID, new DumpAllTagTask()); &amp;#125; // add to dump aggr List&lt;ConfigInfoChanged> configList = persistService.findAllAggrGroup(); if (configList != null &amp;&amp; !configList.isEmpty()) &amp;#123; total = configList.size(); List&lt;List&lt;ConfigInfoChanged>> splitList = splitList(configList, INIT_THREAD_COUNT); for (List&lt;ConfigInfoChanged> list : splitList) &amp;#123; MergeAllDataWorker work = new MergeAllDataWorker(list); work.start(); &amp;#125; log.info(\"server start, schedule merge end.\"); &amp;#125; &amp;#125; catch (Exception e) &amp;#123; LogUtil.fatalLog.error( \"Nacos Server did not start because dumpservice bean construction failure :\\n\" + e.getMessage(), e.getCause()); throw new RuntimeException( \"Nacos Server did not start because dumpservice bean construction failure :\\n\" + e.getMessage()); &amp;#125; if (!STANDALONE_MODE) &amp;#123; Runnable heartbeat = new Runnable() &amp;#123; @Override public void run() &amp;#123; String heartBeatTime = TimeUtils.getCurrentTime().toString(); // write disk try &amp;#123; DiskUtil.saveHeartBeatToDisk(heartBeatTime); &amp;#125; catch (IOException e) &amp;#123; LogUtil.fatalLog.error(\"save heartbeat fail\" + e.getMessage()); &amp;#125; &amp;#125; &amp;#125;; TimerTaskService.scheduleWithFixedDelay(heartbeat, 0, 10, TimeUnit.SECONDS); long initialDelay = new Random().nextInt(INITIAL_DELAY_IN_MINUTE) + 10; LogUtil.defaultLog.warn(\"initialDelay:&amp;#123;&amp;#125;\", initialDelay); TimerTaskService.scheduleWithFixedDelay(dumpAll, initialDelay, DUMP_ALL_INTERVAL_IN_MINUTE, TimeUnit.MINUTES); TimerTaskService.scheduleWithFixedDelay(dumpAllBeta, initialDelay, DUMP_ALL_INTERVAL_IN_MINUTE, TimeUnit.MINUTES); &amp;#125; TimerTaskService.scheduleWithFixedDelay(clearConfigHistory, 10, 10, TimeUnit.MINUTES); &amp;#125; 简单总结简单总结一i下刚才分析的过程: 客户端发起长轮询请求. 服务端收到i请求后, 先比较服务端缓存中的数据是否相同,如果不同, 则直接返回. 如果相同, 则通过 schedule 延迟29.5s 之后再执行比较. 为了保证当服务端在 29.5s之内数据发生变化能够及时的通知给客户端, 服务端采用事件订阅的方式来监听服务端本地数据变化的事件, 一旦收到事件, 则触发ClientLongPolling , 把结果写回到客户端, 就完成了一次数据的推送. 如果 ClientLongPolling 任务完成了数据的推送之后, ClientLongPolling 中的调度任务又开始执行了怎么办？ 很见到那, 只要在进行推送操作之前, 先将原来等待执行的调度任务取消就行了,这样就方式了推送操作写完响应数据之后， 调用任务又去写响应数据, 这时肯定报错. 所以, 在ClientLongPolling 方法中, 最开始的一个步骤就是删除订阅事件. 所以总的来说, Nacos 采用推+拉的方式, 来解决最开始关于长轮询事件间隔的问题, 当然, 30s 这个时间是可以设置的, 之所以设置成30s, 应该是一个经验值, 集群选举问题Nacos 支持集群模式,很显然, . 而一旦涉及到集群, 就涉及到主从, 那么nacos 是一种什么样的机制来实现集群的呢? nacos 的集群模式类似于zookeeper, 它分为leader 角色和 follower角色, 那么从这个角色的名字可以看出, 这个集群存在选举的机制, 因为如果自己不具备选举功能, 角色的命名可能就是master/slave了. 选举算法nacos集群采用raft 算法来实现, 它是相对于zookeeper 的选举算法来说比较简单的一种. 选举算法的核心在 RaftCore中, 包括数据的处理和数据的同步. 在Raft 算法中, 节点有三种角色: Leader : 负责接受客户端的请求. Candidate: 用于选举Leader 的一种角色 Follower: 负责响应来自leader 或者Candidate 的请求. 选举分为两个节点: 服务启动的时候 leader 挂了的时候 所有节点启动的时候, 都是 folower 状态, 如果在一段时间内如果没有收到leader 的心跳(可能是没有leader 或者leader 挂了), 那么folower 会变成Candidate . 然后发起选举, 在选举之前, 会增加term, 这个term 和zookeeper 中的epoch 的道理是一样的. folower 会投自己一票, 并且给其他节点发送票据vote, 等待其他节点回复. 在这个过程中, 可能出现几种情况: 收到过半的票数通过, 则成为leader 被告知其他节点已经成为了leader, 则自己切换为 folower 一段时间内没有收到过半的投票, 则重新发起选举. 约束条件在任一term中, 单个节点最多只能投一票. 选举的几种情况: 第一种情况: 赢得选举后, leader 会给所有节点发送消息, 避免其他节点触发新的选举. 第二种情况: 比如有三个节点A、B、C。 A、B 同时发起选举, 而A的选举消息先达到C,C给A 投了一票, 当B 的消息达到C时, 已经不能满足上面提到的第一个约束, 而C不会给B投票, 而A和B显然都不会给对方投票. A 胜出之后, 会给B、C 发送心跳消息, 节点B发现节点A的term 不低于自己的term, 知道已经有了leader, 于是转换为folower. 第三种情况: 没有任何节点获得投票, 可能是平票的情况. 加入总共有四个节点, (A/B/C/D). NodeC、NodeD 同时成为了 candidate.但NodeA 投了NodeD 一票,NodeB 投了NodeC 一票. 这就出现了凭票 spilt vote 的情况. 这个时候大家都在等呀等呀. 知道超时后重新发起选举, 如果出现平票的情况, 那么就延长了系统不可用的时间, 于是raft 就引入了randomized election timeouts 来尽量避免平票的情况. 数据的处理对于事务操作, 请求会转发给leader. 非事务操作, 可以任意一个节点来处理. 下面这段代码摘自 RaftCore,.在发布内容的时候, 做了两个事情. 如果当前的节点不是leader, 则转发给leader 节点处理. 如果是, 则向所有节点发送 onPublish public void signalPublish(String key, Record value) throws Exception &amp;#123; if (!isLeader()) &amp;#123; JSONObject params = new JSONObject(); params.put(\"key\", key); params.put(\"value\", value); Map&lt;String, String> parameters = new HashMap&lt;>(1); parameters.put(\"key\", key); raftProxy.proxyPostLarge(getLeader().ip, API_PUB, params.toJSONString(), parameters); return; &amp;#125; try &amp;#123; OPERATE_LOCK.lock(); long start = System.currentTimeMillis(); final Datum datum = new Datum(); datum.key = key; datum.value = value; if (getDatum(key) == null) &amp;#123; datum.timestamp.set(1L); &amp;#125; else &amp;#123; datum.timestamp.set(getDatum(key).timestamp.incrementAndGet()); &amp;#125; JSONObject json = new JSONObject(); json.put(\"datum\", datum); json.put(\"source\", peers.local()); onPublish(datum, peers.local()); final String content = JSON.toJSONString(json); final CountDownLatch latch = new CountDownLatch(peers.majorityCount()); for (final String server : peers.allServersIncludeMyself()) &amp;#123; if (isLeader(server)) &amp;#123; latch.countDown(); continue; &amp;#125; final String url = buildURL(server, API_ON_PUB); HttpClient.asyncHttpPostLarge(url, Arrays.asList(\"key=\" + key), content, new AsyncCompletionHandler&lt;Integer>() &amp;#123; @Override public Integer onCompleted(Response response) throws Exception &amp;#123; if (response.getStatusCode() != HttpURLConnection.HTTP_OK) &amp;#123; Loggers.RAFT.warn(\"[RAFT] failed to publish data to peer, datumId=&amp;#123;&amp;#125;, peer=&amp;#123;&amp;#125;, http code=&amp;#123;&amp;#125;\", datum.key, server, response.getStatusCode()); return 1; &amp;#125; latch.countDown(); return 0; &amp;#125; @Override public STATE onContentWriteCompleted() &amp;#123; return STATE.CONTINUE; &amp;#125; &amp;#125;); &amp;#125; if (!latch.await(UtilsAndCommons.RAFT_PUBLISH_TIMEOUT, TimeUnit.MILLISECONDS)) &amp;#123; // only majority servers return success can we consider this update success Loggers.RAFT.error(\"data publish failed, caused failed to notify majority, key=&amp;#123;&amp;#125;\", key); throw new IllegalStateException(\"data publish failed, caused failed to notify majority, key=\" + key); &amp;#125; long end = System.currentTimeMillis(); Loggers.RAFT.info(\"signalPublish cost &amp;#123;&amp;#125; ms, key: &amp;#123;&amp;#125;\", (end - start), key); &amp;#125; finally &amp;#123; OPERATE_LOCK.unlock(); &amp;#125; &amp;#125;","categories":[{"name":"nacos","slug":"nacos","permalink":"https://rainsoil.github.io/categories/nacos/"},{"name":"微服务","slug":"nacos/微服务","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"nacos/微服务/微服务","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"nacos","slug":"nacos/微服务/微服务/nacos","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/nacos/"}],"tags":[]},{"title":"分布式消息通信值Kafka的实现原理","slug":"微服务/kafka/分布式消息通信值Kafka的实现原理","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/kafka/fen-bu-shi-xiao-xi-tong-xin-zhi-kafka-de-shi-xian-yuan-li/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/kafka/fen-bu-shi-xiao-xi-tong-xin-zhi-kafka-de-shi-xian-yuan-li/","excerpt":"","text":"分布式消息通信之Kafka 的实现原理消息中间件能做什么?消息中间件主要解决的就是分布式系统之间消息的传递问题, 它能够屏蔽各种平台以及协议之间的特性,实现应用程序之间的协同. 举个简单的例子, 就拿一个电商平台的注册功能来简单分析一下,用户注册这一个服务,不仅仅只是insert 一条数据库里面就完事了, 还需要发送激活邮件、发送新人红包或者积分、发送营销短信等一些列操作. 假如说这里面的每一个操作都需要消耗1s , 那么整个注册过程就需要耗时4s 才能响应给用户. 但是我们从注册这个服务可以看到, 每一个子操作都是相对独立的. 同时, 基于领域划分后, 发送激活邮件、发送营销短信、赠送积分以及红包都属于不同的子域. 所以我们可以读这些子操作进行实现异步化执行, 类似于多线程并行处理的概念. 如何实现异步化呢? 用多线程去实现吗? 多线程当然可以实现, 只是, 消息的持久化、消息的重发这些条件, 多线程并不能满足, 所以需要借助一些开源中间件来解决. 而分布式消息队列就是一个非常好的解决方法, 引入分布式消息队列以后, 架构图就变成了这样了(下图是异步消息队列的场景). 通过引入分布式队列， 就能够大大提升程序的处理效率, 并且还解决了各个模块之间的耦合问题. 这个是分布式消息队列的第一个解决场景: 异步处理 我们再来展开一种场景,通过分布式消息队列来实现流量整形, 比如在电商平台的秒杀场景, 流量会非常大, 通过消息队列的方式就可以很好的缓解高流量的问题. 用户提交过来的请求, 先写入到消息队列. 消息队列是有长度的, 如果消息队列超过指定的长度, 则直接抛弃. 秒杀的具体核心处理业务, 接受消息队列中消息进行处理, 这里的消息处理能力取决于消费端本身的吞吐量. 当然, 消息中间件还有更多的应用场景, 比如在弱一致性事务模型中, 可以采用分布式消息队列的实现最大能力通知方式来实现数据的最终一致性问题等等. Java 中使用Kafka 进行通信.依赖 &lt;dependency> &lt;groupId>org.apache.kafka&lt;/groupId> &lt;artifactId>kafka-clients&lt;/artifactId> &lt;version>2.0.0&lt;/version> &lt;/dependency> 发送端代码package com.mq.kafka.demo; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.common.serialization.IntegerSerializer; import org.apache.kafka.common.serialization.StringSerializer; import java.util.Properties; import java.util.concurrent.ExecutionException; import java.util.concurrent.TimeUnit; /** * @author luyanan * @since 2019/12/27 * &lt;p>发送端&lt;/p> **/ public class Producer extends Thread &amp;#123; private final KafkaProducer&lt;Integer, String> producer; private final String topic; public Producer(String topic) &amp;#123; Properties properties = new Properties(); properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.86.128:9092\"); properties.put(ProducerConfig.CLIENT_ID_CONFIG, \"producer\"); properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName()); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); producer = new KafkaProducer&lt;Integer, String>(properties); this.topic = topic; &amp;#125; @Override public void run() &amp;#123; int num = 0; try &amp;#123; while (num &lt; 50) &amp;#123; String msg = \"test msg : \" + num; producer.send(new ProducerRecord&lt;Integer, String>(topic, msg)).get(); TimeUnit.SECONDS.sleep(2); System.out.println(\"发送消息\" + msg); num++; &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ExecutionException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; public static void main(String[] args) &amp;#123; new Producer(\"test\").start(); &amp;#125; &amp;#125; 消费端代码package com.mq.kafka.demo; import org.apache.kafka.clients.consumer.ConsumerConfig; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import org.apache.kafka.common.serialization.IntegerDeserializer; import org.apache.kafka.common.serialization.StringDeserializer; import java.time.Duration; import java.util.Collections; import java.util.Properties; /** * @author luyanan * @since 2019/12/27 * &lt;p>消费端&lt;/p> **/ public class Consumer extends Thread &amp;#123; private final KafkaConsumer&lt;Integer, String> consumer; private final String topic; public Consumer(String topic) &amp;#123; Properties properties = new Properties(); properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.86.128:9092\"); properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);// 设置offset 自动提交 properties.put(ConsumerConfig.GROUP_ID_CONFIG, \"test\"); properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000); properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 30000); properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName()); properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\"); // 当前groupid来说，消息的offset从最早的消息开始消费 consumer = new KafkaConsumer&lt;Integer, String>(properties); this.topic = topic; &amp;#125; @Override public void run() &amp;#123; while (true) &amp;#123; consumer.subscribe(Collections.singleton(this.topic)); ConsumerRecords&lt;Integer, String> records = consumer.poll(Duration.ofSeconds(1)); records.forEach(record -> &amp;#123; System.out.println(\"key:\" + record.key() + \"--value: \" + record.value() + \"--offset: \" + record.offset()); &amp;#125;); &amp;#125; &amp;#125; public static void main(String[] args) &amp;#123; new Consumer(\"test\").start(); &amp;#125; &amp;#125; 异步发送Kafka 对于消息的发送，可以支持同步和异步, 前面演示的案例中,我们是基于同步发送消息, 同步会需要阻塞, 而异步不需要等待阻塞的过程. 从本质上来说, Kafka 都是采用异步的方式来发送消息到broker, 但是kafka 并不是每次都发送消息都会直接发送到broker, 而是把消息放到了一个发送队列中, 然后通过一个后台线程不断从队列取出消息进行发送,发送成功后悔触发callback。 Kafka 客户端会积累一定量的消息统一组装成一个批量消息发送出去, 触发条件是前面提到的 batch.size和 linger.ms. 而同步发送的方法, 无非就是通过 future.get() 来等待消息的发送返回结果, 但是这种方法会严重影响消息发送的性能. @Override public void run() &amp;#123; int num = 0; try &amp;#123; while (num &lt; 50) &amp;#123; String msg = \"test msg : \" + num; producer.send(new ProducerRecord&lt;>(topic, msg), new Callback() &amp;#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &amp;#123; System.out.println(\"callback-> offset: \" + recordMetadata.offset() + \"--partition: \" + recordMetadata.partition()); &amp;#125; &amp;#125;); TimeUnit.SECONDS.sleep(2); num++; &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; batch.size生产者发送多个消息到broker 的同一个分区的时候, 为了减少网络请求带来的性能开销, 通过批量的方式来提交信息, 可以通过这个参数来控制批量提交的字节数大小, 默认大小是 16384byte, 也就是16kb, 意味着当一批消息大小达到指定的batch.size 的时候会统一发送. linger.msProducer 默认会把两次发送时间间隔内收到的所有Requests 进行一次聚合然后进行发送, 以此提高吞吐量, 而linger.ms 及时为每次发送到broker 的请求增加一些delay, 以此来聚合更多的Message 请求. 这个有点像TCP里面的Nagle算法, 在TCP 协议的传输中, 为了减少大量小数据包的发送,采用了Nagle 算法, 也就是基于小包的等-停协议. batch.size和linger.ms 这两个参数是Kafka 性能优化的关键参数, 当二者都配置的时候, 只要满足其中一个要求, 都会发送请求到Broker. 一些基础配置分析group.idconsumer group 是Kafka 提供的可扩展且具有容错性的消费机制. 既然是一个组, 那么组内必然可以有多个消费者或者消费者实例, 他们共享一个公共 的ID， 即Group ID. 组内的所有消费者协调在一起来消费订阅主题(subscribed topics) 的所有分区(partition). 当然, 每个分区只能由一个消费者组内的一个 consumer 来消费。 如下图所示： 分别有三个消费者, 属于两个不同的group, 那么对于firstTopic 这个topic 来说, 这两个组的消费者都能同时消费这个topic 的消息, 对于此时的架构来说, 这个firstTopic 就类似于ActiveMQ 中的topic 概念. 如下图所示, 如果这三个消费者都属于同一个group, 那么此时firstTopic 就是一个Queue 的概念。 enable.auto.commit消费者消费消息之后自动提交, 只有当消息提交后, 该消息才不会被再次接收到， 还可以配合auto.commit.interval.ms 控制自动提交的频率. 当然, 我们也可以通过consumer.commitSync() 的方式实现手动提交. auto.offset.reset这个参数是针对新的group Id 中的消费者而言, 当有新的groupId 的消费者来消费指定的topic 时, 对于该参数的配置, 会有不同的语义. auto.offset.reset=latest的情况下, 新的消费者将会从其他消费者最后消费的 offset 处开始消费Topic 下的消息 auto.offset.reset= earliest 的情况下, 新的消费者会从该topic 最早的消息进行消费. auto.offset.reset=none的情况下, 新的消费者加入后, 如果之前不存在offset,则会直接抛出异常. max.poll.records此设置限制每次调用poll返回的消息数，这样可以更容易的预测每次poll 间隔要处理的最大值，通过调整此值, 可以减少poll 间隔. Spring 整合KafkaSpringBoot 的版本和Kafka的版本有一个对照表格，如果没有按照正确的版本引入, 那么会存在版本问题导致 ClassNotFound 的问题, 具体请参考 https://spring.io/projects/spring-kafka Jar 依赖 &lt;dependency> &lt;groupId>org.springframework.kafka&lt;/groupId> &lt;artifactId>spring-kafka&lt;/artifactId> &lt;/dependency> 生产者package com.kafka; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.kafka.core.KafkaTemplate; import org.springframework.stereotype.Component; /** * @author luyanan * @since 2019/12/27 * &lt;p>生产者&lt;/p> **/ @Component public class KafkaProducer &amp;#123; @Autowired private KafkaTemplate kafkaTemplate; public void send(String msg) &amp;#123; kafkaTemplate.send(\"spring-test\", \"key\", \"msgData:\" + msg); &amp;#125; &amp;#125; 消费者package com.kafka; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; import java.util.Optional; /** * @author luyanan * @since 2019/12/27 * &lt;p>消费者&lt;/p> **/ @Component public class KafkaConsumer &amp;#123; @KafkaListener(topics = &amp;#123;\"spring-test\"&amp;#125;) public void listener(ConsumerRecord record) &amp;#123; Optional&lt;Object> optional = Optional.ofNullable(record.value()); if (optional.isPresent()) &amp;#123; System.out.println(\"接受到的消息为: \" + optional.get()); &amp;#125; &amp;#125; &amp;#125; 配置文件spring.kafka.bootstrap-servers=192.168.86.128:9092 spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer spring.kafka.consumer.group-id=spring-test-group spring.kafka.consumer.auto-offset-reset=earliest spring.kafka.consumer.enable-auto-commit=true spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer spring.kafka.listener.missing-topics-fatal=false 测试package com.kafka; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.ConfigurableApplicationContext; @SpringBootApplication public class SpringKafkaApplication &amp;#123; public static void main(String[] args) &amp;#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(SpringKafkaApplication.class, args); KafkaProducer producer = applicationContext.getBean(KafkaProducer.class); for (int i = 0; i &lt; 30; i++) &amp;#123; producer.send(i + \"\"); try &amp;#123; Thread.sleep(3000); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 原理分析从前面的整个演示过程来看, 只要不是超大规模的使用Kafka, 那么基本上就没什么大问题, 否则, 对于Kafka 本身的运维本身的挑战难度很多, 同时,针对每一个参数的调优也显得很重要. 关于Topic和PartitionTopic在Kafka中, Topic 是一个存储消息的逻辑概念, 可以认为是一个消息集合, 每条消息发送到Kafka 集群的消息都有一个类别。物理上说, 不同的topic 是分开存储的. 每个topic 可以有多个生产者向它发送消息, 也可以有多个消费者去消费其中的消息. Partition每个topic 可以划分为多个分区(每个Topic 至少有一个分区), 同一个topic 下的不同分区包含的消息是不同的, 每个消息在被添加到分区时, 都会被分配一个 offset(称之为偏移量), 它是消息在此分区中的唯一编号, kafka通过offset 保证消息在分区内的顺序, offset的顺序不跨分区, 即Kafka 只能保证在同一个分区内的消息是有序的 下图中, 对于名字为test的 topic ,做了三个分区, 分别是p0,p1,p2 每条消息发送到broker的时候, 会根据partition 的规则选择存储到哪一个partition. 如果partition 规则设置合理, 那么所有的消息都会均匀的分布在不同的partition中, 这样就类似数据库的分库分表的概念,把数据做了分片处理. Topic和Partition 的存储Partition 是以文件的形式存储在文件系统中,必须创建一个名为firstTopic的topic,其中有三个partition, 那么在kafka 的数据目录(/tmp/kafka-logs) 中就有三个目录, firstTopic-0-3, 命名规则是 &lt;topic_name&gt;-&lt;partition_id&gt; sh kafka-topics.sh –create –zookeeper 192.168.11.156:2181–replication-factor 1 –partitions 3 –topic firstTopic 关于消息分发Kafka 消息分发策略消息是kafka 中最基本的数据单位, 在kafka中, 一条消息是由 key、value 两部分构成, 在发送一条消息时,我们可以指定这个key, 那么producer 会根据key和partition 机制来判断当前这条消息应该发送并且存储到哪个partition, 我们可以根据需要进行扩展producer 的partition. 代码演示自定义partitionpackage com.mq.kafka.demo; import org.apache.kafka.clients.producer.Partitioner; import org.apache.kafka.common.Cluster; import org.apache.kafka.common.PartitionInfo; import java.util.List; import java.util.Map; import java.util.Random; /** * @author luyanan * @since 2019/12/28 * &lt;p>自定义Partition&lt;/p> **/ public class MyPartitioner implements Partitioner &amp;#123; private Random random = new Random(); @Override public int partition(String s, Object o, byte[] bytes, Object o1, byte[] bytes1, Cluster cluster) &amp;#123; // 获取集群中指定topic 的所有分区信息 List&lt;PartitionInfo> partitionInfos = cluster.partitionsForTopic(s); int size = partitionInfos.size(); int partitionNum = 0; if (o == null) &amp;#123; partitionNum = random.nextInt(size); &amp;#125; else &amp;#123; partitionNum = Math.abs(o1.hashCode()) % size; &amp;#125; System.out.println(\"key->\" + o + \":value->\" + o1 + \":send to partition->\" + partitionNum); return partitionNum; &amp;#125; @Override public void close() &amp;#123; &amp;#125; @Override public void configure(Map&lt;String, ?> map) &amp;#123; &amp;#125; &amp;#125; 发送端代码添加到自定义分区package com.mq.kafka.demo; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.common.serialization.IntegerSerializer; import org.apache.kafka.common.serialization.StringSerializer; import java.util.Properties; /** * @author luyanan * @since 2019/12/28 * &lt;p>自定义Partition&lt;/p> **/ public class KafkaProducerDemo &amp;#123; private final String topic; private final boolean isAysnc; private final KafkaProducer&lt;Integer, String> producer; public KafkaProducerDemo(String topic, boolean isAysnc) &amp;#123; this.topic = topic; this.isAysnc = isAysnc; Properties config = new Properties(); config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.86.128:9092\"); config.put(ProducerConfig.CLIENT_ID_CONFIG, \"kafkaProduceDemo\"); config.put(ProducerConfig.ACKS_CONFIG, -1); config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName()); config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); config.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class.getName()); producer = new KafkaProducer&lt;Integer, String>(config); &amp;#125; &amp;#125; 消息的默认分发机制默认情况下, kafka 采用的是hash 取模的分区算法, 如果key为null, 则会随机分配一个分区, 这个随机是在这个参数 metadata.max.age.ms 的时间范围内随机选择一个. 对于这个时间段内, 如果key 为null, 则只会发送到唯一的分区, 这个值默认的情况下是10分钟更新一次. 关于Metadata, 简单理解就是Topic/Partition和Broker 的映射关系, 每一个topic 的每一个partition , 需要知道对应的broker 列表是什么? leader 是谁？ follower 是谁. 这些信息都是存储在Metadata 这个类中. 消费端如何消费指定的分区通过下面的代码, 就可以消费指定该topic 下的0号分区, 其他分区的数据就无法接受 TopicPartition topicPartition = new TopicPartition(this.topic, 0); consumer.assign(Arrays.asList(topicPartition)); 消息的消费原理Kafka消息消费原理演示在实际生产过程中, 每个topic 都会有多个partition, 多个partition 的好处在于, 一方面能够对broker 上的数据进行分片有效减少了消息的容错从而提升了io性能. 另一方面, 为了提高消费端的消费能力, 一般会通过多个consumer 去消费同一个topic, 也就是消费端的负载均衡机制, 也就是我们接下来要了解的, 在多个partition以及多个consumer 的情况下,消费者是如何消费消息的. 同时，我们知道kafka 存在consumer group 的概念, 也就是group.id 一样的consumer 属于一个consumer group, 组内的所有消费者协调在一起来消费订阅主题的所有分区. 当然每一个分区只能由同一个消费组内的consumer 来消费, 那么在同一个consumer group 里面的consumer 是怎么去分配该消费哪个分区里的数据呢? 如下图所示:3个分区、3个消费者, 那么哪个消费者消费哪个分区? 对于上面这个图来说, 这3个消费者会分别消费test 这个 topic 的3个分区, 也就是每个consumer 消费一个partition. 代码演示(3个partition 对应3个consumer) 创建一个带3个分区的topic 启动3个消费者消费同一个topic, 并且这3个consumer 属于同一个组 启动发送者进行消费发送 演示结果：consumer1会消费partition0分区、consumer2会消费partition1分区、consumer3会消费 partition2分区 如果是2个consumer消费3个partition呢？会是怎么样的结果？ 代码演示(3个partition 对应2个consumer) 基于上面演示的案例的topic 不变 启动2个消费者消费该topic 启动发送者进行发送消息 演示结果: consumer1会消费partition0和partition1分区, consumer2 会消费partition2分区. 代码演示(3个partition 对应4个或者4个以上的consumer) 演示结果: 仍然只有3个consumer 对应3个partition, 其他的consumer 无法消费消息. 通过这个演示的过程，希望引入接下来需要了解的kafka的分区策略(Partition Assignment Strategy) consumer和partition的数量建议 如果consumer 比partition多,是浪费, 因为kafka 的设计时是在一个partition 上是不允许转发的, 所以consumer 数不要大于partition数 如果consumer数比partition少, 一个consumer 会对应几个partition, 这里主要合理分配consumer数和partition数,否则会导致partition 里面的数据被取的不均匀. 最好partition 数目是consumer 数目的整数倍, 所以partition 的数目很重要, 比如取24, 就很容易设定consumer 的数目. 如果consumer 上多个partition 读取数据, 不保证数据间的顺序性, kafka 只保证在一个partition 上数据是有序的,但是多个partition, 根据你读的顺序会有所不同. 增减consumer ,broker\\partition 会导致 rebalance, 所以rebalance 后consumer 对应的 partition 会发生变化. 思考: 什么时候会触发这个策略呢?当出现这几种情况时, kafka 会进行一次分区分配操作, 也就是 kafka consumer 的 rebalance 同一个consumer group 内新增了消费者 消费者离开当前所属的consumer group,比如主动停机或者宕机 topic 新增加了分区(也就是分区数量发生了变化) kafka consumer 的rebalance 机制规定了一个 consumer group 下的 所有consumer 如何达成一致来分配订阅topic 的每个分区, 而具体如何执行分区策略,就是前面提到过的两种内置的分区策略. 而kafka 对于分配策略这块, 提供了可拔插的实现方式, 也就是说, 除了这两种之外, 我们还可以创建自己的分区机制. 什么是分区分配策略通过前面的案例演示, 我们应该能猜到, 同一个group 中的消费者对于一个topic 中的多个partition, 存在一定的分区分配策略. 在kafka 中, 存在三种分区分配策略, 一种是Range(默认), 另一种是RoundRobin(轮询), StickyAssignor(粘性). 在消费端中的consumerConfig 中, 通过这个属性来指定分区分配策略. public static final String PARTITION_ASSIGNMENT_STRATEGY_CONFIG = “partition.assignment.strategy”; RangeAssignor（范围分区）Range 策略是对每个主题而言的, 首先对同一个主题里面的分区按照序号进行排序, 并对消费者按照字母顺序进行排序. 假设n = 分区数/消费者数量 m= 分区数%消费者数量 那么前m个消费者每个分配n+1个分区, 后面的(消费者数量-m) 个消费者每个分配n个分区. 假设我们有10个分区, 3个消费者, 排完序的分区会是0,1,2,3,4,5,6,7,8,9; 消费者线程排完序将会是C1-0,C2-0,C3-0； 然后将partition的个数除以消费者线程的总数来决定每个消费者线程消费几个分区. 如果除不尽, 那么前面几个消费者将会多消费一个分区. 在我们的例子中,我们有10个分区， 3个消费者, 10/3 =3 而且除不尽,那么消费者线程C1-0 就会多消费一个分区. **结果看起来是这样的: ** C1-0 将消费0,1,2,3 分区 C2-0 将消费4,5,6 分区 C3-0 将消费7,8,9 分区 假设我们有11个分区, 那么最后分区分配的结果看起来是这样的: C1-0 将消费0,1,2,3 分区 C2-0 将消费4,5,6 分区 C3-0 将消费7,8,9 分区 假设我们有2个主题(T1,T2), 分别有10个分区, 那么最后分区分配的结果是这样的: C1-0 将消费T1主题的0,1,2,3 分区以及T2主题的0,1,2,3分区 C2-0 将消费T1主题的4,5,6,分区和T2主题的4,5,6分区 C3-0将消费T1主题的7,8,9分区和T2主题的7,8,9分区 可以看出, C1-0 消费者线程比其他消费者线程多消费了2个分区, 这就是Range strategy的一个很明显的弊端. RoundRobinAssignor（轮询分区）轮询分区策略是把所有的protition 和所有的consumer 线程都列出来, 然后按照hashcode 进行排序. 最后通过轮询算法分配partition 给消费者线程. 如果所有的consumer 实例的订阅是相同的, 那么partition 会均匀分布. 在我们的例子里面, 假如按照hashcode 排序完的top-partition 组依次为T1-5, T1-3, T1-0, T1-8, T1- 2, T1-1, T1-4, T1-7, T1-6, T1-9，我们的消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果 为： C1-0 将消费 T1-5, T1-2, T1-6 分区； C1-1 将消费 T1-3, T1-1, T1-9 分区； C2-0 将消费 T1-0, T1-4 分区； C2-1 将消费 T1-8, T1-7 分区； 使用轮询分区策略必须满足两个条件: 每个主题的消费者实例具有相同数量的流 每个消费者订阅的主题必须是相同的. StrickyAssignor 分配策略kafka 在0.11X 版本中支持了 StrickyAssignor,翻译过来叫 粘滞策略,他主要有两个目的: 分区的分配尽可能的均匀 分区的分配尽可能的和上次分配保持相同. 当两者发生冲突的时候, 第一个目标优先于第二个目标. 鉴于这两个目标, StrickyAssignor 分配策略的具体实现要比RangeAssignor和RoundRobinAssi gn or 这两种分配策略要复杂的多, 假设我们有这样一个场景: 假设消费组有3个消费者：C0,C1,C2，它们分别订阅了4个Topic(t0,t1,t2,t3),并且每个主题有两个分 区(p0,p1),也就是说，整个消费组订阅了8个分区：tOpO 、 tOpl 、 tlpO 、 tlpl 、 t2p0 、 t2pl 、t3p0 、 t3pl 那么最终的分配场景结果为 CO: tOpO、tlpl 、 t3p0 Cl: tOpl、t2p0 、 t3pl C2: tlpO、t2pl 这种分配方式有点类似于轮询策略，但实际上并不是，因为假设这个时候，C1这个消费者挂了，就势必会造成 重新分区（reblance），如果是轮询，那么结果应该是 CO: tOpO、tlpO、t2p0、t3p0 C2: tOpl、tlpl、t2pl、t3pl 然后，strickyAssignor它是一种粘滞策略，所以它会满足分区的分配尽可能和上次分配保持相同，所以 分配结果应该是 消费者CO: tOpO、tlpl 、 t3p0、t2p0 消费者C2: tlpO、t2pl、tOpl、t3pl 也就是说，C0和C2保留了上一次是的分配结果，并且把原来C1的分区分配给了C0和C2。 这种策略的好处是 使得分区发生变化时，由于分区的“粘性，减少了不必要的分区移动 谁来执行 rebalance 以及管理consumer 的group 呢?kafka 提供了一个角色: coordinator 来执行对consumer group 的管理. 当 consumer group 的第一个consumer 启动的时候, 它会去和kafka server 确定谁是他们组的coordinator.之后该group 内的所有成员都和该coordinator 进行协调通信. 如何确定coordinatorconsumer group 如何确定自己的coordinator 是谁呢? 消费者向kafka 集群中的任意一个broker 发送一个GroupCoordinatorRequest 请求, 服务端会返回一个负载最小的broker 节点的id, 并将该broker 设置为coordinator JoinGroup 的过程在rebalance 之前, 需要保证coordinator 是已经确定好的, 整个 rebalance 的过程分为两个步骤: Join和Sync Join表示加入到consumer group 中, 在这一步, 所有的成员都会向 coordinator 发送 joinGroup的请求. 一旦所有成员都发送了joinGroup 请求, 那么coordinator 会选择一个 consumer 担任leader角色, 并把组成员信息和订阅信息发送到消费者. leader 选举算法比较简单, 如果消费组内没有leader, 那么第一个加入消费组的消费者就是消费者的leader,如果这个时候leader 消费者推出了消费组, 那么重新选举一个leader, 这个选举很随意, 类似与随机算法. protocol_metadata: 序列化后的消费者的订阅消息 leader_id: 消费组中的消费者, coordinator 会选择一个作为leader, 对应的就是member_id member_metadata : 对应消费者的订阅信息 members: consumer group 中全部的消费者的订阅信息 generation_id: 年代信息, 类似于zookeeper 的epoch 是一样的, 对于每一轮rebalance, generation_id 都会递增. 主要用来保护consumer group. 隔离无效的offset, 也就是上一轮的consumer 成员无法提交offset 到新的 consumer group. 每个消费者都可以设置自己的分区分配策略, 对于消费组而言, 会从各个消费者上报过来的分区分配策略中选举一个彼此都赞同的策略来实现整体的分区分配, 这个”赞同” 的策略是: 消费组内的各个消费者会通过投票来决定. 在joingroup 阶段, 每个consumer 都会把自己支持的分区分配策略发送到coordinator coordinator 收集到所有消费者的分配策略, 组成一个候选集. 每个消费者需要从候选集中找出一个自己支持的策略,并且为这个策略投票. 最终计算候选集中各个策略的选票数, 票数最多的就是当前消费组的分配策略. Synchronizing Group State阶段完成分区分配之后, 就进入了Synchronizing Group State阶段, 主要逻辑是向GroupCoordinator 发送SyncGroupRequest 请求, 并且处理 SyncGroupResponse 响应. 简单来说, 就是leader 将消费者对应的partition 分配方案同步给 consumer group 中的所有 consumer. 每个消费者都回向coordinator 发送syncgroup 请求, 不过只有leader 节点会发送分配方案, 其他消费者只是打打酱油而已. 当leader 把方案发给 coordinator 之后, coordinator 会把结果设置到SyncGroupResponse 中, 这样所有的成员都知道自己应该消费哪个分区. consumer group 的分区分配方案是在客户端执行的, kafka 将这个权利下发给客户端主要是因为这样有很好的灵活性. 总结我们再来总结一下consumer group rebalance 的过程 对于每个consumer group 子集, 都会在服务端对应一个GroupCoordinator 进行管理. GroupCoordinator 会在zookeeper 上添加watcher, 当消费者加入或者退出consumer group的时候, 会修改zookeeper 上修改的数据, 从而触发 GroupCoordinato 开始Rebalance 操作. 当消费者准备加入某个 consumer group 或者GroupCoordinator发生故障的时候, 消费者并不知道 GroupCoordinator 在网络中的位置, 这个时候就需要确定 GroupCoordinator, 消费者会向集群中的任意一个broker 节点发送ConsumerMetadataRequest 请求,收到请求的broker 会返回一个response 作为响应. 其中包含管理当前ConsumerGroup的GroupCoordinator. 消费者会根据broker 的返回信息, 连接到GroupCoordinator , 并且发送HeartbeatRequest. 发送心跳的目的是为了保证 GroupCoordinator 这个消费者是正常在线的. 当消费者在指定的时间内没有发送心跳请求，则 GroupCoordinator 会出发 rebalance 操作. 发起join group 请求的两种情况 如果GroupCoordinator 返回的心跳包数据包含异常,说明GroupCoordinator 因为前面说的集中情况导致了rebalance 操作, 那这个时候，consumer 会发起 join group操作. 新加入的consumer group 的consumer 确定好了GroupCoordinator 之后. 消费者会向GroupCoordinator 发起join group 请求, GroupCoordinator 会收集全部消费者信息之后, 来确认可用的消费者, 并从中选取一个消费者成为group leader. 并把相应的信息(分区分配策略、leader_id…) 封装成一个response返回给所有的消费者. 但是只有group leader 会受到当前consumer group 中的所有消费者信息, 当消费者确定自己是 group leader后, 会根据消费者信息以及选定分区分配策略进行分区分配. 接着进入Synchronizing Group State 阶段, 每个消费者会发送SyncGroupRequest 请求到GroupCoordinator , 但是只有group leader 的请求会存在分区分配结果, GroupCoordinator 会根据group leader 的分区分配结果形成 SyncGroupResponse 返回给所有的consumer consumer 根据分配结果, 执行相应的操作. 到这里来说, 我们已经知道了消息的发送分区策略, 以及消费者的分区消费策略和rebalance. 对于应用层面来说, 还有一个最重要的东西还没有讲解, 就是offset, 它类似于一个游标, 表示当前消费的消息的位置. 如何保存消费端的消费位置什么是offset前面在讲解partition的时候, 提到过offset, 每个topic 可以划分多个分区(每个topic 至少有一个分区). 同一个topic 下的不同分区包含的消息是不同的.每个消息在被添加到分区的时候, 都会被分配一个offset(称之为偏移量), 它是消息在此分区中的唯一编号， kafka通过offset保证消息在分区内的顺序, offset 的顺序不跨分区, 即kafka 只保证在同一个分区的消息是有序的. 对于应用层的消费来说,每次消费一个消息并且提交后, 会保存当前消费到的最近的一个offset, 那么offset 保存到哪里呢? offset 在哪里维护在kafka 中,提供了一个consumer_offsets_ 的一个topic，把offset信息写入到这个topic中, consumer_offset_ 保存了每个consumer group 某个时刻提交的offset 信息. 根据前面我们演示的案例, 我们设置了一个KafkaConsumerDemo的group id . 首先我们需要找到这个 consumer_group 保存在哪个分区. properties.put(ConsumerConfig.GROUP_ID_CONFIG,”KafkaConsumerDemo”); 计算公式: Math.abs(“groupid”.hashCode())%groupMetadataTopicPartitionCount ; 由于默认情况下 groupMetadataTopicPartitionCount有50个分区，计算得到的结果为:35, 意味着当前的 consumer_group的位移信息保存在__consumer_offsets的第35个分区 执行如下命令, 可以查看当前consumer_group中的offset 位移提交的信息 kafka-console-consumer.sh --topic __consumer_offsets --partition 15 -- bootstrap-server 192.168.86.128:9092 --formatter 'kafka.coordinator.group.GroupMetadataManager$OffsetsMessageFormatter' 从输出结果中,我们就可以知道这个topic 的offset的位移日志.","categories":[{"name":"kafka","slug":"kafka","permalink":"https://rainsoil.github.io/categories/kafka/"},{"name":"微服务","slug":"kafka/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"kafka/微服务/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"kafka","slug":"kafka/微服务/微服务/kafka","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/kafka/"}],"tags":[]},{"title":"Dubbo源码之服务通信以及负载均衡","slug":"微服务/dubbo/Dubbo源码之服务通信以及负载均衡","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/dubbo-yuan-ma-zhi-fu-wu-tong-xin-yi-ji-fu-zai-jun-heng/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/dubbo-yuan-ma-zhi-fu-wu-tong-xin-yi-ji-fu-zai-jun-heng/","excerpt":"","text":"Dubbo源码之服务通信和负载均衡客户端生成的proxy消费者初始化完成后, 会生成一个proxy, 而这个proxy 本质上是一个动态代理类. JavassistProxyFactory.getProxy public T getProxy(Invoker invoker, Class[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); &#125; 首先我们来分解一下, 这个invoker 实际上是: MockClusterWrapper(FailoverCluster(directory)), 然后通过 InvokerInvocationHandler 做了一层包装变成了 InvokerInvocationHandler(MockClusterWrapper(FailoverCluster(directory))). proxy.getProxy这个方法里面, 会生成一个动态代理的方法, 我们通过 debug 可以看到动态字节码的拼接过程, 它代理了当前这个接口的方法 info, 并且方法里面是使用 handler.invoke 进行调用的. public java.lang.String info(java.lang.String arg0)&amp;#123; Object[] args = new Object[1]; args[0] = ($w)$1; Object ret = handler.invoke(this, methods[0], args); return (java.lang.String)ret; &amp;#125; 消费端调用的过程handler 的调用链路为: InvokerInvocationHandler(MockClusterWrapper(FailoverCluster(directory))) 图解调用链 InvokerInvocationHandler.invoke这个方法主要判断当前调用的远程方法, 如果是 toString、hashcode、equals, 就直接返回. 否则, 调用 invoke.invoke 进入到 MockClusterWrapper.invoke 方法. @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; String methodName = method.getName(); Class&lt;?>[] parameterTypes = method.getParameterTypes(); if (method.getDeclaringClass() == Object.class) &amp;#123; return method.invoke(invoker, args); &amp;#125; if (\"toString\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &amp;#123; return invoker.toString(); &amp;#125; if (\"hashCode\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &amp;#123; return invoker.hashCode(); &amp;#125; if (\"equals\".equals(methodName) &amp;&amp; parameterTypes.length == 1) &amp;#123; return invoker.equals(args[0]); &amp;#125; // return invoker.invoke(new RpcInvocation(method, args)).recreate(); &amp;#125; MockClusterInvoker.invokeMock, 这里面有两个逻辑: 是否客户端强制配置了 mock调用, 那么在这种场景中主要用来解决服务端还没开发好的时候直接使用本地数据进行测试. 是否出现了异常,如果出现异常则使用配置好的Mock类来实现服务的降级. @Override public Result invoke(Invocation invocation) throws RpcException &amp;#123; Result result = null; // 从url 中获取 MOCK_KEY 对应的key String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), MOCK_KEY, Boolean.FALSE.toString()).trim(); if (value.length() == 0 || value.equalsIgnoreCase(\"false\")) &amp;#123; //no mock // 如果没有配置mock, 则直接传递给下个invoke 调用. result = this.invoker.invoke(invocation); &amp;#125; else if (value.startsWith(\"force\")) &amp;#123; // 如果强制为本地调用, 则执行 mockinvoke if (logger.isWarnEnabled()) &amp;#123; logger.warn(\"force-mock: \" + invocation.getMethodName() + \" force-mock enabled , url : \" + directory.getUrl()); &amp;#125; //force:direct mock result = doMockInvoke(invocation, null); &amp;#125; else &amp;#123; //fail-mock try &amp;#123; result = this.invoker.invoke(invocation); &amp;#125; catch (RpcException e) &amp;#123; if (e.isBiz()) &amp;#123; throw e; &amp;#125; if (logger.isWarnEnabled()) &amp;#123; logger.warn(\"fail-mock: \" + invocation.getMethodName() + \" fail-mock enabled , url : \" + directory.getUrl(), e); &amp;#125; result = doMockInvoke(invocation, e); &amp;#125; &amp;#125; return result; &amp;#125; AbstractClusterInvoker.invoke下一个invoke, 应该是进入FailoverClusterInvoke,但是这里它又用到了模板方法, 所以直接进去到父类的invoke方法. 绑定 attachments, Dubbo 中, 可以通过 RpcContext 上的 setAttachment 和 getAttachment 在服务消费方和提供方之间进行参数的隐形传递, 所以这段代码中会去绑定 attachments. RpcContext.getContext().setAttachment(“index”, “1”) 通过list 获取 invoke 列表, 这个列表基本可以猜测到从 directory 里面获取到, 但是这里面还实现了服务路由的逻辑, 简单来说,就是先拿到invoke 列表,然后通过 route 进行服务路由,筛选出符合路由规则的服务提供者, initLoadBalance 初始化负载均衡机制 执行 doInvoke @Override public Result invoke(final Invocation invocation) throws RpcException &amp;#123; checkWhetherDestroyed(); // binding attachments into invocation. Map&lt;String, String> contextAttachments = RpcContext.getContext().getAttachments(); if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) &amp;#123; ((RpcInvocation) invocation).addAttachments(contextAttachments); &amp;#125; List&lt;Invoker&lt;T>> invokers = list(invocation); LoadBalance loadbalance = initLoadBalance(invokers, invocation); RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance); &amp;#125; initLoadBalance不用看这个代码, 基本才能猜测到, 会从url 中获取到当前的负载均衡算法, 然后使用SPI机制来获取负载均衡的扩展点, 然后返回一个具体的实现. protected LoadBalance initLoadBalance(List&lt;Invoker&lt;T>> invokers, Invocation invocation) &amp;#123; if (CollectionUtils.isNotEmpty(invokers)) &amp;#123; return ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(RpcUtils.getMethodName(invocation), LOADBALANCE_KEY, DEFAULT_LOADBALANCE)); &amp;#125; else &amp;#123; return ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(DEFAULT_LOADBALANCE); &amp;#125; &amp;#125; FailoverClusterInvoker.doInvoke这段代码里面是实现容错的逻辑. 获取重试的次数,并且进行循环 获取目标服务, 并记录当前已经调用过的目标服务,防止下次继续将请求发送过去. 如果执行成功, 则返回结果. 如果出现异常,判断是否为业务异常,如果是, 则抛出. 否则, 进行下一次重试. 这里的 invoke 是provider 的一个可调用 service的抽象, invoke 封装了 provider 地址以及 service 接口信息. Directory 代表多个 Invoker , 可以看到 List&lt;Invoker&gt;,但是与 List 不同的是, 它的值可能是动态变化的, 比如 注册中心推送变更. Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker , 对上层透明, 伪装过程包含了容错逻辑, 调用失败后, 重试另一个. LoadBalance 负责从多个 Invoker 中选出一个用于本地调用, 选的过程包含了负载均衡算法, 失败调用后, 需要重选. @Override @SuppressWarnings(&amp;#123;\"unchecked\", \"rawtypes\"&amp;#125;) public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T>> invokers, LoadBalance loadbalance) throws RpcException &amp;#123; List&lt;Invoker&lt;T>> copyInvokers = invokers; checkInvokers(copyInvokers, invocation); String methodName = RpcUtils.getMethodName(invocation); int len = getUrl().getMethodParameter(methodName, RETRIES_KEY, DEFAULT_RETRIES) + 1; if (len &lt;= 0) &amp;#123; len = 1; &amp;#125; // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T>> invoked = new ArrayList&lt;Invoker&lt;T>>(copyInvokers.size()); // invoked invokers. Set&lt;String> providers = new HashSet&lt;String>(len); for (int i = 0; i &lt; len; i++) &amp;#123; //Reselect before retry to avoid a change of candidate `invokers`. //NOTE: if `invokers` changed, then `invoked` also lose accuracy. if (i > 0) &amp;#123; checkWhetherDestroyed(); copyInvokers = list(invocation); // check again checkInvokers(copyInvokers, invocation); &amp;#125; // 通过 负载均衡获取目标 invoke Invoker&lt;T> invoker = select(loadbalance, invocation, copyInvokers, invoked); // 记录已经调用过的服务, 下次调用会进行过滤. invoked.add(invoker); RpcContext.getContext().setInvokers((List) invoked); try &amp;#123; // 服务调用成功, 直接返回结果. Result result = invoker.invoke(invocation); if (le != null &amp;&amp; logger.isWarnEnabled()) &amp;#123; logger.warn(\"Although retry the method \" + methodName + \" in the service \" + getInterface().getName() + \" was successful by the provider \" + invoker.getUrl().getAddress() + \", but there have been failed providers \" + providers + \" (\" + providers.size() + \"/\" + copyInvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le); &amp;#125; return result; &amp;#125; catch (RpcException e) &amp;#123; // 如果是业务异常, 直接抛出不进行重试. if (e.isBiz()) &amp;#123; // biz exception. throw e; &amp;#125; // 记录异常信息, 进行下一次循环 le = e; &amp;#125; catch (Throwable e) &amp;#123; le = new RpcException(e.getMessage(), e); &amp;#125; finally &amp;#123; providers.add(invoker.getUrl().getAddress()); &amp;#125; &amp;#125; throw new RpcException(le.getCode(), \"Failed to invoke the method \" + methodName + \" in the service \" + getInterface().getName() + \". Tried \" + len + \" times of the providers \" + providers + \" (\" + providers.size() + \"/\" + copyInvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le.getCause() != null ? le.getCause() : le); &amp;#125; 负载均衡select在调用 invoke.invoke 之前, 会需要通过select 选择一个合适的服务进行调用, 而这个选择的过程其实就是负载均衡的实现. 所有负载均衡实现类都继承自 AbstractLoadBalance, 该类实现了LoadBalance 接口, 并封装了一些公共的逻辑, 所以在分析负载均衡之前, 先来看看 AbstractLoadBalance 的逻辑, 首先来看 负载均衡的入口方法 select,如下： @Override public &lt;T> Invoker&lt;T> select(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &amp;#123; if (CollectionUtils.isEmpty(invokers)) &amp;#123; return null; &amp;#125; // 如果 invokers 列表中仅有一个invoker, 直接返回即可. 无需进行负载均衡. if (invokers.size() == 1) &amp;#123; return invokers.get(0); &amp;#125; // 调用 doSelect 方法进行负载均衡, 该方法为抽象方法, 由子类实现 return doSelect(invokers, url, invocation); &amp;#125; 负载均衡的子类实现由四个, 默认情况下是 RandomLoadBalance RandomLoadBalance @Override protected &lt;T> Invoker&lt;T> doSelect(List&lt;Invoker&lt;T>> invokers, URL url, Invocation invocation) &amp;#123; // Number of invokers int length = invokers.size(); // Every invoker has the same weight? boolean sameWeight = true; // the weight of every invokers int[] weights = new int[length]; // the first invoker's weight int firstWeight = getWeight(invokers.get(0), invocation); weights[0] = firstWeight; // The sum of weights int totalWeight = firstWeight; // 下面这个循环有两个作用, 第一是计算总权重 totalWeight // 第二是检测每个服务提供者的权重是否相同. for (int i = 1; i &lt; length; i++) &amp;#123; int weight = getWeight(invokers.get(i), invocation); // save for later use weights[i] = weight; // Sum // 累计权重 totalWeight += weight; // 检测当前服务提供者的权重与上一个服务提供者的权重是否相同. // 不相同的话, 则将sameWeight 设置为false if (sameWeight &amp;&amp; weight != firstWeight) &amp;#123; sameWeight = false; &amp;#125; &amp;#125; // 下面的if分支主要用于获取随机数, 并计算随机数落在哪个区间. if (totalWeight > 0 &amp;&amp; !sameWeight) &amp;#123; // If (not every invoker has the same weight &amp; at least one invoker's weight>0), select randomly based on totalWeight. // 随机获取一个 [0,totalWeight] 区间内的数字 int offset = ThreadLocalRandom.current().nextInt(totalWeight); // Return a invoker based on the random value. // 循环让 offset 数减去服务者权重值, 当offset 小于0时, 返回相应的invoke // 举例说明一下，我们有 servers = [A, B, C]，weights = [5, 3, 2]，offset= 7。 // 第一次循环，offset - 5 = 2 > 0，即 offset > 5， // 表明其不会落在服务器 A 对应的区间上。 // 第二次循环，offset - 3 = -1 &lt; 0，即 5 &lt; offset &lt; 8， // 表明其会落在服务器 B 对应的区间上 for (int i = 0; i &lt; length; i++) &amp;#123; // 让随机值 offset 减去权重值 offset -= weights[i]; if (offset &lt; 0) &amp;#123; // 返回相应的invoker return invokers.get(i); &amp;#125; &amp;#125; &amp;#125; // If all invokers have the same weight value or totalWeight=0, return evenly. // 如果所有服务提供者权重值相同, 此时直接随机返回一个即可. return invokers.get(ThreadLocalRandom.current().nextInt(length)); &amp;#125; 通过 RegistryDirectory 中获取的invoke 是什么呢?这个很重要, 因为它决定了接下来的调用过程, 这个时候我们需要去了解这个invoke 是在哪里被初始化的. 可调用的Invoker初始化过程RegistryDirectory在 RegistryDirectory 中有一个成员属性, 保存了服务地址对应的invoke 信息. private volatile Map&gt; urlInvokerMap; toInvokers这个invoke 是动态的, 基于注册中心的变化而变化的, 它的初始化过程的链路是 RegistryDirectory.notify-&gt;refreshInvoker-&gt;toInvokers 下面你的这段代码中： if (invoker == null) &amp;#123; // Not in the cache, refer again try &amp;#123; boolean enabled = true; if (url.hasParameter(DISABLED_KEY)) &amp;#123; enabled = !url.getParameter(DISABLED_KEY, false); &amp;#125; else &amp;#123; enabled = url.getParameter(ENABLED_KEY, true); &amp;#125; if (enabled) &amp;#123; invoker = new InvokerDelegate&lt;>(protocol.refer(serviceType, url), url, providerUrl); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; logger.error(\"Failed to refer invoker for interface:\" + serviceType + \",url:(\" + url + \")\" + t.getMessage(), t); &amp;#125; if (invoker != null) &amp;#123; // Put new invoker in cache newUrlInvokerMap.put(key, invoker); &amp;#125; &amp;#125; else &amp;#123; newUrlInvokerMap.put(key, invoker); &amp;#125; 是基于 protocol.refer 来构建 的invoke, 并且使用 InvokerDelegate 进行了委托, 在 dubboprotoco 中, 是这样构建 invoke的. 返回的是一个 DubboInvoker 对象. @Override public &lt;T> Invoker&lt;T> refer(Class&lt;T> serviceType, URL url) throws RpcException &amp;#123; optimizeSerialization(url); // create rpc invoker. DubboInvoker&lt;T> invoker = new DubboInvoker&lt;T>(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker; &amp;#125; 所以这个invoker 应该是 InvokerDelegate(ProtocolFilterWrapper(ListenerInvokerWrapper(DubboInvoker()) ProtocolFilterWrapper-&gt; 这是一个 invoker 的过滤链路 ListenerInvokerWrapper-&gt; 这里面暂时没做任何的实现 所以我们可以直接看到DubboInvoker 这个类里面 DubboInvokerAbstractInvoker.invoke这里面也是对 Invocation的attachments进行处理，把attachment加入到Invocation中 这里的attachment , 实际上是目标服务的接口信息以及版本信息. DubboInvoker.doInvoker这里面看到一个很熟悉的东西, 就是 ExchangeClient, 这个是客户端和服务端之间的连接. 然后如果当前方法有返回值的话, 也就是 isOneway=false, 则执行else 逻辑, 然后通过异步的形式进行通信. @Override protected Result doInvoke(final Invocation invocation) throws Throwable &amp;#123; RpcInvocation inv = (RpcInvocation) invocation; final String methodName = RpcUtils.getMethodName(invocation); // 将目标方法以及版本号作为参数放入到invocation 中. inv.setAttachment(PATH_KEY, getUrl().getPath()); inv.setAttachment(VERSION_KEY, version); // 获取客户端连接. ExchangeClient currentClient; if (clients.length == 1) &amp;#123; currentClient = clients[0]; &amp;#125; else &amp;#123; currentClient = clients[index.getAndIncrement() % clients.length]; &amp;#125; try &amp;#123; // 判断方法是否有返回值 boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); // 获取超时时间,默认为1s int timeout = getUrl().getMethodParameter(methodName, TIMEOUT_KEY, DEFAULT_TIMEOUT); // 如果没有返回值 if (isOneway) &amp;#123; boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture(null); return AsyncRpcResult.newDefaultAsyncResult(invocation); &amp;#125; else &amp;#123; AsyncRpcResult asyncRpcResult = new AsyncRpcResult(inv); CompletableFuture&lt;Object> responseFuture = currentClient.request(inv, timeout); responseFuture.whenComplete((obj, t) -> &amp;#123; if (t != null) &amp;#123; asyncRpcResult.completeExceptionally(t); &amp;#125; else &amp;#123; asyncRpcResult.complete((AppResponse) obj); &amp;#125; &amp;#125;); RpcContext.getContext().setFuture(new FutureAdapter(asyncRpcResult)); return asyncRpcResult; &amp;#125; &amp;#125; catch (TimeoutException e) &amp;#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &amp;#125; catch (RemotingException e) &amp;#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &amp;#125; &amp;#125; currentClient.requestcurrentClient 实际是一个 ReferenceCountExchangeClient(HeaderExchangeClient()). 所以它的调用链路是 ReferenceCountExchangeClient-&gt;HeaderExchangeClient-&gt;HeaderExchangeChannel-&gt;(request方 法), 最终将构建好的RpcInvocation， 组装到一个request 对象中进行传递. @Override public CompletableFuture&lt;Object> request(Object request, int timeout) throws RemotingException &amp;#123; if (closed) &amp;#123; throw new RemotingException(this.getLocalAddress(), null, \"Failed to send request \" + request + \", cause: The channel \" + this + \" is closed!\"); &amp;#125; // create request. // 创建请求对象 Request req = new Request(); req.setVersion(Version.getProtocolVersion()); req.setTwoWay(true); req.setData(request); DefaultFuture future = DefaultFuture.newFuture(channel, req, timeout); try &amp;#123; channel.send(req); &amp;#125; catch (RemotingException e) &amp;#123; future.cancel(); throw e; &amp;#125; return future; &amp;#125; channel.send的调用链路 AbstractPeer.send -&gt;AbstractClient.send-&gt;NettyChannel.send 通过 NioSocketChannel 把消息发送出去. ChannelFuture future = channel.writeAndFlush(message); 服务端接收消息的处理流程.客户端把消息发送出去之后, 服务端会收到消息,然后把执行的结果返回到客户端 客户端接收到消息服务端这边接受消息的处理链路, 也比较复杂, 我们回到NettyServer 中创建io 的过程. protected void doOpen() throws Throwable &amp;#123; bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory(\"NettyServerBoss\", true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), new DefaultThreadFactory(\"NettyServerWorker\", true)); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;NioSocketChannel>() &amp;#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &amp;#123; // FIXME: should we use getTimeout()? int idleTimeout = UrlUtils.getIdleTimeout(getUrl()); NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ch.pipeline()//.addLast(\"logging\",new LoggingHandler(LogLevel.INFO))//for debug .addLast(\"decoder\", adapter.getDecoder()) .addLast(\"encoder\", adapter.getEncoder()) .addLast(\"server-idle-handler\", new IdleStateHandler(0, 0, idleTimeout, MILLISECONDS)) .addLast(\"handler\", nettyServerHandler); &amp;#125; &amp;#125;); // bind ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel(); &amp;#125; handler 配置的是 nettyServerHandler server-idle-handler 表示心跳处理机制. final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); Handler 与Servlet中的filter 很像, 通过Handler 可以完成通讯报文的解码编码, 拦截指定的报文, 统一对日志错误进行处理, 统一对请求进行计数、控制Handler 执行与否. handler.channelRead()服务端收到读的请求时, 会进入到这个方法. 接着通过 handler.received 来处理msg, 这个handler 的链路很长, 比较复杂，我们需要逐步剖析. @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &amp;#123; handler.received(channel, msg); &amp;#125; finally &amp;#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &amp;#125; &amp;#125; handler-&gt;MultiMessageHandler-&gt;HeartbeatHandler-&gt;AllChannelHandler-&gt;DecodeHandler- &gt;HeaderExchangeHandler-&gt; 最后进入这个方法-&gt; DubboProtocol$requestHandler(receive) MultiMessageHandler: 复合消息处理 HeartbeatHandler: 心跳消息处理， 接受心跳并发送心跳响应 AllChannelHandler: 业务线程转换处理器, 把接受到的消息封装成 ChannelEventRunnable 可执行任务给线程池处理. DecodeHandler:l 业务解码处理器 HeaderExchangeHandler.received交互层请求响应处理, 有三种处理方式: handlerRequest: 双向请求 handler.received 单向请求 handleResponse 响应消息 @Override public void received(Channel channel, Object message) throws RemotingException &amp;#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); final ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &amp;#123; if (message instanceof Request) &amp;#123; // handle request. Request request = (Request) message; if (request.isEvent()) &amp;#123; handlerEvent(channel, request); &amp;#125; else &amp;#123; if (request.isTwoWay()) &amp;#123; handleRequest(exchangeChannel, request); &amp;#125; else &amp;#123; handler.received(exchangeChannel, request.getData()); &amp;#125; &amp;#125; &amp;#125; else if (message instanceof Response) &amp;#123; handleResponse(channel, (Response) message); &amp;#125; else if (message instanceof String) &amp;#123; if (isClientSide(channel)) &amp;#123; Exception e = new Exception(\"Dubbo client can not supported string message: \" + message + \" in channel: \" + channel + \", url: \" + channel.getUrl()); logger.error(e.getMessage(), e); &amp;#125; else &amp;#123; String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() > 0) &amp;#123; channel.send(echo); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; handler.received(exchangeChannel, message); &amp;#125; &amp;#125; finally &amp;#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &amp;#125; &amp;#125; ExchangeHandler.reply接着进入到 ExchangeHandler.reply 这个方法中: 把 message 转换为 invocation 调用 getInvoker 获取一个invoker 对象 然后通过 Result result = invoker.invoke(inv) 进行调用 我们发现 ExchangeHandler.reply 其实是一个接口方法, 其实实现是在DubboProtocol 里面, private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &amp;#123; @Override public CompletableFuture&lt;Object> reply(ExchangeChannel channel, Object message) throws RemotingException &amp;#123; if (!(message instanceof Invocation)) &amp;#123; throw new RemotingException(channel, \"Unsupported request: \" + (message == null ? null : (message.getClass().getName() + \": \" + message)) + \", channel: consumer: \" + channel.getRemoteAddress() + \" --> provider: \" + channel.getLocalAddress()); &amp;#125; Invocation inv = (Invocation) message; Invoker&lt;?> invoker = getInvoker(channel, inv); // need to consider backward-compatibility if it's a callback if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE))) &amp;#123; String methodsStr = invoker.getUrl().getParameters().get(\"methods\"); boolean hasMethod = false; if (methodsStr == null || !methodsStr.contains(\",\")) &amp;#123; hasMethod = inv.getMethodName().equals(methodsStr); &amp;#125; else &amp;#123; String[] methods = methodsStr.split(\",\"); for (String method : methods) &amp;#123; if (inv.getMethodName().equals(method)) &amp;#123; hasMethod = true; break; &amp;#125; &amp;#125; &amp;#125; if (!hasMethod) &amp;#123; logger.warn(new IllegalStateException(\"The methodName \" + inv.getMethodName() + \" not found in callback service interface ,invoke will be ignored.\" + \" please update the api interface. url is:\" + invoker.getUrl()) + \" ,invocation is :\" + inv); return null; &amp;#125; &amp;#125; RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress()); Result result = invoker.invoke(inv); return result.completionFuture().thenApply(Function.identity()); &amp;#125; @Override public void received(Channel channel, Object message) throws RemotingException &amp;#123; if (message instanceof Invocation) &amp;#123; reply((ExchangeChannel) channel, message); &amp;#125; else &amp;#123; super.received(channel, message); &amp;#125; &amp;#125; @Override public void connected(Channel channel) throws RemotingException &amp;#123; invoke(channel, ON_CONNECT_KEY); &amp;#125; @Override public void disconnected(Channel channel) throws RemotingException &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"disconnected from \" + channel.getRemoteAddress() + \",url:\" + channel.getUrl()); &amp;#125; invoke(channel, ON_DISCONNECT_KEY); &amp;#125; private void invoke(Channel channel, String methodKey) &amp;#123; Invocation invocation = createInvocation(channel, channel.getUrl(), methodKey); if (invocation != null) &amp;#123; try &amp;#123; received(channel, invocation); &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Failed to invoke event method \" + invocation.getMethodName() + \"(), cause: \" + t.getMessage(), t); &amp;#125; &amp;#125; &amp;#125; private Invocation createInvocation(Channel channel, URL url, String methodKey) &amp;#123; String method = url.getParameter(methodKey); if (method == null || method.length() == 0) &amp;#123; return null; &amp;#125; RpcInvocation invocation = new RpcInvocation(method, new Class&lt;?>[0], new Object[0]); invocation.setAttachment(PATH_KEY, url.getPath()); invocation.setAttachment(GROUP_KEY, url.getParameter(GROUP_KEY)); invocation.setAttachment(INTERFACE_KEY, url.getParameter(INTERFACE_KEY)); invocation.setAttachment(VERSION_KEY, url.getParameter(VERSION_KEY)); if (url.getParameter(STUB_EVENT_KEY, false)) &amp;#123; invocation.setAttachment(STUB_EVENT_KEY, Boolean.TRUE.toString()); &amp;#125; return invocation; &amp;#125; &amp;#125;; getInvoker这里面获取到一个invoker 的实现 DubboExporter exporter = (DubboExporter) exporterMap.get(serviceKey); 这段代码非常熟悉, exporterMap 是在服务发布的过程中, 保存的 invoker吗? 而key, 就是对应的 interface:port Invoker&lt;?> getInvoker(Channel channel, Invocation inv) throws RemotingException &amp;#123; boolean isCallBackServiceInvoke = false; boolean isStubServiceInvoke = false; int port = channel.getLocalAddress().getPort(); String path = inv.getAttachments().get(PATH_KEY); // if it's callback service on client side isStubServiceInvoke = Boolean.TRUE.toString().equals(inv.getAttachments().get(STUB_EVENT_KEY)); if (isStubServiceInvoke) &amp;#123; port = channel.getRemoteAddress().getPort(); &amp;#125; //callback isCallBackServiceInvoke = isClientSide(channel) &amp;&amp; !isStubServiceInvoke; if (isCallBackServiceInvoke) &amp;#123; path += \".\" + inv.getAttachments().get(CALLBACK_SERVICE_KEY); inv.getAttachments().put(IS_CALLBACK_SERVICE_INVOKE, Boolean.TRUE.toString()); &amp;#125; String serviceKey = serviceKey(port, path, inv.getAttachments().get(VERSION_KEY), inv.getAttachments().get(GROUP_KEY)); DubboExporter&lt;?> exporter = (DubboExporter&lt;?>) exporterMap.get(serviceKey); if (exporter == null) &amp;#123; throw new RemotingException(channel, \"Not found exported service: \" + serviceKey + \" in \" + exporterMap.keySet() + \", may be version or group mismatch \" + \", channel: consumer: \" + channel.getRemoteAddress() + \" --> provider: \" + channel.getLocalAddress() + \", message:\" + inv); &amp;#125; return exporter.getInvoker(); &amp;#125; exporterMapMap&lt;String, Exporter&lt;?>> exporterMap = new ConcurrentHashMap&lt;String, Exporter&lt;? >>(); 在服务发布时, 实际上就是把invoker 包装成了DubboExpoter, 然后放入到了 exporterMap 中了. @Override public &lt;T> Exporter&lt;T> export(Invoker&lt;T> invoker) throws RpcException &amp;#123; // 获取服务标识, 理解成服务坐标也行, 由服务组名, 服务名,服务版本号以及端口组成,比如: // //$&amp;#123;group&amp;#125;/com.example.ISayHelloService:$&amp;#123;version&amp;#125;:20880 URL url = invoker.getUrl(); // export service. String key = serviceKey(url); // 创建DubboExporter DubboExporter&lt;T> exporter = new DubboExporter&lt;T>(invoker, key, exporterMap); // 将 key,exporter 键值对放入缓存中 exporterMap.put(key, exporter); //export an stub service for dispatching event Boolean isStubSupportEvent = url.getParameter(STUB_EVENT_KEY, DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice) &amp;#123; String stubServiceMethods = url.getParameter(STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(new IllegalStateException(\"consumer [\" + url.getParameter(INTERFACE_KEY) + \"], has set stubproxy support event ,but no stub methods founded.\")); &amp;#125; &amp;#125; else &amp;#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &amp;#125; &amp;#125; // 启动服务 openServer(url); optimizeSerialization(url); return exporter; &amp;#125; invoker.invoke(inv);接着调用 invoker.invoke(inv); 那么在回忆一下, 此时的invoker 是一个什么呢? invoker=ProtocolFilterWrapper(InvokerDelegate(DelegateProviderMetaDataInvoker(AbstractProxy Invoker))) 最后一定会进入到这个代码中. AbstractProxyInvoker在 AbstractProxyInvoker 里面, doInvoker 本质上调用的是 wrapper.invokeMethod(). @Override public &lt;T> Invoker&lt;T> getInvoker(T proxy, Class&lt;T> type, URL url) &amp;#123; // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T>(proxy, type, url) &amp;#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?>[] parameterTypes, Object[] arguments) throws Throwable &amp;#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &amp;#125; &amp;#125;; &amp;#125; 而 Wrapper 是一个动态代理类, 它的定义是这样的, 最后通过调用 w.info() 方法进行处理 public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException &amp;#123; com.dubbo.spring.UserApi w; try &amp;#123; w = ((com.dubbo.spring.UserApi) $1); &amp;#125; catch (Throwable e) &amp;#123; throw new IllegalArgumentException(e); &amp;#125; try &amp;#123; if (\"info\".equals($2) &amp;&amp; $3.length == 1) &amp;#123; return ($w) w.info((java.lang.String) $4[0]); &amp;#125; &amp;#125; catch (Throwable e) &amp;#123; throw new java.lang.reflect.InvocationTargetException(e); &amp;#125; throw new org.apache.dubbo.common.bytecode.NoSuchMethodException(\"Not found method \\\"\" + $2 + \"\\\" in class ccom.dubbo.spring.UserApi.\"); &amp;#125; 到此为止, 服务端的处理过程就分析完了.","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"Dubbo服务注册以及服务消费源码分析","slug":"微服务/dubbo/Dubbo服务注册以及服务消费源码分析","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/dubbo-fu-wu-zhu-ce-yi-ji-fu-wu-xiao-fei-yuan-ma-fen-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/dubbo-fu-wu-zhu-ce-yi-ji-fu-wu-xiao-fei-yuan-ma-fen-xi/","excerpt":"","text":"Dubbo 服务注册以及服务消费源码分析Invoker 是什么?服务的发布分为三个阶段: 第一个阶段会创造一个 invoker 第二个阶段会把经历过一系列处理的 invoker(各种包装), 在 在DubboProtocol 中保存到 exporterMap 中. 第三个阶段把dubbo协议的url 注册到注册中心上去. 我们来简单看看invoker 到底是一个啥东西? incoker 是Dubbo 领域模型中非常重要的一个概念, 和 ExtensionLoader 的重要性是一样的, 如果invoker 没有搞懂, 那么不算是看懂了Dubbo 的源码. 我们继续回到 ServiceConfig中export 的代码,以这个作为入口来分析前面 export出去的invoker 到底是什么东西? Invoker&lt;?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString())); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?> exporter = protocol.export(wrapperInvoker); exporters.add(exporter); ProxyFacotory.getInvoker这是一个代理工程, 用来生成invoker, 从它的定义来看, 它是一个自适用扩展点, 看到这样的扩展点, 我们几乎可以不假思索的想到它会存在这样一个动态适配类. private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); ProxyFactory这个方法的简单解读为: 它是一个SPI扩展点, 并且默认的扩展实现是javassist, 这个接口中有三个方法, 而且都是加了 @Adaptive 的自适应扩展点, 所以如果调用getInvoker() 方法, 应该会返回一个 ProxyFactory$Adaptive. @SPI(\"javassist\") public interface ProxyFactory &amp;#123; /** * create proxy. * * @param invoker * @return proxy */ @Adaptive(&amp;#123;PROXY_KEY&amp;#125;) &lt;T> T getProxy(Invoker&lt;T> invoker) throws RpcException; /** * create proxy. * * @param invoker * @return proxy */ @Adaptive(&amp;#123;PROXY_KEY&amp;#125;) &lt;T> T getProxy(Invoker&lt;T> invoker, boolean generic) throws RpcException; /** * create invoker. * * @param &lt;T> * @param proxy * @param type * @param url * @return invoker */ @Adaptive(&amp;#123;PROXY_KEY&amp;#125;) &lt;T> Invoker&lt;T> getInvoker(T proxy, Class&lt;T> type, URL url) throws RpcException; &amp;#125; ProxyFactory$Adaptive这个自适用扩展点, 做了两件事情. 通过 ExtensionLoader.getExtensionLoader(ProxyFactory.class).getExtension(extName) 获取了一个指定名称的扩展点. 在 dubbo-rpc-api/resources/META-INF/com.alibaba.dubbo.rpc.ProxyFactory 中定义了 javassis=JavassisProxyFactory,调用JavassisProxyFactory` 的getInvoker方法. public class ProxyFactory$Adaptive implements org.apache.dubbo.rpc.ProxyFactory &amp;#123; public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); &amp;#125; public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0, boolean arg1) throws org.apache.dubbo. rpc.RpcException &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0, arg1); &amp;#125; public org.apache.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, org.apache.dubbo.common.URL arg2) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg2 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg2; String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); &amp;#125; &amp;#125; JavassistProxyFactory.getInvokerjavassist 是一个动态类库, 用来实现动态代理的. proxy: 接口的实现 com.dubbo.spring.server.UserApiImpl type: 接口全称: com.dubbo.spring.userApi url: 协议地址: registry://… @Override public &lt;T> Invoker&lt;T> getInvoker(T proxy, Class&lt;T> type, URL url) &amp;#123; // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T>(proxy, type, url) &amp;#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?>[] parameterTypes, Object[] arguments) throws Throwable &amp;#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &amp;#125; &amp;#125;; &amp;#125; javassist生成的动态代理代码通过断点的方式(Wrapper258行), 在 Wrapper.getWrapper 中的 makeWrappe, 会创建一个动态代理, 核心的方法: invokeMethod 代码如下: public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException &amp;#123; com.dubbo.spring.userApi w; try &amp;#123; w = ((com.dubbo.spring.userApi) $1); &amp;#125; catch (Throwable e) &amp;#123; throw new IllegalArgumentException(e); &amp;#125; try &amp;#123; if (\"sayHello\".equals($2) &amp;&amp; $3.length == 1) &amp;#123; return ($w) w.info((java.lang.String) $4[0]); &amp;#125; &amp;#125; catch (Throwable e) &amp;#123; throw new java.lang.reflect.InvocationTargetException(e); &amp;#125; throw new org.apache.dubbo.common.bytecode.NoSuchMethodException(\"Not found method \\\"\" + $2 + \"\\\" in class com.dubbo.spring.userApi.\"); &amp;#125; 构建好了代理类后, 返回一个 AbstractproxyInvoker, 它返回了一个 doInvoker 方法, 这个方法似乎看到了dubbo 消费者调用过来的时候触发的影子, 因为 wrapper.invokeMethod 本质上就是触发上面动态代理类的方法 invokeMethod. return new AbstractProxyInvoker&lt;T>(proxy, type, url) &amp;#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?>[] parameterTypes, Object[] arguments) throws Throwable &amp;#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &amp;#125; 所以, 简单总结一下 invoke 本质上应该是一个代理, 经过层层包装后 最终进行了发布. 当消费者发起请求的时候, 会获取到这个invoke 进行调用. 最终发布出去的invoke , 也不是一个单纯的代理, 也是经过层层包装的. InvokerDelegate(DelegateProviderMetaDataInvoker(AbstractProxyInvoker())) 服务注册流程.关于服务发布这一条线完成之后, 再来了解一下服务注册的过程, 希望大家还记得我们之所以走到这一步, 是因为我们在 RegistryProtoco 这个类中, 看到了服务发布的流程. @Override public &lt;T> Exporter&lt;T> export(final Invoker&lt;T> originInvoker) throws RpcException &amp;#123; // 这里获取的是zookeeper 注册中心的url zookeeper://ip:port URL registryUrl = getRegistryUrl(originInvoker); // url to export locally // 这里是获得服务提供者的url dubbo://ip:port URL providerUrl = getProviderUrl(originInvoker); // Subscribe the override data // FIXME When the provider subscribes, it will affect the scene : a certain JVM exposes the service and call // the same service. Because the subscribed is cached key with the name of the service, it causes the // subscription information to cover. // 订阅 override数据, 在admin 控制台可以针对服务进行治理, 比如修改权重、修改路由机制等, 当有注册中心由此服务的覆盖配置注册进行的时候, // 推送消息给提供者, 重新暴露服务. final URL overrideSubscribeUrl = getSubscribedOverrideUrl(providerUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); providerUrl = overrideUrlWithConfig(providerUrl, overrideSubscribeListener); //export invoker // 这里交给具体的协议去暴露服务 final ExporterChangeableWrapper&lt;T> exporter = doLocalExport(originInvoker, providerUrl); // url to registry // 根据invoker 中的url 获取registry实例 , zookeeperRegistry final Registry registry = getRegistry(originInvoker); // 获取要注册到注册中心的url : dubbo://ip:port final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); ProviderInvokerWrapper&lt;T> providerInvokerWrapper = ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); //to judge if we need to delay publish boolean register = registeredProviderUrl.getParameter(\"register\", true); // 是否配置了注册中心, 如果是,则需要配置 if (register) &amp;#123; // 注册到注册中心的URL register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); &amp;#125; // 注册中心的订阅 // Deprecated! Subscribe to override rules in 2.6.x or before. registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); exporter.setRegisterUrl(registeredProviderUrl); exporter.setSubscribeUrl(overrideSubscribeUrl); //Ensure that a new exporter instance is returned every time export // 保存每次export 都返回一个新的exporter 实例 return new DestroyableExporter&lt;>(exporter); &amp;#125; 服务注册核心代码从export 方法中处理出来的部分代码, 就是服务注册的流程. // url to registry // 根据invoker 中的url 获取registry实例 , zookeeperRegistry final Registry registry = getRegistry(originInvoker); // 获取要注册到注册中心的url : dubbo://ip:port final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); ProviderInvokerWrapper&lt;T> providerInvokerWrapper = ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); //to judge if we need to delay publish boolean register = registeredProviderUrl.getParameter(\"register\", true); // 是否配置了注册中心, 如果是,则需要配置 if (register) &amp;#123; // 注册到注册中心的URL register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); &amp;#125; getRegistry 将url转换为对应配置的注册中心的具体协议. 根据具体协议, 从registryFactory 中获取指定的注册中心实现. 那么这个 registryFactory 具体是怎么赋值的呢? private Registry getRegistry(final Invoker&lt;?> originInvoker) &amp;#123; // 将url 转换为配置的具体协议, 比如 zookeeper://ip:port, 这样后续获取的注册中心就是基于zk的实现 URL registryUrl = getRegistryUrl(originInvoker); return registryFactory.getRegistry(registryUrl); &amp;#125; 在 RegistryProtoco 中存在这样一段代码, 很明显这是通过依赖注入来实现的扩展点. public void setRegistryFactory(RegistryFactory registryFactory) &amp;#123; this.registryFactory = registryFactory; &amp;#125; 按照扩展点的加载规则, 我们可以先看看 /META-INF/dubbo/internal 路径下找到 RegistryFactory的配置文件, 这个歌factory 有多个扩展点的实现. dubbo=org.apache.dubbo.registry.dubbo.DubboRegistryFactory multicast=org.apache.dubbo.registry.multicast.MulticastRegistryFactory zookeeper=org.apache.dubbo.registry.zookeeper.ZookeeperRegistryFactory redis=org.apache.dubbo.registry.redis.RedisRegistryFactory consul=org.apache.dubbo.registry.consul.ConsulRegistryFactory etcd3=org.apache.dubbo.registry.etcd.EtcdRegistryFactory 接着, 找到RegistryFactory 的实现, 发现它里面有个自适应的方法, 根据url 中的protocol 传入的值进行适配. @SPI(\"dubbo\") public interface RegistryFactory &amp;#123; /** * Connect to the registry * &lt;p> * Connecting the registry needs to support the contract: &lt;br> * 1. When the check=false is set, the connection is not checked, otherwise the exception is thrown when disconnection &lt;br> * 2. Support username:password authority authentication on URL.&lt;br> * 3. Support the backup=10.20.153.10 candidate registry cluster address.&lt;br> * 4. Support file=registry.cache local disk file cache.&lt;br> * 5. Support the timeout=1000 request timeout setting.&lt;br> * 6. Support session=60000 session timeout or expiration settings.&lt;br> * * @param url Registry address, is not allowed to be empty * @return Registry reference, never return empty value */ @Adaptive(&amp;#123;\"protocol\"&amp;#125;) Registry getRegistry(URL url); &amp;#125; RegistryFactory$Adaptive由于在前面的代码中, url 中的protocol 已经改成了 zookeeper, 那么这个时候根据zookeeper 获取的spi 扩展点应该是 ZookeeperRegistryFactory import org.apache.dubbo.common.extension.ExtensionLoader; public class RegistryFactory$Adaptive implements org.apache.dubbo.registry.RegistryFactory &amp;#123; public org.apache.dubbo.registry.Registry getRegistry(org.apache.dubbo.common.URL arg0) &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg0; String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.registry.RegistryFactory) name from url (\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.registry.RegistryFactory extension = (org.apache.dubbo.registry.RegistryFactory)ExtensionLoader.getExtensionLoader(or g.apache.dubbo.registry.RegistryFactory.class).getExtension(extName); return extension.getRegistry(arg0); &amp;#125; &amp;#125; ZookeeperRegistryFactory而这个类中并没有 getRegistry 方法, 而是在他的父类 AbstractRegistryFactory. 从缓存REGISTRIES 如果不存在, 则创建 Registry. @Override public Registry getRegistry(URL url) &amp;#123; url = URLBuilder.from(url) .setPath(RegistryService.class.getName()) .addParameter(INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(EXPORT_KEY, REFER_KEY) .build(); String key = url.toServiceStringWithoutResolving(); // Lock the registry access process to ensure a single instance of the registry LOCK.lock(); try &amp;#123; Registry registry = REGISTRIES.get(key); if (registry != null) &amp;#123; return registry; &amp;#125; //create registry by spi/ioc // 创建注册中心 registry = createRegistry(url); if (registry == null) &amp;#123; throw new IllegalStateException(\"Can not create registry \" + url); &amp;#125; REGISTRIES.put(key, registry); return registry; &amp;#125; finally &amp;#123; // Release the lock LOCK.unlock(); &amp;#125; &amp;#125; createRegistry(url)创建一个 ZookeeperRegistry, 把url 和zookeepertransporter 作为参数传入. zookeepeTransporter 这个属性也是基于依赖注入来赋值的, 具体流程就不再进行分析,这个的值应该是 CuratorZookeeperTransporter,表示具体是使用说明框架来和zk 产生连接. @Override public Registry createRegistry(URL url) &amp;#123; return new ZookeeperRegistry(url, zookeeperTransporter); &amp;#125; ZookeeperRegistry这个方法中使用 CuratorZookeeperTransport 来实现zk 的连接. public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &amp;#123; super(url); if (url.isAnyHost()) &amp;#123; throw new IllegalStateException(\"registry address == null\"); &amp;#125; // 获取group 的名称 String group = url.getParameter(GROUP_KEY, DEFAULT_ROOT); if (!group.startsWith(PATH_SEPARATOR)) &amp;#123; group = PATH_SEPARATOR + group; &amp;#125; this.root = group; // 产生一个zookeeper 连接 zkClient = zookeeperTransporter.connect(url); // 添加zookeeper 状态变化事件 zkClient.addStateListener(state -> &amp;#123; if (state == StateListener.RECONNECTED) &amp;#123; try &amp;#123; recover(); &amp;#125; catch (Exception e) &amp;#123; logger.error(e.getMessage(), e); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; RegistryProtocolregistry.register(registedProviderUrl);继续往下分析 会调用 egistry.register(registedProviderUrl) 去将dubbo:// 的协议地址去注册到zookeeper 上. 这个方法会调用 FailbackRegistry 类中的 registry, 为什么呢? 因为ZookeeperRegisry 这个类中并没有registry这个方法, 但是它的父类 FailbackRegistry 中存在这个方法, 而这个类又重写了 AbstractRegistry 类中的 registry 方法, 所以我们可以直接定位到 FailbackRegistry 这个类中的registry方法中. public void register(URL registryUrl, URL registeredProviderUrl) &amp;#123; Registry registry = registryFactory.getRegistry(registryUrl); registry.register(registeredProviderUrl); &amp;#125; FailbackRegistry.register FailbackRegistry 从名字来看, 是一个失败重试机制. 调用父类的registry方法, 将当前url 添加到缓存集合中. 调用doRegister 方法, 这个方法是一个抽象方法, 会由 ZookeeperRegistry 子类实现. @Override public void register(URL url) &amp;#123; super.register(url); removeFailedRegistered(url); removeFailedUnregistered(url); try &amp;#123; // Sending a registration request to the server side // 调用子类实现真正的服务注册, 把url 注册到zk上. doRegister(url); &amp;#125; catch (Exception e) &amp;#123; Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. // 如果开启了启动时检测, 则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &amp;#123; if (skipFailback) &amp;#123; t = t.getCause(); &amp;#125; throw new IllegalStateException(\"Failed to register \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); &amp;#125; else &amp;#123; logger.error(\"Failed to register \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &amp;#125; // Record a failed registration request to a failed list, retry regularly // 将失败了的注册请求记录到失败列表, 定时重试 addFailedRegistered(url); &amp;#125; &amp;#125; ZookeeperRegistry.doRegister最终调用curator 的客户端将服务地址注册到zk中. @Override public void doRegister(URL url) &amp;#123; try &amp;#123; zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true)); &amp;#125; catch (Throwable e) &amp;#123; throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); &amp;#125; &amp;#125; 服务消费思考服务消费应该要具备的逻辑如果要实现服务的消费, 需要实现以下需求: 生成远程服务的代理. 获取目标服务的url 地址 实现远程网络通信. 实现负载均衡 实现集群容错. 服务的消费消费端的代码是从下面这段代码开始的 &lt;dubbo:reference id=”xxxService” interface=”xxx.xxx.Service”/&gt; 注解的方式的初始化入口是: ReferenceAnnotationBeanPostProcessor-&gt;ReferenceBeanInvocationHandler.init- &gt;ReferenceConfig.get() 获得一个远程代理类 ReferenceConfig.get public synchronized T get() &amp;#123; // 修改和检查配置 checkAndUpdateSubConfigs(); if (destroyed) &amp;#123; throw new IllegalStateException(\"The invoker of ReferenceConfig(\" + url + \") has already destroyed!\"); &amp;#125; // 如果当前接口的远程代理引用为空, 则进行初始化. if (ref == null) &amp;#123; init(); &amp;#125; return ref; &amp;#125; init初始化的过程, 和服务发布的过程类似, 会有很多的判断以及参数的组装, 我们只需要关注 createProxy, 创建代理类的方法. private void init() &amp;#123; if (initialized) &amp;#123; return; &amp;#125; ... ref = createProxy(map); String serviceKey = URL.buildKey(interfaceName, group, version); ApplicationModel.initConsumerModel(serviceKey, buildConsumerModel(serviceKey, attributes)); initialized = true; &amp;#125; createProxy(map)代码比较长, 但是逻辑相对比较清晰. 判断是否为本地调用, 如果是, 则使用injvm 协议进行调用. 判断是否为点对点调用, 如果是则将url 保存到url 集合中, 如果url 为1, 进入步骤4, 如果urls&gt;1, 则执行5 如果是配置了注册中心, 遍历注册中心, 把url 添加到urls 集合中, url 为1, 进入步骤4, 如果urls &gt;1, 执行步骤5. 直联构建 invoker 构建 invokers集合, 通过cluster合并多个invoker 最后调用 proxyFactory 生成代理类. @SuppressWarnings(&amp;#123;\"unchecked\", \"rawtypes\", \"deprecation\"&amp;#125;) private T createProxy(Map&lt;String, String> map) &amp;#123; // 判断是否在用一个jvm 进程中调用. if (shouldJvmRefer(map)) &amp;#123; URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map); invoker = REF_PROTOCOL.refer(interfaceClass, url); if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Using injvm service \" + interfaceClass.getName()); &amp;#125; &amp;#125; else &amp;#123; urls.clear(); // reference retry init will add url to urls, lead to OOM // 如果url 不为空, 说明是点对点通信. if (url != null &amp;&amp; url.length() > 0) &amp;#123; // user specified URL, could be peer-to-peer address, or register center's address. String[] us = SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length > 0) &amp;#123; for (String u : us) &amp;#123; URL url = URL.valueOf(u); if (StringUtils.isEmpty(url.getPath())) &amp;#123; url = url.setPath(interfaceName); &amp;#125; // 检测url 协议是否为registry, 若是, 表明用户想使用指定的注册中心. if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &amp;#123; // 将map 转换为查询字符串, 并作为refer 参数的值添加到url 中. urls.add(url.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); &amp;#125; else &amp;#123; // 合并url, 移除服务提供者的一些配置(这些配置来源于用户配置的url属性. ) // 比如线程池相关配置,并保留服务提供者的部分配置, 比如版本、group、时间戳等. // 最后将合并后的配置设置为url, 查询字符串. urls.add(ClusterUtils.mergeUrl(url, map)); &amp;#125; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; // assemble URL from register center's configuration // if protocols not injvm checkRegistry if (!LOCAL_PROTOCOL.equalsIgnoreCase(getProtocol())) &amp;#123; // 校验注册中心的配置以及是否有必要从配置中心组装url, 这里的代码实现和服务端类似. // 也是根据注册中心进行解析得到URL, 这里的URL 肯定也是: registry://ip:port/org.apache.dubbo.service.RegsitryService checkRegistry(); List&lt;URL> us = loadRegistries(false); if (CollectionUtils.isNotEmpty(us)) &amp;#123; for (URL u : us) &amp;#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &amp;#123; map.put(MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &amp;#125; urls.add(u.addParameterAndEncoded(REFER_KEY, StringUtils.toQueryString(map))); &amp;#125; &amp;#125; // 如果没有配置注册中心, 则报错. if (urls.isEmpty()) &amp;#123; throw new IllegalStateException(\"No such any registry to reference \" + interfaceName + \" on the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please config &lt;dubbo:registry address=\\\"...\\\" /> to your spring config.\"); &amp;#125; &amp;#125; &amp;#125; // 如果值只配置了一个注册中心或者一个服务提供者,直接使用REF_PROTOCOL.refer if (urls.size() == 1) &amp;#123; invoker = REF_PROTOCOL.refer(interfaceClass, urls.get(0)); &amp;#125; else &amp;#123; List&lt;Invoker&lt;?>> invokers = new ArrayList&lt;Invoker&lt;?>>(); URL registryURL = null; // 遍历urls 生成多个invoker for (URL url : urls) &amp;#123; invokers.add(REF_PROTOCOL.refer(interfaceClass, url)); if (REGISTRY_PROTOCOL.equals(url.getProtocol())) &amp;#123; registryURL = url; // use last registry url &amp;#125; &amp;#125; // 如果registryURL 不为空, 构建静态directory if (registryURL != null) &amp;#123; // registry url is available // use RegistryAwareCluster only when register's CLUSTER is available // 使用RegistryAwareCluster URL u = registryURL.addParameter(CLUSTER_KEY, RegistryAwareCluster.NAME); // The invoker wrap relation would be: RegistryAwareClusterInvoker(StaticDirectory) -> FailoverClusterInvoker(RegistryDirectory, will execute route) -> Invoker // 通过 Cluster将多个invoker合并 //RegistryAwareClusterInvoker(StaticDirectory) -> //FailoverClusterInvoker(RegistryDirectory, will execute route) -> Invoker invoker = CLUSTER.join(new StaticDirectory(u, invokers)); &amp;#125; else &amp;#123; // not a registry url, must be direct invoke. invoker = CLUSTER.join(new StaticDirectory(invokers)); &amp;#125; &amp;#125; &amp;#125; // 检查invoker 的有效性. if (shouldCheck() &amp;&amp; !invoker.isAvailable()) &amp;#123; throw new IllegalStateException(\"Failed to check the status of the service \" + interfaceName + \". No provider available for the service \" + (group == null ? \"\" : group + \"/\") + interfaceName + (version == null ? \"\" : \":\" + version) + \" from the url \" + invoker.getUrl() + \" to the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion()); &amp;#125; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Refer dubbo service \" + interfaceClass.getName() + \" from url \" + invoker.getUrl()); &amp;#125; /** * @since 2.7.0 * ServiceData Store */ MetadataReportService metadataReportService = null; if ((metadataReportService = getMetadataReportService()) != null) &amp;#123; URL consumerURL = new URL(CONSUMER_PROTOCOL, map.remove(REGISTER_IP_KEY), 0, map.get(INTERFACE_KEY), map); metadataReportService.publishConsumer(consumerURL); &amp;#125; // create service proxy return (T) PROXY_FACTORY.getProxy(invoker); &amp;#125; REF_PROTOCOL.refer(interfaceClass, url)这里通过指定的协议来调用refer 生成一个invoker 对象, invoker 前面讲过, 它是一个代理对象, 那么在当前的消费端而言, invoker 主要用于执行远程调用. 这个protocol , 又是一个自适应扩展点, 它得到的是一个 Protocol$Adaptive Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension() 这段代码中, 根据当前的协议url, 得到一个指定的扩展点,传递进来的参数中, 协议地址为 registry://, 所以我们可以直接定位到 REF_PROTOCOL.refer 代码. Protocol$Adaptive中的refer方法根据当前的协议扩展名registry, 获取一个被包装过 的RegistryProtocol public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url (\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(org.apache.dub bo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &amp;#125; RegistryProtocol.refer这里面的代码逻辑比较简单. 组装注册中心协议的url 判断是否配置 legroup, 如果有，则 cluster=getMergeableCluster(), 构建invoker. doRefer 构建invoker @Override @SuppressWarnings(\"unchecked\") public &lt;T> Invoker&lt;T> refer(Class&lt;T> type, URL url) throws RpcException &amp;#123; // 根据配置的协议, 生成注册中心的url : zookeeper:// url = URLBuilder.from(url) .setProtocol(url.getParameter(REGISTRY_KEY, DEFAULT_REGISTRY)) .removeParameter(REGISTRY_KEY) .build(); Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &amp;#123; return proxyFactory.getInvoker((T) registry, type, url); &amp;#125; // group=\"a,b\" or group=\"*\" // 判断group参数, 根据group 决定 cluster 的类型 Map&lt;String, String> qs = StringUtils.parseQueryString(url.getParameterAndDecoded(REFER_KEY)); String group = qs.get(GROUP_KEY); if (group != null &amp;&amp; group.length() > 0) &amp;#123; if ((COMMA_SPLIT_PATTERN.split(group)).length > 1 || \"*\".equals(group)) &amp;#123; return doRefer(getMergeableCluster(), registry, type, url); &amp;#125; &amp;#125; return doRefer(cluster, registry, type, url); &amp;#125; doReferdoRefer 里面就稍微复杂一些, 涉及到比较多的东西, 我们先关注主线. 构建一个RegistryDirectory 构建一个 consumer://协议的地址注册到注册中心 订阅 zookeeper 中节点的变化. 调用 cluster.join方法. private &lt;T> Invoker&lt;T> doRefer(Cluster cluster, Registry registry, Class&lt;T> type, URL url) &amp;#123; // RegistryDirectory 初始化 RegistryDirectory&lt;T> directory = new RegistryDirectory&lt;T>(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY Map&lt;String, String> parameters = new HashMap&lt;String, String>(directory.getUrl().getParameters()); // 注册consumer://协议的url URL subscribeUrl = new URL(CONSUMER_PROTOCOL, parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters); if (!ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(REGISTER_KEY, true)) &amp;#123; directory.setRegisteredConsumerUrl(getRegisteredConsumerUrl(subscribeUrl, url)); registry.register(directory.getRegisteredConsumerUrl()); &amp;#125; directory.buildRouterChain(subscribeUrl); // 订阅事件监听 directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY, PROVIDERS_CATEGORY + \",\" + CONFIGURATORS_CATEGORY + \",\" + ROUTERS_CATEGORY)); // 构建 invoker Invoker invoker = cluster.join(directory); ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker; &amp;#125; Cluster是什么我们只关注一下 invoker 这个代理类的创建过程, 其他的就暂不关心. Invoker invoker = cluster.join(directory); cluster 其实是在 RegistryProtocol 中通过set方法完成依赖注入的, 并且, 它还是一个被包装的. public void setCluster(Cluster cluster) &amp;#123; this.cluster = cluster; &amp;#125; cluster 扩展点的定义, 由于它是一个自适应扩展点, 那么就会动态生成一个 Cluster$Adaptive 的动态代理类. @SPI(FailoverCluster.NAME) public interface Cluster &amp;#123; /** * Merge the directory invokers to a virtual invoker. * * @param &lt;T> * @param directory * @return cluster invoker * @throws RpcException */ @Adaptive &lt;T> Invoker&lt;T> join(Directory&lt;T> directory) throws RpcException; &amp;#125; Cluster$Adaptive在动态适配的类中会基于extName, 选择一个合适的扩展点进行适配, 由于默认情况下 cluster:failover,所以getExtension(&quot;failover&quot;) 理论情况下会返回 FailOverCluster. 但实际上, 这里做了包装 MockClusterWrapper（FailOverCluster）. public class Cluster$Adaptive implements org.apache.dubbo.rpc.cluster.Cluster &amp;#123; public org.apache.dubbo.rpc.Invoker join(org.apache.dubbo.rpc.cluster.Directory arg0) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.cluster.Directory argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.cluster.Directory argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"cluster\", \"failover\"); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.cluster.Cluster) name from url (\" + url.toString() + \") use keys([cluster])\"); org.apache.dubbo.rpc.cluster.Cluster extension = (org.apache.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(org.apa che.dubbo.rpc.cluster.Cluster.class).getExtension(extName); return extension.join(arg0); &amp;#125; &amp;#125; cluster.join所以再回到 doRefer 方法, 下面这段代码, 实际上调用 MockClusterWrapper(FailOverCluster.join). Invoker invoker = cluster.join(directory); 所以这里返回的invoker, 应该是 MockClusterWrapper(FailOverCluster（directory）). 接着回到ReferenceConfig.createProxy 方法中的最后一行. proxyFactory.getProxy拿到invoker 之后, 会调用获取一个动态代理类. return (T) proxyFactory.getProxy(invoker); 这里的proxyFactory 又是一个自适应扩展点, 所以会进入下面的方法. JavassistProxyFactory.getProxy通过这个方法 生成了一个动态代理类, 并且对invoker 做了一层处理, InvokerInvocationHandler 意味着后续发起服务调用的时候, 会由 InvokerInvocationHandler 来进行处理. public &lt;T> T getProxy(Invoker&lt;T> invoker, Class&lt;?>[] interfaces) &amp;#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); &amp;#125; proxy.getProxy在 proxy.getProxy 这个方法中会生成一个动态代理类, 通过debug 的形式可以看到动态代理类的原貌, 在getProxy这个方法位置增加一个断点. proxy = (Proxy) pc.newInstance(); 然后在debug 窗口, 找到ccp 这个变量 -&gt; mMethods。 public java.lang.String info(java.lang.String arg0)&amp;#123; Object[] args = new Object[1]; args[0] = ($w)$1; Object ret = handler.invoke(this, methods[0], args); return (java.lang.String)ret; &amp;#125; 从这个info方法可以看到, 我们通过. @Reference 注入的一个对象实例本质上就是一个动态代理类, 通过调用这个类中的方法, 会触发 handler.invoke(), 而这个handler 就是InvokerInvocationHandler 网络连接的建立前面分析的逻辑中, 只讲到了动态代理类的生成, 那么目标服务地址信息以及网络通信的建立在哪里实现呢? 我们继续回到 RegistryProtocol.refer 这个方法中. 这里我们暂且关注 directory.subscribe 这个方法, 它是实现服务目标订阅的. private &lt;T> Invoker&lt;T> doRefer(Cluster cluster, Registry registry, Class&lt;T> type, URL url) &amp;#123; // RegistryDirectory 初始化 RegistryDirectory&lt;T> directory = new RegistryDirectory&lt;T>(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY Map&lt;String, String> parameters = new HashMap&lt;String, String>(directory.getUrl().getParameters()); // 注册consumer://协议的url URL subscribeUrl = new URL(CONSUMER_PROTOCOL, parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters); if (!ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(REGISTER_KEY, true)) &amp;#123; directory.setRegisteredConsumerUrl(getRegisteredConsumerUrl(subscribeUrl, url)); registry.register(directory.getRegisteredConsumerUrl()); &amp;#125; directory.buildRouterChain(subscribeUrl); // 订阅事件监听 directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY, PROVIDERS_CATEGORY + \",\" + CONFIGURATORS_CATEGORY + \",\" + ROUTERS_CATEGORY)); // 构建 invoker Invoker invoker = cluster.join(directory); ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker; &amp;#125; RegistryDirectory.subscribe订阅注册中心指定节点的变化, 如果发生变化, 则通知RegistryDirectory. Directory其实和服务的注册以及服务的发现有非常大的关联. public void subscribe(URL url) &amp;#123; // 设置 consumerUrl setConsumerUrl(url); // 把当前RegistryDirectory作为listener，去监听zk上节点的变化 CONSUMER_CONFIGURATION_LISTENER.addNotifyListener(this); serviceConfigurationListener = new ReferenceConfigurationListener(this, url); // 订阅, 这里的registry 是zookeeperRegistry registry.subscribe(url, this); &amp;#125; 这里的registry 是ZookeeperRegistry, 会监听并获取路径下的节点, 监听的路径是: /dubbo/org.apache.dubbo.demo.DemoService/providers 、/dubbo/org.apache.dubbo.demo.DemoService/configurators、/dubbo/org.apache.dubbo.de mo.DemoService/routers 节点下面的子节点变动 FailbackRegistry.subscribelistener为RegistryDirectory , 后续要用到, 移除失效的listener, 调用doSubscribe 进行订阅. @Override public void subscribe(URL url, NotifyListener listener) &amp;#123; super.subscribe(url, listener); removeFailedSubscribed(url, listener); try &amp;#123; // Sending a subscription request to the server side doSubscribe(url, listener); &amp;#125; catch (Exception e) &amp;#123; Throwable t = e; List&lt;URL> urls = getCacheUrls(url); if (CollectionUtils.isNotEmpty(urls)) &amp;#123; notify(url, listener, urls); logger.error(\"Failed to subscribe \" + url + \", Using cached list: \" + urls + \" from cache file: \" + getUrl().getParameter(FILE_KEY, System.getProperty(\"user.home\") + \"/dubbo-registry-\" + url.getHost() + \".cache\") + \", cause: \" + t.getMessage(), t); &amp;#125; else &amp;#123; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &amp;#123; if (skipFailback) &amp;#123; t = t.getCause(); &amp;#125; throw new IllegalStateException(\"Failed to subscribe \" + url + \", cause: \" + t.getMessage(), t); &amp;#125; else &amp;#123; logger.error(\"Failed to subscribe \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &amp;#125; &amp;#125; // Record a failed registration request to a failed list, retry regularly addFailedSubscribed(url, listener); &amp;#125; &amp;#125; ZookeeperRegistry.doSubscribe这个方法是订阅, 逻辑实现比较多, 可以分为两段来看, 这里的实现把所有的service层发起的订阅以及指定的service层发起的订阅分开处理, 所有service 层类似于监控中心发起的订阅. 指定的service层 发起的订阅可以看做是服务消费者的订阅. 我们只需要关心指定的service层发起的订阅即可. @Override public void doSubscribe(final URL url, final NotifyListener listener) &amp;#123; try &amp;#123; if (ANY_VALUE.equals(url.getServiceInterface())) &amp;#123; String root = toRootPath(); ConcurrentMap&lt;NotifyListener, ChildListener> listeners = zkListeners.get(url); if (listeners == null) &amp;#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;>()); listeners = zkListeners.get(url); &amp;#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &amp;#123; listeners.putIfAbsent(listener, (parentPath, currentChilds) -> &amp;#123; for (String child : currentChilds) &amp;#123; child = URL.decode(child); if (!anyServices.contains(child)) &amp;#123; anyServices.add(child); subscribe(url.setPath(child).addParameters(INTERFACE_KEY, child, Constants.CHECK_KEY, String.valueOf(false)), listener); &amp;#125; &amp;#125; &amp;#125;); zkListener = listeners.get(listener); &amp;#125; zkClient.create(root, false); List&lt;String> services = zkClient.addChildListener(root, zkListener); if (CollectionUtils.isNotEmpty(services)) &amp;#123; for (String service : services) &amp;#123; service = URL.decode(service); anyServices.add(service); subscribe(url.setPath(service).addParameters(INTERFACE_KEY, service, Constants.CHECK_KEY, String.valueOf(false)), listener); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; List&lt;URL> urls = new ArrayList&lt;>(); for (String path : toCategoriesPath(url)) &amp;#123; ConcurrentMap&lt;NotifyListener, ChildListener> listeners = zkListeners.get(url); // 如果该路径没有添加到 listener, 则创建一个map 来放置listener if (listeners == null) &amp;#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;>()); listeners = zkListeners.get(url); &amp;#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &amp;#123; // 如果没有添加过对于子节点的listener, 则创建, 通知服务变化, 回调NotifyListener listeners.putIfAbsent(listener, (parentPath, currentChilds) -> ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds))); zkListener = listeners.get(listener); &amp;#125; zkClient.create(path, false); // 添加path 节点的当前节点以及子节点监听, 并且获取子节点信息 // 也就是 dubbo://ip:port/ List&lt;String> children = zkClient.addChildListener(path, zkListener); if (children != null) &amp;#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &amp;#125; &amp;#125; // 调用notify 进行通知, 对已经可用的列表进行通知. notify(url, listener, urls); &amp;#125; &amp;#125; catch (Throwable e) &amp;#123; throw new RpcException(\"Failed to subscribe \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); &amp;#125; &amp;#125; FailbackRegistry.notify调用 FailbackRegistry.notify, 对参数进行判断, 然后调用 AbstractRegistry.notify 方法。 @Override protected void notify(URL url, NotifyListener listener, List&lt;URL> urls) &amp;#123; if (url == null) &amp;#123; throw new IllegalArgumentException(\"notify url == null\"); &amp;#125; if (listener == null) &amp;#123; throw new IllegalArgumentException(\"notify listener == null\"); &amp;#125; try &amp;#123; doNotify(url, listener, urls); &amp;#125; catch (Exception t) &amp;#123; // Record a failed registration request to a failed list, retry regularly addFailedNotified(url, listener, urls); logger.error(\"Failed to notify for subscribe \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &amp;#125; &amp;#125; AbstractRegistry.notify这里面会针对每一个 category, 调用 listener.notify 进行通知, 然后更新本地的缓存文件. protected void notify(URL url, NotifyListener listener, List&lt;URL> urls) &amp;#123; if (url == null) &amp;#123; throw new IllegalArgumentException(\"notify url == null\"); &amp;#125; if (listener == null) &amp;#123; throw new IllegalArgumentException(\"notify listener == null\"); &amp;#125; if ((CollectionUtils.isEmpty(urls)) &amp;&amp; !ANY_VALUE.equals(url.getServiceInterface())) &amp;#123; logger.warn(\"Ignore empty notify urls for subscribe url \" + url); return; &amp;#125; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Notify urls for subscribe url \" + url + \", urls: \" + urls); &amp;#125; // keep every provider's category. Map&lt;String, List&lt;URL>> result = new HashMap&lt;>(); for (URL u : urls) &amp;#123; if (UrlUtils.isMatch(url, u)) &amp;#123; String category = u.getParameter(CATEGORY_KEY, DEFAULT_CATEGORY); List&lt;URL> categoryList = result.computeIfAbsent(category, k -> new ArrayList&lt;>()); categoryList.add(u); &amp;#125; &amp;#125; if (result.size() == 0) &amp;#123; return; &amp;#125; Map&lt;String, List&lt;URL>> categoryNotified = notified.computeIfAbsent(url, u -> new ConcurrentHashMap&lt;>()); for (Map.Entry&lt;String, List&lt;URL>> entry : result.entrySet()) &amp;#123; String category = entry.getKey(); List&lt;URL> categoryList = entry.getValue(); categoryNotified.put(category, categoryList); listener.notify(categoryList); // We will update our cache file after each notification. // When our Registry has a subscribe failure due to network jitter, we can return at least the existing cache URL. saveProperties(url); &amp;#125; &amp;#125; 消费端的listener 是最开始传递过来的RegistryDirectory, 所以这里会触发 的RegistryDirectory.notify(). RegistryDirectory.notifyinvoke 的网络连接以及后续的配置变更, 都会调用 notify 方法. urls: zk的path 数据, 这里表示的是 dubbo:// @Override public synchronized void notify(List&lt;URL> urls) &amp;#123; // 对url 列表进行校验、过滤、然后分成 config、router、provider 3个分组map Map&lt;String, List&lt;URL>> categoryUrls = urls.stream() .filter(Objects::nonNull) .filter(this::isValidCategory) .filter(this::isNotCompatibleFor26x) .collect(Collectors.groupingBy(url -> &amp;#123; if (UrlUtils.isConfigurator(url)) &amp;#123; return CONFIGURATORS_CATEGORY; &amp;#125; else if (UrlUtils.isRoute(url)) &amp;#123; return ROUTERS_CATEGORY; &amp;#125; else if (UrlUtils.isProvider(url)) &amp;#123; return PROVIDERS_CATEGORY; &amp;#125; return \"\"; &amp;#125;)); List&lt;URL> configuratorURLs = categoryUrls.getOrDefault(CONFIGURATORS_CATEGORY, Collections.emptyList()); this.configurators = Configurator.toConfigurators(configuratorURLs).orElse(this.configurators); // 如果route 路由节点变化, 则重新将route 下的数据生成route List&lt;URL> routerURLs = categoryUrls.getOrDefault(ROUTERS_CATEGORY, Collections.emptyList()); toRouters(routerURLs).ifPresent(this::addRouters); // providers // 获取 provider URL, 然后调用refreshOverrideAndInvoker 进行刷新 List&lt;URL> providerURLs = categoryUrls.getOrDefault(PROVIDERS_CATEGORY, Collections.emptyList()); refreshOverrideAndInvoker(providerURLs); &amp;#125; refreshOverrideAndInvoker 逐个调用注册中心里面的配置, 覆盖原来的url, 组成最新的url 放入到overrideDirectoryUrl 存储. 根据 provider urls , 重新刷新 invoker private void refreshOverrideAndInvoker(List&lt;URL> urls) &amp;#123; // mock zookeeper://xxx?mock=return null overrideDirectoryUrl(); refreshInvoker(urls); &amp;#125; refreshInvoker private void refreshInvoker(List&lt;URL> invokerUrls) &amp;#123; Assert.notNull(invokerUrls, \"invokerUrls should not be null\"); if (invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &amp;#123; // 如果是空协议, 则直接返回 不允许访问. this.forbidden = true; // Forbid to access this.invokers = Collections.emptyList(); routerChain.setInvokers(this.invokers); destroyAllInvokers(); // Close all invokers &amp;#125; else &amp;#123; this.forbidden = false; // Allow to access Map&lt;String, Invoker&lt;T>> oldUrlInvokerMap = this.urlInvokerMap; // local reference if (invokerUrls == Collections.&lt;URL>emptyList()) &amp;#123; invokerUrls = new ArrayList&lt;>(); &amp;#125; if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) &amp;#123; invokerUrls.addAll(this.cachedInvokerUrls); &amp;#125; else &amp;#123; this.cachedInvokerUrls = new HashSet&lt;>(); this.cachedInvokerUrls.addAll(invokerUrls);//Cached invoker urls, convenient for comparison &amp;#125; // 如果url为空, 则直接返回. if (invokerUrls.isEmpty()) &amp;#123; return; &amp;#125; // 根据 invokerUrls 生成新的 invoker Map&lt;String, Invoker&lt;T>> newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map /** * If the calculation is wrong, it is not processed. * * 1. The protocol configured by the client is inconsistent with the protocol of the server. * eg: consumer protocol = dubbo, provider only has other protocol services(rest). * 2. The registration center is not robust and pushes illegal specification data. * */ if (CollectionUtils.isEmptyMap(newUrlInvokerMap)) &amp;#123; logger.error(new IllegalStateException(\"urls to invokers error .invokerUrls.size :\" + invokerUrls.size() + \", invoker.size :0. urls :\" + invokerUrls .toString())); return; &amp;#125; // 转换为list List&lt;Invoker&lt;T>> newInvokers = Collections.unmodifiableList(new ArrayList&lt;>(newUrlInvokerMap.values())); // pre-route and build cache, notice that route cache should build on original Invoker list. // toMergeMethodInvokerMap() will wrap some invokers having different groups, those wrapped invokers not should be routed. routerChain.setInvokers(newInvokers); // 如果服务配置了分组,则把分组下的provider 包装成StaticDirectory, 组成一个invoker. // 实际上就是 按照group 进行合并. this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers; this.urlInvokerMap = newUrlInvokerMap; try &amp;#123; // 旧的url是否在新map 里面存在,不存在, 就销毁url 对应的invoker destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker &amp;#125; catch (Exception e) &amp;#123; logger.warn(\"destroyUnusedInvokers error. \", e); &amp;#125; &amp;#125; &amp;#125; toInvokers这个方法中有比较长的判断和处理逻辑, 我们只需要关心invoker 是什么时候初始化的就行, 这里用到了 protocol.refer 来构建一个 invoker . invoker = new InvokerDelegate&lt;>(protocol.refer(serviceType, url), url, providerUrl); 构建完成之后, 会保存在Map&gt; urlInvokerMap 这个集合中. private Map&lt;String, Invoker&lt;T>> toInvokers(List&lt;URL> urls) &amp;#123; Map&lt;String, Invoker&lt;T>> newUrlInvokerMap = new HashMap&lt;>(); if (urls == null || urls.isEmpty()) &amp;#123; return newUrlInvokerMap; &amp;#125; Set&lt;String> keys = new HashSet&lt;>(); String queryProtocols = this.queryMap.get(PROTOCOL_KEY); for (URL providerUrl : urls) &amp;#123; // If protocol is configured at the reference side, only the matching protocol is selected if (queryProtocols != null &amp;&amp; queryProtocols.length() > 0) &amp;#123; boolean accept = false; String[] acceptProtocols = queryProtocols.split(\",\"); for (String acceptProtocol : acceptProtocols) &amp;#123; if (providerUrl.getProtocol().equals(acceptProtocol)) &amp;#123; accept = true; break; &amp;#125; &amp;#125; if (!accept) &amp;#123; continue; &amp;#125; &amp;#125; if (EMPTY_PROTOCOL.equals(providerUrl.getProtocol())) &amp;#123; continue; &amp;#125; if (!ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(providerUrl.getProtocol())) &amp;#123; logger.error(new IllegalStateException(\"Unsupported protocol \" + providerUrl.getProtocol() + \" in notified url: \" + providerUrl + \" from registry \" + getUrl().getAddress() + \" to consumer \" + NetUtils.getLocalHost() + \", supported protocol: \" + ExtensionLoader.getExtensionLoader(Protocol.class).getSupportedExtensions())); continue; &amp;#125; URL url = mergeUrl(providerUrl); String key = url.toFullString(); // The parameter urls are sorted if (keys.contains(key)) &amp;#123; // Repeated url continue; &amp;#125; keys.add(key); // Cache key is url that does not merge with consumer side parameters, regardless of how the consumer combines parameters, if the server url changes, then refer again Map&lt;String, Invoker&lt;T>> localUrlInvokerMap = this.urlInvokerMap; // local reference Invoker&lt;T> invoker = localUrlInvokerMap == null ? null : localUrlInvokerMap.get(key); if (invoker == null) &amp;#123; // Not in the cache, refer again try &amp;#123; boolean enabled = true; if (url.hasParameter(DISABLED_KEY)) &amp;#123; enabled = !url.getParameter(DISABLED_KEY, false); &amp;#125; else &amp;#123; enabled = url.getParameter(ENABLED_KEY, true); &amp;#125; if (enabled) &amp;#123; invoker = new InvokerDelegate&lt;>(protocol.refer(serviceType, url), url, providerUrl); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; logger.error(\"Failed to refer invoker for interface:\" + serviceType + \",url:(\" + url + \")\" + t.getMessage(), t); &amp;#125; if (invoker != null) &amp;#123; // Put new invoker in cache newUrlInvokerMap.put(key, invoker); &amp;#125; &amp;#125; else &amp;#123; newUrlInvokerMap.put(key, invoker); &amp;#125; &amp;#125; keys.clear(); return newUrlInvokerMap; &amp;#125; protocol.refer调用指定的协议来进行远程引用, protocol 是一个 Protocol$Adaptive,而真正的实现是: ProtocolListenerWrapper(ProtocolFilterWrapper(QosProtocolWrapper(DubboProtocol.refer). 我们直接进入DubboProtocol.refer 方法. DubboProtocol.refer 优化序列化 构建DubboInvoker 在构建 DubboInvoker 时, 会构建一个ExchangeClient, 通过 getClients(url) 方法, 这里基本可以猜到是的服务的通信建立. @Override public &lt;T> Invoker&lt;T> protocolBindingRefer(Class&lt;T> serviceType, URL url) throws RpcException &amp;#123; optimizeSerialization(url); // create rpc invoker. DubboInvoker&lt;T> invoker = new DubboInvoker&lt;T>(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker; &amp;#125; getClients这里面是获取客户端连接的方法. 判断是否为共享连接, 默认是共享一个连接进行通信. 是否配置了多个连接通道 conections, 默认只有一个. private ExchangeClient[] getClients(URL url) &amp;#123; // whether to share connection boolean useShareConnect = false; int connections = url.getParameter(CONNECTIONS_KEY, 0); List&lt;ReferenceCountExchangeClient> shareClients = null; // if not configured, connection is shared, otherwise, one connection for one service // 如果配置连接数, 则默认为共享连接. if (connections == 0) &amp;#123; useShareConnect = true; /** * The xml configuration should have a higher priority than properties. */ String shareConnectionsStr = url.getParameter(SHARE_CONNECTIONS_KEY, (String) null); connections = Integer.parseInt(StringUtils.isBlank(shareConnectionsStr) ? ConfigUtils.getProperty(SHARE_CONNECTIONS_KEY, DEFAULT_SHARE_CONNECTIONS) : shareConnectionsStr); shareClients = getSharedClient(url, connections); &amp;#125; ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) &amp;#123; if (useShareConnect) &amp;#123; clients[i] = shareClients.get(i); &amp;#125; else &amp;#123; clients[i] = initClient(url); &amp;#125; &amp;#125; return clients; &amp;#125; getSharedClient获取一个共享连接. private List&lt;ReferenceCountExchangeClient> getSharedClient(URL url, int connectNum) &amp;#123; String key = url.getAddress(); List&lt;ReferenceCountExchangeClient> clients = referenceClientMap.get(key); // 检查当前的key ,检查连接是否已经创建过并且可用, 如果是, 则直接返回并且增加连接的个数的统计. if (checkClientCanUse(clients)) &amp;#123; batchClientRefIncr(clients); return clients; &amp;#125; // 如果连接已经关闭或者连接没有被创建. locks.putIfAbsent(key, new Object()); synchronized (locks.get(key)) &amp;#123; clients = referenceClientMap.get(key); // dubbo check // 在创建l连接之前, 在做一次检查, 防止连接并发创建. if (checkClientCanUse(clients)) &amp;#123; batchClientRefIncr(clients); return clients; &amp;#125; // 连接数必须大于等于1 // connectNum must be greater than or equal to 1 connectNum = Math.max(connectNum, 1); // If the clients is empty, then the first initialization is // 如果当前消费者还没有和服务端产生连接, 则初始化. if (CollectionUtils.isEmpty(clients)) &amp;#123; clients = buildReferenceCountExchangeClientList(url, connectNum); // 创建clients 之后, 保存到map中. referenceClientMap.put(key, clients); &amp;#125; else &amp;#123; // 如果clients 不为空, 则从clients 数组中进行遍历. for (int i = 0; i &lt; clients.size(); i++) &amp;#123; ReferenceCountExchangeClient referenceCountExchangeClient = clients.get(i); // If there is a client in the list that is no longer available, create a new one to replace him. // 如果集合中存在一个连接但是这个连接处于closed 状态, 则重新构建一个进行替换 if (referenceCountExchangeClient == null || referenceCountExchangeClient.isClosed()) &amp;#123; clients.set(i, buildReferenceCountExchangeClient(url)); continue; &amp;#125; // 增加个数 referenceCountExchangeClient.incrementAndGetCount(); &amp;#125; &amp;#125; /** * I understand that the purpose of the remove operation here is to avoid the expired url key * always occupying this memory space. */ locks.remove(key); return clients; &amp;#125; &amp;#125; buildReferenceCountExchangeClientList根据连接配置, 来构建指定个数的连接, 默认为1. private List&lt;ReferenceCountExchangeClient> buildReferenceCountExchangeClientList(URL url, int connectNum) &amp;#123; List&lt;ReferenceCountExchangeClient> clients = new ArrayList&lt;>(); for (int i = 0; i &lt; connectNum; i++) &amp;#123; clients.add(buildReferenceCountExchangeClient(url)); &amp;#125; return clients; &amp;#125; /** * Build a single client * * @param url * @return */ private ReferenceCountExchangeClient buildReferenceCountExchangeClient(URL url) &amp;#123; ExchangeClient exchangeClient = initClient(url); return new ReferenceCountExchangeClient(exchangeClient); &amp;#125; initClient终于进入到初始化客户端连接的方法, 猜测应该是根据url中配置的参数进行远程通信的构建. private ExchangeClient initClient(URL url) &amp;#123; // client type setting. // 获得连接类型 String str = url.getParameter(CLIENT_KEY, url.getParameter(SERVER_KEY, DEFAULT_REMOTING_CLIENT)); // 添加默认序列化方式 url = url.addParameter(CODEC_KEY, DubboCodec.NAME); // enable heartbeat by default // 设置心跳时间 url = url.addParameterIfAbsent(HEARTBEAT_KEY, String.valueOf(DEFAULT_HEARTBEAT)); // BIO is not allowed since it has severe performance issue. // 判断str是否存在于扩展点中, 如果不存在则直接报错. if (str != null &amp;&amp; str.length() > 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &amp;#123; throw new RpcException(\"Unsupported client type: \" + str + \",\" + \" supported client type is \" + StringUtils.join(ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(), \" \")); &amp;#125; ExchangeClient client; try &amp;#123; // connection should be lazy // 是否需要延迟创建连接, 注意, 这里的requestHandler 是一个适配器. if (url.getParameter(LAZY_CONNECT_KEY, false)) &amp;#123; client = new LazyConnectExchangeClient(url, requestHandler); &amp;#125; else &amp;#123; client = Exchangers.connect(url, requestHandler); &amp;#125; &amp;#125; catch (RemotingException e) &amp;#123; throw new RpcException(\"Fail to create remoting client for service(\" + url + \"): \" + e.getMessage(), e); &amp;#125; return client; &amp;#125; Exchangers.connect创建客户端连接. public static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &amp;#123; if (url == null) &amp;#123; throw new IllegalArgumentException(\"url == null\"); &amp;#125; if (handler == null) &amp;#123; throw new IllegalArgumentException(\"handler == null\"); &amp;#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); return getExchanger(url).connect(url, handler); &amp;#125; HeaderExchange.connect主要关注 transporters.connect public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &amp;#123; return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true); &amp;#125; NettyTransport.connect使用netty 构建一个客户端连接. @Override public Client connect(URL url, ChannelHandler listener) throws RemotingException &amp;#123; return new NettyClient(url, listener); &amp;#125; 总结我们讲到了 RegistryProtocol.refer 过程中有一个关键步骤, 即在监听到服务提供者url时触发RegistryDirectory.notify() 方法 RegistryDirectory.notify() 方法调用 refreshInvoker() 方法将服务提供者urls 转换为对应的远程 invoker, 最终会调用到 DubboProtocol.refer() 方法对应的DubboInvoker. DubboInvoker的构造方法中有一项入参 ExchangeClient[] clients , 即对应本文中要讲的网络客户端client, DubboInvoker 就是通过调用 client.request() 方法完成网络通信的请求发送和响应接收功能. client 的具体生成过程就是通过DubboProtocol 的 initClient(URL url) 方法 创建了一个HeaderExchangeClient.","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"Spring RabbitMQ可靠性消息投递","slug":"微服务/rabbitMQ/Spring RabbitMQ可靠性消息投递","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.293Z","comments":true,"path":"2022/01/04/wei-fu-wu/rabbitmq/spring-rabbitmq-ke-kao-xing-xiao-xi-tou-di/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rabbitmq/spring-rabbitmq-ke-kao-xing-xiao-xi-tou-di/","excerpt":"","text":"Spring RabbitMQ可靠性消息投递RabbitMQ核心基础概念。 Server:又称之为Broker，接受客户端的连接，实现AMQP实体服务。 Connection:连接，应用程序与Broker的网络连接。 Channel:网络信道，几乎所有的操作都在Channel中进行，Channel是进行消息读写的通道。客户端可以建立多个Channel，每个Channel代表一个会话任务。 如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立TCP Connection的开销将是巨大的，效率也较低。Channel是在connection内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的channel进行通讯，AMQP method包含了channel id帮助客户端和message broker识别channel，所以channel之间是完全隔离的。Channel作为轻量级的Connection极大减少了操作系统建立TCP connection的开销。 Message：消息，服务器和应用程序之间传送的数据，由Message Properties和Body组成。Properties可以对消息进行修饰，比如消息的优先级，延迟等高级特性，Body就是消息体内容。 Virtual Host:虚拟地址，用于进行逻辑隔离，最上层的消息路由。一个Virtual Host里面可以有若干个Exchange和Queue，同一个Virtual Host里面不能有相同名称的Exchange或者Queue。 Exchange：交换机，接收消息，根据路由键转发消息到绑定的队列。 Binding:Exchange和Queue之间的虚拟连接，binding中可以包含routing key。 Routing key:一个路由规则，虚拟机可以用它来确定如何路由一个特定消息。 Queue：也可以称之为Message Queue(消息队列)，保存消息并将它们转发到消费者。 通过下面2张图，我们能大概能明白AMQP协议模型和消息流转过程。在Exchange和Message Queue上面还有Virtual host。记住同一个Virtual Host里面不能有相同名称的ExChange和Message Queue。 image.png image.png 接着我们看下面的图，这是RabbitMQ消息可靠性投递的解决方案之一。 image.png 1.将消息落地到业务db和Message db。 2.采用Confirm方式发送消息至MQ Broker，返回结果的过程是异步的。Confirm消息，是指生产者投递消息后，如果Broker收到消息后，会给生产者一个ACK。生产者通过ACK，可以确认这条消息是否正常发送到Broker，这种方式是消息可靠性投递的核心。 3、4：在这里将消息分成3种状态。status=0表示消息正在投递中，status=1表示消息投递成功，status=2表示消息投递了3次还是失败。生产者接收Broker返回的Confirm确认消息结果，然后根据结果更新消息的状态。将status的状态从投递中改成投递成功即可。 5.在消息Confirm过程中，可能由于网络闪断问题或者是Broker端出现异常，导致回送消息失败或者出现异常。这时候，就需要生产者对消息进行可靠性投递，保证投递到Broker的消息可靠不丢失。还有一种极端情况值得我们考虑，那就是网络闪断。我们的消息成功投递到Broker，但是在回送ACK确认消息时，由于网络闪断，生产者没有收到。此时我们再重新投递此消息可能会造成消费端重复消费消息了。这时候需要消费端去做幂等处理(生成全局消息ID，判断此消息是否消费过)。对于没有投递成功的消息，我们可以设置一个重新投递时间。比如一个消息在5分钟内，status状态还是0，也就是这个消息还没有成功投递到Broker端。这时候我们需要一个定时任务，每隔几分钟从Message db中拉取status为0的消息。 6.将拉取的消息执行重新投递操作。 7.设置最大消息投递次数。当一个消息被投递了3次，还是不成功，那么将status置为2。最后交给人工解决处理此类问题或者将消息转存到失败表。 下面讲解一下涉及到消息可靠性的知识点和一些配置了。 application-dev.properties #rabbtisMQ配置 spring.rabbitmq.host=127.0.0.1 spring.rabbitmq.port=5672 spring.rabbitmq.username=root spring.rabbitmq.password=root spring.rabbitmq.virtual-host=/ #消费者数量 spring.rabbitmq.listener.simple.concurrency=10 #最大消费者数量 spring.rabbitmq.listener.simple.max-concurrency=10 #消费者每次从队列获取的消息数量 spring.rabbitmq.listener.simple.prefetch=1 #消费者自动启动 spring.rabbitmq.listener.simple.auto-startup=true #消费失败，自动重新入队 #重试次数超过最大限制之后是否丢弃（true不丢弃时需要写相应代码将该消息加入死信队列） #true，自动重新入队，要写相应代码将该消息加入死信队列 #false,丢弃 spring.rabbitmq.listener.simple.default-requeue-rejected=false #是否开启消费者重试（为false时关闭消费者重试，这时消费端代码异常会一直重复收到消息） spring.rabbitmq.listener.simple.retry.enabled=true spring.rabbitmq.listener.simple.retry.initial-interval=1000 spring.rabbitmq.listener.simple.retry.max-attempts=3 spring.rabbitmq.listener.simple.retry.multiplier=1.0 spring.rabbitmq.listener.simple.retry.max-interval=10000 #启动发送重试策略 spring.rabbitmq.template.retry.enabled=true #初始重试间隔为1s spring.rabbitmq.template.retry.initial-interval=1000 #重试的最大次数 spring.rabbitmq.template.retry.max-attempts=3 #重试间隔最多10s spring.rabbitmq.template.retry.max-interval=10000 #每次重试的因子是1.0 等差 spring.rabbitmq.template.retry.multiplier=1.0 # #RabbitMQ的消息确认有两种。 #一种是消息发送确认。这种是用来确认生产者将消息发送给交换器，交换器传递给队列的过程中， # 消息是否成功投递。 #发送确认分为两步，一是确认是否到达交换器，二是确认是否到达队列。 #第二种是消费接收确认。这种是确认消费者是否成功消费了队列中的消息。 # 确认消息发送成功，通过实现ConfirmCallBack接口，消息发送到交换器Exchange后触发回调 spring.rabbitmq.publisher-confirms=true # 实现ReturnCallback接口，如果消息从交换器发送到对应队列失败时触发 # （比如根据发送消息时指定的routingKey找不到队列时会触发） spring.rabbitmq.publisher-returns=true # 消息消费确认，可以手动确认 spring.rabbitmq.listener.simple.acknowledge-mode=manual #在消息没有被路由到合适队列情况下会将消息返还给消息发布者 #当mandatory标志位设置为true时，如果exchange根据自身类型和消息routingKey无法找到一个合适的queue存储消息， # 那么broker会调用basic.return方法将消息返还给生产者;当mandatory设置为false时， # 出现上述情况broker会直接将消息丢弃;通俗的讲，mandatory标志告诉broker代理服务器至少将消息route到一个队列中， # 否则就将消息return给发送者; spring.rabbitmq.template.mandatory=true 要确保RabbitMQ消息的可靠要保证以下3点： 1.publisher Confirms：要确保生产者的消息到broker的可靠性。可能会发生消息投递到broker过程中，broker挂了的情况。 2.Exchange，Queue，Message持久化：RabbitMQ是典型的内存式消息堆积。我们需要把message存储到磁盘中。如果是未持久化的消息存储在内存中，broker挂了那么消息会丢失。 3.consumer acknowledgement:消费者确认模式有3种：none(没有消息会发送应答),auto(自动应答),manual(手动应答)。为了保证消息可靠性，我们设置手动应答，这是为什么呢？采用自动应答的方式，每次消费端收到消息后，不管是否处理完成，Broker都会把这条消息置为完成，然后从Queue中删除。如果消费端消费时，抛出异常。也就是说消费端没有成功消费该消息，从而造成消息丢失。为了确保消息被消费者正确处理，我们采用手动应答(调用basicAck、basicNack、basicReject方法)，只有在消息得到正确处理下，再发送ACK。 RabbitMQ消息确认有2种：消息发送确认，消费接收确认。消息发送确认是确认生产者将消息发送到Exchange，Exchange分发消息至Queue的过程中，消息是否可靠投递。第一步是否到达Exchange，第二步确认是否到达Queue。 实现ConfirmCallBack接口,消息发送到Exchange后触发回调。 // 消息发送到交换器Exchange后触发回调 private final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback() &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; log.info(\"生产端confirm...\"); log.info(\"correlationData=\" + correlationData); String messageId = correlationData.getId(); if (ack) &#123; //confirm返回成功,更新消息投递状态 brokerMessageLogMapper.updateMessageLogStatus(messageId, Constants.ORDER_SEND_SUCCESS, new Date()); &#125; else &#123; // 失败则进行具体的后续操作，重试或者补偿等手段。 log.info(\"异常处理...\"); &#125; &#125; &#125;; 实现ReturnCallBack接口，消息从Exchange发送到指定的Queue失败触发回调 // 如果消息从交换器发送到对应队列失败时触发 private final RabbitTemplate.ReturnCallback returnCallback = new RabbitTemplate.ReturnCallback() &amp;#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &amp;#123; log.info(\"message=\" + message.toString()); log.info(\"replyCode=\" + replyCode); log.info(\"replyText=\" + replyText); log.info(\"exchange=\" + exchange); log.info(\"routingKey=\" + routingKey); &amp;#125; &amp;#125;; 消息确认机制开启，需要配置以下信息 spring.rabbitmq.publisher-confirms=true spring.rabbitmq.publisher-returns=true spring.rabbitmq.listener.simple.acknowledge-mode=manual 之前说过手动应答可以调用basicAck,basicNack,basicReject方法，下面来讲讲。 手动确认消息，当multiple为false，只确认当前的消息。当multiple为true，批量确认所有比当前deliveryTag小的消息。deliveryTag是用来标识Channel中投递的消息。RabbitMQ保证在每个Channel中，消息的deliveryTag是从1递增。 image.png 当消费端处理消息异常时，我们可以选择处理失败消息的方式。如果requeue为true，失败消息会重新进入Queue，试想一下，如果消费者在消费时发生异常，那么就不会对这一次消息进行ACK，进而发生回滚消息的操作，使消息始终放在Queue的头部，然后不断的被处理和回滚，导致队列陷入死循环，为了解决这种问题，我们可以引入重试机制(当重试次数超过最大值，丢弃该消息)或者是死信队列+重试队列。 requeue为false，丢弃该消息。 image.png 和basicNack用法一样。 image.png 为了配合Return机制，我们要配置spring.rabbitmq.template.mandatory=true。它的作用是在消息没有被路由到合适的队列情况下，Broker会将消息返回给生产者。当mandatory为true时，如果Exchange根据类型和消息Routing Key无法路由到一个合适的Queue存储消息，那么Broker会调用Basic.Return回调给handleReturn()，再回调给ReturnCallback，将消息返回给生产者。当mandatory为false时，丢弃该消息。 @Override public void handleReturn(int replyCode, String replyText, String exchange, String routingKey, BasicProperties properties, byte[] body) throws IOException &amp;#123; ReturnCallback returnCallback = this.returnCallback; if (returnCallback == null) &amp;#123; Object messageTagHeader = properties.getHeaders().remove(RETURN_CORRELATION_KEY); if (messageTagHeader != null) &amp;#123; String messageTag = messageTagHeader.toString(); final PendingReply pendingReply = this.replyHolder.get(messageTag); if (pendingReply != null) &amp;#123; returnCallback = new ReturnCallback() &amp;#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &amp;#123; pendingReply.returned(new AmqpMessageReturnedException(\"Message returned\", message, replyCode, replyText, exchange, routingKey)); &amp;#125; &amp;#125;; &amp;#125; else if (logger.isWarnEnabled()) &amp;#123; logger.warn(\"Returned request message but caller has timed out\"); &amp;#125; &amp;#125; else if (logger.isWarnEnabled()) &amp;#123; logger.warn(\"Returned message but no callback available\"); &amp;#125; &amp;#125; if (returnCallback != null) &amp;#123; properties.getHeaders().remove(PublisherCallbackChannel.RETURN_CORRELATION_KEY); MessageProperties messageProperties = this.messagePropertiesConverter.toMessageProperties( properties, null, this.encoding); Message returnedMessage = new Message(body, messageProperties); returnCallback.returnedMessage(returnedMessage, replyCode, replyText, exchange, routingKey); &amp;#125; &amp;#125; 当消息路由不到合适的Queue，会在回调给ReturnCallck这些信息。 image.png 如果消费端忘记了ACK，这些消息会一直处于Unacked 状态。由于RabbitMQ消息消费没有超时机制，也就是程序不重启，消息会一直处于Unacked状态。当消费端程序关闭时，这些处于Unack状态的消息会重新恢复成Ready状态。这时候会出现一种情况：当消费端程序开启时，由于Broker端积压了大量的消息，又可能会让消费端崩溃。所以我们要对消费端进行限流处理。RabbitMQ提供了一种qos(Quality of Service,服务质量保证)功能，即在非自动ACK前提下，如果一定数量的消息未被ACK前，不进行新消息的消息。 image.png spring.rabbitmq.listener.simple.prefetch=1 image.png 下面贴消息可靠性解决方案代码了。 配置任务调度中心 @Configuration @EnableScheduling public class TaskSchedulerConfig implements SchedulingConfigurer &amp;#123; protected ThreadPoolExecutor threadPoolExecutor; @Override public void configureTasks(ScheduledTaskRegistrar taskRegistrar) &amp;#123; taskRegistrar.setScheduler(taskExecutor()); &amp;#125; @Bean(destroyMethod = \"shutdown\") public ThreadPoolExecutor taskExecutor() &amp;#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(\"task-executor-pool-%d\").build(); this.threadPoolExecutor = new ScheduledThreadPoolExecutor(10, namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); return threadPoolExecutor; &amp;#125; &amp;#125; 执行重新投递status为0的消息。这里也可以使用corn表达式设置触发任务调度的时间。关于fixedRate和fixedDelay概念总有人搞混。fixedRate任务两次执行时间间隔是任务的开始点，而fixedDelay的间隔是前次任务的结束和下一次任务开始的间隔。 @Component @Slf4j public class RetryMessageTask &amp;#123; @Autowired private RabbitmqOrderSender rabbitmqOrderSender; @Autowired private BrokerMessageLogMapper brokerMessageLogMapper; @Scheduled(initialDelay = 5000, fixedDelay = 30000) public void trySendMessage() &amp;#123; log.info(\"定时投递status为0的消息...\"); List&lt;BrokerMessageLog> brokerMessageLogList = brokerMessageLogMapper.listStatusAndTimeoutMessage(); brokerMessageLogList.forEach(brokerMessageLog -> &amp;#123; if (brokerMessageLog.getTryCount() >= 3) &amp;#123; log.info(\"投递3次还是失败...\"); brokerMessageLogMapper.updateMessageLogStatus(brokerMessageLog.getMessageId(), Constants.ORDER_SEND_FAIL, new Date()); &amp;#125; else &amp;#123; log.info(\"投递失败...\"); brokerMessageLogMapper.updateReSendMessage(brokerMessageLog.getMessageId(), new Date()); Order order = JSON.parseObject(brokerMessageLog.getMessage(), Order.class); try &amp;#123; rabbitmqOrderSender.sendOrder(order); &amp;#125; catch (Exception e) &amp;#123; log.error(\"重新投递消息发送异常...:\" + e.getMessage()); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; &amp;#125; 消息生产端 @Component @Slf4j public class RabbitmqOrderSender &amp;#123; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private BrokerMessageLogMapper brokerMessageLogMapper; // 消息发送到交换器Exchange后触发回调 private final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback() &amp;#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &amp;#123; log.info(\"生产端confirm...\"); log.info(\"correlationData=\" + correlationData); String messageId = correlationData.getId(); if (ack) &amp;#123; //confirm返回成功,更新消息投递状态 brokerMessageLogMapper.updateMessageLogStatus(messageId, Constants.ORDER_SEND_SUCCESS, new Date()); &amp;#125; else &amp;#123; // 失败则进行具体的后续操作，重试或者补偿等手段。 log.info(\"异常处理...\"); &amp;#125; &amp;#125; &amp;#125;; // 如果消息从交换器发送到对应队列失败时触发 private final RabbitTemplate.ReturnCallback returnCallback = new RabbitTemplate.ReturnCallback() &amp;#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &amp;#123; log.info(\"message=\" + message.toString()); log.info(\"replyCode=\" + replyCode); log.info(\"replyText=\" + replyText); log.info(\"exchange=\" + exchange); log.info(\"routingKey=\" + routingKey); &amp;#125; &amp;#125;; public void sendOrder(Order order) &amp;#123; log.info(\"生产端发送消息...\"); rabbitTemplate.setConfirmCallback(this.confirmCallback); rabbitTemplate.setReturnCallback(this.returnCallback); CorrelationData correlationData = new CorrelationData(order.getMessageId()); rabbitTemplate.convertAndSend(MQConfig.ORDER_DIRECT_EXCAHNGE, MQConfig.ORDER_QUEUE, order, correlationData); &amp;#125; &amp;#125; 消息消费端 @Component @Slf4j public class RabbitmqOrderReceiver &amp;#123; @RabbitListener(queues = MQConfig.ORDER_QUEUE) public void receive(@Payload Order order, Channel channel, @Headers Map&lt;String, Object> headers, Message message) throws IOException, InterruptedException &amp;#123; log.info(\"消费端接收消息...\"); log.info(\"message=\" + message.toString()); log.info(\"order=\" + order); Long deliveryTag = (Long) headers.get(AmqpHeaders.DELIVERY_TAG); log.info(\"deliveryTag=\" + deliveryTag); // 手工ack channel.basicAck(deliveryTag, false); &amp;#125; &amp;#125; 当我们发送消息时，故意将Exchange设置成一个不存在的值。消息路由不到合适的Exchange，Confirm机制回送的ACK会返回false，走异常处理。这个消息的状态不会更新成1。然后定时任务会拉取status为0的消息，进行重新投递，投递了3次消息还未成功，将status置为2。 image.png 接下来，我们测试一波。 @Test public void test() &amp;#123; Order order = new Order(); order.setId(\"36\"); order.setName(\"cmazxiaoma测试订单-36\"); order.setMessageId(UUIDUtil.uuid()); rabbitmqOrderService.createOrder(order); &amp;#125; 消息投递失败。 image.png 定时任务重新投递消息失败。 image.png 将失败的消息重新投递3次还是失败。 image.png 更新Message db信息，将重新投递3次还是失败的消息状态置为2。 image.png 接着我们把消费端手动ACK的代码注释掉，再让生产端发送消息。看看会出现什么情况。 image.png 我们会发现Queue堆积了该消息。 image.png 我们关掉RabbitMQ Server，看看此消息是否会持久化。 [root@VM_0_11_centos log]# ps -ef|grep rabbitmq root 13283 10291 0 13:42 pts/1 00:00:00 grep --color=auto rabbitmq root 23051 1 1 Nov06 ? 00:09:29 /usr/lib64/erlang/erts-5.10.4/bin/beam -W w -A 64 -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -K true -- -root /usr/lib64/erlang -progname erl -- -home /root -- -pa /usr/local/rabbitmq/ebin -noshell -noinput -s rabbit boot -sname rabbit@VM_0_11_centos -boot start_sasl -kernel inet_default_connect_options [&amp;#123;nodelay,true&amp;#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger &amp;#123;file,\"/usr/local/rabbitmq/var/log/rabbitmq/rabbit@VM_0_11_centos.log\"&amp;#125; -rabbit sasl_error_logger &amp;#123;file,\"/usr/local/rabbitmq/var/log/rabbitmq/rabbit@VM_0_11_centos-sasl.log\"&amp;#125; -rabbit enabled_plugins_file \"/usr/local/rabbitmq/etc/rabbitmq/enabled_plugins\" -rabbit plugins_dir \"/usr/local/rabbitmq/plugins\" -rabbit plugins_expand_dir \"/usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@VM_0_11_centos-plugins-expand\" -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir \"/usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@VM_0_11_centos\" -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 -noshell -noinput [root@VM_0_11_centos log]# kill -9 23051 [root@VM_0_11_centos sbin]# rabbitmq-server -detached Warning: PID file not written; -detached was passed. [root@VM_0_11_centos sbin]# ps -ef|grep rabbitmq root 13500 1 31 13:44 ? 00:00:02 /usr/lib64/erlang/erts-5.10.4/bin/beam -W w -A 64 -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -K true -- -root /usr/lib64/erlang -progname erl -- -home /root -- -pa /usr/local/rabbitmq/ebin -noshell -noinput -s rabbit boot -sname rabbit@VM_0_11_centos -boot start_sasl -kernel inet_default_connect_options [&amp;#123;nodelay,true&amp;#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger &amp;#123;file,\"/usr/local/rabbitmq/var/log/rabbitmq/rabbit@VM_0_11_centos.log\"&amp;#125; -rabbit sasl_error_logger &amp;#123;file,\"/usr/local/rabbitmq/var/log/rabbitmq/rabbit@VM_0_11_centos-sasl.log\"&amp;#125; -rabbit enabled_plugins_file \"/usr/local/rabbitmq/etc/rabbitmq/enabled_plugins\" -rabbit plugins_dir \"/usr/local/rabbitmq/plugins\" -rabbit plugins_expand_dir \"/usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@VM_0_11_centos-plugins-expand\" -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir \"/usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@VM_0_11_centos\" -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 -noshell -noinput root 13597 10291 0 13:44 pts/1 00:00:00 grep --color=auto rabbitmq 执行rabbitmqctl list_queues name messages_ready messages_unacknowledged命令，查询Queue情况，发现Message持久化了。 image.png image.png 断开消费者程序，我们可以看到消息从Unacked状态转换成Ready了。 image.png","categories":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/"},{"name":"微服务","slug":"rabbitMQ/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"rabbitMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"rabbitMQ","slug":"rabbitMQ/微服务/微服务/rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/rabbitMQ/"}],"tags":[]},{"title":"Dubbo服务治理功能以及新特性讲解","slug":"微服务/dubbo/Dubbo服务治理功能以及新特性讲解","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/dubbo-fu-wu-zhi-li-gong-neng-yi-ji-xin-te-xing-jiang-jie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/dubbo-fu-wu-zhi-li-gong-neng-yi-ji-xin-te-xing-jiang-jie/","excerpt":"","text":"Dubbo 服务治理以及新功能讲解负载均衡负载均衡的背景到目前为止,Dubbo 集成zookeeper 解决了服务注册以及服务动态感知的问题, 那么当服务端存在多个节点的集群的时候, zookeeper 上会维护不同集群节点, 对于客户端而言,它需要一种负载均衡来实现目标服务的请求负载. 通过负载均衡, 可以让每个服务器节点获得适合自己处理能力的负载. 负载均衡可以分为软负载和硬件负载, 在实际开发中, 我们基础软件负载比较多, 比如nginx, 硬件负载现在用的比较少,而且需要有专门的人维护. Dubbo 里面默认就集成了负载均衡的算法和实现, 默认提供了4中负载均衡实现. Dubbo 中负载均衡的应用配置的属性名称: roundrobin/random/leastactive/ consistenthash &lt;dubbo:service interface=”” loadbalance=”roundrobin”/&gt; ​ &lt;dubbo:reference interface=”” loadbalance=”roundrobin”/&gt; 可以在服务端配置, 也可以在客户端配置 如果是基于注解,配置如下: @Service(loadbalance = \"roundrobin\") public class UserApiImpl implements UserApi &amp;#123; @Override public String info(String id) &amp;#123; System.out.println(\"info 请求\"); return \"张三:\" + id; &amp;#125; &amp;#125; 或者 // dubbo 提供了注入的方法 @Reference(loadbalance = \"roundrobin\") private UserApi userApi; @GetMapping(\"info/&amp;#123;id&amp;#125;\") public String info(@PathVariable(\"id\") String id) &amp;#123; return userApi.info(id); &amp;#125; 演示方式在 run configurations 中, 配置多个 springboot application , 添加jvm参数是 两个程序启动的端口不一样,然后客户端发起多次调用实现请求的负载均衡. -Ddubbo.protocol.port=20881 Dubbo负载均衡算法RandomLoadBalance权重算法,根据权重值进行随机负载. 它的算法思想很简单, 假设我们由一组服务器 servers = [A,B,C], 他们对应的权重为 weights = [5, 3, 2] ,权重总和为10. 现在把这些权重值平铺在一组坐标值上, [0,5] 区间属于服务器A, [5,8] 区间属于服务器B, [8,10]区间属于服务器C. 接下来通过随机数生成器生成一个范围在[0,10] 之间的随机数, 然后计算这个随机数会落在哪个区间上. 比如数字3 会落在服务器A 对应的区间上, 此时返回服务器A 即可. 权重越大的机器, 在坐标轴上对应的区间范围越大, 因为随机数生成器生成的数字就有更大的概率落在此区间内, 只要随机数生成器产生的随机数分布性很好, 在经过多次选择后, 每个服务器被选中的次数比例接近其权重比例. LeastActiveLoadBalance最少活跃调用数算法, 活跃调用数越小, 表明该服务提供者效率越高,单位时间内处理更多的请求这个是比较科学的负载均衡算法. 每个服务器提供者对应一个活跃数 active ,初始情况下, 所有服务提供者活跃数均为0, 每收到一个请求, 活跃数+1, 完成请求后则将活跃数减1, 在服务运行一段事件后, 性能好的服务提供者处理请求的速度更快, 因为活跃数下降的也越快, 此时这样的服务提供者能够优先获取到新的服务请求. ConsistentHashLoadBalancehash 一致性算法, 相同参数的请求总是发到同一个提供者. 当某一台提供者挂时, 原本发往该提供者的请求, 基于虚拟节点,平摊到其他提供者, 不会引起剧烈变动. RoundRobinLoadBalance加权轮询算法. 所谓轮询是指将请求轮流分配给每台服务器, 举个例子, 我们有三台服务器:A,B,C. 我们将第一个请求分配给服务器A, 第二个请求分配给服务器B, 第三个请求分配给服务器C, 这个过程就叫轮询. 轮询是一种无状态负载均衡算法, 实现简单, 适用于每台服务器性能相近的场景下, 但现实情况下,我们并不能保证每台服务器性能均相近. 这个时候如果我们需要将等量的请求分配给性能较差的服务器, 这显然是不合理的. 因此, 这个时候我们需要对轮询过程进行加权, 以调控每台服务器的负载. 经过加权后, 每台服务器能够得到的请求数比例, 接近或者等于他们的权重比. 比如服务器A,B,C 的权重比为5:2:1, 那么在8次请求中,服务器A 将收到其中的5次请求， 服务器B 会收到其中的2次请求, 服务器C 则收到其中的1次请求. 集群容错在分布式网络通信中, 容错能力是必须的, 什么叫容错呢? 从字面意思来看, 容: 是容忍, 错: 是错误, 就是容忍错误的意思. 我们知道网络通信中会有很多不确定的因素, 比如网络延迟、网络中断、服务异常等,会造成当前这次请求出现失败。当服务通信出现这个问题时, 需要采取一定的措施应对, 而dubbo 中提供了容错机制来优雅的处理这种错误. 在集群调用失败时, dubbo 提供了多种容错方案, 缺省值为 failover 重试. @Service(loadbalance = &quot;roundrobin&quot;,cluster = &quot;failsafe&quot;) Failover Cluster失败自动切换, 当出现失败的时候, 重试其他服务器(缺省) 通常用于读操作, 但重试会带来更长的延迟, 可通过retries=&quot;2&quot; 来设置重试次数(不含第一次)M Failfast Cluster快速调用, 只发起一次调用, 失败理解报错 通常用于非幂等性的写操作,比如新增记录等. Failsafe Cluster失败安全, 出现异常时, 直接忽略, 通常用于写入审计日志等操作. Failback Cluster失败自动恢复, 后台记录失败请求，定时重发. 通常用于消息通知操作. Forking Cluster并行调用多个服务器, 只要一个成功即返回。 通常用于实时性要求较高的读操作,但需要浪费更多的服务资源, 可通过 forks=&quot;2&quot; 来设置最大并行数. Broadcast Cluster广播调用所有提供者, 逐个调用, 任意一台报错则报错,(从2.1.0 开始支持), 通常用于通知所有提供者更新资源或日志等本地资源信息. 在实际应用中,查询语句容错策略建议使用默认 Failover Cluster , 而增删改建议使用 Failfast Cluster 或者 使用 Failover Cluster（retries=”0”） 策略防止出现 数据重复添加等其他问题, 建议在设计接口的时候把查询接口单独做一个接口提供查询. 服务降级降级的概念当某个非关键服务出现错误时, 可以通过降级功能来临时屏蔽这个服务. 降级可以有几个层面的分类: 自动降级和人工降级. 按照功能可以分为: 读服务降级和写服务降级. 对一些非核心服务进行人工降级, 在大促之前通过降级开关关闭哪些推荐内容、评价等对主流程没有影响的功能. 故障降级, 比如调用的远程服务挂了, 网络故障、或者PRC 服务返回异常, 那么可以直接降级, 降级的方案比如设置默认值、采用兜底数据(系统推荐的行为广告挂了, 可以提前准备静态页面做返回)等等 限流降级, 在秒杀这种流量比较集群并且流量特别大的情况下, 因为突发访问量特别大可能会导致系统支持不了. 这个时候可能采用限流来限制访问量. 当达到阈值时, 后续的请求被降级, 比如进入排队页面, 比如跳转到错误页等. 那么在Dubbo 中如何实现服务降级呢? Dubbo 中提供了一个mock 的配置, 可以通过mock 来实现当服务提供方出现网络异常或者挂掉以后, 客户端不抛出异常, 而是用过mock 数据返回自定义的数据。 Dubbo 实现服务降级在客户端新建一个mock类, 当出现服务降级的时候, 会被调用. package com.dubbo.client; import com.dubbo.spring.UserApi; /** * @author luyanan * @since 2019/11/21 * &lt;p>降级策略&lt;/p> **/ public class MockUserApi implements UserApi &amp;#123; @Override public String info(String id) &amp;#123; return \"服务出现异常\"; &amp;#125; &amp;#125; 修改客户端的注解, 增加mock配置, 以及修改timeout=1, 表示本次调用的超时时间是1毫秒, 这样可以模拟出失败的场景. 需要配置 cluster=failfast ,否则因为默认是 failover 导致客户端会发起3次重试, 等待的时间比较长. // dubbo 提供了注入的方法 @Reference(loadbalance = \"random\", mock = \"com.dubbo.client.MockUserApi\", timeout = 100, cluster = \"failfast\") private UserApi userApi; 启动时检查Dubbo 缺省会在启动时检查依赖的服务是否可用, 不可用时会抛出异常, 阻止Spring初始化完成, 以便上线时, 能够及早的发现问题, 默认 check=&quot;true&quot; 可以通过 check=&quot;true&quot;。 关闭检查, 比如, 测试时, 有些服务不关心, 或者出现了循环依赖, 必须有一方先启动, registry、reference、consumer 都可以配置 check 这个属性 @Reference(mock = \"com.dubbo.client.HelloApiMock\", timeout = 100,cluster = \"failfast\",check = false) private HelloApi helloApi; 多版本支持当一个接口实现,出现不兼容升级, 可以用版本号过渡, 版本号不同的服务相互间不引用. 可以按照以下步骤进行版本迁移: 在低压力时间段, 先升级一半提供者为新版本. 再将所有消费者升级为新版本 然后将剩下的一半提供者升级为新版本. 主机绑定默认的主机绑定方式 通过 LocalHost.getLocalHost() 获取本机地址 如果是127.* 等 loopback (环路地址)地址, 则扫描各网卡, 获取网卡ip 如果是springboot, 修改配置 dubbo.protocol.host=”” 如果注册地址获取不正确, 可以通过在 dubbo.xml 中加入主机地址的配置 &lt;dubbo:protocol host=&quot;205.182.231.231&quot;&gt; Duboo 新的功能动态配置规划动态配置是Dubbo 2.7版本中引入的一个新的功能, 简单来说, 就是把dubbo.properties 中的属性进行集中式存储, 存储在其他的服务器上. 那么如果需要用到集中式存储, 还需要一些配置中心组件来支撑. 目前Dubbo 能支持的配置中心有: apollo、nacos、zookeeper 其次, 从另外一个角度来看, 我们之前用zookeeper 实现服务注册和发现, 本质上就是使用zookeeper 实现了配置中心, 这个配置中心只是维护了服务注册和服务感知的功能. 在2.7 的版本中, Dubbo 对配置中心做了延展, 除了服务注册以外, 还可以把其他的数据存储在zookeeper上, 从而更好的进行维护. 在dubbo-admin 添加配置应用名称可以是 global ,或者对应当前服务的应用名, 如果是 global 表示全局配置, 针对所有应用可见. 配置的内容, 实际上就是 dubbo.properties 中配置的信息, 只是统一存储在了zookeeper 中而已. 本地配置文件中添加配置中心在 application.properties 中添加配置中心的配置项, app-name 对应的是上一步创建的项目名, dubbo.config-center.address=zookeeper://192.168.86.128:2181 dubbo.config-center.app-name=dubbo-spring-server ## 存于配置中心的配置项, 本地仍然需要配置一份, 这样目的是为了保证可靠性. 配置的优先级引入配置中心后, 配置的优先级就需要关注了, 默认情况下, 外部配置的优先级最高, 也就意味着配置中心上的配置会覆盖本地的配置, 当然我们也可以调整优先级. dubbo.config-center.highest-priority=false 配置中心的原理默认所有的配置都存储在 /dubbo/config 节点, 具体节点结构图如下: namespace:用于不同配置的环境隔离. config: Dubbo 约定的固定节点, 不可更改, 所有配置和服务治理规则都存储在此节点下. dubbo/application: 分别用来隔离全局配置, 应用级别配置, dubbo 是默认group值, application 对应应用名. dubbo.properties : 此节点的node value 存储具体配置内容. 元数据中心Duboo 2.7 的另外一个功能, 就是增加了元数据的配置. 在Dubbo 2.7 之前, 所有的配置信息, 比如服务接口名称、重试次数、版本号、负载策略、容错策略等, 所有的参数都是基于url 形式配置在zookeeper 上的, 这种方式会造成一些问题. url 内容过多,导致数据存储空间增大. url 需要涉及到网络传输, 数据量多大会造成网络传输过慢. 网络传输慢, 会造成服务地址感知的延迟变大, 影响服务的正常响应. 服务提供者这边的配置参数有30多个, 有一半是不需要作为注册中心进行存储的, 而消费者这边可配置的参数有25个以上, 只有个别是需要传递到注册中心的, 所以, 在Dubbo2.7 中对元数据进行了改造, 简单来说, 就是把属于服务治理的数据发布到注册中心, 其他的配置数据统一发布到元数据中心, 这样一来大大降低了注册中心的负载. 元数据配置.元数据中心目前支持 redis 和zookeeper .官方推荐是采用redis, 毕竟redis本身对于非结构化存储的数据读写性能比较高, 当然, 也可以使用zookeeper 来实现. 在配置中心中添加元数据中心的地址 ## 元数据配置 dubbo.metadata-report.address=zookeeper://192.168.86.128:2181 ## 注册到注册中心的url 是否采用精简模式(与低版本兼容) dubbo.registry.simplified=true","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"Spring RabbitMQ参数配置详解","slug":"微服务/rabbitMQ/Spring RabbitMQ参数配置详解","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/rabbitmq/spring-rabbitmq-can-shu-pei-zhi-xiang-jie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rabbitmq/spring-rabbitmq-can-shu-pei-zhi-xiang-jie/","excerpt":"","text":"Spring RabbitMQ参数配置详解1.基础信息spring.rabbitmq.host: 默认localhost spring.rabbitmq.port: 默认5672 spring.rabbitmq.username: 用户名 spring.rabbitmq.password: 密码 spring.rabbitmq.virtual-host: 连接到代理时用的虚拟主机 spring.rabbitmq.addresses: 连接到server的地址列表（以逗号分隔），先addresses后host spring.rabbitmq.requested-heartbeat: 请求心跳超时时间，0为不指定，如果不指定时间单位默认为妙 spring.rabbitmq.publisher-confirms: 是否启用【发布确认】，默认false spring.rabbitmq.publisher-returns: 是否启用【发布返回】，默认false spring.rabbitmq.connection-timeout: 连接超时时间，单位毫秒，0表示永不超时 2. SSLspring.rabbitmq.ssl.enabled: 是否支持ssl，默认false spring.rabbitmq.ssl.key-store: 持有SSL certificate的key store的路径 spring.rabbitmq.ssl.key-store-password: 访问key store的密码 spring.rabbitmq.ssl.trust-store: 持有SSL certificates的Trust store spring.rabbitmq.ssl.trust-store-password: 访问trust store的密码 spring.rabbitmq.ssl.trust-store-type=JKS：Trust store 类型. spring.rabbitmq.ssl.algorithm: ssl使用的算法，默认由rabiitClient配置 spring.rabbitmq.ssl.validate-server-certificate=true：是否启用服务端证书验证 spring.rabbitmq.ssl.verify-hostname=true 是否启用主机验证 3. 缓存cachespring.rabbitmq.cache.channel.size: 缓存中保持的channel数量 spring.rabbitmq.cache.channel.checkout-timeout: 当缓存数量被设置时，从缓存中获取一个channel的超时时间，单位毫秒；如果为0，则总是创建一个新channel spring.rabbitmq.cache.connection.size: 缓存的channel数，只有是CONNECTION模式时生效 spring.rabbitmq.cache.connection.mode=channel: 连接工厂缓存模式：channel 和 connection 4. Listenerspring.rabbitmq.listener.type=simple: 容器类型.simple或direct spring.rabbitmq.listener.simple.auto-startup=true: 是否启动时自动启动容器 spring.rabbitmq.listener.simple.acknowledge-mode: 表示消息确认方式，其有三种配置方式，分别是none、manual和auto；默认auto spring.rabbitmq.listener.simple.concurrency: 最小的消费者数量 spring.rabbitmq.listener.simple.max-concurrency: 最大的消费者数量 spring.rabbitmq.listener.simple.prefetch: 一个消费者最多可处理的nack消息数量，如果有事务的话，必须大于等于transaction数量. spring.rabbitmq.listener.simple.transaction-size: 当ack模式为auto时，一个事务（ack间）处理的消息数量，最好是小于等于prefetch的数量.若大于prefetch， 则prefetch将增加到这个值 spring.rabbitmq.listener.simple.default-requeue-rejected: 决定被拒绝的消息是否重新入队；默认是true（与参数acknowledge-mode有关系） spring.rabbitmq.listener.simple.missing-queues-fatal=true 若容器声明的队列在代理上不可用，是否失败； 或者运行时一个多多个队列被删除，是否停止容器 spring.rabbitmq.listener.simple.idle-event-interval: 发布空闲容器的时间间隔，单位毫秒 spring.rabbitmq.listener.simple.retry.enabled=false: 监听重试是否可用 spring.rabbitmq.listener.simple.retry.max-attempts=3: 最大重试次数 spring.rabbitmq.listener.simple.retry.max-interval=10000ms: 最大重试时间间隔 spring.rabbitmq.listener.simple.retry.initial-interval=1000ms:第一次和第二次尝试传递消息的时间间隔 spring.rabbitmq.listener.simple.retry.multiplier=1: 应用于上一重试间隔的乘数 spring.rabbitmq.listener.simple.retry.stateless=true: 重试时有状态or无状态 spring.rabbitmq.listener.direct.acknowledge-mode= ack模式 spring.rabbitmq.listener.direct.auto-startup=true 是否在启动时自动启动容器 spring.rabbitmq.listener.direct.consumers-per-queue= 每个队列消费者数量. spring.rabbitmq.listener.direct.default-requeue-rejected= 默认是否将拒绝传送的消息重新入队. spring.rabbitmq.listener.direct.idle-event-interval= 空闲容器事件发布时间间隔. spring.rabbitmq.listener.direct.missing-queues-fatal=false若容器声明的队列在代理上不可用，是否失败. spring.rabbitmq.listener.direct.prefetch= 每个消费者可最大处理的nack消息数量. spring.rabbitmq.listener.direct.retry.enabled=false 是否启用发布重试机制. spring.rabbitmq.listener.direct.retry.initial-interval=1000ms # Duration between the first and second attempt to deliver a message. spring.rabbitmq.listener.direct.retry.max-attempts=3 # Maximum number of attempts to deliver a message. spring.rabbitmq.listener.direct.retry.max-interval=10000ms # Maximum duration between attempts. spring.rabbitmq.listener.direct.retry.multiplier=1 # Multiplier to apply to the previous retry interval. spring.rabbitmq.listener.direct.retry.stateless=true # Whether retries are stateless or stateful. 5. Templatespring.rabbitmq.template.mandatory: 启用强制信息；默认false spring.rabbitmq.template.receive-timeout: receive() 操作的超时时间 spring.rabbitmq.template.reply-timeout: sendAndReceive() 操作的超时时间 spring.rabbitmq.template.retry.enabled=false: 发送重试是否可用 spring.rabbitmq.template.retry.max-attempts=3: 最大重试次数 spring.rabbitmq.template.retry.initial-interva=1000msl: 第一次和第二次尝试发布或传递消息之间的间隔 spring.rabbitmq.template.retry.multiplier=1: 应用于上一重试间隔的乘数 spring.rabbitmq.template.retry.max-interval=10000: 最大重试时间间隔","categories":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/"},{"name":"微服务","slug":"rabbitMQ/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"rabbitMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"rabbitMQ","slug":"rabbitMQ/微服务/微服务/rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/rabbitMQ/"}],"tags":[]},{"title":"Nacos基本原理以及实战","slug":"微服务/nacos/Nacos基本原理以及实战","date":"2022-01-04T02:42:07.289Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/nacos/nacos-ji-ben-yuan-li-yi-ji-shi-zhan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/nacos/nacos-ji-ben-yuan-li-yi-ji-shi-zhan/","excerpt":"","text":"Nacos 原理分析以及实战简介Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 ​ –&gt; copy 自官网. 实战演练下载安装1.下载源码或者安装包你可以通过源码和发行包两种方式来获取 Nacos。 从 Github 上下载源码方式git clone https://github.com/alibaba/nacos.git cd nacos/ mvn -Prelease-nacos clean install -U ls -al distribution/target/ // change the $version to your actual path cd distribution/target/nacos-server-$version/nacos/bin 下载编译后压缩包方式您可以从 最新稳定版本 下载 nacos-server-$version.zip 包。 unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gz cd nacos/bin 2.启动服务器Linux/Unix/Mac启动命令(standalone代表着单机模式运行，非集群模式): sh startup.sh -m standalone 如果您使用的是ubuntu系统，或者运行脚本报错提示[[符号找不到，可尝试如下运行： bash startup.sh -m standalone Windows启动命令： cmd startup.cmd 或者双击startup.cmd运行文件。 配置中心试用服务端我们先登录http://192.168.31.22:8848/nacos/index.html ,账号密码默认为nacos/nacos.我们在 客户端我们先新建一个springboot 项目, 然后在pom.xml 中加入config 的依赖 &lt;dependency> &lt;groupId>com.alibaba.boot&lt;/groupId> &lt;artifactId>nacos-config-spring-boot-starter&lt;/artifactId> &lt;version>0.2.3&lt;/version> &lt;/dependency> 新建一个 NacosConfigController , 然后做如下配置 @NacosPropertySource(dataId = \"example\", autoRefreshed = true) @RestController @RequestMapping(\"config\") public class NacosConfigController &amp;#123; @NacosValue(value = \"&amp;#123;info:默认&amp;#125;\", autoRefreshed = true) private String info; @GetMapping(\"info\") public String info() &amp;#123; return this.info; &amp;#125; &amp;#125; 测试我们在浏览器访问 http://localhost:8080/config/info, 可以看到返回的结果是在nacos中配置的信息 使用SDK 进行访问我们在项目中加入 &lt;dependency> &lt;groupId>com.alibaba.nacos&lt;/groupId> &lt;artifactId>nacos-client&lt;/artifactId> &lt;version>$&amp;#123;version&amp;#125;&lt;/version> &lt;/dependency> public static void main(String[] args) &amp;#123; try &amp;#123; String serverAddr = \"127.0.0.1:8848\"; String dataId = \"example\"; String group = \"DEFAULT_GROUP\"; Properties properties = new Properties(); properties.put(\"serverAddr\", serverAddr); ConfigService configService = NacosFactory.createConfigService(properties); String content = configService.getConfig(dataId, group, 5000); System.out.println(content); &amp;#125; catch (NacosException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; 源码分析ConfigService我们通过 NacosFactory.createConfigService(properties) 知道,通过ConfigFactory 工厂构建了ConfigService public static ConfigService createConfigService(Properties properties) throws NacosException &amp;#123; return ConfigFactory.createConfigService(properties); &amp;#125; public static ConfigService createConfigService(Properties properties) throws NacosException &amp;#123; try &amp;#123; Class&lt;?> driverImplClass = Class.forName(\"com.alibaba.nacos.client.config.NacosConfigService\"); Constructor constructor = driverImplClass.getConstructor(Properties.class); ConfigService vendorImpl = (ConfigService) constructor.newInstance(properties); return vendorImpl; &amp;#125; catch (Throwable e) &amp;#123; throw new NacosException(-400, e.getMessage()); &amp;#125; &amp;#125; 我们看到这里通过反射初始化了一个NacosConfigService. configService.getConfigprivate String getConfigInner(String tenant, String dataId, String group, long timeoutMs) throws NacosException &amp;#123; group = null2defaultGroup(group); ParamUtils.checkKeyParam(dataId, group); ConfigResponse cr = new ConfigResponse(); cr.setDataId(dataId); cr.setTenant(tenant); cr.setGroup(group); // 优先使用本地配置 String content = LocalConfigInfoProcessor.getFailover(agent.getName(), dataId, group, tenant); if (content != null) &amp;#123; log.warn(agent.getName(), \"[get-config] get failover ok, dataId=&amp;#123;&amp;#125;, group=&amp;#123;&amp;#125;, tenant=&amp;#123;&amp;#125;, config=&amp;#123;&amp;#125;\", dataId, group, tenant, ContentUtils.truncateContent(content)); cr.setContent(content); configFilterChainManager.doFilter(null, cr); content = cr.getContent(); return content; &amp;#125; try &amp;#123; // 从服务端获取 content = worker.getServerConfig(dataId, group, tenant, timeoutMs); cr.setContent(content); configFilterChainManager.doFilter(null, cr); content = cr.getContent(); return content; &amp;#125; catch (NacosException ioe) &amp;#123; if (NacosException.NO_RIGHT == ioe.getErrCode()) &amp;#123; throw ioe; &amp;#125; log.warn(\"NACOS-0003\", LoggerHelper.getErrorCodeStr(\"NACOS\", \"NACOS-0003\", \"环境问题\", \"get from server error\")); log.warn(agent.getName(), \"[get-config] get from server error, dataId=&amp;#123;&amp;#125;, group=&amp;#123;&amp;#125;, tenant=&amp;#123;&amp;#125;, msg=&amp;#123;&amp;#125;\", dataId, group, tenant, ioe.toString()); &amp;#125; log.warn(agent.getName(), \"[get-config] get snapshot ok, dataId=&amp;#123;&amp;#125;, group=&amp;#123;&amp;#125;, tenant=&amp;#123;&amp;#125;, config=&amp;#123;&amp;#125;\", dataId, group, tenant, ContentUtils.truncateContent(content)); content = LocalConfigInfoProcessor.getSnapshot(agent.getName(), dataId, group, tenant); cr.setContent(content); configFilterChainManager.doFilter(null, cr); content = cr.getContent(); return content; &amp;#125; 那么 agent 在哪里被初始化的呢? 我们看到 NacosConfigService 的构造方法里面 public NacosConfigService(Properties properties) throws NacosException &amp;#123; String encodeTmp = properties.getProperty(PropertyKeyConst.ENCODE); if (StringUtils.isBlank(encodeTmp)) &amp;#123; encode = Constants.ENCODE; &amp;#125; else &amp;#123; encode = encodeTmp.trim(); &amp;#125; String namespaceTmp = properties.getProperty(PropertyKeyConst.NAMESPACE); if (StringUtils.isBlank(namespaceTmp)) &amp;#123; namespace = TenantUtil.getUserTenant(); properties.put(PropertyKeyConst.NAMESPACE, namespace); &amp;#125; else &amp;#123; namespace = namespaceTmp; properties.put(PropertyKeyConst.NAMESPACE, namespace); &amp;#125; agent = new ServerHttpAgent(properties); agent.start(); worker = new ClientWorker(agent, configFilterChainManager); &amp;#125; worker.getServerConfig(dataId, group, tenant, timeoutMs)public String getServerConfig(String dataId, String group, String tenant, long readTimeout) throws NacosException &amp;#123; if (StringUtils.isBlank(group)) &amp;#123; group = Constants.DEFAULT_GROUP; &amp;#125; HttpResult result = null; try &amp;#123; List&lt;String> params = null; if (StringUtils.isBlank(tenant)) &amp;#123; params = Arrays.asList(\"dataId\", dataId, \"group\", group); &amp;#125; else &amp;#123; params = Arrays.asList(\"dataId\", dataId, \"group\", group, \"tenant\", tenant); &amp;#125; result = agent.httpGet(Constants.CONFIG_CONTROLLER_PATH, null, params, agent.getEncode(), readTimeout); &amp;#125; catch (IOException e) &amp;#123; log.error(agent.getName(), \"NACOS-XXXX\", \"[sub-server] get server config exception, dataId=&amp;#123;&amp;#125;, group=&amp;#123;&amp;#125;, tenant=&amp;#123;&amp;#125;, msg=&amp;#123;&amp;#125;\", dataId, group, tenant, e.toString()); throw new NacosException(NacosException.SERVER_ERROR, e.getMessage()); &amp;#125; switch (result.code) &amp;#123; case HttpURLConnection.HTTP_OK: LocalConfigInfoProcessor.saveSnapshot(agent.getName(), dataId, group, tenant, result.content); return result.content; case HttpURLConnection.HTTP_NOT_FOUND: LocalConfigInfoProcessor.saveSnapshot(agent.getName(), dataId, group, tenant, null); return null; case HttpURLConnection.HTTP_CONFLICT: &amp;#123; log.error(agent.getName(), \"NACOS-XXXX\", \"[sub-server-error] get server config being modified concurrently, dataId=&amp;#123;&amp;#125;, group=&amp;#123;&amp;#125;, tenant=&amp;#123;&amp;#125;\", dataId, group, tenant); throw new NacosException(NacosException.CONFLICT, \"data being modified, dataId=\" + dataId + \",group=\" + group + \",tenant=\" + tenant); &amp;#125; case HttpURLConnection.HTTP_FORBIDDEN: &amp;#123; log.error(agent.getName(), \"NACOS-XXXX\", \"[sub-server-error] no right, dataId=&amp;#123;&amp;#125;, group=&amp;#123;&amp;#125;, tenant=&amp;#123;&amp;#125;\", dataId, group, tenant); throw new NacosException(result.code, result.content); &amp;#125; default: &amp;#123; log.error(agent.getName(), \"NACOS-XXXX\", \"[sub-server-error] dataId=&amp;#123;&amp;#125;, group=&amp;#123;&amp;#125;, tenant=&amp;#123;&amp;#125;, code=&amp;#123;&amp;#125;\", dataId, group, tenant, result.code); throw new NacosException(result.code, \"http error, code=\" + result.code + \",dataId=\" + dataId + \",group=\" + group + \",tenant=\" + tenant); &amp;#125; &amp;#125; &amp;#125; 我们看到这里通过http请求从服务端获取配置信息","categories":[{"name":"nacos","slug":"nacos","permalink":"https://rainsoil.github.io/categories/nacos/"},{"name":"微服务","slug":"nacos/微服务","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"nacos/微服务/微服务","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"nacos","slug":"nacos/微服务/微服务/nacos","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/nacos/"}],"tags":[]},{"title":"Spring Cloud Alibaba之naocs配置中心","slug":"微服务/Spring Cloud/Spring Cloud Alibaba之naocs配置中心","date":"2022-01-04T02:42:07.285Z","updated":"2022-01-04T02:42:07.285Z","comments":true,"path":"2022/01/04/wei-fu-wu/spring-cloud/spring-cloud-alibaba-zhi-naocs-pei-zhi-zhong-xin/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/spring-cloud/spring-cloud-alibaba-zhi-naocs-pei-zhi-zhong-xin/","excerpt":"","text":"Spring Cloud Alibaba之naocs配置中心1. 介绍 动态配置服务可以让您以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。 动态配置消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效和敏捷。 配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易。 Nacos 提供了一个简洁易用的UI (控制台样例 Demo) 帮助您管理所有的服务和应用的配置。Nacos 还提供包括配置版本跟踪、金丝雀发布、一键回滚配置以及客户端配置更新状态跟踪在内的一系列开箱即用的配置管理特性，帮助您更安全地在生产环境中管理配置变更和降低配置变更带来的风险。 2. 项目实战2.1 nacos 启动这里就不多说了 2.2 依赖添加 &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-config&lt;/artifactId> &lt;/dependency> 2.3 添加bootstrap 配置文件此文件会优先于application.yml 启动 加入配置中心的配置 spring: cloud: nacos: config: server-addr: localhost:8848 application: name: nacos-config-client application.yml 中配置其他的内容 spring: cloud: nacos: discovery: server-addr: 127.0.0.1:8848 server: port: 12000 2.4 添加主启动类@EnableDiscoveryClient @SpringBootApplication public class NacosConfigClientApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(NacosConfigClientApplication.class, args); &amp;#125; &amp;#125; 2.5 配置测试传统方式中,为了详细说明配置中心的使用,我们先来使用传统的方式 在application.yml 配置文件中加入 info: project: version: 1.0 author: luyanan 编写controller 查出我们设置的配置 @RestController public class InfoController &amp;#123; @Value(\"$&amp;#123;info.project.version&amp;#125;\") public String projectVersion; @Value(\"$&amp;#123;info.project.author&amp;#125;\") public String projectAuthor; @GetMapping(\"info\") public Map info() &amp;#123; HashMap info = new HashMap(2); info.put(\"version\", projectVersion); info.put(\"author\", projectAuthor); return info; &amp;#125; &amp;#125; 访问接口可以看到我们设置的内容 &amp;#123; \"version\": \"1.0\", \"author\": \"luyanan\" &amp;#125; 我们可以通过这种方式来存放我们的配置,但是这样做存在一个问题,如果需要频繁的修改application.yml 文件的话,就需要频繁的打包上线,很是不方便. 接下来我们可以用nacos 来解决这个问题. nacos作为配置中心我们查看启动日志 2020-08-11 13:58:25.947 INFO 14876 --- [ main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource &amp;#123;name='bootstrapProperties-nacos-config-client.properties,DEFAULT_GROUP'&amp;#125;, BootstrapPropertySource &amp;#123;name='bootstrapProperties-nacos-config-client,DEFAULT_GROUP'&amp;#125;] 我们可以发现,在程序启动的时候,程序会去nacos 去查找名称为nacos-config-client.properties的配置文件, 所以我们可以来到nacos的控制台 选择配置列表,点击最右边的加号按钮可以添加配置 Data ID : nacos-config-client.properties 文件的命名规则为：${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} ${spring.application.name}：为微服务名 ${spring.profiles.active}：指明是哪种环境下的配置，如dev、test或info ${spring.cloud.nacos.config.file-extension}：配置文件的扩展名，可以为properties、yml等 点击发布. 查看配置 可以看到我们刚才添加的配置 修改infoController,添加@RefreshScope 注解 @RefreshScope @RestController public class InfoController &amp;#123; @Value(\"$&amp;#123;info.project.version&amp;#125;\") public String projectVersion; @Value(\"$&amp;#123;info.project.author&amp;#125;\") public String projectAuthor; @GetMapping(\"info\") public Map info() &amp;#123; HashMap info = new HashMap(2); info.put(\"version\", projectVersion); info.put(\"author\", projectAuthor); return info; &amp;#125; &amp;#125; 重启测试 重启成功后,再次访问http://localhost:12000/info 接口,就可以看到这个时候返回的就不是我们在application.yml 配置的内容,而是我们在nacos 中配置的内容了. 并且在指明了相同的配置信息的时候,配置中心的配置优先于本地的配置. &amp;#123; \"version\": \"2.0\", \"author\": \"luyanan\" &amp;#125; 我们再次在配置中心中修改配置 info.project.author=luyanan 为info.project.author=luyanan111111,这个时候不重启应用,直接刷新接口. &amp;#123; \"version\": \"2.0\", \"author\": \"luyanan111111\" &amp;#125; 我们看到,接口返回的配置就是我们在nacos 中配置的内容了, 这样就实现了不需要重启就可以动态的修改配置了. 3. Nacos 支持的三种配置加载方案Nacos 支持NameSpace + group + dataID的配置解决方案 详情见: https://github.com/alibaba/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-docs/src/main/asciidoc-zh/nacos-config.adoc 3.1 NameSpace 方案通过命令空间来实现环境的区分 下面是配置实例: 创建命名空间 命名空间-&gt;创建命名空间 创建两个命名空间,dev 和test 回到配置列表,可以看到我们创建的命名空间 下面我们在dev的命令空间下创建nacos-config-client.properties 的配置文件 这个时候,直接访问http://localhost:12000/info 的时候会发现配置并没有改变,原因是因为nacos 会默认使用public 命令空间下配置的规则, 程序指定命令空间 具体要想使用我们自定义的哪个命名空间,就需要在bootstrap.yml 配置文件中指定哪个配置文件的ID, 这个命名空间的ID来源于我们第一步创建的命名空间 修改bootstrap的配置, 加入 spring: cloud: nacos: config: ## 指定配置使用的命名空间ID namespace: d033967d-013d-4f01-9d23-8326105615ac 然后重启,再次访问接口 &amp;#123; \"version\": \"2.0\", \"author\": \"luyanan-dev\" &amp;#125; 就可以发现已经变成了我们设置的dev命名空间的配置文件, 但是这种命名空间的粒度还是不够细化,对此我们可以为每个项目创建一个命名空间 为每个项目创建命名空间 回到配置列表下,克隆public 的配置规则到nacos-config-client 命名空间下. 修改bootstrap.yml的命名空间配置为nacos-config-client的 然后重启重新访问接口,发现这时候读取的就是nacos-config-client 命名空间下的配置文件了. 3.2 Data Id 方案通过指定spring.profile.active和配置文件的DataId , 来使得不同环境下读取不同的配置,读取配置的时候,默认使用的命名空间是public,默认分组是default_group下的DataID 3.3 DataID 方案通过Group 实现环境区分 实例: 通过使用不同的组来读取不同的配置,还是以上面的nacos-config-client 为例 我们还是使用nacos-config-client 命名空间,先清空该命名空间下的所有配置 然后新建Group 为tmp的配置文件 然后修改项目的分组为tmp spring: cloud: nacos: config: ## 指定分组 group: tmp 接下来重启项目,再次访问路径就可以看到tmp 分组下的配置了. 3.4 同时加载多个配置集当微服务的数量很庞大的时候,将所有的配置文件都写入到一个配置文件中,显然是不太合适的,为此我们可以将配置文件按照功能的不同拆分成不同的配置文件. 如下面的配置文件: spring: datasource: url: jdbc:mysql://localhost:3306/test username: root password: rootroot mybatis-plus: global-config: db-config: id-type: auto mapper-locations: classpath:/mapper/**/*.xml 我们就可以将关于数据源的配置放入到写入到一个配置文件中, 将框架相关的配置写入到另外一个配置文件中 将上述的配置配置交给nacos 来管理, 创建datasource.yml 配置文件存储数据库相关的配置 spring: datasource: url: jdbc:mysql://localhost:3306/test username: root password: rootroot 在nacos-config-client 的命名空间下创建datasource.yml 配置文件 将跟mybatis 相关的配置放入mybatis.yml 配置文件中 同样,新建mybatis.yml 配置文件 mybatis-plus: global-config: db-config: id-type: auto mapper-locations: classpath:/mapper/**/*.xml 修改项目的bootstrap.yml 配置文件,加载datasource.yml 和mybatis.yml 配置文件 spring: cloud: nacos: config: ## 指定配置使用的命名空间ID namespace: db8304ef-bf5d-4259-b5d8-c2d532d45e6b ## 指定分组 group: tmp extension-configs: - data-id: datasource.yml group: dev refresh: true - data-id: mybatis.yml group: dev refresh: true 4. 小结 微服务任何配置信息,任何配置文件都可以放在配置中心 只需要在bootstrap 配置文件中说明加载配置中心的那些配置文件即可 @Value 和ConfigurationProperties 都可以用来获取配置中心的信息 配置中心有的优先使用配置中心的,没有的则使用本地配置的.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/"},{"name":"微服务","slug":"Spring-Cloud/微服务","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"Spring-Cloud/微服务/微服务","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Spring Cloud","slug":"Spring-Cloud/微服务/微服务/Spring-Cloud","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Spring-Cloud/"}],"tags":[]},{"title":"Dubbo之服务发现发布源码分析","slug":"微服务/dubbo/Dubbo之服务发现发布源码分析","date":"2022-01-04T02:42:07.285Z","updated":"2022-01-04T02:42:07.289Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/dubbo-zhi-fu-wu-fa-xian-fa-bu-yuan-ma-fen-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/dubbo-zhi-fu-wu-fa-xian-fa-bu-yuan-ma-fen-xi/","excerpt":"","text":"Dubbo 服务发布源码分析Dubbo 对于Spring 的扩展最早我们使用spring 的配置来实现dubbo 服务的发布, 方便大家的同时也意味着Dubbo 里面和Spring 肯定有那种说不清的关系. Spring 的标签扩展在Spring中定义了两个接口, NamespaceHandler : 注册一堆 BeanDefinitionParser，利用他们来进行解析 BeanDefinitionParser : 用于解析每个element 的内容 Spring 默认会加载jar 包下的META-INF/spring.handlers 文件寻找对应的 NamespaceHandler。 Dubbo-config 模块下的dubbo-config-spring Dubbo的接入实现Dubbo 中Spring 的扩展就是使用Spring的自定义类型, 所以同样有 NamespaceHandler、BeanDefinitionParser . 而 NamespaceHandler 是 DubboNamespaceHandler . public class DubboNamespaceHandler extends NamespaceHandlerSupport &amp;#123; static &amp;#123; Version.checkDuplicate(DubboNamespaceHandler.class); &amp;#125; @Override public void init() &amp;#123; registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser(\"config-center\", new DubboBeanDefinitionParser(ConfigCenterBean.class, true)); registerBeanDefinitionParser(\"metadata-report\", new DubboBeanDefinitionParser(MetadataReportConfig.class, true)); registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser(\"metrics\", new DubboBeanDefinitionParser(MetricsConfig.class, true)); registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser(\"annotation\", new AnnotationBeanDefinitionParser()); &amp;#125; &amp;#125; BeanDefinitionParser 全部都使用了 DubboBeanDefinitionParser , 如果我们想看 dubbo:service的配置, 就直接看 DubboBeanDefinitionParser(ServiceBean.class, true) 这里面主要做了一件事情, 把不同的配置分别转换为Spring 容器中的Bean 对象. application 对应 ApplicationConfig registry 对应 RegistryConfig monitor 对应 MonitorConfig provider 对应 ProviderConfig consumer 对应 ConsumerConfig 我们仔细看, 发现涉及到服务发布和服务调用的解析, 使用的是 ServiceBean 和 referenceBean . 并不是config 结尾的, 这两个类稍微特殊些, 当然它同时也继承了 ServiceConfig 和 ReferenceConfig . registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false)); DubboBeanDefinitionParser这里面是实现具体配置文件解析的入口, 它重写了parse方法, 对Spring 的配置进行解析. 我们关注一下ServiceBean的解析, 实际就是解析dubbo:service 这个标签中对应的属性. if (ServiceBean.class.equals(beanClass)) &amp;#123; String className = element.getAttribute(\"class\"); if (className != null &amp;&amp; className.length() > 0) &amp;#123; RootBeanDefinition classDefinition = new RootBeanDefinition(); classDefinition.setBeanClass(ReflectUtils.forName(className)); classDefinition.setLazyInit(false); parseProperties(element.getChildNodes(), classDefinition); beanDefinition.getPropertyValues().addPropertyValue(\"ref\", new BeanDefinitionHolder(classDefinition, id + \"Impl\")); &amp;#125; &amp;#125; ServiceBean 的实现ServiceBean 这个类, 分别实现了InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware, ApplicationEventPublisherAware. InitializingBean接口为bean 提供了初始化方法的方式, 它只包括 afterPropertiesSet方法, 凡是继承该接口的类, 在初始化bean 的时候会执行该方法, 被重写的方法为 afterPropertiesSet DisposableBean被重写的方法为 destroy ， bean 被销毁的时候, sring容器会自动执行 destroy 方法, 比如释放资源. ApplicationContextAware实现了这个接口的Bean，当Spring 的容器初始化的时候, 会自动将 ApplicationContext 注入进来. ApplicationListener ApplicationEvent 事件监听, Spring 容器启动会会发一个事件通知, 被重写的方法为 onApplicationEvent, onApplicationEvent 方法传入的对象是 ContextRefreshedEvent , 这个对象是Spring 的上下文被刷新或者加载完毕后触发的. 因此服务就是在Spring 的上下文刷新后进行导出操作的. BeanNameAware获取自身初始化时, 本身的bean 的id属性,被重写的方法为 setBeanName ApplicationEventPublisherAware这是一个异步事件发送器, 被重写的方法为 setApplicationEventPublisher, 简单来说, 在spring中提供了类似于消息队列的异步事件解耦功能. (典型的观察者模式. ) Spring 事件发送监听由3个部分组成. .ApplicationEvent :表示事件本身, 自定义事件需要继承该类. ApplicationEventPublisherAware : 事件发送器, 需要实现该接口。 ApplicationListener : 事件监听器接口. ServiceBean 中服务暴露服务.在ServiceBean中,我们暂且只需要关注 两个方法, 分别是 在初始化bean的时候会执行该方法 afterPropertiesSet spring 容器启动后悔发送一个事件通知 onApplicationEvent afterPropertiesSet我们发现这个方法里面, 就是把dubbo中配置的 application、registry、service、protocol 等信息加载到对应的config 实体类中, 便于后续的使用. onApplicationEventspring 容器启动后, 会受到这样一个事件通知, 这里面做了两件事情. 判断服务是否已经发布过. 如果没有发布, 则调用export 接口进行服务发布的流程(这里就是入口) @Override public void onApplicationEvent(ContextRefreshedEvent event) &amp;#123; if (!isExported() &amp;&amp; !isUnexported()) &amp;#123; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"The service ready on spring started. service: \" + getInterface()); &amp;#125; // 入口 export(); &amp;#125; &amp;#125; export serviceBean 中重写了export.方法. 实现了一个事件的发布, 并且调用了super.export() , 也就是调用父类的 export 方法. @Override public void export() &amp;#123; super.export(); // Publish ServiceBeanExportedEvent publishExportEvent(); &amp;#125; ServiceConfig 配置类先整体来看一下这个类的作用,从名字来看, 它应该和其他所有的config 类一样去实现对配置文件中的service 的配置信息的存储. 实际上, 这个类并不单纯, 所有的配置它都放在一个 AbstractServiceConfig 的抽象类,自己实现了对于服务发布之前要做的操作逻辑. public synchronized void export() &amp;#123; // 检查并且更新配置信息 checkAndUpdateSubConfigs(); // 如果当前的服务是否需要发布, 通过配置实现 :@Service(export = false) if (!shouldExport()) &amp;#123; return; &amp;#125; // 检查是否需要延时发布, 通过配置 @Service(delay=1000)实现, 单位是毫秒 if (shouldDelay()) &amp;#123; delayExportExecutor.schedule(this::doExport, getDelay(), TimeUnit.MILLISECONDS); &amp;#125; else &amp;#123; // 如果没有配置delay , 则直接调用doExport 进行发布 doExport(); &amp;#125; &amp;#125; doExport这里仍然是在实现发布前的各种判断, 比如刷新 protected synchronized void doExport() &amp;#123; if (unexported) &amp;#123; throw new IllegalStateException(\"The service \" + interfaceClass.getName() + \" has already unexported!\"); &amp;#125; // 服务是否已经发布过 if (exported) &amp;#123; return; &amp;#125; // 设置发布的状态 exported = true; // path 表示服务路径,默认使用interfaceName if (StringUtils.isEmpty(path)) &amp;#123; path = interfaceName; &amp;#125; doExportUrls(); &amp;#125; doExportUrls 记载所有配置的注册中心地址 遍历所有配置的协议. protocol 针对每种协议发布一个对应协议的服务. private void doExportUrls() &amp;#123; // 加载所有配置的注册中心地址, 组装成一个url // //(registry://ip:port/org.apache.dubbo.registry.RegistryService 的东西) List&lt;URL> registryURLs = loadRegistries(true); for (ProtocolConfig protocolConfig : protocols) &amp;#123; // group和version 组成一个pathkey(serviceName) String pathKey = URL.buildKey(getContextPath(protocolConfig).map(p -> p + \"/\" + path).orElse(path), group, version); //ApplicationModel 用来存储 ProviderModel, 发布的服务的元数据, 后续会用到 ProviderModel providerModel = new ProviderModel(pathKey, ref, interfaceClass); ApplicationModel.initProviderModel(pathKey, providerModel); doExportUrlsFor1Protocol(protocolConfig, registryURLs); &amp;#125; &amp;#125; doExportUrlsFor1Protocol发布指定协议的服务, 我们以Dubbo 为例, 由于代码太多, 就不全部贴出来 . 前面的一大串if else 代码, 是为了把当前服务下配置的dubbo:method 参数进行解析, 保存到map 集合中. 获取当前服务需要暴露的ip和端口号 把解析到的所有数据, 组装成一个URL,大概是 dubbo://192.168.9.110:20880/com.example.ISayHelloService private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL> registryURLs) &amp;#123; ...... // 以上都是解析&lt;dubbo:method>和&lt;dubbo:service> 中配置参数的代码, // export service // 获取当前服务发布的目标id和port String host = this.findConfigedHosts(protocolConfig, registryURLs, map); Integer port = this.findConfigedPorts(protocolConfig, name, map); // 组装URL URL url = new URL(name, host, port, getContextPath(protocolConfig).map(p -> p + \"/\" + path).orElse(path), map); // 这里是通过ConfiguratorFactory 去实现动态改变配置的功能, if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .hasExtension(url.getProtocol())) &amp;#123; url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .getExtension(url.getProtocol()).getConfigurator(url).configure(url); &amp;#125; // 如果scope ！=null, 则发布服务, 默认 scope 为null, 如果scope 不为none, 判断是否为local或者remote, 从而发布 // local 或者remote服务, 默认两个都会发布 . String scope = url.getParameter(SCOPE_KEY); // don't export when none is configured if (!SCOPE_NONE.equalsIgnoreCase(scope)) &amp;#123; // export to local if the config is not remote (export to remote only when config is remote) // injvm 发布到本地 if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) &amp;#123; exportLocal(url); &amp;#125; // export to remote if the config is not local (export to local only when config is local) // 发布远程服务 if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) &amp;#123; if (!isOnlyInJvm() &amp;&amp; logger.isInfoEnabled()) &amp;#123; logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to url \" + url); &amp;#125; if (CollectionUtils.isNotEmpty(registryURLs)) &amp;#123; for (URL registryURL : registryURLs) &amp;#123; //if protocol is only injvm ,not register if (LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &amp;#123; continue; &amp;#125; url = url.addParameterIfAbsent(DYNAMIC_KEY, registryURL.getParameter(DYNAMIC_KEY)); URL monitorUrl = loadMonitor(registryURL); if (monitorUrl != null) &amp;#123; url = url.addParameterAndEncoded(MONITOR_KEY, monitorUrl.toFullString()); &amp;#125; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Register dubbo service \" + interfaceClass.getName() + \" url \" + url + \" to registry \" + registryURL); &amp;#125; // For providers, this is used to enable custom proxy to generate invoker String proxy = url.getParameter(PROXY_KEY); if (StringUtils.isNotEmpty(proxy)) &amp;#123; registryURL = registryURL.addParameter(PROXY_KEY, proxy); &amp;#125; Invoker&lt;?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString())); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?> exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &amp;#125; &amp;#125; else &amp;#123; Invoker&lt;?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?> exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &amp;#125; /** * @since 2.7.0 * ServiceData Store */ MetadataReportService metadataReportService = null; if ((metadataReportService = getMetadataReportService()) != null) &amp;#123; metadataReportService.publishProvider(url); &amp;#125; &amp;#125; &amp;#125; this.urls.add(url); &amp;#125; Local服务只是injvm 的服务, 提供一种消费者和提供者都在一个jvm 内的调用方式. 使用injvm 协议, 只是一个伪协议, 它不开启端口,不发起远程调用, 只是JVM内部直接关联(通过集合的方法保存了发布的服务信息),但执行Dubbo的Filter 链. 简单来说, 就是你本地的dubbo服务调用, 都依托于dubbo 的标准来进行, 这样可以享受到dubbo 的一些配置服务. Remote表示根据配置的注册中心进行远程发布, 遍历多个注册中心, 进行协议的发布. incoker 是一个代理类, 它是dubbo 的核心模型, 其他模型都是向它靠拢, 或转换成它. 它代表一个可执行体, 可向它发起invoke 调用, 他有可能是一个本地的实现, 也有可能是一个远程的实现, 也有可能是一个集群实现. DelegateProviderMetaDataInvoker, 因为2.7 引入了元数据, 所以这里对invoker 进行了委托, 把invoker 交给了 DelegateProviderMetaDataInvoker 来处理 调用 protocol.export(invoker) 来发布这个代理. 添加到 exporters 集合中. protocol.export protocol.export 这个protocol 是什么呢? 找到定义出发现它是一个自适应扩展点, 打开Protocol 这个扩展点, 又可以看到他是一个在方法层面上的自适应扩展， 意味着它实现了对于export 这个方法的适配, 也就意味着Protocol 是一个动态代理类, Protocol$Adaptive private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 这个动态代理类, 会根据url 中配置的 protocol name 来实现对应协议的适配. public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol &amp;#123; public void destroy() &amp;#123; throw new UnsupportedOperationException(\"The method public abstract void org.apache.dubbo.rpc.Protocol.destroy()of interface org.apache.dubbo.rpc.Protocol is not adaptive method !\"); &amp;#125; public int getDefaultPort() &amp;#123; throw new UnsupportedOperationException(\"The method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort()of interface org.apache.dubbo.rpc.Protocol is not adaptive method !\"); &amp;#125; public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc. RpcException &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys ([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &amp;#125; public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys ([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &amp;#125; &amp;#125; 那么在当前的场景中, protocol 会调用谁呢? 目前发布的invoker(URL), 实际上是一个 registry://协议, 所以 Protocol$Adaptive，会通过 getExtension(extName)得到一个 RegistryProtocol RegistryProtocol.export很明显, 这个RegistryProtocol 是用来实现服务注册的, 则里面会有很多处理逻辑. 实现对应协议的服务发布 实现服务注册 订阅服务重写 public &lt;T> Exporter&lt;T> export(final Invoker&lt;T> originInvoker) throws RpcException &amp;#123; // 这里获取的是zookeeper 注册中心的url zookeeper://ip:port URL registryUrl = getRegistryUrl(originInvoker); // url to export locally // 这里是获得服务提供者的url dubbo://ip:port URL providerUrl = getProviderUrl(originInvoker); // Subscribe the override data // FIXME When the provider subscribes, it will affect the scene : a certain JVM exposes the service and call // the same service. Because the subscribed is cached key with the name of the service, it causes the // subscription information to cover. // 订阅 override数据, 在admin 控制台可以针对服务进行治理, 比如修改权重、修改路由机制等, 当有注册中心由此服务的覆盖配置注册进行的时候, // 推送消息给提供者, 重新暴露服务. final URL overrideSubscribeUrl = getSubscribedOverrideUrl(providerUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); providerUrl = overrideUrlWithConfig(providerUrl, overrideSubscribeListener); //export invoker // 这里交给具体的协议去暴露服务 final ExporterChangeableWrapper&lt;T> exporter = doLocalExport(originInvoker, providerUrl); // url to registry // 根据invoker 中的url 获取registry实例 , zookeeperRegistry final Registry registry = getRegistry(originInvoker); // 获取要注册到注册中心的url : dubbo://ip:port final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); ProviderInvokerWrapper&lt;T> providerInvokerWrapper = ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); //to judge if we need to delay publish boolean register = registeredProviderUrl.getParameter(\"register\", true); // 是否配置了注册中心, 如果是,则需要配置 if (register) &amp;#123; // 注册到注册中心的URL register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); &amp;#125; // 注册中心的订阅 // Deprecated! Subscribe to override rules in 2.6.x or before. registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); exporter.setRegisterUrl(registeredProviderUrl); exporter.setSubscribeUrl(overrideSubscribeUrl); //Ensure that a new exporter instance is returned every time export // 保存每次export 都返回一个新的exporter 实例 return new DestroyableExporter&lt;>(exporter); &amp;#125; doLocalExport先通过doLocalExport 来暴露一个服务, 本质上应该是启动一个通信服务, 主要的步骤是将本地ip和20880 端口打开, 进行监听。 originInvoker : 应该是 registry://ip:port/com.alibaba.dubbo.registry.RegistryService key: 从 originInvoker 中获得发布协议的 url: dubbo://ip:port/… bounds: 一个 prviderUrl 服务 export 之后，缓存到 bounds 中，所以一个 providerUrl 只会对应一个 exporter private &lt;T> ExporterChangeableWrapper&lt;T> doLocalExport(final Invoker&lt;T> originInvoker, URL providerUrl) &amp;#123; String key = getCacheKey(originInvoker); return (ExporterChangeableWrapper&lt;T>) bounds.computeIfAbsent(key, s -> &amp;#123; // 对原有的 invoker 委托给了invokerDelegate Invoker&lt;?> invokerDelegate = new InvokerDelegate&lt;>(originInvoker, providerUrl); // 将invoke 转换成了exporter 并且启动netty 服务 return new ExporterChangeableWrapper&lt;>((Exporter&lt;T>) protocol.export(invokerDelegate), originInvoker); &amp;#125;); &amp;#125; InvokerDelegete : 是 RegistryProtocol 的一个静态内部类, 该类是一个 originInvoker 的委托类, 该类存储了 originInvoker ,其父类 InvokerWrapper 还会存储 providerUrl，InvokerWrapper 会调用 originInvoker 的invoke方法, 也会销毁invoke. 可以管理invoke的生命周期. DubboProtocol.export基于动态代理的适配, 很自然的就过渡到了 DubboProtocol 这个协议类, 但是实际上是 DubboProtocol 吗? 这里并不是获取一个单纯的 DubboProtocol 扩展点, 而是会通过Wrapper 对Protocol 进行装饰, 装饰器分别为 QosProtocolWrapper/ProtocolListenerWrapper/ProtocolFilterWrapper/DubboProtocol . 为什么是这样呢? 我们再来看看SPI的代码 Wrapper 包装在 ExtensionLoader.loadClass 这个方法中, 有一段这样的判断, 如果当前这个类是一个Wrapper 包装类, 也及时这个wrapper 中有构造方法, 参数是当前被加载的扩展点的类型, 则把这个wrapper 类加入到 cacheWrapperClass 缓存中., &amp;#125; else if (isWrapperClass(clazz)) &amp;#123; cacheWrapperClass(clazz); &amp;#125; private void cacheWrapperClass(Class&lt;?> clazz) &amp;#123; if (cachedWrapperClasses == null) &amp;#123; cachedWrapperClasses = new ConcurrentHashSet&lt;>(); &amp;#125; cachedWrapperClasses.add(clazz); &amp;#125; 我们可以在dubbo 的配置文件中找到三个wrapper QosprotocolWrapper， 如果当前配置了注册中心, 则会启动一个QosServer, qos 是dubbo 的在线运维命令, dubbo2.5.8 版本重构了telnet模块, 提供了新的telnet 命令支持, 新版本的telnet 端口与dubbo 协议的端口是不同的端口, 默认的为22222 ProtocolFilterWrapper 对invoker 进行filter 包装, 实现请求的过滤. ProtocolListenerWrapper 用于服务export 时候插入监听机制. qos=org.apache.dubbo.qos.protocol.QosProtocolWrapper filter=org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper listener=org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper 接着, 在 getExtension-&gt;createExtension 方法中, 会对 cacheWrapperClass 集合进行判断, 如果集合不为空, 则进行包装 Set&lt;Class&lt;?>> wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) &amp;#123; for (Class&lt;?> wrapperClass : wrapperClasses) &amp;#123; instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &amp;#125; &amp;#125; ProtocolFilterWrapper这是一个过滤器的包装, 使用责任链模式, 对invoker 进行包装. @Override public &lt;T> Exporter&lt;T> export(Invoker&lt;T> invoker) throws RpcException &amp;#123; if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &amp;#123; return protocol.export(invoker); &amp;#125; return protocol.export(buildInvokerChain(invoker, SERVICE_FILTER_KEY, CommonConstants.PROVIDER)); &amp;#125; // 构建责任链, 基于激活扩展点 private static &lt;T> Invoker&lt;T> buildInvokerChain(final Invoker&lt;T> invoker, String key, String group) &amp;#123; Invoker&lt;T> last = invoker; List&lt;Filter> filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); .... &amp;#125; 我们看如下文件: /dubbo-rpc-api/src/main/resources/META-INF/dubbo/internal/com.alibaba.dubbo.rpc.Filter 默认提供了非常多的过滤器, 然后基于条件激活扩展点, 来对invoker 进行包装, 从而实现在远程调用的到时候, 会经过这些filter 进行过滤. DubboProtocol.export @Override public &lt;T> Exporter&lt;T> export(Invoker&lt;T> invoker) throws RpcException &amp;#123; // 获取服务标识, 理解成服务坐标也行, 由服务组名, 服务名,服务版本号以及端口组成,比如: // //$&amp;#123;group&amp;#125;/com.example.ISayHelloService:$&amp;#123;version&amp;#125;:20880 URL url = invoker.getUrl(); // export service. String key = serviceKey(url); // 创建DubboExporter DubboExporter&lt;T> exporter = new DubboExporter&lt;T>(invoker, key, exporterMap); // 将 key,exporter 键值对放入缓存中 exporterMap.put(key, exporter); //export an stub service for dispatching event Boolean isStubSupportEvent = url.getParameter(STUB_EVENT_KEY, DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice) &amp;#123; String stubServiceMethods = url.getParameter(STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(new IllegalStateException(\"consumer [\" + url.getParameter(INTERFACE_KEY) + \"], has set stubproxy support event ,but no stub methods founded.\")); &amp;#125; &amp;#125; else &amp;#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &amp;#125; &amp;#125; // 启动服务 openServer(url); optimizeSerialization(url); return exporter; &amp;#125; openServer去开启一个服务, 并且放入缓存中-&gt; 在同一台机器上(单网卡上), 同一个端口上仅允许启动一个服务器实例 private void openServer(URL url) &amp;#123; // find server. // 获取 host:port,并将其作为服务器实例的key, 用于标识当前的服务器实例. String key = url.getAddress(); //client can export a service which's only for server to invoke // client 也可以暴露一个只有server 可以调用的服务 boolean isServer = url.getParameter(IS_SERVER_KEY, true); if (isServer) &amp;#123; // 是否在serverMap 中缓存了 ExchangeServer server = serverMap.get(key); if (server == null) &amp;#123; synchronized (this) &amp;#123; server = serverMap.get(key); if (server == null) &amp;#123; serverMap.put(key, createServer(url)); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; // server supports reset, use together with override // 服务已经创建, 则根据url 中配置 重置服务器. server.reset(url); &amp;#125; &amp;#125; &amp;#125; createServer创建服务, 开启心跳检测,默认使用netty, 组装url . private ExchangeServer createServer(URL url) &amp;#123; // 组装url, 在url 中添加心跳时间,编解码参数 url = URLBuilder.from(url) // send readonly event when server closes, it's enabled by default // 当服务关闭后, 发送一个只读的事件, 默认是开启状态. .addParameterIfAbsent(CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()) // 启动心跳配置 // enable heartbeat by default .addParameterIfAbsent(HEARTBEAT_KEY, String.valueOf(DEFAULT_HEARTBEAT)) .addParameter(CODEC_KEY, DubboCodec.NAME) .build(); String str = url.getParameter(SERVER_KEY, DEFAULT_REMOTING_SERVER); // 通过SPI检测是否存在server 参数所代表的Transporter 扩展, 不存在则抛出异常 if (str != null &amp;&amp; str.length() > 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &amp;#123; throw new RpcException(\"Unsupported server type: \" + str + \", url: \" + url); &amp;#125; // 创建ExchangeServer ExchangeServer server; try &amp;#123; server = Exchangers.bind(url, requestHandler); &amp;#125; catch (RemotingException e) &amp;#123; throw new RpcException(\"Fail to start server(url: \" + url + \") \" + e.getMessage(), e); &amp;#125; str = url.getParameter(CLIENT_KEY); if (str != null &amp;&amp; str.length() > 0) &amp;#123; Set&lt;String> supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); if (!supportedTypes.contains(str)) &amp;#123; throw new RpcException(\"Unsupported client type: \" + str); &amp;#125; &amp;#125; return server; &amp;#125; Exchangers.bind public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &amp;#123; if (url == null) &amp;#123; throw new IllegalArgumentException(\"url == null\"); &amp;#125; if (handler == null) &amp;#123; throw new IllegalArgumentException(\"handler == null\"); &amp;#125; // 获取exchange, 默认为HeaderExchanger。 // 调用 HeaderExchanger 的bind方法 创建ExchangeServer 实例. url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); return getExchanger(url).bind(url, handler); &amp;#125; HeaderExchanger.bind这里面包含多个逻辑: new DecodeHandler(new HeaderExchangeHandler(handler)) Transporters.bind new HeaderExchangeServer 目前我们只需要关心 transporters.bind 方法即可: @Override public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &amp;#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler)))); &amp;#125; Transporters.bind public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &amp;#123; if (url == null) &amp;#123; throw new IllegalArgumentException(\"url == null\"); &amp;#125; if (handlers == null || handlers.length == 0) &amp;#123; throw new IllegalArgumentException(\"handlers == null\"); &amp;#125; ChannelHandler handler; if (handlers.length == 1) &amp;#123; handler = handlers[0]; &amp;#125; else &amp;#123; // 如果handler 的元素数量大于1, 则创建ChannelHandlerDispatcher 分发器 handler = new ChannelHandlerDispatcher(handlers); &amp;#125; // 获取自适应Transporter 实例, 并调用实例方法 return getTransporter().bind(url, handler); &amp;#125; getTransportergetTransporter 是一个自适应扩展点, 它针对bind方法添加了自适应注解, 意味着 bind方法的具体实现, 会基于Transporter$Adaptive 方法进行适配, 那么在这里面默认的通讯协议是netty, 所以它会采用netty4 的实现, 也就是 org.apache.dubbo.remoting.transport.netty4.NettyTransporter public static Transporter getTransporter() &amp;#123; return ExtensionLoader.getExtensionLoader(Transporter.class).getAdaptiveExtension(); &amp;#125; NettyTransporter.bind创建一个 nettyserver @Override public Server bind(URL url, ChannelHandler listener) throws RemotingException &amp;#123; return new NettyServer(url, listener); &amp;#125; nettyserver初始化一个 nettyserver , 并且从url中获取相应的ip/port, 然后调用 doOpen() public NettyServer(URL url, ChannelHandler handler) throws RemotingException &amp;#123; super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME))); &amp;#125; public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &amp;#123; super(url, handler); localAddress = getUrl().toInetSocketAddress(); // 获取ip和端口号 String bindIp = getUrl().getParameter(Constants.BIND_IP_KEY, getUrl().getHost()); int bindPort = getUrl().getParameter(Constants.BIND_PORT_KEY, getUrl().getPort()); if (url.getParameter(ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(bindIp)) &amp;#123; bindIp = ANYHOST_VALUE; &amp;#125; bindAddress = new InetSocketAddress(bindIp, bindPort); this.accepts = url.getParameter(ACCEPTS_KEY, DEFAULT_ACCEPTS); this.idleTimeout = url.getParameter(IDLE_TIMEOUT_KEY, DEFAULT_IDLE_TIMEOUT); try &amp;#123; // 调用模板方法 doOpen 启动服务器 doOpen(); if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Start \" + getClass().getSimpleName() + \" bind \" + getBindAddress() + \", export \" + getLocalAddress()); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to bind \" + getClass().getSimpleName() + \" on \" + getLocalAddress() + \", cause: \" + t.getMessage(), t); &amp;#125; //fixme replace this with better method DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); executor = (ExecutorService) dataStore.get(Constants.EXECUTOR_SERVICE_COMPONENT_KEY, Integer.toString(url.getPort())); &amp;#125; doOpen()开启Netty服务 protected void doOpen() throws Throwable &amp;#123; bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory(\"NettyServerBoss\", true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), new DefaultThreadFactory(\"NettyServerWorker\", true)); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;NioSocketChannel>() &amp;#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &amp;#123; // FIXME: should we use getTimeout()? int idleTimeout = UrlUtils.getIdleTimeout(getUrl()); NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ch.pipeline()//.addLast(\"logging\",new LoggingHandler(LogLevel.INFO))//for debug .addLast(\"decoder\", adapter.getDecoder()) .addLast(\"encoder\", adapter.getEncoder()) .addLast(\"server-idle-handler\", new IdleStateHandler(0, 0, idleTimeout, MILLISECONDS)) .addLast(\"handler\", nettyServerHandler); &amp;#125; &amp;#125;); // bind ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel(); &amp;#125; 然后大家要注意, 这里用到了一个handler 来处理客户端传过来的请求. nettyServerHandler NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); 这个handler 是一个链路, 它的正确组成应该是: MultiMessageHandler(heartbeatHandler(AllChannelHandler(DecodeHandler(HeaderExchangeHeadler(dubboProtocol 后续接收到的请求, 会一层一层的处理, 比较繁琐. invoker 是什么?从前面的分析来看, 服务的发布分为三个阶段. 第一个阶段会创建一个invoker 第二个阶段会把经过一系列处理的invoker(各种包装),在 DubboProtocol 中保存到 exporterMap 中. 第三个节点把dubbo协议的url 地址注册到注册中心 invoker 是Dubbo 领域一个非常重要的概念, 和ExtensionLoader 的重要性是一样的, 如果invoker 没有搞懂, 不算看懂了Dubbo的源码. 我们继续回到 ServiceConfig 的 export 的代码, 这段代码是还没有分析过的, 以这个作为入口来分析我们前面export出去的invoker 到底是什么东西? Invoker&lt;?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString())); proxyFactory.getInvoker这是一个代理工厂, 用来生成 invoker, 从它的定义来看, 它是一个自适应扩展点, 看到这样的扩展点,我们几乎可以不假思索的想到它会存在一个动态适配类. private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); ProxyFactory这个方法的简单解读为: 它是一个SPI 扩展点, 并且默认的扩展实现为 javassit, 这个接口中有三个方法, 并且都加了 @Adaptive 自适应扩展点, 所以如果调用 getInvoker 方法, 应该会返回一个 ProxyFactory$Adaptive @SPI(\"javassist\") public interface ProxyFactory &amp;#123; /** * create proxy. * * @param invoker * @return proxy */ @Adaptive(&amp;#123;PROXY_KEY&amp;#125;) &lt;T> T getProxy(Invoker&lt;T> invoker) throws RpcException; /** * create proxy. * * @param invoker * @return proxy */ @Adaptive(&amp;#123;PROXY_KEY&amp;#125;) &lt;T> T getProxy(Invoker&lt;T> invoker, boolean generic) throws RpcException; /** * create invoker. * * @param &lt;T> * @param proxy * @param type * @param url * @return invoker */ @Adaptive(&amp;#123;PROXY_KEY&amp;#125;) &lt;T> Invoker&lt;T> getInvoker(T proxy, Class&lt;T> type, URL url) throws RpcException; &amp;#125; ProxyFactory$Adaptive这个自适应扩展点, 做了两件事情: 通过 ExtensionLoader.getExtensionLoader(ProxyFactory.class).getExtension(extName) 获取一个指定名称的扩展点 在 dubbo-rpc-api/resources/META-INF/com.alibaba.dubbo.rpc.ProxyFactory 中，定义了 javassis=JavassisProxyFactory 调用 JavassisProxyFactory 的 getInvoker 方法 public class ProxyFactory$Adaptive implements org.apache.dubbo.rpc.ProxyFactory &amp;#123; public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); &amp;#125; public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0, boolean arg1) throws org.apache.dubbo. rpc.RpcException &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0, arg1); &amp;#125; public org.apache.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, org.apache.dubbo.common.URL arg2) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg2 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg2; String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.ProxyFactory) name from url (\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); &amp;#125; &amp;#125; JavassistProxyFactory.getInvoker javassist : 是一个动态类库, 用来实现动态代理. proxy : 接口的实现, com.example.SayHelloServiceImpl type : 接口全称: com.example.ISayHelloService url: 协议地址: registry://…. @Override public &lt;T> Invoker&lt;T> getInvoker(T proxy, Class&lt;T> type, URL url) &amp;#123; // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T>(proxy, type, url) &amp;#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?>[] parameterTypes, Object[] arguments) throws Throwable &amp;#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &amp;#125; &amp;#125;; &amp;#125; javassist 生成的动态代理代码通过断点的方式( Wrapper 258),在 Wrapper.getWrapper 中的 makeWrapper 会创建一个动态代码, 核心的方法 invokeMethod 代码如下: public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException &amp;#123; com.ISayHelloService w; try &amp;#123; w = ((com.ISayHelloService) $1); &amp;#125; catch (Throwable e) &amp;#123; throw new IllegalArgumentException(e); &amp;#125; try &amp;#123; if (\"sayHello\".equals($2) &amp;&amp; $3.length == 1) &amp;#123; return ($w) w.sayHello((java.lang.String) $4[0]); &amp;#125; &amp;#125; catch (Throwable e) &amp;#123; throw new java.lang.reflect.InvocationTargetException(e); &amp;#125; throw new org.apache.dubbo.common.bytecode.NoSuchMethodException(\"Not found method \\\"\" + $2 + \"\\\" in class com.ISayHelloService.\"); &amp;#125; 构建好代理类后, 返回一个 AbstractproxyInvoker ,并且实现了 doInvoke 方法, 这个方法似乎看到了dubbo 消费者调用过来的时候触发的影子, 因为 wrapper.invokeMethod 本质上就是触发上面动态代理类的方法 invokeMethod. return new AbstractProxyInvoker&lt;T>(proxy, type, url) &amp;#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?>[] parameterTypes, Object[] arguments) throws Throwable &amp;#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &amp;#125; &amp;#125;; 所以简单总结一下 invoke 本质上应该是一个代理, 经过层层包装最终进行了发布, 当消费者发起请求的时候, 会获得这个invoker 进行调用. 最终发布触发的invoker, 也不是一个单纯的代理, 也是经过多层包装的. InvokerDelegate(DelegateProviderMetaDataInvoker(AbstractProxyInvoker())) 服务注册流程关于服务发布这一条线分析完成后,再来了解一下服务注册的过程, 希望大家还记得我们之所以走到这一步,是因为我们在 RegistryProtocol 这个类中, 看到了服务发布的流程. @Override public &lt;T> Exporter&lt;T> export(final Invoker&lt;T> originInvoker) throws RpcException &amp;#123; // 这里获取的是zookeeper 注册中心的url zookeeper://ip:port URL registryUrl = getRegistryUrl(originInvoker); // url to export locally // 这里是获得服务提供者的url dubbo://ip:port URL providerUrl = getProviderUrl(originInvoker); // Subscribe the override data // FIXME When the provider subscribes, it will affect the scene : a certain JVM exposes the service and call // the same service. Because the subscribed is cached key with the name of the service, it causes the // subscription information to cover. // 订阅 override数据, 在admin 控制台可以针对服务进行治理, 比如修改权重、修改路由机制等, 当有注册中心由此服务的覆盖配置注册进行的时候, // 推送消息给提供者, 重新暴露服务. final URL overrideSubscribeUrl = getSubscribedOverrideUrl(providerUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); providerUrl = overrideUrlWithConfig(providerUrl, overrideSubscribeListener); //export invoker // 这里交给具体的协议去暴露服务 final ExporterChangeableWrapper&lt;T> exporter = doLocalExport(originInvoker, providerUrl); // url to registry // 根据invoker 中的url 获取registry实例 , zookeeperRegistry final Registry registry = getRegistry(originInvoker); // 获取要注册到注册中心的url : dubbo://ip:port final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); ProviderInvokerWrapper&lt;T> providerInvokerWrapper = ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); //to judge if we need to delay publish boolean register = registeredProviderUrl.getParameter(\"register\", true); // 是否配置了注册中心, 如果是,则需要配置 if (register) &amp;#123; // 注册到注册中心的URL register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); &amp;#125; // 注册中心的订阅 // Deprecated! Subscribe to override rules in 2.6.x or before. registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); exporter.setRegisterUrl(registeredProviderUrl); exporter.setSubscribeUrl(overrideSubscribeUrl); //Ensure that a new exporter instance is returned every time export // 保存每次export 都返回一个新的exporter 实例 return new DestroyableExporter&lt;>(exporter); &amp;#125; 服务注册核心代码从export 方法中抽离出来的部分代码, 就是服务注册的流程. // 根据invoker 中的url 获取registry实例 , zookeeperRegistry final Registry registry = getRegistry(originInvoker); // 获取要注册到注册中心的url : dubbo://ip:port final URL registeredProviderUrl = getRegisteredProviderUrl(providerUrl, registryUrl); ProviderInvokerWrapper&lt;T> providerInvokerWrapper = ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); //to judge if we need to delay publish boolean register = registeredProviderUrl.getParameter(\"register\", true); // 是否配置了注册中心, 如果是,则需要配置 if (register) &amp;#123; // 注册到注册中心的URL register(registryUrl, registeredProviderUrl); providerInvokerWrapper.setReg(true); &amp;#125; getRegistry 把url 转换为对应配置的注册中心的具体协议 根据具体的协议,从 registryFactory 中获取指定的注册中心实现 那么这个 registryFactory 具体是怎么赋值的呢? private Registry getRegistry(final Invoker&lt;?> originInvoker) &amp;#123; // 将url 转换为配置的具体协议, 比如 zookeeper://ip:port, 这样后续获取的注册中心就是基于zk的实现 URL registryUrl = getRegistryUrl(originInvoker); return registryFactory.getRegistry(registryUrl); &amp;#125; 在 RegistryProtocol 中存在这样一段代码, 很明显这是通过依赖注入来实现扩展点的. public void setRegistryFactory(RegistryFactory registryFactory) &amp;#123; this.registryFactory = registryFactory; &amp;#125; 根据扩展点的加载规则, 我们可以先看看 /META-INF/dubbo/internal 路径下找到 RegistryFactory 的配置文件, 这个factory 有多个扩展点的实现 dubbo=org.apache.dubbo.registry.dubbo.DubboRegistryFactory multicast=org.apache.dubbo.registry.multicast.MulticastRegistryFactory zookeeper=org.apache.dubbo.registry.zookeeper.ZookeeperRegistryFactory redis=org.apache.dubbo.registry.redis.RedisRegistryFactory consul=org.apache.dubbo.registry.consul.ConsulRegistryFactory etcd3=org.apache.dubbo.registry.etcd.EtcdRegistryFactory 接着, 找到 RegistryFactory 的实现, 发现它里面有一个自适应的方法, 根据url 中protocol 传入的值进行适配. @SPI(\"dubbo\") public interface RegistryFactory &amp;#123; /** * Connect to the registry * &lt;p> * Connecting the registry needs to support the contract: &lt;br> * 1. When the check=false is set, the connection is not checked, otherwise the exception is thrown when disconnection &lt;br> * 2. Support username:password authority authentication on URL.&lt;br> * 3. Support the backup=10.20.153.10 candidate registry cluster address.&lt;br> * 4. Support file=registry.cache local disk file cache.&lt;br> * 5. Support the timeout=1000 request timeout setting.&lt;br> * 6. Support session=60000 session timeout or expiration settings.&lt;br> * * @param url Registry address, is not allowed to be empty * @return Registry reference, never return empty value */ @Adaptive(&amp;#123;\"protocol\"&amp;#125;) Registry getRegistry(URL url); &amp;#125; RegistryFactory$Adaptive由于前面的代码中, url 中的protocol 已经改成了zookeeper, 那么这个时候根据zookeeper 获取的spi 扩展点应该是ZookeeperRegistryFactory import org.apache.dubbo.common.extension.ExtensionLoader; public class RegistryFactory$Adaptive implements org.apache.dubbo.registry.RegistryFactory &amp;#123; public org.apache.dubbo.registry.Registry getRegistry(org.apache.dubbo.common.URL arg0) &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg0; String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.registr y.RegistryFactory) name from url (\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.registry.RegistryFactory extension = (org.apache.dubbo.registry.RegistryFactory)Exten sionLoader.getExtensionLoader(org.apache.dubbo.registry.RegistryFactory.class).getExtension(extName); return extension.getRegistry(arg0); &amp;#125; &amp;#125; ZookeeperRegistryFactory这个方法中并没有 getRegistry 方法,而是在父类 AbstractRegistryFactory 从缓存 REGISTRIES 中, 根据key 获取对应的Registry 如果不存在, 则创建 Registry @Override public Registry getRegistry(URL url) &#123; url = URLBuilder.from(url) .setPath(RegistryService.class.getName()) .addParameter(INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(EXPORT_KEY, REFER_KEY) .build(); String key = url.toServiceStringWithoutResolving(); // Lock the registry access process to ensure a single instance of the registry LOCK.lock(); try &#123; Registry registry = REGISTRIES.get(key); if (registry != null) &#123; return registry; &#125; //create registry by spi/ioc // 创建注册中心 registry = createRegistry(url); if (registry == null) &#123; throw new IllegalStateException(\"Can not create registry \" + url); &#125; REGISTRIES.put(key, registry); return registry; &#125; finally &#123; // Release the lock LOCK.unlock(); &#125; &#125; createRegistry创建一个 zookeeperRegistry，把 url和zookeepertransporter 作为参数传入. zookeepertransporter 这个属性也是基于依赖注入来赋值的, 具体的流程就不在分析了, 这个的值应该是 CuratorZookeeperTransporter , 表示具体使用什么框架来和zk 产生连接. @Override public Registry createRegistry(URL url) &amp;#123; return new ZookeeperRegistry(url, zookeeperTransporter); &amp;#125; ZookeeperRegistry这个方法中使用了 CuratorZookeeperTransport 来实现zk 的连接. public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &amp;#123; super(url); if (url.isAnyHost()) &amp;#123; throw new IllegalStateException(\"registry address == null\"); &amp;#125; // 获取group 的名称 String group = url.getParameter(GROUP_KEY, DEFAULT_ROOT); if (!group.startsWith(PATH_SEPARATOR)) &amp;#123; group = PATH_SEPARATOR + group; &amp;#125; this.root = group; // 产生一个zookeeper 连接 zkClient = zookeeperTransporter.connect(url); // 添加zookeeper 状态变化事件 zkClient.addStateListener(state -> &amp;#123; if (state == StateListener.RECONNECTED) &amp;#123; try &amp;#123; recover(); &amp;#125; catch (Exception e) &amp;#123; logger.error(e.getMessage(), e); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; registry.register(registedProviderUrl);继续往下分析, 会调用 registry.register(registedProviderUrl); 去将 dubbo:// 的协议注册到zookeeper 上. 这个方法会调用 FailbackRegistry 类中的 register ,为什么呢? 因为 ZookeeperRegistry 这个类中并没有registry 这个方法, 但是它的父类 FailbackRegistry 中存在 registry方法, 而这个类又重写了 AbstractRegistry 类中的registry 方法, 所以我们可以直接定位到 FailbackRegistry 这个类中的registry 方法中. public void register(URL registryUrl, URL registeredProviderUrl) &amp;#123; Registry registry = registryFactory.getRegistry(registryUrl); registry.register(registeredProviderUrl); &amp;#125; FailbackRegistry.register FailbackRegistry 从名字来看, 是一个失败重试机制. 调用父类的 registry方法, 将当前url 添加到缓存集合中. 调用 doRegister 这个方法, 这个方法很明显, 是一个抽象方法, 会由 ZookeeperRegistry 的子类实现. @Override public void register(URL url) &amp;#123; super.register(url); removeFailedRegistered(url); removeFailedUnregistered(url); try &amp;#123; // Sending a registration request to the server side // 调用子类实现真正的服务注册, 把url 注册到zk上. doRegister(url); &amp;#125; catch (Exception e) &amp;#123; Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. // 如果开启了启动时检测, 则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &amp;#123; if (skipFailback) &amp;#123; t = t.getCause(); &amp;#125; throw new IllegalStateException(\"Failed to register \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); &amp;#125; else &amp;#123; logger.error(\"Failed to register \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &amp;#125; // Record a failed registration request to a failed list, retry regularly // 将失败了的注册请求记录到失败列表, 定时重试 addFailedRegistered(url); &amp;#125; &amp;#125; ZookeeperRegistry.doRegister最终调用curator 的客户端把服务地址注册到zk 上去. @Override public void doRegister(URL url) &amp;#123; try &amp;#123; zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true)); &amp;#125; catch (Throwable e) &amp;#123; throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); &amp;#125; &amp;#125;","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"Dubbo之SPI机制","slug":"微服务/dubbo/Dubbo之SPI机制","date":"2022-01-04T02:42:07.285Z","updated":"2022-01-04T02:42:07.285Z","comments":true,"path":"2022/01/04/wei-fu-wu/dubbo/dubbo-zhi-spi-ji-zhi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/dubbo/dubbo-zhi-spi-ji-zhi/","excerpt":"","text":"Dubbo之API机制简介本文的源码是基于Dubbo 2.7.2 版本进行分析的.这里, 我们首先将Dubbo 里面用的比较多的SPI 机制做一个详细的分析 Dubbo 中的SPI机制关于Java SPI了解Dubbo 里面的SPI机制之前, 我们先了解一下Java 提供了SPI(service provider interface)机制, SPI是JDK 内置的一种服务提供发现机制, 目前市面上有很多的框架都是用它来做服务的扩展发.简单来说, 它是一种动态替换发现的机制, 举个简单的例子, 我们想在运行时动态的给它添加实现, 你只需要添加一个实现, 然后把新的实现描述给JDK知道就行了,大家耳熟能详的如JDBC、日志框架都有用到. 实现SPI需要遵循的标准我们如何去实现一个标准的SPI发现机制呢? 其实很简单,只需要满足以下提交就行了. 需要在classpath 下创建一个目录, 该目录命名必须是: META-INF/service 在该目录下创阿基哪一个properties文件, 该文件需要满足以下几个条件 文件名必须是扩展接口的全路径名称 文件内部描述的是该扩展接口的所有实现类 文件的编码格式是UTF-8 通过 java.util.ServiceLoader 的加载机制来发现. SPI的实际应用SPI 在很多地方有应用, 可能大家都没有关注,最常用的就是JDBC 驱动,我们来看看是怎么应用的. JDK本身提供了数据访问的API，在java.sql 这个包里面, 我们在链接数据库的时候, 一定需要用到java.sql.Driver 这个接口对吧, 然后我好奇的去看了下java.sql.Driver, 发现Driver 并没有实现, 而是提供了一套标准的api 接口. 因为我们在实际应用中用的比较多的是mysql, 所以在mysql的包里面看到了如下的目录结构. 这个文件里面写的就是mysql的驱动实现, 是通过SPI 机制把java.sql.Driver 的启动做了集成, 这样就达到了各个数据库厂商自己去实现数据库连接, jdk 本身不关心怎么实现. SPI的缺点 JDK标准的SPI会一次性加载实例化扩展点的所有的实现, 什么意思呢? 就是如果你在META-INF/service 下的文件夹了N个实现类, 那么JDK启动的时候就会一次性的全部加载。如果有的扩展点实现初始化很耗时或者如果有的实现类并没有用到, 那么会很浪费资源. 如果扩展点加载失败, 会导致调用方报错, 而且这个错误很难定位到是这个原因. Dubbo优化后的SPI机制基于Dubbo SPI的实现自己的扩展Dubbo 的SPI扩展机制, 有两个规则: 需要在resource目录下配置 META-INF/dubbo 或者 META-INF/dubbo/internal 或者 META-INF/services ,并基于SPI 接口去创建一个文件. 文件名称和接口文件必须保持一致, 文件内容和SPI有差异, 内容是Key对应Value。 Dubbo 针对的扩展点非常多,可以针对协议、拦截、集群、路由、负载均衡、序列化、容器..几乎里面用到的所有功能, 都可以实现自己的扩展. 比如, 我们可以针对协议做一个扩展 扩展协议扩展点 创建如下结构, 添加 META-INF/dubbo 目录, 添加文件, 文件名和Dubbo 提供的协议扩展点接口保持一致. 创建MyProtocol 协议类 可以实现自己的协议, 我们为了模拟协议产生的作用, 修改了一个端口 package com.dubbo.spring.server; import org.apache.dubbo.common.URL; import org.apache.dubbo.rpc.Exporter; import org.apache.dubbo.rpc.Invoker; import org.apache.dubbo.rpc.Protocol; import org.apache.dubbo.rpc.RpcException; /** * @author luyanan * @since 2019/11/25 * &lt;p>自定义协议类&lt;/p> **/ public class MyProtocol implements Protocol &amp;#123; @Override public int getDefaultPort() &amp;#123; return 8888; &amp;#125; @Override public &lt;T> Exporter&lt;T> export(Invoker&lt;T> invoker) throws RpcException &amp;#123; return null; &amp;#125; @Override public &lt;T> Invoker&lt;T> refer(Class&lt;T> type, URL url) throws RpcException &amp;#123; return null; &amp;#125; @Override public void destroy() &amp;#123; &amp;#125; &amp;#125; 在调用处执行如下代码 Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(\"myProtocol\"); System.out.println(protocol.getDefaultPort()); 输出结果, 可以看到运行结果, 是执行的自定义的协议扩张点. 总的来说, 思路和SPI是差不多的, 都是基于约定的路径下制定配置文件, 目的是通过配置的方式轻松的实现功能的扩展. 我们的猜想是: 一定有一个地方通过读取制定路径下的所有文件进行load, 然后将对应的结果保存在一个map中, key 对应为名称, value 对应的为实现类. 那么这个实现, 一定就在ExtensionLoader 中, 接下来我们就可以基于这个猜想去看看代码的实现. Dubbo 的扩展点实现原理在查看它的代码之前,大家先思考两个问题, 所谓的扩展点, 就是通过制定目录下配置一个对应接口的实现类, 然后程序会进行查找和解析, 找到对应的扩展点. 那么这里就涉及到两个问题. 怎么解析 被加载的类如何存储和使用 ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(“name”)我们从这段代码着手, 去看看到底做了什么事情, 能够通过这样一段代码实现扩展协议的查找和加载. @SuppressWarnings(\"unchecked\") public static &lt;T> ExtensionLoader&lt;T> getExtensionLoader(Class&lt;T> type) &amp;#123; if (type == null) &amp;#123; throw new IllegalArgumentException(\"Extension type == null\"); &amp;#125; if (!type.isInterface()) &amp;#123; throw new IllegalArgumentException(\"Extension type (\" + type + \") is not an interface!\"); &amp;#125; if (!withExtensionAnnotation(type)) &amp;#123; throw new IllegalArgumentException(\"Extension type (\" + type + \") is not an extension, because it is NOT annotated with @\" + SPI.class.getSimpleName() + \"!\"); &amp;#125; // 初始化ExtensionLoader ExtensionLoader&lt;T> loader = (ExtensionLoader&lt;T>) EXTENSION_LOADERS.get(type); if (loader == null) &amp;#123; EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T>(type)); loader = (ExtensionLoader&lt;T>) EXTENSION_LOADERS.get(type); &amp;#125; return loader; &amp;#125; 实例化ExtensionLoader如果当前的type= ExtensionFactory.type ,那么 objectFactory == null, 否则会创建一个自适应扩展点给到 objectFactory private ExtensionLoader(Class&lt;?> type) &amp;#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()); &amp;#125; getExtension @SuppressWarnings(\"unchecked\") public T getExtension(String name) &amp;#123; if (StringUtils.isEmpty(name)) &amp;#123; throw new IllegalArgumentException(\"Extension name == null\"); &amp;#125; // 如果name 为true, 表示返回一个默认的扩展点 if (\"true\".equals(name)) &amp;#123; return getDefaultExtension(); &amp;#125; Holder&lt;Object> holder = getOrCreateHolder(name); // 缓存一下, 如果实例中已经加载过, 则直接从缓存中获取 Object instance = holder.get(); if (instance == null) &amp;#123; synchronized (holder) &amp;#123; instance = holder.get(); if (instance == null) &amp;#123; // 根据名称创建实例 instance = createExtension(name); holder.set(instance); &amp;#125; &amp;#125; &amp;#125; return (T) instance; &amp;#125; createExtension根据名称创建扩展, :getExtensionClasses() 加载指定路径下的所有文件 @SuppressWarnings(\"unchecked\") private T createExtension(String name) &amp;#123; Class&lt;?> clazz = getExtensionClasses().get(name); if (clazz == null) &amp;#123; // 如果没有找到, 抛出异常 throw findException(name); &amp;#125; try &amp;#123; // 这里用一个chm 来保存实例,做缓存使用. T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) &amp;#123; EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &amp;#125; // 实例注入, 对这里实例中的成员属性实现依赖注入的功能. injectExtension(instance); Set&lt;Class&lt;?>> wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) &amp;#123; for (Class&lt;?> wrapperClass : wrapperClasses) &amp;#123; instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &amp;#125; &amp;#125; return instance; &amp;#125; catch (Throwable t) &amp;#123; throw new IllegalStateException(\"Extension instance (name: \" + name + \", class: \" + type + \") couldn't be instantiated: \" + t.getMessage(), t); &amp;#125; &amp;#125; getExtensionClasses()这个方法, 会查找指定目录, /META-INF/dubbo || /META-INF/services 下对应的type-&gt; 也就是本次演示案例中Protocol 的properties 文件, 然后扫描这个文件下的配置信息, 然后保存到一个HashMap中(classes),key=name(对应protocol 文件中配置的myProtocol),value=对应配置的类的实例 private Map&lt;String, Class&lt;?>> getExtensionClasses() &amp;#123; Map&lt;String, Class&lt;?>> classes = cachedClasses.get(); if (classes == null) &amp;#123; synchronized (cachedClasses) &amp;#123; classes = cachedClasses.get(); if (classes == null) &amp;#123; // 这里的代码就是假造的过程. classes = loadExtensionClasses(); cachedClasses.set(classes); &amp;#125; &amp;#125; &amp;#125; return classes; &amp;#125; injectExtension private T injectExtension(T instance) &amp;#123; try &amp;#123; if (objectFactory != null) &amp;#123; // 获取实例对应的方法,判断方法是否是一个set方法 for (Method method : instance.getClass().getMethods()) &amp;#123; if (isSetter(method)) &amp;#123; /** * Check &amp;#123;@link DisableInject&amp;#125; to see if we need auto injection for this property */ // 可以选择禁用依赖注入 if (method.getAnnotation(DisableInject.class) != null) &amp;#123; continue; &amp;#125; // 获取方法的参数, 这个参数必须是一个对象类型并且是一个扩展点 Class&lt;?> pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) &amp;#123; continue; &amp;#125; try &amp;#123; // 获取set方法中的属性名称, 并且根据属性名字进行加载 String property = getSetterProperty(method); Object object = objectFactory.getExtension(pt, property); if (object != null) &amp;#123; // 调用set方法进行赋值 method.invoke(instance, object); &amp;#125; &amp;#125; catch (Exception e) &amp;#123; logger.error(\"Failed to inject via method \" + method.getName() + \" of interface \" + type.getName() + \": \" + e.getMessage(), e); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (Exception e) &amp;#123; logger.error(e.getMessage(), e); &amp;#125; return instance; &amp;#125; 分析到这里, 我们发现所谓的扩展点, 套路有一样, 不管是 springfactorieyLoader，还是 Dubbo 的SPI. 实际上, dubbo 的功能还更强大, 比如自适应扩展点, 比如依赖注入. Adaptive 自适应扩展点什么叫自适应扩展点呢? 我们先来演示一个例子, 在下面这个例子中, 我们传入一个 Compiler 接口, 它就会传入一个 AdaptiveCompiler。这个就叫自适应。 Compiler adaptiveExtension = ExtensionLoader.getExtensionLoader(Compiler.class).getAdaptiveExtension(); System.out.println(adaptiveExtension.getClass()); 它是怎么实现的呢? 我们呢根据返回的AdaptiveCompiler 上, 看到类上有一个注解@Adaptive. 这个就是一个自适应扩展点的标识.它可以修饰在类上, 也可以修饰在方法上, 这两者有什么区别呢? 简单来说, 放在类上, 说明当前类是一个确定的自适应扩展点的类. 如果放在方法级别, 那么需要生成一个动态字节码, 来进行转发. 比如拿Protocol 这个接口来说, 它里面定义了 export 和 refer 两个抽象方法, 这两个方法分别带有@Adaptive 注解, 标识是一个自适应方法. 我们知道 Protocol 是一个通信协议的接口, 具体有多种实现, 那么这个时候选择那一种呢? 取决于我们在使用dubbo 的时候配置的协议名, 而这里的方法层面的@Adaptive 就决定了当前这个方法会采用何种协议来发布服务. getAdaptiveExtension()这个方法主要就是根据传入的接口返回一个自适应的实现类 public T getAdaptiveExtension() &amp;#123; // cachedAdaptiveInstance 是一个缓存, 在dubbo 中大量用到了这种内存缓存 Object instance = cachedAdaptiveInstance.get(); if (instance == null) &amp;#123; if (createAdaptiveInstanceError == null) &amp;#123; synchronized (cachedAdaptiveInstance) &amp;#123; instance = cachedAdaptiveInstance.get(); if (instance == null) &amp;#123; try &amp;#123; // 很明显,这里是创建一个自适应扩展点的实现 instance = createAdaptiveExtension(); cachedAdaptiveInstance.set(instance); &amp;#125; catch (Throwable t) &amp;#123; createAdaptiveInstanceError = t; throw new IllegalStateException(\"Failed to create adaptive instance: \" + t.toString(), t); &amp;#125; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; throw new IllegalStateException(\"Failed to create adaptive instance: \" + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); &amp;#125; &amp;#125; return (T) instance; &amp;#125; createAdaptiveExtension()这个方法中做两件事情: 获取一个自适应扩展点的实例 实现依赖注入 private T createAdaptiveExtension() &amp;#123; try &amp;#123; return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &amp;#125; catch (Exception e) &amp;#123; throw new IllegalStateException(\"Can't create adaptive extension \" + type + \", cause: \" + e.getMessage(), e); &amp;#125; &amp;#125; getAdaptiveExtensionClass() 这个方法在前面讲过了, 会加载当前传入类型的所有扩展点, 保存在一个HashMap中, 这里有一个判断逻辑, 如果 cachedApdaptiveClass！= null, 直接返回这个 cachedApdaptiveClass . cachedApdaptiveClass , 还记得前面讲过 Adaptive 可以放在两个位置, 一个是类级别, 一个是方法级别. 那么这个cachedApdaptiveClass 很明显, 就是放在类上的Adaptive. cachedAdaptiveClass 应该是加载解析 /META-INF/dubbo 下的扩展点的时候加载进来的, 在加载完之后如果这个类有 @Adaptive 标识, 则会赋值. 如果cachedAdaptiveClass 不存在, dubbo 会动态生成一个代理类 Protocol$Adaptive, 前面的名字是protocol 是根据前面 ExtensionLoader 所加载的扩展点来定义的. private Class&lt;?> getAdaptiveExtensionClass() &amp;#123; getExtensionClasses(); if (cachedAdaptiveClass != null) &amp;#123; return cachedAdaptiveClass; &amp;#125; return cachedAdaptiveClass = createAdaptiveExtensionClass(); &amp;#125; createAdaptiveExtensionClass动态生成字节码, 然后进行动态加载。 那么这个时候返回的class 如果加载的是Protocol.class, 就应该是 Protocol$Adaptive , 这个 cachedDefaultName 实际上就是扩展点接口的@SPI 注解对应的名字, 如果此时加载的是Protocol.class, 那么 cachedDefaultName=dubbo private Class&lt;?> createAdaptiveExtensionClass() &amp;#123; String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); ClassLoader classLoader = findClassLoader(); org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader); &amp;#125; Protocol$Adaptive动态生成的代码类, 以下 是通过debug 拿到的代码类. package org.apache.dubbo.rpc; import org.apache.dubbo.common.extension.ExtensionLoader; public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol &amp;#123; public void destroy() &amp;#123; throw new UnsupportedOperationException(\"The method public abstract void org.apache.dubbo.rpc.Protocol.destroy() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &amp;#125; public int getDefaultPort() &amp;#123; throw new UnsupportedOperationException(\"The method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); &amp;#125; public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url (\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &amp;#125; public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException &amp;#123; if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url (\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &amp;#125; &amp;#125; 图形理解简单来说, 上面的基于方法层面的@Adaptive,基于实现原理的图形大概是这样的 injectExtension对于扩展点进行依赖注入,简单来说, 如果当前加载的扩展点中存在一个成员属性(对象), 并且提供了set方法,那么这个方法就会执行依赖注入的. private T injectExtension(T instance) &amp;#123; try &amp;#123; if (objectFactory != null) &amp;#123; // 获取实例对应的方法,判断方法是否是一个set方法 for (Method method : instance.getClass().getMethods()) &amp;#123; if (isSetter(method)) &amp;#123; /** * Check &amp;#123;@link DisableInject&amp;#125; to see if we need auto injection for this property */ // 可以选择禁用依赖注入 if (method.getAnnotation(DisableInject.class) != null) &amp;#123; continue; &amp;#125; // 获取方法的参数, 这个参数必须是一个对象类型并且是一个扩展点 Class&lt;?> pt = method.getParameterTypes()[0]; // 如果不是对象类型, 就跳过 if (ReflectUtils.isPrimitives(pt)) &amp;#123; continue; &amp;#125; try &amp;#123; // 获取set方法中的属性名称, 并且根据属性名字进行加载 // 根据class 以及name, 使用自适用扩展点进行加载并且赋值到当前的set方法 String property = getSetterProperty(method); Object object = objectFactory.getExtension(pt, property); if (object != null) &amp;#123; // 调用set方法进行赋值 method.invoke(instance, object); &amp;#125; &amp;#125; catch (Exception e) &amp;#123; logger.error(\"Failed to inject via method \" + method.getName() + \" of interface \" + type.getName() + \": \" + e.getMessage(), e); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (Exception e) &amp;#123; logger.error(e.getMessage(), e); &amp;#125; return instance; &amp;#125; objectFactory在 injectExtension 这个方法中, 我们发现入口出的代码首先判断了objectFactory 这个对象是否为空, 这个是在哪里初始化的呢? 实际上我们在获取 ExtensionLoader 的时候, 就对 objectFactory 进行了初始化. private ExtensionLoader(Class&lt;?> type) &amp;#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()); &amp;#125; 然后通过 ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()) 去获取一个自适应的扩展点, 进入到ExtensionFactory 这个接口中, 可以看到他是一个扩展点, 并且有一个自己实现的自适应扩展点 AdaptiveExtensionFactory . @ Adaptive 加载到类上表示这是一个自适应的适配器类, 表明我们在调用 getAdaptiveExtension 方法的时候, 不需要走上面那么复杂的流程, 会直接加载到 AdaptiveExtensionFactory。然后在 getAdaptiveExtensionClass()方法处有判断 我们看到除了自定义的自适用适配器以外, 还有别的实现, 一个是SPI， 一个是 AdaptiveExtensionFactory , AdaptiveExtensionFactory 轮询这两个, 从一个中获取到就返回. @Override public &lt;T> T getExtension(Class&lt;T> type, String name) &amp;#123; for (ExtensionFactory factory : factories) &amp;#123; T extension = factory.getExtension(type, name); if (extension != null) &amp;#123; return extension; &amp;#125; &amp;#125; return null; &amp;#125; Activate 自动激活扩展点自动激活扩展点, 有点类似于springboot的 conditional，根据条件进行自动激活. 但是这里涉及的初衷是对于一个类会加载多个扩展点的实现, 这个时候可以通过自动激活扩展点进行动态加载, 从而简化我们的配置工作. 举个例子, 我们可以看看 org.apache.dubbo.Filter 这个类, 它有非常多的实现, 比如说 CacheFilter , 这个缓存过滤器, 配置信息如下: @Activate(group = &amp;#123;CONSUMER, PROVIDER&amp;#125;, value = CACHE_KEY) public class CacheFilter implements Filter &amp;#123; 通过下面这段代码, 演示关于Filter 的自动激活扩展点的效果, 当不添加注释的那段代码的时候, 结果为10, 添加之后结果为11, 会自动把 cacheFilter 加载进来. URL url = new URL(\"\", \"\", 0); // url.addParameter(\"cache\", \"cache\"); ExtensionLoader&lt;Filter> loader = ExtensionLoader.getExtensionLoader(Filter.class); List&lt;Filter> filters = loader.getActivateExtension(url, \"cache\"); System.out.println(filters.size());","categories":[{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"}],"tags":[]},{"title":"阻塞队列,原子操作的原理分析(7)","slug":"并发编程/阻塞队列,原子操作的原理分析(7)","date":"2022-01-04T02:42:07.281Z","updated":"2022-01-04T02:42:07.281Z","comments":true,"path":"2022/01/04/bing-fa-bian-cheng/zu-sai-dui-lie-yuan-zi-cao-zuo-de-yuan-li-fen-xi-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/bing-fa-bian-cheng/zu-sai-dui-lie-yuan-zi-cao-zuo-de-yuan-li-fen-xi-7/","excerpt":"","text":"7. 阻塞队列,原子操作的原理分析阻塞队列生产者消费者的实际使用我们相信大家都有使用过分布式消息队列,比如ActiveMQ,Kafka,RabbitMQ等等,消息队列的是有可能使得程序之间实现解耦,提升程序响应的效率. 如果我们把多线程环境比作是分布式的haunt,那么线程与线程之间是不是也可以这种消息队列的方式进行数据通信和解耦呢? 阻塞队列的使用案例注册成功后增加积分假如我们模拟一个场景,就是用户注册的时候,在注册成功以后发送积分,这个场景在一般来说,我们会这么去实现. 但是实际上,我们需要考虑两个问题： 性能,在注册这个环节上,加入添加用户需要花费1秒钟,增加积分需要花费1秒钟,那么整个注册结果的返回就可能需要大于2秒,虽然影响不大,但是在量比较大的时候我们也需要做一些优化. 耦合,添加用户和添加积分,可以认为是两个领域,也就是说,增加积分并不是注册必须要具备的功能,但是一旦增加积分这个逻辑出现异常,就会导致注册失败,这种耦合在程序设计的时候一定要规避. 因此我们可以通过异步的方式来实现 改进之前的代码逻辑 package com.notes.concurrent.queue; import java.util.concurrent.TimeUnit; /** * @author luyanan * @since 2019/8/16 * &lt;p>&lt;/p> **/ public class UserService &amp;#123; public static void main(String[] args) &amp;#123; UserService service = new UserService(); service.regester(); &amp;#125; public boolean regester() &amp;#123; User user = new User(); user.setName(\"TOM\"); addUser(user); sendPoints(user); return true; &amp;#125; private void sendPoints(User user) &amp;#123; System.out.println(\"发送积分到指定的用户:\" + user); try &amp;#123; TimeUnit.SECONDS.sleep(1); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; private void addUser(User user) &amp;#123; System.out.println(\"添加用户\"); try &amp;#123; TimeUnit.SECONDS.sleep(1); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; class User &amp;#123; private String name; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; &amp;#125; &amp;#125; 改进之后的代码逻辑 package com.notes.concurrent.queue; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.TimeUnit; /** * @author luyanan * @since 2019/8/16 * &lt;p>&lt;/p> **/ public class UserService2 &amp;#123; private final ExecutorService service = Executors.newSingleThreadExecutor(); private volatile boolean isRunning = true; ArrayBlockingQueue&lt;User> queue = new ArrayBlockingQueue(10); &amp;#123; init(); &amp;#125; public void init() &amp;#123; service.execute(() -> &amp;#123; while (isRunning) &amp;#123; try &amp;#123; // 使用阻塞的方式获取队列中的数据 User user = queue.take(); sendPoints(user); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; private void sendPoints(User user) &amp;#123; System.out.println(\"发送积分到指定的用户:\" + user); try &amp;#123; TimeUnit.SECONDS.sleep(1); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; private void addUser(User user) &amp;#123; System.out.println(\"添加用户\"); try &amp;#123; TimeUnit.SECONDS.sleep(1); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; public boolean regester() &amp;#123; User user = new User(); user.setName(\"TOM\"); addUser(user); queue.add(user); return true; &amp;#125; public static void main(String[] args) &amp;#123; UserService2 userService2 = new UserService2(); userService2.regester(); &amp;#125; class User &amp;#123; private String name; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; &amp;#125; &amp;#125; 优化之后,整个流程就变成了这样 在这个案例中,我们使用了ArrayBlockingQueue 基于数组的阻塞队列,来优化代码的执行逻辑 阻塞队列的应用场景阻塞队列这块的应用场景,比较多的仍然是对于生产者消费者场景的应用,但是由于分布式架构的普及,使得大家更多的关注在分布式消息队列上,所以其实入宫把阻塞队列比喻成分布式消息队列的话,那么所谓的生产者和消费者其实就是基于阻塞队列的解耦. 另外,阻塞队列是一个FIFO的队列,所以对于希望在线程需要实现对目标服务的顺序访问的场景中,也可以使用. J.U.C中的消费队列J.U.C 提供的阻塞队列在java8中,提供了7个阻塞队列 ArrayBlockingQueue 数组实现的有界阻塞队列,此队列按照先进先出(FIFO)原则,对元素进行排序 LinkedBlockingQueue 链表实现的有界阻塞队列，此队列的默认和最大长度为Integer.MAX_VALUE.此队列按照先进先出的原则对元素进行排序 PriorityBlockingQueue 支持优先级排序的无界阻塞队列,默认情况下元素采取自然顺序升序排列.也可以自定义实现compareTo()方法来指定元素的排序规则,或者初始化PriortyBlockingQueue时,指定构造函数Comparator 来对元素进行排序 DelayQueue 优先级队列实现的无界阻塞队列 SynchronousQueue 不存储元素的阻塞队列,每一个put 操作都必须等待一个take操作,否则不能继续添加元素 LinkedTransferQueue 链表实现的无界阻塞队列 LinkedBlockingDeque 链表实现的双向阻塞队列 阻塞队列的操作方法在阻塞队列中,提供了四种处理方式 插入操作 add(e): 添加元素到队列中,如果队列满了,继续插入元素会报错(IllegalStateException) offer(e): 添加元素到队列,同时会返回元素是否添加成功的状态,如果成功则返回true put(e): 当阻塞队列满了之后,生产者继续通过put 添加元素,队列会一直阻塞生产者线程,直到队列可用 offer(e,time,unit), 当阻塞队列满了以后,继续添加元素,生产者线程会被阻塞指定时间,如果超时,则线程直接退出. 移除操作 remove(): 当队列为空时调用remove 会返回false, 如果元素移除成功,则返回true poll(): 当队列中存在元素,则从队列中取出一个元素,如果队列为空,则直接返回null take(): 基于阻塞的方式获取队列中的元素,如果队列为空,则take方法会一直阻塞,直到队列中有新的数据可以消费. poll(time,unit) 带超时机制的获取数据,如果队列为空,则会等待指定的时间再去获取元素返回。 ArrayBlockingQueue 原理分析构造方法ArrayBlockingQueue 提供了三个构造方法,分别如下： capacity: 表示数组的长度,也就是队列的长度 fair: 表示是否为公平的阻塞队列,默认情况下构造的是非公平的阻塞队列 第三个参数就不解释了,它提供了接受一个几个作为数据初始化的方法 public ArrayBlockingQueue(int capacity) &amp;#123; this(capacity, false); &amp;#125; /** * Creates an &amp;#123;@code ArrayBlockingQueue&amp;#125; with the given (fixed) * capacity and the specified access policy. * * @param capacity the capacity of this queue * @param fair if &amp;#123;@code true&amp;#125; then queue accesses for threads blocked * on insertion or removal, are processed in FIFO order; * if &amp;#123;@code false&amp;#125; the access order is unspecified. * @throws IllegalArgumentException if &amp;#123;@code capacity &lt; 1&amp;#125; */ public ArrayBlockingQueue(int capacity, boolean fair) &amp;#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; // 重入锁,出队和入队都持有这一把锁 lock = new ReentrantLock(fair); // 初始化非空队列 notEmpty = lock.newCondition(); // 初始化非满等待队列 notFull = lock.newCondition(); &amp;#125; 关于锁的用途,大家在没有看接下来的源码之前,先思考一下他的作用 items构造之后,大概是一个这样的数组 add 方法以add方法作为入口,在add方法中会调用父类的add方法,也就是AbstractQueue, public boolean add(E e) &amp;#123; return super.add(e); &amp;#125; public boolean add(E e) &amp;#123; // 如果队列满了,就直接抛出异常 if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\"); &amp;#125; offer 方法add方法最终还是会调用offer方法来添加数据,返回一个添加成功或者失败的布尔值. 这段代码做了几件事情 判断添加的数据是否为空 添加重入锁 判断队列长度,如果队列长度等于数组长度,表示满了,直接返回false 否则,直接调用 enqueue 将元素添加到队列中 public boolean offer(E e) &amp;#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &amp;#123; if (count == items.length) return false; else &amp;#123; enqueue(e); return true; &amp;#125; &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; enqueue这个是最核心的逻辑,方法内部通过putIndex 索引直接将元素添加到数组items private void enqueue(E x) &amp;#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; // 通过putIndex 对数据赋值 items[putIndex] = x; // 当putIndex 等于数组长度的时候,将putIndex 充值未0 if (++putIndex == items.length) putIndex = 0; // 记录队列元素的个数 count++; // 唤醒处于等待状态下的线程,表示当前队列中的元素不为空,如果存在消费者线程阻塞,就可以取出元素 notEmpty.signal(); &amp;#125; 这里大家肯定会由一个疑问,putIndex 为什么会在等于数组长度的时候 重新设置为0 因为 ArrayBlockingQueue 是一个FIFO的队列,队列添加元素时,是从队尾获取putIndex 来存储元素,当putIndex 等于数组长度的时候,下次就需要从数组头部开始添加了 下面这个图模拟了添加到不同长度的元素时,putIndex的变化,当putIndex 等于数组长度时,不可能让putIndex 继续累加,否则会超出数组初始化的容量大小,同时大家还需要考虑两个问题？ 当元素满了之后是无法继续添加的,因为会报错 其次,队列中的元素肯定会有一个消费者线程通过take 或者其他方法来获取数据,而获取数据的同时元素也会从队列中移除, put方法put方法金额add方法的功能是一样的,差异是put 方法如果队列满了,会阻塞,这个在最开始的时候说过,现在看一下他的实现逻辑 public void put(E e) throws InterruptedException &amp;#123; checkNotNull(e); final ReentrantLock lock = this.lock; // 这个也是获得锁,但是和Lock的区别是,这个方法优先允许在等待时由其他线程调用等待线程的 //interrupt 方法来中断等待直接返回.而lock 方法是尝试获得锁成功后才响应中断 lock.lockInterruptibly(); try &amp;#123; while (count == items.length) // 队列满了的情况下,当前线程会被notFull 条件对象挂起添加到等待队列中 notFull.await(); enqueue(e); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; take 方法take方法是一种阻塞获取队列中元素的方法 他的实现原理很简单.有就删除没有就阻塞,注意这个阻塞是可以中断的,如果队列中没有数据加入到notEmpty 条件队列等待（有数据就直接取走,方法结束),如果有新的put线程添加了数据,那么put操作将会唤醒take线程,直接take操作 public E take() throws InterruptedException &amp;#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &amp;#123; while (count == 0) // 如果队列为空的情况下,直接通过await 进行阻塞 notEmpty.await(); return dequeue(); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; 如果队列中添加了元素,那么这个时候,会在enqueue 中调用notEmpty.signal 唤醒take 线程来获得元素 dequeue 方法这个是出队的方法,主要是删除队列头部的元素并返回给客户端 takeIndex 是用来记录拿数据的索引值 private E dequeue() &amp;#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(\"unchecked\") // 默认获取0位置的元素 E x = (E) items[takeIndex]; // 将元素的位置设置为空 items[takeIndex] = null; // 这里的作用也是一样的,如果拿到数组的最大值,那么重置为0,继续从头部位置开始获取数据 if (++takeIndex == items.length) takeIndex = 0; // 记录元素个数递减 count--; if (itrs != null) // 同时更新迭代器中的元素数据 itrs.elementDequeued(); // 触发因为队列满了以后导致的被阻塞的线程 notFull.signal(); return x; &amp;#125; itrs.elementDequeued()ArrayBlockingQueue 中,实现了迭代器的功能,也就是可以通过迭代器来遍历阻塞队列中的元素 public static void main(String[] args) &amp;#123; ArrayBlockingQueue queue = new ArrayBlockingQueue(10); for (int i = 0; i &lt; 10; i++) &amp;#123; queue.add(\"test-\" + i); &amp;#125; Iterator iterator = queue.iterator(); while (iterator.hasNext())&amp;#123; System.out.println(iterator.next()); &amp;#125; &amp;#125; 结果 test-0 test-1 test-2 test-3 test-4 test-5 test-6 test-7 test-8 test-9 所以itrs.elementDequeued() 是用来更新迭代器中的元素数据的 takeIndex 的索引变化图如下,同时随着数据的移除,会唤醒处于put 阻塞状态下的线程来继续添加数据 remove 方法remove 方法是移除一个指定元素,查看它的实现代码 public boolean remove(Object o) &amp;#123; if (o == null) return false; // 获取数组元素 final Object[] items = this.items; final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &amp;#123; // 如果队列不为空 if (count > 0) &amp;#123; // 获取下一个要添加元素时的索引 final int putIndex = this.putIndex; // 获取当前要被移除时的元素的索引 int i = takeIndex; do &amp;#123; if (o.equals(items[i])) &amp;#123; removeAt(i); return true; &amp;#125; // 当前删除索引执行加1后判断是否与数组长度相等 // 若为true 说明索引已到数组尽头,将i设置为0 if (++i == items.length) i = 0; // 继续查找,知道找到最后一个元素 &amp;#125; while (i != putIndex); &amp;#125; return false; &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; 原子操作类原子性这个概念,在多线程编程里面是一个老生常谈的问题.所谓的原子性表示一个或者多个操作,要么全部执行完,要么一个也不执行,不能出现成功一部分失败一部分的情况. 在多线程中,如果多个线程同时更新同一个共享变量,可能会得到一个意外之外的值,比如i = 1,A 线程更新 i+1,B线程也更新 i+1. 通过这两个线程并行操作之后可能得到i的值不等于3,而可能等于2.因为A和B在更新变量I的时候拿到的i 可能都是1,这就是典型的原子性问题. 在多线程里面,要实现原子性,有几种方法,其中一种就是加synchronized同步锁, 而从JDK1.5开始,在J.U.C包中提供了Atomic包,提供了对于常见的数据结构的原子操作.它提供了简单,高效,以及线程安全的更新一个变量的方式 J.U.C中的原子操作类由于变量类型的关系,在J.U.C中提供了12个原子操作类,这12个类可以分为四大类 原子更新基本类型 AtomicBoolean,AtomicInteger,AtomicLong 原子更新数组 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 原子更新引用 AtomicRegerence、AtomicReferenceFieldUpdater、AtomicMarkableReference(更新带有标记位的引用类型) 原子更新字段 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicStampedReference AtomicInteger 原理分析接下来我们来剖析一下AtomicInteger 的实现原理 getAndIncrementgetAndIncrement方法实际上是调用unsafe这个类里面提供的方法 Unsafe类相当于是一个后门,使得java可以向C的指针一样直接操作内存空间,当然也会带来一些弊端,就是指针的问题,实际上这个类在很多方面都有使用,除了J.U.C这个包以外,还有Netty,Kafka等. 这个类提供了很多的功能,包括多线程同步(monitorEnter),CAS操作(compareAndSwap),线程的挂起和恢复(park/unpark),内存屏障(loadFence/storeFence),内存管理(内存分配,释放内存,获取内存地址等) public final int getAndIncrement() &amp;#123; return unsafe.getAndAddInt(this, valueOffset, 1); &amp;#125; valueOffset 是通过unsafe.objectFieldOffset() 获取当前value这个变量在内存中的偏移量,后续会基于这个偏移量从内存中得到的value 的值来和当前值进行比较,实现乐观锁 private static final long valueOffset; static &amp;#123; try &amp;#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &amp;#125; catch (Exception ex) &amp;#123; throw new Error(ex); &amp;#125; &amp;#125; getAndAddInt通过do/while循环,基于CAS乐观锁来做原子递增.实际上前面的valueOffset的作用就是从主内存中获取当前的value值和预期值做一个比较,如果相等,则对value做递增并结束循环 /** * Atomically adds the given value to the current value of a field * or array element within the given object &lt;code>o&lt;/code> * at the given &lt;code>offset&lt;/code>. * * @param o object/array to update the field/element in * @param offset field/element offset * @param delta the value to add * @return the previous value * @since 1.8 */ public final int getAndAddInt(Object o, long offset, int delta) &amp;#123; int v; do &amp;#123; v = getIntVolatile(o, offset); &amp;#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v; &amp;#125; get方法get方法只需要直接返回value的值就行,这里的value是通过 volatile修饰的,用来保证可见性 /** * Gets the current value. * * @return the current value */ public final int get() &amp;#123; return value; &amp;#125; 其他方法AtomicInteger 的实现非常简单,所以我们很快就可以分析完他的原理,当然除了刚刚分析的这两个方法之外,还有其他的一些,比如 它提供了 compareAndSet, 允许客户端基于AtomicIngeter 来实现乐观锁的操作 public final boolean compareAndSet(int expect, int update) &amp;#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &amp;#125;","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"RocketMQ 基本原理分析","slug":"微服务/RocketMQ/RocketMQ 基本原理分析","date":"2022-01-04T02:42:07.281Z","updated":"2022-01-04T02:42:07.281Z","comments":true,"path":"2022/01/04/wei-fu-wu/rocketmq/rocketmq-ji-ben-yuan-li-fen-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rocketmq/rocketmq-ji-ben-yuan-li-fen-xi/","excerpt":"","text":"RocketMQ 基本原理分析1. 思考一下消息中间件的设计1.1 可以先从基本的需求开始考虑 最基本的是要能支持消息的发送和接收, 需要涉及网络通信就一定就会涉及到NIO. 消息中心的消息存储(持久化/非持久化) 消息的序列化和非序列化 是否跨语言 消息的确认机制,如何避免消息重发. 1.2 高级功能 消息的有序性 是否支持事务消息 消息收发的性能,对高并发大数据量的支持 是否支持集群 消息的可靠性存储 是否支持多协议 2. MQ消息存储选择从主流的几种MQ 消息队列采用的存储方式来看,主要会有三种: 分布式KV存储, 比如ActiviteMQ 中采用的是lebelDB、Redis 这种存储方式对于消息读写能力要求不高的情况下可以使用. 文件系统存储,常见的kafka、RocketMQ、RabbitMQ 都是采用消息刷盘到所部署的机器上的文件系统来做持久化, 这种方案适用于对于有高吞吐量的消息中间件,因为消息刷盘是一种高效率、高可靠、高性能的持久化方式, 除非磁盘出现故障,否则一般是不会出现无法持久化的问题. 关系型数据库,比如ActiviteMQ 可以采用mysql作为消息存储,关系型数据库在单表数据量达到千万级的情况下IO性能会出现瓶颈,所以ActiviteMQ 并不适合高吞吐量的消息队列场景. 总的来说, 对于存储效率,文件系统要优于分布式LV存储,分布式LV存储要优于关系型数据库. 3. RocketMQ的发展历史RocketMQ 是一个由阿里巴巴开源的消息中间件, 2012年开源, 2017年成为apache 顶级项目. ​ 它的核心设计借鉴了kafka,所以我们在了解RocketMQ 的时候, 会发现很多和kafka 相同的特性。 同时, RocketMQ 在某些功能上和kafka 又有较大的差异,接下来我们就去了解RocketMQ. 1. 支持集群模式、负载均衡、水平扩展能力. 2. 亿级别消息堆积能力. 3. 采用零拷贝的原理、顺序写盘,随机读 4. 底层通信框架采用Netty NIO 5. NameServer 代替zookeeper,实现服务寻址和服务协调 6. 消息失败重试机制, 消息可查询. 7. 强调集群无节点, 可扩展,任意一点高可用, 水平可扩展 . 8. 经过多次双11的考验. 4. RocketMQ 的架构 集群本身没有什么特殊之处,和kafka 的整体结构相比,其中zookeeper 替换成了NameServer. 在rocketMQ 的早版本(2.X) 的时候, 是没有namespace 组件的, 用的是zookeeper 做分布式协调和服务发现, 但是后期阿里数据根据实际业务需求进行改进和优化,自己研发了轻量级的namesrv,用于注册Client 服务和Broker 的请求路由,namesrv 上不做任何消息的位置存储,频繁才做zookeeper 的位置存储数据会影响整体集群性能. RocketMQ 由四部分组成: Name Server 可集群部署, 节点之间无任何信息同步,提供轻量级的服务发现和路由. Broker(消息中间角色、负责存储消息, 转发消息). 部署相对复杂，Broker 分为Master 和Slave. 一个Master 可以对应多个Slave,但是一个Slave 只能对应一个Master. Master和Slave 的对应关系通过指定相同的BrokerName,不同的BroklerId 来定义,BrokerId0 表示Master,非0表示Slave. Producer: 生产者, 拥有相同的Producer Group 的Producer 组成一个集群, 与Name Server 集群中的其中一个节点(随机选择)建立长连接,定期 从Name Server 取Topic 路由信息, 并向提供Topic 服务的Master 建立长连接,且定时向Master 发送心跳. Producer 完全无状态,可集群部署. Consumer: 消费者,接受消息进行消费的实例,拥有相同Consumer Group 的Consumer 组成一个集群,与Name Server 集群中的其中一个节点(随机选择) 建立长连接,定期从Name Server 取Topic 路由信息,并向提供Topic 服务的Master、Slave 建立长连接,且定时向Master、Slave 发送心跳。Consumer 既可以从Master 订阅消息, 也可以从Slave 订阅消息,订阅规则由Broker 配置决定. 要使用RockerMQ, 至少需要启动两个进程,Name Server 、Broker , 前者是各种Topic 注册中心, 后者是真正的Broker. 5.单机环境下的RocketMQ 的安装5.1 下载并解压安装 下载RocketMQ的安装文件 https://rocketmq.apache.org/ unzip rocketmq-all-4.6.0-bin-release.zip 解压压缩包 5.2 启动Name Server 进入bin目录,运行namesrv, 启动NameServer nohup sh mqnamesrv &amp; 默认情况下,Name Server 监听的是9876 端口 查看启动日志 tail -1000f /root/logs/rocketmqlogs/namesrv.log 5.3 启动Broker nohup sh bin/mqbroker -n ${namesrvIp}:9876 -c /conf/broker.conf &amp; -&gt;[-c可以指定broker.conf配 置文件]。 默认情况下会加载 config/broker/conf 启动Broker,其中-n 表示指定当前broker 对应的命名服务地址: 默认情况下,Broker 监听的是10911端口 nohup sh mqbroker -n localhost:9876 &amp; 查看日志 tail -100f /root/logs/rocketmqlogs/broker.log 5.4内存不足的问题这是因为bin 目录下启动namesrv 和broker 的 runbroker.sh和runserver.sh 文件中默认分配的内存太大,rocketmq 比较耗内存,所以默认分配的内存比较大,而系统实际内存太小导致启动失败, 通常像虚拟机上安装的Centos 服务器内存可能是没有高的,只能调小. 实际中应该根据服务器内存情况, 配置一个合适的值. # There is insufficient memory for the Java Runtime Environment to continue. # Native memory allocation (mmap) failed to map 8589934592 bytes for committing reserved memory. # An error report file with more information is saved as: # /data/program/rocketmq-all-4.6.0-bin-release/bin/hs_err_pid6465.log 解决方法修改 runbroker.sh和 runserver,sh JAVA_OPT=\"$&amp;#123;JAVA_OPT&amp;#125; -server -Xms1g -Xmx1g -Xmn512g\" Xms 是指设定程序启动时占用内存大小。一般来讲，大点，程序会启动的快一点，但是也可能会导致机器暂时 间变慢。 Xmx 是指设定程序运行期间最大可占用的内存大小。如果程序运行需要占用更多的内存，超出了这个设置值， 就会抛出OutOfMemory异常。 xmn 年轻代的heap大小，一般设置为Xmx的3、4分之一 5.5 停止服务【sh bin/mqshutdown broker】 //停止 brokersh 【bin/mqshutdown namesrv】 //停止 nameserver 停止服务的时候需要注意，要先停止broker，其次停止nameserver。 5.6 broker.conf 文件默认情况下,启动broker 会加载 conf/broker.conf 这个文件,这个文件里面就是一些常规的配置信息 namesrvAddr: NameServer 的地址 brokerClusterName: Cluster 的名称, 如果集群机器比较多, 可以分为多个cluster,每个cluster 提供给不同的业务场景使用. brokerName: broker 名称, 如果配置主从模式, master和slave 需要配置相同的名称来表明关系. brokerId=0: 在主从模式中,一个master broker 可以有多个slave,0 表示master, 大于0表示不同slave 的id brokerRole=SYNC_MASTER/ASYNC_MASTER/SLAVE: 同步表示slave 和master 消息同步完成后再返回信息给客户端. autoCreateTopicEnable=true: topic 不存在的情况下自动创建 6. 消息发送和接收基本应用6.1 添加jar 依赖 &lt;dependency> &lt;groupId>org.apache.rocketmq&lt;/groupId> &lt;artifactId>rocketmq-client&lt;/artifactId> &lt;version>4.5.2&lt;/version> &lt;/dependency> 6.2 生产者package com.mq; import org.apache.rocketmq.client.exception.MQBrokerException; import org.apache.rocketmq.client.exception.MQClientException; import org.apache.rocketmq.client.producer.DefaultMQProducer; import org.apache.rocketmq.client.producer.SendResult; import org.apache.rocketmq.common.message.Message; import org.apache.rocketmq.remoting.common.RemotingHelper; import org.apache.rocketmq.remoting.exception.RemotingException; import java.io.UnsupportedEncodingException; /** * @author luyanan * @since 2020/1/13 * &lt;p>生产者&lt;/p> **/ public class Producer &amp;#123; public static void main(String[] args) throws MQClientException &amp;#123; /** * 生产者组,简单来说就是多个发送用一类消息的生产者称之为一个生产者组 * RocketMQ 支持事务消息,在发送事务消息时, 如果事务消息异常(producer 挂了), * broker 端会来回查事务的状态,这个时候会根据group 名称来查找对应的producer 来 * 执行相应的回查逻辑,相当于实现了producer 的高可用. */ DefaultMQProducer producer = new DefaultMQProducer(\"producer_group\"); // 执行namesrv 服务地址, 获取broker 的相关信息 producer.setNamesrvAddr(\"192.168.86.128:9876\"); producer.setVipChannelEnabled(false); producer.start(); for (int i = 0; i &lt; 100; i++) &amp;#123; try &amp;#123; // 创建一个消息实例,指定topic、tag、消息内容 Message message = new Message(\"TopicTest\",// topic \"TagA\", // tag (\"Hello World\" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)// message Body ); // 发送消息并且发送结果 SendResult sendResult = producer.send(message); System.out.println(sendResult); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); try &amp;#123; Thread.sleep(1000); &amp;#125; catch (InterruptedException ex) &amp;#123; ex.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; producer.shutdown(); &amp;#125; &amp;#125; SendResult 中有一个sendStatus状态, 表示消息的发送状态, 一共有四种状态. FLUSH_DISK_TIMEOUT: 表示没有在规定的时间内完成刷盘(需要Broker的刷新策略设置成SYNC_FLUSH 才会报这个错) FLUSH_SLAVE_TIMEOUT: 表示在主备方式下, 并且Broker 设置成成SYNC_MASTER 方式,没有在设定时间内完成主从同步. SLAVE_NOT_AVAILABLE: 这个状态产生的场景和FLUSH_SLAVE_TIMEOUT 类似,表示在主备方式下, 并且Broker 被设置为SYNC_MASTER , 并且没有找到被配置为Slave 的Broker. SEND OK: 表示发送成功,发送成功的具体含义, 比如消息是否已经被存储到磁盘? 消息是否被同步到了Slave 上？消息在Slave 是否被写入磁盘? 需要结合所配置的刷盘策略,主从策略来定. 这个状态还可以简单理解为, 没有发生上面累出的三个问题状态就是SEND OK. 消费者consumerGroup:位于同一个consumerGroup 中的consumer 实例和producerGroup 中的各个producer 实例承担的角色类似,同一个group 中可以配置多个consumer, 可以体改消费端的并发消费能力以及容灾. ​ 和Kafka 一样,多个consumer 会对消息做负载均衡, 意味着同一个topic 下的不同messageQueue 会分发给同一个group中的不同 consumer. ​ 同时, 如果我们希望消息能够达到广播的目的, 只需要把consumer 加入到不同的group就行. ​ RocketMQ 提供了两种消息消费模式,一种是pull主动去拉, 另一种是push,被动接收. 但是实际上,RocketMQ 都是pull模式,只是push在pull模式上做了一层封装,也就是pull到消息以后触发业务消息. nameServer 的地址: nameserver 地址,用于或者broker、topic. package com.mq; import org.apache.rocketmq.client.consumer.DefaultMQPullConsumer; import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; import org.apache.rocketmq.client.exception.MQClientException; import org.apache.rocketmq.common.consumer.ConsumeFromWhere; import org.apache.rocketmq.common.message.MessageExt; import java.util.List; /** * @author luyanan * @since 2020/1/13 * &lt;p>消费者&lt;/p> **/ public class Consumer &amp;#123; public static void main(String[] args) throws MQClientException &amp;#123; // 消费者的组名, 这个和kafka 的一样的, 需要特别注意 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"consumer_group\"); // 指定NameServer 的地址, 多个地址用, 隔开 consumer.setNamesrvAddr(\"192.168.86.128:9876\"); // 设置consumer 第一次启动是从队列头部开始还是从队尾开始消费 // 如果非第一次启动,则按照上次消费的位置继续消费 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); // 订阅TopicTest 下的所有tag的消息 // * 表示不过滤,可以通过tag来过滤 consumer.subscribe(\"TopicTest\", \"*\"); /** * 注册消息监听,这里有两种监听 MessageListenerConcurrently以及MessageListenerOrderly, 前者是普通监听, 后者是顺序监听. */ consumer.registerMessageListener(new MessageListenerConcurrently() &amp;#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt> list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &amp;#123; System.out.println(\"receive Message : \" + list); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &amp;#125; &amp;#125;); consumer.start(); &amp;#125; &amp;#125; 7. RocketMQ 控制台安装​ 启动好服务之后, 总得有一个可视化节界面来看看我们配置的节点把, Rocket 官方提供了一个可视化控制台,大家可以在这个地址下载. https://github.com/apache/rocketmq-externals 这个是RocketMQ的扩展,里面不仅包含控制台的扩展,也包含了对大数据 flume、hbase 等组件的对接和扩展. 7.1 下载源码包https://github.com/apache/rocketmq-externals/archive/master.zip 7.2 解压并修改配置 cd /$&#123;rocketmq-externals-home&#125;/rocket-console/ 修改application.properties 文件 配置namesrvAddr地址，指向目标服务的ip和端口: rocketmq.config.namesrvAddr=192.168.86.128:9876 7.3 运行 cd /$&#123;rocketmq-externals-home&#125;/rocket-console/ mvn spring-boot:run 7.4 通过控制台创建消息要能够发送和接受消息,需要先创建Topic, 这里的topic 和kafka 的topic 的概念是一样的.进入到控制台,选择Topic readQueueNums和writeQueueNums分别表示读队列数和写队列数 writeQueueNums表示producer发送到的MessageQueue的队列个数 readQueueNumbs表示Consumer读取消息的MessageQueue队列个数，其实类似于kafka的分区的概 念 这两个值需要相等，在集群模式下如果不相等，假如说writeQueueNums=6,readQueueNums=3, 那 么每个broker上会有3个queue的消息是无法消费的。 8. RocketMQ消息支持的模式8.1 NormalProducer（普通）8.1.1 消息同步发送​ 普通消息的发送和接收已经前面演示过了,在上面的案例中是基于同步消息发送模式,也就是说 消息发送出去后, producer 会等到broker 回应后才能继续发送下一个消息. 8.1.2 消息异步发送​ 异步发送是指发送方发送数据后,不等接收方发回响应,接着发送下个数据包的通讯方式.MQ的异步发送, 需要用户实现异步发送回调接口(SendCalllable).消息发送方在发送了一条消息后,不需要等待服务器响应即可返回,进行第二条消息发送。发送方通过回调接口接受服务器响应, 并对响应结果进行处理. 异步代码改造 // 异步发送 producer.send(message, new SendCallback() &amp;#123; @Override public void onSuccess(SendResult sendResult) &amp;#123; System.out.println(sendResult); &amp;#125; @Override public void onException(Throwable throwable) &amp;#123; throwable.printStackTrace(); &amp;#125; &amp;#125;); 8.2 OneWay单向(OneWay) 发送特点为发送方只负责发送消息, 不等待服务器且没有回调函数触发,即只发送请求不等待应发, 效率最高. producer.sendOneway(msg); 8.3 OrderProducer（顺序）​ 在kafka 中, 消息可以通过自定义分区策略来实现消息的顺序发送,实现原理就是把同一类消息发送到相同的分区上. ​ 在RocketMQ中,是基于多个Message Queue 来实现类似于Kafka 的分区效果的. 如果一个Topic 要发送和接收的数据量非常大,需要能支持增加并行处理的机器来提高处理速度,这时候一个Topic 可以根据需求设置一个或者多个Message Queue . Topic 有了多个Message Queue 后, 消息可以并行的向各个Message Queue 发送, 消息者也可以从多个Message Queue 读取消息并消费. 要了解RocketMQ消息的顺序消费, 还的对RocketMQ的整体架构有一定的了解 8.3.1 RocketMQ 消息发送和消费的基本原理​ 这是一个比较宏观的部署架构图,Rocketmq 天然支持高可用,它可以支持多主多从的架构部署,这也是和kafka 最大的区别. ​ 原因是RocketMQ 中并没有master 选举功能,所以通过配置多个Master 节点来保证RocketMQ 的高可用, 和所有的集群角色定位一样,Master 节点负责接收事务请求,slave 节点只负责接收读请求,并且接收master 同步过来的数据和slave 保持一致. 当master 挂了以后,如果当前rocketmq 是一主多从, 就意味着无法接收发送端的消息,但是消费者仍然能够继续消费. ​ 所以配置多个主节点后, 可以保证其中一个master节点挂了之后, 另外一个master 节点仍然能够堆外提供消息发送服务. ​ 当存在多个主节点时, 一条消息只会发送到其中一个主节点, rocketmq 对于多个master节点的消息发送, 会做负载均衡,使得消息可以平衡的发送到多个master 节点上. ​ 一个消费者可以同时消费多个master 节点上的消息,在下面的这个架构图中, 两个master 节点恰好可以平均分发到两个消费者上,如果此时只有一个消费者,那么这个消费者会同时消费两个master 节点的数据. ​ 由于每个master 可以配置多个slave, 所以如果其中一个master 挂了, 消息仍然可以被消费者从slave 节点消费到,可以完美的实现rocketmq 消息的高可用. ​ 接下来,站在topic 的角度来看看消息是如何分发和处理的, 假设有两个master 节点的集群, 创建了一个TestTopic, 并且对这个topic 创建了两个队列,也就是分区. ​ 消费者定义了两个分组, 分组的概念也是跟kafka 一样, 通过分区可以实现消息的广播. ​ 将下来, 站在topic 的角度来看看消息是如何分发和处理的,假设有两个master节点的集群, 创建了一个TestTopic,并且对这个topic 创建了两个队列,也就是分区. ​ 消费者定义了两个分组,分组的概念也是和kafka 一样, 通过分组可以实现消息的广播. 8.3.2 集群支持RocketMQ 天生对集群的支持非常友好. 1. 单Master优点: 除了配置简单没有什么优点 缺点: 不可靠, 该集群重启或者宕机,将导致 整个服务不可用 2. 多Master优点: 配置简单, 性能最高 缺点: 可能会有少量消息丢失(配置相关), 单台机器重启或者宕机期间,该机器下未被消费的消息将在机器恢复前不可订阅, 影响消息实时性. 3. 多Master,多Slave(异步复制)每个master 配置一个slave, 有多对master-slave, 集群采用异步复制的方式, 主备有短暂的消息延迟,毫秒级 优点: 性能同多master 一样,实时性高, 主备间切换应用透明, 不需要人工干预. 缺点: Master 宕机或者磁盘损坏时会有少量的消息丢失. 4. 多Master,多Slave(同步双写)每个Master 配一个Slave, 有多对Master-slave, 集群采用同步双写方式, 主备都写成功, 向应用返回成功. 优点: 服务可用性与数据可用性非常高. 缺点: 性能比异步集群略低, 当前版本主宕机备不能自动切换为主. 需要注意的是:在RocketMQ 中, 1台机器只能要么是Master, 要么是slave, 这个在初始化的机器配置里面, 就定死了. 不会像kafka 那样存在master 动态选举的功能. 其中Master 的brokerId=0,Slaved的brokerId&gt;0 有点类似于mysql的主从的概念,master 挂了以后, Slave仍然可以提供读服务,但是由于有多主的存在, 当一个master 挂了以后,可以写到其他的master上. 8.4 消息发送到topic 多个MessageQueue接下来演示一下 topic 创建多个MessageQueue 创建一个队列,设置2个写队列和2个读队列,如果读和写的队列不一样,会存在消息无法消费的问题. 构建生产者和消费者, 参考上面写的生产者和消费者的代码 消费者数量控制对于队列的消费情况 如果消费队列为2,启动一个消费者,那么这个消费者会消费两个队列 如果两个消费者消费这个队列,那么意味着消费会均衡平摊到这两个消费者 如果消费者数大于readQueueNumbs, 那么会有一些消费者消费不到消息,浪费资源. 8.5 消息的顺序消费​ 首先需要保证顺序的消息要发送到用一个MessageQueue;其次, 一个MessageQueue 只能被一个消费者消费,这点是消息队列的分配机制来保证的; 最后, 一个消费者内部对一个mq 的消费者要保证是有序的. ​ 我们要做到生产者- messagequeue - 消费者,是一对一的关系. 8.6 自定义消息发送负责​ 通过自定义发送策略来实现消息只发送到同一个队列. ​ 因为同一个Topic 会有多个MessageQueue, 如果使用Producer 会轮流向各个Message Queue 发送消息. Consumer 在消费消息的时候, 会根据负载均衡策略, 消费被分配到Message Queue. ​ 如果不经过特定的设置, 某条消息被发往哪个Message Queue, 被哪个Consumer 消费是未知的. ​ 如果业务需要我们把消息发送到指定的Message Queue 里面, 比如把某一类型的消息都发往相同的Message Queue, 那是不是可以实现顺序消息的功能呢？ ​ 和kafka 一样,rocketMQ 也实现了消息的路由功能,我们可以自定义消息分发策略,可以实现MessageQueueSelector , 来实现自己的消息分发策略. // 自定义消息发送规则 producer.send(message, new MessageQueueSelector() &amp;#123; @Override public MessageQueue select(List&lt;MessageQueue> list, Message message, Object o) &amp;#123; int key = o.hashCode(); int size = list.size(); int index = key % size; return list.get(index);// list.get(0); &amp;#125; &amp;#125;, \"key_\" + i); 8.7 如何保证消息消费顺序呢?​ 通过分区规则可以实现同类消息在rocketmq 上的顺序存储,但是对于消费端来说,如何保证消费的顺序? ​ 我们前面写的消息消费代码使用的是MessageListenerConcurrently 并发监听, 也就是基于多个线程并行来消费消息,这个无法保证消息消费的顺序. ​ RocketMQ 中提供了MessageListenerOrderly 一个类来实现顺序消费. // 顺序消费 consumer.registerMessageListener(new MessageListenerOrderly() &amp;#123; @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt> list, ConsumeOrderlyContext consumeOrderlyContext) &amp;#123; list.stream().forEach(m -> System.out.println(new String(m.getBody()))); return ConsumeOrderlyStatus.SUCCESS; &amp;#125; &amp;#125;); 顺序消费会带来一些问题： 遇到消息失败的消息, 无法跳过,当前队列消费暂停. 降低了消息处理的性能. 8.8 消费端的负载均衡​ 和kafka 一样,消费端也会针对Message Queue 做负载均衡,使得每个消费者能够合理的消费多个分区的消息. 8.8.1 消费端会通过RebalanceService 线程, 10秒做一次机遇topic下的所有队列负载 消费者遍历自己所有的topic, 依次调用rebalanceByTopic. 根据topic 获取此topic 下的所有queue 选择一台broker 获取机遇group 的所有消费端(有心跳向所有broker 注册客户端信息) 选择队列分配策略实例 AllocateMessageQueueStrategy 执行分配算法 8.8.2 什么时候触发负载均衡 消费者启动之后 消费者数量发生变更 每10秒会触发检查一次rebalance 8.8.3 分配算法RocketMQ 提供了6种分区的分配算法 AllocateMessageQueueAveragely: 平均分配算法(默认) AllocateMessageQueueAveragelyByCircle: 环状分配消息队列 AllocateMessageQueueByConfig: 按照配置来分配队列, 根据用户指定的配置来进行负载 AllocateMessageQueueByMachineRoom: 按照指定机房来配置队列 AllocateMachineRoomNearby: 按照就近机房来配置队列 AllocateMessageQueueConsistentHash: 一致性Hash,根据消费者的cid进行 9. 消息的可靠性原则​ 在实际使用RocketMQ 的时候我们并不能保证每次发送的消息都刚好能被消费者一次性正常消费成功,可能会存在需要多次消费才能成功或者一直消费失败的情况,那作为发送者该做如何处理呢? 9.1 消息消费端的确认机制​ RocketMQ 提供了ack机制,以保证消息能够被正常消费. 发送方为了保证消息肯定消费成功,只有使用方明确表示消费成功,RocketMQ 才会认为消息消费成功. 中途断电、抛出异常都不会认为成功. consumer.registerMessageListener(new MessageListenerConcurrently() &amp;#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt> list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &amp;#123; System.out.println(\"receive Message : \" + list); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &amp;#125; &amp;#125;); ​ 所有的消费者在设置监听的时候会提供一个回调,业务实现消费回调的时候, 当回调方法中返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS, RocketMQ 才会认为这批消息(默认是1条),是消费完成的. 如果这个时候消息消费失败, 例如数据库异常、余额扣款不足等一切业务认为消息需要重试的场景,只要返回回ConsumeConcurrentlyStatus.RECONSUME_LATER, RocketMQ 就会认为这批消息消费失败了. 9.2 消息的衰减机制​ 为了保证消息肯定至少被消费一次,RocketMQ 会把这批消息重新发回到broker,在延迟的某个时间点(默认是10s, 业务可设置)后, 再次投递到这个consumerGroup. 而如果一直这样重复消费都持续到一定次数(默认16次),就会投递到DLQ死信队列,应用可以监控死信队列来做人工干预. 可以修改broker-a.conf 文件 messageDelayLevel = 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 9.3 重试消息的处理机制​ 一般情况下,我们在实际生产中是不需要重试16次, 这样既浪费时间又浪费性能,理论上当尝试重复次数达到我们想要的结果时如果还是消费失败, 那么我们就需要将对应的消息进行记录,并且结束重试尝试. consumer.registerMessageListener((MessageListenerConcurrently) (list, consumeOrderlyContext) -> &amp;#123; for (MessageExt messageExt : list) &amp;#123; if(messageExt.getReconsumeTimes()==3) &amp;#123; //可以将对应的数据保存到数据库，以便人工干预 System.out.println(messageExt.getMsgId()+\",\"+messageExt.getBody()); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &amp;#125; &amp;#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &amp;#125;);","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/"},{"name":"微服务","slug":"RocketMQ/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"RocketMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"RocketMQ","slug":"RocketMQ/微服务/微服务/RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/RocketMQ/"}],"tags":[]},{"title":"Spring Cloud Alibaba之naocs注册中心","slug":"微服务/Spring Cloud/Spring Cloud Alibaba之naocs注册中心","date":"2022-01-04T02:42:07.281Z","updated":"2022-01-04T02:42:07.281Z","comments":true,"path":"2022/01/04/wei-fu-wu/spring-cloud/spring-cloud-alibaba-zhi-naocs-zhu-ce-zhong-xin/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/spring-cloud/spring-cloud-alibaba-zhi-naocs-zhu-ce-zhong-xin/","excerpt":"","text":"Spring Cloud Alibaba之naocs注册中心1. 确定版本我们先要确定下载的nacos的版本号, spring cloud alibaba的官网表明了各个组件的版本依赖关系和与Spring cloud和Spring Boot的依赖关系 https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E#%E7%BB%84%E4%BB%B6%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB 组件版本关系 Spring Cloud Alibaba Version Sentinel Version Nacos Version RocketMQ Version Dubbo Version Seata Version 2.2.1.RELEASE or 2.1.2.RELEASE or 2.0.2.RELEASE 1.7.1 1.2.1 4.4.0 2.7.6 1.2.0 2.2.0.RELEASE 1.7.1 1.1.4 4.4.0 2.7.4.1 1.0.0 2.1.1.RELEASE or 2.0.1.RELEASE or 1.5.1.RELEASE 1.7.0 1.1.4 4.4.0 2.7.3 0.9.0 2.1.0.RELEASE or 2.0.0.RELEASE or 1.5.0.RELEASE 1.6.3 1.1.1 4.4.0 2.7.3 0.7.1 毕业版本依赖关系(推荐使用) Spring Cloud Version Spring Cloud Alibaba Version Spring Boot Version Spring Cloud Hoxton.SR3 2.2.1.RELEASE 2.2.5.RELEASE Spring Cloud Hoxton.RELEASE 2.2.0.RELEASE 2.2.X.RELEASE Spring Cloud Greenwich 2.1.2.RELEASE 2.1.X.RELEASE Spring Cloud Finchley 2.0.2.RELEASE 2.0.X.RELEASE Spring Cloud Edgware 1.5.1.RELEASE(停止维护，建议升级) 1.5.X.RELEASE 2. 下载https://github.com/alibaba/nacos/releases 去挑选合适的版本下载,下载. 如果只是为了使用的话, 我们可以下载编译好的版本 3. 编写客户端3.1 pom.xml 编写 &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;spring-boot.version>2.2.5.RELEASE&lt;/spring-boot.version> &lt;spring-cloud-alibaba.version>2.2.1.RELEASE&lt;/spring-cloud-alibaba.version> &lt;spring-cloud.version>Hoxton.SR3&lt;/spring-cloud.version> &lt;!-- &lt;spring-boot.version>2.2.1.RELEASE&lt;/spring-boot.version>--> &lt;!-- &lt;spring-cloud-alibaba.version>2.2.0.RELEASE&lt;/spring-cloud-alibaba.version>--> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-dependencies&lt;/artifactId> &lt;version>$&amp;#123;spring-boot.version&amp;#125;&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-alibaba-dependencies&lt;/artifactId> &lt;version>$&amp;#123;spring-cloud-alibaba.version&amp;#125;&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>$&amp;#123;spring-cloud.version&amp;#125;&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 3.2 编写启动类@EnableDiscoveryClient @SpringBootApplication public class SpringCloudNacosDiscoveryClientApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(SpringCloudNacosDiscoveryClientApplication.class, args); &amp;#125; &amp;#125; 3.3 编写配置文件 application.ymlspring: application: name: spring-cloud-nacos-discovery-client cloud: nacos: discovery: server-addr: 127.0.0.1:8848 server: port: 12000 3.4 启动项目启动项目之前,确保之前安装的nacos 已经启动 等项目启动成功后,我们访问http://localhost:8848/nacos nacos 的后台, 可以看到 我们可以看到, spring-cloud-nacos-discovery-client 这个项目已经注册到了nacos 上面了. nacos 中可以通过命名空间来区分不同的环境 新建一个dev的命令空间,点击确定之后,我们会发现列表会多出来一条, 还有一个命令空间ID, 这个ID就是我们所需要的, 我们复制这个id, 到项目的application.yml配置文件,修改配置文件为 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 ## 指定命令空间 namespace: d033967d-013d-4f01-9d23-8326105615ac 然后重启项目, 再次查看nacos 的控制台 我们发现在原本的public 旁边多了一个dev的tab,点击dev 我们可以发现我们注册的服务.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/"},{"name":"微服务","slug":"Spring-Cloud/微服务","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"Spring-Cloud/微服务/微服务","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Spring Cloud","slug":"Spring-Cloud/微服务/微服务/Spring-Cloud","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Spring-Cloud/"}],"tags":[]},{"title":"Sentinel 整合Dubbo限流实战","slug":"微服务/Sentinel/Sentinel 整合Dubbo限流实战","date":"2022-01-04T02:42:07.281Z","updated":"2022-01-04T02:42:07.281Z","comments":true,"path":"2022/01/04/wei-fu-wu/sentinel/sentinel-zheng-he-dubbo-xian-liu-shi-zhan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/sentinel/sentinel-zheng-he-dubbo-xian-liu-shi-zhan/","excerpt":"","text":"Sentinel 整合Dubbo限流实战创建生产者项目这里需要提供一个对外的api项目和一个Dubbo服务 添加依赖 &lt;dependency> &lt;groupId>com.sentinel&lt;/groupId> &lt;artifactId>sentinel-dubbo-api&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-client&lt;/artifactId> &lt;version>4.0.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-recipes&lt;/artifactId> &lt;version>4.0.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.dubbo&lt;/groupId> &lt;artifactId>dubbo&lt;/artifactId> &lt;version>2.7.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;/dependency> api服务在api项目中创建接口类 package com.sentinel; /** * @author luyanan * @since 2019/12/16 * &lt;p>&lt;/p> **/ public interface SentinelService &amp;#123; String sayello(String name); &amp;#125; 生产者服务接口实现类 package com.sentinel; import org.apache.dubbo.config.annotation.Service; /** * @author luyanan * @since 2019/12/16 * &lt;p>&lt;/p> **/ @Service public class SentinelServiceImpl implements SentinelService &amp;#123; @Override public String sayello(String name) &amp;#123; System.out.println(\"sayHello :\" + name); return \"hello \" + name; &amp;#125; &amp;#125; dubbo 配置类 package com.sentinel; import org.apache.dubbo.config.ApplicationConfig; import org.apache.dubbo.config.ProtocolConfig; import org.apache.dubbo.config.RegistryConfig; import org.apache.dubbo.config.spring.context.annotation.DubboComponentScan; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @author luyanan * @since 2019/12/16 * &lt;p>&lt;/p> **/ @Configuration @DubboComponentScan(\"com.sentinel\") public class ProviderConfig &amp;#123; @Bean public ApplicationConfig applicationConfig() &amp;#123; ApplicationConfig config = new ApplicationConfig(); config.setName(\"sentinel-provider\"); config.setOwner(\"luyanan\"); return config; &amp;#125; @Bean public RegistryConfig registryConfig() &amp;#123; RegistryConfig config = new RegistryConfig(); config.setAddress(\"zookeeper:192.168.9.106:2181\"); config.setCheck(false); return config; &amp;#125; @Bean public ProtocolConfig protocolConfig() &amp;#123; ProtocolConfig config = new ProtocolConfig(); config.setPort(20880); config.setName(\"dubbo\"); return config; &amp;#125; &amp;#125; 启动类package com.sentinel; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import java.io.IOException; public class SentinelDubboProviderApplication &amp;#123; public static void main(String[] args) throws IOException &amp;#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(ProviderConfig.class); ((AnnotationConfigApplicationContext) applicationContext).start(); System.in.read(); &amp;#125; &amp;#125; 消费者项目添加依赖 &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-recipes&lt;/artifactId> &lt;version>4.0.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-client&lt;/artifactId> &lt;version>4.0.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.sentinel&lt;/groupId> &lt;artifactId>sentinel-dubbo-api&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.dubbo&lt;/groupId> &lt;artifactId>dubbo&lt;/artifactId> &lt;version>2.7.2&lt;/version> &lt;/dependency> 测试类编写测试类 package com.sentinel; import org.apache.dubbo.config.annotation.Reference; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; /** * @author luyanan * @since 2019/12/16 * &lt;p>&lt;/p> **/ @RestController public class SyaHelloController &amp;#123; @Reference private SentinelService sentinelService; @GetMapping(\"say\") public String sayHello() &amp;#123; String result = sentinelService.sayello(\"Tom\"); System.out.println(result); return result; &amp;#125; &amp;#125; 添加配置信息dubbo.scan.base-packages=com.sentinel dubbo.application.name=sentinel-constumer dubbo.registry.address=zookeeper://192.168.9.106:2181 设置限流的基准sentinel-provider 用于向外界提供服务, 处理各个消费者的调用请求, 为了保护 provider 不被激增的流量拖垮影响稳定性, 可以向 provider 配置 QPS 模式的限流. 这样当每秒的请求量超过设置的阈值时会超过自动拒绝多的请求. 限流粒度可以是服务接口和服务方法两个粒度 . 若希望整个服务接口的QPS 不超过一定数值, 则可以为对应服务接口资源(resourceName 为接口全限定名) 配置QPS 阈值, 若希望服务的某个方法的QPS 不超过一定数值, 则可以为对应服务方法资源(resourceName 为接口全限定名:方法签名) 配置QPS 阈值. package com.sentinel; import com.alibaba.csp.sentinel.slots.block.RuleConstant; import com.alibaba.csp.sentinel.slots.block.flow.FlowRule; import com.alibaba.csp.sentinel.slots.block.flow.FlowRuleManager; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import java.io.IOException; import java.util.ArrayList; import java.util.List; public class SentinelDubboProviderApplication &amp;#123; public static void main(String[] args) throws IOException &amp;#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(ProviderConfig.class); ((AnnotationConfigApplicationContext) applicationContext).start(); initFlowerRule(); System.in.read(); &amp;#125; private static void initFlowerRule() &amp;#123; List&lt;FlowRule> ruleList = new ArrayList&lt;>(); FlowRule flowRule = new FlowRule(); flowRule.setResource(\"com.sentinel.SentinelService:sayello(java.lang.String)\"); flowRule.setCount(10); // 限定阈值 flowRule.setGrade(RuleConstant.FLOW_GRADE_QPS);// 限定阈值类型(QPS/并发线程数) flowRule.setLimitApp(\"default\");// 流针对的调用来源, 若为default则不区分来源 //流量控制手段（直接拒绝、Warm Up、匀速排队） flowRule.setControlBehavior(RuleConstant.CONTROL_BEHAVIOR_DEFAULT); ruleList.add(flowRule); FlowRuleManager.loadRules(ruleList); &amp;#125; &amp;#125; 启动时加入 JVM 参数 -Dcsp.sentinel.dashboard.server=localhost:8080 指定控制台地址和端口 参数解释LimitApp很多场景下, 根据调用方来限流也是非常重要的,比如有两个服务A 和B 都向 service provider 发起调用请求, 我们希望只对于来着服务 B 的请求进行限流, 则可以设置限流规则的 limitpp 为服务B 的名称. Sentinel Dubbo Adapter 会自动解析 Dubbo消费者(调用方) 的 application name 作为调用方名称(origin), 在进行资源保护的时候都会带上调用方的名称. 若限流规则未配置调用方(default), 则该限流规则对所有调用方生效。 若限流规则配置了调用方,则限流规则仅对指定调用方生效. 注：Dubbo 默认通信不携带对端application name 信息, 因此需要开发者在调用端手动的将 application anme 置入 attachement 中, provider 再进行响应的解析. sentinel Dubbo Adapter 实现了一个Filter Adapter, 如果根据调用端限流, 可以在调用端手动将 application name 置入到 attachement 中, key为 dubboApplication`. ​ 演示流程 修改 provider 中限流规则: flowRule.setLimitApp(&quot;springboot-study&quot;); 在 consumer 工程中, 做如下处理, 其中一个通过 attachment 传递了一个消费者的application name,另外一个没有传, 通过 jemeter 工具进行测试. @GetMapping(\"/say\") public String sayHello()&amp;#123; RpcContext.getContext().setAttachment(\"dubboApplication\",\"springbootstudy\"); String result=sentinelService.sayHello(\"Mic\"); return result; &amp;#125; @GetMapping(\"/say2\") public String say2Hello()&amp;#123; String result=sentinelService.sayHello(\"Mic\"); return result; &amp;#125; ControlBehavior当QPS 超过某个阈值后, 则采取措施进行流量控制. 流量控制的手段包括以下几种: 直接拒绝、Warm up、匀速排队. 对应FlowRule 中的controlBehavior 字段 直接拒绝（RuleConstant.CONTROL_BEHAVIOR_DEFAULT）直接拒绝方式是默认的流量控制方式, 当QPS 超过任意规则的阈值后, 新的请求会被立即拒绝. 拒绝方式为抛出FlowException. 这种方式适用于对系统处理能力确切已知的情况下, 比如通过压测确定了系统的准确水位时. Warm Up（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）Warm Up方式,即预热/冷启动方式, 当系统长期处于低并发的情况下, 流量突然增加到QPS的最高峰值, 可能会造成系统的瞬间流量过大把系统压垮. 所以Warm Up ,相当于处理请求的数量是缓慢增加的, 经过一段时间后,到达系统处理请求个数的最大值. 匀速排队（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）匀速排队方式会严格控制请求通过的间隔时间, 也即是让请求以均匀的速度通过, 对应的是漏桶算法. 它的原理是: 以固定的时间间隔让请求通过, 当请求过来的时候, 如果当前请求距离上个通过的请求通过的时间间隔不小于预设值, 则让当前请求通过. 否则, 计算当前请求的预期通过时间, 如果该i请求的预期通过时间小于规则预设的 timeout 时间 ， 则该请求会等待直到预设时间来通过. 反之, 则马上抛出阻塞异常. 可以设置一个最长排队等待时间: flowRule.setMaxQueueingTimeMs(5 * 1000); // 最长排队等待时 间：5s 这种方式主要用于处理间隔性突发的流量, 假如消息队列, 想象一下这样的场景, 在某一秒有大量的请求到来, 而接下来的几秒则处于空闲状态, 我们希望系统能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒就直接拒绝多余的请求. 如何实现分布式限流在前面的案例中,我们只是基于sentinel的基本使用和单机限流的使用, 假设有这样一个场景, 我们现在把provider 部署了10个集群, 希望调用这个服务器的api 的总的QPS 是100, 意味着每一台集群的QPS 是10, 理想情况下总的QPS 就是100, 但是实际上由于负载均衡的流量分发并不是非常均匀, 就会导致总的QPS 不足100时就会被限了. 在这个场景中, 仅仅依靠单机来实现总的流量的控制是有问题的, 所以最好的能实现集群限流. 架构图要想使用集群流控功能, 我们需要在应用端配置动态规则源, 并通过 sentinel控制台进行推送, 如下图所示: 搭建token-server 添加jar依赖 &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-cluster-server-default&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-transport-simple-http&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-datasource-nacos&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.slf4j&lt;/groupId> &lt;artifactId>slf4j-log4j12&lt;/artifactId> &lt;version>1.7.25&lt;/version> &lt;/dependency> 编写启动类TokenClusterServerpublic class TokenClusterServer &amp;#123; public static void main(String[] args) &amp;#123; ClusterTokenServer tokenServer = new SentinelDefaultTokenServer(); ClusterServerConfigManager.loadGlobalTransportConfig(new ServerTransportConfig() .setIdleSeconds(600) .setPort(9999)); ClusterServerConfigManager.loadServerNamespaceSet(Collections.singleton(\"App\")); try &amp;#123; tokenServer.start(); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; DataSourceInitFuncpublic class DataSourceInitFunc implements InitFunc &amp;#123; /** * &lt;p>nacos 的远程服务host&lt;/p> * * @author luyanan * @since 2019/12/20 */ private final String remoteAddr = \"192.168.86.128\"; /** * &lt;p>nacos groupId&lt;/p> * * @author luyanan * @since 2019/12/20 */ private final String groupId = \"SENTINEL_GROUP\"; /** * &lt;p>namespace 不同, 限流规则不同&lt;/p> * * @author luyanan * @since 2019/12/20 */ private static final String FLOW_POSTFIX = \"-flow-rules\"; @Override public void init() throws Exception &amp;#123; ClusterFlowRuleManager.setPropertySupplier(namespace -> &amp;#123; ReadableDataSource&lt;String, List&lt;FlowRule>> dataSource = new NacosDataSource&lt;List&lt;FlowRule>>(remoteAddr, groupId, namespace + FLOW_POSTFIX, s -> JSON.parseObject(s, new TypeReference&lt;List&lt;FlowRule>>() &amp;#123; &amp;#125;)); return dataSource.getProperty(); &amp;#125;); &amp;#125; &amp;#125; resources 目录添加扩展点/META-INF/services/com.alibaba.csp.sentinel.init.InitFunc = 自定义扩展点 com.sentinel.token.DataSourceInitFunc 启动Sentinel dashboard java -Dserver.port=8081 -Dcsp.sentinel.dashboard.server=localhost:8080 - Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.6.3.jar 启动nacos 并增加配置 启动nacos 服务 nohup sh startup.sh -m standalone &amp; 增加限流配置 配置JVM参数配置如下JVM参数, 连接到 sentinel dashboard, -Dproject.name=App -Dcsp.sentinel.dashboard.server=192.168.86.128:8081 - Dcsp.sentinel.log.use.pid=true 服务启动后, 在 $user.home$/logs/csp/ 可以找到sentinel-record.log.pid*.date 文件, 如果看到日志文件中获取了远程服务的信息, 说明 token-server 启动成功了. Dubbo 接入分布式限流jar依赖&lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-dubbo-adapter&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-cluster-client-default&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-datasource-nacos&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-annotation-aspectj&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-transport-simple-http&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-core&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.sentinel&lt;/groupId> &lt;artifactId>sentinel-dubbo-api&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-client&lt;/artifactId> &lt;version>4.0.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.curator&lt;/groupId> &lt;artifactId>curator-recipes&lt;/artifactId> &lt;version>4.0.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.dubbo&lt;/groupId> &lt;artifactId>dubbo&lt;/artifactId> &lt;version>2.7.2&lt;/version> &lt;/dependency> 增加扩展点扩展点需要在resources/META-INF/services/增加扩展的配置 com.alibaba.csp.sentinel.init.InitFunc = 自定义扩展点 package com.sentinel2; import com.alibaba.csp.sentinel.cluster.client.ClientConstants; import com.alibaba.csp.sentinel.cluster.client.config.ClusterClientAssignConfig; import com.alibaba.csp.sentinel.cluster.client.config.ClusterClientConfig; import com.alibaba.csp.sentinel.cluster.client.config.ClusterClientConfigManager; import com.alibaba.csp.sentinel.datasource.ReadableDataSource; import com.alibaba.csp.sentinel.datasource.nacos.NacosDataSource; import com.alibaba.csp.sentinel.init.InitFunc; import com.alibaba.csp.sentinel.slots.block.flow.FlowRule; import com.alibaba.csp.sentinel.slots.block.flow.FlowRuleManager; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.TypeReference; import org.aspectj.weaver.ast.Or; import javax.xml.crypto.Data; import java.util.List; /** * @author luyanan * @since 2019/12/20 * &lt;p>&lt;/p> **/ public class DataSourceInitFunc implements InitFunc &amp;#123; /** * &lt;p>token server 的ip&lt;/p> * * @author luyanan * @since 2019/12/20 */ private final String CLUSTER_SERVER_HOST = \"192.168.86.128\"; /** * &lt;p>token-server 的端口&lt;/p> * * @author luyanan * @since 2019/12/20 */ private static final int CLUSTER_SERVER_PORT = 9999; /** * &lt;p>请求超时时间&lt;/p> * * @author luyanan * @since 2019/12/20 */ private static final int REQUEST_TIME_OUT = 20000; private final static String APP_NAME = \"APP\"; /** * &lt;p>nacos 服务的ip&lt;/p> * * @author luyanan * @since 2019/12/20 */ private final static String REOMOTE_ADDR = \"192.168.86.128\"; /** * &lt;p>group id&lt;/p> * * @author luyanan * @since 2019/12/20 */ private final static String GROUP_ID = \"SENTINEL_GROUP\"; /** * &lt;p>限流规则后缀&lt;/p> * * @author luyanan * @since 2019/12/20 */ private static final String FLOW_POSTFIX = \"-flow-rules\"; @Override public void init() throws Exception &amp;#123; loadClusterClientConfig(); registerClusterFlowRuleProperty(); &amp;#125; /** * 注册动态规则 Property, * 当Client与Server连接中断, 退化为本地限流时需要用到的规则 * 该配置为必选项,客户端会从nacos 上加载限流规则, 请求tokenserver 的时候, 会带上要check 的规则id */ private void registerClusterFlowRuleProperty() &amp;#123; // 使用Nacos 数据源作为配置中心, 需要在REMOTE_ADDRSS 上启动一个Nacos 的服务 ReadableDataSource&lt;String, List&lt;FlowRule>> ds = new NacosDataSource&lt;List&lt;FlowRule>>(REOMOTE_ADDR, GROUP_ID, APP_NAME + FLOW_POSTFIX, source -> JSON.parseObject(source, new TypeReference&lt;List&lt;FlowRule>>() &amp;#123; &amp;#125;)); // 为集群客户端注册动态规则源 FlowRuleManager.register2Property(ds.getProperty()); &amp;#125; /** * 通过硬编码的方式,配置连接到token-server 服务的地址，(这种在实际使用过程中不建议使用, 后续可以基于动态配置源改造) */ private void loadClusterClientConfig() &amp;#123; ClusterClientAssignConfig assignConfig = new ClusterClientAssignConfig(); assignConfig.setServerHost(CLUSTER_SERVER_HOST); assignConfig.setServerPort(CLUSTER_SERVER_PORT); ClusterClientConfigManager.applyNewAssignConfig(assignConfig); ClusterClientConfig clientConfig = new ClusterClientConfig(); clientConfig.setRequestTimeout(REQUEST_TIME_OUT); // token-client 请求token-server 获取令牌的时间 ClusterClientConfigManager.applyNewConfig(clientConfig); &amp;#125; &amp;#125; 配置JVM参数这里的project_name 要包含在 token-server 中配置的 namesapce token-server 会根据客户端对应的namespace(默认为 project.name定义的应用名)下的连接数来计算总的阈值 -Dproject.name=App -Dcsp.sentinel.dashboard.server=192.168.86.128:8081 - Dcsp.sentinel.log.use.pid=true 服务启动后, 在 $user.home$/logs/csp/ 可以找到sentinel-record.log.pid*.date 文件, 如果看到日志文件中获取到了 token-server 的信息, 说明连接成功了 演示集群限流所谓集群限流, 就是多个服务节点使用同一个限流规则, 从而对多个节点的总流量进行限制, 添加一个 sentinel-server , 同时运行两个程序.","categories":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://rainsoil.github.io/categories/Sentinel/"},{"name":"微服务","slug":"Sentinel/微服务","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"Sentinel/微服务/微服务","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Sentinel","slug":"Sentinel/微服务/微服务/Sentinel","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Sentinel/"}],"tags":[]},{"title":"RocketMQ问题","slug":"微服务/RocketMQ/RocketMQ问题","date":"2022-01-04T02:42:07.281Z","updated":"2022-01-04T02:42:07.281Z","comments":true,"path":"2022/01/04/wei-fu-wu/rocketmq/rocketmq-wen-ti/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rocketmq/rocketmq-wen-ti/","excerpt":"","text":"RocketMQ 问题rocketmq 连接异常 sendDefaultImpl call timeout需要将broker 的ip 换成本地的ip在conf/broker.conf 里面加上 brokerIP1=[本机ip] 然后重启 nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf autoCreateTopicEnable=true &amp; 再运行程序, 就不在报错.","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/"},{"name":"微服务","slug":"RocketMQ/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"RocketMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"RocketMQ","slug":"RocketMQ/微服务/微服务/RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/RocketMQ/"}],"tags":[]},{"title":"Sentinel的基本应用以及原理分析","slug":"微服务/Sentinel/Sentinel的基本应用以及原理分析","date":"2022-01-04T02:42:07.281Z","updated":"2022-01-04T02:42:07.281Z","comments":true,"path":"2022/01/04/wei-fu-wu/sentinel/sentinel-de-ji-ben-ying-yong-yi-ji-yuan-li-fen-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/sentinel/sentinel-de-ji-ben-ying-yong-yi-ji-yuan-li-fen-xi/","excerpt":"","text":"Sentinel的基本应用以及原理分析限流的基本认识场景分析一个互联网产品, 打算搞一次大促来增加销量以及曝光. 公司的架构师基于往期的流量情况做了一个活动流量的预估. 然后整个公司的各个技术团队开始按照这个目标进行设计和优化, 最终在大家的不懈努力下,达到了链路压测的目标流量峰值. 到了活动开始那天, 大家都盯着监控面板, 看着流量像洪水一样涌进来, 由于前期的宣传工作做得非常好, 使得这个流程远远超过预期的峰值, 后端服务开始不稳定, CPU、内存各种爆表. 部分服务开始出现无响应的情况. 最后, 整个系统开始崩溃, 用户无法正常访问服务, 最后导致公司巨大的损失. 引入限流在10.1黄金周, 各大旅游景点都是人满为患, 所以有些景点为了避免出现踩踏事故, 会采取限流措施. 那在架构场景中, 是不是也能这样做呢? 针对这个场景, 能不能设置一个最大的流量限制, 如果超过这个流量, 我们就拒绝提供服务, 从而使得我们的服务不会挂掉. 当前, 限流虽然能够保证系统不被压垮, 但是对于被限流的用户来说, 就会很不开心. 所以限流其实是一种有损的解决方案, 但是相对于全部不可用, 有损服务是最好的一种解决方法. 限流的作用除了前面说的限流使用场景之外，限流的设置还能防止恶意请求流量、恶意攻击. 所以, 限流的基本原理是通过对并发访问/请求进行限速或者一个时间窗口内的请求进行限速来保护系统, 一旦达到限制速率则可以拒绝服务(定向到错误页面或者告知资源没有了)、排队或等待(秒杀、下单)、降级(返回兜底数据或者默认数据,如商品详情库存默认有货). 一般互联网企业常见的限流有: 限制总并发数(如数据库连接池、线程池)、限制瞬间并发数(nginx的limit_conn模块、用来限制瞬间并发连接数)、限制时间窗口内的平均速率(如Guava 的RateLimiter、nginx的limit_req模块、限制每秒的平均速率);其他的还有限制远程接口调用速率、限制MQ的消费速率、另外还可以根据网络连接数、网络流量、CPU或内存负载等来限流. 有了限流, 就意味着在处理高并发的时候多了一种保护机制, 不用担心瞬间流量导致系统挂掉或者雪崩, 最后做到有损服务而不是不服务, 但是限流需要做好评估, 不能乱用, 否则一些正常流量出现一些奇怪的问题而导致用户体验很差造成用户损失. 常见的限流算法滑动窗口算法发送和接收方都会维护一个数据帧的序列, 这个序列被称为窗口。发送方的窗口大小由接收方确定,目的在于控制发送速度, 以免接收方的缓存不够大, 而导致溢出. 同时控制流量也可以避免网络拥塞. 下面图中的4，5，6号数据帧已经被发送出去, 但是未收到关联的ACK， 7，8，9 帧则是等待发送. 可以看出发送端的窗口大小为6, 这时由接收端告知的. 此时如果发送端收到4号ACK， 则窗口的左边缘向右收缩, 窗口的右边缘则向右扩展, 此时窗口就向前滑动了, 则数据帧10 也可以被发送. 漏桶(控制传输速率Leaky bucket)漏桶算法思路是: 不断的往桶里面注水, 无论注水的速度是大还是小, 水都是按照固定的速率往外漏水, 如果桶满了, 水会溢出. 桶本身具有一个恒定的速率往下漏水, 而上方时快时慢的会由水进入桶中,当桶还未满时, 上方的水可以加入. 一旦水满, 上方的水就无法加入. 桶满正是算法中的一个关键的触发条件(即流量异常判断成立的条件).而此条件下如何处理上方流下的水, 有两种方式: 在桶满水之后, 常见的两种处理方式: 暂时拦截住上方水的向下流动, 等待桶中的一部分水漏走后, 再放行上方水. 溢出的上方水直接抛弃. 特点： 漏水的速率是固定的. 即使存在突然注水量变大的情况, 漏水的速率也是固定的. 令牌桶(能够解决突发流量)令牌桶算法是网络流量整形(Traffic Shaping) 和速率限制(Rate Limiting) 中最常用的一种算法. 典型情况下, 令牌桶算法用来控制发送到网络上的数据数目, 并允许突发数据的发送. 令牌桶是一个存放固定容量令牌(token)的桶, 按照固定速率往桶里添加令牌, 令牌桶算法实际上由三部分组成, 两个流和一个桶, 分别是令牌桶、数据流和令牌桶. 令牌流和令牌桶系统会以一定的速度生成令牌, 并将其防止到令牌桶中, 可以将令牌桶想象成一个缓存区(可以用队列这种数据结构来实现), 当缓冲区填满的时候, 新生成的令牌会被扔掉, 这里有两个变量很重要. 第一个是生成令牌的速度, 一般成为 rate, 比如我们设定rate=2, 即每秒生成2个令牌，也就是每 1/2 秒生成一个令牌. 第二个是令牌桶的大小, 一般称为burst, 比如我们设定burst = 10, 即令牌桶最大只能容纳10个令牌. 有三种情况可能发生: 数据流的速率等于令牌流的速率, 这种情况下每个到来的数据包或者请求都能对应一个令牌, 然后无延迟的通过队列. 数据流的速率小于令牌桶的速率, 通过队列的数据包或者请求只消耗了一部分令牌, 剩下的令牌会在令牌桶中积累下来, 直到桶被装满, 剩下的令牌可以在突发请求的时候消耗掉. 数据流的速率大于令牌流的速率 , 这意味着桶里的令牌很快就被耗尽, 导致服务中断一段时间, 如果数据包或者请求持久到来, 将发生丢包或者拒绝响应. 使用Sentinel 实现限流介绍sentinel 是Alibaba 开源的一个面向分布式服务架构的轻量级流量控制组件,主要以流量为切入点, 从限流、流量整型、熔断降级、系统负载保存等多个维度来保证微服务的稳定性. 简单实现我们先再pom.xml 中添加sentinel 的依赖 &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-core&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> 代码示例 package com.sentinel; import com.alibaba.csp.sentinel.Entry; import com.alibaba.csp.sentinel.SphU; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.alibaba.csp.sentinel.slots.block.RuleConstant; import com.alibaba.csp.sentinel.slots.block.flow.FlowRule; import com.alibaba.csp.sentinel.slots.block.flow.FlowRuleManager; import java.util.ArrayList; import java.util.List; /** * @author luyanan * @since 2019/12/13 * &lt;p>&lt;/p> **/ public class SentinelDemo &amp;#123; private final static String resource = \"hello\"; /** * &lt;p>初始化限流规则&lt;/p> * * @return &amp;#123;@link &amp;#125; * @author luyanan * @since 2019/12/13 */ private static void initFlowRules() &amp;#123; List&lt;FlowRule> rules = new ArrayList&lt;>(); FlowRule flowRule = new FlowRule(); // 资源(方法名称/接口) flowRule.setResource(resource); // 限流的阈值类型 qps和线程数 flowRule.setGrade(RuleConstant.FLOW_GRADE_QPS); // 设置数量 flowRule.setCount(1000); rules.add(flowRule); FlowRuleManager.loadRules(rules); &amp;#125; public static void main(String[] args) &amp;#123; // 初始化规则 initFlowRules(); while (true) &amp;#123; Entry entry = null; try &amp;#123; entry = SphU.entry(resource); System.out.println(\"hello world\"); &amp;#125; catch (BlockException e) &amp;#123; // 如果被限流, 则会抛出异常 e.printStackTrace(); &amp;#125; finally &amp;#123; if (entry != null) &amp;#123; // 释放 entry.exit(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 通过上面的代码, 我们就基本完成了一个单机版的限流 接入控制台获取sentinel 控制台从release页面获取最新版本的控制台jar包 启动使用如下命令启动控制台 java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 其中 -Dserver.port=8080 用于指定 Sentinel 控制台端口为 8080。 从 Sentinel 1.6.0 起，Sentinel 控制台引入基本的登录功能，默认用户名和密码都是 sentinel 客户端接入控制台控制台启动后, 客户端需要按照以下步骤接入到控制台 1. 添加依赖 &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-transport-simple-http&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> 2. 配置启动参数启动时加入 JVM 参数 -Dcsp.sentinel.dashboard.server=consoleIp:port 指定控制台地址和端口。若启动多个应用，则需要通过 -Dcsp.sentinel.api.port=xxxx 指定客户端监控 API 的端口（默认是 8719） 3. 然后就可以访问 localhost:8080 查看访问控制台了使用注解实现限流Sentinel 支持通过 @SentinelResource 注解定义资源并配置 blockHandler 和 fallback 函数来进行限流之后的处理。示例： 添加依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-aop&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba.csp&lt;/groupId> &lt;artifactId>sentinel-annotation-aspectj&lt;/artifactId> &lt;version>1.6.3&lt;/version> &lt;/dependency> 编写配置类和加载规则package com.sentinel; import com.alibaba.csp.sentinel.annotation.aspectj.SentinelResourceAspect; import com.alibaba.csp.sentinel.slots.block.RuleConstant; import com.alibaba.csp.sentinel.slots.block.flow.FlowRule; import com.alibaba.csp.sentinel.slots.block.flow.FlowRuleManager; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.ArrayList; import java.util.List; /** * @author luyanan * @since 2019/12/16 * &lt;p>&lt;/p> **/ @Configuration public class SentinelConfiguration &amp;#123; @Bean public SentinelResourceAspect sentinelResourceAspect() &amp;#123; initFlowRules(); return new SentinelResourceAspect(); &amp;#125; /** * &lt;p>初始化规则&lt;/p> * * @author luyanan * @since 2019/12/16 */ private void initFlowRules() &amp;#123; List&lt;FlowRule> ruleList = new ArrayList&lt;>(); FlowRule flowRule = new FlowRule(); // 资源的地址 flowRule.setResource(\"hello\"); // 限流的类型 flowRule.setGrade(RuleConstant.FLOW_GRADE_QPS); flowRule.setCount(10); ruleList.add(flowRule); FlowRuleManager.loadRules(ruleList); &amp;#125; &amp;#125; 编写测试的方法/** * @author luyanan * @since 2019/12/16 * &lt;p>&lt;/p> **/ @RestController @RequestMapping(\"user\") public class SentinelController &amp;#123; @SentinelResource(value = \"hello\") @GetMapping(\"hello\") public String hello() &amp;#123; System.out.println(\"hello world\"); return \"hello\"; &amp;#125; &amp;#125; 规则的种类Sentinel 的所有规则都可以在内存态中动态地查询及修改，修改之后立即生效。同时 Sentinel 也提供相关 API，供您来定制自己的规则策略。 Sentinel 支持以下几种规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则 和 热点参数规则。 流量控制规则 (FlowRule)流量规则的定义重要属性： Field 说明 默认值 resource 资源名，资源名是限流规则的作用对象 count 限流阈值 grade 限流阈值类型，QPS 模式（1）或并发线程数模式（0） QPS 模式 limitApp 流控针对的调用来源 default，代表不区分调用来源 strategy 调用关系限流策略：直接、链路、关联 根据资源本身（直接） controlBehavior 流控效果（直接拒绝 / 排队等待 / 慢启动模式），不支持按调用关系限流 直接拒绝 同一个资源可以同时有多个限流规则，检查规则时会依次检查。 通过代码定义流量控制规则理解上面规则的定义之后，我们可以通过调用 FlowRuleManager.loadRules() 方法来用硬编码的方式定义流量控制规则，比如： private void initFlowQpsRule() &amp;#123; List&lt;FlowRule> rules = new ArrayList&lt;>(); FlowRule rule = new FlowRule(resourceName); // set limit qps to 20 rule.setCount(20); rule.setGrade(RuleConstant.FLOW_GRADE_QPS); rule.setLimitApp(\"default\"); rules.add(rule); FlowRuleManager.loadRules(rules); &amp;#125; 原理分析入口 entry= SphU.entry(resource); 进入到 public static Entry entry(String name) throws BlockException &amp;#123; return Env.sph.entry(name, EntryType.OUT, 1, OBJECTS0); &amp;#125; Env.sphpublic class Env &amp;#123; public static final Sph sph = new CtSph(); static &amp;#123; // If init fails, the process will exit. InitExecutor.doInit(); &amp;#125; &amp;#125; 我们发现有一个静态块 InitExecutor.doInit(); public static void doInit() &amp;#123; if (!initialized.compareAndSet(false, true)) &amp;#123; return; &amp;#125; try &amp;#123; ServiceLoader&lt;InitFunc> loader = ServiceLoader.load(InitFunc.class); List&lt;OrderWrapper> initList = new ArrayList&lt;OrderWrapper>(); for (InitFunc initFunc : loader) &amp;#123; RecordLog.info(\"[InitExecutor] Found init func: \" + initFunc.getClass().getCanonicalName()); insertSorted(initList, initFunc); &amp;#125; for (OrderWrapper w : initList) &amp;#123; w.func.init(); RecordLog.info(String.format(\"[InitExecutor] Executing %s with order %d\", w.func.getClass().getCanonicalName(), w.order)); &amp;#125; &amp;#125; catch (Exception ex) &amp;#123; RecordLog.warn(\"[InitExecutor] WARN: Initialization failed\", ex); ex.printStackTrace(); &amp;#125; catch (Error error) &amp;#123; RecordLog.warn(\"[InitExecutor] ERROR: Initialization failed with fatal error\", error); error.printStackTrace(); &amp;#125; &amp;#125; 我们发现, 这里通过SPI 机制加载InitFunc 的实现类, 然后分别调用他们的 init 方法. Env.sph.entry @Override public Entry entry(String name, EntryType type, int count, Object... args) throws BlockException &amp;#123; StringResourceWrapper resource = new StringResourceWrapper(name, type); return entry(resource, count, args); &amp;#125; 这里通过name 和type 包装一个StringResourceWrapper, 即抽象的资源. CtSph.entry public Entry entry(ResourceWrapper resourceWrapper, int count, Object... args) throws BlockException &amp;#123; return entryWithPriority(resourceWrapper, count, false, args); &amp;#125; entryWithPriorityprivate Entry entryWithPriority(ResourceWrapper resourceWrapper, int count, boolean prioritized, Object... args) throws BlockException &amp;#123; Context context = ContextUtil.getContext(); if (context instanceof NullContext) &amp;#123; // The &amp;#123;@link NullContext&amp;#125; indicates that the amount of context has exceeded the threshold, // so here init the entry only. No rule checking will be done. return new CtEntry(resourceWrapper, null, context); &amp;#125; if (context == null) &amp;#123; // Using default context. context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME); &amp;#125; // Global switch is close, no rule checking will do. if (!Constants.ON) &amp;#123; return new CtEntry(resourceWrapper, null, context); &amp;#125; ProcessorSlot&lt;Object> chain = lookProcessChain(resourceWrapper); /* * Means amount of resources (slot chain) exceeds &amp;#123;@link Constants.MAX_SLOT_CHAIN_SIZE&amp;#125;, * so no rule checking will be done. */ if (chain == null) &amp;#123; return new CtEntry(resourceWrapper, null, context); &amp;#125; Entry e = new CtEntry(resourceWrapper, chain, context); try &amp;#123; chain.entry(context, resourceWrapper, null, count, prioritized, args); &amp;#125; catch (BlockException e1) &amp;#123; e.exit(count, args); throw e1; &amp;#125; catch (Throwable e1) &amp;#123; // This should not happen, unless there are errors existing in Sentinel internal. RecordLog.info(\"Sentinel unexpected exception\", e1); &amp;#125; return e; &amp;#125; InternalContextUtil.internalEnter private final static class InternalContextUtil extends ContextUtil &amp;#123; static Context internalEnter(String name) &amp;#123; return trueEnter(name, \"\"); &amp;#125; static Context internalEnter(String name, String origin) &amp;#123; return trueEnter(name, origin); &amp;#125; &amp;#125; trueEnterprotected static Context trueEnter(String name, String origin) &amp;#123; Context context = contextHolder.get(); if (context == null) &amp;#123; Map&lt;String, DefaultNode> localCacheNameMap = contextNameNodeMap; DefaultNode node = localCacheNameMap.get(name); if (node == null) &amp;#123; if (localCacheNameMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) &amp;#123; setNullContext(); return NULL_CONTEXT; &amp;#125; else &amp;#123; try &amp;#123; LOCK.lock(); node = contextNameNodeMap.get(name); if (node == null) &amp;#123; if (contextNameNodeMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) &amp;#123; setNullContext(); return NULL_CONTEXT; &amp;#125; else &amp;#123; node = new EntranceNode(new StringResourceWrapper(name, EntryType.IN), null); // Add entrance node. Constants.ROOT.addChild(node); Map&lt;String, DefaultNode> newMap = new HashMap&lt;>(contextNameNodeMap.size() + 1); newMap.putAll(contextNameNodeMap); newMap.put(name, node); contextNameNodeMap = newMap; &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; LOCK.unlock(); &amp;#125; &amp;#125; &amp;#125; context = new Context(node, name); context.setOrigin(origin); contextHolder.set(context); &amp;#125; return context; &amp;#125; lookProcessChainProcessorSlot&lt;Object> lookProcessChain(ResourceWrapper resourceWrapper) &amp;#123; ProcessorSlotChain chain = chainMap.get(resourceWrapper); if (chain == null) &amp;#123; synchronized (LOCK) &amp;#123; chain = chainMap.get(resourceWrapper); if (chain == null) &amp;#123; // Entry size limit. if (chainMap.size() >= Constants.MAX_SLOT_CHAIN_SIZE) &amp;#123; return null; &amp;#125; chain = SlotChainProvider.newSlotChain(); Map&lt;ResourceWrapper, ProcessorSlotChain> newMap = new HashMap&lt;ResourceWrapper, ProcessorSlotChain>( chainMap.size() + 1); newMap.putAll(chainMap); newMap.put(resourceWrapper, chain); chainMap = newMap; &amp;#125; &amp;#125; &amp;#125; return chain; &amp;#125; chain = SlotChainProvider.newSlotChain(); 构建一个Chaninpublic static ProcessorSlotChain newSlotChain() &amp;#123; if (builder != null) &amp;#123; return builder.build(); &amp;#125; resolveSlotChainBuilder(); if (builder == null) &amp;#123; RecordLog.warn(\"[SlotChainProvider] Wrong state when resolving slot chain builder, using default\"); builder = new DefaultSlotChainBuilder(); &amp;#125; return builder.build(); &amp;#125; new DefaultSlotChainBuilder()public class DefaultSlotChainBuilder implements SlotChainBuilder &amp;#123; public DefaultSlotChainBuilder() &amp;#123; &amp;#125; public ProcessorSlotChain build() &amp;#123; ProcessorSlotChain chain = new DefaultProcessorSlotChain(); chain.addLast(new NodeSelectorSlot()); chain.addLast(new ClusterBuilderSlot()); chain.addLast(new LogSlot()); chain.addLast(new StatisticSlot()); chain.addLast(new SystemSlot()); chain.addLast(new AuthoritySlot()); chain.addLast(new FlowSlot()); chain.addLast(new DegradeSlot()); return chain; &amp;#125; &amp;#125; 即最后的调用顺序如下： NodeSelectorSlot =&gt; ClusterBuilderSlot =&gt; LogSlot =&gt; StatisticSlot =&gt; AuthoritySlot =&gt; SystemSlot =&gt; FlowSlot =&gt; DegradeSlot 如果想改变他们的调用顺序，可通过SPI机制实现 NodeSelectorSlot构造调用链，具体参考 NodeSelectorSlot @Override public void entry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable &amp;#123; // 每个资源对应一个 ProcessorSlotChain // 一个资源可以对应多个Context // 一个ContextName 对应一个 DefaultNode , 即 一个资源可能对应多个 DefaultNode, 但 一个资源只有一个 ClusterNode // 针对同一段代码，不同线程对应的Context实例是不一样的，但是对应的Context Name是一样的，所以这时认为是同一个Context，Context我们用Name区分 DefaultNode node = map.get(context.getName()); if (node == null) &amp;#123; synchronized (this) &amp;#123; node = map.get(context.getName()); if (node == null) &amp;#123; node = new DefaultNode(resourceWrapper, null); // key 为 ontextName , vaue 为 DefaultNode HashMap&lt;String, DefaultNode> cacheMap = new HashMap&lt;String, DefaultNode>(map.size()); cacheMap.putAll(map); cacheMap.put(context.getName(), node); map = cacheMap; // Build invocation tree ((DefaultNode) context.getLastNode()).addChild(node); &amp;#125; &amp;#125; &amp;#125; context.setCurNode(node); fireEntry(context, resourceWrapper, node, count, prioritized, args); &amp;#125; ClusterBuilderSlot具体参考 ClusterBuilderSlot 每个资源对应一个ClusterNode，并且DefaultNode引用了ClusterNode LogSlot记录日志用的，先执行下面的 Solt， 如果报错了或者被Block了，记录到日志中 @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode obj, int count, boolean prioritized, Object... args) throws Throwable &amp;#123; try &amp;#123; fireEntry(context, resourceWrapper, obj, count, prioritized, args); &amp;#125; catch (BlockException e) &amp;#123; EagleEyeLogUtil.log(resourceWrapper.getName(), e.getClass().getSimpleName(), e.getRuleLimitApp(), context.getOrigin(), count); throw e; &amp;#125; catch (Throwable e) &amp;#123; RecordLog.warn(\"Unexpected entry exception\", e); &amp;#125; &amp;#125; StatisticSlot核心实现，各种计数的实现逻辑，基于时间窗口实现。 基于触发请求通过 和 请求Block 的回调逻辑，回调逻辑在 MetricCallbackInit 中初始化了， 最终还是靠 StatisticSlotCallbackRegistry // 省略了一些代码 @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &amp;#123; try &amp;#123; // 执行下来的Solt ，判断是否通过 fireEntry(context, resourceWrapper, node, count, prioritized, args); // Request passed, add thread count and pass count. node.increaseThreadNum(); node.addPassRequest(count); &amp;#125; catch (BlockException e) &amp;#123; // Blocked, set block exception to current entry. context.getCurEntry().setError(e); // Add block count. node.increaseBlockQps(count); if (context.getCurEntry().getOriginNode() != null) &amp;#123; context.getCurEntry().getOriginNode().increaseBlockQps(count); &amp;#125; &amp;#125; &amp;#125; DefaultNode 继承自 StatisticNode , 在 StatisticNode 中有两个属性 // 第一个参数表示 窗口的个数；第二个参数表示 窗口对多长时间进行统计 比如 QPS xx/秒 那就是 1000 毫秒， 所以窗口的长度为 1000/个数 private transient volatile Metric rollingCounterInSecond = new ArrayMetric(SampleCountProperty.SAMPLE_COUNT, IntervalProperty.INTERVAL); // 窗口长度为1000 60个 刚好一分钟 private transient Metric rollingCounterInMinute = new ArrayMetric(60, 60 * 1000, false); ArrayMetric 持有 LeapArray ， LeapArray 主要有两个实现类 OccupiableBucketLeapArray 、 BucketLeapArray ， 但根据当前时间获取窗口的核心实现在 LeapArray 抽象类中 滑动窗口简单理解就是： 根据任何时间，都可以获取一个对应的窗口，在该窗口内，保存着在窗口长度时间内通过的请求数、被block的请求数、异常数、RT。基于这些数据，我们就可以得到对应的资源的QPS、RT等指标信息。 核心方法在 LeapArray#currentWindow ， 整体思路如下 根据当前时间获取时间窗口的下标 (time/windowLength) % array.length() 计算当前时间对应时间窗口的开始时间 time - time % windowLength 根据下标获取时间窗口，这里分三种情况： (1) 根据下标没有获取到窗口，此时创建一个窗口。此时代表窗口没有创建 或者 窗口还没有开始滑动， 所以对应的下标位置为null (2) 根据下标获取到窗口，并且该窗口的开始时间和上面计算的开始时间一样，此时直接返回该窗口 (3) 根据下标获取到窗口，但是该窗口的开始时间大于上面计算的开始时间，这时需要用计算的开始时间重置该窗口的开始时间，这就类似于窗口在滑动 public WindowWrap&lt;T> currentWindow(long timeMillis) &amp;#123; if (timeMillis &lt; 0) &amp;#123; return null; &amp;#125; // 计算窗口数组下标 int idx = calculateTimeIdx(timeMillis); // 计算开始时间 long windowStart = calculateWindowStart(timeMillis); while (true) &amp;#123; WindowWrap&lt;T> old = array.get(idx); if (old == null) &amp;#123; WindowWrap&lt;T> window = new WindowWrap&lt;T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); if (array.compareAndSet(idx, null, window)) &amp;#123; // Successfully updated, return the created bucket. return window; &amp;#125; else &amp;#123; // 循环重试 Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); &amp;#125; &amp;#125; else if (windowStart == old.windowStart()) &amp;#123; return old; &amp;#125; else if (windowStart > old.windowStart()) &amp;#123; if (updateLock.tryLock()) &amp;#123; try &amp;#123; // Successfully get the update lock, now we reset the bucket. return resetWindowTo(old, windowStart); &amp;#125; finally &amp;#123; updateLock.unlock(); &amp;#125; &amp;#125; else &amp;#123; // Contention failed, the thread will yield its time slice to wait for bucket available. Thread.yield(); &amp;#125; &amp;#125; else if (windowStart &lt; old.windowStart()) &amp;#123; // Should not go through here, as the provided time is already behind. return new WindowWrap&lt;T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); &amp;#125; &amp;#125; &amp;#125; todo OccupiableBucketLeapArray 还不太理解 AuthoritySlot黑白名单规则校验，非常简单 @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &amp;#123; checkBlackWhiteAuthority(resourceWrapper, context); fireEntry(context, resourceWrapper, node, count, prioritized, args); &amp;#125; 加载所有的黑白名单规则 遍历所有黑白名单规则，调用 AuthorityRuleChecker#passCheck 方法，如果不通过则抛出 AuthorityException 校验逻辑：从 Context 中拿到 originName, 然后判断 originName 是否在 规则的 limitApp 中, 然后判断是 黑名单 还是白名单，然后校验返回结果 SystemSlot仅对入口流量有效，校验顺序 QPS -&gt; 线程数 -&gt; RT -&gt; BBR -&gt; CPU @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &amp;#123; SystemRuleManager.checkSystem(resourceWrapper); fireEntry(context, resourceWrapper, node, count, prioritized, args); &amp;#125; FlowSlot限流处理 三种拒绝策略：直接拒绝、WarnUP、匀速排队 三种限流模式：直接、关联、链路 @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &amp;#123; checkFlow(resourceWrapper, context, node, count, prioritized); fireEntry(context, resourceWrapper, node, count, prioritized, args); &amp;#125; FlowRuleChecker#checkFlow 获取所有限流规则 遍历规则，执行 FlowRuleChecker#canPassCheck =&gt; FlowRuleChecker#passLocalCheck =&gt; rule.getRater().canPass(selectedNode, acquireCount, prioritized) rule.getRater() 返回一个 TrafficShapingController 对象， 它有3种实现(代码中有4中，但官方文档只介绍了3种)，即对应上面的三种流控模式，每个规则对用的 TrafficShapingController 是在加载规则的时候就确定了 // FlowRuleUtil#generateRater private static TrafficShapingController generateRater(/*@Valid*/ FlowRule rule) &amp;#123; if (rule.getGrade() == RuleConstant.FLOW_GRADE_QPS) &amp;#123; switch (rule.getControlBehavior()) &amp;#123; case RuleConstant.CONTROL_BEHAVIOR_WARM_UP: return new WarmUpController(rule.getCount(), rule.getWarmUpPeriodSec(), ColdFactorProperty.coldFactor); case RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER: return new RateLimiterController(rule.getMaxQueueingTimeMs(), rule.getCount()); case RuleConstant.CONTROL_BEHAVIOR_WARM_UP_RATE_LIMITER: return new WarmUpRateLimiterController(rule.getCount(), rule.getWarmUpPeriodSec(), rule.getMaxQueueingTimeMs(), ColdFactorProperty.coldFactor); case RuleConstant.CONTROL_BEHAVIOR_DEFAULT: default: // Default mode or unknown mode: default traffic shaping controller (fast-reject). &amp;#125; &amp;#125; return new DefaultController(rule.getCount(), rule.getGrade()); &amp;#125; DefaultController比较简单，判断逻辑 (当前的Count + 本次调用) 是否大于 规则中设置的 阈值 WarmUpController让QPS在指定的时间内增加到 阈值， 目前每太看懂 RateLimiterController也比较简单，先按规则中配置的QPS计算每个请求的平均响应时间，然后判断当前请求是否能够等那么久(规则中的时间窗口) 三种限流模式在哪里体现？其实这个主要就是判断 你的指标数据应该要从哪个 Node 中获取，这部分逻辑在 FlowRuleChecker#selectNodeByRequesterAndStrategy 方法中 直接： 根据你的 originName 和 limitApp 来判断是取 ClusterNode 还是 OriginNode 关联： 根据关联的资源名取对应的 ClusterNode 链路： 判断关联的资源 和 当前的 contextName 是否一致，是则返回 当前的 DefaultNode DegradeSlot降级处理 目前有三种降级模式：基于RT、基于异常比例、基于一分钟异常数 @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &amp;#123; DegradeRuleManager.checkDegrade(resourceWrapper, context, node, count); fireEntry(context, resourceWrapper, node, count, prioritized, args); &amp;#125; 基于RT从时间窗口获取RT和规则中配置的阈值进行比较， 通过则 重置计数，然后直接返回； 不通过则 计数加1，如果 计数 &gt;= 5，则进行降级处理 基于异常比例前提条件 QPS &gt; =5 , 然后用 1s异常数/1s总请求数 , 和规则中配置的阈值进行比较 基于1分钟异常数直接用1分钟内的异常数和规则的阈值做比较 如何按时间窗口降级定时任务 + flag 如果降级了， 设置 flag = true , 在 时间窗口秒后， 重置 flag = false ，然后再 passCheck 方法的入口处， 如果 flag = true 就直接降级","categories":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://rainsoil.github.io/categories/Sentinel/"},{"name":"微服务","slug":"Sentinel/微服务","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"Sentinel/微服务/微服务","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Sentinel","slug":"Sentinel/微服务/微服务/Sentinel","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Sentinel/"}],"tags":[]},{"title":"RocketMQ事务性消息","slug":"微服务/RocketMQ/RocketMQ事务性消息","date":"2022-01-04T02:42:07.281Z","updated":"2022-01-04T02:42:07.281Z","comments":true,"path":"2022/01/04/wei-fu-wu/rocketmq/rocketmq-shi-wu-xing-xiao-xi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/wei-fu-wu/rocketmq/rocketmq-shi-wu-xing-xiao-xi/","excerpt":"","text":"RocketMQ事务性消息​ 在现在的很多分布式集群环境中, 经常会遇到本地事务无法解决的问题, 所以会引进分布式事务. 所谓的分布式事务是指分布式架构中多个服务的节点的数据一致性. 1. 经典的X/OpenDTP事务模型​ X/Open DTP(X/Open Distributed Transaction Processing Reference Model) 是X/Open 这个组织定义的一套分布式事务的标准， 也就是定义了规范和API接口,由各个厂商进行具体的实现. ​ 这个标准提出了使用二阶段提交(2PC- Two-Phase-Commit) 来保证分布式事务的完整性.后来J2EE 也遵循了X/Open DTP 规范, 设计并使用了Java 的分布式事务编程接口规范-JTA 1.1 X/Open DTP 角色在X/Open DTP事务模型中,定义了三个角色: AP: application,应用程序,也就是业务层,哪些操作属于同一个事务,就是AP定义的. RM: Resource Manager,资源管理器, 一般是数据库, 也可以是其他资源管理器, 比如消息队列. TM:Transaction Manage: 事务管理器、事务协调者,负责接收来自用户程序(AP)发起的XA事务指令,并调度和协调参与事务的所有RM(S数据库) , 确保事务正确完成. ​ 在分布式系统中, 每一个机器节点虽然都能够明确知道自己在进行事务操作过程中的结果是成功还是失败, 但却无法直接获取到其他分布式节点的操作结果.因此, 当一个事务操作需要跨越多个分布式节点的时候, 为了保证事务处理的ACID特性, 就需要引入一个”协调者”(TM)来统一调度所有分布式节点的执行逻辑 , 这些被调度的分布式节点被称为AP.TM负责调度AP的行为, 并最终决定这些AP 是否要事务真正的进行提交到RM. ​ XA是X/Open DTP 定义的资源管理器和事务管理器之间的接口规范,TM 用它来通知和协调相关RM事务的开始、结束、提交和回滚.目前Oracle、Mysql、DR2 都提交了对XA的支持; XA接口是双向的系统接口, 在事务管理器(TM) 以及多个资源管理器之间形成通信的桥梁(XA不能自动提交). 1.2 2PC1.2.1 第一阶段 RM 在第一阶段会做两件事情: 记录事务日志: reduo、undo 返回给TM 信息 : ok、error 存在问题:如果第一阶段完成后TM宕机或者网络出现故障了,此时RM 就会一直阻塞,发生了死锁,因为没有 timeout机制,3PC就针对此问题进行了改造,加入了 timeout机制. 1.2.2 第二阶段 根据第一个阶段的返回结果进行提交或者回滚. 1.3 CAP理论CAP的含义是: C: Consistency一致性,同一个数据的多个副本是否实时相同. A：Availability可用性, 可用性: 一定时间内 &amp; 系统返回一个明确的结果,则称之为该系统可用. P：Partition tolerance 分区容错性,将同一服务分布在多个系统中, 从而保证某一个系统宕机, 让然有其他系统提供相同的服务. CAP 理论告诉我们, 在分布式系统中, C、A、P 三个条件中我们最多只能选择两个,那么问题来了,究竟选择哪两个条件较为合适呢? ​ 对于一个业务系统来说, 可用性和分区容错性是必须满足的两个条件,并且这两个是相辅相成的. 业务系统之所以使用分布式系统, 主要原因有两个: 提升系统性能, 当业务量猛增, 单个服务器已经无法满足我们的业务需求的时候, 就需要使用分布式系统,使用多个节点提供相同的功能, 从而整体上提升系统的性能,这就是使用分布式系统的第一个原因. 实现分区容错性, 单一节点或者多个节点处于相同的是网络环境下, 那么会存在一定的风险, 万一该机房断电、该地区发生自然灾害, 那么业务系统就全面瘫痪了.为了防止这一问题,采用分布式系统,将多个子系统分布在不同的地域、不同的机房, 从而保证了系统高可用. 这说明分区容错性是分布式系统的根本, 如果分区容错性不能满足, 那使用分布式系统将失去意义. ​ 此外,可用性对业务系统也尤为重要, 在大谈用户体验的今天,如果业务系统常出现”系统异常”、响应时间过程等情况, 这使得用户对系统的好感度大打折扣, 在互联网行业竞争激烈的今天,相同领域竞争者不甚枚举,系统的间歇性不可以会立马导致用户流向竞争对手。因此, 我们只能通用牺牲一致性来换取系统的可用性和分区容错. 1.4 Base 理论CAP理论告诉我们一个悲惨但不得不接受的事实– 我们只能在C、A、P 中选择两个条件, 而对于业务系统而言,我们往往选择牺牲一致性来换取系统的可用性和分区容错性. 不过要在这里指出的是, 所谓是”牺牲一致性”并不是完全放弃数据一致性, 而是牺牲”强一致性”换取”弱一致性”. BA:Basic Availabl 基本可用 整个系统在某些不可抗力的情况下, 让然能够保证”可用性”, 即一定时间内然然能返回一个明确的结果.只不过”基本可用”和”高可用”的区别是: “一定时间”可以适当延长,当举行大促时, 响应时间可以适当延长. 给部分用户返回一个降级页面, 给部分用户直接返回一个降级页面, 从而缓解服务器压力. 但要注意的是: 返回降级页面仍然是返回明确结果. S:Soft State: 柔性状态,同一数据的不同副本的状态, 可以不需要实时一致. E:Eventual Consisstency: 最终一致性, 同一数据的不同副本状态, 可以不需要实时一致, 但一定要保证经过一段时间后仍然是一致的. 2. 分布式事务常见解决方案2.1 最大努力通知方案 2.2 TCC 两阶段补偿方案TCC 是Try-Confirm-Cance, 比如在支付场景中,先冻结一部分资金,再去发起支付. 如果支付成功,则将冻结的资金进行实时扣除, 如果支付失败, 则取消资金冻结. ​ 2.2.1 Try阶段完成所以业务检查(一致性),预留业务资源(准隔离性) 2.2.2Confirm阶段确认执行业务操作, 不做任何业务检查, 只使用try 阶段预留的业务资源. 2.2.3 Cancel阶段取消try 阶段预留的业务资源, Try出现出现阶段时, 取消所有业务资源预留请求. 2.3 关于状态机在使用最终一致性的方案时, 一定要提到的一个概念就是状态机. ​ 什么是状态机? 是一种特殊的组织代码的方式, 用这种方式能够确保你的对象随时都直到自己所处的状态以及能够做的操作。它也是一种用来进行对象行为建模的工具, 用于描述对象在他的生命周期内所经历的状态序列, 以及如何响应来自外界的各种事件. ​ 状态机这个概念大家都不陌生, 比如TCP 协议的状态机. 同时我们在编写相关业务逻辑的时候经常也会需要处理各种事件和状态的切换, 比如swith、if/else . 所以我们其实一致都在跟状态机打交道,只是可能都没有意识到而已. 在处理一些业务逻辑比较复杂的需求的时候, 可以先看看是否适用于一个有限状态机来描述, 如果可以把业务模型抽象成一个有限的状态机, 那么代码就会逻辑非常清晰, 结构特别规整. ​ 比如我们来简单描述一个订单. ​ 我们以支付为例, 一笔订单可能会有等待支付、支付中、已支付状态, 那么我们就可以先去把可能出现的状态以及状态的流程画出来。 状态机的两个作用: 实现幂等 通过状态驱动数据的变化 业务流程以及逻辑更加清晰, 特别是应对复杂的业务场景. 3. 什么是幂等 简单来说, 重复调用多次产生的业务结果与调用一次产生的业务结果相同; 在分布式架构中, 我们调用一个远程服务去完成一个操作, 除了成功和我失败以外, 还有未知状态, 那么针对这个未知状态, 我们会采用一些重试的行为. 或者在消息中间件的使用场景中, 消费者可能会重复收到消息. 对于这两种情况, 消费端或者服务端需要采取一定的手段, 也就是考虑到重发的情况下保证数据的安全性.我们一般常用的手段： 状态机实现幂等 数据库唯一约束实现幂等 通过tokenId 的方式去识别每次请求判断是否重复. 4. 开源的分布式事务解决方案4.1 TransactionProducer（事务消息）RocketMQ 和其他消息中间件最大的一个区别就是支持了事务消息, 这也是分布式事务中基于消息的最终一致性方案. 4.2 RocketMQ 消息的事务架构设计 生产者执行本地事务, 修改订单支付状态, 并且提交事务 生产者发送事务消息到broker上, 消息发送到broker 上在没有确认之前, 消息对于consumer 是 不可见的状态. 生产者确认事务消息, 使得发送到broker上的事务消息对于消费者可见. 消费者获取到消息进行消费,消费完之后执行ack 进行确认. 这里可能会存在一个问题 , 生产者本地事务成功后,发送事务确认消息到broker 上失败了怎么办? 这个时候意味着消费者无法正常消费到这个消息, 所以RocketMQ 提供了消息回查机制, 如果事务消息一直处于中间状态,broker 会发起重试去查询broker 上这个事务的处理状态。一旦发送事务处理成功, 则把这条消息设置为可见. 4.3 事务消息的实践通过一个下单以后扣减库存的数据一致性场景来演示RocketMQ的分布式事务特性. TransactionProducer package com.mq; import org.apache.rocketmq.client.exception.MQClientException; import org.apache.rocketmq.client.producer.TransactionMQProducer; import org.apache.rocketmq.common.message.Message; import org.apache.rocketmq.remoting.common.RemotingHelper; import java.io.UnsupportedEncodingException; import java.util.UUID; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; /** * @author luyanan * @since 2020/1/16 * &lt;p>事务生产者&lt;/p> **/ public class TransactionProducer &amp;#123; public static void main(String[] args) throws MQClientException, UnsupportedEncodingException, InterruptedException &amp;#123; TransactionMQProducer producer = new TransactionMQProducer(\"tx_producer_group\"); producer.setNamesrvAddr(\"192.168.86.128:9876\"); // 自定义线程池 ExecutorService executorService = Executors.newFixedThreadPool(10); producer.setExecutorService(executorService); producer.setTransactionListener(new TransactionListenerLocal()); producer.start(); for (int i = 0; i &lt; 20; i++) &amp;#123; String orderId = UUID.randomUUID().toString(); String body = \"&amp;#123;'operation':'doOrder','orderId':'\" + orderId + \"'&amp;#125;\"; Message message = new Message(\"ex_topic\", \"TagA\", orderId, body.getBytes(RemotingHelper.DEFAULT_CHARSET)); producer.sendMessageInTransaction(message, orderId + \"&amp;\" + i); Thread.sleep(1000); &amp;#125; &amp;#125; &amp;#125; TransactionListenerLocal package com.mq; import org.apache.rocketmq.client.producer.LocalTransactionState; import org.apache.rocketmq.client.producer.TransactionListener; import org.apache.rocketmq.common.message.Message; import org.apache.rocketmq.common.message.MessageExt; import java.util.HashMap; import java.util.Map; import java.util.concurrent.ConcurrentHashMap; /** * @author luyanan * @since 2020/1/16 * &lt;p>&lt;/p> **/ public class TransactionListenerLocal implements TransactionListener &amp;#123; private static final Map&lt;String, Boolean> results = new ConcurrentHashMap&lt;>(); /** * &lt;p>执行本地事务&lt;/p> * * @param message * @param o * @return &amp;#123;@link LocalTransactionState&amp;#125; * @author luyanan * @since 2020/1/16 */ @Override public LocalTransactionState executeLocalTransaction(Message message, Object o) &amp;#123; System.out.println(\"执行本地事务:\" + o.toString()); String orderId = o.toString(); //模拟插入数据库操作 boolean rs = saveOrder(orderId); //这个返回状态表示broker 这个事务消息是否被确认,允许给到consumer 进行消费 // LocalTransactionState.ROLLBACK_MESSAGE 回滚 // LocalTransactionState.UNKNOW 未知 return rs ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.UNKNOW; &amp;#125; private boolean saveOrder(String orderId) &amp;#123; // 如果订单取模等于0, 表示成功, 否则失败 boolean success = Math.abs(orderId.hashCode()) % 2 == 0; results.put(orderId, success); return success; &amp;#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt messageExt) &amp;#123; String orderId = messageExt.getKeys(); System.out.println(\"执行事务执行状态的回查:orderId:\" + orderId); boolean rs = Boolean.TRUE.equals(results.get(orderId)); System.out.println(\"回调：\" + rs); return rs ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; &amp;#125; &amp;#125; 消费者 TransactionConsumer package com.mq; import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; import org.apache.rocketmq.client.exception.MQClientException; import org.apache.rocketmq.common.consumer.ConsumeFromWhere; import org.apache.rocketmq.common.message.Message; import org.apache.rocketmq.common.message.MessageExt; import org.apache.rocketmq.remoting.common.RemotingHelper; import java.io.IOException; import java.io.UnsupportedEncodingException; import java.util.List; /** * @author luyanan * @since 2020/1/16 * &lt;p>事务 消费者&lt;/p> **/ public class TransactionConsumer &amp;#123; public static void main(String[] args) throws MQClientException, IOException &amp;#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"tx_consumer_group\"); consumer.setNamesrvAddr(\"192.168.86.128:9876\"); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(\"ex_topic\", \"\"); consumer.registerMessageListener(new MessageListenerConcurrently() &amp;#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt> list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &amp;#123; list.stream().forEach(messageExt -> &amp;#123; String orderId = messageExt.getKeys(); String body = null; try &amp;#123; body = new String(messageExt.getBody(), RemotingHelper.DEFAULT_CHARSET); &amp;#125; catch (UnsupportedEncodingException e) &amp;#123; e.printStackTrace(); &amp;#125; System.out.println(\"收到消息:\" + body + \"->开始扣钱库存:\" + orderId); &amp;#125;); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &amp;#125; &amp;#125;); consumer.start(); System.in.read(); &amp;#125; &amp;#125; 4.4 RocketMQ 事务消息的三种状态 ROLLBACK_MESSAGE: 回滚事务 COMMIT_MESSAGE: 提交事务 UNKNOW: broker 会定时的回查producer 消息状态,知道彻底成功或者失败. 当 com.mq.TransactionListenerLocal#executeLocalTransaction 方法返回ROLLBACK_MESSAGE的时候, 表示直接回滚事务, 当返回 COMMIT_MESSAGE的时候直接提交事务. 当返回UNKNOW的时候,broker 会在一段时间之后查com.mq.TransactionListenerLocal#checkLocalTransaction, 根据com.mq.TransactionListenerLocal#checkLocalTransaction 返回状态执行事务的操作(提交或者回滚) ​ 如示例中,当返回ROLLBACK_MESSAGE 时消费者不会收到消息, 且不会调用回查函数, 当返回COMMIT_MESSAGE 时事务提交,消费者收到消息. 当返回UNKNOW的时候, 在一段时间之后调用回查函数, 并根据state 判断返回提交或者回滚状态,返回提交状态的消息将会被消费者消费, 所以此时消费者可以消费部分消息. 5. 消息的存储和发送​ 由于分布式消息队列对于可靠性的要求比较高, 所以需要保证生产者将消息发送到broker 之后, 保证消息是不会丢失的,因此消息队列就少不了对于可靠性存储的要求. 5.1 MQ消息存储选择​ 从主流的几种MQ 消息队列采用的存储方式来看, 主要会有几种: 分布式KV存储, 比如使用ActiviteMQ中采用的LebelDB、Redis, 这种存储方式对于消息读写能力要求不高的情况下可以使用. 文件系统存储, 常见的比如 kafka、RocketMQ、RabbitMQ 都是采用消息刷盘到所部署的机器上的文件系统来做持久化, 这种方案适用于对于有高吞吐量要求的消息中间件, 因为消息刷盘是一种高效率、高可靠、高性能的持久化方式, 除非磁盘出现故障, 否则一般是不会出现无法持久化问题的. 关系型数据库,比如ActiviteMQ 可以采用Mysql 作为消息存储,关系型数据库在单表数量达到千万级的情况下IO性能会出现瓶颈, 所以ActiviteMQ 并不适用于高吞吐量的消息队列场景. 5.2 消息的存储结构​ RocketMQ 就是采用文件系统的方式来存储消息, 消息的存储是由ConsumeQueue和CommitLog 配合完成的. CommitLog 是消息真正的物理存储文件。 ConsumeQueue 是消息的逻辑队列, 有点类似于数据库的索引文件, 里面存储的是指向CommitLog 文件中消息存储的地址. ​ 每个Topic 下的每个Message Queue都会对应一个ConsumerQueue 文件,文件的地址是$&#123;store_home&#125;/consumequeue/$&#123;topicNmae&#125;/$&#123;queueId&#125;/$&#123;filename&#125;,, 默认路径是/root/store. 在rocketMQ的文件存储目录下, 可以看到这样一个结构的文件 我们只需要关心Commitlog、Consumerqueue、Index 5.2.1 Commitlogcommitlog是用来存放消息的物理文件, 每个broker 上的commitlog文件是当前机器上的所有consumerqueue 共享, 不做任何区分. ​ commitlog中的文件默认大小为1G，可以动态配置; 当一个文件写满以后, 会生成一个新的commitlog文件. 所有的topic 数据是顺序写入在commitlog 文件中的. 文件名的长度为20位, 左边补零, 剩余末起始偏移量,比如00000000000000000000 表示第一个文件， 文件大小为102410241024，当第一个文件写满之后，生 成第二个文件 000000000001073741824 表示第二个文件，起始偏移量为1073741824 00000000000000000000 表示第一个文件， 文件大小为102410241024，当第一个文件写满之后，生 成第二个文件 000000000001073741824 表示第二个文件，起始偏移量为1073741824 5.2.2 consumeQueueconsumeQueue 表示消息 消费的逻辑队列, 这里面包含messageQueue在commitlog 中的真实物理地址偏移量ooffst,消息实体内容的大小和Message Tag的hash值。 对于实际物理存储来说, consumerQueue 对应每个topic 和queueid下的文件, 每个consumerqueue类型的文件也是有带大小的,每个文件默认大小为6000W字节,如果文件满了之后也会生成一个新的文件. 5.2.3 IndexFile​ 索引文件, 如果一个消息包含key值的话 ,会使用indexFile存储消息索引.Index 索引文件提交了对Commitlog 进行数据检索, 提供了一种通过key 或者时间区间来查找commitlog 中的消息的方法. 在物理存储中, 文件名是以创建的时间戳命名的, 固定的单个indexFile 大小大概为400M,一个indexFile 可以保存2000W个索引. 5.2.4 abort​ broker 就会在启动的时候创建一个名为abort的文件,并在shutdown的时候将其删除,用于标识进程是否正常退出,如果不是正常退出, 会在启动的时候做故障恢复. 5.3 消息存储的消息结构 ​ RrokerMQ 的消息存储采用的是混合型的存储结构, 也就是broker 单个实例下的所有队列公用一个日志数据文件connitlog. 这个是和kafka 的又一不同之处. ​ 为什么不采用kafka 的设计, 针对不同的partition存储一个独立的物理文件呢? 这是因为在kafka的设计中, 一旦kafka 中Topic的的partition数量过多, 队列文件会过多, 那么会给磁盘的IO读写造成比较大的压力, 也就造成了性能瓶颈. 所以RocketMQ 进行了优化, 消息主题统一存储在commitlog中. 当然, 这种设计并不是银弹, 也是有他的优缺点: 优点: 由于消息主题都是通过commitlog 进行读写, comsumerQueue 中只存储了很少的数据, 所以队列更加的轻量化, 对于磁盘的访问是串行化从而避免了磁盘的竞争. 缺点: 消息写入磁盘虽然是基于顺序读写, 但是读的过程是随机的,读取一条消息会先读取consumerQueue , 在读commitlog, 会降低消息读的效率. 5.4 消息发送到消息接收的整体流程 Producer 将消息发送到Broker 后, Broker 会采用同步或者异步的方式把消息写入到commitlog,RocketMQ 所有的消息都会存放在commitlog中, 为了保证消息存储不发生混乱, 对commitlog 写之前会加锁, 同时也可以使得消息能够被顺序写入到commitlog, 只要消息被持久化到磁盘文件commitlog,那么就可以保证producer 发送的消息不会丢失. commitlog持久化后, 会把里面的消息Dispatch到对应的consumer queue上, consumer queue 相当于kafka 的partition, 是一个逻辑队列, 存储了这个queue 在commitlog 中的其实offset、log大小和MessageTag的hashCode. 当消费者进行消息消费时,会先读取consumerQueue,逻辑消费队列consumerQueue 保存了指定topic 下的队列消息在consumerLog 中的起始物理偏移量offset、消息大小、和消息tag HashCode值. 直接从consumerqueue 中读取消息是没有数据的, 真正的消息主题是在consumerlog中, 所以换需要从consumerlog 中读取消息. 6. 什么时候清理物理消息文件那消息文件到底删不删? 什么时候删除呢? ​ 消息存储在commitlog之后, 的确是会被清理的,但是这个清理只会在以下任一条件成立后才会批量删除消息文件(comitlog) 消息文件过期(默认72个小时),且到达清理时点(默认是凌晨4点),删除过期文件. 消息文件过期(默认72个小时),且磁盘空间达到了水位线(默认75%), 删除过期文件 磁盘已经达到了必须释放的上限(85%水位线)的时候, 则开始批量清理文件(无论是否过期), 直到空间充足. 注意： 若磁盘空间达到危险水位线(90%), 处于保护自身的目的, broker 会拒绝写入服务.","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/"},{"name":"微服务","slug":"RocketMQ/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"RocketMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"RocketMQ","slug":"RocketMQ/微服务/微服务/RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/RocketMQ/"}],"tags":[]},{"title":"线程安全性的原理分析(3)","slug":"并发编程/线程安全性的原理分析(3)","date":"2022-01-04T02:42:07.277Z","updated":"2022-01-04T02:42:07.277Z","comments":true,"path":"2022/01/04/bing-fa-bian-cheng/xian-cheng-an-quan-xing-de-yuan-li-fen-xi-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/bing-fa-bian-cheng/xian-cheng-an-quan-xing-de-yuan-li-fen-xi-3/","excerpt":"","text":"3. 线程的安全性的原理分析 初始volatile一段代码引发的思考下面这段代码,演示了一个使用volatile 以及没使用volatile 这几个关键字,对于变量更新的影响 package com.notes.concurrent.synchronizeds; /** * @author luyanan * @since 2019/7/20 * &lt;p&gt;演示volatile关键字的demo&lt;/p&gt; **/ public class VolatileDemo &#123; public static boolean stop1 = false; public static volatile boolean stop2 = false; public static void main(String[] args) &#123; VolatileDemo volatileDemo = new VolatileDemo(); try &#123; volatileDemo.demo1(); // volatileDemo.demo2(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void demo1() throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; int i = 0; while (!stop1) &#123; i++; &#125; &#125;, &quot;thread1&quot;); thread.start(); System.out.println(&quot;start Thread 1&quot;); Thread.sleep(1000); stop1 = true; &#125; public void demo2() throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; int i = 0; while (!stop2) &#123; i++; &#125; &#125;, &quot;thread2&quot;); thread.start(); System.out.println(&quot;start Thread 2&quot;); Thread.sleep(1000); stop2 = true; &#125; &#125; 当调用demo1方法的时候 程序输出start Thread1 但是未停止,说明stop1=true的修改没有可见于线程1 当调用demo2方法的时候 程序输出start Thread2,而且停止,说明stop2=true的修改可见于线程2 volatile的作用volatile 可以使得在多处理环境下保证了共享变量的可见性,那么到底什么是可见性呢? 不知道大家有没有思考过这个问题? 在单线程的环境下,如果向一个变量先写入一个值,然后在没有写干涉的情况下读取这个变量的值,那这个时候读取到的这个变量的值应该是之前写入的那个值.这本来是一个很正常的事情.但是在多线程的环境下,读和写发生在不同的线程中的时候,可能会出现:读线程不能及时的读取到其他线程写入的最新的值.这就是所谓的可见性. 为了实现跨线程写入的内存可见性问题,必须使用到一些机制来实现.而volatile 就是这样一种机制. vloatile 关键字是如何保证可见性的?我们可以使用[hsdis] 这个工具来查看前面演示的这段代码的汇编指令,在运行的代码中,设置JVM的参数如下 -server -Xcomp -XX:+UnlockDiagnosticVMOptions - XX:+PrintAssembly - XX:CompileCommand=compileonly,*App.*（替换成实际 运行的代码） 然后在输出的结果中,查找一下lock 指令会发现在修改带有 vloatile 修饰的成员变量的时候,会多一个Lock 指令.lock是一种控制指令,在多处理器环境下,lock汇编指令可以基于总线锁或者缓存所的机制来达到可见性的一个效果. 为了让大家更好的理解了可见性的本质,我们需要从硬件层面进行梳理 从硬件层间了解可见性的本质一台计算机中最核心的组件的CPU,内存以及I/O设备.在整个计算机的发展里程中,除了CPU,内存以及I/O设备不断迭代升级来提升计算机处理性能之外,还有一个非常核心的矛盾点,就是这三者在处理速度的差异.CPU的计算速度是非常快的,内存次之,最后是IO设备比如磁盘.而在绝大部分的程序中,一定会存在内存访问,有些可能还会存在I/O设备的访问. 为了提升计算机性能,CPU从单核升级到了多核,甚至用了超线程技术最大化的提升CPU的处理性能,但是仅仅提升CPU的性能还不够,如果后面两者的处理性能没有跟上,意味着整体的计算效率取决于最慢的设备.为了平衡三者的速度差异,最大化的利用CPU提升性能,从硬件,操作系统,编译器等方面都做出了很多的优化. CPU 增加了高速缓存. 操作系统增加了进程,线程.通过CPU的时间片切换最大化的提升CPU的使用率. 编译器的指令优化,更合理的去利用好CPU的高速缓存. 每一种优化都会带来相应的问题,然而这些问题也是导致线程安全性的问题的根源,为了了解前面提到的可见性问题的本质,我们有必要去了解一下这些优化的过程。 CPU 高速缓存线程是CPU调度的最小单元,线程设计的目的最终仍然是更充分的利用计算机处理的效能,但是绝大部分的运算任务不能只依靠计算就能完成,处理器还需要与内存交互,比如读取运算出具,存储运算结果,这个I/O操作是很难消除的.而由于计算机的存储设备与计算器的运算差距是非常大,所以现代计算机系统都会增加一层读写速度尽可能接近处理器运算速递的高速缓存来作为内存和处理器之间的缓存:将运算需要使用的数据复制到缓存中,让运算能够快速进行,当运算结束后再从缓存同步到内存之中. 通过高速缓存的存储交互很好的解决了处理器和内存的速度矛盾,但是也为计算机系统带来了更高的复杂性,因为他引入了一个新的问题,缓存一致性. 什么叫缓存一致性首先,有了高速缓存的存在之后,每个CPU的处理过程是先将计算机需要用到的数据缓存在CPU的高速缓存中,在CPU进行计算时,直接从高速缓存中读取数据并且在计算完成之后写入到缓存中.在整个运算过程完成后,再把缓存中的数据同步到主内存. 由于在多CPU中,每个线程可能会运行在不同的CPU内,并且每个线程拥有自己的高速缓存.同一份数据都可能会被缓存在多个CPU中,如果在不同的CPU中运行的不同线程看到同一份内存的缓存值不一样就会存在缓存不一致的问题 为了解决缓存不一致的问题,在CPU层面做了很多事情,主要提供了两种解决方案 总线锁 缓存锁 总线锁和缓存锁总线锁,简单来说就是在多CPU下,当其中一个处理器要对共享内存进行操作的时候,在总线上发出一个LOCK# 信号,这个信号使得其他处理器无法通过总线来访问到共享内存中的数据,总线锁把CPU和内存之间的通信锁住了,这使得锁定期间,其他处理器不能操作其他内存地址的数据,所以总线锁定的开销比较大,这种机制显然是不合适的. 如何优化呢? 最好的方法就是控制锁的保护粒度,我们只要保证对于被多个CPU缓存是同一份数据是一致的就行.所以引入了缓存锁,它核心机制是基于缓存一致性协议来实现的. 缓存一致性协议为了达到数据访问的一致性,需要各个处理器在访问缓存时遵循一些协议,在读写时根据协议来进行操作,常见的协议有MSI,MESI,MOSI等. 最常见的就是MESI协议.接下来给大家简单讲解一下 MESI。 MESI表示缓存行的四种状态,分别是: M(Medify)表示共享数据只缓存在当前CPU缓存中,并且是被修改状态,也就是缓存的数据和主内存中的数据不一致. E(Exclusive)表示缓存的独占状态,数据只缓存在当前CPU缓存中,并且没有被修改. S(Shared)表示数据可能被多个CPU缓存,并且各个缓存中的数据和主内存数据一致. I(Invalid) 表示缓存已经失效 在MESI协议中,每个缓存的缓存控制器不仅知道自己的读写操作,而且也监听(snoop)其他Cache的读写操作. 使用MESI协议,从CPU的读写角度来说会遵循以下原则: CPU读请求:缓存处在M,E,S状态都可以被读取,I状态CPU只能从主内存中读取数据 CPU写请求: 缓存处在M,E状态才可以被写.对于S 状态的写,需要将其他CPU中缓存行置为无效才可写. 使用总线锁和缓存锁机制之后,CPU对于内存的操作大概可以抽象成下面这样的结果,从而达到缓存一致性的效果。 总结可见性的本质由于CPU高速缓存的出现使得如果多个CPU同时缓存了相同的共享数据时,可能存在可见性的问题.也就是CPU0修改了自己的本地缓存的值对于CPU1不可见.不可见导致的后果是CPU1后续在对该数据进行写入操作的时候,是使用的脏数据,使得数据最终的结果不可预测. 很多同学肯定希望想在代码中模拟一下可见性的问题i，实际上,这种情况很难进行模拟.因为我们无法让某个线程指定某个CPU,这是系统底层的算法,JVM应该也是无法控制点. 还有最重要的一点就是无法玉泽CPU缓存什么时候会把值传给主内存,可能这个时间间隔非常短,短到你无法观察到. 最后就是线程的执行的顺序问题,因为多线程你无法控制哪个线程的某句代码会在哪一个线程的某句代码后面马上执行, 所以我们只能基于它的原理去了解这样一个存在的客观事实. 了解到这里,大家应该会有一个疑问？ 刚刚不是说基于缓存一致性协议或者总线锁能够达到缓存一致性的要求吗? 为什么还需要加volatile关键字呢? 或者说为什么还会存在可见性的问题呢? MESI优化带来的可见性问题MESI协议虽然可以实现缓存的一致性问题, 但是也会存在一些问题. 就是各个CPU缓存行的状态是通过消息传递来进行的.如果CPU0要对一个在缓存中共享的变量进行写入,首先需要发送一个失效的消息给到其他缓存了该数据的CPU.并且要等到他们的确认回执.CPU0这段时间都会处于阻塞状态.为了避免阻塞带来的资源浪费,在CPU中引入了store bufferes. CPU0只需要在写入共享数据的时候直接把数据写入到store bufferes中,同时发送invalidata 消息,然后继续去处理其他指令. 当收到其他所有CPU发送的 invalidate acknowledge消息的时候,再将store bufferes 中的数据存储至 cache line 中,最后再从缓存行同步到主内存. 但是这种优化存在两个问题: 数据说明时候提交是不准确的,因为需要等待其他cpu给回复才会进行数据同步.这里其实是一个异步操作. 引入了store bufferes 后,处理器会先从storebufferes中读取到值,如果storebufferes中有数据,则直接从storebuffrresz中读取,否则就再从缓存行中读取. 我们来看一个例子 value = 3; void exeToCPU0()&#123; value = 10; isFinish = true; &#125; void exeToCPU1()&#123; if(isFinish)&#123; assert value = 10; &#125; &#125; exeToCPU0 和exeToCPU1分别在两个独立的CPU上执行.例如CPU0的缓存行中缓存了isFinish这个共享变量,并且状态为(E),而value 可能是(S)状态. 那么这个时候,CPU0在执行的时候,会先把value = 10 的指令写入到storebufferes 中,并且通知给其他缓存了改value变量的CPU.在等待其他CPU通知结果的时候,CPU0会继续执行isFinish=true 这个指令. 而因为当前CPU0缓存了isFinish 并且是Exclusive 这个状态,所以可以直接修改isFinish = true. 这个时候CPU1 发起read 操作去读取 isFinish 的值可能是true,但是value的值不等于10; 这种情况我们可以认为是CPU 的乱序执行,也可以认为是一种重排序,而这种重排序会带来可见性的问题. 这下硬件工程师也抓狂了,我们也能理解,从硬件层面上很难去知道软件层面上的这种前后依赖关系,所以没有办法通过某种手段自动的去解决. 所有硬件工程师就在CPU层面上提供了memory barrier(内存屏障)的指令,从硬件层面上看这个 memory barrier 就是CPU flush store buffer 中的 指令,软件层面可以决定在适当的地方插入内存屏障. CPU层面的内存屏障什么是内存屏障?从前面的内容基本能有一个初步的猜想,内存屏障就是将store bufferes中的指令写入到内存中,从而使得其他访问同一共享内存的线程的可见性. X86的 memory barrier 指令 包括 lfence(读屏障),sfence(写屏障),mfence(全屏障) Store Memory Barrier(写屏障) 告诉处理器在写屏障之前的所有已经存储在存储缓存(store bufferes)中 的数据同步到主内存,简单来说就是使得写屏障之前的指令的结果对屏障之后的读或者写是可见的. Load Memory Barrier(读屏障) 处理器在读屏障之后的读操作,都在读屏障之后执行.配合写屏障,使得写屏障之前的内存更新对于读屏障之后的读操作是可见的. Full Memory Barrier(全屏障)确保屏障前的内存读写操作的结果提交到内存之后,再执行屏障后的读写操作. 有了内存屏障之后,对于上面的例子,我们可以这么来改,从而避免出现可见性的问题。 value = 3; void exeToCPU0()&#123; value = 10; // 这是一个伪代码,插入一个写屏障,是的value =10 这个值强制性的插入到主内存 storeMemoryBarrier(); isFinish = true; &#125; void exeToCPU1()&#123; if(isFinish)&#123; // 这是一个伪代码,插入一个读屏障,使得cpu1 从主内存中获取到最新的数据 loadMemoryBarrier(); assert value = 10; &#125; &#125; 总的来说,内存屏障的作用可以通过防止CPU对内存的乱序访问来保证共享数据在多线程b并行执行下的可见性. 但是这个屏障怎么来加呢?回到最开始我们讲到的 volatile 关键字的代码,这个关键字会生成一个Lock的汇编指令,这个指令就相当于实现了一种内存屏障. 这个时候问题又来了,内存屏障,重排序这些东西好像和平台以及硬件架构有关系.作为java语言的特性,一处编写多处运行.我们不应该考虑平台相关的问题,并且这些所谓的内存屏障也不应该让程序员关心. JMM什么是JMMJMM全称是 Java Memory Model.什么是JMM呢?通过前面的分析发现,导致可见性的问题的根本原因是缓存以及重排序. 而JMM实际上j就是提供了合理的j禁用缓存以及 禁止重排序的方法. 所以它最核心的价值在于解决可见性和有序性. JMM属于语言级别的抽象内存模型,可以简单理解为对硬件模型的抽象. 它定义了共享内存中多线程读写操作的行为规范: 在虚拟机中把共享变量存储到内存以及从内存中取出共享变量的底层实现细节. 通过这些规则来规范对内存的读写操作从而保证指令的正确性,它解决了CPU多级缓存、处理器优化、指令重排序导致的内存访问问题,保证了并发场景下的可见性. 需要注意的是,JMM并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令的执行速度,也没有限制编译器对指令进行重排序,也就是说在JMM中,也会存在缓存一致性问题和指令重排序问题.只是JMM把底层的问题抽象到了JMM层面,再基于CPU底层提供的内存屏障指令以及限制编译器的重排序来解决并发问题。 JMM抽象模型分为主内存,工作内存; 主内存是所有线程共享的,一般是实例对象、静态字段、数组对象等存储在堆内存中的变量. 工作内存是每个线程独有的,线程对变量的所有操作都必须在工作内存中进行,不能直接读写主内存中的变量,线程之间的共享变量值的传递都是基于主内存来完成. java内存模型底层实现简单的认为:通过内存屏障(memory barrier) 禁止重排序,即时编译器根据具体的底层体系架构,将这些内存屏障替换成具体的CPU指令.对于编译器而言,内存屏障将限制它能做的重排序优化.而对于处理器而言,内存屏障将d导致缓存的刷新操作.比如,对于volatile,编译器将在volatile字段的读写操作前后各插入一些内存屏障. JMM是如何解决可见性有序性问题的.简单来说,JMM提供了一些禁用缓存以及禁止重排序的方法,来解决了可见性和有序性的问题.这些方法大家都熟悉: volatile,synchronized,final JMM如何解决顺序一致性的问题重排序问题为了提高程序的执行性能,编译器和处理器都会对指令做重排序,其中处理器的重排序在前面已经分析过.所以的重排序其实就是指执行的指令的顺序. 编译器的重排序指的是程序编写的指令在编译之后,指令可能会产生重排序来优化程序的执行性能. 从源代码到最终执行的指令,可能会经过三种重排序 源代码-&gt;1:编译器优化重排序-&gt;2:指令级优化重排序-&gt;3:内存系统重排序-&gt;最终执行的指令序列 2和3属于处理器重排序. 这些重排序可能会导致可见性问题. 编译器的重排序,JMM提供了禁止特定类型的编译器重排序. 处理器重排序,JMM会要求编译器生成指令时,会插入内存屏障来禁止处理器重排序. 当然并不是所有的程序都会出现重排序问题,编译器的重排序和CPU的重排序的原则一样,会遵守数据依赖性原则,编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序,比如下面的代码 a = 1,b = 1; a = 1,b = 2; a = b,b = 1; 这三种情况在单线程里面如果改变代码的执行顺序,就会导致结果不一致,所以重排序不会对这类的指令做优化.这种规则也成为 as-if-serial. 不管怎么重排序,对于单个线程来说执行结果不能改变.比如: int a = 2; // 1 int b = 3; //2 int rs = a * b; //3 1和3 、 2和3 之间存在数据依赖,所以在最终执行的指令中,3 不能重排序到1，2之前,否则程序会报错. 由于1和2不存在数据依赖,所以可以重排序1和2 的顺序. JMM层面的内存屏障.为了保证内存可见性,java编译器在生成指令序列的的适当位置会插入内存屏障来禁止特定类型的处理器的重排序 在JMM中把内存屏障分为四类:| 屏障类型 | 指令示例 | 备注 || —————— | ——————————– | ———————————————————— || LoadLoadBarriers | load1;loadload;load2 | 确保load1数据的装载先于load2以及所有后续装载指令的装载 || StoreStoreBarriers | store1;storestore;store2 | 确保store1数据对其他处理器可见优先于store2以及所有后续存储指令的存储 || LoadStoreBarriers | load1;loadstore;store2 | 确保load1数据装载优先于store2以及后续的存储指令刷新到内存中 || StoreLoadBarriers | store1;storeload;load2 | 确保store1数据对其他处理器变得可见,优先于load2以及后续装载指令的装载,这条内存屏障指令是一个全能型的指令. | HappensBefore它的意思表示的是前一个操作的结果对于后续操作是可见的. 所以它是一种表达多个线程之间对于内存的可见性.所以我们可以认为在JMM中,如果一个操作执行的结果需要对另一个操作可见,那么这两个操作必须要存在happens-before关系,这两个操作可以是同一个线程,也可以是不同的线程. JMM中那些方法会建立happens-before 规则程序顺序规则 一个线程中的每个操作,happens-before于该线程中的任意后续操作,可以简单认为是as-if-serial. 单个线程中的代码顺序不管怎么变,对于结果来说都是不变的,顺序规则表示 1 happens-before; 2,3 happens-before 4 class VolatileExample&#123; int a = 0; volatile boolean flg = false; public void write()&#123; a = 1; //1 flg = true; //2 &#125; public void reader()&#123; if(flg)&#123; // 3 int i = 1; //4 .... &#125; &#125; volatile 变量规则,对于volatile修饰的变量的写操作,一定happens-before 后续对volatile变量的读操作,根据 volatile 规则,2 happens-before 3```class VolatileExample{ int a = 0; volatile boolean flg = false; public void write(){ a = 1; //1 flg = true; //2 }public void reader(){if(flg){ // 3 int i = a; //4.... } } 3. 传递性规则 如果 1 happens-before 2；3 happens -before 4 ;那么传递性规则表示i 1 happens-before 4; class VolatileExample{ int a = 0; volatile boolean flg = false; public void write(){ a = 1; //1 flg = true; //2 &#125; public void reader(){ if(flg){ // 3 int i = a; //4 …. } } 4. start 规则 .如果线程A 执行操作 ThreadB.start(),那么线程A 的ThreadB.start()操作 happens-before 线程B 中的任意操作 public startDemo{ int x = 0; Thread t= new Thread(()-&gt;{ // 主线程调用 t1.satrt() 之前 // 所有对共享变量的修改,此处皆可见 // 此例中,X == 10 &#125;); // 此处对共享变量X 修改 x = 10; // 主线程启动子线程 t1.start(); } 5. join规则,如果线程A 执行操作Thread.join() 并成功返回,那么线程B 中的任意操作 happens-before 于线程A 从ThreadB.join() 操作成功返回, Thread t1 = new Thread(()-&gt;{ // 此处对共享变量x修改 x = 100; });// 例如此处对共享变量修改// 主线程启动子线程t1.satrt();t1.join();//子线程所有对共享变量的修改// 在主线程调用t1.join() 之后皆可见// 此例中, x = 100; 6. 监视器锁的规则,对一个锁的解锁,happens-before 于随后对这个锁的加锁 synchronized(this){ // 此处自动加锁 // x是共享值,初始值是10 if(this.x &lt; 12){ this.x = 12; }}// 此处自动解锁 ```假设x的初始值是10,线程A 执行完代码块之后X的值就会变成12(执行完成后自动释放锁),线程B进入代码块时,能够看到线程A对x的写操作,也就是线程B 能够看到x ==12","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"并发编程的基本认识(1)","slug":"并发编程/并发编程的基本认识(1)","date":"2022-01-04T02:42:07.277Z","updated":"2022-01-04T02:42:07.277Z","comments":true,"path":"2022/01/04/bing-fa-bian-cheng/bing-fa-bian-cheng-de-ji-ben-ren-shi-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/bing-fa-bian-cheng/bing-fa-bian-cheng-de-ji-ben-ren-shi-1/","excerpt":"","text":"1. 并发编程的基本认识 并发的发展历史真空管和穿孔打卡最早的计算机智能解决简单的数据运算问题,比如正弦,余弦等.运行方式: 程序员首先把程序写到纸上,然后穿孔成卡片,再把卡片盒带入到专门的输入室. 输入室也有专门的操作员将卡片的程序输入到计算机上 计算机运行完当前的任务后,把计算结果从打印机上进行输出,操作员再把打印出来的结果送入到输出室 然后,操作员再继续从已经送入到输出室的卡片盒中读入另一个任务重复上述的步骤. 操作员在机房里面来回调度资源,以及计算机同一个时刻只能运行一个程序,在程序输入的过程中,计算机处于空闲状态.而当时的计算机是非常昂贵的,人们为了减少这种资源的浪费,就采用了批处理系统来解决. 晶体管和批处理系统批处理操作系统的运行方式: 在输入室收集全部的作业,然后用一台比较便宜的计算机把他们读取到磁带上. 然后把磁带输入到计算机上,计算机通过读取磁带的指令来进行运算,最后把结果输出到磁带上. 批处理操作系统的好处在于计算机会一直处于运算状态,合理的利用了计算机的资源(运行流程如下图所示) 程序员把卡片拿到1401机 1401机把批处理作业读取到磁带上 操作员把输出磁带送到7094机 7094机进行计算 操作员把输出的磁带送到1401机 1401机打印输出 批处理操作系统虽然能够解决计算机的空闲问题,但是当某一个作业因为等待磁盘或者其他I/O操作而暂停的时候,那么CPU就只能阻塞到该I/O完成,对于CPU操作密集的程序,I/O操作相对较少,因为浪费的时间也很少,但是对于I/O操作较多的场景来说,CPU的资源就是属于严重浪费的. 集成电路和多道程序设计多道程序设计的出现解决了这个问题,就是把内存分为几个部分,每一个部分放不同的程序.当一个程序需要等到I/O操作完成的时候,那么CPU可以切换执行内存的另一个程序,如果内存中可以同时存放足够多的程序,那CPU的利用率就可以接近100%. 在这个时候,引入了第一个概念 进程,进程的本质是一个正在执行的程序,程序运行时系统就会创建一个进程,并且给每个进程分配独立的内存地址空间保证每个进程地址不会相互干扰.同时,在CPU对进程做时间片的切换的时候,保证进程切换过程中仍然要从进程切换之前运行的位置开始执行.所以进程通常还会包括程序计数器,堆栈指针。 有了进程之后,可以让操作系统从宏观层面实现多应用并发,而并发的实现是通过CPU时间片不断的切换执行.对于单核CPU来说,在任意一个时刻只会有一个进程被CPU调度. 线程的出现&lt; 有了进程之后,为什么还会发明线程呢？ 在多核CPU中,利用多线程可以实现真正意义上的并行执行. 在一个应用进程中,会存在多个同时执行的任务,如果其中一个任务被阻塞,将会引起不依赖该任务的任务也被阻塞.通过对不同任务创建不同的线程去处理,可以提高程序处理的实时性. 线程可以认为是轻量级的进程,所以线程的创建,销毁比进程更快.线程的应用如何应用多线程在java中,有多种方式来实现多线层.继承Thread类,实现Runnable接口,使用ExecutorService,Callable,Future实现带返回结果的多线程. 继承Thread 类创建线程.Thread类本质上是实现了Runnable接口的一个实例,代表一个线程的实例.启动线程的唯一的方法就是通过Thread类的start()方法.start()方法是一个native 方法,它会启动一个新的线程,并执行run()方法,这种方式实现多线层很简单,通过自己的类直接extend Thread,并重写run() 方法,就可以启动新线程并执行自己定义的run()方法。 package com.notes.concurrent.thread; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;使用继承Thread的方式实现多线程&lt;/p&gt; **/ public class ThreadDemo extends Thread &#123; @Override public void run() &#123; System.out.println(&quot;我是使用继承Thread的方式实现的多线程&quot;); &#125; public static void main(String[] args) &#123; ThreadDemo threadDemo1 = new ThreadDemo(); threadDemo1.start(); ThreadDemo threadDemo2 = new ThreadDemo(); threadDemo2.start(); &#125; &#125; 我是使用继承Thread的方式实现的多线程 我是使用继承Thread的方式实现的多线程 实现Runnable 接口创建线程如果自己的类已经继承了一个类,就无法直接extends Thread,此时,可以实现一个Runnable接口 package com.notes.concurrent.thread; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;通过实现Runnable接口实现多线程&lt;/p&gt; **/ public class RunnableDemo implements Runnable &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;--通过实现Runnable接口实现多线程&quot;); &#125; public static void main(String[] args) &#123; RunnableDemo runnableDemo1 = new RunnableDemo(); RunnableDemo runnableDemo2 = new RunnableDemo(); new Thread(runnableDemo1,&quot;runnableDemo1&quot;).start(); new Thread(runnableDemo2,&quot;runnableDemo2&quot;).start(); &#125; &#125; runnableDemo1--通过实现Runnable接口实现多线程 runnableDemo2--通过实现Runnable接口实现多线程 实现Callable接口 通过FutureTask包装器来创建Thread线程有的时候,我们可能需要让执行的线程在执行完成之后,提供一个返回值给当前的主线程,主线程需要依赖这个值进行后续的逻辑处理,那么这个时候,就需要用到带返回值的线程了.java中提供了这样的线程机制 package com.notes.concurrent.thread; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;实现Callable接口 通过FutureTask包装器来创建Thread线程&lt;/p&gt; **/ public class CallableDemo implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; int a = 1; int b = 2; return &quot;返回结果:&quot; + (a + b); &#125; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newFixedThreadPool(1); CallableDemo callableDemo = new CallableDemo(); executorService.submit(callableDemo); System.out.println(callableDemo.call()); executorService.shutdown(); &#125; &#125; 返回结果:3 多线程的实际应用场景其实大家在工作中应该很少有场景能够应用多线程,因为基于业务开发来说,很多使用异步的场景我们都通过分布式消息队列来做了.当不是说多线程就不会被用到,如果看一些项目的源码,就会发现线程的使用无处不在. 之前看zookeeper 源码的时候看到一个比较有意思的异步责任链模式 Request package com.notes.concurrent.thread.chain; import lombok.Data; import lombok.ToString; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;&lt;/p&gt; **/ @ToString @Data public class Request &#123; private String name; &#125; RequestProcessor package com.notes.concurrent.thread.chain; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;&lt;/p&gt; **/ @FunctionalInterface public interface RequestProcessor &#123; void processRequest(Request request); &#125; PrintProcessor package com.notes.concurrent.thread.chain; import java.util.concurrent.LinkedBlockingQueue; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;输出执行链&lt;/p&gt; **/ public class PrintProcessor extends Thread implements RequestProcessor &#123; private RequestProcessor nextRequestProcessor; LinkedBlockingQueue&lt;Request&gt; requests = new LinkedBlockingQueue&lt;&gt;(); public PrintProcessor() &#123; &#125; public PrintProcessor(RequestProcessor requestProcessor) &#123; this.nextRequestProcessor = requestProcessor; &#125; @Override public void run() &#123; while (true) &#123; try &#123; Request take = requests.take(); // if(null != nextRequestProcessor)&#123; System.out.println(&quot;PrintProcessor &quot; + take.getName()); nextRequestProcessor.processRequest(take); // &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; @Override public void processRequest(Request request) &#123; requests.add(request); &#125; &#125; SaveProcessor package com.notes.concurrent.thread.chain; import java.util.concurrent.LinkedBlockingQueue; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;输出执行链&lt;/p&gt; **/ public class SaveProcessor extends Thread implements RequestProcessor &#123; private RequestProcessor nextRequestProcessor; LinkedBlockingQueue&lt;Request&gt; requests = new LinkedBlockingQueue&lt;&gt;(); public SaveProcessor() &#123; &#125; public SaveProcessor(RequestProcessor requestProcessor) &#123; this.nextRequestProcessor = requestProcessor; &#125; @Override public void run() &#123; while (true) &#123; try &#123; Request take = requests.take(); System.out.println(&quot;SaveProcessor &quot; + take.getName()); if(null != nextRequestProcessor)&#123; nextRequestProcessor.processRequest(take); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; @Override public void processRequest(Request request) &#123; requests.add(request); &#125; &#125; ChainTest package com.notes.concurrent.thread.chain; /** * @author luyanan * @since 2019/7/11 * &lt;p&gt;&lt;/p&gt; **/ public class ChainTest &#123; public static void main(String[] args) &#123; SaveProcessor saveProcessor = new SaveProcessor(); saveProcessor.start(); PrintProcessor printProcessor = new PrintProcessor(saveProcessor); printProcessor.start(); Request request = new Request(); request.setName(&quot;one&quot;); printProcessor.processRequest(request); &#125; &#125; 结果 PrintProcessor one SaveProcessor one 并发编程的基础基本应用搞清楚后,我们再来基于Java 线程的基础切入来逐步去深入挖掘线程的整体模型. 线程的生命周期java线程既然能够创建,那么也势必会被销毁,所以线程是存在生命周期的,那么我们接下来从线程的生命周期开始去了解线程. 线程一共有6种状态(NEW,RUNNABLE,BLOCKED,WAITING,TIME_WAITING,TERMINATED) NEWNEW:初始状态,线程被构建,但是还没有调用start() 方法 RUNNABLERUNNABLE: 运行状态,JAVA 线程把操作系统中的就绪和运行状态统一称为”运行中” BLOCKEDBLOCKED: 阻塞状态,表示线程进入等待状态,也就是线程因为某种原因放弃了堆CPU使用权,阻塞也分为几种情况: 等待阻塞: 运行的线程执行 wait方法,jvm会把当前的线程放入到等待队列 同步阻塞:运行的线程在获取对象的同步锁的时候,若该同步锁被其他线程锁占用,那么jvm 会把当前的线程放入到锁池中 其他阻塞:运行的线程执行 Thread.sleep() 或者 t.join() 方法,或者发出了I/O请求时,jvm会把当前的线程设置为阻塞状态,当sleep 结束,join 线程终止 ,io处理完毕则线程恢复. TIME_WAITINGTIME_WAITING: 超时等待状态,超时以后自动返回. TERMINATEDTERMINATED:终止状态,表示当前线程执行完毕通过代码演示线程的状态 package com.notes.concurrent.thread; import java.util.concurrent.TimeUnit; /** * @author luyanan * @since 2019/7/12 * &lt;p&gt;线程的状态&lt;/p&gt; **/ public class ThreadStatus &#123; public static void main(String[] args) &#123; // TIME_WAITING new Thread(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, &quot;time_waiting&quot;).start(); // WAITING,线程在hreadStatus 类锁上通过wait 进行等待 new Thread(() -&gt; &#123; while (true) &#123; synchronized (ThreadStatus.class) &#123; try &#123; ThreadStatus.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, &quot;WAITING&quot;).start(); //线程在ThreadStatus 加锁后,不会释放锁 new Thread(new BlockedDemo(),&quot;BlockedDemo_01&quot;).start(); new Thread(new BlockedDemo(),&quot;BlockedDemo_02&quot;).start(); &#125; static class BlockedDemo extends Thread &#123; @Override public void run() &#123; synchronized (BlockedDemo.class) &#123; while (true)&#123; try &#123; TimeUnit.SECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; &#125; 启动一个线程前,最好为这个线程设置线程名称,因为这样在使用 jstack分析程序或者进行问题排查的时候,就会给开发人员提供一些提示. 显示线程的状态 运行该实例,打开终端或者命令提示符,输入”jps”(显示当前所有java进程pid,window用户如果显示找不见此命令,去jdk的bin目录下运行)```$ jps1105612064 Launcher15184 RemoteMavenServer18480 ThreadStatus19328 Jps15028 jar19224 Launcher14444 Launcher2252 WebApplication 2. 根据上一步骤获取的pid,继续输入 jstack pid(jstack是java虚拟机自带的一种堆栈追踪工具.jstack用于打印出给定的java进程ID或者core file 或者远程调试服务器的java堆栈信息) jstack 184802019-07-12 12:58:50Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode): “DestroyJavaVM” #17 prio=5 os_prio=0 tid=0x0000000003143800 nid=0x3284 waiting o n condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE “BlockedDemo_02” #16 prio=5 os_prio=0 tid=0x000000001e780800 nid=0x1c0 waiting f or monitor entry [0x000000001f33f000] java.lang.Thread.State: BLOCKED (on object monitor) at com.notes.concurrent.thread.ThreadStatus$BlockedDemo.run(ThreadStatus .java:52) - waiting to lock &lt;0x000000076bc1ab70&gt; (a java.lang.Class for com.notes. concurrent.thread.ThreadStatus$BlockedDemo) at java.lang.Thread.run(Thread.java:748) “BlockedDemo_01” #14 prio=5 os_prio=0 tid=0x000000001e780000 nid=0x3c74 waiting on condition [0x000000001f23f000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at com.notes.concurrent.thread.ThreadStatus$BlockedDemo.run(ThreadStatus .java:52) - locked &lt;0x000000076bc1ab70&gt; (a java.lang.Class for com.notes.concurren t.thread.ThreadStatus$BlockedDemo) at java.lang.Thread.run(Thread.java:748) “WAITING” #12 prio=5 os_prio=0 tid=0x000000001e77f000 nid=0x19b4 in Object.wait( ) [0x000000001f13f000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x000000076b7b59b0&gt; (a java.lang.Class for com.notes.concu rrent.thread.ThreadStatus) at java.lang.Object.wait(Object.java:502) at com.notes.concurrent.thread.ThreadStatus.lambda$main$1(ThreadStatus.j ava:30) - locked &lt;0x000000076b7b59b0&gt; (a java.lang.Class for com.notes.concurren t.thread.ThreadStatus) at com.notes.concurrent.thread.ThreadStatus$$Lambda$2/381259350.run(Unkn own Source) at java.lang.Thread.run(Thread.java:748) “Service Thread” #10 daemon prio=9 os_prio=0 tid=0x000000001dc7f000 nid=0x1f5c r unnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE “C1 CompilerThread2” #9 daemon prio=9 os_prio=2 tid=0x000000001dc60000 nid=0x89c waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE “C2 CompilerThread1” #8 daemon prio=9 os_prio=2 tid=0x000000001dc07800 nid=0x338 c waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE “C2 CompilerThread0” #7 daemon prio=9 os_prio=2 tid=0x000000001dc04800 nid=0x111 c waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE “Monitor Ctrl-Break” #6 daemon prio=5 os_prio=0 tid=0x000000001dbf2000 nid=0x492 c runnable [0x000000001e23f000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284) at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326) at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178) - locked &lt;0x000000076b8ca230&gt; (a java.io.InputStreamReader) at java.io.InputStreamReader.read(InputStreamReader.java:184) at java.io.BufferedReader.fill(BufferedReader.java:161) at java.io.BufferedReader.readLine(BufferedReader.java:324) - locked &lt;0x000000076b8ca230&gt; (a java.io.InputStreamReader) at java.io.BufferedReader.readLine(BufferedReader.java:389) at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java: 64) “Attach Listener” #5 daemon prio=5 os_prio=2 tid=0x000000001db50800 nid=0x25d8 w aiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE “Signal Dispatcher” #4 daemon prio=9 os_prio=2 tid=0x000000001c7d0000 nid=0x1f64 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE “Finalizer” #3 daemon prio=8 os_prio=1 tid=0x0000000003238800 nid=0x2720 in Obje ct.wait() [0x000000001db3e000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x000000076b608ec8&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x000000076b608ec8&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209) “Reference Handler” #2 daemon prio=10 os_prio=2 tid=0x0000000003233000 nid=0xb28 in Object.wait() [0x000000001da3f000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x000000076b606b68&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x000000076b606b68&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153) “VM Thread” os_prio=2 tid=0x000000001c787000 nid=0x2698 runnable “GC task thread#0 (ParallelGC)” os_prio=0 tid=0x0000000003158800 nid=0x1204 runn able “GC task thread#1 (ParallelGC)” os_prio=0 tid=0x000000000315a000 nid=0x4240 runn able “GC task thread#2 (ParallelGC)” os_prio=0 tid=0x000000000315b800 nid=0x4a78 runn able “GC task thread#3 (ParallelGC)” os_prio=0 tid=0x000000000315d000 nid=0x3378 runn able “VM Periodic Task Thread” os_prio=2 tid=0x000000001dce1000 nid=0x38ac waiting on condition JNI global references: 336 通过上面的分析,我们了解到了线程的生命周期,现在在整个生命周期中并不是固定的处于某个状态,而是随着代码的执行在不同的状态之间进行切换. #### 线程的启动 前面我们通过一些案例演示了线程的启动,也就是调动statr()方法去启动一个线程,当run方法中的代码执行完毕之后,线程的声明周期也将终止.调用start 方法的语义是当前线程告诉JVM,启动调用satrt方法的线层. ##### 线程的启动原理 很多同学最早学习线程的时候会比较疑惑,启动一个线程为什么是调用start()方法,而不是run()方法,这里做一个简单的分析,先简单看一下start()方法的定义 public synchronized void start() { /** * This method is not invoked for the main method thread or “system” * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state “NEW”. */ if (threadStatus != 0) throw new IllegalThreadStateException(); /* Notify the group that this thread is about to be started * so that it can be added to the group&#39;s list of threads * and the group&#39;s unstarted count can be decremented. */ group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125; &#125; private native void start0(); 我们看到调用start()方法实际上是调用一个nactve方法satrt0()来启动一个线程,首先start0()这个方法是在Thread的静态块中注册的,代码如下: publicclass Thread implements Runnable { /* Make sure registerNatives is the first thing does. */ private static native void registerNatives(); static { registerNatives(); } registerNatives的本地方法的定义在文件Thread.c,Thread.c 定义了各个操作系统平台要用到店关于线程的公共数据和操作,一下是Thread.c的全部内容 http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/00cd9dc3c2b5/src/share/native/java/lang/Thread.c /* Copyright (c) 1994, 2003, Oracle and/or its affiliates. All rights reserved. DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER. This code is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License version 2 only, as published by the Free Software Foundation. Oracle designates this particular file as subject to the “Classpath” exception as provided by Oracle in the LICENSE file that accompanied this code. This code is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License version 2 for more details (a copy is included in the LICENSE file that accompanied this code). You should have received a copy of the GNU General Public License version 2 along with this work; if not, write to the Free Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA or visit www.oracle.com if you need additional information or have any questions. / /*- Stuff for dealing with threads. originally in threadruntime.c, Sun Sep 22 12:09:39 1991 / #include “jni.h”#include “jvm.h” #include “java_lang_Thread.h” #define THD “Ljava/lang/Thread;”#define OBJ “Ljava/lang/Object;”#define STE “Ljava/lang/StackTraceElement;” #define ARRAY_LENGTH(a) (sizeof(a)/sizeof(a[0])) static JNINativeMethod methods[] = { {“start0”, “()V”, (void *)&amp;JVM_StartThread}, {“stop0”, “(“ OBJ “)V”, (void *)&amp;JVM_StopThread}, {“isAlive”, “()Z”, (void *)&amp;JVM_IsThreadAlive}, {“suspend0”, “()V”, (void *)&amp;JVM_SuspendThread}, {“resume0”, “()V”, (void *)&amp;JVM_ResumeThread}, {“setPriority0”, “(I)V”, (void *)&amp;JVM_SetThreadPriority}, {“yield”, “()V”, (void *)&amp;JVM_Yield}, {“sleep”, “(J)V”, (void *)&amp;JVM_Sleep}, {“currentThread”, “()” THD, (void *)&amp;JVM_CurrentThread}, {“countStackFrames”, “()I”, (void *)&amp;JVM_CountStackFrames}, {“interrupt0”, “()V”, (void *)&amp;JVM_Interrupt}, {“isInterrupted”, “(Z)Z”, (void *)&amp;JVM_IsInterrupted}, {“holdsLock”, “(“ OBJ “)Z”, (void *)&amp;JVM_HoldsLock}, {“getThreads”, “()[“ THD, (void *)&amp;JVM_GetAllThreads}, {“dumpThreads”, “([“ THD “)[[“ STE, (void *)&amp;JVM_DumpThreads},}; #undef THD#undef OBJ#undef STE JNIEXPORT void JNICALLJava_java_lang_Thread_registerNatives(JNIEnv *env, jclass cls){ (*env)-&gt;RegisterNatives(env, cls, methods, ARRAY_LENGTH(methods));} 从这段代码中可以看出,satrt0()实际上会执行JVM_StartThread方法,这个方法是干啥的呢?从名字上看,似乎是在JVM层面上启动一个线程,如果真的是这样的话,那么在JVM层面,一定会调用java定义的run方法.那么接下来就去找找答案,我们找到 jvm.cpp这个文件,这个文件需要下载 hotspot 的源码才能找见 JVM_ENTRY(void, JVM_StartThread(JNIEnv* env, jobject jthread)) JVMWrapper(“JVM_StartThread”); JavaThread *native_thread = NULL; // We cannot hold the Threads_lock when we throw an exception, // due to rank ordering issues. Example: we might need to grab the // Heap_lock while we construct the exception. bool throw_illegal_thread_state = false; // We must release the Threads_lock before we can post a jvmti event // in Thread::start. { // Ensure that the C++ Thread and OSThread structures aren’t freed before // we operate. MutexLocker mu(Threads_lock); // Since JDK 5 the java.lang.Thread threadStatus is used to prevent // re-starting an already started thread, so we should usually find // that the JavaThread is null. However for a JNI attached thread // there is a small window between the Thread object being created // (with its JavaThread set) and the update to its threadStatus, so we // have to check for this if (java_lang_Thread::thread(JNIHandles::resolve_non_null(jthread)) != NULL) &#123; throw_illegal_thread_state = true; &#125; else &#123; // We could also check the stillborn flag to see if this thread was already stopped, but // for historical reasons we let the thread detect that itself when it starts running jlong size = java_lang_Thread::stackSize(JNIHandles::resolve_non_null(jthread)); // Allocate the C++ Thread structure and create the native thread. The // stack size retrieved from java is signed, but the constructor takes // size_t (an unsigned type), so avoid passing negative values which would // result in really large stacks. size_t sz = size &gt; 0 ? (size_t) size : 0; native_thread = new JavaThread(&amp;thread_entry, sz); // At this point it may be possible that no osthread was created for the // JavaThread due to lack of memory. Check for this situation and throw // an exception if necessary. Eventually we may want to change this so // that we only grab the lock if the thread was created successfully - // then we can also do this check and throw the exception in the // JavaThread constructor. if (native_thread-&gt;osthread() != NULL) &#123; // Note: the current thread is not being used within &quot;prepare&quot;. native_thread-&gt;prepare(jthread); &#125; &#125; } JVM_ENTRY是用来定义 JVM_StartThread 函数的,在这个函数里面创建了一个真正和平台有关的本地线程,我们继续看newJavaThread做了什么事情, 在hotspot的源码中,thread.cpp 文件中的1558行的位置可以找下如下代码 JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) : Thread()#if INCLUDE_ALL_GCS , _satb_mark_queue(&amp;_satb_mark_queue_set), _dirty_card_queue(&amp;_dirty_card_queue_set)#endif // INCLUDE_ALL_GCS{ if (TraceThreadEvents) { tty-&gt;print_cr(“creating thread %p”, this); } initialize(); _jni_attach_state = _not_attaching_via_jni; set_entry_point(entry_point); // Create the native thread itself. // %note runtime_23 os::ThreadType thr_type = os::java_thread; thr_type = entry_point == &amp;compiler_thread_entry ? os::compiler_thread : os::java_thread; os::create_thread(this, thr_type, stack_sz); _safepoint_visible = false; // The _osthread may be NULL here because we ran out of memory (too many threads active). // We need to throw and OutOfMemoryError - however we cannot do this here because the caller // may hold a lock and all locks must be unlocked before throwing the exception (throwing // the exception consists of creating the exception object &amp; initializing it, initialization // will leave the VM via a JavaCall and then all locks must be unlocked). // // The thread is still suspended when we reach here. Thread must be explicit started // by creator! Furthermore, the thread must also explicitly be added to the Threads list // by calling Threads:add. The reason why this is not done here, is because the thread // object must be fully initialized (take a look at JVM_Start)} 这个方法有两个参数,第一个是函数名称,线程创建成功之后会根据这个函数名称调用对用的函数,第二个是当前进程中已经有的线程数量.最后我们重点关注一下os::create_thread,实际上就是调用平台创建线程的方法来创建线程. 接下来就是线程的启动,会调用Thread.cpp文件中的 Thread::start(Thread* thread) 方法,代码如下: void Thread::start(Thread* thread) { trace(“start”, thread); // Start is different from resume in that its safety is guaranteed by context or // being called from a Java method synchronized on the Thread object. if (!DisableStartThread) { if (thread-&gt;is_Java_thread()) { // Initialize the thread state to RUNNABLE before starting this thread. // Can not set it after the thread started because we do not know the // exact thread state at that time. It could be in MONITOR_WAIT or // in SLEEPING or some other state. java_lang_Thread::set_thread_status(((JavaThread*)thread)-&gt;threadObj(), java_lang_Thread::RUNNABLE); } os::start_thread(thread); }} start方法中有一个函数调用,os::start_thread(thread); 调用平台启动线程的方法,最终会调用Thread.cpp文件中的 JavaThread::run()方法 // The first routine called by a new Java threadvoid JavaThread::run() { // initialize thread-local alloc buffer related fields this-&gt;initialize_tlab(); // used to test validitity of stack trace backs this-&gt;record_base_of_stack_pointer(); // Record real stack base and size. this-&gt;record_stack_base_and_size(); // Initialize thread local storage; set before calling MutexLocker this-&gt;initialize_thread_local_storage(); this-&gt;create_stack_guard_pages(); this-&gt;cache_global_variables(); // Thread is now sufficient initialized to be handled by the safepoint code as being // in the VM. Change thread state from _thread_new to _thread_in_vm ThreadStateTransition::transition_and_fence(this, _thread_new, _thread_in_vm); assert(JavaThread::current() == this, “sanity check”); assert(!Thread::current()-&gt;owns_locks(), “sanity check”); DTRACE_THREAD_PROBE(start, this); // This operation might block. We call that after all safepoint checks for a new thread has // been completed. this-&gt;set_active_handles(JNIHandleBlock::allocate_block()); if (JvmtiExport::should_post_thread_life()) { JvmtiExport::post_thread_start(this); } EventThreadStart event; if (event.should_commit()) { event.set_javalangthread(java_lang_Thread::thread_id(this-&gt;threadObj())); event.commit(); } // We call another function to do the rest so we are sure that the stack addresses used // from there will be lower than the stack base just computed thread_main_inner(); // Note, thread is no longer valid at this point!} #### 线程的终止 线程的终止,并不是简单的调用stop命令去,虽然api现在可以调用,但是和其他的线程控制方法如 suppend,resume 一样都是过期了的方法 不建议使用,就拿stop来说,stop方法在结束一个线程的时候并不会保证线程的资源正常释放,因此会导致程序可能会出现一些不确定的状态. 要优雅的去中断一个线程,在线程中提供了一个interrupt 方法 ##### interrupt方法 当其他的线程通过调用当前线程的interrupt 方法,表示向当前线程打个招呼,告诉他可以中断线程的执行,至于什么时候中断,取决于当前线程自己. 线程通过检查自身是否被中断,可以通过isInterrupted() 来判断是否被中断. 通过下面这个例子,来实现线程终止的逻辑 package com.notes.concurrent.thread; import java.util.concurrent.TimeUnit; /** @author luyanan @since 2019/7/12 线程中断演示 */public class InterruptDemo { private static int i; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; //默认情况下isInterrupted返回false,通过thread.interrupt 设置为true while (!Thread.currentThread().isInterrupted()) &#123; i++; &#125; System.out.println(&quot;num:&quot; + i); &#125;); thread.start(); TimeUnit.SECONDS.sleep(1); thread.interrupt(); &#125; } 通过这种标识位或者中断操作的方式能够使线程在终止的时候有机会去清理资源,而不是武断的去将线程停止,因为这种终止线程的方式更加安全和优雅. ##### Thread.interrupted 上面的案例中,通过interrupt 设置了一个标识告诉线程可以终止了,线程中还提供了静态方法Thread.interrupted()对设置中断标识的线程复位.比如在上面的案例中,外面的线程调用thread.interrupt 来设置中断标识,而在线程里面,又通过Thread.interrupted 把线程的标识又进行了复位. package com.notes.concurrent.thread; import java.util.concurrent.TimeUnit; /** @author luyanan @since 2019/7/12 线程复位演示 */public class InterruptedDemo { private static int i; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; while (true) &#123; if (Thread.currentThread().isInterrupted()) &#123; System.out.println(&quot;before:&quot; + Thread.currentThread().isInterrupted()); //对线程进行复位 Thread.interrupted(); System.out.println(&quot;after:&quot; + Thread.currentThread().isInterrupted()); &#125; &#125; &#125;, &quot;Interrupted&quot;); thread.start(); TimeUnit.SECONDS.sleep(1); thread.interrupt(); &#125; } 结果 before:trueafter:false ##### 其他线程的复位 除了可以通过Thread.interruped 方法对线程中断标识进行复位以外,还有一种被动复位的场景,就是抛出InterruptedException 异常,在InterruptedExeception 抛出之前,JVM会先把线程的中断标识进行清除,然后才会抛出InterruptedExeception 异常,这个时候如果调用isIntercepted 方法,将会返回false,分别通过下面两个Demo来演示复位的效果: private static int i; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; while (!Thread.currentThread().isInterrupted())&#123; &#125; &#125;,&quot;InterruptedDemo&quot;); thread.start(); System.out.println(thread.isInterrupted()); thread.interrupt(); System.out.println(thread.isInterrupted()); &#125; 结果 falsetrue Thread thread = new Thread(() -&gt; &#123; while (!Thread.currentThread().isInterrupted()) &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, &quot;InterruptedDemo&quot;); thread.start(); TimeUnit.SECONDS.sleep(1); thread.interrupt(); System.out.println(thread.isInterrupted()); 结果 true ##### 为什么要复位 Thread.interrupeed() 是属于当前线程的,是当前线程对外界中断信号的一个响应,表示自己已经得到了中断的信号,但不会立即中断,具体什么时候中断由自己决定,让外界知道在自身中断前,他的中断状态仍然是false,这就是复位的原因. ##### 线程的终止原理 我们来看一下thread.interrupt() 方法做了什么事情 public void interrupt() { if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0(); &#125; 这个方法里面,调用了interrupt0() 这个方法是一个native 方法,我们找到 jvm.cpp 里面,找到JVM_interrupt 的定义 JVM_ENTRY(void, JVM_Interrupt(JNIEnv* env, jobject jthread)) JVMWrapper(“JVM_Interrupt”); // Ensure that the C++ Thread and OSThread structures aren’t freed before we operate oop java_thread = JNIHandles::resolve_non_null(jthread); MutexLockerEx ml(thread-&gt;threadObj() == java_thread ? NULL : Threads_lock); // We need to re-resolve the java_thread, since a GC might have happened during the // acquire of the lock JavaThread* thr = java_lang_Thread::thread(JNIHandles::resolve_non_null(jthread)); if (thr != NULL) { Thread::interrupt(thr); }JVM_END 这个方法比较简单,直接调用了 Thread::interrupt(thr) 方法,这个方法的定义在 Thread.cpp 文件中,代码如下: void Thread::interrupt(Thread* thread) { trace(“interrupt”, thread); debug_only(check_for_dangling_thread_pointer(thread);) os::interrupt(thread);} &gt; Thread::interrupt() 方法调用了os::interrupt(thread)方法,这个方法是调用平台的interrupt 方法,这个方法的实现是在 os_*.cpp文件中,其中* 代表不同的平台,因为JVM是跨平台的,所以对于不同的操作系统,线程的调度方式都是不一样的,我们以 os_linux.cpp为例 // interrupt support void os::interrupt(Thread* thread) { assert(Thread::current() == thread || Threads_lock-&gt;owned_by_self(), “possibility of dangling Thread pointer”); OSThread* osthread = thread-&gt;osthread(); if (!osthread-&gt;interrupted()) { osthread-&gt;set_interrupted(true); // More than one thread can get here with the same value of osthread, // resulting in multiple notifications. We do, however, want the store // to interrupted() to be visible to other threads before we execute unpark(). OrderAccess::fence(); ParkEvent * const slp = thread-&gt;_SleepEvent ; if (slp != NULL) slp-&gt;unpark() ; } // For JSR166. Unpark even if interrupt status already was set if (thread-&gt;is_Java_thread()) ((JavaThread*)thread)-&gt;parker()-&gt;unpark(); ParkEvent * ev = thread-&gt;_ParkEvent ; if (ev != NULL) ev-&gt;unpark() ; } set_interrupted(true) 实际上是调用了osThread.hpp中的set_interrupted() 方法,在os_Thread中定义了一个成员属性volatile jint _interrupted; 通过上面的代码分析可以知道 thread.interrput() 方式实际上就是设置一个 interrupted 状态标识为true, 并且通过ParkEvent 的unpark()方法来唤醒线程. 1. 对于synchronized 阻塞的线程,被唤醒后会继续尝试获取锁，如果失败仍然可能被park 2. 在调用ParkEvent的park 之前,会先判断线程的中断状态,如果为true,会清除当前线程的中断标识. 3. Object.wait,Thread.sleep,Thread.join 方法会抛出InterruptedExeception 异常. 在这里给大家普及一下为什么Object.wair,Thread.sleep,Thread.join 都会抛出InterrupredException ?你会发现这几个方法都个共同点,都是属于阻塞方法 而阻塞方法的释放会取决于一些外部的事件,但是阻塞方法可能因为等不到外部的触发时间而导致无法终止,所以它允许一个线程请求自己来停止它正在做的事情. 当一个方法抛出InterruptedException 的时候,它是在告诉调用者如果执行该方法的线程被中断,它会尝试正在做的事情,并且抛出InterruptedException 表示提前返回. 所以这个异常的意思是表示一个阻塞被其他线程中断了,然后,由于线程调用了interrupt() 中断方法,那么 Object.wait(),Thread.sleep(),Thread.join() 等被阻塞的线程在被唤醒后会通过 isInterupted() 方法判断中断标识的状态变化,如果发现中断标识为true,则清除中断标识, 然后抛出InterruptedException 需要注意的是,InterruptedException 异常的抛出并不意味着线程必须终止,而是提醒当前线程有中断的操作发生,至于接下来怎么处理,取决于线程本身,比如: 1. 直接捕获异常不做任何处理 2. 将异常往外抛出 3. 停止当前线程,并打印异常信息. 为了让大家更好的理解上面的那段话,我们以Thread.sleep为例,直接从jdk中找到中断标识的清除和异常抛出的方法代码 找到is_interrupted() 方法,linux 平台的中的实现在 os_linux.cpp文件中M代码如下: bool os::is_interrupted(Thread* thread, bool clear_interrupted) { assert(Thread::current() == thread || Threads_lock-&gt;owned_by_self(), “possibility of dangling Thread pointer”); OSThread* osthread = thread-&gt;osthread(); bool interrupted = osthread-&gt;interrupted(); if (interrupted &amp;&amp; clear_interrupted) { osthread-&gt;set_interrupted(false); // consider thread-&gt;_SleepEvent-&gt;reset() … optional optimization } return interrupted;} 找到Thread.sleep 这个操作在jdk中的源码体现怎么找? 代码在 jvm.cpp 文件中 JVM_ENTRY(void, JVM_Sleep(JNIEnv* env, jclass threadClass, jlong millis)) JVMWrapper(“JVM_Sleep”); if (millis &lt; 0) { THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), “timeout value is negative”); } // 判断并清除线程中断状态,如果中断状态为ture,则抛出InterruptedException 异常 if (Thread::is_interrupted (THREAD, true) &amp;&amp; !HAS_PENDING_EXCEPTION) { THROW_MSG(vmSymbols::java_lang_InterruptedException(), “sleep interrupted”); } // Save current thread state and restore it at the end of this block. // And set new thread state to SLEEPING. JavaThreadSleepState jtss(thread); ``` 注意上面加了中文注释的地方的代码,先判断 is_interrupted的状态,然后抛出一个InterruptedException 异常.到此为止,我们就已经分析清除了整个中断的流程.","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"常见的并发工具的使用和原理(5)","slug":"并发编程/常见的并发工具的使用和原理(5)","date":"2022-01-04T02:42:07.273Z","updated":"2022-01-04T02:42:07.273Z","comments":true,"path":"2022/01/04/bing-fa-bian-cheng/chang-jian-de-bing-fa-gong-ju-de-shi-yong-he-yuan-li-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/bing-fa-bian-cheng/chang-jian-de-bing-fa-gong-ju-de-shi-yong-he-yuan-li-5/","excerpt":"","text":"5. 常见的并发工具的使用和原理Condition 在前面学习synchronized 的时候,有讲到 wait/nofity 的基本使用,结合synchronized 可以实现对线程的通信.那么既然J.U.C 里面提供了锁的实现机制,那么J.U.C 里面有没有提供了类似的线程通信的工具呢? 于是发现了Condition 工具类 Condition 是一个多线程协调通信的工具类,可以让某些线程一起等待某个条件(condition),只有满足条件时，线程才会被唤醒. Condition的基本使用condition.wait ConditionWaitDemo package com.notes.concurrent.lock; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; /** * @author luyanan * @since 2019/8/8 * &lt;p&gt;使用condition实现线程wait&lt;/p&gt; **/ public class ConditionWaitDemo implements Runnable &#123; private Lock lock; private Condition condition; public ConditionWaitDemo(Lock lock, Condition condition) &#123; this.lock = lock; this.condition = condition; &#125; @Override public void run() &#123; System.out.println(&quot;ConditionWaitDemo start &quot;); try &#123; lock.lock(); condition.await(); System.out.println(&quot;ConditionWaitDemo end &quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; ConditionSignalDemo package com.notes.concurrent.lock; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; /** * @author luyanan * @since 2019/8/8 * &lt;p&gt;使用condition 实现线程唤醒&lt;/p&gt; **/ public class ConditionSignalDemo implements Runnable &#123; private Lock lock; private Condition condition; public ConditionSignalDemo(Lock lock, Condition condition) &#123; this.lock = lock; this.condition = condition; &#125; @Override public void run() &#123; try &#123; System.out.println(&quot;ConditionSignalDemo start &quot;); lock.lock(); condition.signal(); System.out.println(&quot;ConditionSignalDemo end &quot;); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; 测试类 package com.notes.concurrent.lock; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * @author luyanan * @since 2019/8/8 * &lt;p&gt;测试类&lt;/p&gt; **/ public class ConditionDemo &#123; public static void main(String[] args) &#123; Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); new Thread(new ConditionWaitDemo(lock,condition)).start(); new Thread(new ConditionSignalDemo(lock,condition)).start(); &#125; &#125; 结果 ConditionWaitDemo start ConditionSignalDemo start ConditionSignalDemo end ConditionWaitDemo end 通过这个案例简单实现了wait和 notify的功能, 当调用await 方法之后,当前线程会释放锁并等待,而其他线程调用confition对象的signal或者signalAll 方法通知被阻塞的线程,然后自己执行unlock 释放锁,被唤醒的线程获得之前是锁继续执行,最后释放锁. 所以,condition 中两个最重要的方法,一个是await,一个是 signal. await: 把当前线程阻塞挂起 signal: 唤醒阻塞的线程 Condition 源码分析调用Condition , 需要获得Lock锁,所以意味着会存在一个AQS 同步队列,在上面的案例中,假如两个线程同时运行的话,那么AQS的队列可能是下面四种情况那么这个时候,ThreadA 调用了condition.await() 方法之后,它做了什么事情呢? condition.await调用Condition 的await()方法[或者以await开头的方法],会使得当前线程进入到等待队列并释放锁,同时线程状态变为等待状态.当await()方法返回时,当前线程一定获取了Condition 相关联的锁. public final void await() throws InterruptedException &#123; // 表示await 允许被中断 if (Thread.interrupted()) throw new InterruptedException(); // 创建一个新的节点,节点状态为condition, 采用的数据结构依然为链表, Node node = addConditionWaiter(); // 释放当前的锁,得到锁的状态,并唤醒AQS队列中的一个线程 int savedState = fullyRelease(node); int interruptMode = 0; // 判断这个节点是否在AQS队列中,第一次判断的是false, 因为前面已经是释放过锁了. while (!isOnSyncQueue(node)) &#123; // 通过park 挂起当前线程 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 当这个线程醒来之后,会尝试拿锁,当acquireQueued 返回false 就是拿到锁了 // interruptMode != THROW_IE 表示这个线程没有成功将node 入队,但是signal 执行了enq 方法让其入队了 // 将interruptMode 设置为 REINTERRUPT if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 如果node 的下一个等待着不是null, 则进行清理,清理condition队列上的节点 // 如果是null,则不需要清理 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 如果线程被中断了,需要抛出异常,或者什么都不做. if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; addConditionWaiter这个方法的主要作用是把当前线程封装成Node,添加到等待队列,这里的队列不是双向链表,而是单向链表。 private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. // 如果laseWaiter 不等于空并且waitStatus 不等于CONDITION的时候,把这个节点从链表中移除 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; // 构建一个Node, waitStatus = CONDITION, 这里的链表是一个单向链表，相对于AQS来说会简单很多 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; 图解分析 执行完 addConditionWaiter 这个方法之后,就会产生一个这样的condition 队列 fullyReleasefullyRelease,就是彻底的释放锁,什么叫彻底呢? 就是如果当前锁存在多次重入,那么在这个方法中只需要释放一次,就会把所有的重入次数归零. final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; // 获得重入的次数 int savedState = getState(); // 释放锁并且唤醒下一个同步队列中的线程 if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125; &#125; 图解分析此时,同步队列会出发锁的释放和重新竞争.ThreadB 获得了锁 isOnSyncQueue判断当前节点是否在同步队列中，返回false 则表示不在,返回true 则表示在 如果不在AQS同步队列,说明当前节点没有唤醒去争抢同步锁,所以需要把当前线程阻塞起来,直到其他的线程调用signal 唤醒. 如果在AQS同步队列中,意味着它需要同步锁去获得执行程序执行权限。 为什么要做这个判断呢? 原因是在conditin 队列中的节点会重新加入到AQS队列去竞争锁.也就是调用signal的时候,会把当前节点从condition 队列转移到AQS 队列中. 大家思考一下,基于现在的逻辑结构.如何去判断ThreadA 这个节点是否存在于AQS队列中呢? 如果ThreadA的waitStatus 的状态为CONDITION,说明他存在于condition队列中,不在AQS队列中,因为AQS 队列的状态一定不可能有CONDITION 如果node.prev为空,说明也不存在于AQS队列,原因是prev = null 在AQS队列中只存在一种可能性,就是它是head节点,head节点意味着它是获得锁的节点. 如果node.next 不等于空,说明一定存在于AQS队列中,因为只有AQS队列才会存在next和prev 关系. findNodeFromTail 表示从tail节点往前扫描AQS队列，一旦发现AQS队列的节点与当前节点一样,说明节点一定存在于AQS队列中.```final boolean isOnSyncQueue(Node node) { if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; /* * node.prev can be non-null, but not yet on queue because * the CAS to place it on queue can fail. So we have to * traverse from tail to make sure it actually made it. It * will always be near the tail in calls to this method, and * unless the CAS failed (which is unlikely), it will be * there, so we hardly ever traverse much. */ return findNodeFromTail(node); } #### condition.signal await 方法会阻塞ThreadA, 然后ThreadB 抢占到了锁获得了执行权限,这个时候在ThreadB 中调用了condition.signal()方法,将会唤醒在等待队列中的节点 public final void signal() { // 先判断当前线程是否获得了锁,这个判断比较简单,直接用获得了锁的线程和当前线程进行相对即可. if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 拿到Condition队列上的第一个节点 Node first = firstWaiter; if (first != null) doSignal(first); } ##### doSignal 对 condition 队列中从首部开始的第一个condition状态的节点,执行 transferForSignal 操作,将node 从condition 队列中转换到AQS队列中,同时修改AQS队列中原先队尾 的状态. private void doSignal(Node first) { do { if ( (firstWaiter = first.nextWaiter) == null) // 将next 节点设置为null lastWaiter = null; first.nextWaiter = null; } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); } ##### AQS.transferForSignal 该方法显示CAS 修改了节点状态,如果成功,就将这个节点放到AQS 队列中,然后唤醒这个节点上的线程. 此时,这个节点j就会在await 方法中唤醒. final boolean transferForSignal(Node node) { /* * If cannot change waitStatus, the node has been cancelled. */ // 更新节点的状态为0,如果更新失败,只有一种可能就是节点被CANCELLED 了 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ // 调用enq,把当前节点添加到AQS队列中,b并且返回当前节点的上一个节点,也就是原tail节点 Node p = enq(node); int ws = p.waitStatus; // 如果上一个节点的状态被取消了,或者尝试设置上一个节点的状态为SIGNAL,失败了(SIGNAL 表示它的next节点需要停止阻塞) if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) // 唤醒节点上的线程 LockSupport.unpark(node.thread); // 如果node的prev 节点已经是signal 状态,那么被阻塞的ThreadA 的唤醒工作由AQS 队列来完成 return true; &#125; ###### 图解分析 执行完doSignal 以后,会把condition 队列中的节点转移到AQS 队列中 这个时候会判断ThreadA的prev 节点也就是head节点的waitStatus,如果大于0 或者设置signal 失败,表示节点被设置成了CANCELLED状态.这个时候会唤醒ThreadA 这个线程,否则就基于AQS 队列的机制来唤醒,也就是等到ThreadB 释放锁之后来唤醒ThreadA ##### 被阻塞的线程唤醒后的逻辑 前面在分析 await方法时,线程会被阻塞.而通过signal 被唤醒后又继续回到上次执行的逻辑中被标注为红色部分的代码 checkInterruptWhileWaiting 这个方法是干啥的呢? 其实从名字上就可以看出来,就是ThreadA 在condition 队列被阻塞的过程中,有没有被其他线程触发过中断请求 . public final void await() throws InterruptedException { // 表示await 允许被中断 if (Thread.interrupted()) throw new InterruptedException(); // 创建一个新的节点,节点状态为condition, 采用的数据结构依然为链表, Node node = addConditionWaiter(); // 释放当前的锁,得到锁的状态,并唤醒AQS队列中的一个线程 int savedState = fullyRelease(node); int interruptMode = 0; // 判断这个节点是否在AQS队列中,第一次判断的是false, 因为前面已经是释放过锁了. while (!isOnSyncQueue(node)) { // 通过park 挂起当前线程 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 当这个线程醒来之后,会尝试拿锁,当acquireQueued 返回false 就是拿到锁了 // interruptMode != THROW_IE 表示这个线程没有成功将node 入队,但是signal 执行了enq 方法让其入队了 // 将interruptMode 设置为 REINTERRUPT if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 如果node 的下一个等待着不是null, 则进行清理,清理condition队列上的节点 // 如果是null,则不需要清理 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 如果线程被中断了,需要抛出异常,或者什么都不做. if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } ###### checkInterruptWhileWaiting 如果当前线程被中断,则调用transferAfterCancelledWait 方法判断后续的处理应该是抛出InterruptedException 异常 还是重新中断 这里需要注意的是,如果第一次CAS 失败了,则不能判断当前线程是先进行了中断还是先进行了signal方法的调用,可能是先执行了signal 然后中断,也可能是先执行了中断,后执行了signal。 当然 这两个操作肯定是发生在CAS之前,这时需要做的就是等待当前线程的node被添加到AQS 队列后，也就是enq方法返回后,返回false 告诉 checkInterruptWhileWaiting 方法返回 REINTERRUPT(1), 后续进行重新中断。 简单来说,该方法的返回值代表当前线程是否在park的时候被中断唤醒,如果为true, 表示中断在siganl调用之前,signal 还未执行. 那么这个时候会根据await() 的语义,在await 时遇到中断需要抛出InterruptedException ,返回true 就是告诉checkInterruptWhileWaiting 返回THROW_IE(-1). 如果返回false ,否则表示siganl 已经执行过了,只需要响应中断即可. private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; &#125; final boolean transferAfterCancelledWait(Node node) &#123; // 使用cas 修改节点状态,如果 还能修改成功,说明线程被中断时,signal 还没有被调用 // 这里有一个知识点,就是线程被唤醒,并不一定是在java层面执行了 lockSupport.unpark,也就是调用了线程的interrupt()方法,这个方法 // 会更新一个中断标识,并且会唤醒处于阻塞状态下的线程 if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; // 如果cas成功,则把node添加到AQS队列中 enq(node); return true; &#125; /* * If we lost out to a signal(), then we can&#39;t proceed * until it finishes its enq(). Cancelling during an * incomplete transfer is both rare and transient, so just * spin. */ // 循环检测node是否已经添加到AQS队列中,如果没有,则通过yield while (!isOnSyncQueue(node)) Thread.yield(); return false; &#125; ##### acquireQueued 这个方法在讲AQS的时候说过,是当前被唤醒的节点ThreadA 去抢占锁,并且要恢复到原本的重入次数状态.调用完这个方法之后,AQS队列的状态如下:将head节点的waitStatus 设置为-1 Signal 状态 ##### reportInterruptAfterWait 根据checkInterruptWhileWaiting 方法返回的中断标识来进行中断上报,如果是THROW_IE,则抛出中断异常,如果是REINTERRUPT,则重新响应中断. private void reportInterruptAfterWait(int interruptMode) throws InterruptedException { if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); } ### Condition 总结 #### await 和 signal 的总结 ![](http://files.luyanan.com//img/20190812142913.jpg) 我们把前面的整个分解的图在通过一张整体的结构图来表述,线程awaitThread 先通过lock.lock() 方法 获得锁成功后调用了 condition.await() 方法进入了等待队列中,而另一个线程signalThread通过lock.lock() 方法获得锁成功后调用了condition.signal() 或者signalAll() 方法,使得线程awaitThread 能够有机会移入到同步队列中,当其他线程释放lock 后使得线程 awaitThread 能够有机会获取lock,从而使得线程awaitThread 能够从await 方法中推出执行后续操作.如果awaitThread 获得lock失败会直接进入到同步队列中. **阻塞:** 在await方法中,在线程释放锁资源后,如果节点不在AQS等待队列,则阻塞当前线程,如果在等待队列,则自旋鞥带尝试获得锁. **释放:** signal 后,节点会从condition队列移动到 AQS等待队列,则进入正常锁的获得流程. ## CountDownLatch countDownLatch 是一个同步工具类,它允许一个或者多个线程一直等待,直到其他线程的操作执行完毕再执行.,从命名汇总可以解读到 countdown 是倒数的意思,类似于我们倒计时的概念 countDownLatch 提供了两个方法.一个是 countDown,一个是 await . countDownLatch 在初始化的时候需要传入一个整数,在这个整数倒数到0之前,调用await 方法的线程都必须等待,然后通过countDown 来倒数 package com.notes.concurrent; import java.util.concurrent.CountDownLatch; /** @author luyanan @since 2019/8/12 countDownLatch的demo */public class CountDownLatchDemo { public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(3); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;-&quot; + &quot;执行中&quot;); countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot;-&quot; + &quot;执行完毕&quot;); &#125;,&quot;t1&quot;).start(); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;-&quot; + &quot;执行中&quot;); countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot;-&quot; + &quot;执行完毕&quot;); &#125;,&quot;t2&quot;).start(); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;-&quot; + &quot;执行中&quot;); countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot;-&quot; + &quot;执行完毕&quot;); &#125;,&quot;t3&quot;).start(); countDownLatch.await(); System.out.println(&quot;所有线程执行结束&quot;); } } 结果 t1-执行中t1-执行完毕t2-执行中t3-执行中t3-执行完毕t2-执行完毕所有线程执行结束 从代码的实现上来看,有点类似于join的功能,但是比join 更加的灵活.CountDownLatch 构造函数会接受一个int 类型的参数作为计数器的初始值. 当调用CountDownLatch的 countDown 方法的时候,这个计数器就会减1,通过await方法去阻塞主流程. ##### 模拟高并发 package com.notes.concurrent; import java.util.concurrent.CountDownLatch; /** @author luyanan @since 2019/8/12 使用countDownLatch 模拟高并发 */public class CountDownLatchDemo2 extends Thread { static CountDownLatch countDownLatch = new CountDownLatch(1); @Override public void run() &#123; try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;ThreadName:&quot; + Thread.currentThread().getName()); &#125; public static void main(String[] args) &#123; for (int i = 0; i &lt; 1000; i++) &#123; new CountDownLatchDemo2().start(); &#125; countDownLatch.countDown(); &#125; } 总的来说,凡是涉及到需要指定某个任务执行之前,需要等待前置任务执行完毕之后才执行的场景,都可以使用CountDownLatch #### CountDownLatch的源码分析 ![](http://files.luyanan.com//img/20190812154533.jpg) 对于CountDownLatch ,我们仅仅需要关心两个方法,一个是countDown,另一个是 await()方法。 countDown() 方法每次调用都会将state 减1,知道state 的值为0; 而await方法是一个阻塞方法,当state 减为0的时候,await方法才会返回. await可以被多个线程调用,大家在这个时候脑子里面要有个图: 所有调用了await方法的线程阻塞在AQS队列中,等待条件(state = 0) 满足,将线程从队列中一个个的唤醒过来. ##### acquireSharedInterruptibly countDownLatch 也用到了AQS,在CountDownLatch 内部写了一个Sync 并且继承了AQS这个抽象类重写了AQS中的共享锁的方法. 首先看到下面这个代码,这段代码主要是判断当前线程是否获取到了共享锁;(在CountDownLatch中使用的是共享锁机制,因为在CountDownLatch 中并不需要实现互斥的特性) public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); // state 如果不等于0,说明当前线程需要加入到共享锁队列 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); } ##### doAcquireSharedInterruptibly 1. addWaiter 设置为shared 模式 2. tryAcquire和tryAcquireShared 的返回值不同,因此会多出一个判断过程. 3. 在判断前驱节点是头节点之后,调用了setHeadAndPropagate方法,而不是简单的更新了一下头节点 private void doAcquireSharedInterruptibly(int arg) throws InterruptedException { // 创建一个共享模式的节点添加到队列中 final Node node = addWaiter(Node.SHARED); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head) { // 判断尝试获得锁 int r = tryAcquireShared(arg); // r &gt;=0 表示尝试获取到了执行权限,这个时候因为 state !=0 ,所以不会执行这段代码 if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; } } // 阻塞线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } ###### 图解分析 加入这个时候有是三个线程都调用了await方法,由于这个时候state的值还不为0,所以这三个线程都会加入到AQS队列中,并且这三个线程都属于阻塞状态. ![](http://files.luyanan.com//img/20190812163630.jpg) #### CountDownLatch.countDown 由于线程被await 方法阻塞了,所以只能等到countDown 方法使得state = 0的时候才会被唤醒,我们来看看countDown 做了什么? 1. 只有当state 减为0的时候,tryReleaseShared 才返回true, 否则只是简单的 state = state -1 2. 如果state = 0, 则调用 doReleaseShared 唤醒 处于await 状态下的线程 protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero // 用自旋的方式实现state 减1 for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; &#125; #### AQS.doReleaseShared 共享锁的释放和独占锁的释放是有一定的差别的 前面唤醒锁的逻辑和独占锁是一样的,先判断头节点是不是SIGNAL状态,如果是,则修改为0,并且唤醒头节点的下一个节点. &gt; PROPAGATE： 标识为PROPAGETE 状态的节点,是共享锁模式下的节点状态,处于这个状态的节点会对线程的唤醒进行传播. private void doReleaseShared() { /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } // 这个CAS失败的场景是: 执行到这里的时候,刚好有一个节点入队,入队会将这个ws设置为-1 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } // 如果到这里的时候,前面唤醒的线程已经占领了head,那么再循环通过检查头节点是否被改变了,如果改变了就继续循环 if (h == head) // loop if head changed break; } } - h == head:说明头节点还没有被刚刚用unparkSuccessor唤醒的线程(这里可以理解为ThreadB) 占有,此时break 退出循环. - h!= head: 头节点被刚刚唤醒的线程占用,那么这里重新进入到下一轮循环,唤醒下一个节点(这里是ThreadB),我们知道等到ThreadB被唤醒后,其实是会主动唤醒ThreadC... ##### doAcquireSharedInterruptibly 一旦ThreadA被唤醒后,代码又会继续回到doAcquireSharedInterruptibly 中来执行.如果当前state = 0的条件满足,则会执行setHeadAndPropagate 方法 private void doAcquireSharedInterruptibly(int arg) throws InterruptedException { // 创建一个共享模式的节点添加到队列中 final Node node = addWaiter(Node.SHARED); boolean failed = true; try { // 被唤醒的线程进入下一次循环继续判断 for (;;) { final Node p = node.predecessor(); if (p == head) { // 判断尝试获得锁 int r = tryAcquireShared(arg); // r &gt;=0 表示尝试获取到了执行权限,这个时候因为 state !=0 ,所以不会执行这段代码 if (r &gt;= 0) { setHeadAndPropagate(node, r); // 把当前节点移除AQS队列 p.next = null; // help GC failed = false; return; } } // 阻塞线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } ##### setHeadAndPropagate 这个方法的主要作用是把被唤醒的节点设置成head节点,然后继续唤醒队列中的其他线程. 由于现在队列中有三个线程处于阻塞状态,一旦ThreaA 被唤醒,并且设置成head后,会继续唤醒后续的ThreadB private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don’t know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); } } ###### 图解分析 ![](http://files.luyanan.com//img/20190812171333.jpg) ## Semaphore Semaphore 也就是我们常说的信号灯,Semaphore 可以控制同时访问的线程个数,通过acquire 获得一个许可,如果没有就等待，通过release 释放一个许可.有点类似于限流的作用. 叫信号灯的原因也和她的用户有关，比如某商场就5个停车位,每个停车位只能停一辆车,如果这个时候来了10辆车,必须要等到前面有空的车位才能进去. package com.notes.concurrent; import java.util.concurrent.Semaphore;import java.util.concurrent.TimeUnit; /** @author luyanan @since 2019/8/12 Semaphore demo */public class SemaphoreDemo { public static void main(String[] args) &#123; Semaphore semaphore = new Semaphore(5); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Car(i,semaphore)).start(); &#125; &#125; static class Car extends Thread &#123; private int num; private Semaphore semaphore; public Car(int num, Semaphore semaphore) &#123; this.num = num; this.semaphore = semaphore; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println(&quot;第&quot; + num + &quot;个车位被占用了&quot;); TimeUnit.SECONDS.sleep(2); System.out.println(&quot;第&quot; + num + &quot;个车位被释放了&quot;); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; } 结果 第0个车位被占用了第2个车位被占用了第1个车位被占用了第3个车位被占用了第4个车位被占用了第4个车位被释放了第1个车位被释放了第0个车位被释放了第5个车位被占用了第7个车位被占用了第3个车位被释放了第2个车位被释放了第8个车位被占用了第9个车位被占用了第6个车位被占用了第8个车位被释放了第5个车位被释放了第7个车位被释放了第6个车位被释放了第9个车位被释放了 ##### 使用场景 Semaphore比较常见的就是用来做限流 ##### Semaphore 源码分析 从Semaphore的功能上来看,我们基本能猜测到他的底层一定是基于AQS的共享锁,因为需要实现多个线程共享一个令牌池. 创建Semaphore实例的时候,需要一个参数permit, 这个基本上可以确定是设置给AQS的state的,然后每个线程调用acquire 的时候,执行state = state -1, release的时候执行 state = state +1,当然,acquire的时候,如果state = 0 说明没有资源了,需要等待其他线程release Semaphore 分公平策略和非公平策略 ##### FairSync static final class FairSync extends Sync { private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; // 区别在于是不是会先判断是否有线程在排队,然后才进行CAS 减操作 if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; &#125; ##### NofairSync static final class NonfairSync extends Sync { private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125; &#125; final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; ## CyclicBarrier CyclicBarrier 的字面意思是可循环使用(Cyclic)的屏障(Barrier).他要做的事情是让一组线程到达一个屏障(也可以叫同步点)时被阻塞,知道最后一个线程达到屏障时,屏障才会开门,所有被屏障拦截的线程才会继续工作. CyclicBarrier的默认的构造方法是CyclicBarrier(int parties),其参数表示屏障拦截的线程数量,每个线程调用await方法告诉 CyclicBarrier 当前线程已经达到了屏障,然后当前线程被阻塞. ##### 使用场景 当存在需要所有的子任务都完成时,才执行主任务,这个时候就可以选择使用CyclicBarrier ##### 使用案例 DataImportThread package com.notes.concurrent.cyclicbarrier; import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier; /** @author luyanan @since 2019/8/12 */public class DataImportThread extends Thread { private CyclicBarrier cyclicBarrier; private String path; public DataImportThread(CyclicBarrier cyclicBarrier, String path) &#123; this.cyclicBarrier = cyclicBarrier; this.path = path; &#125; @Override public void run() &#123; System.out.println(&quot;开始导入:&quot; + path + &quot;位置的数据&quot;); try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; } CycliBarrierDemo package com.notes.concurrent.cyclicbarrier; import java.util.concurrent.CyclicBarrier; /** @author luyanan @since 2019/8/12 */public class CycliBarrierDemo extends Thread { @Override public void run() { System.out.println(&quot;开始进行数据分析&quot;); } public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3, new CycliBarrierDemo()); new Thread(new DataImportThread(cyclicBarrier,&quot;path1&quot;)).start(); new Thread(new DataImportThread(cyclicBarrier,&quot;path2&quot;)).start(); new Thread(new DataImportThread(cyclicBarrier,&quot;path3&quot;)).start(); &#125; } 结果 开始导入:path1位置的数据开始导入:path2位置的数据开始导入:path3位置的数据开始进行数据分析 ``` 注意点 对于指定计数值 parties,若由于某种原因,没有足够的线程调用CyclicBarrier的await() ，则所有调用 await() 的线程都会被阻塞. 同样的CyclicBarrier 也可以调用 await(timeout,unit),设置超时时间,在设定的时候内,没有足够线程到达,则解除阻塞状态,继续工作. 通过rest重置计数,会使得进入await的线程出现BrokenBarrierException； 如果采用是CyclicBarrier(int parties,Runnable barrierAction) 构造方法,执行 barrierAction操作的最后一个到达线程. 实现原理CyclicBarrier 相比CountDownLatch 来说,简单很多,源码是基于ReentrantLock和Condition组合使用的.","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"多线程的基本原理及挑战(2)","slug":"并发编程/多线程的基本原理及挑战(2)","date":"2022-01-04T02:42:07.273Z","updated":"2022-01-04T02:42:07.273Z","comments":true,"path":"2022/01/04/bing-fa-bian-cheng/duo-xian-cheng-de-ji-ben-yuan-li-ji-tiao-zhan-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/bing-fa-bian-cheng/duo-xian-cheng-de-ji-ben-yuan-li-ji-tiao-zhan-2/","excerpt":"","text":"2. 多线程的基本原理由一个问题引发的思考线程的合理使用能够提升程序的处理性能,主要由两个方面: 第一是能够利用多核CPU以及超线程技术来实现线程的并行执行. 第二是线程的异步化执行相比于同步执行来说,异步执行能够很好的优化程序的处理性能提升吞吐量 同时,也带来了很多麻烦,举个简单的例子 多线程对于共享变量访问带来的安全性问题 一个变量i 假如一个线程去访问这个变量进行修改,这个时候对于数据的修改和访问没有任何问题.但是如果多个线程对于这同一个变量进行修改,就会存在一个数据安全性问题. 对于线程安全性,本质上是管理对于数据状态的访问,而且这个状态通常来说是共享的,可变的. 共享,是指这个数据变量可以被多个线程访问. 可变,指这个变量的值在它的生命周期内是可以改变的. 一个对象是否是线程安全,取决于它是否会被多个线程访问,以及程序中是如何使用这个对象的. 所以,如果多个线程同时访问同一个共享对象,在不需要额外的同步以及调用端代码不用做其他协调的情况下,这个共享对象的状态依然是正确的(正确性意味着这个对象的结果与我们预期的规定的结果是保持一致的),那说明这个对象是线程安全的. package com.notes.concurrent.synchronizeds; /** * @author luyanan * @since 2019/7/17 * &lt;p&gt;线程不安全&lt;/p&gt; **/ public class UnSafeThread &#123; private static int i = 0; public static void inc() &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; i++; &#125; public static void main(String[] args) &#123; for (int i = 0; i &lt; 1000; i++) &#123; new Thread(() -&gt; UnSafeThread.inc()).start(); &#125; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(i); &#125; &#125; 在java中如何解决由于线程并行导致的数据安全性问题呢？ 思考如何保证线程并行的数据安全性我们可以思考一下,问题的本质在于共享数据存在并发访问.如果我们能够有一种方法使得线程的并行变得串行,那是不是就不存在这个问题了呢? 按照大家已有的知识,最先想到的应该就是锁了把？ 毕竟这个场景并不陌生,我们在和数据库打交道的时候,就了解过悲观锁和乐观锁. 什么是锁? 他是处理并发的一种同步手段,而如果需要达到我们说的一个目的,那么这个锁就需要实现互斥的特性. java提供的加锁方法就是Synchronized 关键字. Synchronized的基本认识在多线程并发编程中synchronized 一直是元老级角色,很多人就会称呼它为 重量级锁. 但是,锁着java Se 1.6 对synchronized 进行了各种优化之后,有些情况下它就并不那么重,java se 1.6 中为了减少获取锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁. synchronized 的基本语法synchronized 有三种方式加锁,分别是: 修饰实例方法,作用于当前实例加锁,进入同步代码块前要获取当前实例的锁 静态方法,作用于当前类对象加锁,进入同步代码前要获得当前类对象的锁. 修饰代码块,指定加锁对象,对给定对象加锁,进入同步代码库前要获得给定对象的锁. 不同的修饰类型,代码锁的控制粒度. synchronized 的应用修改前面的案例,使用synchronized 关键字后,可以达到数据安全的效果 package com.notes.concurrent.synchronizeds; /** * @author luyanan * @since 2019/7/18 * &lt;p&gt;线程安全的例子&lt;/p&gt; **/ public class SafeThread &#123; private static int i = 0; public static void inc() &#123; synchronized (SafeThread.class) &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; i++; &#125; &#125; public static void main(String[] args) &#123; for (int i = 0; i &lt; 1000; i++) &#123; new Thread(() -&gt; SafeThread.inc()).start(); &#125; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(i); &#125; &#125; 结果 1000 思考锁是如何存储的可以思考一下,要实现多线程的互斥特性,那么这把锁需要哪些因素呢? 锁需要有一个东西来表示,比如获得锁是什么状态.无锁是什么状态, 这个状态需要对多个线程共享那么我们来分析,synchronized 锁是如何存储的呢? 观察synchronized 的整个语法发现,synchronized(lock)是基于lock这个对象的生命周期俩控制锁粒度的,那是不是锁的存储和这个lock对象有关系呢? 于是我们以对象在jvm内存中是如何存储的作为切入点,去看看对象里面有什么特性能够实现锁 对象在内存中的布局在Hotspot 虚拟机中,对象在内存中的存储布局,可以分为三个区域:对象头(Header),实例数据(Instance Data), 对齐填充(Padding). 探究jvm 源码实现当我们在java代码中,使用new 创建一个实例对象的时候,(hotsport虚拟机) JVM 层面实际上会创建一个instanceOopDesc 对象 Hotspot 虚拟机 采用 OOP -Klass 模型 来描述java对象实例,OOP(Ordinary Object Point) 指的是普通对象指针,Klass 用来描述对象对象的具体类型.Hotspot 采用instanceOopDesc 和arrayOopDesc 来描述对象头,arrayOopDesc 对象来描述数组类型. instanceOopDesc 的定义在Hotspot 源码汇总的instanceOop.hpp 文件中.另外,arrayOopDesc的定义对应在 arrayOop.hpp #ifndef SHARE_VM_OOPS_INSTANCEOOP_HPP #define SHARE_VM_OOPS_INSTANCEOOP_HPP #include &quot;oops/oop.hpp&quot; // An instanceOop is an instance of a Java Class // Evaluating &quot;new HashTable()&quot; will create an instanceOop. class instanceOopDesc : public oopDesc &#123; public: // aligned header size. static int header_size() &#123; return sizeof(instanceOopDesc)/HeapWordSize; &#125; // If compressed, the offset of the fields of the instance may not be aligned. static int base_offset_in_bytes() &#123; // offset computation code breaks if UseCompressedClassPointers // only is true return (UseCompressedOops &amp;&amp; UseCompressedClassPointers) ? klass_gap_offset_in_bytes() : sizeof(instanceOopDesc); &#125; static bool contains_field_offset(int offset, int nonstatic_field_size) &#123; int base_in_bytes = base_offset_in_bytes(); return (offset &gt;= base_in_bytes &amp;&amp; (offset-base_in_bytes) &lt; nonstatic_field_size * heapOopSize); &#125; &#125;; #endif // SHARE_VM_OOPS_INSTANCEOOP_HPP 从instanceOopDesc 代码中可以看到 instanceOopDesc 继承自 oopDesc, oopDesc 的定义在Hotspot 源码中的oop.hpp 中 /* * Copyright (c) 1997, 2013, Oracle and/or its affiliates. All rights reserved. * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER. * * This code is free software; you can redistribute it and/or modify it * under the terms of the GNU General Public License version 2 only, as * published by the Free Software Foundation. * * This code is distributed in the hope that it will be useful, but WITHOUT * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or * FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License * version 2 for more details (a copy is included in the LICENSE file that * accompanied this code). * * You should have received a copy of the GNU General Public License version * 2 along with this work; if not, write to the Free Software Foundation, * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. * * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA * or visit www.oracle.com if you need additional information or have any * questions. * */ #ifndef SHARE_VM_OOPS_OOP_HPP #define SHARE_VM_OOPS_OOP_HPP #include &quot;memory/iterator.hpp&quot; #include &quot;memory/memRegion.hpp&quot; #include &quot;memory/specialized_oop_closures.hpp&quot; #include &quot;oops/metadata.hpp&quot; #include &quot;utilities/macros.hpp&quot; #include &quot;utilities/top.hpp&quot; // oopDesc is the top baseclass for objects classes. The &#123;name&#125;Desc classes describe // the format of Java objects so the fields can be accessed from C++. // oopDesc is abstract. // (see oopHierarchy for complete oop class hierarchy) // // no virtual functions allowed // store into oop with store check template &lt;class T&gt; void oop_store(T* p, oop v); template &lt;class T&gt; void oop_store(volatile T* p, oop v); extern bool always_do_update_barrier; // Forward declarations. class OopClosure; class ScanClosure; class FastScanClosure; class FilteringClosure; class BarrierSet; class CMSIsAliveClosure; class PSPromotionManager; class ParCompactionManager; class oopDesc &#123; friend class VMStructs; private: volatile markOop _mark; union _metadata &#123; Klass* _klass; narrowKlass _compressed_klass; &#125; _metadata; // Fast access to barrier set. Must be initialized. static BarrierSet* _bs; public: markOop mark() const &#123; return _mark; &#125; markOop* mark_addr() const &#123; return (markOop*) &amp;_mark; &#125; void set_mark(volatile markOop m) &#123; _mark = m; &#125; void release_set_mark(markOop m); markOop cas_set_mark(markOop new_mark, markOop old_mark); // Used only to re-initialize the mark word (e.g., of promoted // objects during a GC) -- requires a valid klass pointer void init_mark(); Klass* klass() const; Klass* klass_or_null() const volatile; Klass** klass_addr(); narrowKlass* compressed_klass_addr(); void set_klass(Klass* k); // For klass field compression int klass_gap() const; void set_klass_gap(int z); // For when the klass pointer is being used as a linked list &quot;next&quot; field. void set_klass_to_list_ptr(oop k); oop list_ptr_from_klass(); // size of object header, aligned to platform wordSize static int header_size() &#123; return sizeof(oopDesc)/HeapWordSize; &#125; // Returns whether this is an instance of k or an instance of a subclass of k bool is_a(Klass* k) const; // Returns the actual oop size of the object int size(); // Sometimes (for complicated concurrency-related reasons), it is useful // to be able to figure out the size of an object knowing its klass. int size_given_klass(Klass* klass); // type test operations (inlined in oop.inline.h) bool is_instance() const; bool is_instanceMirror() const; bool is_instanceRef() const; bool is_array() const; bool is_objArray() const; bool is_typeArray() const; private: // field addresses in oop void* field_base(int offset) const; jbyte* byte_field_addr(int offset) const; jchar* char_field_addr(int offset) const; jboolean* bool_field_addr(int offset) const; jint* int_field_addr(int offset) const; jshort* short_field_addr(int offset) const; jlong* long_field_addr(int offset) const; jfloat* float_field_addr(int offset) const; jdouble* double_field_addr(int offset) const; Metadata** metadata_field_addr(int offset) const; public: // Need this as public for garbage collection. template &lt;class T&gt; T* obj_field_addr(int offset) const; // Needed for javaClasses address* address_field_addr(int offset) const; static bool is_null(oop obj); static bool is_null(narrowOop obj); static bool is_null(Klass* obj); // Decode an oop pointer from a narrowOop if compressed. // These are overloaded for oop and narrowOop as are the other functions // below so that they can be called in template functions. static oop decode_heap_oop_not_null(oop v); static oop decode_heap_oop_not_null(narrowOop v); static oop decode_heap_oop(oop v); static oop decode_heap_oop(narrowOop v); // Encode an oop pointer to a narrow oop. The or_null versions accept // null oop pointer, others do not in order to eliminate the // null checking branches. static narrowOop encode_heap_oop_not_null(oop v); static narrowOop encode_heap_oop(oop v); // Load an oop out of the Java heap static narrowOop load_heap_oop(narrowOop* p); static oop load_heap_oop(oop* p); // Load an oop out of Java heap and decode it to an uncompressed oop. static oop load_decode_heap_oop_not_null(narrowOop* p); static oop load_decode_heap_oop_not_null(oop* p); static oop load_decode_heap_oop(narrowOop* p); static oop load_decode_heap_oop(oop* p); // Store an oop into the heap. static void store_heap_oop(narrowOop* p, narrowOop v); static void store_heap_oop(oop* p, oop v); // Encode oop if UseCompressedOops and store into the heap. static void encode_store_heap_oop_not_null(narrowOop* p, oop v); static void encode_store_heap_oop_not_null(oop* p, oop v); static void encode_store_heap_oop(narrowOop* p, oop v); static void encode_store_heap_oop(oop* p, oop v); static void release_store_heap_oop(volatile narrowOop* p, narrowOop v); static void release_store_heap_oop(volatile oop* p, oop v); static void release_encode_store_heap_oop_not_null(volatile narrowOop* p, oop v); static void release_encode_store_heap_oop_not_null(volatile oop* p, oop v); static void release_encode_store_heap_oop(volatile narrowOop* p, oop v); static void release_encode_store_heap_oop(volatile oop* p, oop v); static oop atomic_exchange_oop(oop exchange_value, volatile HeapWord *dest); static oop atomic_compare_exchange_oop(oop exchange_value, volatile HeapWord *dest, oop compare_value, bool prebarrier = false); // Access to fields in a instanceOop through these methods. oop obj_field(int offset) const; volatile oop obj_field_volatile(int offset) const; void obj_field_put(int offset, oop value); void obj_field_put_raw(int offset, oop value); void obj_field_put_volatile(int offset, oop value); Metadata* metadata_field(int offset) const; void metadata_field_put(int offset, Metadata* value); jbyte byte_field(int offset) const; void byte_field_put(int offset, jbyte contents); jchar char_field(int offset) const; void char_field_put(int offset, jchar contents); jboolean bool_field(int offset) const; void bool_field_put(int offset, jboolean contents); jint int_field(int offset) const; void int_field_put(int offset, jint contents); jshort short_field(int offset) const; void short_field_put(int offset, jshort contents); jlong long_field(int offset) const; void long_field_put(int offset, jlong contents); jfloat float_field(int offset) const; void float_field_put(int offset, jfloat contents); jdouble double_field(int offset) const; void double_field_put(int offset, jdouble contents); address address_field(int offset) const; void address_field_put(int offset, address contents); oop obj_field_acquire(int offset) const; void release_obj_field_put(int offset, oop value); jbyte byte_field_acquire(int offset) const; void release_byte_field_put(int offset, jbyte contents); jchar char_field_acquire(int offset) const; void release_char_field_put(int offset, jchar contents); jboolean bool_field_acquire(int offset) const; void release_bool_field_put(int offset, jboolean contents); jint int_field_acquire(int offset) const; void release_int_field_put(int offset, jint contents); jshort short_field_acquire(int offset) const; void release_short_field_put(int offset, jshort contents); jlong long_field_acquire(int offset) const; void release_long_field_put(int offset, jlong contents); jfloat float_field_acquire(int offset) const; void release_float_field_put(int offset, jfloat contents); jdouble double_field_acquire(int offset) const; void release_double_field_put(int offset, jdouble contents); address address_field_acquire(int offset) const; void release_address_field_put(int offset, address contents); // printing functions for VM debugging void print_on(outputStream* st) const; // First level print void print_value_on(outputStream* st) const; // Second level print. void print_address_on(outputStream* st) const; // Address printing // printing on default output stream void print(); void print_value(); void print_address(); // return the print strings char* print_string(); char* print_value_string(); // verification operations void verify_on(outputStream* st); void verify(); // locking operations bool is_locked() const; bool is_unlocked() const; bool has_bias_pattern() const; // asserts bool is_oop(bool ignore_mark_word = false) const; bool is_oop_or_null(bool ignore_mark_word = false) const; #ifndef PRODUCT bool is_unlocked_oop() const; #endif // garbage collection bool is_gc_marked() const; // Apply &quot;MarkSweep::mark_and_push&quot; to (the address of) every non-NULL // reference field in &quot;this&quot;. void follow_contents(void); #if INCLUDE_ALL_GCS // Parallel Scavenge void push_contents(PSPromotionManager* pm); // Parallel Old void update_contents(ParCompactionManager* cm); void follow_contents(ParCompactionManager* cm); #endif // INCLUDE_ALL_GCS bool is_scavengable() const; // Forward pointer operations for scavenge bool is_forwarded() const; void forward_to(oop p); bool cas_forward_to(oop p, markOop compare); #if INCLUDE_ALL_GCS // Like &quot;forward_to&quot;, but inserts the forwarding pointer atomically. // Exactly one thread succeeds in inserting the forwarding pointer, and // this call returns &quot;NULL&quot; for that thread; any other thread has the // value of the forwarding pointer returned and does not modify &quot;this&quot;. oop forward_to_atomic(oop p); #endif // INCLUDE_ALL_GCS oop forwardee() const; // Age of object during scavenge uint age() const; void incr_age(); // Adjust all pointers in this object to point at it&#39;s forwarded location and // return the size of this oop. This is used by the MarkSweep collector. int adjust_pointers(); // mark-sweep support void follow_body(int begin, int end); // Fast access to barrier set static BarrierSet* bs() &#123; return _bs; &#125; static void set_bs(BarrierSet* bs) &#123; _bs = bs; &#125; // iterators, returns size of object #define OOP_ITERATE_DECL(OopClosureType, nv_suffix) \\ int oop_iterate(OopClosureType* blk); \\ int oop_iterate(OopClosureType* blk, MemRegion mr); // Only in mr. ALL_OOP_OOP_ITERATE_CLOSURES_1(OOP_ITERATE_DECL) ALL_OOP_OOP_ITERATE_CLOSURES_2(OOP_ITERATE_DECL) #if INCLUDE_ALL_GCS #define OOP_ITERATE_BACKWARDS_DECL(OopClosureType, nv_suffix) \\ int oop_iterate_backwards(OopClosureType* blk); ALL_OOP_OOP_ITERATE_CLOSURES_1(OOP_ITERATE_BACKWARDS_DECL) ALL_OOP_OOP_ITERATE_CLOSURES_2(OOP_ITERATE_BACKWARDS_DECL) #endif int oop_iterate_no_header(OopClosure* bk); int oop_iterate_no_header(OopClosure* bk, MemRegion mr); // identity hash; returns the identity hash key (computes it if necessary) // NOTE with the introduction of UseBiasedLocking that identity_hash() might reach a // safepoint if called on a biased object. Calling code must be aware of that. intptr_t identity_hash(); intptr_t slow_identity_hash(); // Alternate hashing code if string table is rehashed unsigned int new_hash(jint seed); // marks are forwarded to stack when object is locked bool has_displaced_mark() const; markOop displaced_mark() const; void set_displaced_mark(markOop m); // for code generation static int mark_offset_in_bytes() &#123; return offset_of(oopDesc, _mark); &#125; static int klass_offset_in_bytes() &#123; return offset_of(oopDesc, _metadata._klass); &#125; static int klass_gap_offset_in_bytes(); &#125;; #endif // SHARE_VM_OOPS_OOP_HPP 在普通实例对象中, oopDesc 的定义包含两个成员,分别是 _mark和_metadata. _mark 表示对象标记,属于markOop类型,也就是接下来要讲解的Mark Work ,他记录了对象和锁的有关信息, _metadata 表示类元信息,类元信息存储的是对象指向它的类元数据(Klass)的首地址,其中 Klass 表示普通指针,_compressed_klass 表示压缩指针类型 MarkWord在Hotspot 中,markOop的定义在markOop.hpp 文件中,代码如下 /* * Copyright (c) 1997, 2012, Oracle and/or its affiliates. All rights reserved. * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER. * * This code is free software; you can redistribute it and/or modify it * under the terms of the GNU General Public License version 2 only, as * published by the Free Software Foundation. * * This code is distributed in the hope that it will be useful, but WITHOUT * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or * FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License * version 2 for more details (a copy is included in the LICENSE file that * accompanied this code). * * You should have received a copy of the GNU General Public License version * 2 along with this work; if not, write to the Free Software Foundation, * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. * * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA * or visit www.oracle.com if you need additional information or have any * questions. * */ #ifndef SHARE_VM_OOPS_MARKOOP_HPP #define SHARE_VM_OOPS_MARKOOP_HPP #include &quot;oops/oop.hpp&quot; // The markOop describes the header of an object. // // Note that the mark is not a real oop but just a word. // It is placed in the oop hierarchy for historical reasons. // // Bit-format of an object header (most significant first, big endian layout below): // // 32 bits: // -------- // hash:25 ------------&gt;| age:4 biased_lock:1 lock:2 (normal object) // JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object) // size:32 ------------------------------------------&gt;| (CMS free block) // PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object) // // 64 bits: // -------- // unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object) // JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object) // PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object) // size:64 -----------------------------------------------------&gt;| (CMS free block) // // unused:25 hash:31 --&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object) // JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object) // narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object) // unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block) // // - hash contains the identity hash value: largest value is // 31 bits, see os::random(). Also, 64-bit vm&#39;s require // a hash value no bigger than 32 bits because they will not // properly generate a mask larger than that: see library_call.cpp // and c1_CodePatterns_sparc.cpp. // // - the biased lock pattern is used to bias a lock toward a given // thread. When this pattern is set in the low three bits, the lock // is either biased toward a given thread or &quot;anonymously&quot; biased, // indicating that it is possible for it to be biased. When the // lock is biased toward a given thread, locking and unlocking can // be performed by that thread without using atomic operations. // When a lock&#39;s bias is revoked, it reverts back to the normal // locking scheme described below. // // Note that we are overloading the meaning of the &quot;unlocked&quot; state // of the header. Because we steal a bit from the age we can // guarantee that the bias pattern will never be seen for a truly // unlocked object. // // Note also that the biased state contains the age bits normally // contained in the object header. Large increases in scavenge // times were seen when these bits were absent and an arbitrary age // assigned to all biased objects, because they tended to consume a // significant fraction of the eden semispaces and were not // promoted promptly, causing an increase in the amount of copying // performed. The runtime system aligns all JavaThread* pointers to // a very large value (currently 128 bytes (32bVM) or 256 bytes (64bVM)) // to make room for the age bits &amp; the epoch bits (used in support of // biased locking), and for the CMS &quot;freeness&quot; bit in the 64bVM (+COOPs). // // [JavaThread* | epoch | age | 1 | 01] lock is biased toward given thread // [0 | epoch | age | 1 | 01] lock is anonymously biased // // - the two lock bits are used to describe three states: locked/unlocked and monitor. // // [ptr | 00] locked ptr points to real header on stack // [header | 0 | 01] unlocked regular object header // [ptr | 10] monitor inflated lock (header is wapped out) // [ptr | 11] marked used by markSweep to mark an object // not valid at any other time // // We assume that stack/thread pointers have the lowest two bits cleared. class BasicLock; class ObjectMonitor; class JavaThread; class markOopDesc: public oopDesc &#123; private: // Conversion uintptr_t value() const &#123; return (uintptr_t) this; &#125; public: // Constants enum &#123; age_bits = 4, lock_bits = 2, biased_lock_bits = 1, max_hash_bits = BitsPerWord - age_bits - lock_bits - biased_lock_bits, hash_bits = max_hash_bits &gt; 31 ? 31 : max_hash_bits, cms_bits = LP64_ONLY(1) NOT_LP64(0), epoch_bits = 2 &#125;; // The biased locking code currently requires that the age bits be // contiguous to the lock bits. enum &#123; lock_shift = 0, biased_lock_shift = lock_bits, age_shift = lock_bits + biased_lock_bits, cms_shift = age_shift + age_bits, hash_shift = cms_shift + cms_bits, epoch_shift = hash_shift &#125;; enum &#123; lock_mask = right_n_bits(lock_bits), lock_mask_in_place = lock_mask &lt;&lt; lock_shift, biased_lock_mask = right_n_bits(lock_bits + biased_lock_bits), biased_lock_mask_in_place= biased_lock_mask &lt;&lt; lock_shift, biased_lock_bit_in_place = 1 &lt;&lt; biased_lock_shift, age_mask = right_n_bits(age_bits), age_mask_in_place = age_mask &lt;&lt; age_shift, epoch_mask = right_n_bits(epoch_bits), epoch_mask_in_place = epoch_mask &lt;&lt; epoch_shift, cms_mask = right_n_bits(cms_bits), cms_mask_in_place = cms_mask &lt;&lt; cms_shift #ifndef _WIN64 ,hash_mask = right_n_bits(hash_bits), hash_mask_in_place = (address_word)hash_mask &lt;&lt; hash_shift #endif &#125;; // Alignment of JavaThread pointers encoded in object header required by biased locking enum &#123; biased_lock_alignment = 2 &lt;&lt; (epoch_shift + epoch_bits) &#125;; #ifdef _WIN64 // These values are too big for Win64 const static uintptr_t hash_mask = right_n_bits(hash_bits); const static uintptr_t hash_mask_in_place = (address_word)hash_mask &lt;&lt; hash_shift; #endif enum &#123; locked_value = 0, unlocked_value = 1, monitor_value = 2, marked_value = 3, biased_lock_pattern = 5 &#125;; enum &#123; no_hash = 0 &#125;; // no hash value assigned enum &#123; no_hash_in_place = (address_word)no_hash &lt;&lt; hash_shift, no_lock_in_place = unlocked_value &#125;; enum &#123; max_age = age_mask &#125;; enum &#123; max_bias_epoch = epoch_mask &#125;; // Biased Locking accessors. // These must be checked by all code which calls into the // ObjectSynchronizer and other code. The biasing is not understood // by the lower-level CAS-based locking code, although the runtime // fixes up biased locks to be compatible with it when a bias is // revoked. bool has_bias_pattern() const &#123; return (mask_bits(value(), biased_lock_mask_in_place) == biased_lock_pattern); &#125; JavaThread* biased_locker() const &#123; assert(has_bias_pattern(), &quot;should not call this otherwise&quot;); return (JavaThread*) ((intptr_t) (mask_bits(value(), ~(biased_lock_mask_in_place | age_mask_in_place | epoch_mask_in_place)))); &#125; // Indicates that the mark has the bias bit set but that it has not // yet been biased toward a particular thread bool is_biased_anonymously() const &#123; return (has_bias_pattern() &amp;&amp; (biased_locker() == NULL)); &#125; // Indicates epoch in which this bias was acquired. If the epoch // changes due to too many bias revocations occurring, the biases // from the previous epochs are all considered invalid. int bias_epoch() const &#123; assert(has_bias_pattern(), &quot;should not call this otherwise&quot;); return (mask_bits(value(), epoch_mask_in_place) &gt;&gt; epoch_shift); &#125; markOop set_bias_epoch(int epoch) &#123; assert(has_bias_pattern(), &quot;should not call this otherwise&quot;); assert((epoch &amp; (~epoch_mask)) == 0, &quot;epoch overflow&quot;); return markOop(mask_bits(value(), ~epoch_mask_in_place) | (epoch &lt;&lt; epoch_shift)); &#125; markOop incr_bias_epoch() &#123; return set_bias_epoch((1 + bias_epoch()) &amp; epoch_mask); &#125; // Prototype mark for initialization static markOop biased_locking_prototype() &#123; return markOop( biased_lock_pattern ); &#125; // lock accessors (note that these assume lock_shift == 0) bool is_locked() const &#123; return (mask_bits(value(), lock_mask_in_place) != unlocked_value); &#125; bool is_unlocked() const &#123; return (mask_bits(value(), biased_lock_mask_in_place) == unlocked_value); &#125; bool is_marked() const &#123; return (mask_bits(value(), lock_mask_in_place) == marked_value); &#125; bool is_neutral() const &#123; return (mask_bits(value(), biased_lock_mask_in_place) == unlocked_value); &#125; // Special temporary state of the markOop while being inflated. // Code that looks at mark outside a lock need to take this into account. bool is_being_inflated() const &#123; return (value() == 0); &#125; // Distinguished markword value - used when inflating over // an existing stacklock. 0 indicates the markword is &quot;BUSY&quot;. // Lockword mutators that use a LD...CAS idiom should always // check for and avoid overwriting a 0 value installed by some // other thread. (They should spin or block instead. The 0 value // is transient and *should* be short-lived). static markOop INFLATING() &#123; return (markOop) 0; &#125; // inflate-in-progress // Should this header be preserved during GC? inline bool must_be_preserved(oop obj_containing_mark) const; inline bool must_be_preserved_with_bias(oop obj_containing_mark) const; // Should this header (including its age bits) be preserved in the // case of a promotion failure during scavenge? // Note that we special case this situation. We want to avoid // calling BiasedLocking::preserve_marks()/restore_marks() (which // decrease the number of mark words that need to be preserved // during GC) during each scavenge. During scavenges in which there // is no promotion failure, we actually don&#39;t need to call the above // routines at all, since we don&#39;t mutate and re-initialize the // marks of promoted objects using init_mark(). However, during // scavenges which result in promotion failure, we do re-initialize // the mark words of objects, meaning that we should have called // these mark word preservation routines. Currently there&#39;s no good // place in which to call them in any of the scavengers (although // guarded by appropriate locks we could make one), but the // observation is that promotion failures are quite rare and // reducing the number of mark words preserved during them isn&#39;t a // high priority. inline bool must_be_preserved_for_promotion_failure(oop obj_containing_mark) const; inline bool must_be_preserved_with_bias_for_promotion_failure(oop obj_containing_mark) const; // Should this header be preserved during a scavenge where CMS is // the old generation? // (This is basically the same body as must_be_preserved_for_promotion_failure(), // but takes the Klass* as argument instead) inline bool must_be_preserved_for_cms_scavenge(Klass* klass_of_obj_containing_mark) const; inline bool must_be_preserved_with_bias_for_cms_scavenge(Klass* klass_of_obj_containing_mark) const; // WARNING: The following routines are used EXCLUSIVELY by // synchronization functions. They are not really gc safe. // They must get updated if markOop layout get changed. markOop set_unlocked() const &#123; return markOop(value() | unlocked_value); &#125; bool has_locker() const &#123; return ((value() &amp; lock_mask_in_place) == locked_value); &#125; BasicLock* locker() const &#123; assert(has_locker(), &quot;check&quot;); return (BasicLock*) value(); &#125; bool has_monitor() const &#123; return ((value() &amp; monitor_value) != 0); &#125; ObjectMonitor* monitor() const &#123; assert(has_monitor(), &quot;check&quot;); // Use xor instead of &amp;~ to provide one extra tag-bit check. return (ObjectMonitor*) (value() ^ monitor_value); &#125; bool has_displaced_mark_helper() const &#123; return ((value() &amp; unlocked_value) == 0); &#125; markOop displaced_mark_helper() const &#123; assert(has_displaced_mark_helper(), &quot;check&quot;); intptr_t ptr = (value() &amp; ~monitor_value); return *(markOop*)ptr; &#125; void set_displaced_mark_helper(markOop m) const &#123; assert(has_displaced_mark_helper(), &quot;check&quot;); intptr_t ptr = (value() &amp; ~monitor_value); *(markOop*)ptr = m; &#125; markOop copy_set_hash(intptr_t hash) const &#123; intptr_t tmp = value() &amp; (~hash_mask_in_place); tmp |= ((hash &amp; hash_mask) &lt;&lt; hash_shift); return (markOop)tmp; &#125; // it is only used to be stored into BasicLock as the // indicator that the lock is using heavyweight monitor static markOop unused_mark() &#123; return (markOop) marked_value; &#125; // the following two functions create the markOop to be // stored into object header, it encodes monitor info static markOop encode(BasicLock* lock) &#123; return (markOop) lock; &#125; static markOop encode(ObjectMonitor* monitor) &#123; intptr_t tmp = (intptr_t) monitor; return (markOop) (tmp | monitor_value); &#125; static markOop encode(JavaThread* thread, uint age, int bias_epoch) &#123; intptr_t tmp = (intptr_t) thread; assert(UseBiasedLocking &amp;&amp; ((tmp &amp; (epoch_mask_in_place | age_mask_in_place | biased_lock_mask_in_place)) == 0), &quot;misaligned JavaThread pointer&quot;); assert(age &lt;= max_age, &quot;age too large&quot;); assert(bias_epoch &lt;= max_bias_epoch, &quot;bias epoch too large&quot;); return (markOop) (tmp | (bias_epoch &lt;&lt; epoch_shift) | (age &lt;&lt; age_shift) | biased_lock_pattern); &#125; // used to encode pointers during GC markOop clear_lock_bits() &#123; return markOop(value() &amp; ~lock_mask_in_place); &#125; // age operations markOop set_marked() &#123; return markOop((value() &amp; ~lock_mask_in_place) | marked_value); &#125; markOop set_unmarked() &#123; return markOop((value() &amp; ~lock_mask_in_place) | unlocked_value); &#125; uint age() const &#123; return mask_bits(value() &gt;&gt; age_shift, age_mask); &#125; markOop set_age(uint v) const &#123; assert((v &amp; ~age_mask) == 0, &quot;shouldn&#39;t overflow age field&quot;); return markOop((value() &amp; ~age_mask_in_place) | (((uintptr_t)v &amp; age_mask) &lt;&lt; age_shift)); &#125; markOop incr_age() const &#123; return age() == max_age ? markOop(this) : set_age(age() + 1); &#125; // hash operations intptr_t hash() const &#123; return mask_bits(value() &gt;&gt; hash_shift, hash_mask); &#125; bool has_no_hash() const &#123; return hash() == no_hash; &#125; // Prototype mark for initialization static markOop prototype() &#123; return markOop( no_hash_in_place | no_lock_in_place ); &#125; // Helper function for restoration of unmarked mark oops during GC static inline markOop prototype_for_object(oop obj); // Debugging void print_on(outputStream* st) const; // Prepare address of oop for placement into mark inline static markOop encode_pointer_as_mark(void* p) &#123; return markOop(p)-&gt;set_marked(); &#125; // Recover address of oop from encoded form used in mark inline void* decode_pointer() &#123; if (UseBiasedLocking &amp;&amp; has_bias_pattern()) return NULL; return clear_lock_bits(); &#125; // These markOops indicate cms free chunk blocks and not objects. // In 64 bit, the markOop is set to distinguish them from oops. // These are defined in 32 bit mode for vmStructs. const static uintptr_t cms_free_chunk_pattern = 0x1; // Constants for the size field. enum &#123; size_shift = cms_shift + cms_bits, size_bits = 35 // need for compressed oops 32G &#125;; // These values are too big for Win64 const static uintptr_t size_mask = LP64_ONLY(right_n_bits(size_bits)) NOT_LP64(0); const static uintptr_t size_mask_in_place = (address_word)size_mask &lt;&lt; size_shift; #ifdef _LP64 static markOop cms_free_prototype() &#123; return markOop(((intptr_t)prototype() &amp; ~cms_mask_in_place) | ((cms_free_chunk_pattern &amp; cms_mask) &lt;&lt; cms_shift)); &#125; uintptr_t cms_encoding() const &#123; return mask_bits(value() &gt;&gt; cms_shift, cms_mask); &#125; bool is_cms_free_chunk() const &#123; return is_neutral() &amp;&amp; (cms_encoding() &amp; cms_free_chunk_pattern) == cms_free_chunk_pattern; &#125; size_t get_size() const &#123; return (size_t)(value() &gt;&gt; size_shift); &#125; static markOop set_size_and_free(size_t size) &#123; assert((size &amp; ~size_mask) == 0, &quot;shouldn&#39;t overflow size field&quot;); return markOop(((intptr_t)cms_free_prototype() &amp; ~size_mask_in_place) | (((intptr_t)size &amp; size_mask) &lt;&lt; size_shift)); &#125; #endif // _LP64 &#125;; #endif // SHARE_VM_OOPS_MARKOOP_HPP Mark word 记录了对象和锁有关的信息,当某个对象被synchronized 关键字当成同步锁时,那么围绕这个锁的一系列操作都和Mark Word 有关系. Mark Word 在32虚拟机的长度是 32bit,在64位虚拟机的长度是64bit. Mark Word 可能变化为存储以上五种情况 为什么每个对象都可以实现锁? 首先,java中的每个对象都派生自Object类,而每个java Object 在JVM 内部都有一个 native 的C++ 对象 oop/oopDesc 进行对应. 在线程获取锁的时候,实际上就是获取一个监视器对象(minitor),monitor 可以认为是一个同步对象,所有的java 对象天生到monitor .在hotspot 源码中 markOop.hpp源码中,可以看到下面这段代码 ObjectMonitor* monitor() const &#123; assert(has_monitor(), &quot;check&quot;); // Use xor instead of &amp;~ to provide one extra tag-bit check. return (ObjectMonitor*) (value() ^ monitor_value); &#125; 多个线程访问同步代码块,相当于去争抢对象监视器,修改对象中的锁标识,上面的代码汇总objectMonitor 这个对象和线程争抢锁的逻辑有密切的关系。 synchronized 锁的升级在分析 synchronized 时,提高了偏向锁,轻量级锁,重量级锁.在分析这几种锁的区别的时候,我们先来思考一个问题, 使用锁能够实现数据的安全性,但是会带来性能的下降. 不使用锁能够基于线程并行提升程序性能,但是却不能保证线程安全性. 这两者之间似乎是没办法达到既能满足性能也能满足安全性的要求. hotspot 虚拟机的作者经过调查发现, 大部分情况下,加锁的代码不仅仅不存在多线程竞争,而且总是由同一个线程多次获得.所以基于这样一个概率,synchronized 在JDK1.6之后做了一些优化, 为了减少获得锁和释放锁带来的性能开销,引入了偏向锁,轻量级锁的概念. 因为大家会发现在synchronized 中,锁存在四种状态. 分别为无锁,偏向锁,轻量级锁,重量级锁;锁的状态根据竞争激烈的程序 从低到高不断升级. 偏向锁的基本原理前面说过,大部分情况下,锁不仅仅不存在多线程竞争,而是总是由同一个线程多次获得,为了让线程获得锁的代价更低就引入了偏向锁的概念. 怎么理解偏向锁呢? 当一个线程访问了加了同步锁的代码块时,会在对象头汇总存储当前线程的ID,后续这个线程进入和退出这段加了同步锁的代码块的时候,不需要再次加锁和释放锁.,而是直接比较对象头里面是否存储了指向当前线程的偏向锁.如果相等表示偏向锁是偏向于当前线程,就不需要再尝试获得锁了. 偏向锁的获取逻辑 首先获取锁对象的MarkWord ,判断是否处于可偏向状态(biased_lock =1 且 ThreadId 为空) 如果是可偏向状态,则通过CAS 操作,把当前线程的ID 写入到 MarkWord 如果cas成功,那么markword 就会变成这样,表示已经获得了锁对象的偏向锁,接着执行同步代码块 如果cas失败,说明有其他线程已经获得了偏向锁,正宗情况说明当前锁存在竞争,需要撤销已获得偏向锁的线程,并且把他持有的锁升级为轻量级锁(这个操作需要等到全局安全点,也就是没有线程在执行的字节码) 才能执行. 如果是已偏向状态,需要检查markword 中存储的ThreadID 是否等于当前线程的Thread ID 如果相等,不需要再次获得锁,可以直接执行同步代码块. 如果不相等,说明当前锁偏向于其他线程,需要撤销偏向锁并升级到轻量级锁. 偏向锁的撤销偏向锁的撤销并不是把对象恢复到无锁可偏向状态(因为偏向锁并不存在锁释放的概念),而是在获得偏向锁的过程中,发现cas 失败也就是存在线程竞争的时候,直接把被偏向的锁的对象升级到了被加了轻量级锁的状态. 对原持有偏向锁多线程进行撤销时,原获得偏向锁的线程存在两种情况: 原获得偏向锁的线程如果已经退出了临界区,也就是同步代码块执行完了,那么这个时候就会把对象头设置成无锁状态并且争抢锁的线程可以基于CAS 重新偏向前线程. 如果原获得偏向锁的线程的同步代码块还没有执行完,处于临界区之内,这个时候会把原获得偏向锁的线程升级为轻量级锁后继续执行同步代码块. 在我们的应用开发中,绝大部分情况下一定会存在2个以上的线程竞争,那么如果开启偏向锁,反而会提升获取锁的资源消耗.所以可以通过jvm参数 UseBiasedLocking 来设置开启或者关闭偏向锁. 轻量级锁的基本原理轻量级锁的加锁和解锁逻辑锁升级为轻量级之后,对象的MarkWord 也会进行相应的变化.升级为轻量级锁的过程: 线程在自己的栈帧中创建锁记录LockRecore 将锁对象的对象头中的 MarkWord 复制到线程的刚创建的锁记录中. 将锁记录中的Owner 指针指向锁对象。 将锁对象的对象头的MarkWord 替换为指向锁记录的指针. 自旋锁轻量级锁在加锁过程中用到了自旋锁 所谓自旋,就是指当有另外一个线程来竞争锁的时候,这个线程会在原地循环等待,而不是把该线程阻塞,知道那个获得锁的线程释放锁之后,这个线程就可以马上获得锁. 注意,锁在原地循环的时候,会消耗cpu,就相当于执行一个什么也没有的for循环. 所以,轻量级锁适用于那些同步代码块执行的很快的场景,这样,线程原地等待很短的时间就能够获得锁了. 自旋锁的使用,其实也是有一定的概率背景的,在大部分同步代码块执行的时间都是很短的,所在通过看似无意义的循环反而能够提升锁的性能. 但是自旋必须要有一定的条件控制,否则如果一个线程执行同步代码块的时间很长,那么这个线程不断的循环反而会消耗CPU 资源.默认情况下自旋的次数是10次.可以通过 preBlockSpin 来修改 在JDK1.6之后,引入了自适应自旋锁,自适用意味着自旋的次数不是固定的,而是根据前一次在同一个锁上自旋的时间以及锁的拥有者的状态来决定的. 如果在同一个锁对象上,自旋等待刚刚成功获得过锁,并且持有锁的线程正在运行,那么虚拟机就会认为这次自旋也很有可能再次成功,进而它将允许自旋等待持续相对更长的时间. 如果对于这个锁,自旋很少成功获得过,那在以后尝试获取这个锁的时候将可能省略掉自旋的过程,直接阻塞线程,避免浪费处理器资源. 轻量级锁的解锁轻量级锁的锁释放逻辑其实就是获得锁的逆向逻辑,通过CAS 操作把线程栈帧中的LockRecord 替换回到锁对象的MarkWord 中,如果成功表示没有竞争,如果失败,表示当前锁存在竞争,那么轻量级锁就会膨胀为重量级锁。 流程图分析 重量级锁的基本原理当轻量级锁膨胀为重量级锁的时候,意味着线程只能被挂起阻塞来等待被唤醒了. 重量级锁的monitor package com.notes.concurrent.synchronizeds; /** * @author luyanan * @since 2019/7/18 * &lt;p&gt;重量级锁&lt;/p&gt; **/ public class HeavyweightThread &#123; public static void main(String[] args) &#123; synchronized (HeavyweightThread.class) &#123; test(); &#125; &#125; public static void test() &#123; System.out.println(&quot;打印&quot;); &#125; &#125; 运行以后通过javap 工具查看生成的class 文件信息分析synchronzied 关键字的实现细节 javap -v /d/workspace/lyn/lyn-project/notes/java/javaNotes/concurrent-notes/target/classes/com/notes/concurrent/synchronizeds/HeavyweightThread.class Classfile /D:/workspace/lyn/lyn-project/notes/java/javaNotes/concurrent-notes/ta rget/classes/com/notes/concurrent/synchronizeds/HeavyweightThread.class Last modified 2019-7-18; size 795 bytes MD5 checksum 4bfd6f95270bf0aad230cbdd4243efac Compiled from &quot;HeavyweightThread.java&quot; public class com.notes.concurrent.synchronizeds.HeavyweightThread minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: #1 = Methodref #7.#26 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Class #27 // com/notes/concurrent/synchronizeds/ HeavyweightThread #3 = Methodref #2.#28 // com/notes/concurrent/synchronizeds/ HeavyweightThread.test:()V #4 = Fieldref #29.#30 // java/lang/System.out:Ljava/io/Print Stream; #5 = String #31 // ▒▒ӡ #6 = Methodref #32.#33 // java/io/PrintStream.println:(Ljava/ lang/String;)V #7 = Class #34 // java/lang/Object #8 = Utf8 &lt;init&gt; #9 = Utf8 ()V #10 = Utf8 Code #11 = Utf8 LineNumberTable #12 = Utf8 LocalVariableTable #13 = Utf8 this #14 = Utf8 Lcom/notes/concurrent/synchronizeds/HeavyweightThread ; #15 = Utf8 main #16 = Utf8 ([Ljava/lang/String;)V #17 = Utf8 args #18 = Utf8 [Ljava/lang/String; #19 = Utf8 StackMapTable #20 = Class #18 // &quot;[Ljava/lang/String;&quot; #21 = Class #34 // java/lang/Object #22 = Class #35 // java/lang/Throwable #23 = Utf8 test #24 = Utf8 SourceFile #25 = Utf8 HeavyweightThread.java #26 = NameAndType #8:#9 // &quot;&lt;init&gt;&quot;:()V #27 = Utf8 com/notes/concurrent/synchronizeds/HeavyweightThread #28 = NameAndType #23:#9 // test:()V #29 = Class #36 // java/lang/System #30 = NameAndType #37:#38 // out:Ljava/io/PrintStream; #31 = Utf8 ▒▒ӡ #32 = Class #39 // java/io/PrintStream #33 = NameAndType #40:#41 // println:(Ljava/lang/String;)V #34 = Utf8 java/lang/Object #35 = Utf8 java/lang/Throwable #36 = Utf8 java/lang/System #37 = Utf8 out #38 = Utf8 Ljava/io/PrintStream; #39 = Utf8 java/io/PrintStream #40 = Utf8 println #41 = Utf8 (Ljava/lang/String;)V &#123; public com.notes.concurrent.synchronizeds.HeavyweightThread(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt; &quot;:()V 4: return LineNumberTable: line 8: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/notes/concurrent/synchronizeds/Heavywei ghtThread; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: ldc #2 // class com/notes/concurrent/sync hronizeds/HeavyweightThread 2: dup 3: astore_1 4: monitorenter 5: invokestatic #3 // Method test:()V 8: aload_1 9: monitorexit 10: goto 18 13: astore_2 14: aload_1 15: monitorexit 16: aload_2 17: athrow 18: return Exception table: from to target type 5 10 13 any 13 16 13 any LineNumberTable: line 13: 0 line 14: 5 line 15: 8 line 16: 18 LocalVariableTable: Start Length Slot Name Signature 0 19 0 args [Ljava/lang/String; StackMapTable: number_of_entries = 2 frame_type = 255 /* full_frame */ offset_delta = 13 locals = [ class &quot;[Ljava/lang/String;&quot;, class java/lang/Object ] stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4 public static void test(); descriptor: ()V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=0, args_size=0 0: getstatic #4 // Field java/lang/System.out:Ljav a/io/PrintStream; 3: ldc #5 // String ▒▒ӡ 5: invokevirtual #6 // Method java/io/PrintStream.prin tln:(Ljava/lang/String;)V 8: return LineNumberTable: line 19: 0 line 20: 8 &#125; SourceFile: &quot;HeavyweightThread.java&quot; 加了同步代码块之后,在字节码中会看到一个 monitorenter 和monitorexit 每一个java对象都会与一个监视器monitor 关联,我们可以把他理解成一把锁,当一个线程想要执行一段被synchronized 修饰的同步方法或者代码块时,该线程得先获取到synchronized 修饰的对象对应的monitor . monitorenter 表示去获取一个对象的监视器,monitorexit 表示释放monitor 监视器的所有权,使得其他被阻塞的线程可以尝试去获得这个监视器. monitor 依赖操作系统的MutexLock(互斥锁)来实现的,线程被阻塞后便进入到内核(Linux)调度任务,这个会导致系统在用户态和内核态之间来回切换,严重影响锁的性能. 重量级锁的加锁的基本流程 任意线程对Object(Object由synchronized保护)的访问,首先要先获得Object的监视器.如果获取失败,线程进入同步队列,线程状态变为Blocked. 当访问Object 进程(获得了锁的线程) 释放了锁,则该释放操作唤醒阻塞在同步队列中的线程,使其重新尝试对监视器的获取. 回顾线程的竞争机制再来回顾一下线程的竞争机制对于锁升级这块的基本流程,方便大家更好的理解 加入有这样一个同步代码块,存在Thread#1,Thread#2等多个线程 synchronized(lock)&#123; // do Something &#125; 情况一: 只有Thread#1 会进入临界区 情况二: Thread#1和Thread#2 交替进入临界区,竞争不激烈 情况三: Thread#1/Thread#2/Thread#3… 同时进入临界区,竞争激烈 偏向锁此时当Thread#1 进入临界区时,JVM会将lockObject 对象头Mark Word 的锁标志位设置”01”,同时会用CAS操作把Thread#1的线程ID 记录到Mark Word 中,此时进入偏向模式.所谓偏向,指的是这个锁会偏向于Thread#1,若接下来没有其他线程进入临界区,则Thread#1 再出入临界区无需再执行任何的同步操作,也就是说,若只有Thread#1 会进入临界区,实际上只有Thread#1 初次进入临界区时需要执行CAS 操作,以后再出入临界区都不会有同步操作带来的开销. 轻量级锁偏向锁的场景太多理想化,更多的时候是Thread#2 也会尝试进入临界区,如果Thread#2 也进入临界区但是Thread#! 还没有执行完同步代码块的时候,会暂停Thread#1 并且升级到轻量级锁.Thread#2 通过自旋再次尝试以轻量级锁的方式来获得锁. 重量级锁如果Thread#1和Thread#2正常交替执行,那么轻量级锁基本能够满足锁的需求.但是Thread#1和Thread#2 同时进入临界区,那么轻量级锁就会膨胀成重量级锁,意味着Thread#1 线程获得了重量级锁的情况下,Thread#2 就会被阻塞. Synchronized 结合java Object 对象中的wait,notify,notifyAll前面讲到我们再将synchroized 的时候,发现被阻塞的线程什么时候被唤醒,取决于获得锁的线程什么时候执行完同步块并且释放锁.那么怎么做到显示控制呢? 我们就需要借助一个信号机制:在Object对象中,提供了wait/nofity/nofityAll，可以用于控制线程的状态. wait/nofity/nofityAll的基本概念wait:表示持有对象锁的线程A 准备释放对象锁权限,释放CPU资源并进入等待状态.notify:表示持有对象锁的线程A 准备释放对象锁权限,通知jvm唤醒某个竞争该线程锁的线程X. 线程A synchronized代码执行结束并且释放了锁之后,线程x 直接获得锁权限,其他竞争线程继续等待(即使线程X同步完毕,释放对象锁,其他竞争线程仍然等待,直至有新的 notify/notifyAll被调用) notifyAll: notifyAll和noify的区别在于,notifyAll会唤醒所有竞争同一个对象锁的所有线程,当已经获得锁的线程A 释放锁之后,所有被唤醒的线程都有可能获得对象锁权限. 需要注意的是:三个方法都必须在synchronized 同步关键字所限定的作用域中,否则会报java.lang.IllegalMonitorStateException,意思是没有同步方法.所以线程对象锁的状态是不确定的,不能调用这些方法. 另外,通过同步机制来确保线程从wait方法返回时能够感知到notify线程对变量做出的改变. wait/notify的基本使用package com.notes.concurrent.synchronizeds; /** * @author luyanan * @since 2019/7/19 * &lt;p&gt;&lt;/p&gt; **/ public class ThreadA extends Thread &#123; private Object lock; public ThreadA(Object lock) &#123; this.lock = lock; &#125; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(&quot;start ThreadA&quot;); try &#123; // 实现线程的阻塞 lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;end ThreadA&quot;); &#125; &#125; &#125; package com.notes.concurrent.synchronizeds; /** * @author luyanan * @since 2019/7/19 * &lt;p&gt;&lt;/p&gt; **/ public class ThreadB extends Thread &#123; private Object lock; public ThreadB(Object lock) &#123; this.lock = lock; &#125; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(&quot;start ThreadB&quot;); // 唤醒被阻塞的线程 lock.notify(); System.out.println(&quot;end ThreadB&quot;); &#125; &#125; &#125; package com.notes.concurrent.synchronizeds; import javax.tools.Diagnostic; /** * @author luyanan * @since 2019/7/19 * &lt;p&gt;&lt;/p&gt; **/ public class WaitNotifyDemo &#123; public static void main(String[] args) &#123; Object lock = new Object(); ThreadA threadA = new ThreadA(lock); threadA.start(); ThreadB threadB = new ThreadB(lock); threadB.start(); &#125; &#125; 结果 start ThreadA start ThreadB end ThreadB end ThreadA wait/notify的基本原理wait/notify的基本原理","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"jsonpath的介绍","slug":"工具/jsonpath的介绍","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/gong-ju/jsonpath-de-jie-shao/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/gong-ju/jsonpath-de-jie-shao/","excerpt":"","text":"jsonpath的介绍:JsonPath是一种简单的方法来提取给定JSON文档的部分内容。 JsonPath有许多编程语言，如Javascript，Python和PHP，Java。 JsonPath提供的json解析非常强大，它提供了类似正则表达式的语法，基本上可以满足所有你想要获得的json内容。 github上有它的应用:https://github.com/json-path/JsonPath JsonPath可在Central Maven存储库中找到。 Maven用户将其添加到您的POM: &lt;dependency> &lt;groupId>com.jayway.jsonpath&lt;/groupId> &lt;artifactId>json-path&lt;/artifactId> &lt;version>2.2.0&lt;/version> &lt;/dependency> JsonPath表达式总是以与XPath表达式结合使用XML文档相同的方式引用JSON结构。 JsonPath中的“根成员对象”始终称为$，无论是对象还是数组。 JsonPath表达式可以使用点表示法 $.store.book [0].title 或括号表示法 $[&#39;store&#39;][&#39;book&#39;][0][&#39;title&#39;] jsonpath操作符： 操作 说明 $ 查询根元素。这将启动所有路径表达式。 @ 当前节点由过滤谓词处理。 * 通配符，必要时可用任何地方的名称或数字。 .. 深层扫描。 必要时在任何地方可以使用名称。 . 点，表示子节点 [‘‘ (, ‘‘)] 括号表示子项 [ (, )] 数组索引或索引 [start:end] 数组切片操作 [?()] 过滤表达式。 表达式必须求值为一个布尔值。 函数函数可以在路径的尾部调用，函数的输出是路径表达式的输出，该函数的输出是由函数本身所决定的。 函数 描述 输出 min() 提供数字数组的最小值 Double max() 提供数字数组的最大值 Double avg() 提供数字数组的平均值 Double stddev() 提供数字数组的标准偏差值 Double length() 提供数组的长度 Integer 过滤器运算符过滤器是用于筛选数组的逻辑表达式。一个典型的过滤器将是[?(@.age &gt; 18)]，其中@表示正在处理的当前项目。 可以使用逻辑运算符&amp;&amp;和||创建更复杂的过滤器。 字符串文字必须用单引号或双引号括起来([?(@.color == ‘blue’)] 或者 [?(@.color == “blue”)]). 操作符 描述 == left等于right（注意1不等于’1’） != 不等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 &gt;= 大于等于 =~ 匹配正则表达式[?(@.name =~ /foo.*?/i)] in 左边存在于右边 [?(@.size in [‘S’, ‘M’])] nin 左边不存在于右边 size （数组或字符串）长度 empty （数组或字符串）为空 接下来我们就用java代码来写一个案例: Java操作示例JSON &amp;#123; \"expensive\": 10, \"store\": &amp;#123; \"bicycle\": &amp;#123; \"color\": \"red\", \"price\": 19.95 &amp;#125;, \"book\": [ &amp;#123; \"author\": \"Nigel Rees\", \"category\": \"reference\", \"price\": 8.95, \"title\": \"Sayings of the Century\" &amp;#125;, &amp;#123; \"author\": \"Evelyn Waugh\", \"category\": \"fiction\", \"price\": 12.99, \"title\": \"Sword of Honour\" &amp;#125;, &amp;#123; \"author\": \"Herman Melville\", \"category\": \"fiction\", \"isbn\": \"0-553-21311-3\", \"price\": 8.99, \"title\": \"Moby Dick\" &amp;#125;, &amp;#123; \"author\": \"J. R. R. Tolkien\", \"category\": \"fiction\", \"isbn\": \"0-395-19395-8\", \"price\": 22.99, \"title\": \"The Lord of the Rings\" &amp;#125; ] &amp;#125; &amp;#125; JsonPath (点击链接测试) 结果 $.store.book[*].author 获取json中store下book下的所有author值 $..author 获取所有json中所有author的值 $.store.* 所有的东西，书籍和自行车 $.store..price 获取json中store下所有price的值 $..book[2] 获取json中book数组的第3个值 $..book[-2] 倒数的第二本书 $..book[0,1] 前两本书 $..book[:2] 从索引0（包括）到索引2（排除）的所有图书 $..book[1:2] 从索引1（包括）到索引2（排除）的所有图书 $..book[-2:] 获取json中book数组的最后两个值 $..book[2:] 获取json中book数组的第3个到最后一个的区间值 $..book[?(@.isbn)] 获取json中book数组中包含isbn的所有值 [$.store.book[?(@.price &lt; 10)\\]](http://jsonpath.herokuapp.com/?path=$.store.book[?(@.price &lt; 10)]) 获取json中book数组中price&lt;10的所有值 [$..book[?(@.price &lt;= $[&#39;expensive&#39;\\])]](http://jsonpath.herokuapp.com/?path=$..book[?(@.price &lt;= $[‘expensive’])]) 获取json中book数组中price&lt;=expensive的所有值 [$..book[?(@.author =~ /.*REES/i)\\]](http://jsonpath.herokuapp.com/?path=$..book[?(@.author =~ /.*REES/i)]) 获取json中book数组中的作者以REES结尾的所有值（REES不区分大小写） $..* 逐层列出json中的所有值，层级由外到内 $..book.length() 获取json中book数组的长度 上面的json字符串的读取案例: (1) String json = &quot;...&quot;; List&lt;String&gt; authors = JsonPath.read(json, &quot;$.store.book[*].author&quot;); (2) 如果你只想读取一次，那么上面的代码就可以了 如果你还想读取其他路径，现在上面不是很好的方法，因为他每次获取都需要再解析整个文档。所以，我们可以先解析整个文档，再选择调用路径。 String json = \"...\"; Object document = Configuration.defaultConfiguration().jsonProvider().parse(json); String author0 = JsonPath.read(document, \"$.store.book[0].author\"); String author1 = JsonPath.read(document, \"$.store.book[1].author\"); (3) 当在java中使用JsonPath时，重要的是要知道你在结果中期望什么类型。 JsonPath将自动尝试将结果转换为调用者预期的类型。 // 抛出 java.lang.ClassCastException 异常 List&lt;String> list = JsonPath.parse(json).read(\"$.store.book[0].author\") // 正常 String author = JsonPath.parse(json).read(\"$.store.book[0].author\") (4) 默认情况下，MappingProvider SPI提供了一个简单的对象映射器。 这允许您指定所需的返回类型，MappingProvider将尝试执行映射。 在下面的示例中，演示了Long和Date之间的映射。 String json = \"&amp;#123;\\\"date_as_long\\\" : 1411455611975&amp;#125;\"; Date date = JsonPath.parse(json).read(\"$['date_as_long']\", Date.class); (5) 如果您将JsonPath配置为使用JacksonMappingProvider或GsonMappingProvider，您甚至可以将JsonPath输出直接映射到POJO中。 Book book = JsonPath.parse(json).read(\"$.store.book[0]\", Book.class); 另外一个案例: &#123; &quot;store&quot;: &#123; &quot;book&quot;: [ &#123; &quot;category&quot;: &quot;reference&quot;, &quot;author&quot;: &quot;Nigel Rees&quot;, &quot;title&quot;: &quot;Sayings of the Century&quot;, &quot;price&quot;: 8.95 &#125;, &#123; &quot;category&quot;: &quot;fiction&quot;, &quot;author&quot;: &quot;Evelyn Waugh&quot;, &quot;title&quot;: &quot;Sword of Honour&quot;, &quot;price&quot;: 12.99, &quot;isbn&quot;: &quot;0-553-21311-3&quot; &#125; ], &quot;bicycle&quot;: &#123; &quot;color&quot;: &quot;red&quot;, &quot;price&quot;: 19.95 &#125; &#125; &#125; private` `static` `void` `jsonPathTest() &#123; ``JSONObject json = jsonTest();``//调用自定义的jsonTest()方法获得json对象，生成上面的json ``//输出book[0]的author值 ``String author = JsonPath.read(json, ``&quot;$.store.book[0].author&quot;``); ``//输出全部author的值，使用Iterator迭代 ``List&lt;String&gt; authors = JsonPath.read(json, ``&quot;$.store.book[*].author&quot;``); ``//输出book[*]中category == &#39;reference&#39;的book ``List&lt;Object&gt; books = JsonPath.read(json, ``&quot;$.store.book[?(@.category == &#39;reference&#39;)]&quot;``); ``//输出book[*]中price&gt;10的book ``List&lt;Object&gt; books = JsonPath.read(json, ``&quot;$.store.book[?(@.price&gt;10)]&quot;``); ``//输出book[*]中含有isbn元素的book ``List&lt;Object&gt; books = JsonPath.read(json, ``&quot;$.store.book[?(@.isbn)]&quot;``); ``//输出该json中所有price的值 ``List&lt;Double&gt; prices = JsonPath.read(json, ``&quot;$..price&quot;``); ``//可以提前编辑一个路径，并多次使用它 ``JsonPath path = JsonPath.compile(``&quot;$.store.book[*]&quot;``); ``List&lt;Object&gt; books = path.read(json); &#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://rainsoil.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"工具/工具","permalink":"https://rainsoil.github.io/categories/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"}],"tags":[]},{"title":"Docker 安装","slug":"安装/Docker 安装","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/docker-an-zhuang/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/docker-an-zhuang/","excerpt":"","text":"Centos 安装Docker从1.13版本之后采用时间线的方式作为版本号，分为社区版CE和企业版EE。 社区版是免费提供给个人开发者和小型团体使用的，企业版会提供额外的收费服务，比如经过官方测试认证过的基础设施、容器、插件等。 社区版按照stable和edge两种方式发布，每个季度更新stable版本，如17.06，17.09；每个月份更新edge版本，如17.09，17.10。 安装docker安装Docker1、Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。 通过 uname -r 命令查看你当前的内核版本 $ uname -r 2、使用 root 权限登录 Centos。确保 yum 包更新到最 $ sudo yum update 3、卸载旧版本(如果安装过旧版本的话) $ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 4、安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 $ sudo yum install -y yum-utils device-mapper-persistent-data lvm2 5、设置yum源 $ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 6、可以查看所有仓库中所有docker版本，并选择特定版本安装 $ yum list docker-ce --showduplicates | sort -r 7、安装docker $ sudo yum install -y docker-ce docker-ce-cli containerd.io $ sudo yum install &lt;FQPN&gt; # 例如：sudo yum install docker-ce-17.12.0.ce 8、启动并加入开机启动 $ sudo systemctl start docker $ sudo systemctl enable docker 9、验证安装是否成功(有client和service两部分表示docker安装启动都成功了) $ docker version 问题1、因为之前已经安装过旧版本的docker，在安装的时候报错如下： Transaction check error: file /usr/bin/docker from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 file /usr/bin/docker-containerd from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 file /usr/bin/docker-containerd-shim from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 file /usr/bin/dockerd from install of docker-ce-17.12.0.ce-1.el7.centos.x86_64 conflicts with file from package docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 2、卸载旧版本的包 $ sudo yum erase docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64 3、再次安装docker $ sudo yum install docker-ce 安装docker-compose安装docker-compose相对比较简单，可以直接去https://github.com/docker/com… 下载然后选择相应的版本，或者直接执行如下命令安装，安装完后docker-compose会被安装到/usr/local/bin目录下 curl -L https://github.com/docker/compose/releases/download/1.24.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 设置docker-compose可执行sudo chmod +x /usr/local/bin/docker-compose 查看docker-compose是否安装成功docker-compose --version","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"CentOS7安装Zookeeper","slug":"安装/CentOS7安装Zookeeper","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/centos7-an-zhuang-zookeeper/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/centos7-an-zhuang-zookeeper/","excerpt":"","text":"CentOS7安装Zookeeper创建目录 mkdir -p /usr/local/soft/zookeeper cd /usr/local/soft/zookeeper 下载解压 wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz tar -zxvf zookeeper-3.4.9.tar.gz cd zookeeper-3.4.9 mkdir data mkdir logs 修改配置文件 cd conf cp zoo_sample.cfg zoo.cfg 修改zoo.cfg # 数据文件夹 dataDir=/usr/local/services/zookeeper/zookeeper-3.4.9/data # 日志文件夹 dataLogDir=/usr/local/services/zookeeper/zookeeper-3.4.9/logs 配置环境变量 vim /etc/profile 在尾部追加 # zk env export ZOOKEEPER_HOME=/usr/local/soft/zookeeper/zookeeper-3.4.9/ export PATH=$ZOOKEEPER_HOME/bin:$PATH export PATH 编译生效 source /etc/profile 启动ZK cd ../bin zkServer.sh start 查看状态 zkServer.sh status","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"CentOS7安装Redis单实例","slug":"安装/CentOS7安装Redis单实例","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/centos7-an-zhuang-redis-dan-shi-li/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/centos7-an-zhuang-redis-dan-shi-li/","excerpt":"","text":"CentOS7安装Redis单实例由于环境差异，安装过程可能遇到各种各样的问题，不要慌，根据错误提示解决即可。 1、下载redis下载地址在：redis.io比如把Redis安装到/usr/local/soft/ cd /usr/local/soft/ wget http://download.redis.io/releases/redis-5.0.5.tar.gz 2、解压压缩包 tar -zxvf redis-5.0.5.tar.gz 3、安装gcc依赖Redis是C语言编写的，编译需要 yum install gcc 4、编译安装 cd redis-5.0.5 make MALLOC=libc 将/usr/local/soft/redis-5.0.5/src目录下二进制文件安装到/usr/local/bin cd src make install 5、修改配置文件默认的配置文件是/usr/local/soft/redis-5.0.5/redis.conf后台启动 daemonize no 改成 daemonize yes 下面一行必须改成 bind 0.0.0.0 或注释，否则只能在本机访问 bind 127.0.0.1 如果需要密码访问，取消requirepass的注释 requirepass yourpassword 6、使用指定配置文件启动Redis（这个命令建议配置alias） /usr/local/soft/redis-5.0.5/src/redis-server /usr/local/soft/redis-5.0.5/redis.conf 7、进入客户端（这个命令建议配置alias） /usr/local/soft/redis-5.0.5/src/redis-cli 8、停止redis（在客户端中） redis&gt; shutdown 或 ps -aux | grep redis kill -9 xxxx","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"CentOS7卸载openJDK安装JDK1","slug":"安装/CentOS7卸载openJDK安装JDK1.8","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/centos7-xie-zai-openjdk-an-zhuang-jdk1.8/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/centos7-xie-zai-openjdk-an-zhuang-jdk1.8/","excerpt":"","text":"CentOS7卸载openJDK安装JDK1.8CentOS7自带了一个openjdk，使用的时候用诸多问题，例如明明配置了Java环境变量但是不能使用，这个时候需要卸载重新安装。 查看已有openjdk版本rpm -qa|grep jdk 卸载openjdkremove后面的参数是上面得到的结果.noarch结尾的包 yum -y remove copy-jdk-configs-3.3-10.el7_5.noarch 下载jdk1.8下载jdk-8u40-linux-x64.tar.gz，上传到/usr/local/soft/java 解压tar -zxvf jdk-8u40-linux-x64.tar.gz -C /usr/local/soft/java 配置环境变量在/etc/profile文件的末尾加上 export JAVA_HOME=/usr/local/soft/java/jdk1.8.0_40 export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 编译使之生效 source /etc/profile 验证 java -version","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"CentOS 7 单机安装Redis Cluster（3主3从）","slug":"安装/CentOS 7 单机安装Redis Cluster（3主3从）","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/centos-7-dan-ji-an-zhuang-redis-cluster-3-zhu-3-cong/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/centos-7-dan-ji-an-zhuang-redis-cluster-3-zhu-3-cong/","excerpt":"","text":"CentOS 7 单机安装Redis Cluster（3主3从）首先，本篇要基于单实例的安装，你的机器上已经有一个Redis 为了节省机器，我们直接把6个Redis实例安装在同一台机器上（3主3从），只是使用不同的端口号。机器IP 192.168.8.207 更新：新版的cluster已经不需要通过ruby脚本创建，删掉了ruby相关依赖的安装 cd /usr/local/soft/redis-5.0.5 mkdir redis-cluster cd redis-cluster mkdir 7291 7292 7293 7294 7295 7296 复制redis配置文件到7291目录 cp /usr/local/soft/redis-5.0.5/redis.conf /usr/local/soft/redis-5.0.5/redis-cluster/7291 修改7291的redis.conf配置文件，内容： cd /usr/local/soft/redis-5.0.5/redis-cluster/7291 &gt;redis.conf vim redis.conf port 7291 daemonize yes protected-mode no dir /usr/local/soft/redis-5.0.5/redis-cluster/7291/ cluster-enabled yes cluster-config-file nodes-7291.conf cluster-node-timeout 5000 appendonly yes pidfile /var/run/redis_7291.pid 把7291下的redis.conf复制到其他5个目录。 cd /usr/local/soft/redis-5.0.5/redis-cluster/7291 cp redis.conf ../7292 cp redis.conf ../7293 cp redis.conf ../7294 cp redis.conf ../7295 cp redis.conf ../7296 批量替换内容 cd /usr/local/soft/redis-5.0.5/redis-cluster sed -i &#39;s/7291/7292/g&#39; 7292/redis.conf sed -i &#39;s/7291/7293/g&#39; 7293/redis.conf sed -i &#39;s/7291/7294/g&#39; 7294/redis.conf sed -i &#39;s/7291/7295/g&#39; 7295/redis.conf sed -i &#39;s/7291/7296/g&#39; 7296/redis.conf 启动6个Redis节点 cd /usr/local/soft/redis-5.0.5/ ./src/redis-server redis-cluster/7291/redis.conf ./src/redis-server redis-cluster/7292/redis.conf ./src/redis-server redis-cluster/7293/redis.conf ./src/redis-server redis-cluster/7294/redis.conf ./src/redis-server redis-cluster/7295/redis.conf ./src/redis-server redis-cluster/7296/redis.conf 是否启动了6个进程 ps -ef|grep redis 创建集群旧版本中的redis-trib.rb已经废弃了，直接用–cluster命令注意用绝对IP，不要用127.0.0.1 cd /usr/local/soft/redis-5.0.5/src/ redis-cli --cluster create 192.168.8.207:7291 192.168.8.207:7292 192.168.8.207:7293 192.168.8.207:7294 192.168.8.207:7295 192.168.8.207:7296 --cluster-replicas 1 Redis会给出一个预计的方案，对6个节点分配3主3从，如果认为没有问题，输入yes确认 &gt;&gt;&gt; Performing hash slots allocation on 6 nodes... Master[0] -&gt; Slots 0 - 5460 Master[1] -&gt; Slots 5461 - 10922 Master[2] -&gt; Slots 10923 - 16383 Adding replica 127.0.0.1:7295 to 127.0.0.1:7291 Adding replica 127.0.0.1:7296 to 127.0.0.1:7292 Adding replica 127.0.0.1:7294 to 127.0.0.1:7293 &gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c 127.0.0.1:7291 slots:[0-5460] (5461 slots) master M: 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 127.0.0.1:7292 slots:[5461-10922] (5462 slots) master M: aeeb7d7076d9b25a7805ac6f508497b43887e599 127.0.0.1:7293 slots:[10923-16383] (5461 slots) master S: ebc479e609ff8f6ca9283947530919c559a08f80 127.0.0.1:7294 replicates aeeb7d7076d9b25a7805ac6f508497b43887e599 S: 49385ed6e58469ef900ec48e5912e5f7b7505f6e 127.0.0.1:7295 replicates dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c S: 8d6227aefc4830065624ff6c1dd795d2d5ad094a 127.0.0.1:7296 replicates 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 Can I set the above configuration? (type &#39;yes&#39; to accept): 注意看slot的分布： 7291 [0-5460] (5461个槽) 7292 [5461-10922] (5462个槽) 7293 [10923-16383] (5461个槽) 集群创建完成 &gt;&gt;&gt; Nodes configuration updated &gt;&gt;&gt; Assign a different config epoch to each node &gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join .... &gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7291) M: dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c 127.0.0.1:7291 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 127.0.0.1:7292 slots:[5461-10922] (5462 slots) master 1 additional replica(s) M: aeeb7d7076d9b25a7805ac6f508497b43887e599 127.0.0.1:7293 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 8d6227aefc4830065624ff6c1dd795d2d5ad094a 127.0.0.1:7296 slots: (0 slots) slave replicates aeeb7d7076d9b25a7805ac6f508497b43887e599 S: ebc479e609ff8f6ca9283947530919c559a08f80 127.0.0.1:7294 slots: (0 slots) slave replicates dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c S: 49385ed6e58469ef900ec48e5912e5f7b7505f6e 127.0.0.1:7295 slots: (0 slots) slave replicates 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 [OK] All nodes agree about slots configuration. &gt;&gt;&gt; Check for open slots... &gt;&gt;&gt; Check slots coverage... [OK] All 16384 slots covered. 重置集群的方式是在每个节点上个执行cluster reset，然后重新创建集群 连接到客户端 redis-cli -p 7291 redis-cli -p 7292 redis-cli -p 7293 批量写入值 cd /usr/local/soft/redis-5.0.5/redis-cluster/ vim setkey.sh 脚本内容 #!/bin/bash for ((i=0;i&lt;20000;i++)) do echo -en &quot;helloworld&quot; | redis-cli -h 192.168.8.207 -p 7291 -c -x set name$i &gt;&gt;redis.log done chmod +x setkey.sh ./setkey.sh 每个节点分布的数据 127.0.0.1:7292&gt; dbsize (integer) 6683 127.0.0.1:7293&gt; dbsize (integer) 6665 127.0.0.1:7291&gt; dbsize (integer) 6652 其他命令，比如添加节点、删除节点，重新分布数据： redis-cli --cluster help Cluster Manager Commands: create host1:port1 ... hostN:portN --cluster-replicas &lt;arg&gt; check host:port --cluster-search-multiple-owners info host:port fix host:port --cluster-search-multiple-owners reshard host:port --cluster-from &lt;arg&gt; --cluster-to &lt;arg&gt; --cluster-slots &lt;arg&gt; --cluster-yes --cluster-timeout &lt;arg&gt; --cluster-pipeline &lt;arg&gt; --cluster-replace rebalance host:port --cluster-weight &lt;node1=w1...nodeN=wN&gt; --cluster-use-empty-masters --cluster-timeout &lt;arg&gt; --cluster-simulate --cluster-pipeline &lt;arg&gt; --cluster-threshold &lt;arg&gt; --cluster-replace add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id &lt;arg&gt; del-node host:port node_id call host:port command arg arg .. arg set-timeout host:port milliseconds import host:port --cluster-from &lt;arg&gt; --cluster-copy --cluster-replace help For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster. 附录： 集群命令 cluster info ：打印集群的信息 cluster nodes ：列出集群当前已知的所有节点（node），以及这些节点的相关信息。 cluster meet ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。 cluster forget ：从集群中移除 node_id 指定的节点(保证空槽道)。 cluster replicate ：将当前节点设置为 node_id 指定的节点的从节点。 cluster saveconfig ：将节点的配置文件保存到硬盘里面。 槽slot命令 cluster addslots [slot …] ：将一个或多个槽（slot）指派（assign）给当前节点。 cluster delslots [slot …] ：移除一个或多个槽对当前节点的指派。 cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。 cluster setslot node ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽&gt;，然后再进行指派。 cluster setslot migrating ：将本节点的槽 slot 迁移到 node_id 指定的节点中。 cluster setslot importing ：从 node_id 指定的节点中导入槽 slot 到本节点。 cluster setslot stable ：取消对槽 slot 的导入（import）或者迁移（migrate）。 键命令 cluster keyslot ：计算键 key 应该被放置在哪个槽上。 cluster countkeysinslot ：返回槽 slot 目前包含的键值对数量。 cluster getkeysinslot ：返回 count 个 slot 槽中的键","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"Java8之lambda函数式编程","slug":"基础/Java8之lambda函数式编程","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/ji-chu/java8-zhi-lambda-han-shu-shi-bian-cheng/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/ji-chu/java8-zhi-lambda-han-shu-shi-bian-cheng/","excerpt":"","text":"Java8之lambda函数式编程1. 引言java8的最大的特性就是引入Lambda 表达式,即函数式编程,可以将行为进行传递.总结就是:使用不可变值与函数,函数对不可变值进行处理,映射成另一个值 2. java 重要的函数式接口1. 什么是函数式接口 函数式接口是只有一个抽象方法的接口,用作Lambda 表达式的类型,使用@FunctionalInterface 注解修饰的类,编译器会检测该类是否只有一个抽象方法或者接口,否则,会报错,可以有多个默认的方法,静态方法. 1.1 java8自带的常用函数式接口 函数接口 抽象方法 功能 参数 Predicate test(T t) 判断真假 T Consumer accept(T t) 消费消息 T Function R apply(T t) 将T 映射为R (转换功能) T Supplier T get() 产生消息 None UnaryOperator T apply(T t) 一元操作 T BinaryOperator apply(T t,U u) 二元操作 (T,U) package com.notes.utils.lambda; import org.junit.jupiter.api.Test; import java.math.BigDecimal; import java.util.function.*; /** * @author luyanan * @since 2019/7/17 * &lt;p>Lambda测试类&lt;/p> **/ public class LambdaTest &amp;#123; @Test public void test() &amp;#123; Predicate&lt;Integer> predicate = x -> x > 12; // 判断真假 User user = User.builder().age(15).name(\"张三\").build(); System.out.println(\"张三的年龄是否大于12:\" + predicate.test(user.getAge())); // 消费消息 Consumer&lt;String> consumer = LambdaTest::say; consumer.accept(\"我相信我就是我\"); // 映射 Function&lt;User, String> function = User::getName; String name = function.apply(user); System.out.println(name); // 产生消息 Supplier&lt;Integer> supplier = () -> Integer.valueOf(BigDecimal.TEN.toString()); System.out.println(supplier.get()); UnaryOperator&lt;Boolean> unaryOperator = uglily -> !uglily; Boolean apply = unaryOperator.apply(true); System.out.println(apply); BinaryOperator&lt;Integer> binaryOperator = (x, y) -> x * y; Integer integer = binaryOperator.apply(2, 4); System.out.println(integer); test(()->\"我是一个工作者\"); &amp;#125; // 演示自定义函数式接口编程 public static void test(Worker worker) &amp;#123; String worker1 = worker.worker(); System.out.println(worker1); &amp;#125; public interface Worker &amp;#123; String worker(); &amp;#125; public static void say(String msg) &amp;#123; System.out.println(msg); &amp;#125; &amp;#125; 结果 张三的年龄是否大于12:true 我相信我就是我 张三 10 false 8 我是一个工作者 以上演示了Lambda接口的使用和自定义一个函数式接口并使用.下面,我们看看java8 将函数式接口封装到流中 如何高效的帮助我们处理集合. 1.2 惰性求值与及早求值惰性求值: 只描述Stream,操作的结果也是Stream,这样的操作成为惰性求值, 惰性求值可以想建造者模式一样链式调用,最后再使用及早求值得到最终结果. 及早求值:得到的最终的结果而不是Stream,这样的操作称之为及早求值 2 常用的流2.1 collect(Collectors.toList())将流转换为list,还有toSet().toMap()等,及早求值 @Test public void collectTest() &amp;#123; List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); System.out.println(userList); &amp;#125; 结果 [User(name=张三, age=13), User(name=李四, age=16), User(name=王五, age=18)] 2.2 filter顾名思义,就是起过滤筛选的作用,内部就是Predicate接口,惰性求值. 筛选出年龄大于16的用户 @Test public void filter() &amp;#123; List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); // 筛选出年龄大于15的用户 List&lt;User> users = userList .stream() .filter(a -> a.getAge() > 15) .collect(Collectors.toList()); System.out.println(users); &amp;#125; 结果 [User(name=李四, age=16), User(name=王五, age=18)] 2.3 map转换功能,内部就是Function接口.惰性求值. @Test public void map() &amp;#123; List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); // 将所有的用户姓名 转换成一个集合 List&lt;String> names = userList .stream() .map(User::getName) .collect(Collectors.toList()); System.out.println(names); &amp;#125; 结果 [张三, 李四, 王五] 2.4 flatNap将多个Stream 合并为一个Stream.惰性求值. @Test public void flatMap() &amp;#123; // 合并Stream List&lt;User> users1 = new ArrayList&lt;>(); users1.add(new User(\"张三\", 11)); users1.add(new User(\"李四\", 12)); List&lt;User> users2 = new ArrayList&lt;>(); users2.add(new User(\"王五\", 13)); users2.add(new User(\"赵柳\", 14)); // 合并 List&lt;User> userList = users1 .stream() .flatMap(user -> users2.stream()) .collect(Collectors.toList()); System.out.println(userList); &amp;#125; 结果 [User(name=王五, age=13), User(name=赵柳, age=14), User(name=王五, age=13), User(name=赵柳, age=14)] 2.5 max和min集合中求最大值和最小值 @Test public void maxOrMin() &amp;#123; // 求最大值/最小值 List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); // 求年龄的最小的用户/年龄最大的用户 User max = userList.stream().max(Comparator.comparing(User::getAge)).get(); System.out.println(\"年龄最大的用户:\"+max); User min = userList.stream().min(Comparator.comparing(User::getAge)).get(); System.out.println(\"年龄最小的用户:\"+min); &amp;#125; 结果 年龄最大的用户:User(name=王五, age=18) 年龄最小的用户:User(name=张三, age=13) 2.6 count统计功能,一般都是结合filter 使用,因为先筛选出我们需要的再统计即可.及早求值. @Test public void count() &amp;#123; List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); // 统计 long count = userList.stream().filter(a -> a.getAge() > 10).count(); System.out.println(count); &amp;#125; 2.7 reducereduce 操作可以实现从一组值中生成一个值,再上述例子中用到的count,min,max,因为常用而被纳入标准库.事实上,这些方法都是reduce操作. @Test public void reduce() &amp;#123; Integer reduce = Stream .of(1, 2, 3, 4) .reduce(0, (acc, x) -> acc + x); System.out.println(reduce); &amp;#125; 结果 10 3 高级集合类及收集器 3.1 数据分块常用的流操作 是将其分解成两个集合,Collectors.partitioningBy 帮我们实现了,接受一个Predicate 函数式接口 @Test public void partitioningBy() &amp;#123; List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); Map&lt;Boolean, List&lt;User>> listMap = userList.stream().collect(Collectors.partitioningBy(a -> a.getName().contains(\"张\"))); System.out.println(listMap); &amp;#125; 结果 {false=[User(name=李四, age=16), User(name=王五, age=18)], true=[User(name=张三, age=13)]} 3.2 数据分组数据分组 是一种更自然的分割数据操作，可以使用任意值对数据分组。Collectors.groupingBy接收一个Function做转换。 @Test public void groupingBy() &amp;#123; List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); Map&lt;String, List&lt;User>> listMap = userList .stream() .collect(Collectors.groupingBy(User::getName)); System.out.println(listMap); &amp;#125; 结果 &#123;李四=[User(name=李四, age=16)], 张三=[User(name=张三, age=13)], 王五=[User(name=王五, age=18)]&#125; 3.3 字符串拼接 @Test public void join() &amp;#123; // 字符串拼接 List&lt;User> userList = Stream .of(new User(\"张三\", 13), new User(\"李四\", 16), new User(\"王五\", 18)) .collect(Collectors.toList()); String collect = userList .stream() .map(User::getName) .collect(Collectors.joining(\",\")); System.out.println(collect); &amp;#125; 结果 张三,李四,王五","categories":[{"name":"基础","slug":"基础","permalink":"https://rainsoil.github.io/categories/%E5%9F%BA%E7%A1%80/"},{"name":"基础","slug":"基础/基础","permalink":"https://rainsoil.github.io/categories/%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"vagrant安装centos7","slug":"安装/vagrant安装centos7","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/vagrant-an-zhuang-centos7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/vagrant-an-zhuang-centos7/","excerpt":"","text":"基于vagrant 安装centos7 环境1. 安装Vagrant 访问官网 https://www.vagrantup.com/ 点击DownloadWindows，MacOS，Linux等 选择对应的版本 傻瓜式的安装 在命令行输入vagrant ,出现 就表明安装成功了. 2. 安装virtual box 访问官网https://www.virtualbox.org/ 选择左侧的 “Downloads” 选择对应的操作系统版本 傻瓜式安装 [win10中若出现]安装virtualbox快完成时立即回滚，并提示安装出现严重错误(1)打开服务 (2)找到Device Install Service和Device Setup Manager，然后启动 (3)再次尝试安装 3. 安装centos 创建centos7 目录, 并进去启动(目录全路径不要有中文空格) 在此目录下打开cmd ,运行 vagrant init centos/7, (centos7是镜像,镜像可以去镜像仓库https://app.vagrantup.com/boxes/search 查找) 或者你也可以下载 virtualbox.box 文件到本地, 然后再将virtualbox.box 文件添加到vagrant 管理的镜像中. 添加镜像并起名叫centos/7：vagrant box add centos/7 D:\\virtualbox.box 使用vagrant bos list 就可以查看本地的镜像了 镜像有了,接下来根据Vagrantfile文件启动创建虚拟机 来到centos 文件夹,在此目录下打开cmd 窗口,执行vagrant up, 然后打开virtual box,可以看到centos7 创建成功. vagrant 常用命令 vagrant ssh 进入刚才创建的centos7中 vagrant status 查看centos7的状态 vagrant halt 停止/关闭centos7 vagrant destroy 删除centos7 Vagrantfile中也可以写脚本命令，使得centos7更加丰富 但是要注意，修改了Vagrantfile，要想使正常运行的centos7生效，必须使用vagrant reload 至此，使用vagrant+virtualbox搭建centos7完成，后面可以修改Vagrantfile对虚拟机进行相应配置 4. 使用xshell 连接虚拟机 使用虚拟机的默认账号连接 在centos 目录下执行vagrant ssh-config 关注:Hostname Port IdentityFile IP:127.0.0.1 port:2222 用户名:vagrant 密码:vagrant 文件:Identityfile指向的文件private-key 使用root账号登陆 vagrant ssh 进入到虚拟机中 sudo -i 修改配置 vi /etc/ssh/sshd_config 修改 PasswordAuthentication yes 修改密码 使用passwd 修改密码 重启 systemctl restart sshd 重启 5. Vagrantfile通用写法ruby # -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The \"2\" in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don't change it unless you know what # you're doing. Vagrant.configure(\"2\") do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = \"centos/7\" # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \"localhost:8080\" will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network \"forwarded_port\", guest: 80, host: 8080 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access # config.vm.network \"forwarded_port\", guest: 80, host: 8080, host_ip: \"127.0.0.1\" # Create a private network, which allows host-only access to the machine # using a specific IP. # config.vm.network \"private_network\", ip: \"192.168.33.10\" # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. config.vm.network \"public_network\" # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \"../data\", \"/vagrant_data\" # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \"virtualbox\" do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = \"1024\" # end config.vm.provider \"virtualbox\" do |vb| vb.memory = \"4000\" vb.name= \"centos7-01\" vb.cpus= 2 end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. # config.vm.provision \"shell\", inline: &lt;&lt;-SHELL # apt-get update # apt-get install -y apache2 # SHELL end ## 6. `box` 的打包分发 退出虚拟机 `vagrant halt` 打包 `vagrant package --output first-docker-centos7.box` ​ 得到first-docker-centos7.box 将first-docker-centos7.box添加到其他的vagrant环境中 vagrant box add first-docker-centos7 first-docker-centos7.box 得到Vagrantfile vagrant init first-docker-centos7 根据Vagrantfile启动虚拟机 vagrant up [此时可以得到和之前一模一样的环境，但是网络要重新配置] ​ ​","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"rocketmq 部署启动指南-Docker 版","slug":"安装/rocketmq 部署启动指南-Docker 版","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/rocketmq-bu-shu-qi-dong-zhi-nan-docker-ban/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/rocketmq-bu-shu-qi-dong-zhi-nan-docker-ban/","excerpt":"","text":"rocketmq 部署启动指南-Docker 版最近学习使用 rocketmq，需要搭建 rocketmq 服务端，本文主要记录 rocketmq 搭建过程以及这个过程踩到的一些坑。 准备工作在搭建之前，我们需要做一些准备工作，这里我们需要使用 docker 搭建服务，所以需要提前安装 docker。此外，由于 rocketmq 需要部署 broker 与 nameserver ，考虑到分开部署比较麻烦，这里将会使用 docker-compose。 rocketmq 架构图如下: 另外，还需要搭建一个 web 可视化控制台，可以监控 mq 服务状态，以及消息消费情况，这里使用 rocketmq-console，同样该程序也将使用 docker 安装。 部署过程首先我们需要 rocketmq docker 镜像，这里我们可以选择自己制作，直接拉取 git@github.com:apache/rocketmq-docker.git ，然后再制作镜像。 另外还可以直接使用 docker hub 上官方制作的镜像，镜像名： rocketmqinc/rocketmq。 接着创建 mq 配置文件 broker.conf，文件放置到 /opt/rocketmq/conf ，配置如下: brokerClusterName = DefaultCluster brokerName = broker-a brokerId = 0 deleteWhen = 04 fileReservedTime = 48 brokerRole = ASYNC_MASTER flushDiskType = ASYNC_FLUSH # 如果是本地程序调用云主机 mq，这个需要设置成 云主机 IP brokerIP1=10.10.101.80 在创建如下文件夹：/opt/rocketmq/logs，/opt/rocketmq/store，最后创建 docker-compose.yml 文件，配置如下： version: '2' services: namesrv: image: rocketmqinc/rocketmq container_name: rmqnamesrv ports: - 9876:9876 volumes: - /opt/rocketmq/logs:/home/rocketmq/logs - /opt/rocketmq/store:/home/rocketmq/store command: sh mqnamesrv broker: image: rocketmqinc/rocketmq container_name: rmqbroker ports: - 10909:10909 - 10911:10911 - 10912:10912 volumes: - /opt/rocketmq/logs:/home/rocketmq/logs - /opt/rocketmq/store:/home/rocketmq/store - /opt/rocketmq/conf/broker.conf:/opt/rocketmq-4.4.0/conf/broker.conf #command: sh mqbroker -n namesrv:9876 command: sh mqbroker -n namesrv:9876 -c ../conf/broker.conf depends_on: - namesrv environment: - JAVA_HOME=/usr/lib/jvm/jre console: image: styletang/rocketmq-console-ng container_name: rocketmq-console-ng ports: - 8087:8080 depends_on: - namesrv environment: - JAVA_OPTS= -Dlogging.level.root=info -Drocketmq.namesrv.addr=rmqnamesrv:9876 - Dcom.rocketmq.sendMessageWithVIPChannel=false 注意点 这里需要注意 rocketmq broker 与 rokcetmq-console 都需要与 rokcetmq nameserver 连接，需要知道 nameserver ip。使用 docker-compose 之后，上面三个 docker 容器将会一起编排，可以直接使用容器名代替容器 ip，如这里 nameserver 容器名 rmqnamesrv。 配置完成之后，运行 docker-compose up 启动三个容器，启动成功后，访问 ip:8087，查看 mq 外部控制台，如果可以看到以下信息，rocketmq 服务启动成功。 初体验 rocketmq这里将会使用 springboot 快速上手使用 mq，将会使用 rocketmq-spring-boot-starter 模块，pom 配置如下： org.apache.rocketmq rocketmq-spring-boot-starter 2.0.3 消费服务发送方配置如下： ## application.properties rocketmq.name-server=ip:9876 rocketmq.producer.group=my-group 消费服务发送方程序如下： @SpringBootApplication public class ProducerApplication implements CommandLineRunner &amp;#123; @Resource private RocketMQTemplate rocketMQTemplate; public static void main(String[] args)&amp;#123; SpringApplication.run(ProducerApplication.class, args); &amp;#125; public void run(String... args) throws Exception &amp;#123; rocketMQTemplate.convertAndSend(\"test-topic-1\", \"Hello, World!\"); rocketMQTemplate.send(\"test-topic-1\", MessageBuilder.withPayload(\"Hello, World! I'm from spring message\").build()); &amp;#125; &amp;#125; 消息消费方配置如下： ## application.properties rocketmq.name-server=ip:9876 消息消费方运行程序如下： @SpringBootApplication public class ConsumerApplication&amp;#123; public static void main(String[] args)&amp;#123; SpringApplication.run(ConsumerApplication.class, args); &amp;#125; @Slf4j @Service @RocketMQMessageListener(topic = \"test-topic-1\", consumerGroup = \"my-consumer_test-topic-1\") public static class MyConsumer1 implements RocketMQListener&lt;String> &amp;#123; public void onMessage(String message) &amp;#123; log.info(\"received message: &amp;#123;&amp;#125;\", message); &amp;#125; &amp;#125; &amp;#125; 相关问题 消息发送方消息发送异常，异常如图所示：Caused by: org.apache.rocketmq.remoting.exception.RemotingTooMuchRequestException: sendDefaultImpl call timeout。 该异常是由于 brokerip 未设置正确导致，登录 mq 服务控制台，可以查看 broker 配置信息。 上面 192.168.128.3:10911 是 docker 容器 IP，这是一个主机内部 IP。这里需要将 IP 设置为云主机的 IP，需要在 broker.conf 修改 brokerIP1 参数。 mq 控制台无法正常查看 mq 服务信息。 这个问题主要是 nameserver ip 设置错误导致。查看 mq 控制台运维页面，可以看到此时连接的 nameserver 地址信息。 可以看到这里设置的地址为：127.0.0.1:9876。由于这里 mq 控制台使用 docker 容器，容器内直接访问 127.0.0.1:9876 将会访问自己内部，而非宿主机内正确程序。 这里需要在 docker 配置环境变量，配置如下： - JAVA_OPTS= -Dlogging.level.root=info -Drocketmq.namesrv.addr=rmqnamesrv:9876","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"gitlab搭建","slug":"安装/gitlab搭建","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/gitlab-da-jian/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/gitlab-da-jian/","excerpt":"","text":"搭建gitlabhttps://about.gitlab.com/install/#centos-7 1. 说明安装gitlab 的机器至少需要4G的内存, 因为gitlab 比较吃内存. 2. 安装必要的依赖sudo yum install -y curl policycoreutils-python openssh-server sudo systemctl enable sshd sudo systemctl start sshd sudo firewall-cmd --permanent --add-service=http sudo systemctl reload firewalld 3. 如果想要发送邮件, 就执行sudo yum install postfix sudo systemctl enable postfix sudo systemctl start postfix 4. 添加gitlab的仓库地址curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh | sudo bash 这个下载仓库可能速度会很慢,此时可以使用国内的仓库地址 新建文件 /etc/yum.repos.d/gitlab-ce.repo 内容为 [gitlab-ce] name=Gitlab CE Repository baseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/ gpgcheck=0 enabled=1 5. 设置gitlab的域名和安装gitlabsudo EXTERNAL_URL=\"https://gitlab.xxx.com\" yum install -y gitlab-ee 如果用的是国内仓库地址，则执行以下命令，其实区别就是ee和ce版 sudo EXTERNAL_URL=\"https://gitlab.xxx.com\" yum install -y gitlab-ce 此时要么买一个域名，要么在本地的hosts文件中设置一下安装gitlab服务器的ip地址https://gitlab.xxx.com 假如不想设置域名,可以直接安装 yum install -y gitlab-ee 6. 重新configure如果没有成功,可以运行 gitlab-ctl reconfigure 7.查看gitlab的运行情况gitlab-ctl status 可以查看 运行gitlab 服务所需要的进程 8.访问浏览器输入 https://gitlab.xxx.com , 此时需要修改root 账号的密码 9. 配置已经安装好的gitlabvim /etc/gitlab/gitlab.rb 修改完成之后一定要 gitlab-ctl reconfigure","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"docker安装nginx","slug":"安装/docker安装nginx","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/docker-an-zhuang-nginx/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/docker-an-zhuang-nginx/","excerpt":"","text":"docker安装nginx 随便启动一个nginx实例，只是为了复制出配置 docker run -p80:80 --name nginx -d nginx:1.10 将容器内的配置文件拷贝到/mydata/nginx/conf/ 下 mkdir -p /mydata/nginx/html mkdir -p /mydata/nginx/logs mkdir -p /mydata/nginx/conf docker container cp nginx:/etc/nginx/* /mydata/nginx/conf/ #由于拷贝完成后会在config中存在一个nginx文件夹，所以需要将它的内容移动到conf中 mv /mydata/nginx/conf/nginx/* /mydata/nginx/conf/ rm -rf /mydata/nginx/conf/nginx 终止原容器： docker stop nginx 执行命令删除原容器： docker rm nginx 创建新的Nginx，执行以下命令 docker run -p 80:80 --name nginx \\ -v /mydata/nginx/html:/usr/share/nginx/html \\ -v /mydata/nginx/logs:/var/log/nginx \\ -v /mydata/nginx/conf/:/etc/nginx \\ -d nginx:1.10 设置开机启动nginx docker update nginx --restart=always 创建“/mydata/nginx/html/index.html”文件，测试是否能够正常访问 echo &#39;&lt;h2&gt;hello nginx!&lt;/h2&gt;&#39; &gt;index.html 访问：http://ngix所在主机的IP:80/index.html","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"docker安装可道云私有网盘","slug":"工具/docker安装可道云私有网盘","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/gong-ju/docker-an-zhuang-ke-dao-yun-si-you-wang-pan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/gong-ju/docker-an-zhuang-ke-dao-yun-si-you-wang-pan/","excerpt":"","text":"docker安装可道云私有网盘1. 镜像查找我们可以在https://dashboard.daocloud.io/packages/50846266-dc26-473e-9725-4e5e2d8c7534 中找见 KodExplorer docker的docker 最新镜像 2. 容器启动docker run -d -p 8888:80 daocloud.io/huiqiang/kod:master 或者 docker run -d -p 8888:80 registry.cn-hangzhou.aliyuncs.com/l_third_party/kod:master 3. 页面访问浏览器输入: localhost:8888,然后设置管理员账号,就可以了. 4. app端使用我们可以在应用市场搜索 可道云基础版,然后输入上面的地址和用户的账号密码即可以登录了. 这里分享一个基础班, 可以配合我的镜像的版本使用 链接：https://pan.baidu.com/s/1MZKjkN69ERiR6-fBMZ0yfg 提取码：3nr1","categories":[{"name":"工具","slug":"工具","permalink":"https://rainsoil.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"工具/工具","permalink":"https://rainsoil.github.io/categories/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"}],"tags":[]},{"title":"Swagger使用说明","slug":"工具/swagger/Swagger使用说明","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/gong-ju/swagger/swagger-shi-yong-shuo-ming/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/gong-ju/swagger/swagger-shi-yong-shuo-ming/","excerpt":"","text":"Swagger的基本使用Swagger 注解说明springfox 把对接口的描述都通过注解的方式来完成, 主要包括以下几种注解: 数据模型注解 @ApiModel: 实体描述 @ApiModelProperty: 实体属性描述 接口注解 @ApiOperation:接口描述 @ApiIgnore 忽略此接口 控制器注解 @Api: 控制器描述 输入参数注解 @ApiImplicitParams: 接口多个参数 @ApiImplicitParam: 接口单个参数 @ApiParam 单个参数描述 响应数据注解 @ResponseHeader: 响应值header @ApiResponses: 响应值集 @ApiResponse : 单个响应值 1.数据模型注解说明开发过程中,对于MVC模式的接口,使用M(Model)进行数据通信,因此, 需要对此数据模型进行有效的描述。 对应的注解有: @ApiModel: 实体描述 @ApiModelProperty: 实体字段描述 1. @ApiModel 注解说明 属性名称 数据类型 默认值 描述 value String 类名 为模型提供备用名称 description String “” 提供详细的类描述 parent Class&lt;?&gt; parent Void.class 为模型提供父类以允许描述继承关系 discriminatory String “” 支持模型继承和多态，使用鉴别器的字段的名称，可以断言需要使用哪个子类型 subTypes Class&lt;?&gt;[] {} 从此模型继承的子类型数组 reference String “” 指定对应类型定义的引用，覆盖指定的任何其他元数据 下面为 @ApiModelProperty 的使用说明 注解属性 类型 默认值 描述 value String “” 字段说明 name String “” 字段说明 dataType String “” 字段类型 required boolean false 是否为必填 example String “” 举例说明 hidden boolean false 是否在文档中隐藏此字段 allowEmptyValue boolean false 是否允许为空 allowableValues String “” 该字段允许的值 本实例中, 用User 类使用注解进行描述: @ApiModel( description = \"用户信息\") @Data public class User &amp;#123; @ApiModelProperty(value = \"id\", required = true, example = \"1\") private Long id; @ApiModelProperty(value = \"姓名\", required = true, example = \"张三\") private String name; @ApiModelProperty(value = \"年龄\", example = \"10\") private Integer age; @ApiModelProperty(value = \"密码\", hidden = true, required = true) private String passWord; &amp;#125; 使用这些注解后, 显示的文档如下: 2. 接口输入参数注解说明在介绍Swagger 的接口输入参数说明之前, 有必要对SpringMvc的接口参数有一个清晰的了解. 我们知道SpringMvc 是通过@RequestMapping 把方法与请求的URL 对应起来, 而调用接口方法时需要将参数传给控制器. 一般来说, SpringMVC 的参数传递包括以下几种: 无注解参数 @RequestParam 注解参数 数组参数 JSON 对象参数 REST风格参数 3. Swagger 输入参数注解说明对于上面提供的SpringMvc参数,springfox 已经做了自动处理, 在 swagger-ui 文档中显示的时候, 也会根据参数类型进行显示. 在 swagger 中, 参数类型分为: path: 以地址的形式提交数据, 根据id 查询用户的接口就是这种形式传参 query：Query String的方式传参, 对应无注解和 @RequestParam 注解参数 header: 请求头(header) 中的参数 form: 以Form 表单的形式提交, 比如上传文件, 属于此类. body: 以JSON 方式传参. 在描述输入参数的时候, swagger 有以下注解: @ApiImplicitParams 描述接口的参数集 @ApiImplicitParam 描述接口单个参数, 与 @ApiImplicitParams 组合使用 @ApiParam 描述单个参数, 可选 其中, @ApiParam 与单个参数一起用, @ApiImplicitParam 使用在接口描述中,两者的属性基本一致, @ApiImplicitParam的属性如下所示： 注解属性 描述 paramType 查询参数类型, 表示参数在哪里, 可取值:path、query、header、form、body dataType 参数的数据类型, 只作为标志说明, 并没有实际验证. 可按照实际类型填写, 比如String、User name 参数的名字 value 参数意义的描述 required 是否必填 allowMultiple 是否有多个, 在使用JSON 数组对象时使用. example 数据示例 示例如下: @ApiOperation(value = \"添加多个用户\", notes = \"使用JSON数组的方式添加\") @ApiImplicitParams(@ApiImplicitParam(name = \"user\", value = \"用户数组\", required = true, dataType = \"User\", allowMultiple = true)) @PostMapping(\"/users\") public void addUsers(@RequestBody List&lt;User> users) &amp;#123; &amp;#125; 4.接口响应数据注解说明对于使用了@RestController 注解的控制器, SpringMVC 会自动将返回的数据转换为JSON 数据. 对于响应消息, swagger 提供了默认的401、403、404的响应消息, 也可以自己针对接口进行指定, 有以下注解可以使用. @ApiResponses 响应消息集 @ApiResponses 响应消息, 描述一个错误的响应信息, 与 @ApiResponses 一起使用 @ResponseHeader 响应头设置 @ApiResponses 属性描述 属性 描述 code 错误码 message 错误信息 response 抛出异常的类 @ApiResponses(@ApiResponse(code = 401, message = \"错误信息\", response = NullPointerException.class)) @PostMapping(\"/users\") public void addUsers(@RequestBody List&lt;User> users) &amp;#123; &amp;#125; 5. 接口描述注解说明@API 接口类说明注解 用在类上, 说明该类的作用, 可以标记一个Controller 类作为swagger 文档资源, 使用方式: 使用@Api(value = \"/user\", description = \"用户\", tags = \"用户\") @RestController @RequestMapping(\"user\") public class UserController &amp;#123; 属性说明 属性 描述 vaue url的路径值 tags 标签, 如果设置这个值, value 的值就会被覆盖 description 对API 资源的描述 basePath 基本路径, 不需要配置 position 如果配置多个API， 想改变显示的顺序位置 produces For example, “application/json, application/xml” consumes For example, “application/json, application/xml” protocols Possible values: http, https, ws, wss. authorizations 高级特性认证时配置 hidden 配置为true 将在文档中隐藏 @ApiOperation 接口描述注解 配置在方法上, 说明方法的作用, 每一个url 资源的定义. 使用示例 @ApiOperation( notes = \"根据id查询用户信息\", response = User.class) public User user() &amp;#123; return new User(); &amp;#125; 属性介绍 属性 描述 value url的路径值 tags 如果设置这个值, value 的值就会被隐藏 description 对api资源的介绍 basePath 基本路径, 可以不设置 position 如果设置多个API 想改变显示的顺序位置 produces For example, “application/json, application/xml” consumes For example, “application/json, application/xml” protocols Possible values: http, https, ws, wss. authorizations 高级特性认证时配置 hidden 配置为true 将在文档中隐藏 response 返回的对象 responseContainer 这些对象是有效的 “List”, “Set” or “Map”.，其他无效 httpMethod “GET”, “HEAD”, “POST”, “PUT”, “DELETE”, “OPTIONS” and “PATCH” code http状态码, 默认为200 extensions 扩展属性 @ApiIgnore添加此注解的接口, swagger 在扫描的时候会忽略 6. 响应头注解@ResponseHeader 响应由设置 示例 @ResponseHeader(name = \"token\",description = \"token\") public User user() &amp;#123; return new User(); &amp;#125; 属性描述 属性 描述 name 响应头名称 description 头介绍 response 默认响应类Void responseContainer 参考ApiOperation中配置 接口认证对于前后端分离的项目, 现在很多采用jwt的认证(属于Bearer认证),需要先获取token, 然后在调用token 的时候, 添加类似 Authorization: Bearer &lt;token&gt; 的请求头来对接口进行认证, 针对这种方式, 在swgger 中有以下三种方式来实现. 1. 添加接口认证参数针对需要认证的接口, 直接使用 @ApiImplicitParam, 其中参数 ParamType=header , 如下: @ApiImplicitParam(name = \"Authorization\", value = \"token，格式: Bearer &amp;lttoken&amp;gt\", required = false, dataType = \"String\",paramType = \"header\") 这种方式的缺点是, 针对每一个接口,都需要添加这个参数描述, 而描述都是一样的, 重复工作. 2. 添加全局接口参数swagger 中, 方法 globalOperationParameters 可以设置全局的参数 //全局header参数 ParameterBuilder tokenPar = new ParameterBuilder(); List&lt;Parameter> pars = new ArrayList&lt;Parameter>(); tokenPar.name(\"Authorization\").description(\"token令牌\") .modelRef(new ModelRef(\"string\")) .parameterType(\"header\") .required(true).build(); pars.add(tokenPar.build()); docket.globalOperationParameters(pars); 这种方式缺点也明显, 由于设置了全局参数, 则所有接口都需要此参数, 若某些接口不需要, 则需要进行特殊处理. 3. 添加安全认证上下文设置认证模式, 并使用正则对需要认证的接口进行筛选, 这样swagger 界面提供统一的认证界面, 如下: docket.securitySchemes(securitySchemes()) .securityContexts(securityContexts()); ...//省略 private List&lt;ApiKey> securitySchemes() &amp;#123; return Lists.newArrayList( new ApiKey(\"Authorization\", \"Authorization\", \"header\")); &amp;#125; private List&lt;SecurityContext> securityContexts() &amp;#123; return Lists.newArrayList( SecurityContext.builder() .securityReferences(defaultAuth()) //正则式过滤,此处是所有非login开头的接口都需要认证 .forPaths(PathSelectors.regex(\"^(?!login).*$\")) .build() ); &amp;#125; List&lt;SecurityReference> defaultAuth() &amp;#123; AuthorizationScope authorizationScope = new AuthorizationScope(\"global\", \"认证权限\"); return Lists.newArrayList( new SecurityReference(\"Authorization\", new AuthorizationScope[]&amp;#123;authorizationScope&amp;#125;)); &amp;#125;","categories":[{"name":"swagger","slug":"swagger","permalink":"https://rainsoil.github.io/categories/swagger/"},{"name":"工具","slug":"swagger/工具","permalink":"https://rainsoil.github.io/categories/swagger/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"swagger/工具/工具","permalink":"https://rainsoil.github.io/categories/swagger/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"},{"name":"swagger","slug":"swagger/工具/工具/swagger","permalink":"https://rainsoil.github.io/categories/swagger/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/swagger/"}],"tags":[]},{"title":"Hexo实现Hexo自动添加Front-matter、部署","slug":"工具/hexo/Hexo实现Hexo自动添加Front-matter、部署","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/gong-ju/hexo/hexo-shi-xian-hexo-zi-dong-tian-jia-front-matter-bu-shu/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/gong-ju/hexo/hexo-shi-xian-hexo-zi-dong-tian-jia-front-matter-bu-shu/","excerpt":"","text":"实现hexo的自动添加Front-matter和部署背景我的笔记是存在gitee上的, 分类为目录名字.会有多层目录. 但是要把这些笔记转到hexo上的话, 有几个问题: 首先, hexo 是不支持多层目录结构的 第二,hexo 需要在文章头上添加 Front-matter的 第三, 每次我提交了笔记代码,还需要去服务器上执行一下 hexo的重新编译部署,比较麻烦 基于上面的这几个问题,我基于脚本和python 实现了自动添加Front-matter 和部署 自动添加Front-matterhexoFile.py #!/usr/bin/python3 import os; import shutil; import time; import datetime; # tag 列表 def alltagLists(): tagList = []; tagList.append(\"Hexo\"); tagList.append(\"mybatis\"); tagList.append(\"前端\"); tagList.append(\"后端\"); tagList.append(\"javaScript\"); tagList.append(\"Github\"); tagList.append(\"架构\"); tagList.append(\"代码规范\"); tagList.append(\"面试\"); tagList.append(\"算法\"); tagList.append(\"Android\"); tagList.append(\"CSS\"); tagList.append(\"程序员\"); tagList.append(\"Vue.js\"); tagList.append(\"java\"); tagList.append(\"Node.js\"); tagList.append(\"数据库\"); tagList.append(\"设计\"); tagList.append(\"设计模式\"); tagList.append(\"前端框架\"); tagList.append(\"HTML\"); tagList.append(\"开源\"); tagList.append(\"产品\"); tagList.append(\"Linux\"); tagList.append(\"React.js\"); tagList.append(\"Git\"); tagList.append(\"Python\"); tagList.append(\"IOS\"); tagList.append(\"人工智能\"); tagList.append(\"Webpack\"); tagList.append(\"全栈\"); tagList.append(\"微信小程序\"); tagList.append(\"微信\"); tagList.append(\"Mysql\"); tagList.append(\"Google\"); tagList.append(\"HTTP\"); tagList.append(\"正则表达式\"); tagList.append(\"机器学习\"); tagList.append(\"黑客\"); tagList.append(\"JQuery\"); tagList.append(\"响应式设计\"); tagList.append(\"APP\"); tagList.append(\"创业\"); tagList.append(\"Chrome\"); tagList.append(\"Nginx\"); tagList.append(\"编程语言\"); tagList.append(\"命令行\"); tagList.append(\"产品经理\"); tagList.append(\"Docker\"); tagList.append(\"Redis\"); tagList.append(\"Mac\"); tagList.append(\"Angular.js\"); tagList.append(\"React Native\"); tagList.append(\"Bootstrap\"); tagList.append(\"Apple\"); tagList.append(\"图片资源\"); tagList.append(\"Photoshop\"); tagList.append(\"PHP\"); tagList.append(\"API\"); tagList.append(\"设计师\"); tagList.append(\"数据挖掘\"); tagList.append(\"Sublime Text\"); tagList.append(\"操作系统\"); tagList.append(\"gradle\"); tagList.append(\"阿里巴巴\"); tagList.append(\"Mongo DB\"); tagList.append(\"数据可视化\"); tagList.append(\"安全\"); tagList.append(\"招聘\"); tagList.append(\"Swift\"); tagList.append(\"Go\"); tagList.append(\"MVVC\"); tagList.append(\"Vuex\"); tagList.append(\"ReJava\"); tagList.append(\"Xcode\"); tagList.append(\"敏捷开发\"); tagList.append(\"Markdown\"); tagList.append(\"动效\"); tagList.append(\"运维\"); tagList.append(\"linux\"); tagList.append(\"字体\"); tagList.append(\"运营\"); tagList.append(\"云计算\"); tagList.append(\"物联网\"); tagList.append(\"Canvas\"); tagList.append(\"Icon\"); tagList.append(\"Spring\"); tagList.append(\"深度学习\"); tagList.append(\"爬虫\"); tagList.append(\"Objective-C\"); tagList.append(\"C++\"); tagList.append(\"虚拟现实\"); tagList.append(\"HTTPS\"); tagList.append(\"Eclipse\"); tagList.append(\"Debug\"); tagList.append(\"电子书\"); tagList.append(\"Ubuntu\"); tagList.append(\"NPM\"); tagList.append(\"测试\"); tagList.append(\"JSON\"); tagList.append(\"微服务\"); tagList.append(\"Ajax\"); tagList.append(\"DOM\"); tagList.append(\"Facebook\"); tagList.append(\"源码\"); tagList.append(\"VIM\"); tagList.append(\"Apache\"); tagList.append(\"TypeScript\"); tagList.append(\"游戏\"); tagList.append(\"Maven\"); tagList.append(\"SVG\"); tagList.append(\"Kotlin\"); tagList.append(\"Window\"); tagList.append(\"SEO\"); tagList.append(\"负载均衡\"); tagList.append(\"区块链\"); tagList.append(\"函数式编程\"); tagList.append(\"Gulp\"); tagList.append(\"SqlLite\"); tagList.append(\"浏览器\"); tagList.append(\"SQL\"); tagList.append(\"APK\"); tagList.append(\"Firefox\"); tagList.append(\"Flutter\"); tagList.append(\"Atom\"); tagList.append(\"Promise\"); tagList.append(\"Hadoop\"); tagList.append(\"嵌入式\"); tagList.append(\"机器人\"); tagList.append(\"IDEA\"); tagList.append(\"IntelliJ IDEA\"); tagList.append(\"Spring Boot\"); tagList.append(\"JVM\"); return tagList; def matchTags(fileName, fileCategories, content): matchTagList = []; tagLists = alltagLists(); for tag in tagLists: if tag.lower() in fileName.lower(): matchTagList.append(tag); if tag.lower() in fileCategories.lower(): matchTagList.append(tag); if tag.lower() in content.lower(): matchTagList.append(tag); matchTagList = list(&amp;#123;&amp;#125;.fromkeys(matchTagList).keys()) return matchTagList; def copyFile(sourceDir, targetDir): if os.path.exists(targetDir): shutil.rmtree(targetDir); shutil.copytree(sourceDir, targetDir); ## 获取文件的创建时间 def getFileCreateTime(file): createTime = os.path.getctime(file); timeStruct = time.localtime(createTime); return time.strftime('%Y-%m-%d %H:%M:%S', timeStruct); # 遍历文件夹下的所有文件,并把结果存到一个列表中 def listFile(dir, fileList): newDir = dir; if os.path.isfile(dir): if os.path.basename(dir).endswith(\"md\"): fileList.append(dir); ## 若只是想返回文件名,使用这个 # fileList.append(os.path.basename(dir)); elif os.path.isdir(dir): for s in os.listdir(dir): ## 如果需要忽略某些文件夹,使用一下代码 if s == '.git': continue; newDir = os.path.join(dir, s); listFile(newDir, fileList); return fileList; #########################开始干活############################# # 列出所有的文件,将所有的组装成hexo支持的文件 sourceDir: str = \"/web/hexo/note\"; hexoDir: str = \"/web/hexo/hexo_blog/blog/source/_posts\"; ## 清空hexo下的所有文件 for hexiFile in os.listdir(hexoDir): print(hexiFile) os.remove(os.path.join(hexoDir,hexiFile)); # copyFile(sourceDir, targetDir); fileList = []; listFile(sourceDir, fileList); for file in fileList: frontMatter = \"---\" + \"\\n\"; ## 分类 categories = []; fileName = os.path.basename(file); fileCategorieStr = os.path.abspath(file).replace(\"\\\\\", \"/\").replace(sourceDir, \"\").replace(fileName, \"\"); fileCategories = fileCategorieStr.split(\"/\"); if len(fileCategories) > 0: for fileCategorie in fileCategories: if len(fileCategorie) > 0: categories.append(fileCategorie); # 添加标题 frontMatter = frontMatter + \"title: \" + fileName.replace(\".md\", \"\") + \"\\n\"; # 添加分类 frontMatter = frontMatter + \"categories:\" + \"\\n\"; for ca in categories: frontMatter = frontMatter + \"- \" + ca + \"\\n\"; # # ## 进行文件拼接,并且移动文件到hexo文件夹中 sourcefile = open(os.path.abspath(file), 'r+', encoding='utf-8'); ## 添加标签 content = sourcefile.read(); tags = matchTags(fileName, fileCategorieStr,content) frontMatter = frontMatter + \"tags: \" + \"\\n\"; for t in tags: frontMatter = frontMatter + \"- \" + t + \"\\n\"; ## 文件创建时间 createTime = getFileCreateTime(file); frontMatter = frontMatter + \"date: \"+createTime + \"\\n\"; frontMatter = frontMatter + \"---\" + \"\\n\"; print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \"---------fileName: \" + file + \"\\n\" + \"-----------------Front-matter----------------------\" + \"\\n\" + frontMatter + \"\\n\" + \"------------------end---------------------\") targetFile = open(hexoDir + \"/\" + os.path.basename(file).replace(' ',\"\"), 'w', encoding='utf-8'); targetFile.write(frontMatter + content); sourcefile.close(); targetFile.close(); 分类: 取得是文件夹名称 标签: 这里准备了一堆标签, 用文件名、分类名、和文章内容进行匹配 文章时间: 取得是文件的创建时间 然后最后将所有的文件都写入到 hexo的source/_posts 目录中 自动部署我这里先拉去我的笔记的git代码.然后执行上面的 hexoFile.py 脚本实现 笔记的自动分类到hexo目录下,然后实现hexo的自动编译 hexorun.sh ## 先拉取笔记的代码 cd ../note/ git pull && cd /web/hexo/hexo_blog pwd python3 hexoFile.py && cd blog/ && hexo clean && hexo g 最后使用python的定时任务.定时部署 schedule.py import time import os import sched # 初始化sched模块的scheduler类 # 第一个参数是一个可以返回时间戳的函数，第二个参数可以在定时未到达之前阻塞。 schedule = sched.scheduler(time.time, time.sleep) # 被周期性调度触发的函数 def execute_command(cmd, inc): print('执行主程序') ''''' 终端上显示当前计算机的连接情况 ''' os.system(cmd) schedule.enter(inc, 0, execute_command, (cmd, inc)) def main(cmd, inc=60): # enter四个参数分别为：间隔事件、优先级（用于同时间到达的两个事件同时执行时定序）、被调用触发的函数， # 给该触发函数的参数（tuple形式） schedule.enter(0, 0, execute_command, (cmd, inc)) schedule.run() # 每60秒查看下网络连接情况 if __name__ == '__main__': main(\"sh hexorun.sh\", 14400) 使用 nohup python3 schedule.py &amp; 就可以实现自动部署了","categories":[{"name":"hexo","slug":"hexo","permalink":"https://rainsoil.github.io/categories/hexo/"},{"name":"工具","slug":"hexo/工具","permalink":"https://rainsoil.github.io/categories/hexo/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"hexo/工具/工具","permalink":"https://rainsoil.github.io/categories/hexo/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"},{"name":"hexo","slug":"hexo/工具/工具/hexo","permalink":"https://rainsoil.github.io/categories/hexo/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/hexo/"}],"tags":[]},{"title":"如何借助GitHub搭建属于自己的maven仓库","slug":"工具/github/如何借助GitHub搭建属于自己的maven仓库","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/gong-ju/github/ru-he-jie-zhu-github-da-jian-shu-yu-zi-ji-de-maven-cang-ku/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/gong-ju/github/ru-he-jie-zhu-github-da-jian-shu-yu-zi-ji-de-maven-cang-ku/","excerpt":"","text":"借助GitHub搭建属于自己的maven仓库I. 背景在Github上也写了不少的项目了，然后经常遇到的一个问题就是，很多自己写的项目，希望在另外一个项目中使用时，只能把这个项目下载下来，相当之不方便 因为大多数的java后端项目都是基于maven管理依赖的，所以就希望能有一个公共的maven仓库，可以把自己的项目扔进去，然后再应用就方便很多了 基于此，就有了本文这个教程了 II. 实现步骤1. github仓库建立新建一个repository的前提是有github帐号，默认看到本文的是有帐号的 首先是在github上新建一个仓库，命令随意，如我新建项目为 github.com/liuyueyi/ma… 2. 配置本地仓库本地指定一个目录，新建文件夹 maven-repository, 如我的本地配置如下 ## 进入目录 cd /Users/yihui/GitHub ## 新建目录 mkdir maven-repository; cd maven-repository ## 新建repository目录 # 这个目录下面就是存放我们deploy的项目相关信息 # 也就是说我们项目deploy指定的目录，就是这里 mkdir repository ## 新增一个readme文档 # 保持良好的习惯，每个项目都有一个说明文档 touch README.md 复制代码 这个目录结构为什么是这样的？ 我们直接看maven配置中默认的目录结构，同样拷贝一份出来而已 3. 仓库关联将本地的仓库和远程的github仓库关联起来，执行的命令也比较简单了 git add . git commit -m &#39;first comit&#39; git remote add origin https://github.com/liuyueyi/maven-repository.git git push -u origin master 复制代码 接着就是进行分支管理了 约定将项目中的snapshot版，deploy到仓库的 snapshot分支上 约定将项目中的release版，deploy到仓库的 release分支上 master分支管理所有的版本 所以需要新创建两个分支 ## 创建snapshot分支 git checkout -b snapshot git push origin snapshot # 也可以使用 git branch snapshot , 我通常用上面哪个，创建并切换分支 ## 创建release分支 git checkout -b release git push origin release 复制代码 4. 项目deploy项目的deploy，就需要主动的指定一下deploy的地址了，所以我们的deploy命令如下 ## deploy项目到本地仓库 mvn clean deploy -Dmaven.test.skip -DaltDeploymentRepository=self-mvn-repo::default::file:/Users/yihui/GitHub/maven-repository/repository 复制代码 上面的命令就比较常见了，主要需要注意的是file后面的参数，根据自己前面设置的本地仓库目录来进行替换 5. deploy脚本每次进行上面一大串的命令，不太好记，特别是不同的版本deploy到不同的分支上，主动去切换分支并上传，也挺麻烦，所以就有必要写一个deploy的脚本了 由于shell实在是不太会写，所以下面的脚本只能以凑合能用来说了 #!/bin/bash if [ $# != 1 ];then echo &#39;deploy argument [snapshot(s for short) | release(r for short) ] needed!&#39; exit 0 fi ## deploy参数，snapshot 表示快照包，简写为s， release表示正式包，简写为r arg=$1 DEPLOY_PATH=/Users/yihui/GitHub/maven-repository/ CURRENT_PATH=`pwd` deployFunc()&#123; br=$1 ## 快照包发布 cd $DEPLOY_PATH ## 切换对应分支 git checkout $br cd $CURRENT_PATH # 开始deploy mvn clean deploy -Dmaven.test.skip -DaltDeploymentRepository=self-mvn-repo::default::file:/Users/yihui/GitHub/maven-repository/repository # deploy 完成,提交 cd $DEPLOY_PATH git add -am &#39;deploy&#39; git push origin $br # 合并master分支 git checkout master git merge $br git commit -am &#39;merge&#39; git push origin master cd $CURRENT_PATH &#125; if [ $arg = &#39;snapshot&#39; ] || [ $arg = &#39;s&#39; ];then ## 快照包发布 deployFunc snapshot elif [ $arg = &#39;release&#39; ] || [ $arg = &#39;r&#39; ];then ## 正式包发布 deployFunc release else echo &#39;argument should be snapshot(s for short) or release(r for short). like: `sh deploy.sh snapshot` or `sh deploy.sh s`&#39; fi 复制代码 将上面的脚本，考本到项目的根目录下，然后执行 chmod +x deploy.sh ## 发布快照包 ./deploy.sh s # sh deploy.sh snapshot 也可以 ## 发布正式包 ./deploy.sh r 复制代码 基于此，整个步骤完成 III. 使用上面仓库的基本搭建算是ok了，然后就是使用了，maven的pom文件应该怎么配置呢？ 首先是添加仓库地址 添加仓库 如果要区分snapshot和release的话，如下配置 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;yihui-maven-repo-snap&lt;/id&gt; &lt;url&gt;https://raw.githubusercontent.com/liuyueyi/maven-repository/snapshot/repository&lt;/url&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;yihui-maven-repo-release&lt;/id&gt; &lt;url&gt;https://raw.githubusercontent.com/liuyueyi/maven-repository/release/repository&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 复制代码 如果不care的话，直接添加下面的即可 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;yihui-maven-repo&lt;/id&gt; &lt;url&gt;https://raw.githubusercontent.com/liuyueyi/maven-repository/master/repository&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 复制代码 仓库配置完毕之后，直接引入依赖即可，如依赖我的Quick-Alarm包，就可以添加下面的依赖配置 &lt;dependency&gt; &lt;groupId&gt;com.hust.hui.alarm&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; 复制代码 IV. 其他","categories":[{"name":"github","slug":"github","permalink":"https://rainsoil.github.io/categories/github/"},{"name":"工具","slug":"github/工具","permalink":"https://rainsoil.github.io/categories/github/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"github/工具/工具","permalink":"https://rainsoil.github.io/categories/github/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"},{"name":"github","slug":"github/工具/工具/github","permalink":"https://rainsoil.github.io/categories/github/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/github/"}],"tags":[]},{"title":"docker和jennkins部署springcloud dubbo应用","slug":"安装/docker和jennkins部署springcloud dubbo应用","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/docker-he-jennkins-bu-shu-springcloud-dubbo-ying-yong/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/docker-he-jennkins-bu-shu-springcloud-dubbo-ying-yong/","excerpt":"","text":"基于docker和jenkins实现springboot dubbo的自动化部署1. 容器镜像仓库我们这里使用的是阿里的容器镜像仓库([https://cr.console.aliyun.com/]:) 1.1 创建镜像仓库 我们这里填好仓库名称(只能小写), 然后下一步 点击创建镜像即可. 1.2 获取仓库地址 我们点击这里的管理, 复制上面的地址即可. 这就是我们创建的仓库地址 1.3 获取访问凭证我们上传镜像的时候, 需要一个上传的密码(不是阿里云的登陆密码). 我这里为了麻烦获取一个固定的密码 2 .上传jar到docker仓库2.1 编写Dockerfile文件FROM openjdk:8-jdk-alpine MAINTAINER luyanan VOLUME /tmp COPY target/app.jar app.jar ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"] 2.2 配置maven的pom文件我们这里使用的是docker-maven-plugin 插件 &lt;properties> &lt;!-- 这里配置的是仓库地址-->> &lt;docker.repository>registry.cn-hangzhou.aliyuncs.com/luyanan/fieldarmy-web&lt;/docker.repository> &lt;docker.maven.plugin.version>0.4.3&lt;/docker.maven.plugin.version> &lt;/properties> &lt;build> &lt;finalName>app&lt;/finalName> &lt;!--&lt;finalName>$&amp;#123;project.artifactId&amp;#125;&lt;/finalName>--> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>$&amp;#123;java.version&amp;#125;&lt;/source> &lt;target>$&amp;#123;java.version&amp;#125;&lt;/target> &lt;/configuration> &lt;/plugin> &lt;/plugins> &lt;pluginManagement> &lt;plugins> &lt;plugin> &lt;groupId>com.spotify&lt;/groupId> &lt;artifactId>docker-maven-plugin&lt;/artifactId> &lt;version>$&amp;#123;docker.maven.plugin.version&amp;#125;&lt;/version> &lt;configuration> &lt;!-- build 时，指定 –no-cache 不使用缓存 --> &lt;noCache>true&lt;/noCache> &lt;!-- build 时，指定 –rm=true 即 build 完成后删除中间容器 --> &lt;!--&lt;rm>true&lt;/rm>--> &lt;!--build 完成后 push 镜像 --> &lt;pushImage>true&lt;/pushImage> &lt;!--设置镜像的名字为镜像仓库地址--> &lt;imageName>$&amp;#123;docker.repository&amp;#125;&lt;/imageName> &lt;!--设置镜像的tag为项目的maven构建的jar的名字和版本号--> &lt;imageTags> &lt;!--&lt;imageTag>$&amp;#123;project.build.finalName&amp;#125;V$&amp;#123;project.version&amp;#125;&lt;/imageTag>--> &lt;!--&lt;imageTag>latest&lt;/imageTag>--> &lt;imageTag>$&amp;#123;project.version&amp;#125;&lt;/imageTag> &lt;/imageTags> &lt;!--存放Dockerfile的文件夹--> &lt;dockerDirectory>$&amp;#123;project.basedir&amp;#125;&lt;/dockerDirectory> &lt;!--maven settings中配置的服务的id--> &lt;serverId>docker-registry&lt;/serverId> &lt;!--docker仓库的地址--> &lt;registryUrl>registry.cn-hangzhou.aliyuncs.com&lt;/registryUrl> &lt;/configuration> &lt;/plugin> &lt;/plugins> &lt;/pluginManagement> &lt;/build> 2.2 配置上传的凭证需要在maven的settings.xml文件中配置 在中配置 &lt;server> &lt;id>docker-registry&lt;/id> &lt;username>阿里云的账号&lt;/username> &lt;password>上面获取的访问凭证&lt;/password> &lt;configuration> &lt;email>邮箱地址&lt;/email> &lt;/configuration> &lt;/server> 2.3 测试打包在项目目录下执行 mvn clean package -Dmaven.test.skip=true &amp;&amp; mvn docker:build &amp;&amp; mvn docker:removeImage 等执行成功后, 在阿里云的镜像仓库 你就可以看到自己上传的镜像了 3. 使用jenkins 部署镜像这里不讲部署和配置jenkins的过程 需要用到的jenkins插件 SSH plugin 3.1创建项目 我们创建这么一个项目 勾选这个,设置为多参数 参数为: name: 镜像的名称 command: 启动后执行的命令 repository: 仓库的地址 tag: 标签 port:端口映射 operate 执行的操作,分为: start: 启动容器 stop: 停止容器 restart: 重启容器(不会重新拉取镜像) update: 重启拉取镜像,重新启动容器. 3.2 执行脚本我们在Build 中选择 SSH site需要去 中配置 里面执行的脚本 if [ ! -d \"/web/$&amp;#123;name&amp;#125;\" ]; then mkdir -p /web/$&amp;#123;name&amp;#125; fi cd /web/$&amp;#123;name&amp;#125; ## 是否存在启动脚本 if [ -f \"./docker-composeRun.sh\" ];then echo \"file exist\" else echo \"file not exist\" wget https://blog-1253651602.cos.ap-beijing.myqcloud.com/software/docker-composeRun.sh chmod +x ./docker-composeRun.sh fi ## 是否存在docker-compose if [ -f \"./docker-compose.yml\" ];then echo \"file exist\" else echo \"file not exist\" wget https://blog-1253651602.cos.ap-beijing.myqcloud.com/software/docker-compose.yml fi sh ./docker-composeRun.sh -n $&amp;#123;name&amp;#125; -p $&amp;#123;port&amp;#125; -c $&amp;#123;command&amp;#125; -r $&amp;#123;repository&amp;#125; -t $&amp;#123;tag&amp;#125; -o \"$&amp;#123;operate&amp;#125;\" #sh docker-composeRun.sh -n fieldarmy-blog-single -p 8081:8081 -c '--spring.profiles.active=dev' -t latest -r registry.cn-hangzhou.aliyuncs.com/luyanan/ -o stop 脚本的意思是在目标服务器的/web目录下创建 上面参数中执行的 name的目录,然后会检测目录下是否存在 docker-compose.yml文件和docker-composeRun.sh文件,如果不存在则从远程中下载. 然后全部下载成功后, 执行docker-compose.sh 脚本 docker-composeversion: '3' services: base: restart: always image: $&#123;repository&#125;$&#123;name&#125;:$&#123;tag&#125; container_name: $&#123;name&#125; hostname: localhost network_mode: host ports: - $&#123;port&#125; env_file: - .env environment: - TZ=Asia/Shanghai command: - $&#123;command&#125; volumes: - ./log:/log docker-compose.yml 启动的时候, 会默认读取当前目录下的.env文件, 所以docker-composeRun.sh 脚本的目录就是就是将传入的参数生成.env文件. ## 输出到.env的内容 #!/bin/sh #说明 show_usage=\"args: [-n , -p , -c , -r , -t, -o]\\ [--name=, --port=, --command=, --repository=, --tag, --operate]\" #参数 # 容器名称 opt_name=\"\" # 启动参数 opt_command=\"\" # 仓库地址 opt_repository=\"\" ## 端口映射 opt_port='' ## 操作 opt_operate=\"\" GETOPT_ARGS=`getopt -o n:p:c:r:t:o: -al name:,command:,repository:,operate: -- \"$@\"` eval set -- \"$GETOPT_ARGS\" start()&amp;#123; docker-compose up -d &amp;#125; stop()&amp;#123; docker-compose down &amp;#125; restart()&amp;#123; docker-compose restart &amp;#125; update()&amp;#123; stop docker-compose pull start &amp;#125; #获取参数 while [ -n \"$1\" ] do case \"$1\" in -n|--name) opt_name=$2; shift 2;; -c|--command) opt_command=$2; shift 2;; -p|--port) opt_port=$2; shift 2;; -t|--tag) opt_tag=$2; shift 2;; -r|--repository) opt_repository=$2; shift 2;; -o|--operate) opt_operate=$2; shift 2;; --) break ;; *) echo $1,$2,$show_usage; break ;; esac done if [[ -z $opt_name || -z $opt_command || -z $opt_repository || -z $opt_operate ]]; then echo $opt_operate echo $show_usage echo \"opt_name: $opt_name , opt_command: $opt_command , opt_repository: $opt_repository , opt_operate: $opt_operate\" exit 0 else echo \"opt_name: $opt_name , opt_command: $opt_command , opt_repository: $opt_repository , opt_operate: $opt_operate\" # define web container env #repository=registry.cn-hangzhou.aliyuncs.com/luyanan/ #name=fieldarmy-blog-single #tag=latest #command=--spring.profiles.active=dev #port=8081:8081 echo repository=$opt_repository > .env echo name=$opt_name >> .env echo tag=$opt_tag >> .env echo command=$opt_command >> .env echo port=$opt_port >> .env case $opt_operate in start) echo '启动中' start ;; stop) echo '停止中' stop ;; restart) echo '重启中' restart ;; update) echo '重新拉取镜像' update ;; esac fi 当然, 也可以在项目目录下使用docker-compose 的命令进行操作. 4. 测试部署 然后,我们就可以进行参数化部署了, 点击Build 就可以将生成的镜像部署到远程服务器了. 5. 注意:因为解决dubbo项目启动的时候, 注册到注册中心的ip为容器中ip, 访问不到的情况, 所以docker-compose.yml 中必须配置 hostname: localhost network_mode: host","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"docker 搭建mysql","slug":"安装/docker 搭建mysql","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/docker-da-jian-mysql/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/docker-da-jian-mysql/","excerpt":"","text":"1. 新建 docker 目录2. 创建mysql 目录3. 拉取容器 docker pull mysql:5.7 4.启动dockerdocker run -p 3306:3306 --name mymysql -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 // 命令说明 -p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口 -v -v $PWD/conf:/etc/mysql/conf.d：将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。 -v $PWD/logs:/logs：将主机当前目录下的 logs 目录挂载到容器的 /logs。 -v $PWD/data:/var/lib/mysql ：将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。 -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。 5. 查看容器使用情况 docker ps 6. 修改编码 在 config 下创建my.cnf 添加: [mysqld] user=mysql character-set-server=utf8 [client] default-character-set=utf8 [mysql] default-character-set=utf8 重启容器 7. 创建自定义用户和数据库首先进入容器 docker exec -it mymysql bash 登录root用户 mysql -uroot -p123456; 上面的这两个命令就可以通过alias 别名简化 vim ~/.bashrc 加入一行 alias sql=&#39;docker exec -it mymysql mysql -uroot -p123456&#39; 编译生效 source ~/.bashrc 进入客户端执行 mysql> create user 'test'@'%' identified by '123456'; mysql> flush privileges; mysql> create database db0 DEFAULT CHARSET utf8mb4 COLLATE utf8mb4_general_ci; mysql> grant all privileges on db0.* to 'test'@'%' identified by '123456'; flush privileges;","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"docker  安装redis","slug":"安装/docker  安装redis","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/docker-an-zhuang-redis/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/docker-an-zhuang-redis/","excerpt":"","text":"1. 拉取容器 docker pull redis:4.0 2. 查看本地容器 docker images 3. 启动docker run --name redis -p 6379:6379 -v $PWD/data:/data -d --restart=always redis:4.0 redis-server --appendonly yes --requirepass \"your passwd\"","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"centos安装nfs","slug":"安装/centos安装nfs","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/centos-an-zhuang-nfs/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/centos-an-zhuang-nfs/","excerpt":"","text":"centos安装nfs1. 安装nfs1.1 安装yum install nfs-utils rpcbind 1.2 启动rpcbind 服务systemctl restart rpcbind.service 1.3 查看服务状态systemctl status rpcbind.service 1.4 启动NFS服务systemctl start nfs.service 查看状态 systemctl status nfs.service 查看RPC注册的端口信息 rpcinfo -p localhost 1.5 启动 顺序一定是rpcbind-&gt;nfs，否则有可能出现错误 systemctl start rpcbind.service systemctl enable rpcbind.service systemctl start nfs.service systemctl enable nfs.service 1.6 配置创建文件存储目录 mkdir /nfs vim /etc/exports 在最后面添加一行： /nfs *(insecure,rw,sync,no_root_squash,no_subtree_check) ​ （/nfs为root目录下新建的一个文件夹，这个文件夹就是nfs服务对外的共享目录，名字可以随便。 ，注意如果当前登录用户不是root那么这个目录必须要在root目录下，不可以是当前登录用户的根目录 #重载exports配置 exportfs -r #查看共享参数 exportfs -v 此时NFS服务就搭建成功了.","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"ReentrantLock底层原理分析(4)","slug":"并发编程/ReentrantLock底层原理分析(4)","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.273Z","comments":true,"path":"2022/01/04/bing-fa-bian-cheng/reentrantlock-di-ceng-yuan-li-fen-xi-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/bing-fa-bian-cheng/reentrantlock-di-ceng-yuan-li-fen-xi-4/","excerpt":"","text":"4. ReentrantLock底层原理分析J.U.C 简介java.util.concurrent是在并发编程中比较常用的工具类,里面包含很多用来在并发场景中使用的组件.比如线程池,阻塞队列,计时器,同步器,并发集合等.并发包的作者是大名鼎鼎的 Doug Lea. lockLock简介在Lock接口出现之前,java中的应用程序对于多线程的并发安全处理只能基于synchronized 关键字来解决,但是 synchronized 在有些场景下会存在一些短板,也就是它不适用于所有的并发场景. 但是在java5之后,Lock的出现可以解决synchronized 在某些场景中的短板,它比synchronized 更加的灵活. Lock的实现Lock本质上是一个接口,它定义了释放和获取锁的抽象方法,定义成接口就意味着它定义了锁的一个标准规范,也同时意味着锁的不同实现.实现Lock接口类有很多,以下为几个常见的锁实现 ReentrantLock: 表示重入锁,它是唯一实现了Lock接口的锁. 重入锁指的是线程在获得锁之后,再次获得锁不需要阻塞,而是直接关联一次计数器增加重入次数. ReentrantWriteReadLock: 重入读写锁,它实现了ReadWriteLock接口,在这个类中维护了两个类,一个是ReadLock,一个是WriteLock,他们都分别实现了Lock接口.读写锁是一种适合于读多写少的场景下解决线程安全问题的工具,基本原则是:读和读不互斥,读和写互斥,写和写互斥.也就是说影响数据变化的操作都会互斥. StampedLock: StampedLock 是JDK8引入的新的锁机制,可以简单认为是读写锁的一个改进版本,读写锁虽然可以通过分离读和写的功能使得读和读之间可以完全并发,但是读和写是有冲突的,如果大量的线程存在,可能会引起写线程的饥饿,StampedLock 是一种乐观的读策略,使得乐观锁完全不会阻塞写线程. Lock的类关系图Lock有很多的锁的实现,但是直观的实现是ReentrantLock 重入锁 ReentrantLock lock = new ReentrantLock(); // 如果锁可用就直接获得锁,如果不可用就直接阻塞 lock.lock(); // 和lock方法相似,但是阻塞的线程可中断,抛出InterruptedException 异常 lock.lockInterruptibly(); // 非阻塞获取锁,尝试获取锁,r如果成功返回true lock.tryLock(); // 带有超时时间的获取锁的方法 lock.tryLock(11, TimeUnit.DAYS); //释放锁 lock.unlock(); ReentrantLock 重入锁重入锁,表示支持重新进入的锁,也就是说,如果当前线程t1 通过调用lock方法获得了锁之后,再次调用lock,是不会再去阻塞去获取锁,直接增加重试次数就行了.synchronized 和ReentrantLock 都是可重入锁.很多人不理解为什么锁会存在重入的特性,那是因为对于同步锁的理解程度还不够.比如在下面这类的场景中,c存在多个加锁的方法的相互调用,其实就是一种重入特性的场景. 重入锁的设计目的比如调用demo方法获得了当前的对象锁,然后在这个方法中再去调用demo2,demo2中的存在同一个实例锁,这个时候当前线程会因为无法获得demo2的对象锁而阻塞, 就会产生死锁. 重入锁设计的目的就是为了避免线程的死锁. public class ReentrantLockDemo &#123; public static void main(String[] args) &#123; ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); new Thread(reentrantLockDemo::demo).start(); &#125; public synchronized void demo() &#123; System.out.println(&quot;begin demo&quot;); demo2(); &#125; private synchronized void demo2() &#123; System.out.println(&quot;begin demo&quot;); &#125; &#125; ReentrantLock 的使用案例 public class ReentrantLockDemo &#123; private static int count; static ReentrantLock lock = new ReentrantLock(); public static void inc() &#123; try &#123; lock.lock(); TimeUnit.MILLISECONDS.sleep(2); count++; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 100; i++) &#123; new Thread(() -&gt; ReentrantLockDemo.inc()).start(); &#125; TimeUnit.SECONDS.sleep(30); System.out.println(count); &#125; &#125; ReentrantWriteReadLock我们以前的理解的锁,基本上都是排他锁,也就是这些锁在同一时刻只允许一个线程进行访问,而读写锁在同一时刻可以允许多个线程访问,但是在写线程访问时,所有的读线程和写线程都会被阻塞. 读写锁维护了一堆锁,一个读锁,一个写锁;一般情况下,读写锁的性能都比排他锁强,因为大部分场景都是读多写少的. 在读多于写的情况下,读写锁能够提供比排他锁更好的并发量和吞吐量. package com.notes.concurrent.synchronizeds; import java.util.HashMap; import java.util.Map; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantReadWriteLock; /** * @author luyanan * @since 2019/7/29 * &lt;p&gt;读写锁&lt;/p&gt; **/ public class ReentrantWriteReadLockDemo &#123; static Map&lt;String, Object&gt; cache = new HashMap&lt;&gt;(); static ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); static ReentrantReadWriteLock.ReadLock readLock = lock.readLock(); static ReentrantReadWriteLock.WriteLock writeLock = lock.writeLock(); public static final Object get(String key) &#123; System.out.println(&quot;开始读取数据&quot;); readLock.lock(); try &#123; return cache.get(key); &#125; finally &#123; readLock.unlock(); &#125; &#125; public static final Object put(String key, Object value) &#123; System.out.println(&quot;开始写数据&quot;); writeLock.lock(); try &#123; return cache.put(key, value); &#125; finally &#123; writeLock.unlock(); &#125; &#125; &#125; 在这个案例中,通过hashmap 来模拟了一个内存缓存,然后使用读写锁来保证这个内存缓存d的线程安全性.当执行读操作的时候,需要获取读锁,在并发访问的时候,读锁不会阻塞,因为读锁不会影响执行结果. 在执行写操作的时候,线程必须获取写锁,当已有线程持有写锁的情况下,当前线程会被阻塞,只有当写锁释放后,其他读写操作才能继续执行. 使用读写锁提升了读操作的并发性,也保证了每次写操作对所有读写操作的可见性. 读锁和读锁共享 读锁和写锁不可以共享(排他) 写锁和写锁不可以共享(排他) ReentrantLock 的实现原理我们知道锁的基本原理是基于将多线程并行任务通过某一种机制实现线程的串行执行,从而达到线程安全性的目的. 在synchronized 中 ,我们分析了偏向锁,轻量级锁,乐观锁以及自旋锁来优化了synchronized 的加锁开销,同时在重量级锁阶段,通过线程的阻塞以及唤醒来达到线程竞争和同步的目的. 那么在ReentrantLock中,也一定会存在这样的需求去解决问题,就是在多线程竞争重入锁的时候,竞争失败的线程是如何阻塞和被 唤醒的呢？ AQSAQS是什么？在Lock中 用到了一个同步队列AQS,全称 AbstractQueuedSynchronizer,它是一个同步工具也是Lock用来实现线程同步的核心组件. 如果你搞懂了AQS，那么J.U.C 中的绝大部分的工具你都能掌握. AQS的两种功能从使用层面上来说,AQS的功能分为两种:独占和共享 独占锁,每次只能有一个线程持有锁,比如前面演示的ReentrantLock 就是以独占方式实现的互斥锁. 共享锁:允许多个线程同时获取锁,并发访问共享资源,比如ReenteantWriteReadLock AQS的内部实现AQS内部维护的是一个FIFO的双向链表,这种结构的特点是每个数据结构都有两个指针,分别指向直接的后继节点和直接前驱节点. 所以双向链表可以从任意一个节点开始很方便的访问前驱和后继. 每个Node其实是由线程封装,当线程抢占锁失败后就会被封装成Node节点加入到AQS队列中. 当获取锁的线程释放锁以后,会从队列中唤醒一个阻塞的节点(线程) Node的组成static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; /** waitStatus value to indicate successor&#39;s thread needs unparking */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; volatile int waitStatus; // 前置节点 volatile Node prev; // 后继节点 volatile Node next; /** * The thread that enqueued this node. Initialized on * construction and nulled out after use. */ // 当前线程 volatile Thread thread; // 存储在condition队列中的后继节点 Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ // 是否为共享锁 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** * Returns previous node, or throws NullPointerException if null. * Use when predecessor cannot be null. The null check could * be elided, but is present to help the VM. * * @return the predecessor of this node */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; // 将线程构造成一个Node,添加到等待队列 Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; // 这个方法会在Condition 中用到 Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; 释放锁以及添加线程对于队列的变化当出现锁竞争以及释放锁的时候, AQS 同步队列中的节点会发生变化,首先看一下添加节点的场景里面会涉及两个变化 新的线程封装成Node节点追加到同步队列中,设置prev节点以及修改当前节点的前置节点d的next 指向自己。 通过CAS将tail 重新指向新的尾部节点 head节点表示获得锁成功的节点,当头节点在释放同步状态的时候,会唤醒后继节点,如果后继节点获得锁成功,会将自己设置为头节点,节点的变化过程如下:这个过程也设涉及两个变化 修改head节点指向下一个获得锁的节点 新的获得锁的节点,将prev的节点设置为null 设置head节点不需要用CAS,原因是设置head节点是由获得锁的线程来完成的,而同步锁只能由一个线程获取,所以不需要CAS保证,只需要把head节点设置为原首节点的后继节点,并且断开与原head节点的next引用即可. ReentrantLock 的源码分析以ReentrantLock 作为切入点,来看看在这个场景下是如何使用AQS来实现线程同步的 ReentrantLock的时序图调用ReentrantLock的lock()方法ReentrantLock.lock() 这个是ReentrantLock获取锁的入口 public void lock() &#123; sync.lock(); &#125; syn实际上是一个抽象的静态内部类,它继承了AQS来实现重入锁的逻辑.我们前面说过AQS是一个同步队列,他能够实现线程的阻塞以及唤醒,但是它并不具备业务功能,所以在不同的同步场景中,会继承AQS来实现对应场景的功能. Sync有两个具体的实现: NonfairSync: 表示可以存在抢占锁的功能,也就是说不管当前队列上是否有其他线程等待,新线程都有机会抢占锁. FairSync:表示所有线程都严格按照FIFO来获取锁. NonfairSync.lock()以非公平锁为例,来看看lock中的实现 非公平锁和公平锁的最大的区别在于,在非公平锁中我抢占锁的逻辑是 不管有没有线程排队,我先上来cas 去抢占一下. CAS成功,就表示成功获得了锁. CAS失败,就调用 acquire(1); 走锁竞争逻辑 final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; CAS的实现逻辑 protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; 通过cas 乐观锁的方式来做比较并替换,这段代码的意思是,如果当前内存中的state的值于预期值expect 相等,则替换update.更新成功则返回true,否则返回false. 这个操作是原子的,不会出现线程安全的问题,这里面涉及到了Unsafe的操作,以及涉及到state 这个属性的意思. state是AQS中的一个属性, 它在不同的实现中所表达的含义是不一样的,对于重入锁的实现来说,它表示一个同步状态.它有两个含义的表示: 当state =0时,表示无锁状态. 当state &gt;0时,表示已有线程获得了锁,也就是state =1,但是因为ReentrantLock 允许重入,所以同一个线程多次获得同步锁的时候,state 就会递增,比如重入5次,那么state = 5; 而在释放锁的时候,同样需要释放5次知道state = 0 其他线程才有资格获得锁. Unsafe类Unsafe累是在sun.misc 包下,不属于java标准.但是在很多的java的基础类库中,包括以下被广泛使用的高性能的开发库都是基于Unfafe类开发的,比如 Netty,Hadoop,Kafka等. Unsafe可以被认为是java中留下的后门,提供了一些低层次的操作,如直接内存访问,线程的挂起和恢复,CAS,线程的同步,内存屏障等. 而CAS 就是Unsafe类中提供的一个原子操作,第一个参数为需要改变的对象,第二个为偏移量(即之前求出来的headOffset的值),第三个参数为期待的值,第四个为更新后的值。 整个方法的作用是如果当前的值于预期的值var4相等,则更新为新的期望的值var5, 如果更新成功,则返回true,否则返回false. stateOffset一个java对象可以看做是一段内存,每个字段都得按照一定的顺序放在这段内存里,通过这个方法可以准确的告诉你某个字段相对于对象的起始内存地址的字节偏移.用于在后面的 compareAndSwapInt 中,去根据偏移量找到对象在内存中的具体位置. 所以stateOffset 表示state 这个字段在AQS 类的内存中相对于该类首地址的偏移量 compareAndSwapInt在 unsafe.cpp中,可以找到 compareAndSwapInt 的实现 UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) UnsafeWrapper(&quot;Unsafe_CompareAndSwapInt&quot;); oop p = JNIHandles::resolve(obj); // 将java对象解析成JVM的oop(普通对象指针) jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);// 根据对象p和地址偏移量找到地址 return (jint)(Atomic::cmpxchg(x, addr, e)) == e; // 基于cas比较并替换,x表示需要更新的值,addr表示state在内存中的值,e 表示预期值 UNSAFE_END AQS.acquireacquire 是AQS中的方法,如果CAS 操作未能成功,说明state 已经不为0了,此时继续acquire(1)操作 大家思考一下,acquire 方法中的1的参数是用来做什么的? public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 这个方法的主要逻辑是: 通过tryAcquire 尝试获取独占锁,如果成功返回true,如果失败返回false 如果tryAcquire 失败,则会通过 addWaiter 方法将当前线程封装成Node节点添加到AQS 队列尾部. acquireQueued 将Node作为参数,通过自旋去尝试获得锁. NonfairSync.tryAcquire protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; 这个方法的作用的尝试获取锁,如果成功则返回true,如果失败则返回false, 它是重写AQS类中的tryAcquire 方法,并且大家仔细看一下 AQS中的tryAcquire 方法的定义,并没有实现,而是抛出异常.按照一般的思维模式,既然是一个不实现的模板方法,那应该定位是abstract, 让子类来实现? ReentrantLock.nonfairTryAcquire final boolean nonfairTryAcquire(int acquires) &#123; // 获得当前执行的线程 final Thread current = Thread.currentThread(); // 获得state 值 int c = getState(); if (c == 0) &#123; // 表示无锁状态 if (compareAndSetState(0, acquires)) &#123;// cas替换 state的值,如果cas成功表示获得锁成功 // 保存当前获得锁的线程,下次再来的时候就不再尝试竞争锁 setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果同一个线程来获得锁,直接增加重入次数 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 获得当前线程,判断当前锁的状态 如果state=1 表示当前是无锁状态,通过cas 更新state状态的值 当前线程是属于重入,则增加重入次数 AQS.addWaiter private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // tail是AQS中表示同比队列队尾的属性,默认为null Node pred = tail; // tail 不为空的情况下,说明队列中存在节点 if (pred != null) &#123; // 把当前线程的Node的prev 指向tail node.prev = pred; // 通过cas把Node节点加入到AQS队列中,也就是设置为tail if (compareAndSetTail(pred, node)) &#123; // 设置成功后,把原tail节点的next指向当前node pred.next = node; return node; &#125; &#125; // tail = null,把node添加到同步队列 enq(node); return node; &#125; 当tryAcquire 方法获得锁失败之后,则会先调用 addWaiter 将当前线程封装成Node 入参mode表示当前节点的状态,传递的参数是Node.EXCLUSIVE,表示独占状态,意味着重入锁用到了AQS的独占锁功能. 将当前线程封装成Node 当前链表中的tail节点是否为空,如果不为空,则通过cas操作把当前线程的node节点添加到CAS 队列 如果为空或者cas失败,调用enq 将节点添加到AQS 队列 enqenq 就是通过自旋把当前节点加入到队列中 private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 图解分析假设3个线程来争抢锁,那么截至到enq方法运行结束之后,或者调用addWaiter()方法结束后,AQS中的链表结构 AQS.acquireQueued final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 获得当前节点的prev节点 final Node p = node.predecessor(); // 如果是nead节点,说明有资格去争抢锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获得锁成功,也就是ThreadA 已经释放了锁,然后设置head为ThreadB 获得执行权限 setHead(node); // 把原head 节点从链表中移除 p.next = null; // help GC failed = false; return interrupted; &#125; // ThreadA 可能还没有释放锁,使得ThreadB 在执行 tryAcquire时就会返回false if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 并且返回当前线程在等待过程中有没有中断过 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 通过addWaiter 方法把线程添加到链表后,会接着把Node作为参数传递给acquireQueued 方法中去竞争锁. 获得当前节点的prev节点 如果prev 节点为head节点,那么它就有资格去争抢锁,调用tryAcquire 抢占锁. 抢占锁成功之后,把获得锁的节点设置为head, 并且移除原来的初始化head 节点 如果获得锁失败,根据waitStatus决定是否要挂起锁. 最后,通过cancelAcquire 取消获得锁的操作. NofairSync.tryAcquire这个方法在前面分析过,就是通过state 的状态来判断是否处于无锁状态,然后再通过cas进行竞争锁操作. 成功表示获得锁,失败表示获得锁失效. shouldParkAfterFailedAcquireprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 前置节点的waitStatus int ws = pred.waitStatus; // 如果前置节点为SIGNAL, 意味着只需要等待其他前置节点的线程被释放 if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ // 返回true,意味着可以直接放心的挂起了. return true; // ws 大于0 意味着prev节点取消了 排队,直接移除这个节点就行了 if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; // 相当于: pred = pred.prev; node.prev = pred; node.prev = pred = pred.prev; // 这里采用循环,从双向列表中移除 CANCELLED的节点 &#125; while (pred.waitStatus &gt; 0); pred.next = node; // 利用cas设置prev节点的状态为 SIGNAL &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don&#39;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; 如果ThreadA的锁还没有释放的情况下,ThreadB 和ThreadC 来争抢锁 肯定是会失败,那么失败后还调用shouldParkAfterFailedAcquire 方法. Node 有5种状态,分别是 CANCELLED（1），SIGNAL（-1）、CONDITION（-2）、PROPAGATE(-3)、默认状态(0) CANCELLED: 在同步队列中等待的线程等待超时或者中断,需要从同步队列中取消该Node的节点,其节点的waitStatus 为 CANCELLED, 即结束状态,进入该状态的节点将不会再变化. SIGNAL: 只要前置节点释放锁,就会通知标识为SIGNAL状态的后续节点的线程CONDITION: 和Condition 有关系.PROPAGATE: 共享模式下,PROPAGATE状态的线程处于可运行状态,0: 初始状态. 这个方法的主要作用是通过Node的状态来判断ThreadA 竞争锁失败以后是否应该被挂起. 如果ThreadA 的pred 节点状态为SIGNAL, 那就表示可以放心的挂起当前线程 通过循环扫描链表把 CANCELLED 状态的节点移除 修改pred 节点的状态为 SIGNAL,返回false 返回fasle时,也就是不需要挂起,返回true, 则需要调用 shouldParkAfterFailedAcquire 挂起当前线程. parkAndCheckInterrupt private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; 使用LockSupport.park 挂起当前线程为 WATING 状态. Thread.interrupted() 返回当前线程是否被其他线程触发过中断请求,也就是thread.interrupt(); 如果有触发过中断请求,那么这个方法会返回当前的中断标识true, 并且对中断标识进行复位标识已经响应过的中断请求.如果返回true,意味着在acquire方法中执行 selfInterrupt(). selfInterrupt static void selfInterrupt() &#123; Thread.currentThread().interrupt(); &#125; 标识如果当前线程在 acquireQueued 中被中断过,则需要产生一个中断请求,原因是线程在调用 acquireQueued 方法的时候是不会响应中断请求的 图解分析 通过 acquireQueued 方法来竞争锁, 如果ThreadA 还在执行中没有释放锁的话,意味着ThreadB 和ThreadC 只能挂起了. LockSupport LockSupport 类是java6 引入的一个类,提供了基本的线程同步原语.LockSupport 实际上是调用了 Unsafe类里面的函数,归结到Unsafe 里面,只有两个函数 /** * Unblock the given thread blocked on &lt;tt&gt;park&lt;/tt&gt;, or, if it is * not blocked, cause the subsequent call to &lt;tt&gt;park&lt;/tt&gt; not to * block. Note: this operation is &quot;unsafe&quot; solely because the * caller must somehow ensure that the thread has not been * destroyed. Nothing special is usually required to ensure this * when called from Java (in which there will ordinarily be a live * reference to the thread) but this is not nearly-automatically * so when calling from native code. * @param thread the thread to unpark. * */ public native void unpark(Object thread); /** * Block current thread, returning when a balancing * &lt;tt&gt;unpark&lt;/tt&gt; occurs, or a balancing &lt;tt&gt;unpark&lt;/tt&gt; has * already occurred, or the thread is interrupted, or, if not * absolute and time is not zero, the given time nanoseconds have * elapsed, or if absolute, the given deadline in milliseconds * since Epoch has passed, or spuriously (i.e., returning for no * &quot;reason&quot;). Note: This operation is in the Unsafe class only * because &lt;tt&gt;unpark&lt;/tt&gt; is, so it would be strange to place it * elsewhere. */ public native void park(boolean isAbsolute, long time); unpark 函数为线程提供了”许可(permit)” ,线程调用park函数则等待”许可”.这个有点像信号量,但是这个”许可” 是不能叠加的,”许可”是一次性的. permit 相当于0/1的开关, 默认是0, 调用一次unpark 就加1 变成了1,调用一个park 就会消费permit, 又会变成0. 如果再调用一次 park就会阻塞,因为permit 已经是0了,知道permit 变成1 ,这时调用unpark 会把 permit 设置为1.每个线程都已经一个相关的permit, permit最多只有一个,重复调用unpark 不会累计. 锁的释放流程 如果这个时候 ThreadA 释放锁了,那么我们来看看锁被释放够会产生什么效果. ReentrantLock.unlock public void unlock() &#123; sync.release(1); &#125; 在unlock 中,会调用 release 方法来释放锁 public final boolean release(int arg) &#123; // 释放锁成功 if (tryRelease(arg)) &#123; // 得到aqs中的头部节点 Node h = head; // 如果head节点不为空并且状态!=0 调用unparkSuccessor(h); 唤醒后续的节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; ReentrantLock.tryRelease protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; 这个方法可以认为是一个设置锁状态的操作,通过将state状态减掉传入的参数值(参数值为1),如果结果状态为0,就想排它锁的Owner设置为null, 使得其他线程有机会进行. 在排它锁中,加锁的时候的状态会增加1(当然可以自己修改这个值),在解锁的时候减掉1,同一个锁,在可以重入后,可能会被叠加为2、3、4这些值,只有unlock() 的次数和lock()的次数对应才会将Owner线程设置为空,而且也只有这种情况下,才会返回true. unparkSuccessor private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ // 获得head 节点的状态 int ws = node.waitStatus; if (ws &lt; 0) // 设置head节点状态为0 compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 得到head节点的下一个节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; // 如果下一个节点为null或者status&gt;0 表示cancelled 状态, // 通过从尾部节点开始扫描,找到距离head最近的一个waitStatus&lt;=0的节点 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // next节点不为空,直接唤醒这个线程即可. if (s != null) LockSupport.unpark(s.thread); &#125; 为什么在释放锁的时候是从tail 进行扫描的呢? 我们再回到enq这个方法 来看一下一个新的节点是如何加入到链表中的 将新的节点的prev 指向tail 通过cas将tail设置为新的节点, 因为cas是原子操作 所以能够保证线程安全性. t.next = node; 设置 原tail 的next节点指向新的节点 private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 在cas操作之后,t.next=node 操作之前.存在其他线程调用 unlock 方法从 head开始往后遍历,由于t.next=nodel 还没执行 ,意味着链表的关系还没有建立完整,就会导致遍历到t 节点的时候被中断.所有从后往前遍历,一定不会存在这个问题。 图解分析通过锁的释放,原本的结构就发生了一些变化.head节点的waitStatus 变成了0,ThreadB被唤醒. 原本挂起的线程执行通过ReentrantLock.unlock ,原本挂起的线程是在acquireQueued 方法中,被唤醒之后从这个方法开始执行. AQS.acquireQueuedfinal boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 这个方法前面已经分析过了,我们只关注一下ThreadB 被唤醒以后的执行流程. 由于ThreadB的 prev 节点指向的是head, 并且ThreadA 已经释放锁,所以这个时候调用tryAcquire 方法时 就可以顺利获取到锁。 把ThreadB节点当成head 把原head节点的next节点指向null 图解分析 设置新head 节点的prev 为null 设置原head节点的next节点为null 公平锁和非公平锁的区别锁的公平性是相对于获取锁的顺序而言的,如果是一个公平锁,那么获取锁的顺序j就应该符合请求的绝对时间排序,也就是FIFO。 在上面的例子来说,只要CAS设置成功,则表示当前线程获得了锁,而公平锁则不一样，差异点有两个 FairSync.tryAcquire非公平锁在获得锁的时候,会先通过CAS进行抢占,而公平锁则不会. final void lock() &#123; acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 这个方法与nonfairTryAcquire(int acquires) 比较,不同的地方在于判断条件多了 hasQueuedPredecessors 方法,也就是加入了[同步队列中当前节点是否有前驱节点] 的判断,如果该方法返回true,则表示有线程比当前 线程更早的请求获取锁,因为需要等待前驱线程获取并释放锁之后才能继续获得锁.","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"centos 7 yum方式安装Mysql5","slug":"安装/centos 7 yum方式安装Mysql5.7","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/centos-7-yum-fang-shi-an-zhuang-mysql5.7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/centos-7-yum-fang-shi-an-zhuang-mysql5.7/","excerpt":"","text":"centos 7 yum方式安装Mysql5.7在CentOS中默认安装有MariaDB（MySQL的一个分支），安装完成之后可以直接覆盖MariaDB。 MySQL版本号：5.7.28 下载yum repository wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm 安装 yum -y install mysql57-community-release-el7-10.noarch.rpm 安装MySQL服务器 yum -y install mysql-community-server 启动MySQL systemctl start mysqld.service 查看运行状态 systemctl status mysqld.service 找到MySQL root用户的初始密码： grep \"password\" /var/log/mysqld.log 使用临时密码连接客户端： mysql -uroot -p:E+,Y_Dp_35j 修改密码安全限制，否则不能使用简单密码临时修改： mysql&gt; set global validate_password_policy=0; mysql&gt; set global validate_password_length=1; 永久修改：MySQL默认的配置文件：vim /etc/my.cnf validate_password_policy=0 validate_password_length=1 修改后重启MySQL service mysqld restart 修改密码： mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;; 授权远程访问： mysql&gt; grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;123456&#39;; 如果需要远程连接，注意开放3306端口或者关闭防火墙。 MySQL默认的数据文件目录： show variables like ‘datadir’; /var/lib/mysql/ MySQL默认错误日志文件： show variables like ‘log_error’; /var/log/mysqld.log 如果忘记了root密码或者用临时密码无法登录： vim /etc/my.cnf 在配置文件中加一行skip-grant-tables [mysqld] skip-grant-tables 重启数据库服务 service mysqld restart 然后使用mysql命令登录，使用以下密码修改密码。 mysql&gt; update user set authentication_string=password(&#39;123456&#39;) where Host=&#39;localhost&#39; and User=&#39;root&#39;; 修改以后，在配置文件中去掉skip-grant-tables，重启数据库服务。再使用 mysql -uroot -p123456登录。修改密码安全限制和授权远程访问依然要做。","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"Window10 利用WSL2 安装Linux子系统以及docker","slug":"安装/Window10 利用WSL2 安装Linux子系统以及docker","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/window10-li-yong-wsl2-an-zhuang-linux-zi-xi-tong-yi-ji-docker/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/window10-li-yong-wsl2-an-zhuang-linux-zi-xi-tong-yi-ji-docker/","excerpt":"","text":"Window10 利用WSL2 安装Linux子系统以及docker前言windows10目前推出了WSL2，相对于WSL采用API转换的方式， WSL2 则完全不同，win10 开始内置了一个轻量级虚拟机，经过不断的优化，这个虚拟机实现了与 windows 的高度集成，实现了虚拟机的高性能运行，WSL2 便是运行在虚拟机上的一个完整的 linux 内核。因此WSL2给了在windows更接近原生linux的体验，同时wsl2 的开启速度有了非常明显的提升，几乎不需要再等待。本文探讨在win10专业版上利用WSL2安装docker的2种方式。 操作实践1.开启安装windows10的WSL2功能 更新windows10系统 要升级 windows 系统到 win10 v2004 的内部版本 19041 或更高版本 升级 Windows 可以使用官方的更新助手，非常方便，地址：https://www.microsoft.com/zh-cn/software-download/windows10，在更新过程中，系统可能或多次重启。 打开系统虚拟机平台 系统更新并重启后，我们就可以开始 wsl 的升级了 首先，需要打开“系统虚拟机平台”功能，在“控制面板\\所有控制面板项\\程序和功能”中选择“启用或者关闭Windows功能”，勾选对应选项即可： 也可以通过在管理员权限下的 cmd 或 PowerShell 中执行： dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 下载 wsl2 需要使用的 linux 内核 在 https://docs.microsoft.com/zh-cn/windows/wsl/wsl2-kernel 页面点击下载 linux 内核更新包，下载完点击安装 启用”适用于 Linux 的 Windows 子系统”这个功能 启用”适用于 Linux 的 Windows 子系统”这个功能，然后才能在 Windows 上安装 Linux 发行版，如果之前使用过旧的wsl，此功能应该开启过。以管理员身份打开 PowerShell 运行如下所示的命令： dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 也可以在“控制面板\\所有控制面板项\\程序和功能”中选择“启用或者关闭Windows功能”，勾选对应选项即可。 重启系统并设置WSL 2 设置为默认版本 # wsl命令可以设置单独某个具体wsl的linux版本为1版本但是2版本，wsl2速度较于旧版wsl快了很多，有了高铁还蹬啥自行车。 wsl --set-default-version 2 查看是不是WSL2， wsl -l -v 2.安装配置 Linux 发行版选择实用比较多的ubuntu版本，其他版本未测试能否安装成功docker。 打开 Microsoft Store，搜索 Terminal，安装 Windows Terminal，用于后面和 WSL 子系统交互。 搜索 Ubuntu，选择安装。 安装完成后，第一次打开 Ubuntu 的时候，将打开一个控制台窗口，会等待几分钟来进行配置，启动完成后为 Ubuntu 创建一个用户和密码（如果第一次启动ubuntu失败，可以重启windows10系统再次试下）。 使用 Windows Terminal 来操作 Ubuntu 系统了，在 Windows Terminal 中选择 Ubuntu 发行版就可以跳转到 Ubuntu 终端中，使用上面我们配置的用户名和密码登录即可： 由于默认情况下我们不知道 root 用户的密码，所以如果我们想要使用 root 用户的话可以使用 passwd 命令为 root 用户设置一个新的密码，同时为了避免sudo切换root是需要输入密码，把自己配置的用户名加到sudo免密中，命令如下： # 替换leap为自己单独配置的用户名 sudo echo &quot;leap ALL=(ALL:ALL) NOPASSWD: ALL&quot; &gt;&gt;/etc/sudoers 更换ubuntu的apt安装源 默认的安装源相对国内很慢，我们更换源到阿里云，登录到ubuntu到操作如下： cp /etc/apt/sources.list /etc/apt/sources.list.bak echo &quot;deb http://mirrors.aliyun.com/ubuntu/ focal main restricted deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted deb http://mirrors.aliyun.com/ubuntu/ focal universe deb http://mirrors.aliyun.com/ubuntu/ focal-updates universe deb http://mirrors.aliyun.com/ubuntu/ focal multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted deb http://mirrors.aliyun.com/ubuntu/ focal-security universe deb http://mirrors.aliyun.com/ubuntu/ focal-security multiverse&quot;&gt;/etc/apt/sources.list 执行更新： apt update &amp;&amp; apt upgrade -y 3.安装docker设置仓库更新 apt 包索引。 $ sudo apt-get update 安装 apt 依赖包，用于通过HTTPS来获取仓库: $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 安装最新版本的 Docker Engine-Community 和 containerd ，或者转到下一步安装特定版本： $ sudo apt-get install docker-ce docker-ce-cli containerd.io 要安装特定版本的 Docker Engine-Community，请在仓库中列出可用版本，然后选择一种安装。列出您的仓库中可用的版本： $ apt-cache madison docker-ce docker-ce **|** 5:18.09.1~3-0~ubuntu-xenial **|** https:**//**mirrors.ustc.edu.cn**/**docker-ce**/**linux**/**ubuntu xenial**/**stable amd64 Packages docker-ce **|** 5:18.09.0~3-0~ubuntu-xenial **|** https:**//**mirrors.ustc.edu.cn**/**docker-ce**/**linux**/**ubuntu xenial**/**stable amd64 Packages docker-ce **|** 18.06.1~ce~3-0~ubuntu **|** https:**//**mirrors.ustc.edu.cn**/**docker-ce**/**linux**/**ubuntu xenial**/**stable amd64 Packages docker-ce **|** 18.06.0~ce~3-0~ubuntu **|** https:**//**mirrors.ustc.edu.cn**/**docker-ce**/**linux**/**ubuntu xenial**/**stable amd64 Packages ... 启动 service docker start 测试 Docker 是否安装成功，输入以下指令，打印出以下信息则安装成功: 手动安装卸载旧版本Docker 的旧版本被称为 docker，docker.io 或 docker-engine 。如果已安装，请卸载它们： $ sudo apt-get remove docker docker-engine docker.io containerd runc 当前称为 Docker Engine-Community 软件包 docker-ce 。 安装 Docker Engine-Community，以下介绍两种方式。 使用 Docker 仓库进行安装在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker 。 设置仓库更新 apt 包索引。 $ sudo apt-get update 安装 apt 依赖包，用于通过HTTPS来获取仓库: $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 添加 Docker 的官方 GPG 密钥： $ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 通过搜索指纹的后8个字符，验证您现在是否拥有带有指纹的密钥。 $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 **[**SCEA**]** 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid **[** unknown**]** Docker Release **(**CE deb**)** **&lt;**docker**@**docker.com**>** sub rsa4096 2017-02-22 **[**S**]** 使用以下指令设置稳定版仓库 $ sudo add-apt-repository \\ \"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ \\ $(lsb_release -cs) \\ stable\" 安装 Docker Engine-Community更新 apt 包索引。 $ sudo apt-get update 安装最新版本的 Docker Engine-Community 和 containerd ，或者转到下一步安装特定版本： $ sudo apt-get install docker-ce docker-ce-cli containerd.io 要安装特定版本的 Docker Engine-Community，请在仓库中列出可用版本，然后选择一种安装。列出您的仓库中可用的版本： $ apt-cache madison docker-ce docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.1~ce~3-0~ubuntu | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.0~ce~3-0~ubuntu | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages ... 使用第二列中的版本字符串安装特定版本，例如 5:18.09.13-0ubuntu-xenial。 $ sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io 测试 Docker 是否安装成功，输入以下指令，打印出以下信息则安装成功: $ sudo docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:c3b4ada4687bbaa170745b3e4dd8ac3f194ca95b2d0518b417fb47e5879d9b5f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 安装docker-compose安装docker-compose相对比较简单，可以直接去https://github.com/docker/com… 下载然后选择相应的版本，或者直接执行如下命令安装，安装完后docker-compose会被安装到/usr/local/bin目录下 curl -L https://github.com/docker/compose/releases/download/1.24.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 设置docker-compose可执行sudo chmod +x /usr/local/bin/docker-compose 查看docker-compose是否安装成功docker-compose --version","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"vue","slug":"前端/vue/vue","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/qian-duan/vue/vue/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/qian-duan/vue/vue/","excerpt":"","text":"vueVue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。 MVVM思想 M:module 包含数据和一些基本的操作 V: view视图,页面渲染结果 VM:view-module模型和视图间的双向操作 视图和数据通过VM 绑定起来,模型里面有变化会自动的通过Directives 填写到视图中,视图表单中添加了内容也会自动的通过DOM Listeners 保存到模型中 教程：https://cn.vuejs.org/v2/guide/ 安装 直接下载并使用&lt;script&gt; 标签引入 或者直接在控制台使用npm install vue引入, 先使用npm init -y 初始化项目, 生成了一个package.json 文件,说明它是一个npm 管理的项目 npm install vue,安装后在项目node_modules 里就有了vue vue 声明式渲染let vue = new Vue(&amp;#123; // 生成vue 对象 el: \"#app\", // 绑定元素, id=app data: &amp;#123; //封装数据 name: \"张三\", num: 0 &amp;#125;, methods: &amp;#123; // 取消点赞的方法 cancle() &amp;#123; this.num--; &amp;#125;, hello() &amp;#123; return \"1\"; &amp;#125; &amp;#125; &amp;#125;); 双向绑定,模型变化, 视图变化. 反之亦然双向绑定,使用v-model 指令 &lt;input type=\"text\" v-model=\"num\" /> &lt;h1>&amp;#123;&amp;#123;name&amp;#125;&amp;#125;, 非常帅,有&amp;#123;&amp;#123;num&amp;#125;&amp;#125;人为他点赞&amp;#123;&amp;#123;hello()&amp;#125;&amp;#125;&lt;/h1> index.html &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;input type=\"text\" v-model=\"num\" /> &lt;button v-on:click=\"num++\">点赞&lt;/button> &lt;button v-on:click=\"cancle()\">取消&lt;/button> &lt;h1>&amp;#123;&amp;#123;name&amp;#125;&amp;#125;, 非常帅,有&amp;#123;&amp;#123;num&amp;#125;&amp;#125;人为他点赞&amp;#123;&amp;#123;hello()&amp;#125;&amp;#125;&lt;/h1> &lt;/div> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> let vue = new Vue(&amp;#123; // 生成vue 对象 el: \"#app\", // 绑定元素, id=app data: &amp;#123; //封装数据 name: \"张三\", num: 0 &amp;#125;, methods: &amp;#123; // 取消点赞的方法 cancle() &amp;#123; this.num--; &amp;#125;, hello() &amp;#123; return \"1\"; &amp;#125; &amp;#125; &amp;#125;); &lt;/script> &lt;/body> &lt;/html> 事件处理v-xx 指令,比如v-on:click 是按钮的单击事件 在vue 中, el,data,methods的作用 el: 用来绑定数据 data: 用来封装数据 methods: 用来封装方法,并且能够封装多个方法,如上面封装了calcle 方法和hello 方法 v-text和v-html指令v-text指令会将绑定的内容按照文本进行展示,会对html 标签进行转义. v-html 指令会将绑定的内容按照html元素进行展示,不会对html 标签进行转义,而是直接在浏览器上显示data所设置的内容 &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>演示vue的v-text和v-html指令的demo&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;span v-html=\"html\">&lt;/span> &lt;span v-text=\"text\">&lt;/span> &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> let vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; html: \"&lt;h1>v-html的标题&lt;/h1>\", text: \"&lt;h1>v-html的标题&lt;/h1>\" &amp;#125;, methods: &amp;#123; &amp;#125; &amp;#125;); &lt;/script> &lt;/html> 显示的内容为: v-bind 单向绑定v-bind 指令用于动态的绑定一个或者多个attribute 中, &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>使用v-bind进行演示&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;a v-bind:href=\"link\">百度一下&lt;/a> &lt;span v-bind:class=\"&amp;#123;active:isActive,'text-danger':hasError&amp;#125;\" :style=\"&amp;#123;color:color1,fontSize:size&amp;#125;\">大家好, 才是真的好&lt;/span> &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> let vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; link: \"https://baidu.com\", isActive: true, hasError: true, color1: 'red', size: \"100px\" &amp;#125;, methods: &amp;#123; &amp;#125; &amp;#125;); &lt;/script> &lt;/html> 上面所完成的任务就是给一个a 标签绑定一个超链接, 当isActive 和hasError 都是true的时候,将属性动态的绑定 active和text-danger class,这样可以动态的调整属性的存在. 而且如果实时的修改vm的size和color1, span元素的style 样式也会随着改变, 则可以写作v-bind:style, 也可以省略为:style v-model 双向绑定&lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>vue双向绑定&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;input type=\"checkbox\" v-model=\"language\" value=\"java\" />java&lt;br> &lt;input type=\"checkbox\" v-model=\"language\" value=\"python\" />python&lt;br> &lt;input type=\"checkbox\" v-model=\"language\" value=\"go\" />go&lt;br> 选中了&amp;#123;&amp;#123;language.join(\",s\")&amp;#125;&amp;#125; &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> let vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; language: [] &amp;#125;, methods: &amp;#123; &amp;#125; &amp;#125;); &lt;/script> &lt;/html> 上面的功能主要是完成通过v-model 为输入框绑定多个值,能够实现选中的值,在data的language 也在不断的发生着变化 通过v-model 实现了页面发生了变化，则数据发生变化，数据发现变化,页面也发生变化,这样就实现了双向绑定的功能. v-on 为按钮绑定事件&lt;button v-on:click=\"num++\">点赞&lt;/button> &lt;button v-on:click=\"cancle()\">取消&lt;/button> 上面是为两个按钮绑定了单击事件,其中一个对于num 自增， 一个对num 自减 v-on:click 也可以写作@click 事件的冒泡 &lt;div style=\"border: 1px solid red; padding: 20px;\" @click=\"hello\"> 大的div &lt;div style=\"border: 1px solid blue; padding: 20px;\" @click=\"hello\"> 小的div &lt;&lt;a href=\"http://baidu.com\" @click=\"hello\">百度一下你就知道了&lt;/a> &lt;/div> &lt;/div> 上面的这两个嵌套div 中， 如果点击了内层的div, 则外层的div 也会被触发,这种问题可以用事件修饰符来完成. &lt;div style=\"border: 1px solid red; padding: 20px;\" @click=\"hello\"> 大的div &lt;div style=\"border: 1px solid blue; padding: 20px;\" @click=\"hello\"> 小的div &lt;&lt;a href=\"http://baidu.com\" @click.prevent.stop=\"hello\">百度一下你就知道了&lt;/a> &lt;!--这里禁止了超链接的点击跳转事件,并且只会触发当前对象的操作 --> &lt;/div> &lt;/div> 关于事件修饰符 按键修饰符 v-for 遍历循环&lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>vue的v-for演示&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;li v-for=\"(user,index) in users\" :key=\"user.name\" v-if=\"user.gender == '女'\"> &lt;!-- 1. 显示user信息:v-for=\"item in items\" --> 当前索引:&amp;#123;&amp;#123;index&amp;#125;&amp;#125; ==>&amp;#123;&amp;#123;user.name&amp;#125;&amp;#125;==>&amp;#123;&amp;#123;user.gender&amp;#125;&amp;#125; =>&amp;#123;&amp;#123;user.age&amp;#125;&amp;#125; &lt;!-- 2. 获取数组的下标: v-for=\"(item,index) in users\"--> &lt;!-- 3. 遍历对象： v-for=\"value in object\" v-for = \"(value,key) in object\" v-for = \"(value,key,index) in object\" --> &lt;br> 对象信息 &lt;br> &lt;span v-for=\"(v,k,i) in user\"> &amp;#123;&amp;#123;k&amp;#125;&amp;#125; ==>&amp;#123;&amp;#123;v&amp;#125;&amp;#125; =>&amp;#123;&amp;#123;i&amp;#125;&amp;#125; &lt;br> &lt;/span> &lt;/li> &lt;!-- 4. 遍历的时候,加上:key 来区分不同的数据,提高vue 的渲染效率--> &lt;ul> &lt;li v-for=\"(num,index) in nums\" :key=\"index\"> &amp;#123;&amp;#123;num&amp;#125;&amp;#125; &lt;/li> &lt;/ul> &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> let vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; users: [&amp;#123; name: \"张三\", age: 18, gender: '男' &amp;#125;, &amp;#123; name: \"李四\", age: 26, gender: '女' &amp;#125;, &amp;#123; name: \"王五\", age: 35, gender: '男' &amp;#125;, &amp;#123; name: \"赵六\", age: 48, gender: '男' &amp;#125; ], nums: [2, 3, 5, 2, 1] &amp;#125;, methods: &amp;#123; &amp;#125; &amp;#125;); &lt;/script> &lt;/html> 过滤器&lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>vue 过滤器&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;!-- 过滤器通常用来处理文本格式化的操作,过滤器可以用在两个地方: 双花括号插值和v-bind 表达式--> &lt;ul> &lt;li v-for=\"user in users\"> &amp;#123;&amp;#123;user.name&amp;#125;&amp;#125; ==> &amp;#123;&amp;#123;user.age&amp;#125;&amp;#125; ==>&amp;#123;&amp;#123;user.gender == 1 ? \"男\":\"女\"&amp;#125;&amp;#125; ==> &amp;#123;&amp;#123;user.gender | genderFilter&amp;#125;&amp;#125; ==> &amp;#123;&amp;#123;user.gender | gFilter&amp;#125;&amp;#125; &lt;!-- 这里的| 表示管道,将--user.gender的值交给genderFilter --> &lt;/li> &lt;/ul> &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> // 全局过滤器 Vue.filter(\"gFilter\", function(val) &amp;#123; if (val == 1) &amp;#123; return \"男...\" &amp;#125; else if (val == 0) &amp;#123; return \"女...\" &amp;#125; &amp;#125;) let vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; users: [&amp;#123; name: \"张三\", age: 18, gender: '1' &amp;#125;, &amp;#123; name: \"李四\", age: 26, gender: '0' &amp;#125;, &amp;#123; name: \"王五\", age: 35, gender: '1' &amp;#125;, &amp;#123; name: \"赵六\", age: 48, gender: '1' &amp;#125; ] &amp;#125;, methods: &amp;#123; &amp;#125;, filters: &amp;#123; // filters 定义局部过滤器,只能在当前vue实例中使用 genderFilter(val) &amp;#123; if (val == 1) &amp;#123; return \"男\" &amp;#125; else if (val == 0) &amp;#123; return \"女\" &amp;#125; &amp;#125; &amp;#125; &amp;#125;); &lt;/script> &lt;/html> 组件化&lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>vue的组件化&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;button @click=\"count++\">我被点击了&amp;#123;&amp;#123;count&amp;#125;&amp;#125;次 &lt;/button>&lt;br> &lt;counter>&lt;/counter> &lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;!-- 使用所定义的组件button-counter --> &lt;button-counter>&lt;/button-counter>&lt;br> &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> // 1. 全局声明注册一个组件 Vue.component(\"counter\", &amp;#123; template: `&lt;button v-on:click=\"count++\">我被点击了 &amp;#123;&amp;#123;count&amp;#125;&amp;#125; 次&lt;/button>`, data() &amp;#123; return &amp;#123; count: 1 &amp;#125; &amp;#125; &amp;#125;); // 2. 局部声明一个组件 const buttonCounter = &amp;#123; template: `&lt;button v-on:click=\"count++\">我被点击了 &amp;#123;&amp;#123;count&amp;#125;&amp;#125; 次........&lt;/button>`, data() &amp;#123; return &amp;#123; count: 1 &amp;#125; &amp;#125; &amp;#125; vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; count: 1 &amp;#125;, components: &amp;#123; // 声明所定义的局部组件 \"button-counter\": buttonCounter &amp;#125;, methods: &amp;#123; &amp;#125; &amp;#125;); &lt;/script> &lt;/html> 生命周期钩子函数&lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>vue的组件化&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;button @click=\"count++\">我被点击了&amp;#123;&amp;#123;count&amp;#125;&amp;#125;次 &lt;/button>&lt;br> &lt;counter>&lt;/counter> &lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;counter>&lt;/counter>&lt;br> &lt;!-- 使用所定义的组件button-counter --> &lt;button-counter>&lt;/button-counter>&lt;br> &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> // 1. 全局声明注册一个组件 Vue.component(\"counter\", &amp;#123; template: `&lt;button v-on:click=\"count++\">我被点击了 &amp;#123;&amp;#123;count&amp;#125;&amp;#125; 次&lt;/button>`, data() &amp;#123; return &amp;#123; count: 1 &amp;#125; &amp;#125; &amp;#125;); // 2. 局部声明一个组件 const buttonCounter = &amp;#123; template: `&lt;button v-on:click=\"count++\">我被点击了 &amp;#123;&amp;#123;count&amp;#125;&amp;#125; 次........&lt;/button>`, data() &amp;#123; return &amp;#123; count: 1 &amp;#125; &amp;#125; &amp;#125; vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; count: 1 &amp;#125;, components: &amp;#123; // 声明所定义的局部组件 \"button-counter\": buttonCounter &amp;#125;, methods: &amp;#123; &amp;#125; &amp;#125;); &lt;/script> &lt;/html> 生命钩子函数&lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>vue&lt;/title> &lt;/head> &lt;body> &lt;div id=\"app\"> &lt;span id=\"num\"> &amp;#123;&amp;#123;num&amp;#125;&amp;#125; &lt;/span> &lt;button @click=\"num++\">赞&lt;/button> &lt;h2>&amp;#123;&amp;#123;name&amp;#125;&amp;#125;,有&amp;#123;&amp;#123;num&amp;#125;&amp;#125;人点赞&lt;/h2> &lt;/div&lt;> &lt;/body> &lt;script src=\"./node_modules/vue/dist/vue.js\">&lt;/script> &lt;script> let vue = new Vue(&amp;#123; el: \"#app\", data: &amp;#123; num: 1, name: \"张三\" &amp;#125;, methods: &amp;#123; show() &amp;#123; return this.name; &amp;#125;, add() &amp;#123; this.num++; &amp;#125; &amp;#125;, beforeCreate() &amp;#123; console.log(\"=========beforeCreate=============\"); console.log(\"数据模型未加载：\" + this.name, this.num); console.log(\"方法未加载：\" + this.show()); console.log(\"html模板未加载：\" + document.getElementById(\"num\")); &amp;#125;, created: function () &amp;#123; console.log(\"=========created=============\"); console.log(\"数据模型已加载：\" + this.name, this.num); console.log(\"方法已加载：\" + this.show()); console.log(\"html模板已加载：\" + document.getElementById(\"num\")); console.log(\"html模板未渲染：\" + document.getElementById(\"num\").innerText); &amp;#125;, beforeMount() &amp;#123; console.log(\"=========beforeMount=============\"); console.log(\"html模板未渲染：\" + document.getElementById(\"num\").innerText); &amp;#125;, mounted() &amp;#123; console.log(\"=========mounted=============\"); console.log(\"html模板已渲染：\" + document.getElementById(\"num\").innerText); &amp;#125;, beforeUpdate() &amp;#123; console.log(\"=========beforeUpdate=============\"); console.log(\"数据模型已更新：\" + this.num); console.log(\"html模板未更新：\" + document.getElementById(\"num\").innerText); &amp;#125;, updated() &amp;#123; console.log(\"=========updated=============\"); console.log(\"数据模型已更新：\" + this.num); console.log(\"html模板已更新：\" + document.getElementById(\"num\").innerText); &amp;#125; &amp;#125;); &lt;/script> &lt;/html>","categories":[{"name":"vue","slug":"vue","permalink":"https://rainsoil.github.io/categories/vue/"},{"name":"前端","slug":"vue/前端","permalink":"https://rainsoil.github.io/categories/vue/%E5%89%8D%E7%AB%AF/"},{"name":"前端","slug":"vue/前端/前端","permalink":"https://rainsoil.github.io/categories/vue/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/"},{"name":"vue","slug":"vue/前端/前端/vue","permalink":"https://rainsoil.github.io/categories/vue/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/vue/"}],"tags":[]},{"title":"Redis一主二从Sentinel监控配置","slug":"安装/Redis一主二从Sentinel监控配置","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/redis-yi-zhu-er-cong-sentinel-jian-kong-pei-zhi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/redis-yi-zhu-er-cong-sentinel-jian-kong-pei-zhi/","excerpt":"","text":"Redis一主二从Sentinel监控配置开启哨兵模式，至少需要3个Sentinel实例（奇数个，否则无法选举Leader）。本例通过3个Sentinel实例监控3个Redis服务（1主2从）。 IP地址 节点角色&amp;端口 192.168.8.203 Master：6379 / Sentinel : 26379 192.168.8.204 Slave ：6379 / Sentinel : 26379 192.168.8.205 Slave ：6379 / Sentinel : 26379 在204和205的redis.conf配置中添加一行 slaveof 192.168.8.203 6379 在203、204、205创建sentinel配置文件（单例安装后根目录下默认有sentinel.conf，可以先备份默认的配置） cd /usr/local/soft/redis-5.0.5 mkdir logs mkdir rdbs mkdir sentinel-tmp cp sentinel.conf sentinel.conf.bak &gt;sentinel.conf vim sentinel.conf sentinel.conf配置文件内容，三台机器相同 daemonize yes port 26379 protected-mode no dir &quot;/usr/local/soft/redis-5.0.5/sentinel-tmp&quot; sentinel monitor redis-master 192.168.8.203 6379 2 sentinel down-after-milliseconds redis-master 30000 sentinel failover-timeout redis-master 180000 sentinel parallel-syncs redis-master 1 在3台机器上分别启动Redis和Sentinel cd /usr/local/soft/redis-5.0.5/src ./redis-server ../redis.conf ./redis-sentinel ../sentinel.conf 哨兵节点的另一种启动方式： ./redis-server ../sentinel.conf --sentinel 在3台机器上查看集群状态： $ /usr/local/soft/redis-5.0.5/src/redis-cli redis&gt; info replication 模拟master宕机，在203执行： redis&gt; shutdown 注意看sentinel.conf里面的redis-master被修改了，变成了当前master的IP端口。 $ /usr/local/soft/redis-5.0.5/src/redis-cli redis&gt; info replication 这个时候会有一个slave节点被Sentinel设置为master。再次启动master，它不一定会被选举为master。 slave宕机和恢复测试省略。 注意这里有的同学遇到了坑，1、slave可以显示master信息，而master没有slave信息。2、master宕机后slave没有被提升为master。 可能有几个主要原因：1、master信息配置不正确。","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"Docker安装RabbitMQ集群","slug":"安装/Docker安装RabbitMQ集群","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/docker-an-zhuang-rabbitmq-ji-qun/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/docker-an-zhuang-rabbitmq-ji-qun/","excerpt":"","text":"Docker安装RabbitMQ集群环境CentOS 7机器IP：192.168.8.1461个磁盘节点+2个内存节点 一、安装docker这个过程里面可能会遇到很多问题，不要慌，根据错误提示来解决。 参考：https://www.cnblogs.com/lonelyxmas/p/10430207.html1）更新yum源 sudo yum update 2）添加仓库 sudo yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 3）查看最新版本如果之前安装了docker，需要卸载旧版本 yum list docker-ce --showduplicates | sort -r 4)安装Docker CE版本 yum install docker-ce -y 二、安装RabbitMQ1）拉取RabbitMQ镜像（带managment） docker pull rabbitmq:3.7.17-management 2）创建docker网络（让容器可以和主机通信） docker network create rabbitmqnet 3）创建三个容器，端口分别是 5673 5674 5675 docker run -d \\ --name=rabbitmq1 \\ -p 5673:5672 \\ -p 15673:15672 \\ -e RABBITMQ_NODENAME=rabbitmq1 \\ -e RABBITMQ_ERLANG_COOKIE=&#39;RABBITMQ_COOKIE&#39; \\ -h rabbitmq1 \\ --net=rabbitmqnet \\ rabbitmq:management docker run -d \\ --name=rabbitmq2 \\ -p 5674:5672 \\ -p 15674:15672 \\ -e RABBITMQ_NODENAME=rabbitmq1 \\ -e RABBITMQ_ERLANG_COOKIE=&#39;RABBITMQ_COOKIE&#39; \\ -h rabbitmq2 \\ --net=rabbitmqnet \\ rabbitmq:management docker run -d \\ --name=rabbitmq3 \\ -p 5675:5672 \\ -p 15675:15672 \\ -e RABBITMQ_NODENAME=rabbitmq1 \\ -e RABBITMQ_ERLANG_COOKIE=&#39;RABBITMQ_COOKIE&#39; \\ -h rabbitmq3 \\ --net=rabbitmqnet \\ rabbitmq:management 4）后两个节点作为内存节点加入集群 docker exec -it rabbitmq2 /bin/bash rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster --ram rabbitmq1@rabbitmq1 rabbitmqctl start_app docker exec -it rabbitmq3 /bin/bash rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster --ram rabbitmq1@rabbitmq1 rabbitmqctl start_app 访问：http://192.168.8.146:15673/guest/guest登录","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"ConcurrentHashMap 源码分析(6)","slug":"并发编程/ConcurrentHashMap 源码分析(6)","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/bing-fa-bian-cheng/concurrenthashmap-yuan-ma-fen-xi-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/bing-fa-bian-cheng/concurrenthashmap-yuan-ma-fen-xi-6/","excerpt":"","text":"6. ConcurrentHashMap的源码分析ConcurrentHashMap的初步使用以及场景CHM的使用ConcurrentHashMap是J.U.C包里面提供的一个线程安全并且高效的HashMap,所以ConcurrentHashMap在并发场景中使用的效率比较高 api 的使用ConcurrentHashMap 是Map的派生类,所以api基本上和HashMap是类似的,只要就是put、get这些方法,接下来基于ConcurrentHashMap 的put和get方法作为切入点分析ConcurrentHashMap的源码实现 ConcurrentHashMap的源码分析先要做一个声明,本文中分析的ConcurrentHashMap是基于JDK1.8版本的 jdk1.7和jdk1.8版本的变化ConcurrentHashMap和HashMap的实现源码差不多,但是因为ConcurrentHashMap需要支持并发操作,所以实现上要比hashMap稍微复杂一些. 在JDK1.7的实现上,ConcurrentHashMap 由一个个Segment 组成,简单来说,ConcurrerntHashMap 是一个Segment 数组,它通过继承ReentrantLock 来进行加锁,通过每次锁住一个segment 来保证每个segment 内的操作的线程安全性从而实现全局线程安全. 整个结构图如下： 当我们操作分布在不同的segment上的时候,默认情况下,理论上可以同时支持16个线程的并发写入. 相比于1.7版本,他做了两个改进 取消了segment分段设计,直接使用Node数组来保存数据,并且采用Node数组元素作为锁来实现每一行数据进行加锁来进一步减少并发冲突的概率 将原本数组+单向链表的数据结构变更为了数组+单向链表+红黑树的结构.为什么要引入红黑树呢?在正常情况下,key hash 之后如果能够很均匀的分散在数组中,那么table 数组中的每个队里偶尔的长度主要为0，或者1. 但是实际情况下,还是会存在一些队列长度多长的情况下. 如果还采用单向列表的方式,那么查询某个节点的时间复杂度就变为了O(N);因此对于队列长度超过8的列表,JDK1.8采用了红黑树的结构,那么查询的时间复杂度就会降低到O(logN),可以提升查找的性能. 这个结构和JDK1.8中的HashMap的数据结构基本一致,但是为了保证线程安全性,COncurrentHashMap的实现会稍微复杂一下.接下来我们从源码层面来了解一下他的原理.我们基于put和get方法来分析它的实现即可. put方法第一阶段 public V put(K key, V value) &amp;#123; return putVal(key, value, false); &amp;#125; final V putVal(K key, V value, boolean onlyIfAbsent) &amp;#123; if (key == null || value == null) throw new NullPointerException(); // 计算hash值 int hash = spread(key.hashCode()); // 用来记录链表的长度 int binCount = 0; // 这里其实就是个自旋,当出现线程竞争时不断自旋 for (Node&lt;K,V>[] tab = table;;) &amp;#123; Node&lt;K,V> f; int n, i, fh; // 如果数组为空,则进行数组初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 通过hash值对应的数组下表得到第一个节点,以volatile 读的方式来读取table数组中的元素,保证每次拿到的数据都是最新的 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &amp;#123; // 如果该下表返回的节点为空,则直接通过CAS 将新的值封装成Node插入即可,如果CAS失败,说明存在竞争,进入下一次循环, if (casTabAt(tab, i, null, new Node&lt;K,V>(hash, key, value, null))) break; // no lock when adding to empty bin &amp;#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &amp;#123; V oldVal = null; synchronized (f) &amp;#123; if (tabAt(tab, i) == f) &amp;#123; if (fh >= 0) &amp;#123; binCount = 1; for (Node&lt;K,V> e = f;; ++binCount) &amp;#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &amp;#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &amp;#125; Node&lt;K,V> pred = e; if ((e = e.next) == null) &amp;#123; pred.next = new Node&lt;K,V>(hash, key, value, null); break; &amp;#125; &amp;#125; &amp;#125; else if (f instanceof TreeBin) &amp;#123; Node&lt;K,V> p; binCount = 2; if ((p = ((TreeBin&lt;K,V>)f).putTreeVal(hash, key, value)) != null) &amp;#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &amp;#125; &amp;#125; &amp;#125; &amp;#125; if (binCount != 0) &amp;#123; if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &amp;#125; &amp;#125; &amp;#125; addCount(1L, binCount); return null; &amp;#125; 假如在上面的这段代码中存在两个线程,在不加锁的情况下: 线程A 成功执行 casTabAt操作后,随后的线程B可以通过tabAt 方法立即看到 table[i] 的改变. 原因如下: 线程A的casTabAt 操作,具有 volatile 读写相同的内存语义,根据volatile 的happens-before 规则: 线程A 的casTabAt 操作一定对线程B的tabAt 操作可见. initTable数组初始化方法,这个方法比较简单,就是初始化一个合适大小的数组,sizeCtl 这个要单独说一下,如果没有搞懂这个属性的意义,可能会被搞晕,这个标志是在Node数组初始化或者扩容的时候的一个控制位标识,负数代表正在进行初始化或者扩容操作. -1 代表正在初始化 -N 代表有N-1 个线程正在进行扩容操作, 这里不是简单的理解成n个线程,sizeCtl 就是-N,这块在后续讲扩容的时候会说明. 0 表示Node数组还没有被初始化,整数代表初始化或者下一次扩容的大小. private final Node&lt;K,V>[] initTable() &amp;#123; Node&lt;K,V>[] tab; int sc; while ((tab = table) == null || tab.length == 0) &amp;#123; // 被其他线程抢占了初始化操作,则直接让出自己的CPU 时间片 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // 通过CAS操作,将sizeCrl 替换为-1, 表示当前线程抢占到了初始化资格 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &amp;#123; try &amp;#123; if ((tab = table) == null || tab.length == 0) &amp;#123; // 默认的初始容量为16 int n = (sc > 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") // 初始化数组,长度为16,或者初始化在构造concurrentHashMap的时候传入的长度 Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n]; // 将这个数组赋值给table table = tab = nt; // 计算下次扩容的大小,实际就是当前容量的0.075倍,这里使用了右移操作. sc = n - (n >>> 2); &amp;#125; &amp;#125; finally &amp;#123; // 设置sizeCtl 为sc,如果默认是16的话,那么这个时候sc = 16*0.75 = 12 sizeCtl = sc; &amp;#125; break; &amp;#125; &amp;#125; return tab; &amp;#125; tabAt该方法获取对象中offset偏移地址对应的对象field的值.实际上这段代码的含义等价于tab[i], 但是为什么不直接使用tab[i] 来计算呢? getObjectVolatile ,一旦看到 volatile关键字,就表示可见性. 因为对 volatile 写操作happens-before 于vloatile 读操作,因此其他线程对table 的修改对get 读取可见. 虽然table 数组本身是增加了volatile 属性,但是”volatile的数组只针对数组的引用具有volatile的语义,而不是它的元素”.所以如果有其他的线程对这个数组的元素进行写操作,那么当前线程来读的时候不一定能读取到最新的值. 出于性能考虑,Doug Lea 直接通过Unsafe 类对table 进行操作 static final &lt;K,V> Node&lt;K,V> tabAt(Node&lt;K,V>[] tab, int i) &amp;#123; return (Node&lt;K,V>)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE); &amp;#125; 图解分析 put方法第二阶段在putVal方法执行完成以后,会通过addCount 来增加ConcurrentHashMap中的元素个数,并且还会可能触发扩容操作,这里会有两个非常经典的设计 高并发下的扩容 如何保证addCount 的数据安全性以及性能 // 将当前的concurrentHashMap 的元素数量加1,有可能触发 transfer操作(扩容) addCount(1L, binCount); return null; &amp;#125; addCount 在putVal 最后调用了addCount 的时候,传递了两个参数,分别是1和bigCount(链表长度),看看 addCount 方法里面做了什么操作呢? x表示这次需要在表中增加的元素个数,check参数表示是否需要进行扩容检查,大于等于0 都需要进行检查 private final void addCount(long x, int check) &amp;#123; CounterCell[] as; long b, s; // 判断 counterCells 是否为空, // 1. 如果为空,就通过CAS 操作尝试修改baseCount 变量,对这个变量进行原子累加操作(做这个操作的意义是: 如果在没有竞争的情况下 // 仍然采用baseCount 来记录元素的个数) // 2. 如果CAS失败则说明存在竞争,这个时候不能采用baseCount 来累加,而是用过counterCells 来记录 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &amp;#123; CounterCell a; long v; int m; // 是否冲突标识,默认没有冲突. // 这里有几个判断 // 1. 计数表为空则直接调用 fullAddCount // 2. 从计数表汇总随机取出一个数组的位置为空,则直接调用 fullAddCount // 3. 通过CAS 修改CountCell随机位置的值,如果修改失败说明出现并发情况(这里又用到了一种巧妙的办法),调用 fullAddCount // Random 在线程并发的时候会有性能问题以及可能会产生相同的随机数,ThreadLocalRandom.getProbe,可以解决这个问题,并且性能要比Random 高 boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &amp;#123; // 执行 fullAddCount 方法 fullAddCount(x, uncontended); return; &amp;#125; // 链表长度小于等于1,不需要考虑扩容 if (check &lt;= 1) return; // 统计concurrentHashMap 元素个数 s = sumCount(); &amp;#125; if (check >= 0) &amp;#123; Node&lt;K,V>[] tab, nt; int n, sc; while (s >= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &amp;#123; int rs = resizeStamp(n); if (sc &lt; 0) &amp;#123; if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &amp;#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &amp;#125; &amp;#125; &amp;#125; CounterCells 解释ConcurrentHashMap 是采用CounterCells 数组来记录元素个数的,像一般的集合记录记录集合大小,直接定义一个size 成员变量就行了，当出现改变的时候只要更新这个变量就行了.为什么ConcurrentHashMap 要用这种形式来处理呢? 问题还是出在并发上,ConcurrentHashMap是并发集合,如果用一个成员变量来统计元素的个数的话,为了保证并发情况下共享变量的安全,势必会需要通过加锁或者自旋的方式来实现,如果竞争比较激烈的情况下,size 的设置上会出现比较大的冲突反而影响了性能,所以在ConcurrentHaashMap 采用了分片的方法来记录大小,具体什么意思,我们来分析下 // 标识当前cell数组是否在初始化或者扩容中的CAS 标识位 private transient volatile int cellsBusy; /** * Table of counter cells. When non-null, size is a power of 2. */ // counterCells 数组,总数值的分数分别存在每个cell中 private transient volatile CounterCell[] counterCells; @sun.misc.Contended static final class CounterCell &amp;#123; volatile long value; CounterCell(long x) &amp;#123; value = x; &amp;#125; &amp;#125; // 看到这段代码就能明白了,CountCell 数组的每个元素都存储一个元素个数,而实际上我们调用size方法就是通过这个循环累加来得到的 final long sumCount() &amp;#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &amp;#123; for (int i = 0; i &lt; as.length; ++i) &amp;#123; if ((a = as[i]) != null) sum += a.value; &amp;#125; &amp;#125; return sum; &amp;#125; fullAddCount 源码分析fullAddCount 主要是用来初始化 CountCell来记录元素个数的,里面包含了扩容,初始化等操作 // See LongAdder version for explanation private final void fullAddCount(long x, boolean wasUncontended) &amp;#123; int h; // 获得当前线程的probe的值,如果值为0,则初始化当前线程的probe的值,probe就是随机数 if ((h = ThreadLocalRandom.getProbe()) == 0) &amp;#123; ThreadLocalRandom.localInit(); // force initialization h = ThreadLocalRandom.getProbe(); // 由于重新生成了probe, 未冲突标志位设置为true wasUncontended = true; &amp;#125; boolean collide = false; // True if last slot nonempty // 自旋 for (;;) &amp;#123; CounterCell[] as; CounterCell a; int n; long v; // 说明countCells 已经被初始化过了 if ((as = counterCells) != null &amp;&amp; (n = as.length) > 0) &amp;#123; // 通过该值于当前线程probe 求与,获得cells的下标元素,和hash表获得索引是一样的 if ((a = as[(n - 1) &amp; h]) == null) &amp;#123; // cellsBusy = 0 表示countCells 不在初始化或者扩容状态下 if (cellsBusy == 0) &amp;#123; // Try to attach new Cell // 构造一个CounterCell 的值,传入元素个数 CounterCell r = new CounterCell(x); // Optimistic create // 通过cas 设置cellsBusy 标识,防止其他线程来对countCells 并发处理 if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &amp;#123; boolean created = false; try &amp;#123; // Recheck under lock CounterCell[] rs; int m, j; // 将初始化的r对象的元素个数放在对应下标的位置 if ((rs = counterCells) != null &amp;&amp; (m = rs.length) > 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &amp;#123; rs[j] = r; created = true; &amp;#125; &amp;#125; finally &amp;#123; // 恢复标识位 cellsBusy = 0; &amp;#125; // 如果创建成功,退出循环 if (created) break; // 说明指定cells 下标位置的数据不为空,则进行下一次循环 continue; // Slot is now non-empty &amp;#125; &amp;#125; collide = false; &amp;#125; // 说明在 addCount 方法中cas失败了,并且获取probe 的值不为空 else if (!wasUncontended) // CAS already known to fail // 设置为未冲突标识,进入下一次自旋 // 由于指定下标位置的cell值不为空,则直接通过cas进行原子累加,如果成功,则直接退出 wasUncontended = true; // Continue after rehash else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; // 如果已经有其他线程建立了新的countCells或者counterCells 大于CPU核心数(很巧妙,线程的并发数不会超过CPU核心数) else if (counterCells != as || n >= NCPU) // 设置当前线程的循环失败不进行扩容 collide = false; // At max size or stale // 恢复 collide 状态,标识下次循环会进行扩容 else if (!collide) // 进入这个步骤,说米用countCells 数组容量不够,线程竞争比较大,所以先设置一个表示为正在扩容 collide = true; else if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &amp;#123; try &amp;#123; if (counterCells == as) &amp;#123;// Expand table unless stale // 扩容一倍 2变成4, 这个扩容比较简单 CounterCell[] rs = new CounterCell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; counterCells = rs; &amp;#125; &amp;#125; finally &amp;#123; // 恢复标识 cellsBusy = 0; &amp;#125; collide = false; // 继续下一次自旋 continue; // Retry with expanded table &amp;#125; // 更新随机数的值 h = ThreadLocalRandom.advanceProbe(h); &amp;#125; // 初始化 CountCells 数组 // cellsBusy = 0 表示没有在做初始化,通过CAS 更新cellsBusy 的值标注当前线程正在做初始化操作 else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &amp;#123; boolean init = false; try &amp;#123; // Initialize table if (counterCells == as) &amp;#123; // 初始化容量为2 CounterCell[] rs = new CounterCell[2]; // 将x 也就是元素的个数放在指定的数组下标位置 rs[h &amp; 1] = new CounterCell(x); // 赋值给 counterCells counterCells = rs; // 设置初始化完成标识 init = true; &amp;#125; &amp;#125; finally &amp;#123; // 恢复标识 cellsBusy = 0; &amp;#125; if (init) break; &amp;#125; // 竞争激烈,其他线程占据cell数组,直接累加在base变量 else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; // Fall back on using base &amp;#125; &amp;#125; CounterCells 初始化图解初始化长度为2的数组,然后随机得到一个指定的数组下标,将需要新增的值加入到对应的下标位置处 transfer 扩容阶段判断是否需要扩容,也就是当更新后的键值对总数baseCount &gt;= 阈值 sizeCtl时,进行rehash, 这里面会有两个逻辑 如果当前正在处于扩容阶段,则当前线程会加入并且协助扩容 如果当前没有在扩容,则直接出发扩容操作 // 如果binCount >=0,标识需要检查扩容 if (check >= 0) &amp;#123; Node&lt;K,V>[] tab, nt; int n, sc; // s 标识集合大小,如果集合的长度大于或者等于扩容阈值(默认是0.75) 并且table不为空并且table的长度小于最大容量 while (s >= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &amp;#123; // 这里是生成一个唯一的扩容戳 int rs = resizeStamp(n); // sc&lt; 0 , 也就是 sizeCtl &lt; 0 说明已经有别的线程正在进行扩容了 if (sc &lt; 0) &amp;#123; // 这5个条件只有有一个条件为true, 说明当前线程不能帮助进行此次的扩容了,直接跳出循环 // (sc >>> RESIZE_STAMP_SHIFT) != 表示比较高 RESIZE_STAMP_SHIFT 位生成戳和rs 是否相等,相同 // sc == rs + 1 表示扩容结束 // sc == rs + MAX_RESIZERS 表示帮助线程线程已经达到最大值了 // nt = nextTable 表示扩容已经结束了 // transferIndex &lt;= 0 表示所有的 transfer 任务已经被领取完了,没有剩余的hash桶来给自己的这个线程做 transfer if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 当前线程尝试帮助此次扩容,如果成功,则调用transfer if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &amp;#125; // 如果当前没有在扩容，那么rs肯定是一个正数,通过(rs &lt;&lt; RESIZE_STAMP_SHIFT) 将rs 设置为一个负数,+2 表示有一个线程在执行扩容 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); // 重新计数,判断是否需要开启下一轮扩容 s = sumCount(); &amp;#125; &amp;#125; &amp;#125; resizeStamp这块的逻辑理解起来,也有一点复杂 resizeStamp 用来生成一个和扩容有关的扩容戳,具体有什么用呢? 我们基于他的实现来做一个分析 static final int resizeStamp(int n) &amp;#123; return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));&amp;#125; Integer.numberOfLeadingZeros(n) 这个方法是返回无符号整数n 最高位非0位前面的0的个数 比如10的二进制是 0000 0000 0000 0000 0000 0000 0000 1010 那么这个方法返回的值就是28 根据resizeStamp 的运算逻辑,我们来推演一下,加入n=16, 那么resizeStamp(16) = 32796,转换为二进制是 [0000 0000 0000 0000 1000 0000 0001 1100] 接下来来看,当第一个线程尝试进行扩容的时候,会执行下面这段代码 U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) rs 左移16位,相当于原本的二进制低位变成了高位 1000 0000 0001 1100 0000 0000 0000 0000 然后再+2 = 1000 0000 0001 1100 0000 0000 0000 0000 +10 = 1000 0000 0001 1100 0000 0000 0000 0010 高16位代表扩容的标记,低16位代表并行扩容的线程数 高RESIZE_STAMP_BITS位 低 RESIZE_STAMP_SHIFT 位 扩容标记 并行扩容线程数 这样来存储有什么好处？ 首先在CHM中是支持并发扩容的,也就是说如果当前的数组是需要进行扩容操作,可以由多个线程来共同负责, 可以保证每次扩容都生成唯一的时间戳,每次新的扩容,都有一个不同的n,这个生成的戳就是根据n来计算出来的一个数字,n不同,这个数字也不同. 第一次线程尝试扩容的时候,为什么是+2 因为1 表示初始化,2 表示一个线程正在扩容,而且对sizeCtl 的操作都是基于位运算的,所以不会关心它本身的数值是多,只关心它在二进制上的数值,而sc +1 会在低16位上+1 . transfer 扩容是ConcurrentHashMap 的精华之一,扩容操作的核心在于数组的转移,在单线程环境下数据的转移很简单,无非就是把旧数组中的数据迁移到新的数组. 但是这种多线程环境下,在扩容的时候其他线程也可能正在添加元素,这时又触发了扩容怎么办? 可能大家想到的第一个解决方案就是加互斥锁,把转移过程锁住,虽然是可行的方案,但是会带来较大的性能开销. 因为互斥锁会导致所有访问临界区的线程陷入到阻塞状态,持有锁的线程耗时越长,其他竞争线程就会一直被阻塞,导致吞吐量较低.而且还可能导致死锁. 而ConcurentHashMap 并没有直接加锁,而是采用CAS实现无锁的并发同步策略,最精华的部分就是它可以利用多线程来进行协同扩容. 简单来说, 它把Node数组当作多个线程之间共享的任务队列,然后通过维护一个指针来划分每个线程锁负责的区间,每个线程通过区间逆向便利来实现扩容,一个已经迁移完的blucket 会被替换为一个ForwardingNode节点,标记当前bucket 已经被其他线程迁移完了,接下来分析一下它的源码: fwd:这个类是个标识类,用于指向新表用的,其他线程遇到这个类会主动跳过这个类,因为这个类要么就是扩容迁移正在进行,要么就是已经完成扩容迁移,也就是这个类要保证线程安全,再进行操作. advance: 这个变量是用于提示代码是否进行推进处理的,也就是当前桶处理完,处理下一个桶的标识. finishing: 这个变量用于提示扩容是否结束用的. private final void transfer(Node&lt;K,V>[] tab, Node&lt;K,V>[] nextTab) &amp;#123; int n = tab.length, stride; // 将(n>>>3 相当于 n/8) 然后除以CPU核心数,如果得到的结果小于16,那么就使用16 // 这里的目的是让每个CPU处理的桶一样多,避免处理转移任务不均匀的现象,如果桶较少的话,默认一个CPU(一个线程)处理16个桶 // 这就是长度为16的时候,扩容的时候只会有一个线程来扩容. if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // nextTab 未初始化,nextTab是用来扩容的node数组 if (nextTab == null) &amp;#123; // initiating try &amp;#123; @SuppressWarnings(\"unchecked\") // 新建一个 n&lt;&lt;1 原始table 大小的nextTab ,也就是32 Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n &lt;&lt; 1]; // 赋值给nextTab nextTab = nt; &amp;#125; catch (Throwable ex) &amp;#123; // try to cope with OOME // 扩容失败,sizeCtl就是用int的最大值 sizeCtl = Integer.MAX_VALUE; return; &amp;#125; // 更新成员变量 nextTable = nextTab; // 更新转移下标,表示转移时的下标 transferIndex = n; &amp;#125; // 新的tab的长度 int nextn = nextTab.length; // 创建一个fwd 节点,表示一个正在被迁移的Node,并且它的hash值为-1(MOVED), 也就是前面我们在讲putval方法的时候,会有一个判断 MOVED的逻辑.它的作用是 // 用来占位的,表示原数组中位置i处的节点完成迁移以后,就会在i位置设置一个fwd 来告诉其他线程这个位置已经处理过了 ForwardingNode&lt;K,V> fwd = new ForwardingNode&lt;K,V>(nextTab); // 首次推进为true, 如果等于true,说明需要再次推进一个下标(i--),反之,如果是false, 那么就不能推进下标,需要将当前的下标处理完毕后才能继续推进 boolean advance = true; // 判断是否已经扩容完成,完成就return, 退出循环 boolean finishing = false; // to ensure sweep before committing nextTab // 通过for 自循环处理每个槽位中的链表元素,默认为advace为真,通过CAS设置 // transferIndex 属性值,并初始化i和 bound的值,i指当前处理的槽位序号, // bound 指需要处理的槽位边界,先处理槽位15的节点 for (int i = 0, bound = 0;;) &amp;#123; // 这个循环使用CAS 不断的尝试为当前线程分配任务 // 直到分配成功或者任务队列已经被全部分配完毕 // 如果当前线程已经被分配过bucket 区域 // 那么会通过i-- 指向下一个待处理的bucket 然后退出循环 Node&lt;K,V> f; int fh; while (advance) &amp;#123; int nextIndex, nextBound; // --i 表示下一个待处理的 bucket , 如果他 >=bound, 表示当前线程已经分配过 bucket 区域 if (--i >= bound || finishing) advance = false; // 表示所有的bucket 已经被分配完毕了 else if ((nextIndex = transferIndex) &lt;= 0) &amp;#123; i = -1; advance = false; &amp;#125; // 通过CAS 修改TRANSFERINDEX 为当前线程分配任务,处理的节点区间为 (nextBound,nextIndex)->(0,15) else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex > stride ? nextIndex - stride : 0))) &amp;#123; bound = nextBound; //0 i = nextIndex - 1;// 15 advance = false; &amp;#125; &amp;#125; // i&lt;0 说明已经完成遍历完旧的数组,也就是当前线程已经处理完所有的负债的 bucket if (i &lt; 0 || i >= n || i + n >= nextn) &amp;#123; int sc; // 如果完成了扩容 if (finishing) &amp;#123; // 删除成员变量 nextTable = null; // 更新table 数组 table = nextTab; // 更新阈值(32*0.75 = 24) sizeCtl = (n &lt;&lt; 1) - (n >>> 1); return; &amp;#125; // sizeCtl 在迁移前会设置为( (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 然后,每增加一个线程参会迁移都会对sizeCtl 加1 // 这里使用 CAS 操作对sizeCtl 的低16位进行减1,代表做完了属于自己的任务 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &amp;#123; // 第一个扩容的线程,执行 transfer 方法之前,会设置 sizeCtl = (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 后续帮其扩容的线程执行 transfer 方法之前,会设置 sizeCtl = sizeCtl+1 // 每一个退出transfer 的方法的线程,退出之前会设置 sizeCtl = sizeCtl-1,那么最后一个线程退出时:必然有 //sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2)，即 (sc - 2)== resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT // 如果sc -2 不等于标识符 左移16位.如果他们相等了,说明没有线程在帮助他们扩容了,也就是说,扩容结束了, if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 如果相等,扩容结束了,更新finishing的值 finishing = advance = true; // 再次循环检查一下整张表 i = n; // recheck before commit &amp;#125; &amp;#125; // 如果位置i处是空,没有任何节点,那么放入刚刚初始化的 ForwardingNode\"空节点\" else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 表示该位置已经完成了迁移,也就是如果线程A 已经处理过了这个节点,那么线程B处理这个节点时,hash值一定为MOVED else if ((fh = f.hash) == MOVED) advance = true; // already processed else &amp;#123; synchronized (f) &amp;#123; if (tabAt(tab, i) == f) &amp;#123; Node&lt;K,V> ln, hn; if (fh >= 0) &amp;#123; int runBit = fh &amp; n; Node&lt;K,V> lastRun = f; for (Node&lt;K,V> p = f.next; p != null; p = p.next) &amp;#123; int b = p.hash &amp; n; if (b != runBit) &amp;#123; runBit = b; lastRun = p; &amp;#125; &amp;#125; if (runBit == 0) &amp;#123; ln = lastRun; hn = null; &amp;#125; else &amp;#123; hn = lastRun; ln = null; &amp;#125; for (Node&lt;K,V> p = f; p != lastRun; p = p.next) &amp;#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V>(ph, pk, pv, ln); else hn = new Node&lt;K,V>(ph, pk, pv, hn); &amp;#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &amp;#125; else if (f instanceof TreeBin) &amp;#123; TreeBin&lt;K,V> t = (TreeBin&lt;K,V>)f; TreeNode&lt;K,V> lo = null, loTail = null; TreeNode&lt;K,V> hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V> e = t.first; e != null; e = e.next) &amp;#123; int h = e.hash; TreeNode&lt;K,V> p = new TreeNode&lt;K,V> (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &amp;#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &amp;#125; else &amp;#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &amp;#125; &amp;#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V>(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V>(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 扩容过程图解ConcurrentHashMap 支持并发扩容,实现方式,把Node数组进行拆分,让每个线程处理自己的区域,假设table的数组总长度为64,默认情况下,那么每个线程可以分到16个bucket. 然后每个线程处理的范围,按照倒序来做迁移, 通过for 自循环处理每个槽位中的链表元素,默认advace 为真,通过CAS 设置transferIndex 属性值,并初始化i和bound的值,i指当前处理的槽位序号,bound指需要处理的槽位边界,先处理槽位31的节点 (bound,i) = (16,31),从31的位置往前推动, 假设这个时候ThreadA在进行transfer ,那么逻辑图表示如下: 在当前假设情况下,槽位15中没有节点,则通过CAS 插入到第二步的初始化的 ForwardingNode节点,用于告诉其他线程该槽位已经处理过了. sizeCtl 扩容退出机制在扩容操作 transfer 的第2414行, 代码如下: if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &amp;#123; // 第一个扩容的线程,执行 transfer 方法之前,会设置 sizeCtl = (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 后续帮其扩容的线程执行 transfer 方法之前,会设置 sizeCtl = sizeCtl+1 // 每一个退出transfer 的方法的线程,退出之前会设置 sizeCtl = sizeCtl-1,那么最后一个线程退出时:必然有 //sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2)，即 (sc - 2)== resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT // 如果sc -2 不等于标识符 左移16位.如果他们相等了,说明没有线程在帮助他们扩容了,也就是说,扩容结束了, if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 如果相等,扩容结束了,更新finishing的值 finishing = advance = true; // 再次循环检查一下整张表 i = n; // recheck before commit &amp;#125; 每存在一个线程执行完扩容操作,就通过CAS 执行sc -1 接着判断(sc-2) != resizeStamp(n)&lt;&lt; RESIZE_STAMP_SHIFT; 如果相等, 表示当前为整个扩容操作的最后一个线程,那么意味着整个扩容操作就结束了; 如果不相等,说明还得继续. 这么做的目的,一方面是防止不同扩容之间出现相同的sizeCtl, 另一方面,还可以避免sizeCtl的ABA问题 导致的扩容重叠问题. 数据迁移阶段的实现分析通过分配好迁移的区间之后,开始对数据进行迁移 // 对数组该节点位置加锁,开始处理数组该位置的迁移工作 synchronized (f) &amp;#123; // 在做一次校验 if (tabAt(tab, i) == f) &amp;#123; // ln 表示低位,hn表示高位,接下来这段代码的作用是将链表拆分为两部分,0在低位,1在高位. Node&lt;K,V> ln, hn; if (fh >= 0) &amp;#123; int runBit = fh &amp; n; Node&lt;K,V> lastRun = f; // 遍历当前 bucket 的链表,目的是尽量重用Node链表尾部的一部分 for (Node&lt;K,V> p = f.next; p != null; p = p.next) &amp;#123; int b = p.hash &amp; n; if (b != runBit) &amp;#123; runBit = b; lastRun = p; &amp;#125; &amp;#125; // 如果最后更新的runBit是0,设置低位节点 if (runBit == 0) &amp;#123; ln = lastRun; hn = null; &amp;#125; else &amp;#123; // 否则,设置高位节点 hn = lastRun; ln = null; &amp;#125; for (Node&lt;K,V> p = f; p != lastRun; p = p.next) &amp;#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V>(ph, pk, pv, ln); else hn = new Node&lt;K,V>(ph, pk, pv, hn); &amp;#125; // 将低位的链表放在i位置上也就是不动 setTabAt(nextTab, i, ln); // 将高位链表放在i+n位置点,表示此hash 桶已经被处理 setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &amp;#125; 高低位原理分析CocurrentHashMap 在做链表迁移时,会用高低位来实现,这里有两个问题要分析一下, 如何实现高低位链表的区分 假设我们有这样一个队列 第14个槽位插入新的节点之后,链表元素个数已经达到了8,且数组的长度为16,优先通过扩容来缓解链表过长的问题,库哦哦让这块的图解稍后在分析,先分析高低位扩容的原理. 加入当前线程正在处理槽位为14的节点,它是一个链表结构,在代码中,首先定义两个变量节点 ln和hn,实际上就是lowNode和highNode, 分别保存hash值的第x位为0和不等于0的节点 通过fn&amp;n 就可以把这个链表的元素分为两类,A累是hash值的第X位为0,B类是hash值的第X位不等于0,并且通过lastRun记录最后要处理的节点.最终要达到的目的是,A类的链表保持位置不对,B类的链表为14+16(扩容增加的长度) = 30 我们把14槽位的链表单独拎出来,我们用蓝色来标识fn&amp;n=0的接待你,假设链表的分类是这样的 for (Node&lt;K,V> p = f.next; p != null; p = p.next) &amp;#123; int b = p.hash &amp; n; if (b != runBit) &amp;#123; runBit = b; lastRun = p; &amp;#125; &amp;#125; 通过上面的代码遍历,会记录 runBit以及lastRun,按照上面的这个结构,那么runBit 应该是蓝色节点,lastRun 应该是第6个节点 接着,再通过这段代码进行遍历,生成ln链以及hn链 for (Node&lt;K,V> p = f; p != lastRun; p = p.next) &amp;#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V>(ph, pk, pv, ln); else hn = new Node&lt;K,V>(ph, pk, pv, hn); &amp;#125; 接着,通过CAS操作,把hn链放在i+n也就是 14+16的位置上,ln链保持原来的位置不动,并且设置当前节点为fwd, 表示已经被当前线程迁移完了. // 将低位的链表放在i位置上也就是不动 setTabAt(nextTab, i, ln); // 将高位链表放在i+n位置点,表示此hash 桶已经被处理 setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); 迁移完成以后的数据分布如下： 为什么要做高低位的划分要想了解这么设计的目的,我们需要从ConcurrentHashMap 的根据下标获取对象的算法来看,在putVal 方法中1018行 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &amp;#123; 通过 (n-1)&amp;hash 来获得在 table 中的数组下标来获取节点数据(&amp;运算是二进制运算符,1&amp;1=1,其它都为0) 假设我们的table长度为16,二进制是[0001 1000],减一以后的二进制是[0000 1111]. 假如某个key的hash值=9对应的二进制是[0000 1001],那么按照(n-1)&amp;hash的算法 0000 1111 &amp; 0000 1001 = 0000 1001 ，运算结果是9 当我们扩容后,16 变成了32，那么(n-1)的二进制是[ 0001 1111 ] 仍然以hash 值 = 9 的二进制计算为例 0001 1111 &amp; 0000 1001 = 0000 1001,运算结果仍然是9 我们换一个数字,假如某个key的hash值为20,对应的二进制是[0001 0100],仍然按照(n-1)&amp;hash 算法,分别在16长度和32长度下的计算结果 16位:0000 1111 &amp; 0001 0100 = 0000 0100 32位: 0001 1111 &amp; 0001 0100 = 0001 0100 从结果上看,同样的一个hash值,在扩容前和扩容之后,得到的下标位置是不一样的,这样情况当然是不允许出现的,所以在扩容的时候就需要考虑的. 大家可以看到,16位的结果到32位的结果,正好增加了16 比如 20&amp;15= 4 , 20&amp;31=20 ; 4-20 = 16 比如 60&amp;15 = 12, 60 &amp; 31 = 28, 12-28 = 16 所以对于高位,直接增加了扩容的长度,当下次hash 获得数组位置的时候,可以直接定位到对应的位置,这个地方又是一个很巧妙的设计,直接通过高低位分类以后,就使得不需要在每次扩容的时候来重新计算hash.极大的提升了效率. 扩容结束以后的退出机制如果线程扩容结束,那么需要退出,就会执行transfer 方法的如下代码 // i&lt;0 说明已经完成遍历完旧的数组,也就是当前线程已经处理完所有的负债的 bucket if (i &lt; 0 || i >= n || i + n >= nextn) &amp;#123; int sc; // 如果完成了扩容 if (finishing) &amp;#123; // 删除成员变量 nextTable = null; // 更新table 数组 table = nextTab; // 更新阈值(32*0.75 = 24) sizeCtl = (n &lt;&lt; 1) - (n >>> 1); return; &amp;#125; // sizeCtl 在迁移前会设置为( (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 然后,每增加一个线程参会迁移都会对sizeCtl 加1 // 这里使用 CAS 操作对sizeCtl 的低16位进行减1,代表做完了属于自己的任务 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &amp;#123; // 第一个扩容的线程,执行 transfer 方法之前,会设置 sizeCtl = (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 后续帮其扩容的线程执行 transfer 方法之前,会设置 sizeCtl = sizeCtl+1 // 每一个退出transfer 的方法的线程,退出之前会设置 sizeCtl = sizeCtl-1,那么最后一个线程退出时:必然有 //sc == (resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) + 2)，即 (sc - 2)== resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT // 如果sc -2 不等于标识符 左移16位.如果他们相等了,说明没有线程在帮助他们扩容了,也就是说,扩容结束了, if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 如果相等,扩容结束了,更新finishing的值 finishing = advance = true; // 再次循环检查一下整张表 i = n; // recheck before commit &amp;#125; &amp;#125; put方法的第三阶段如果对应的节点存在,判断这个节点的hash是不是等于MOVED(-1), 说明当前节点是ForwardingNode 节点,意味着有其他线程正在进行扩容,那么当前直接帮助它进行扩容,因为调用 helpTransfer 方法 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); helpTransfer从名字上看,代表当前是去协助扩容 final Node&lt;K,V>[] helpTransfer(Node&lt;K,V>[] tab, Node&lt;K,V> f) &amp;#123; Node&lt;K,V>[] nextTab; int sc; // 判断此时是否仍然在执行扩容,nextTab = null的时候说明扩容已经结束了 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V>)f).nextTable) != null) &amp;#123; // 生成扩容戳 int rs = resizeStamp(tab.length); // 说明扩容还未完成的情况下不断的循环来尝试将当前线程加入到扩容操作中 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &amp;#123; // 下面部分的整个代码表示扩容结束,直接退出循环 // transferIndex &lt;= 0 表示所有的Node 都分配了线程 // sc == rs + MAX_RESIZERS 表示扩容线程数达到最大扩容线程数 // (sc >>> RESIZE_STAMP_SHIFT) != rs 如果在同一轮扩容中,那么sc 无符号右移比较高位和rs的值,那么应该是相等的,如果不相等,说明扩容结束了 // sc == rs + 1 表示扩容结束 if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) // 跳出循环 break; // 在低16位上增加扩容线程数 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &amp;#123; // 帮助扩容 transfer(tab, nextTab); break; &amp;#125; &amp;#125; return nextTab; &amp;#125; // 返回新的数组 return table; &amp;#125; put 方法第四阶段这个方法的主要作用是: 如果被添加的节点的位置已经存在了节点的时候,需要以链表的方式加入到节点中 如果当前节点已经是一棵红黑树,那么就会按照红黑树的规则将当前节点加入到红黑树中 V oldVal = null; // 给对应的头节点加锁 synchronized (f) &amp;#123; // 再次判断对应下标位置是否为f节点 if (tabAt(tab, i) == f) &amp;#123; // 头节点的hash值大于0,说明是链表 if (fh >= 0) &amp;#123; // 用来记录链表的长度 binCount = 1; // 遍历链表 for (Node&lt;K,V> e = f;; ++binCount) &amp;#123; K ek; // 如果发现相同的key,则判断是否需要进行值的覆盖 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &amp;#123; oldVal = e.val; // 默认情况下,直接覆盖旧的值 if (!onlyIfAbsent) e.val = value; break; &amp;#125; // 一直遍历到链表的最末端,直接把新的值加入到链表的最后面 Node&lt;K,V> pred = e; if ((e = e.next) == null) &amp;#123; pred.next = new Node&lt;K,V>(hash, key, value, null); break; &amp;#125; &amp;#125; &amp;#125; // 如果当前的节点是一颗红黑树 else if (f instanceof TreeBin) &amp;#123; Node&lt;K,V> p; binCount = 2; // 则调用红黑树的插入方法插入新的值 if ((p = ((TreeBin&lt;K,V>)f).putTreeVal(hash, key, value)) != null) &amp;#123; oldVal = p.val; // 同样,如果值已经存在,则直接替换 if (!onlyIfAbsent) p.val = value; &amp;#125; &amp;#125; &amp;#125; &amp;#125; if (binCount != 0) &amp;#123; if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &amp;#125; put 方法的第五个阶段判断链表的长度是否已经达到了临界值8, 如果达到了临界值,这个时候会根据当前数组的长度来决定是扩容还是将链表转换为红黑树.也就是说当前数组的长度小于64,就会先扩容,否则,会把当前链表转换为红黑树. // 如果上面在做链表操作 if (binCount != 0) &amp;#123; // 如果链表的长度已经达到了临界值8就需要把链表转换为树结构 if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); // 如果val是被替换的,则返回替换之前的值 if (oldVal != null) return oldVal; break; &amp;#125; treeifyBinprivate final void treeifyBin(Node&lt;K,V>[] tab, int index) &amp;#123; Node&lt;K,V> b; int n, sc; if (tab != null) &amp;#123; // tab的长度是不是小于64, 如果是,则执行扩容 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); // 否则将当前链表转换为红黑树结构存储 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash >= 0) &amp;#123; // 将链表转换为红黑树 synchronized (b) &amp;#123; if (tabAt(tab, index) == b) &amp;#123; TreeNode&lt;K,V> hd = null, tl = null; for (Node&lt;K,V> e = b; e != null; e = e.next) &amp;#123; TreeNode&lt;K,V> p = new TreeNode&lt;K,V>(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &amp;#125; setTabAt(tab, index, new TreeBin&lt;K,V>(hd)); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; tryPresize private final void tryPresize(int size) &amp;#123; // 对size 进行修复,主要目的是防止传入的值不是一个2次幂的整数,然后通过tableSizeFor 来将入参转换为离该整数的最近的2次幂 int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size >>> 1) + 1); int sc; while ((sc = sizeCtl) >= 0) &amp;#123; Node&lt;K,V>[] tab = table; int n; // 这段代码和initTable是一样的,如果table 没有初始化,则开始初始化 if (tab == null || (n = tab.length) == 0) &amp;#123; n = (sc > c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &amp;#123; try &amp;#123; if (table == tab) &amp;#123; @SuppressWarnings(\"unchecked\") Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n]; table = nt; // 0.75 sc = n - (n >>> 2); &amp;#125; &amp;#125; finally &amp;#123; sizeCtl = sc; &amp;#125; &amp;#125; &amp;#125; else if (c &lt;= sc || n >= MAXIMUM_CAPACITY) break; // 这段代码和addCount 后续部分代码是一样的,做辅助扩容操作 else if (tab == table) &amp;#123; int rs = resizeStamp(n); if (sc &lt; 0) &amp;#123; Node&lt;K,V>[] nt; if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &amp;#125; else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &amp;#125; &amp;#125; &amp;#125;","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"Docker-Compose的基本命令","slug":"安装/Docker-Compose的基本命令","date":"2022-01-04T02:42:07.269Z","updated":"2022-01-04T02:42:07.269Z","comments":true,"path":"2022/01/04/an-zhuang/docker-compose-de-ji-ben-ming-ling/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/an-zhuang/docker-compose-de-ji-ben-ming-ling/","excerpt":"","text":"Docker-Compose的基本使用1. 搭建Docker-Compose环境1.下载安装docker-compose #下载 sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose #安装 chmod +x /usr/local/bin/docker-compose #查看版本 docker-compose version image.png 2.下载docker补全命令 #安装 yum install bash-completion #下载docker-compose脚本 curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose image.png 2. 基本命令#查看帮助 docker-compose -h # -f 指定使用的 Compose 模板文件 # 默认为 docker-compose.yml，可以多次指定。 docker-compose -f docker-compose.yml up -d #启动所有容器，-d 将会在后台启动并运行所有的容器 docker-compose up -d #停用移除所有容器以及网络相关 docker-compose down #查看服务容器的输出 docker-compose logs #列出项目中目前的所有容器 docker-compose ps #构建（重新构建）项目中的服务容器。服务容器一旦构建后，将会带上一个标记名. #例如对于 web 项目中的一个 db 容器，可能是 web_db。 #可以随时在项目目录下运行 docker-compose build 来重新构建服务 docker-compose build # 不带缓存的构建。 docker-compose build --no-cache #拉取服务依赖的镜像 docker-compose pull #重启项目中的服务 docker-compose restart #删除所有（停止状态的）服务容器。 #推荐先执行 docker-compose stop 命令来停止容器。 docker-compose rm #在指定服务上执行一个命令。 docker-compose run ubuntu ping docker.com #设置指定服务运行的容器个数。通过 service=num 的参数来设置数量 docker-compose scale web=3 db=2 #启动已经存在的服务容器。 docker-compose start #停止已经处于运行状态的容器，但不删除它。 #通过 docker-compose start 可以再次启动这些容器。 docker-compose stop","categories":[{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"}],"tags":[]},{"title":"任务调度之Eliastic-Job","slug":"任务调度/任务调度之Eliastic-Job","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/ren-wu-diao-du/ren-wu-diao-du-zhi-eliastic-job/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/ren-wu-diao-du/ren-wu-diao-du-zhi-eliastic-job/","excerpt":"","text":"任务调度之Eliastic-Job.md1.1 任务调度高级需求Quartz 的不足: 作业只能通过DB 抢占随机负载, 无法协调. 作业不能分片, 单个任务数据太多了跑不完,消耗线程,负载不均匀. 作业日志可视化监控,统计. 1.2 发展历史Elastic-Job 是怎么来的? 在当当的ddframe 框架中, 需要一个任务调度系统(作业系统) 实现的话有两种思路: 一种是修改开源产品, 一种是基于开源产品搭建(封装), 当当选择了后者,最开始这个调度系统叫做dd-job.它是一个无中心化的分布式任务调度框架。 因为数据库缺少分布式协调功能(必须选主), 替换为Zookeeper后, 增加了弹性扩容和数据分片的功能. Elastic-Job 是ddframe 中的dd-job 作业模块分离出来的作业框架, 基于Quartz和Curator开发,在2015年开源. 轻量级,无中心化的解决方案. 为什么哦是无中心化呢? 因为没有统一的调度中心, 集群的每个节点都是对等的, 节点之间通过注册中心进行分布式协调. Elastic-Job存在主节点的概念, 但是主节点没有调度的功能,而是用于处理一些集中式的任务, 如分片、清理运行时信息等. 思考: 如果ZK挂了怎么办？ 每个任务都有自己独立的线程池. 从官网开始: http://elasticjob.io/docs/elastic-job-lite/00-overview/ https://github.com/elasticjob Elastic-Job 最开始只有一个elastic-job-core 的项目, 在2.X版本之后分为Elastic-job-Lite和Elastic-job-Cloud 两个子项目. 其中Elastic-job-Lite 定位为轻量级无中心化的解决方案,使用jar 包的形式来提供分布式任务的协调服务. 而Elastic-job-Cloud 使用Mesos+Docker 的解决方案, 额外提供资源管理、应用分发以及进程隔离服务(跟Lite的区别只是部署方式不同,他们使用相同的API, 只要开发一次) 1.3 功能特性 分布式调度协调:使用ZK 实现注册中心 错误执行作用重触发(Misfire) 支持并行调度(任务分片) 作业分片一致性,保证同一个分片在分布式环境中仅有一个执行实例 弹性扩容缩容: 将任务拆分成N个任务后, 各个服务区分别执行各自分配到的任务项, 一旦有新的服务器加入集群, 或现有服务器下线, Elastic-job将在保留本地任务不变的情况下, 下次任务开始前触发任务重分片. 失效转移(failover): 弹性扩容缩容在下次作业运行前重新分片, 但本次作用执行的过程中, 下线的服务器所分配的作业将不会重新分配. 失效转移功能可以在本地作用运行中用空闲服务器抓取孤儿作业分片执行. 同样, 失效转移功能也会牺牲部分性能. 支持作业生命周期操作(listener) 丰富的作业类型(Simple、DataFlow、Script) Spring整合以及命名空间提供 运维平台 1.4 项目架构应用在各自的节点上执行任务, 通过ZK 注册中心协调,节点注册、节点选举、任务分片、监听都在Elastic-Job 的代码中完成. 2. Java 开发2.1 pom 依赖 &lt;dependency> &lt;groupId>com.dangdang&lt;/groupId> &lt;artifactId>elastic-job-lite-core&lt;/artifactId> &lt;version>2.1.5&lt;/version> &lt;/dependency> 2.2 任务类型任务类型有三种: 2.2.1 SimpleJobSimpleJob: 简单实现,非经过任何封装的类型,需要实现SimpleJob接口 public class MySimpleJob implements SimpleJob &amp;#123; @Override public void execute(ShardingContext shardingContext) &amp;#123; System.out.println(String.format(\"分片项 ShardingItem: %s | 运行时间: %s | 线程ID: %s | 分片参数: %s \", shardingContext.getShardingItem(), new SimpleDateFormat(\"HH:mm:ss\").format(new Date()), Thread.currentThread().getId(), shardingContext.getShardingParameter())); &amp;#125; &amp;#125; 测试类 /** * @author luyanan * @since 2020/4/11 * &lt;p>测试类&lt;/p> **/ public class SimpleJobTest &amp;#123; public static void main(String[] args) &amp;#123; // zk注册中心 ZookeeperRegistryCenter registryCenter = new ZookeeperRegistryCenter(new ZookeeperConfiguration(\"192.168.31.22:2181\", \"ejob-standalone\")); registryCenter.init(); // 数据源，使用DBCP /* BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://localhost:3306/elastic_job_log\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123456\"); JobEventConfiguration jobEventConfig = new JobEventRdbConfiguration(dataSource);*/ // 定义作业核心配置 JobCoreConfiguration coreConfiguration = JobCoreConfiguration.newBuilder(MySimpleJob.class.getSimpleName(), \"0/2 * * * * ?\", 4).shardingItemParameters(\"0=RDP, 1=CORE, 2=SIMS, 3=ECIF\").build(); // 定义Simple 类型配置 SimpleJobConfiguration simpleJobConfiguration = new SimpleJobConfiguration(coreConfiguration, MySimpleJob.class.getCanonicalName()); // 作业分片策略 // 基于平均分配算法的分片策略 String jobShardingStrategyClass = AverageAllocationJobShardingStrategy.class.getCanonicalName(); // 定义Lite 作业根配置 // LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(simpleJobConfig).jobShardingStrategyClass(jobShardingStrategyClass).build(); LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(simpleJobConfiguration).build(); // 构建Job new JobScheduler(registryCenter, simpleJobRootConfig).init(); // new JobScheduler(regCenter, simpleJobRootConfig, jobEventConfig).init(); &amp;#125; &amp;#125; 结果: 分片项 ShardingItem: 2 | 运行时间: 16:00:44 | 线程ID: 27 | 分片参数: SIMS 分片项 ShardingItem: 3 | 运行时间: 16:00:44 | 线程ID: 28 | 分片参数: ECIF 分片项 ShardingItem: 0 | 运行时间: 16:00:44 | 线程ID: 25 | 分片参数: RDP 分片项 ShardingItem: 1 | 运行时间: 16:00:44 | 线程ID: 26 | 分片参数: CORE 分片项 ShardingItem: 0 | 运行时间: 16:00:46 | 线程ID: 29 | 分片参数: RDP 分片项 ShardingItem: 1 | 运行时间: 16:00:46 | 线程ID: 30 | 分片参数: CORE 分片项 ShardingItem: 2 | 运行时间: 16:00:46 | 线程ID: 31 | 分片参数: SIMS 分片项 ShardingItem: 3 | 运行时间: 16:00:46 | 线程ID: 32 | 分片参数: ECIF 分片项 ShardingItem: 0 | 运行时间: 16:00:48 | 线程ID: 28 | 分片参数: RDP 分片项 ShardingItem: 1 | 运行时间: 16:00:48 | 线程ID: 27 | 分片参数: CORE 分片项 ShardingItem: 2 | 运行时间: 16:00:48 | 线程ID: 28 | 分片参数: SIMS 分片项 ShardingItem: 3 | 运行时间: 16:00:48 | 线程ID: 25 | 分片参数: ECIF 分片项 ShardingItem: 0 | 运行时间: 16:00:50 | 线程ID: 29 | 分片参数: RDP 分片项 ShardingItem: 1 | 运行时间: 16:00:50 | 线程ID: 30 | 分片参数: CORE 分片项 ShardingItem: 2 | 运行时间: 16:00:50 | 线程ID: 31 | 分片参数: SIMS 分片项 ShardingItem: 3 | 运行时间: 16:00:50 | 线程ID: 32 | 分片参数: ECIF 分片项 ShardingItem: 0 | 运行时间: 16:00:52 | 线程ID: 27 | 分片参数: RDP 分片项 ShardingItem: 1 | 运行时间: 16:00:52 | 线程ID: 26 | 分片参数: CORE 分片项 ShardingItem: 3 | 运行时间: 16:00:52 | 线程ID: 28 | 分片参数: ECIF 分片项 ShardingItem: 2 | 运行时间: 16:00:52 | 线程ID: 27 | 分片参数: SIMS 2.2.2 DataFlowJobDataFlowJob: DataFlow 类型用于处理数据流, 必须实现fetchData()和 processData() 的方法, 一个用来获取数据, 一个用来处理获取到的数据. package com.job.elasticjob.dataflow; import com.dangdang.ddframe.job.api.ShardingContext; import com.dangdang.ddframe.job.api.dataflow.DataflowJob; import java.util.Arrays; import java.util.List; /** * @author luyanan * @since 2020/4/11 * &lt;p>数据流&lt;/p> **/ public class MyDataFlowJob implements DataflowJob&lt;String> &amp;#123; @Override public List&lt;String> fetchData(ShardingContext shardingContext) &amp;#123; System.out.println(\"开始获取数据\"); return Arrays.asList(\"张三\", \"李四\", \"王五\"); &amp;#125; @Override public void processData(ShardingContext shardingContext, List&lt;String> list) &amp;#123; // 需要移除数据, 不然会一直循环 for (String s : list) &amp;#123; System.out.println(\"开始处理任务:\" + s); &amp;#125; &amp;#125; &amp;#125; 测试类 public class DataFlowJobTest &amp;#123; public static void main(String[] args) &amp;#123; // zk注册中心 ZookeeperRegistryCenter registryCenter = new ZookeeperRegistryCenter(new ZookeeperConfiguration(\"192.168.31.22:2181\", \"ejob-standalone-dataflow\")); registryCenter.init(); // 定义作业核心配置 JobCoreConfiguration coreConfiguration = JobCoreConfiguration.newBuilder(MyDataFlowJob.class.getSimpleName(), \"0/2 * * * * ?\", 4).build(); // 定义Simple 类型配置 DataflowJobConfiguration dataflowJobConfiguration = new DataflowJobConfiguration(coreConfiguration, MyDataFlowJob.class.getCanonicalName(), true); // 作业分片策略 // 基于平均分配算法的分片策略 String jobShardingStrategyClass = AverageAllocationJobShardingStrategy.class.getCanonicalName(); // 定义Lite 作业根配置 // LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(simpleJobConfig).jobShardingStrategyClass(jobShardingStrategyClass).build(); LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(dataflowJobConfiguration).build(); // 构建Job new JobScheduler(registryCenter, simpleJobRootConfig).init(); // new JobScheduler(regCenter, simpleJobRootConfig, jobEventConfig).init(); &amp;#125; &amp;#125; 结果: 开始获取数据 开始处理任务:张三 开始处理任务:李四 开始处理任务:王五 2.2.3 ScriptJobScriptJob:Script 类型作业为脚本类型作业, 支持Shell、Python、Perl 等所有类型脚本, 只需要指定脚本的内容或者位置. public static void main(String[] args) &amp;#123; // zk注册中心 ZookeeperRegistryCenter registryCenter = new ZookeeperRegistryCenter( new ZookeeperConfiguration(\"192.168.31.22:2181\", \"ejob-standalone-script\")); registryCenter.init(); //定义作业核心配置 JobCoreConfiguration jobCoreConfiguration = JobCoreConfiguration .newBuilder(\"scriteJob\", \"0/4 * * * * ?\", 2) .build(); //定义script类型配置 ScriptJobConfiguration scriptJobConfiguration = new ScriptJobConfiguration(jobCoreConfiguration, \"D:/1.bat\"); // 作业分片策略 // 基于平均分配算法的分片策略 String jobShardingStrategyClass = AverageAllocationJobShardingStrategy.class.getCanonicalName(); // 定义Lite作业根配置 // LiteJobConfiguration scriptJobRootConfig = LiteJobConfiguration.newBuilder(scriptJobConfig).jobShardingStrategyClass(jobShardingStrategyClass).build(); LiteJobConfiguration scriptJobRootConfig = LiteJobConfiguration.newBuilder(scriptJobConfiguration).build(); // 构建Job new JobScheduler(registryCenter, scriptJobRootConfig).init(); // new JobScheduler(regCenter, scriptJobRootConfig, jobEventConfig).init(); &amp;#125; 2.3 Elastic-Job 配置2.3.1 配置步骤配置手册: http://elasticjob.io/docs/elastic-job-lite/02-guide/config-manual/ ZK 注册中心配置 作业级别(从底层往下层: core-Type-Lite) 配置级别 配置类 配置内容 core JobCoreConfiguration 用于提供作业核心配置信息，如：作业名称、CRON 表达式、分片总数等。 type JobTypeConfiguration 有 3 个子类分别对应 SIMPLE, DATAFLOW 和 SCRIPT 类型作业，提供 3 种作 业需要的不同配置，如：DATAFLOW 类型是否流式处理或 SCRIPT 类型的命 令行等。Simple 和 DataFlow 需要指定任务类的路径 Root JobRootConfiguration 有 2 个子类分别对应 Lite 和 Cloud 部署类型，提供不同部署类型所需的配 置，如：Lite 类型的是否需要覆盖本地配置或 Cloud 占用 CPU 或 Memory 数量等。可以定义分片策略：http://elasticjob.io/docs/elastic-job-lite/02-guide/job-sharding-strategy/ public static void main(String[] args) &amp;#123; // zk注册中心 ZookeeperRegistryCenter registryCenter = new ZookeeperRegistryCenter(new ZookeeperConfiguration(\"192.168.31.22:2181\", \"ejob-standalone\")); registryCenter.init(); // 数据源，使用DBCP /* BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://localhost:3306/elastic_job_log\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123456\"); JobEventConfiguration jobEventConfig = new JobEventRdbConfiguration(dataSource);*/ // 定义作业核心配置 JobCoreConfiguration coreConfiguration = JobCoreConfiguration.newBuilder(MySimpleJob.class.getSimpleName(), \"0/2 * * * * ?\", 4).shardingItemParameters(\"0=RDP, 1=CORE, 2=SIMS, 3=ECIF\").build(); // 定义Simple 类型配置 SimpleJobConfiguration simpleJobConfiguration = new SimpleJobConfiguration(coreConfiguration, MySimpleJob.class.getCanonicalName()); // 作业分片策略 // 基于平均分配算法的分片策略 String jobShardingStrategyClass = AverageAllocationJobShardingStrategy.class.getCanonicalName(); // 定义Lite 作业根配置 // LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(simpleJobConfig).jobShardingStrategyClass(jobShardingStrategyClass).build(); LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(simpleJobConfiguration).build(); // 构建Job new JobScheduler(registryCenter, simpleJobRootConfig).init(); // new JobScheduler(regCenter, simpleJobRootConfig, jobEventConfig).init(); &amp;#125; 作业配置分为三级, 分别是JobCoreConfiguration、JobTypeConfiguration和LiteJobConfiguration.LiteJobConfiguration 使用JobTypeConfiguration,JobTypeConfiguration 使用JobCoreConfiguration, 层层嵌套 JobTypeConfiguration 根据不同的实现类型分为SimpleJobConfiguration ， DataflowJobConfiguration 和 ScriptJobConfiguration。 Elastic-Job 使用zk 做分布式协调,所有的配置都会写入到ZK中. 2.3.2 ZK注册中心数据结构一个任务, 一个二级节点 这里面有些节点是临时节点,只有任务运行的是才能看到. 注意：修改了任务重新运行任务不生效, 是因为zk的信息不会更新,除非把overwrite修改成``true` config节点JSON 格式存储 存储任务的配置信息,包括执行类,cron 表达式, 分片算法类、分片数量、分片参数等. &amp;#123; \"cron\": \"0/2 * * * * ?\", \"description\": \"\", \"disabled\": false, \"failover\": false, \"jobClass\": \"job.MySimpleJob\", \"jobName\": \"MySimpleJob\", \"jobParameter\": \"\", \"jobProperties\": &amp;#123; \"executor_service_handler\": \"com.dangdang.ddframe.job.executor.handler.impl.DefaultExecutorServiceHandler\", \"job_exception_handler\": \"com.dangdang.ddframe.job.executor.handler.impl.DefaultJobExceptionHandler\" &amp;#125;, \"jobShardingStrategyClass\": \"\", \"jobType\": \"SIMPLE\", \"maxTimeDiffSeconds\": -1, \"misfire\": true, \"monitorExecution\": true, \"monitorPort\": -1, \"overwrite\": false, \"reconcileIntervalMinutes\": 10, \"shardingItemParameters\": \"\", \"shardingTotalCount\": 1 &amp;#125; config节点的数据是通过ConfigService 持久化到zookeeper中去的, 默认情况下, 如果你修改了job的配置, 比如cron 表达式、分片数量等是不会更新到zookeeper上去的, 除非你在Lite级别的配置把参数overwrite 修改成true LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(simpleJobConfig).overwrite(true).build(); instances 节点同一个Job下的elasticJob 的部署实例, 一台机器上可以运行多个Job实例, 也就是Jar包,instances 的命令是Ip+@-@+PID. 只有在运行的时候能看到. Leader节点 任务实例的主节点信息,通过zookeeper 的主节点选举,选出来的主节点信息, 在elastic -job 中, 任务的执行可以分布在不同的实例(节点)中, 但是任务分片等核心控制 ,需要由主节点完成, 因为, 任务执行前, 需要选举出主节点. 下面有三个子节点: election: 主节点选举 sharding: 分片 failover:失效转移 election:下面的instance节点显示了当前主节点的实例ID：JobInstanceId sharding:节点下面有一个临时节点, necessary,是否需要重新分片的标记. 如果分片数总数变化, 或者任务实例节点上下线或启动/禁用,以及主节点选举, 都会触发设置重分片标记, 主节点会进行分片计算. Servers节点 任务实例的信息, 主要是IP地址, 任务实例的IP地址, 跟instances不同, 如果多个任务实例在同一台机器上运行则会只出现一个IP子节点, 可在IP地址节点写入DISABLED 表示该任务实例禁用. sharding 节点 任务的分片信息, 子节点是分片项序号, 从0开始. 分片个数是在任务配置中设置的, 分片项序号的子节点存储详细信息, 每个分片项下的子节点用于控制和记录分片运行状态 , 最主要的子节点就是instance. 子节点名 是否临时节点 描述 instance 否 执行该分片项的作业运行实例主键 running 是 分片项正在运行的状态仅配置monitorExecution 时有效 failover 是 如果该分片项被失效转移分配给其他作业服务器, 则该节点值记录执行此分派你的作业服务器IP misfire 否 是否开启错误任务重新执行 disabled 否 是否禁用此分片项 3. 运维平台3.1 下载解压运行git 下载源码 https://github.com/elasticjob/elastic-job-lite 对elastic-job-lite-console打包得到安装包. 解压缩elastic-job-lite-console-$&#123;version&#125;.tar.gz 并执行bin\\start.sh（Windows 运行.bat）. 打开浏览器访问http://localhost:8899/ 即可访问控制台. 8899为默认端口号, 可通过启动脚本输入-p 自定义端口号. 默认管理员用户名和密码是root/root.右上角可以切换语言. 3.2 添加ZK注册中心第一步,添加注册中心, 输入ZK地址和命名空间, 并连接 运维平台和elastic-job 并无关系,是通过读取作业注册中心数据展现作业状态,或更新注册中心数据修改全局配置. 控制台只能控制作业本身是否运行,但不能控制作业进程的启动, 因为控制台和作业本身是完全分离的,控制台并不能控制作业服务器. 可以对作业机型操作. 修改作业 3.3 事件追踪http://elasticjob.io/docs/elastic-job-lite/02-guide/event-trace/ Elastic-Job 提供了事件追踪功能, 可以通过事件订阅的方式处理调度过程的重要事件, 用于查询、统计和监控. Elastic-Job-Lite 在配置中提供了JobEventConfiguration, 目前支持数据库方式配置. BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://localhost:3306/elastic_job_log\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123456\"); JobEventConfiguration jobEventConfig = new JobEventRdbConfiguration(dataSource); 事件追踪的event_trace_rdb_url 属性对应库自动创建JOB_EXECUTION_LOG 和JOB_STATUS_TRACE_LOG 两张表以及若干索引 需要在运维平台中添加数据源信息,并且连接: 在作业中查询: 4.Spring 集成与分片详解4.1 pom依赖 &lt;elastic-job.version>2.1.5&lt;/elastic-job.version> &lt;dependency> &lt;groupId>com.dangdang&lt;/groupId> &lt;artifactId>elastic-job-lite-core&lt;/artifactId> &lt;version>$&amp;#123;elastic-job.version&amp;#125;&lt;/version> &lt;/dependency> &lt;!-- elastic-job-lite-spring --> &lt;dependency> &lt;groupId>com.dangdang&lt;/groupId> &lt;artifactId>elastic-job-lite-spring&lt;/artifactId> &lt;version>$&amp;#123;elastic-job.version&amp;#125;&lt;/version> &lt;/dependency> 4.2 application.properties 定义配置类和任务类中要用到的参数server.port=$&amp;#123;random.int[10000,19999]&amp;#125; regCenter.serverList = localhost:2181 regCenter.namespace = ejob-springboot elasticJob.cron = 0/3 * * * * ? elasticJob.shardingTotalCount = 4 elasticJob.shardingItemParameters = 0=aaa,1=bbb, 2=mic, 3=ccc elasticJob.jobParameter = 2673 4.3 创建任务创建任务类,加上@Component 注解 @Component public class MySimpleJob implements SimpleJob &amp;#123; @Override public void execute(ShardingContext shardingContext) &amp;#123; System.out.println(String.format(\"------【简单任务】Thread ID: %s, %s,任务总片数: %s, \" + \"当前分片项: %s.当前参数: %s,\" + \"当前任务名称: %s.当前任务参数 %s\", Thread.currentThread().getId(), new SimpleDateFormat(\"HH:mm:ss\").format(new Date()), shardingContext.getShardingTotalCount(), shardingContext.getShardingItem(), shardingContext.getShardingParameter(), shardingContext.getJobName(), shardingContext.getJobParameter() )); &amp;#125; &amp;#125; 4.4 注册中心配置Bean的initMethod 属性用来指定Bean 初始化完成之后要执行的方法, 用来替代继承InitializingBean 接口, 以便在容器启动的时候创建注册中心. @Configuration public class ElasticRegistryCenterConfig &amp;#123; @Bean(initMethod = \"init\") public ZookeeperRegistryCenter zookeeperRegistryCenter( @Value(\"$&amp;#123;regCenter.serverList&amp;#125;\") String serverList, @Value(\"$&amp;#123;regCenter.namespace&amp;#125;\") String namespace) &amp;#123; return new ZookeeperRegistryCenter( new ZookeeperConfiguration(serverList, namespace)); &amp;#125; &amp;#125; 4.5 作业三级配置Core - Type -Lite @Configuration public class ElasticJobConfig &amp;#123; @Autowired private ZookeeperRegistryCenter regCenter; // 定义调度器 @Bean(initMethod = \"init\") public JobScheduler simpleJobScheduler(final MySimpleJob simpleJob, @Value(\"$&amp;#123;elasticJob.cron&amp;#125;\") final String cron, @Value(\"$&amp;#123;elasticJob.shardingTotalCount&amp;#125;\") final int shardingTotalCount, @Value(\"$&amp;#123;elasticJob.shardingItemParameters&amp;#125;\") final String shardingItemParameters, @Value(\"$&amp;#123;elasticJob.jobParameter&amp;#125;\") final String jobParameter) &amp;#123; return new SpringJobScheduler(simpleJob, regCenter, getLiteJobConfiguration(simpleJob.getClass(), cron, shardingTotalCount, shardingItemParameters, jobParameter)); &amp;#125; // 配置任务详细信息 private LiteJobConfiguration getLiteJobConfiguration(final Class&lt;? extends SimpleJob> jobClass, final String cron, final int shardingTotalCount, final String shardingItemParameters, final String jobParameter) &amp;#123; return LiteJobConfiguration.newBuilder(new SimpleJobConfiguration( JobCoreConfiguration.newBuilder(jobClass.getName(), cron, shardingTotalCount) .shardingItemParameters(shardingItemParameters).jobParameter(jobParameter).build() , jobClass.getCanonicalName()) ).overwrite(true).build(); &amp;#125; @Bean(initMethod = \"init\") public JobScheduler dataFlowJobScheduler(final MyDataFlowJob dataFlowJob, @Value(\"$&amp;#123;elasticJob.dataflow.cron&amp;#125;\") final String cron, @Value(\"$&amp;#123;elasticJob.dataflow.shardingTotalCount&amp;#125;\") final int shardingTotalCount, @Value(\"$&amp;#123;elasticJob.dataflow.shardingItemParameters&amp;#125;\") final String shardingItemParameters) &amp;#123; return new SpringJobScheduler(dataFlowJob, regCenter, getDataFlowJobConfiguration(dataFlowJob.getClass(), cron, shardingTotalCount, shardingItemParameters, true)); &amp;#125; private LiteJobConfiguration getDataFlowJobConfiguration(final Class&lt;? extends DataflowJob> jobClass, //任务类 final String cron, // 运行周期配置 final int shardingTotalCount, //分片个数 final String shardingItemParameters, final Boolean streamingProcess //是否是流式作业 ) &amp;#123; // 分片参数 return LiteJobConfiguration.newBuilder(new DataflowJobConfiguration( JobCoreConfiguration.newBuilder(jobClass.getName(), cron, shardingTotalCount) .shardingItemParameters(shardingItemParameters).build() // true为流式作业,除非fetchData返回数据为null或者size为0,否则会一直执行 // false非流式,只会按配置时间执行一次 , jobClass.getCanonicalName(), streamingProcess) ).overwrite(true).build(); &amp;#125; @Bean(initMethod = \"init\") public JobScheduler scriptJobScheduler(@Value(\"$&amp;#123;elasticJob.script.cron&amp;#125;\") final String cron, @Value(\"$&amp;#123;elasticJob.script.shardingTotalCount&amp;#125;\") final int shardingTotalCount, @Value(\"$&amp;#123;elasticJob.script.shardingItemParameters&amp;#125;\") final String shardingItemParameters) &amp;#123; return new SpringJobScheduler(null, regCenter, getScriptJobConfiguration(\"script_job\", cron, shardingTotalCount, shardingItemParameters, \"D:/1.bat\")); &amp;#125; private LiteJobConfiguration getScriptJobConfiguration(final String jobName, //任务名字 final String cron, // 运行周期配置 final int shardingTotalCount, //分片个数 final String shardingItemParameters, final String scriptCommandLine //是脚本路径或者命令 ) &amp;#123; // 分片参数 return LiteJobConfiguration.newBuilder(new ScriptJobConfiguration( JobCoreConfiguration.newBuilder(jobName, cron, shardingTotalCount) .shardingItemParameters(shardingItemParameters).build() // 此处配置文件路径或者执行命令 , scriptCommandLine) ).overwrite(true).build(); &amp;#125; // 动态添加任务 /* public void addSimpleJobScheduler(final Class&lt;? extends SimpleJob> jobClass, final String cron, final int shardingTotalCount, final String shardingItemParameters)&amp;#123; JobCoreConfiguration coreConfig = JobCoreConfiguration .newBuilder(jobClass.getName(), cron, shardingTotalCount) .shardingItemParameters(shardingItemParameters) .jobParameter(\"name\") .build(); SimpleJobConfiguration simpleJobConfig = new SimpleJobConfiguration(coreConfig, jobClass.getCanonicalName()); JobScheduler jobScheduler = new JobScheduler(regCenter, LiteJobConfiguration.newBuilder(simpleJobConfig).build()); jobScheduler.init(); &amp;#125;*/ &amp;#125; 4.6 分片策略4.6.1 分片项和分片参数任务分片, 是为了实现把一个任务拆分成多个子任务, 在不同的ejob实例上运行, 假如说100W 条数据, 在配置文件中指定分为10个子任务(分片项),这10个子任务再按照一定的规则分配到5个实际运行的服务器上执行, 除了直接用分片项ShardingItem 获取分片任务之外, 还可以用item对应的parameter 获取任务. JobCoreConfiguration coreConfig = JobCoreConfiguration.newBuilder(\"MySimpleJob\", \"0/2 * * * * ?\", 4).shardingItemParameters(\"0=RDP, 1=CORE, 2=SIMS, 3=ECIF\").build(); springboot 工程, 在application.properties 中定义. 定义几个分片项, 一个任务就会有几个线程去运行他. 注意: 分片个数和分片参数要一一对应,通常把分片项设置的比Elastic-Job 服务器个数要大一些, 比如3台服务器,分成9片, 这样如果有服务器宕机,分片还可以相对均匀. 4.6.2 分片验证为避免运行的任务太多,看不清楚运行结果, 可以注释在Elastic-Job 中注释DatFlowJob和ScriptJob,SimpleJob的分片项改为2. 然后运行主启动类 多实例运行(单机) 多运行一个点, 任务不会重跑(两个节点各获得一个分片项) 关闭一个节点, 任务不会漏跑 4.7.3 分片策略http://elasticjob.io/docs/elastic-job-lite/02-guide/job-sharding-strategy/ 分片项如何分配到服务器? 这个跟分片策略有关. 策略类 描述 具体规则 AverageAllocationJobShardingStrategy 基于平均分配算法的分片策略, 也是默认的分片策略 如果分片不能整除, 则不能整除的多余分片将依次追加到序号小的服务器, 如:1. 如果有3台服务器,分成9片, 则每台服务器分到的分片是1=[0,1,2], 2=[3,4,5], 3=[6,7,8]2. 如果有三台服务器, 分成8片, 则每台服务器分到的分片是: 1=[0,1,6], 2=[2,3,7], 3=[4,5]3.如果有三台服务器,分成10片, 则每台服务器分到的分片是: 1=[0,1,2,9], 2=[3,4,5], 3=[6,7,8] OdevitySortByNameJobShardingStrategy 根据作业名的哈希值奇偶数决定IP 升将序算法的分片策略 1. 作业名是哈希值为奇数则IP升序2. 作业名的哈希值为偶数则Ip降序用于不同的作业平均分配负载至不同的服务器 RotateServerByNameJobShardingStrategy 根据作业名的哈希值对服务器列表进行轮转的分片策略 自定义分片策略 实现JobShardingStrategy 接口并实现sharding 方法, 接口方法参数为作业服务器IP列表和分片策略选项,分片策略选项包括作业名称、分片总数以及分片序列号和个性化参数对照表, 可以根据需求定制化自己的分片策略. AverageAllocationJobShardingStrategy的缺点是: 一旦分片数小于作业服务器数,作业将永远分配至IP 地址靠前的服务器, 导致IP地址靠后的服务器空闲. 而OdevitySortByNameJobShardingStrategy 则可以根据作业名称重新分配服务器负载. 如: 如果有 3 台服务器，分成 2 片，作业名称的哈希值为奇数，则每台服务器分到的分片是：1=[0], 2=[1], 3=[] 如果有 3 台服务器，分成 2 片，作业名称的哈希值为偶数，则每台服务器分到的分片是：3=[0], 2=[1], 1=[] 在Lite 配置中指定分片策略: String jobShardingStrategyClass = AverageAllocationJobShardingStrategy.class.getCanonicalName(); LiteJobConfiguration simpleJobRootConfig = LiteJobConfiguration.newBuilder(simpleJobConfig).jobShardingStrategyClass(jobShardingStrategyClass).build() 4.6.4 分片方案获取到分片项shardingItem 之后, 怎么对数据进行分片呢? 对业务主键进行取模, 获取余数等于分片项的数据 举例: 获取到的shardingItem 是0,1 在SQL 中加入过滤条件: where mod(id, 4) in (1, 2) 这种方式的缺点: 会导致索引失效,查询数据时会全表扫描 . 解决方案: 在查询条件中在增加一个索引条件进行过滤. 在表中增加一个字段, 根据分片数生成一个mod的值. 取模的基数要大于机器数,否则在增加机器后, 会导致机器空闲. 假如取模基数是2,而服务器有5台, 那么有三台服务器是永远空闲的.而取模基数是10, 生成10个shardingItem，可以分配到5台服务器. 当然,取模基数也可以调整. 如果从业务层面,可以用ShardingParamter 进行分片. 假如0=RDP, 1=CORE, 2=SIMS, 3=ECIF List = SELECT * FROM user WHERE status = 0 AND SYSTEM_ID = &#39;RDP&#39; limit 0, 100。 在SpringBoot中Elastic-Job 要配置的东西太多了,有没有更加简单的添加任务的方法呢? 比如在类上添加一个注解, 这个时候我们就要用到starter 4.7 Elastic-Job startergit上有一个现成的实现 https://github.com/TFdream/elasticjob-spring-boot-starter 5. Elastic-Job的原理5.1 启动我们从 new JobScheduler(registryCenter, simpleJobRootConfig).init(); 开始分析,首先看init() 方法 /** * 初始化作业. */ public void init() &amp;#123; LiteJobConfiguration liteJobConfigFromRegCenter = schedulerFacade.updateJobConfiguration(liteJobConfig); // 设置分片数 JobRegistry.getInstance().setCurrentShardingTotalCount(liteJobConfigFromRegCenter.getJobName(), liteJobConfigFromRegCenter.getTypeConfig().getCoreConfig().getShardingTotalCount()); // 构建任务, 创建调度器 JobScheduleController jobScheduleController = new JobScheduleController( createScheduler(), createJobDetail(liteJobConfigFromRegCenter.getTypeConfig().getJobClass()), liteJobConfigFromRegCenter.getJobName()); // 去ZK上注册任务 JobRegistry.getInstance().registerJob(liteJobConfigFromRegCenter.getJobName(), jobScheduleController, regCenter); // 添加任务信息,并进行节点选举 schedulerFacade.registerStartUpInfo(!liteJobConfigFromRegCenter.isDisabled()); // 启动调度器 jobScheduleController.scheduleJob(liteJobConfigFromRegCenter.getTypeConfig().getCoreConfig().getCron()); &amp;#125; 接下来看com.dangdang.ddframe.job.lite.internal.schedule.SchedulerFacade#registerStartUpInfo方法 /** * 注册作业启动信息. * * @param enabled 作业是否启用 */ public void registerStartUpInfo(final boolean enabled) &amp;#123; // 启动所有的监听器 listenerManager.startAllListeners(); // 节点选举 leaderService.electLeader(); // 服务信息持久化(写入ZK) serverService.persistOnline(enabled); // 实例信息持久化(写到ZK) instanceService.persistOnline(); // 重新分片 shardingService.setReshardingFlag(); // 监控信息监听器 monitorService.listen(); // 自诊断恢复, 使本地节点与ZK数据一致 if (!reconcileService.isRunning()) &amp;#123; reconcileService.startAsync(); &amp;#125; &amp;#125; 监听器用于监听ZK节点信息变化 启动的时候进行主节点选举 /** * 选举主节点. */ public void electLeader() &amp;#123; log.debug(\"Elect a new leader now.\"); jobNodeStorage.executeInLeader(LeaderNode.LATCH, new LeaderElectionExecutionCallback()); log.debug(\"Leader election completed.\"); &amp;#125; Latch是 一个分布式锁,选举成功后在instance 写入服务器信息 服务信息持久化(写到ZK Servers 节点) serverService.persistOnline(enabled) 以下是单机运行多个实例: 运行了两个实例 5.2 任务执行和分片原理关注两个问题 LiteJob 是怎么被执行的? 分片项是怎么分配给不同的服务实例的? 在创建Job的时候(createJobDetail), 创建的是一个实现了quartz的job接口的LiteJob类, LiteJob类也实现了Quartz的Job 接口 . 在LiteJOb的execute方法中获取对应类型的执行器, 调用execute() public static AbstractElasticJobExecutor getJobExecutor(ElasticJob elasticJob, JobFacade jobFacade) &amp;#123; if (null == elasticJob) &amp;#123; return new ScriptJobExecutor(jobFacade); &amp;#125; else if (elasticJob instanceof SimpleJob) &amp;#123; return new SimpleJobExecutor((SimpleJob)elasticJob, jobFacade); &amp;#125; else if (elasticJob instanceof DataflowJob) &amp;#123; return new DataflowJobExecutor((DataflowJob)elasticJob, jobFacade); &amp;#125; else &amp;#123; throw new JobConfigurationException(\"Cannot support job type '%s'\", new Object[]&amp;#123;elasticJob.getClass().getCanonicalName()&amp;#125;); &amp;#125; &amp;#125; Elastic-Job 提供管理任务执行器的抽象类AbstractElasticJobExecutor, 核心动作在execute() 方法中执行. public final void execute() &amp;#123; 调用了另一个execute() 方法, 122行 execute(shardingContexts, JobExecutionEvent.ExecutionSource.NORMAL_TRIGGER); private void execute(final ShardingContexts shardingContexts, final JobExecutionEvent.ExecutionSource executionSource) &amp;#123; if (shardingContexts.getShardingItemParameters().isEmpty()) &amp;#123; if (shardingContexts.isAllowSendJobEvent()) &amp;#123; jobFacade.postJobStatusTraceEvent(shardingContexts.getTaskId(), State.TASK_FINISHED, String.format(\"Sharding item for job '%s' is empty.\", jobName)); &amp;#125; return; &amp;#125; jobFacade.registerJobBegin(shardingContexts); String taskId = shardingContexts.getTaskId(); if (shardingContexts.isAllowSendJobEvent()) &amp;#123; jobFacade.postJobStatusTraceEvent(taskId, State.TASK_RUNNING, \"\"); &amp;#125; try &amp;#123; process(shardingContexts, executionSource); &amp;#125; finally &amp;#123; // TODO 考虑增加作业失败的状态，并且考虑如何处理作业失败的整体回路 jobFacade.registerJobCompleted(shardingContexts); if (itemErrorMessages.isEmpty()) &amp;#123; if (shardingContexts.isAllowSendJobEvent()) &amp;#123; jobFacade.postJobStatusTraceEvent(taskId, State.TASK_FINISHED, \"\"); &amp;#125; &amp;#125; else &amp;#123; if (shardingContexts.isAllowSendJobEvent()) &amp;#123; jobFacade.postJobStatusTraceEvent(taskId, State.TASK_ERROR, itemErrorMessages.toString()); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 在这个execute方法中又调用了com.dangdang.ddframe.job.executor.AbstractElasticJobExecutor#process(com.dangdang.ddframe.job.executor.ShardingContexts, com.dangdang.ddframe.job.event.type.JobExecutionEvent.ExecutionSource)方法 private void process(final ShardingContexts shardingContexts, final JobExecutionEvent.ExecutionSource executionSource) &amp;#123; Collection&lt;Integer> items = shardingContexts.getShardingItemParameters().keySet(); // 当只有一个分片的时候, 直接执行 if (1 == items.size()) &amp;#123; int item = shardingContexts.getShardingItemParameters().keySet().iterator().next(); JobExecutionEvent jobExecutionEvent = new JobExecutionEvent(shardingContexts.getTaskId(), jobName, executionSource, item); process(shardingContexts, item, jobExecutionEvent); return; &amp;#125; final CountDownLatch latch = new CountDownLatch(items.size()); // 本节点遍历执行相应的分片信息 for (final int each : items) &amp;#123; final JobExecutionEvent jobExecutionEvent = new JobExecutionEvent(shardingContexts.getTaskId(), jobName, executionSource, each); if (executorService.isShutdown()) &amp;#123; return; &amp;#125; executorService.submit(new Runnable() &amp;#123; @Override public void run() &amp;#123; try &amp;#123; process(shardingContexts, each, jobExecutionEvent); &amp;#125; finally &amp;#123; latch.countDown(); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; try &amp;#123; // 等待所有的分片项任务执行完毕 latch.await(); &amp;#125; catch (final InterruptedException ex) &amp;#123; Thread.currentThread().interrupt(); &amp;#125; &amp;#125; 里面又调用了一个com.dangdang.ddframe.job.executor.AbstractElasticJobExecutor#process(com.dangdang.ddframe.job.executor.ShardingContexts, int, com.dangdang.ddframe.job.event.type.JobExecutionEvent) 方法 private void process(final ShardingContexts shardingContexts, final int item, final JobExecutionEvent startEvent) &amp;#123; if (shardingContexts.isAllowSendJobEvent()) &amp;#123; jobFacade.postJobExecutionEvent(startEvent); &amp;#125; log.trace(\"Job '&amp;#123;&amp;#125;' executing, item is: '&amp;#123;&amp;#125;'.\", jobName, item); JobExecutionEvent completeEvent; try &amp;#123; process(new ShardingContext(shardingContexts, item)); completeEvent = startEvent.executionSuccess(); log.trace(\"Job '&amp;#123;&amp;#125;' executed, item is: '&amp;#123;&amp;#125;'.\", jobName, item); if (shardingContexts.isAllowSendJobEvent()) &amp;#123; jobFacade.postJobExecutionEvent(completeEvent); &amp;#125; // CHECKSTYLE:OFF &amp;#125; catch (final Throwable cause) &amp;#123; // CHECKSTYLE:ON completeEvent = startEvent.executionFailure(cause); jobFacade.postJobExecutionEvent(completeEvent); itemErrorMessages.put(item, ExceptionUtil.transform(cause)); jobExceptionHandler.handleException(jobName, cause); &amp;#125; &amp;#125; 然后调用了一个抽象的com.dangdang.ddframe.job.executor.AbstractElasticJobExecutor#process(com.dangdang.ddframe.job.api.ShardingContext) 方法 protected abstract void process(ShardingContext shardingContext); 交给具体的实现类（SimpleJobExecutor、DataflowJobExecutor、 ScriptJobExecutor） 去处理 最终调用到任务类 @Override protected void process(final ShardingContext shardingContext) &amp;#123; simpleJob.execute(shardingContext); &amp;#125; public class MySimpleJob implements SimpleJob &amp;#123; @Override public void execute(ShardingContext shardingContext) &amp;#123; System.out.println(String.format(\"分片项 ShardingItem: %s | 运行时间: %s | 线程ID: %s | 分片参数: %s \", shardingContext.getShardingItem(), new SimpleDateFormat(\"HH:mm:ss\").format(new Date()), Thread.currentThread().getId(), shardingContext.getShardingParameter())); &amp;#125; &amp;#125; 5.3 失效转移所谓的失效转移,就是在执行任务的过程中发生了异常,这个分片任务可以在其他节点再次执行, // 定义作业核心配置 JobCoreConfiguration coreConfiguration = JobCoreConfiguration.newBuilder(MySimpleJob.class.getSimpleName(), \"0/2 * * * * ?\", 4).shardingItemParameters(\"0=RDP, 1=CORE, 2=SIMS, 3=ECIF\").failover(true).build(); FailoverListenerManager 监听的是zl的instance节点删除事件,如果任务配置了fairover等于true,其中某个instance 与zk 失去联系或者被删除,并且失效的节点又不是本身, 就会触发是失效转移逻辑. Job的失效转移监听来源于FailoverListenerManager的内部类,JobCrashedJobListener 的 dataChanged 方法 当节点任务失效后会调用JobCrashedJobListener 监听器,此监听器会根据实例id 获取所有的分片, 然后调用FailoverService 的 setCrashedFailoverFlag 方法, 将每个分片id 写到到/jobName/leader/failover/items, 假如原来的实例负责1、2分片项, 那items 节点就会写入1、2, 代表这两个分片项需要失效转移. @Override protected void dataChanged(final String path, final Type eventType, final String data) &amp;#123; if (isFailoverEnabled() &amp;&amp; Type.NODE_REMOVED == eventType &amp;&amp; instanceNode.isInstancePath(path)) &amp;#123; String jobInstanceId = path.substring(instanceNode.getInstanceFullPath().length() + 1); if (jobInstanceId.equals(JobRegistry.getInstance().getJobInstance(jobName).getJobInstanceId())) &amp;#123; return; &amp;#125; List&lt;Integer> failoverItems = failoverService.getFailoverItems(jobInstanceId); if (!failoverItems.isEmpty()) &amp;#123; for (int each : failoverItems) &amp;#123; // 设置失效的分片项标记 failoverService.setCrashedFailoverFlag(each); failoverService.failoverIfNecessary(); &amp;#125; &amp;#125; else &amp;#123; for (int each : shardingService.getShardingItems(jobInstanceId)) &amp;#123; failoverService.setCrashedFailoverFlag(each); failoverService.failoverIfNecessary(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 然后接下来调用FailoverService 的 failoverIfNessary方法, 首先判断是否需要失效转移,如果可以需要则只需要作业失败转移. /** * 如果需要失效转移, 则执行作业失效转移. */ public void failoverIfNecessary() &amp;#123; if (needFailover()) &amp;#123; jobNodeStorage.executeInLeader(FailoverNode.LATCH, new FailoverLeaderExecutionCallback()); &amp;#125; &amp;#125; 条件一： $&#123;JOB_NAME&#125;/leader/failover/items/$&#123;ITEM_ID&#125; 有失效转移的作业分片 条件二: 当前作业不再运行中 private boolean needFailover() &amp;#123; return jobNodeStorage.isJobNodeExisted(FailoverNode.ITEMS_ROOT) &amp;&amp; !jobNodeStorage.getJobNodeChildrenKeys(FailoverNode.ITEMS_ROOT).isEmpty() &amp;&amp; !JobRegistry.getInstance().isJobRunning(jobName); &amp;#125; 在主节点执行操作 /** * 在主节点执行操作. * * @param latchNode 分布式锁使用的作业节点名称 * @param callback 执行操作的回调 */ public void executeInLeader(final String latchNode, final LeaderExecutionCallback callback) &amp;#123; try (LeaderLatch latch = new LeaderLatch(getClient(), jobNodePath.getFullPath(latchNode))) &amp;#123; latch.start(); latch.await(); callback.execute(); //CHECKSTYLE:OFF &amp;#125; catch (final Exception ex) &amp;#123; //CHECKSTYLE:ON handleException(ex); &amp;#125; &amp;#125; 再次判断是否需要失效转移 从注册中心获取一个$&#123;JOB_NAME&#125;/leader/failover/items/$&#123;ITEM_ID&#125; 作业分片项 在注册中心节点$&#123;JOB_NAME&#125;/sharding/$&#123;ITEM_ID&#125;/failover 注册作业分片项为当前作业节点 然后移除任务转移分片项 最后调用执行, 提交任务 class FailoverLeaderExecutionCallback implements LeaderExecutionCallback &amp;#123; @Override public void execute() &amp;#123; // 判断是否需要失效转悠 if (JobRegistry.getInstance().isShutdown(jobName) || !needFailover()) &amp;#123; return; &amp;#125; // 从$&amp;#123;JOB_NAME&amp;#125;/leader/failover/items/$&amp;#123;ITEM_ID&amp;#125;获得一个分片项 int crashedItem = Integer.parseInt(jobNodeStorage.getJobNodeChildrenKeys(FailoverNode.ITEMS_ROOT).get(0)); log.debug(\"Failover job '&amp;#123;&amp;#125;' begin, crashed item '&amp;#123;&amp;#125;'\", jobName, crashedItem); // 在注册中心节点`$&amp;#123;JOB_NAME&amp;#125;/sharding/$&amp;#123;ITEM_ID&amp;#125;/failover`注册作业分片项为当前作业节点 jobNodeStorage.fillEphemeralJobNode(FailoverNode.getExecutionFailoverNode(crashedItem), JobRegistry.getInstance().getJobInstance(jobName).getJobInstanceId()); // 移除任务转移分片项 jobNodeStorage.removeJobNodeIfExisted(FailoverNode.getItemsNode(crashedItem)); // TODO 不应使用triggerJob, 而是使用executor统一调度 JobScheduleController jobScheduleController = JobRegistry.getInstance().getJobScheduleController(jobName); if (null != jobScheduleController) &amp;#123; // 提交任务 jobScheduleController.triggerJob(); &amp;#125; &amp;#125; &amp;#125; 这里仅仅是触发作业，而不是立即执行.","categories":[{"name":"任务调度","slug":"任务调度","permalink":"https://rainsoil.github.io/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"},{"name":"任务调度","slug":"任务调度/任务调度","permalink":"https://rainsoil.github.io/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"}],"tags":[]},{"title":"基于Socket手写一个RPC框架","slug":"分布式/2. 分布式架构基础/基于Socket手写一个RPC框架","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/fen-bu-shi/2.fen-bu-shi-jia-gou-ji-chu/ji-yu-socket-shou-xie-yi-ge-rpc-kuang-jia/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/fen-bu-shi/2.fen-bu-shi-jia-gou-ji-chu/ji-yu-socket-shou-xie-yi-ge-rpc-kuang-jia/","excerpt":"","text":"这里基于Socket 手写一个五脏俱全的RPC 框架服务端我们这里先建两个项目 rpc-server-api : 用于存放需要对外的接口类 rpc-server-prodiver： 存放业务代码的项目 rpc-server-api先在项目中加入spring的 pom依赖 &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-context&lt;/artifactId> &lt;version>4.2.8.RELEASE&lt;/version> &lt;/dependency> &lt;/dependencies> 我们这里先建一个注解类 @Component @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) public @interface RpcService &amp;#123; Class&lt;?> value(); /** * &lt;p>版本号&lt;/p> * * @return &amp;#123;@link String&amp;#125; * @author luyanan * @since 2019/9/4 */ String version() default \"\"; &amp;#125; 再将一个 请求封装类 /** * @author luyanan * @since 2019/9/3 * &lt;p>rpc 请求封装&lt;/p> **/ public class RpcRequest implements Serializable &amp;#123; /** * &lt;p>类名&lt;/p> * * @author luyanan * @since 2019/9/3 */ private String className; /** * &lt;p>方法名&lt;/p> * * @author luyanan * @since 2019/9/3 */ private String methodName; /** * &lt;p>参数列表&lt;/p> * * @author luyanan * @since 2019/9/3 */ private Object[] params; public String getClassName() &amp;#123; return className; &amp;#125; public void setClassName(String className) &amp;#123; this.className = className; &amp;#125; public String getMethodName() &amp;#123; return methodName; &amp;#125; public void setMethodName(String methodName) &amp;#123; this.methodName = methodName; &amp;#125; public Object[] getParams() &amp;#123; return params; &amp;#125; public void setParams(Object[] params) &amp;#123; this.params = params; &amp;#125; &amp;#125; 然后再建 一个 User 对象和IUserService public class User &amp;#123; private String name; private Integer age; public User(String name, Integer age) &amp;#123; this.name = name; this.age = age; &amp;#125; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; public Integer getAge() &amp;#123; return age; &amp;#125; public void setAge(Integer age) &amp;#123; this.age = age; &amp;#125; @Override public String toString() &amp;#123; return \"User&amp;#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&amp;#125;'; &amp;#125; &amp;#125; IUserService public interface IUserService &amp;#123; String saveUser(User user); String info(String id); &amp;#125; rpc-server-prodiver实现IUserService的业务 UserServiceImpl @RpcService(IUserService.class) public class UserServiceImpl implements IUserService &amp;#123; @Override public String saveUser(User user) &amp;#123; System.out.println(\"保存的用户为:\" + user); return \"success\"; &amp;#125; @Override public String info(String id) &amp;#123; return \"id:Tom\"; &amp;#125; &amp;#125; 接下来是有关socket 通信的代码 RpcService @Component public class RpcService implements InitializingBean, ApplicationContextAware &amp;#123; private int port; public RpcService() &amp;#123; &amp;#125; static ExecutorService executorService = Executors.newCachedThreadPool(); static Map&lt;String, Object> handlerMap = new HashMap&lt;>(); public RpcService(int port) &amp;#123; this.port = port; &amp;#125; @Override public void afterPropertiesSet() throws Exception &amp;#123; ServerSocket serverSocket = null; try &amp;#123; serverSocket = new ServerSocket(port); while (true) &amp;#123; Socket socket = serverSocket.accept(); executorService.submit(new SocketHandler(handlerMap, socket)); &amp;#125; &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; if (null != serverSocket) &amp;#123; try &amp;#123; serverSocket.close(); &amp;#125; catch (IOException e) &amp;#123; &amp;#125; &amp;#125; &amp;#125; &amp;#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &amp;#123; Map&lt;String, Object> objectMap = applicationContext.getBeansWithAnnotation(com.formula.rpc.api.annotaion.RpcService.class); for (Object value : objectMap.values()) &amp;#123; // 获取注解 com.formula.rpc.api.annotaion.RpcService rpcService = value.getClass().getAnnotation(com.formula.rpc.api.annotaion.RpcService.class); String name = rpcService.value().getName(); String version = rpcService.version(); if (!StringUtils.isEmpty(version)) &amp;#123; name += \"-\" + version; &amp;#125; handlerMap.put(name, value); &amp;#125; &amp;#125; &amp;#125; SocketHandler package com.formula.rpc.provider; import com.formula.rpc.api.RpcRequest; import java.io.IOException; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; import java.net.Socket; import java.util.HashMap; import java.util.Map; /** * @author luyanan * @since 2019/9/3 * &lt;p>处理&lt;/p> **/ public class SocketHandler implements Runnable &amp;#123; Map&lt;String, Object> handlerMap = null; private Socket socket; public SocketHandler(Map&lt;String, Object> handlerMap, Socket socket) &amp;#123; this.handlerMap = handlerMap; this.socket = socket; &amp;#125; @Override public void run() &amp;#123; ObjectInputStream objectInputStream = null; ObjectOutputStream objectOutputStream = null; try &amp;#123; objectInputStream = new ObjectInputStream(socket.getInputStream()); RpcRequest request = (RpcRequest) objectInputStream.readObject(); // 利用反射调用 Class clazz = Class.forName(request.getClassName()); Class&lt;?>[] types = new Class[request.getParams().length]; for (int i = 0; i &lt; request.getParams().length; i++) &amp;#123; types[i] = request.getParams()[i].getClass(); &amp;#125; Method method = clazz.getMethod(request.getMethodName(), types); Object result = method.invoke(handlerMap.get(request.getClassName()), request.getParams()); objectOutputStream = new ObjectOutputStream(socket.getOutputStream()); objectOutputStream.writeObject(result); objectOutputStream.flush(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (NoSuchMethodException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (IllegalAccessException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (InvocationTargetException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; if (objectInputStream != null) &amp;#123; try &amp;#123; objectInputStream.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; if (objectOutputStream != null) &amp;#123; try &amp;#123; objectOutputStream.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 配置类 RpcConfig package com.formula.rpc.provider; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; /** * @author luyanan * @since 2019/9/4 * &lt;p&gt;&lt;/p&gt; **/ @ComponentScan(basePackages = &quot;com.formula.rpc&quot;) @Configuration public class RpcConfig &#123; @Bean public RpcService rpcService() &#123; return new RpcService(8080); &#125; &#125; 启动类 ServerAPP package com.formula.rpc.provider; import com.formula.rpc.api.IUserService; import org.springframework.context.annotation.AnnotationConfigApplicationContext; /** * @author luyanan * @since 2019/9/4 * &lt;p&gt;&lt;/p&gt; **/ public class ServerAPP &#123; public static void main(String[] args) &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(RpcConfig.class); applicationContext.start(); &#125; &#125; 客户端这里使用一个动态代理来实现远程调用 首先要在客户端的poml 里面加入 api的依赖 &lt;dependency> &lt;groupId>com.formula&lt;/groupId> &lt;artifactId>rpc-server-api&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/dependency> RpcProxyClient package com.formula.rpc.client; import java.lang.reflect.Proxy; /** * @author luyanan * @since 2019/9/4 * &lt;p>&lt;/p> **/ public class RpcProxyClient &amp;#123; public &lt;T> T getService(Class&lt;?> interfaceClss, String host, int port) &amp;#123; return (T) Proxy.newProxyInstance(interfaceClss.getClassLoader(), new Class[]&amp;#123;interfaceClss&amp;#125;, new RemoteInvocationHandler(host, port)); &amp;#125; &amp;#125; RemoteInvocationHandler package com.formula.rpc.client; import com.formula.rpc.api.RpcRequest; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; /** * @author luyanan * @since 2019/9/4 * &lt;p>&lt;/p> **/ public class RemoteInvocationHandler implements InvocationHandler &amp;#123; private String host; private int port; public RemoteInvocationHandler(String host, int port) &amp;#123; this.host = host; this.port = port; &amp;#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; // 这是使用socket发送请求 if (method.getName().equals(\"toString\")) &amp;#123; return method.invoke(method.getDeclaringClass(), args); &amp;#125; RpcRequest request = new RpcRequest(); request.setClassName(method.getDeclaringClass().getName()); request.setMethodName(method.getName()); request.setParams(args); RpcNetTransport netTransport = new RpcNetTransport(host, port); return netTransport.send(request); &amp;#125; &amp;#125; 主启动类 package com.formula.rpc.client; import com.formula.rpc.api.IUserService; import org.springframework.context.annotation.AnnotationConfigApplicationContext; /** * @author luyanan * @since 2019/9/4 * &lt;p>&lt;/p> **/ public class ClientAPP &amp;#123; public static void main(String[] args) &amp;#123; RpcProxyClient proxyClient = new RpcProxyClient(); IUserService userService = proxyClient.getService(IUserService.class, \"localhost\", 8080); System.out.println(userService.info(\"1\")); &amp;#125; &amp;#125;","categories":[{"name":"2. 分布式架构基础","slug":"2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"},{"name":"分布式","slug":"2-分布式架构基础/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式","slug":"2-分布式架构基础/分布式/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"2. 分布式架构基础","slug":"2-分布式架构基础/分布式/分布式/2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"远程通信协议(2)","slug":"分布式/1. 漫谈分布式架构/远程通信协议(2)","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/fen-bu-shi/1.man-tan-fen-bu-shi-jia-gou/yuan-cheng-tong-xin-xie-yi-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/fen-bu-shi/1.man-tan-fen-bu-shi-jia-gou/yuan-cheng-tong-xin-xie-yi-2/","excerpt":"","text":"远程通信协议一个http 请求的整个流程在分布式架构中,有一个很重要的环节,就是分布式网络中的计算机节点彼此之间需要通信,这个通信的过程一定会涉及到通信协议相关的知识点. 我们每天都在用浏览器访问各种网站,作为用户来说,只需要输入一个网址并且正确跳转就行,但是作为程序员,看到的可能是这个响应背后的整体流程,所以我想通过一个http请求的整个流程来进行讲解通信的知识, 负责域名解析的DNS服务首先,用户访问一个域名,会经过DNS解析. DNS(Domain Name System) ,它和HTTP协议一样是位于应用层的协议,主要提供域名到IP的解析服务. 我们其实不用域名也可以访问目标主机的服务,但是IP本身不是那么容易记,所以使用域名进行替换使得用户更容易记住。 加速静态内容访问速度的CDN在很多大型的网站,会引入CDN 来加速静态内容的访问,这里给大家简单解释一下什么是CDN(Content Delivry Network),表示的是内容分发网络. CDN 其实就是一种网络缓存技术,能够把一些相对稳定的资源放到距离最终用户较近的地方,一方面可以节省整个广域网的带宽消耗,另外一方面可以提升用户的访问速度,改进用户体验. 我们一般会把静态的文件(图片、脚本、静态页面)放到CDN中. 如果引入了CDN,那么解析的流程可能会稍微复杂点 HTTP 协议通信原理域名被成功解析以后，客户端和服务端之间是怎么建立连接并如何通信的呢? 说到通信,大家一定听过TCP和UDP这两种通信协议,以及建立连接的握手过程,而http协议的通信是基于tcp/ip协议之上的一个应用层协议,应用层协议除了http还有哪些呢?(FTP、DNS、SMTP、Telnet等). 涉及到网络协议,我们一定需要知道OSI七层网路模型和TCP/IP四层概念模型, OSI七层网络模式包括: 应用层 表示层 会话层、 传输层、 网络层、 数据链路层’物理层 TCP/IP四层概念模型包括: 应用层 传输层 网络层 数据链路层 请求发生过程,在tcp/ip四层网络模型中所做的事情当应用程序用TCP传送数据时,数据被送入协议栈中,然后逐个通过每一层直到被当做一串比特流送入网络中.其中每一层对收到的数据都要增加一些首部信息(有时还要增加尾部信息) 客户端如何找到目标服务在客户端发起请求的时候,我们会在数据链路层去组装目标机器的MAC地址,目标机器的MAC地址怎么得到呢? 这里就涉及到一个ARP协议,这个协议简单来说就是已知目标机器的IP,需要获取目标机器的mac地址(发送一个广播消息,这个ip是谁,请来认领. 认领的机器会发送一个mac地址的响应) 有了这个目标MAC地址,数据包在链路上广播,MAC的网卡才能发现,这个包是给它的, MAC的网卡把包收进来,然后打开IP包,发现IP地址也是自己的,再打开TCP包,发现端口是自己,也就是80端口,而这个时候这台机器上有一个nginx 是监听80端口的. 于是将请求提交给nginx,nginx返回一个网页. 然后将网页需要发回请求的机器. 然后层层封装,最后到MAC层. 因为来的时候有源MAC地址,返回的时候,源MAC地址就变成了目标MAC, 再返回请求的机器 为了避免每次都用ARP请求,机器本地也会进行ARP缓存. 当然机器会不断的上线下线的,ip也可能会变,所以ARP的MAC地址缓存过一段时间就会过期. 接收端收到数据包以后的处理过程当目标机器收到一个以太网数据帧时,数据就开始从协议栈中由低向上升,同时去掉各层的协议加上的报文首部. 每层协议都要去检查报文首部中的协议标识,以确定接受数据的上层协议. 为什么有了MAC层还要走IP层呢?之前我们提到,mac地址是唯一的,那理论上说,在任何两个设备之间,应该都可以通过mac地址发送数据,那为什么还需要ip地址呢? mac地址就像个人的身份证号码,人的身份证号码与人户口所在的城市,出生日期有关,但是和人所在的位置没有关系,人是会移动的,知道一个人的身份证号码,并不能找到他这个人,mac地址类似,它是和设备的生产者、批次、日期之类的关联起来,知道一个设备的mac地址,并不能在网络中将数据发送给他,除非它和发送方的在同一个网络中. 所以要实现机器之间的通信,我们还需要有ip的概念,ip表达的是当前机器在网络中的位置,类似于城市名+道路号+门牌号的概念。通过ip层的寻址,我们能知道按何种路径在全世界任意两台internet 上的机器 间传输数据 TPC/IP的分层管理TPC/IP协议按照层次分为4层: 应用层、传输层、网络层、数据链路层.对于分层这个概念,大家一定不会陌生,比如我们的分布式机构体系中分为业务层、服务层、基础支撑层. 比如docker,也是基于分层来实现. 所以我们会发现,复杂的程序都需要分层,这个是软件设计的要求. 每一层专注于领域的事情. 如果某些地方需要修改,我们只需要把变动的层替换掉就行,一方面改动影响少,另一方面整个架构的灵活性一更高. 最后, 在分层之后,整个架构的设计也变得相对简单了. 分层架构了解了分层的概念后,我们再去理解所谓的二层负载,三层负载,四层负载,七层负载就容易多了 一次http请求过来,一定会从应用层到传输层,完成整个交互. 只要在网络上跑的数据,都是完整的. 可以有下层没上层,绝不可能有上层没下层. 二层负载二层负载是针对MAC,负载均衡服务器对外依然是提供一个vip(虚拟ip),集群中不同的机器采用相同的ip地址,但是机器的MAC地址是不相同的, 当负载均衡服务器接受到请求后,通过改写报文的目标MAC地址的方式将请求转发到目标机器实现负载均衡. 二层负载均衡会通过一个虚拟MAC地址接受请求,然后再分配到真实的MAC地址 三层负载均衡三层负载是针对IP,和二层负载均衡类似,负载均衡服务器对外依然提供一个VIP(虚拟ip),但是集群中不同的机器采用不同的ip地址. 当负载均衡服务器接受到请求之后,根据不同的负载均衡算法,通过ip将请求转发至不同的真实服务器. 三层负载均衡会通过一个虚拟ip地址来接受请求,然后再分配到真实的ip地址上 四层负载均衡四层负载均衡工作在OSI模型的传输层,由于在传输层,只有TCP/UDP协议,这两种协议中除了包含源ip、目标ip以外,还包含源端口号以及目标端口号. 四层负载均衡服务器在接受到客户端请求后,通过修改数据包的地址信息(ip+端口号) 将流量转发到应用服务器. 四层通过虚拟ip+端口号接受请求,然后再分配到真实的服务器上. 七层负载均衡七层负载均衡巩工作在OSI模型的应用层,应用层协议较多,常用http、redius、dns等.七层负载就可以基于这些协议来负载. 这些应用协议中会包含很多有意义的内容,比如同一个WEB服务器的负载均衡,除了根据ip+端口号进行负载外,还可根据七层的URL、浏览器类别来决定是否要进行负载均衡. TCP/IP协议的深入分析通过前面一个案例的分析,基本清楚了网络的通信流程,在http协议中,底层用到了tcp通信协议,我们接下来给大家简单介绍一下TCP的通信协议原理。 我们如果需要深入学习网络协议,就要先把一些基本的协议的作用和工作过程搞清楚,网络设备还没有只能到人脑的程序，它是由人类创造出来的,它的工作过程肯定是符合人类习惯并且按照人类的交流习惯来设计的. 所以要以人类的思维方式来理解这些协议. 假如, 你给别人打电话,不可能电话一接通你就啪啦啪啦地说一大通,万一对方接通电话后因为有事还没来得及倾听呢？ 这不太符合正常人类的交流习惯. 一般是电话接通后,双方会有个交互的过程,会先说一声”你好”,然后对方也回复一声”你好”,双方通过各自一句”你好” 明确对方的注意力都放在了电话沟通上,然后你们双方就可以开始交流了,这才是正常人类交流方式。 这个过程体现在计算机网络里就是网络协议,我们通过TCP 协议在两台电脑建立网络连接之前要先发数据包进行沟通,沟通后再建立连接,然后才是信息的传输, 而UDP协议就类似于我们的校园广播,广播内容已经通过广播站播放出去了,你能不能听到,那就于广播站无关了, 正常情况下,不可能你说没注意听然后再让广播站再播放一次广播内容, 基于这些思路,我们先去了解一下TCP里面关注比较多的握手协议. TCP 握手协议所以TCP 消息的可靠性首先来自于有效的连接建立, 所以在数据进行传输前,需要通过三次握手建立一个连接,所谓的三次握手,就是在建立TCP连接时,需要客户端和服务端总共发送3个包来确认连接的建立,在socket编程中,这个过程由客户端执行connect来触发. 第一次握手(SYN=1,seq=x)客户端发送一个TCP的SYN标志位置1的包,指明客户端打算了解的服务器的端口,以及初始序号X,保存在包头的序列号(Sequence Number)字段里, 发送完毕后,客户端进入SYN_SEND状态, 第二次握手(SYN=1,ACK=1,seq=y,ACKnum =1) 服务器发回确认包(ACK)应答. 即 SYN标志位和ACK标志位均为1. 服务器端选择自己ISN序列号,放在Seq域里,同时将确认序号(Acknowledgement Number) 设置为客户的ISN加1,即X+1.发送完毕后,服务器端进入SYN_RCVD状态, 第三次握手(ACK=1 , ACKnum = y+1)客户端再次发送确认包(ACK),SYN标志位为0,ACK的标志位为1, 并且把服务器发来ACK的序号字段+1, 放在确定字段中发送给对方,并且在数据段放些ISN 发完毕后,客户端进入 ESTABLISHED 状态, 当服务器端接收到这个包时，也会进入ESTABLISHED 状态,TCP 握手结束. 那TCP再三次握手的时候,IP层和MAC层都在做什么呢? 当然是TCP 发送每一个消息,都会带着IP层和MAC层了.因为TCP每发送一个消息,IP层和MAC层的所有机制都要运行一遍,而你只看到TCP三次握手了. 其实IP层和MAC层为此也忙活了好久, SYN 攻击在三次握手过程中,Server发送SYN-ACK之后,收到Client 的ACK之前的TCP连接称为半连接(half-open connect),此时Server 处于SYN_RCVD状态,当收到ACK后,Server 转入ESTABLISHED 状态. SYN攻击就是Client在短时间内伪造大量不存在的IP地址,并向Server 不断的发送SYN包,Server回复确认包,并等待Client的确认. 由于源地址是不存在的,因为Server 需要不断的重发直至超时,这些伪造的SYN包将长时间占用未连接队列,导致正常的SYN请求因为队列满而被丢弃,从而引起网络堵塞甚至系统瘫痪. SYN攻击时一种典型的DDOS攻击,检测SYN攻击的方式非常简单,即当Server上有大量半连接状态且源ip地址是随机的,则可以断定遭到SYN攻击了. TCP四次挥手协议四次挥手表示TCP 断开连接的时候,需要客户端和服务端总共发送4个包以确认连接的断开,客户端或服务器均可主动发起挥手动作(因为TCP是一个全双工协议),在socket 编程中,任何一方执行close() 操作即可产生挥手操作。 单工: 数据传输只支持数据在一个方向上传输 半双工: 数据传输允许数据在两个方向上传输,但是在某一时刻,只允许在一个方向上传输,实际上有点像切换方向的单工通信. 全双工:数据通信允许数据同时在两个方向上传输,因此全双工是两个单双工通信方式的结合,它要求发送设备和接受设备都有独立的接受和发送能力. 第一次挥手(FIN=1,seq=x)假设客户端想要关闭连接,客户端发送一个FIN标志位置为1的包,表示自己已经没有数据可以发送了,但是仍然可以接受数据. 发送完毕后,客户端进入FIN_WAIT_1状态 第二次挥手(ACK=1,ACKnum=x+1)服务器确认客户端的FIN包,发送一个确认包,表明自己接受到了客户端关闭连接的请求,但还没有准备好关闭连接. 发送完毕后,服务器端进入CLOSE_WAIT 状态,客户端接受到这个确认包后,进入FIN_WAIT_2状态,等待服务器端关闭连接。 第三次挥手(FIN = 1, seq =w)服务器端准备好关闭连接时,向客户端发送结束连接请求,FIN置为1,发送完毕后,服务器端进入LAST_ACK状态,等待来自客户端的最后一个ACK 第四次挥手(ACK =1,ACKnum = w+1)客户端接收到来自服务器端的关闭请求,发送一个确认包,并进入TIME_WAIT状态,等待可能出现的要求重传的ACK包. 服务器端接受到这个确认包后,关闭连接,进入CLOSED状态 客户端等待了某个固定时间(两个最大段生命周期,2MSL,2Maximum Segment Lefetime)之后,没有收到服务器端的ACK 认为服务器端已经正常关闭连接,于是自己也关闭了连接,进入CLOSED状态. 假设Client端发起中断连接请求,也就是发送FIN报文.Server端接收到了FIN报文后,意思是说”我Client端已经没有数据要发送给你了”,但是如果你还有数据没有发送完成,则不必急着关闭Socket,可以继续发送数据. 所以你先发送ACK,”告诉Client端,你的请求我收到了,但是我还没准备好,清继续你等我的消息”. 这个时候CLient端就进入FIN_WAIT状态,继续等待Server端的FIN报文. 当Server端确定数据已经发送完成,则向Client端发送FIN报文,“告诉Client端,好了,我这边数据发送完了,准备好关闭连接了.”Client端接收FIN报文后,”就知道可以关闭连接了,但是他还是不想担心网络,怕Server端不知道要关闭,所以发送ACK后进入TIME_WAIT状态,如果Server端没有收到ACK 则可以重传”,Server端收到ACK后,”就知道可以断开连接了”. Client端等待了2MSL 后依然没有收到回复,则证明了Server端已经正常关闭,那好,我Client端也可以关闭连接,OK,TCP 连接就这样关闭了. 问题：问题1: 为什么连接的时候是三次握手,关闭的时候是四次挥手？三次握手是因为当Server端收到Client端的SYN连接请求报文后,可以直接发送SYN + ACK报文. 其中ACK报文是用来应答的,SYN报文是用来同步的. 但是关闭连接时,当Server端收到FIN时,很可能并不会立即关闭socket(因为可能还有消息还处理),所以只能先回复一个ACK报文,告诉Client端,”你发的FIN报文我收到了”,只有等到我Server端所有的报文都发送完了,我才能发送FIN报文,因此不能一起发送. 顾需要四步. 问题2: 为什么TIEM_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态虽然按照道理,四个报文都发送完毕,我们可以直接进入CLOSE状态,但是我们必须假设网络是不可靠的,有可能最后一个ACK丢失,所以TIME_WAIT状态就是用来重发可能丢失的报文. 使用协议进行通信tcp连接建立后,就可以基于这个连接通道来发送和接受消息了,TCP、UDP 都是在基于Socket概念上为某类应用场景而扩展出来的传输协议,那么什么是socket呢? socket 是一种抽象层,应用程序通过它来发送和接收数据,就像应用程序打开一个文件句柄,把数据读写到磁盘上一样, 使用scoket可以把应用程序添加到网络中. 并与处于同一个网络中 其他应用程序进行通信. 不同类型的Socket 与不同类型的底层协议簇有关联,主要的socket 类型为流套接字(stream socket) 和数据报文套接字(datagram socket). stream socket 把TCP作为端对端协议(底层使用IP协议),提供一个可信赖的字节流服务. 数据报文套接字(datagram socket) 使用UDP协议(底层同样使用IP协议) 提供了一种”尽力而为”的数据报文服务 接下来,我们使用java提供的API来展示TCP协议的客户端和服务端通信的案例和UDP协议的客户端和服务端通信的案例,然后更进一步了解底层的原理 基于TCP协议实现通信实现一个简单的从客户端发送消息到服务端的功能 package com.notes.socket; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.net.ServerSocket; import java.net.Socket; /** * @author luyanan * @since 2019/8/27 * &lt;p>socket服务器端&lt;/p> **/ public class ServerSocketDemo &amp;#123; public static void main(String[] args) &amp;#123; ServerSocket serverSocket = null; BufferedReader in = null; try &amp;#123; /* TCP的服务器要先监听一个端口,一般是先调用bing函数,给这个socket 赋予一个ip地址和端口., 为什么需要端口呢? 要知道你写的是一个应用程序,当一个网络包来的时候,内核需要通过TCP头里面的这个端口,来找到你的这个应用程序, 把包给你. 为什么需要ip地址? 有时候,一台机器会有多个网卡,也就会有多个ip地址,你可以选择监听所有的网卡, 也可以选择监听一个网卡,这样,只有发给这个网卡的包,才会给你 */ serverSocket = new ServerSocket(8080); /* 阻塞等待客户端连接,接下来,服务端调用accept函数,拿出一个已经完成的连接进行处理,如果还没有完成,就要等着. */ Socket socket = serverSocket.accept(); /* 连接建立后,双方开始通过read/write 函数来读写数据,就像往一个文件流里面写东西一样. */ InputStreamReader inputStreamReader = new InputStreamReader(socket.getInputStream()); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); System.out.println(\"Client:\" + bufferedReader.readLine()); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; if (in != null) &amp;#123; try &amp;#123; in.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; if (serverSocket != null) &amp;#123; try &amp;#123; serverSocket.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 客户端 package com.notes.socket; import java.io.IOException; import java.io.OutputStream; import java.io.PrintWriter; import java.net.Socket; /** * @author luyanan * @since 2019/8/27 * &lt;p>socket客户端&lt;/p> **/ public class ClientSocketDemo &amp;#123; public static void main(String[] args) &amp;#123; Socket socket = null; PrintWriter printWriter = null; try &amp;#123; socket = new Socket(\"localhost\", 8080); OutputStream outputStream = socket.getOutputStream(); printWriter = new PrintWriter(outputStream, true); printWriter.println(\"Hello Word\"); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; if (printWriter != null) &amp;#123; printWriter.close(); &amp;#125; if (socket != null) &amp;#123; try &amp;#123; socket.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 基于TCP实现双向通信对话功能TCP是一个全双工协议,数据通信允许数据同时在两个方向上传输,因此全双工是两个单通信方式的结合,它要求发送设备和接收设备都有独立的接收和发送的能力. 我们来做一个简单的实现 Server端package com.notes.socket; import com.sun.org.apache.bcel.internal.generic.NEW; import sun.java2d.opengl.WGLGraphicsConfig; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.io.PrintWriter; import java.net.ServerSocket; import java.net.Socket; /** * @author luyanan * @since 2019/8/27 * &lt;p>socket 全双工&lt;/p> **/ public class ServerSocketDemo2 &amp;#123; public static void main(String[] args) &amp;#123; ServerSocket serverSocket = null; BufferedReader bufferedReader = null; PrintWriter printWriter = null; Socket socket = null; BufferedReader sin = null; try &amp;#123; serverSocket = new ServerSocket(8080); // 使用accept 阻塞等待客户请求 socket = serverSocket.accept(); // 由Socket 对象得到输入流,并构造响应的BufferedReader 对象 bufferedReader = new BufferedReader(new InputStreamReader(socket.getInputStream())); // 由socket 对象得到输出流,并构造PrintWrite 对象 printWriter = new PrintWriter(socket.getOutputStream()); System.out.println(\"Client:\" + bufferedReader.readLine()); String line = null; sin = new BufferedReader(new InputStreamReader(System.in)); line = sin.readLine(); //如果字符串为bye 则停止循环 while (!line.equals(\"bye\")) &amp;#123; // 向 客户端输出该字符串 printWriter.println(line); printWriter.flush(); System.out.println(\"server:\" + line); // 客户端输入 System.out.println(bufferedReader.readLine()); line = sin.readLine(); &amp;#125; &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; try &amp;#123; serverSocket.close(); bufferedReader.close(); printWriter.close(); socket.close(); sin.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; Client 端package com.notes.socket; import com.sun.org.apache.regexp.internal.RE; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.io.PrintWriter; import java.net.Socket; /** * @author luyanan * @since 2019/8/27 * &lt;p>socket 全双工 客户端&lt;/p> **/ public class ClientSocketDemo2 &amp;#123; public static void main(String[] args) &amp;#123; try &amp;#123; Socket socket = new Socket(\"localhost\", 8080); BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream())); PrintWriter printWriter = new PrintWriter(socket.getOutputStream()); BufferedReader sin = new BufferedReader(new InputStreamReader(System.in)); String line = null; line = sin.readLine(); while (!line.equals(\"bye\")) &amp;#123; printWriter.println(line); printWriter.flush(); System.out.println(\"Client:\" + line); System.out.println(\"Server:\" + br.readLine()); line = sin.readLine(); &amp;#125; socket.close(); br.close(); printWriter.close(); sin.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 总结我们通过一个图来简单描述一下socket 链接建立以及通信的模型 理解TCP的通信原理以及IO阻塞通过上面的这个简单的案例,基本清楚了在java 应用程序中如何使用socket套接字来建立一个基于tcp协议的通信流程. 接下来,我们再来了解一下tcp的底层通信过程是怎么样的? 了解TCP协议的通信过程首先,对于TCP通信来说,每个TCP socket的内核中都有一个发送缓冲区和一个接收缓冲区. TCP的全双工的工作模式以及TCP的滑动窗口就是依赖于这两个独立的Buffer和该Buffer的填充状态. 接收缓冲区把数据缓存到内核,若应用进程一直没有调用Socket的read 方法进行读取,那么该数据会一直被缓冲在接受缓冲区内. 不管进程是否 读取Socket ,对端发来的数据都会经过内核接收并缓存到Socket 的内核接收缓冲区. read所要做的工作就是把内核接收缓冲区的数据复制到应用层用户的Buffer里. 进程调用Socket 的send发送数据的时候,一般情况下是将数据从应用层用户的Buffer 里面复制到Socket 的内核发送缓冲区,然后send 就会在上层返回. 换句话来说,send返回时,数据不一定会被发送到对端, 前面我们提到,Socket的接收缓冲区被TCP用来缓存网络上收到的数据,一直保存到应用进程读走为止. 如果应用进程一直没有读取,那么Buffer 满了以后,出现的情况是: 通知对端TCP协议汇总的窗口关闭,保证TCP接收缓冲区不会移除. 保证了TCP是可靠传输的, 如果对方无视窗口大小发出了超过窗口大小的数据,那么接收方会把这些数据丢弃. 滑动窗口协议这个过程中涉及到了TCP的滑动窗口协议,滑动窗口(Sliding window) 是一种流量控制技术.早期的网络通信中,通信双方不会考虑网络的拥挤情况直接发送数据. 由于大家不知道网络拥挤情况,同时发送数据,导致中间节点阻塞掉包,谁也发不了数据, 所以就有了滑动窗口机制来解决此问题. 发送和接收方都会维护一个数据帧的序列,这个序列被称为窗口. 发送窗口就是发送端允许连续发送的帧的序列号 发送端可以不等待应发而连续发送的最大帧数称为发送窗口的尺寸. 接收窗口接收方允许接收的帧的序列号,凡落在接收窗口内的帧,接收方都必须处理,落在接收窗口外的帧被丢弃 接收方每次允许接收的帧数称为接收窗口的尺寸 在线滑动窗口演示功能 https://media.pearsoncmg.com/aw/ecs_kurose_compnetwork_7/cw/content/interactiveanimations/selective-repeat-protocol/index.html 理解阻塞到底是怎么回事?了解了基本通信原理以后, 我们再来思考一个问题,在前面的代码演示中,我们通过socket.accept() 去接收一个客户端请求,accept 是一个阻塞的方法,意味着TCP服务器一次只能处理一个客户端请求,当一个客户端向一个已经被其他客户端占用的服务器发送链接请求时,虽然在链接建立后可以向服务端发送数据,但是在服务器端处理完之前都请求之前,却不会对新的客户端做出响应,这种类型的服务器被称为”迭代服务器”. 迭代服务器是按照顺序处理客户端请求的,也就是服务器端必须要处理完前一个请求才能对下一个客户端的请求进行响应, 但是在实际应用中,我们不能接受这样的处理方式,所以我们需要一种方法可以独立处理每一个连接,并且他们之间不会相互干扰, 而java提供的多线程技术正好满足这个条件,这个机制使得服务器能够方便的处理多个客户端的请求. 一个客户端对应一个线程为每个客户端创建一个线程实际上会存在一些弊端,因为创建一个线程需要占用CPU的资源和内存资源,另外,随着线程数的增加,系统资源将会成为瓶颈最终达到一个不可控的状态,所以我们还可以通过线程池来实现多个客户端请求的功能. 因为线程池是可控的, 非阻塞模型上面的这种模型虽然优化了IO处理的方式,但是,不管是线程池还是单个线程,线程本身的处理个数是有限制的, 对于操作系统而言,如果线程数太多会造成CPU上下文切换的开销, 因此这种方式不能解决根本问题. 所以在java1.4以后,引入了NIO(NEW IO)的功能, 阻塞IO前面其实已经简单讲过了阻塞IO的原理,我想在这里重申一下什么是阻塞IO呢? 就是当客户端的数据从网卡缓冲区复制到内核缓冲区之前,服务端会一直阻塞. 以socket接口为例,进程空间中调用recvfrom,进程从调用 recvform 开始到它返回的整段时间 都是被阻塞的,因此被称为阻塞IO模型. 非阻塞IO那大家思考一个问题,如果我们希望这台服务器能够处理更多的连接,怎么去优化呢? 我们第一时间想到的应该是如何保证这个阻塞变成非阻塞吧.所以就引入了非阻塞模型,非阻塞IO模型的原理很简单,就是进程空间调用recvform, 如果这个时候内核缓冲区没有数据的话,就直接返回一个 EWOULDBLOCK 错误,然后应用程序通过不断轮询来检查这个内核状态,看内核是不是有数据过来. IO复用模型我们前面讲的非阻塞仍然需要进程不断的轮询重试, 能不能实现当数据可读了以后给程序一个通知呢? 所以这里引入了IO多路复用模型, IO多路复用模型的本质是通过一种机制(系统内核缓冲I/O数据),让单个进程可以监视多个文件描述符,一旦某个描述符就绪(一般是读就绪或者写就绪),能够通知程序进行相应的读写操作 什么是fd: 在linux中,内核把所有的外部设备都当成是一个文件来操作,对一个文件的读写会调用内核提供了系统命令,返回一个fd(文件描述符). 而对于一个socket的读写也会有相应的文件名描述符,称为 socketfd 常见的IO多路复用方式有[select、poll、epoll], 都是linux API提供的IO复用方式,那么接下来重点讲一下 select和 epoll 这两个模型 select:select: 进程可以通过把一个或者多个fd传递给select 系统调用,进程会阻塞在select操作上,这样select 可以帮我们检测多个fd是否处于就绪状态. 这个模式有两个缺点: 由于他能够同时箭筒多个文件描述符,假如说有1000个,这个时候如果其中一个fd处于就绪状态,那么当前进程需要线性轮询所有的fd,也就是监听的fd 越多,性能开销就越大. 同时,select 在单个进程中能打开的fd是有限制的,默认是1024, 对于那些需要支持单机上万的TCP连接来说确实有点少, epollepoll : linux 还提供了epoll的系统调用,epoll 是基于事件驱动方式来代替扫描顺序的,因此性能相对来说更高,主要原理是,当被监听的fd中, 有fd就绪时,会告知当前进程具体哪一个fd就绪,那么当前进程只需要去从指定的fd上读取数据即可. 由于epoll 能够通过事件告知应用进程哪个fd是可读的,所以我们也称这种IO为异步非阻塞IO,当然它是伪异步的，因为它还需要去把数据从内核同步复制到用户空间中,真正的异步非阻塞,应该是数据已经完全准备好了,我只需要从用户空间读就行. 多路复用的好处I/O多路复用可以通过把多个IO的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端的请求. 他最大的优势是系统开销小,并且不需要创建新的进程或者线程,降低了系统的资源开销。 一台机器理论上能支持的连接数首先,在确定最大连接数之前,大家先跟我了解一下系统如何标识一个tcp连接. 系统用一个四元组来唯一标识一个TCP连接,(source_ip,source_port,destination_ip,destination_port).即(源ip,源端口,目的ip,目的端口)四个元素的组合,只要四个元素组合中有一个元素不一样,那就可以区别不同的连接. 比如: 你的IP地址 是11.1.2.3, 在8080 端口监听 那么当一个来自 22.4.5.6,端口号5555的连接到达后，那么建立的这条连接的四元组为(11.1.2.3,8080,22.4.5.6,5555) 这时，假设上面的那个客户(22.4.5.6) 发来第二条连接请求,端口号为6666, 那么新的连接四元组为(11.1.2.3,8080,22.4.5.6,6666) 那么,你主机的8080端口就建立了两条连接. 通常来说,服务端是固定一个监听端口,比如8080,等待客户端的连接请求. 在不考虑地址重用的情况下，即使Server端有多个ip，但是本地监听的端口是独立的. 所以对于tcp连接的4元组中,如果destination_ip和destination_port 不变,那么只有source_ip和source_port 是可变的,因此最大的tcp连接数应该为客户端的ip数* 客户端的端口数. 在IPV4中,不考虑ip分类的因素,最大的ip数为2的32次方, 客户端最大的端口数为2的16次方,也就是65536. 也就是服务端单机的最大的TCP连接数约为2的48次方 当然,这只是一个理论值,以linux 服务器为例,实际的连接数还取决于： 内存大小(因为每一个TCP连接都要占用一定的内存) 文件句柄限制,每一个tcp连接都需要占一个文件描述符,一旦这个文件描述符使用完了,新来的连接会返回一个”“Can’t open so many files”的异常,如果大家知道对于操作系统最大可以打开的文件数限制,就知道怎么去调整这个限制. 可以执行 [ulimit -n] 得到当前一个进程最大能打开1024个文件,所以你要采用此默认配置最多也就可以并发上千个TCP连接 可以通过 [ vim /etc/security/limits.conf ]去修改系统最大文件打开数限制 ​ * soft nofile 2048 ​ *hard nofile 2048 ​ 表示所有用户限制, soft/hard 表示软限制还是硬限制, 2048 表示修改后的值 * 可以通过 [cat /proc/sys/fs/file-max ] 查看linux 系统级 最大打开文件限制,表示当前这个服务器最多能够打开多少个文件 带宽资源的限制","categories":[{"name":"1. 漫谈分布式架构","slug":"1-漫谈分布式架构","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"},{"name":"分布式","slug":"1-漫谈分布式架构/分布式","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式","slug":"1-漫谈分布式架构/分布式/分布式","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"1. 漫谈分布式架构","slug":"1-漫谈分布式架构/分布式/分布式/1-漫谈分布式架构","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"}],"tags":[]},{"title":"ES6","slug":"前端/ES6/ES6","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.265Z","comments":true,"path":"2022/01/04/qian-duan/es6/es6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/qian-duan/es6/es6/","excerpt":"","text":"ES6ECMAScript6.0 (以下简称ES6,ECMAScript 是一种由Ecma 国际通过ECMA-262标准化的脚本),是javaScript 语言的下一代标准,2015年6月份正式发布,从ES6 开始的版本号采用年号,如ES2015,就是ES6. ES2016 就是ES7 ECMAScript 是规范,JavaScript 则是具体的实现. 在ES6 中,加入了很多新的特性. 1. 声明变量在es6 中可以使用let来声明变量 let 具有严格的作用域 我们可以用var 声明一个变量,但是声明的变量往往会存在越域的问题, 但是用let 声明的变量则拥有严格的局部作用域 // var的申明往往会越域 //let申明的变量具有严格的局部作用域 &amp;#123; var a = 1; let b = 2; &amp;#125; console.log(a); console.log(b); /** * 输出结果: * let.html:19 Uncaught ReferenceError: b is not defined * at let.html:19 */ var 可以声明多次,但是let 只能声明一次 // var 可以声明多次 // 但是`let` 只能声明一次 var m = 1; var m = 2; let n = 1; let n = 2; /** * 输出结果: * Uncaught SyntaxError: Identifier 'n' has already been declared */ var 会存在变量提升,但是let 不会存在 // var 会变量提升,let不会存在变量提升 console.log(x); var x = 10; console.log(y); let y = 10; /** * 输出结果: * undefined let.html:43 Uncaught ReferenceError: Cannot access 'y' before initialization at let.html:43 */ const 也可以用来声明变量,区别在于const 声明之后不允许改变,而且一旦声明之后必须初始化,否则会报错. // const 声明后不允许改变,一旦声明必须初始化,否则会报错 const a = 1; a = 3; /** * 输出结果: * let.html:55 Uncaught TypeError: Assignment to constant variable. at let.html:55 */ 全部 &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>let&lt;/title> &lt;/head> &lt;body> &lt;/body> &lt;script> // var的申明往往会越域 //let申明的变量具有严格的局部作用域 // &amp;#123; // var a = 1; // let b = 2; // &amp;#125; // console.log(a); // console.log(b); /** * 输出结果: * let.html:19 Uncaught ReferenceError: b is not defined * at let.html:19 */ /**************************************/ // var 可以声明多次 // 但是`let` 只能声明一次 // var m = 1; // var m = 2; // let n = 1; // let n = 2; /** * 输出结果: * Uncaught SyntaxError: Identifier 'n' has already been declared */ /************************************/ // var 会变量提升,let不会存在变量提升 console.log(x); var x = 10; console.log(y); let y = 10; /** * 输出结果: * undefined let.html:43 Uncaught ReferenceError: Cannot access 'y' before initialization at let.html:43 */ /***********************************/ // const 声明后不允许改变,一旦声明必须初始化,否则会报错 const a = 1; a = 3; /** * 输出结果: * let.html:55 Uncaught TypeError: Assignment to constant variable. at let.html:55 */ &lt;/script> &lt;/html> 2. 结构表达式结构表达式使得我们可以通过特定的语法直接优雅的获取数组或者对象中的一个或者多个的值 数组 let arr = [1, 2, 3]; let a = arr[0]; let b = arr[1]; let c = arr[2]; console.log(a, b, b); let [d, e, f] = arr; console.log(d, e, f); 对象 // 对象结构 const persion = &amp;#123; name: \"zhangsan\", age: 12, language: ['java', 'js', 'python'] &amp;#125; // 对象结构 const &amp;#123; name: Name, // 当结构的key:value的值不一样的时候,使用冒号区分,当一样的时候, 冒号可以忽略 age, language &amp;#125; = persion; console.log(Name, age, language); /** * 运行结果: * zhangsan 12 (3) [\"java\", \"js\", \"python\"] */ 字符串扩展 // 字符串扩展 let str = \"hello world\" console.log(str.startsWith(\"hello\")); console.log(str.endsWith(\"world\")); console.log(str.includes(\"e\")); console.log(str.includes(\"hello\")); /** * 运行结果: * true * true * true * true */ 字符串模板 //字符串模板 let template = ` &lt;div > &lt;span > 我只是一个span &lt; /span> /div>` console.log(template) /** * 运行结果: * &lt;div > &lt;span > 我只是一个span &lt; /span> /div> */ 字符串插入变量和表达式,变量名写在${}中, ${} 中可以放入javaScript 表达式 //字符串插入变量和表达式,变量名写在$&amp;#123;&amp;#125;中, $&amp;#123;&amp;#125; 中可以放入javaScript 表达式 function fun() &amp;#123; return \"这是一个函数\"; &amp;#125; let info = `我是$&amp;#123;Name&amp;#125;,今年$&amp;#123;age&amp;#125;, 我想说:$&amp;#123;fun()&amp;#125;` console.log(info); /** * 运行结果: * 我是zhangsan,今年12, 我想说:这是一个函数 */ 全部示例 &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>结构表达式&lt;/title> &lt;/head> &lt;body> &lt;/body> &lt;script> //数组结构 let arr = [1, 2, 3]; let a = arr[0]; let b = arr[1]; let c = arr[2]; console.log(a, b, b); let [d, e, f] = arr; console.log(d, e, f); /** * 运行结果: * 1 2 2 * 1 2 3 */ // 对象结构 const persion = &amp;#123; name: \"zhangsan\", age: 12, language: ['java', 'js', 'python'] &amp;#125; // 对象结构 const &amp;#123; name: Name, // 当结构的key:value的值不一样的时候,使用冒号区分,当一样的时候, 冒号可以忽略 age, language &amp;#125; = persion; console.log(Name, age, language); /** * 运行结果: * zhangsan 12 (3) [\"java\", \"js\", \"python\"] */ // 字符串扩展 let str = \"hello world\" console.log(str.startsWith(\"hello\")); console.log(str.endsWith(\"world\")); console.log(str.includes(\"e\")); console.log(str.includes(\"hello\")); /** * 运行结果: * true * true * true * true */ //字符串模板 let template = ` &lt;div > &lt;span > 我只是一个span &lt; /span> /div>` console.log(template) /** * 运行结果: * &lt;div > &lt;span > 我只是一个span &lt; /span> /div> */ //字符串插入变量和表达式,变量名写在$&amp;#123;&amp;#125;中, $&amp;#123;&amp;#125; 中可以放入javaScript 表达式 function fun() &amp;#123; return \"这是一个函数\"; &amp;#125; let info = `我是$&amp;#123;Name&amp;#125;,今年$&amp;#123;age&amp;#125;, 我想说:$&amp;#123;fun()&amp;#125;` console.log(info); /** * 运行结果: * 我是zhangsan,今年12, 我想说:这是一个函数 */ &lt;/script> &lt;/html> 3. 函数优化参数默认值// 在es6之前, 我们无法给一个函数参数设置默认值,只能采用通用的写法 function add(a, b) &amp;#123; // 判断B 是否为空,为空则给默认值 b = b || 1; return a + b; &amp;#125; // 传一个参数 console.log(add(1)); // 现在可以这么写,直接给参数上加上默认值,没传的话就自动使用默认值 function add2(a, b = 1) &amp;#123; return a + b; &amp;#125; console.log(add2(1)); 不定参数 //不定参 function test3(...values) &amp;#123; console.log(values.length); &amp;#125; test3(1, 2); test3(2, 3, 4) 箭头函数//箭头函数 //以前声明一个方法 var print = function(obj) &amp;#123; console.log(obj);; &amp;#125; //现在 var print2 = obj => console.log(obj); print2(\"hello\"); var sum = function(a, b) &amp;#123; c = a + b; return c; &amp;#125; var sum2 = (a, b) => a + b; console.log(sum2(1, 2)); var sum3 = (a, b) => &amp;#123; c = a + b; return c; &amp;#125; console.log(sum3(2, 3)); const person = &amp;#123; name: \"张三\", age: 12, language: ['java', 'js', 'css'] &amp;#125; function hello(person) &amp;#123; console.log('hello,' + person.name); &amp;#125; var hello2 = (&amp;#123; name &amp;#125;) => console.log(\"hello,\" + name); hello2(person); 全部页面 &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>&lt;/title> &lt;/head> &lt;body> &lt;/body> &lt;script> // 在es6之前, 我们无法给一个函数参数设置默认值,只能采用通用的写法 function add(a, b) &amp;#123; // 判断B 是否为空,为空则给默认值 b = b || 1; return a + b; &amp;#125; // 传一个参数 console.log(add(1)); // 现在可以这么写,直接给参数上加上默认值,没传的话就自动使用默认值 function add2(a, b = 1) &amp;#123; return a + b; &amp;#125; console.log(add2(1)); //不定参 function test3(...values) &amp;#123; console.log(values.length); &amp;#125; test3(1, 2); test3(2, 3, 4) //箭头函数 //以前声明一个方法 var print = function(obj) &amp;#123; console.log(obj);; &amp;#125; //现在 var print2 = obj => console.log(obj); print2(\"hello\"); var sum = function(a, b) &amp;#123; c = a + b; return c; &amp;#125; var sum2 = (a, b) => a + b; console.log(sum2(1, 2)); var sum3 = (a, b) => &amp;#123; c = a + b; return c; &amp;#125; console.log(sum3(2, 3)); const person = &amp;#123; name: \"张三\", age: 12, language: ['java', 'js', 'css'] &amp;#125; function hello(person) &amp;#123; console.log('hello,' + person.name); &amp;#125; var hello2 = (&amp;#123; name &amp;#125;) => console.log(\"hello,\" + name); hello2(person); &lt;/script> &lt;/html> 4. 对象优化方法优化,可以获取map的键值对等keys,values,entriesconst person = &amp;#123; name: \"张三\", age: 15, language: [\"java\", \"python\", \"css\"] &amp;#125; console.log(Object.keys(person)); //[\"name\", \"age\", \"language\"] console.log(Object.values(person)); //[\"jack\", 21, Array(3)] console.log(Object.entries(person)); //[Array(2), Array(2), Array(2)] 对象合并const target = &amp;#123; a: 1 &amp;#125; const source1 = &amp;#123; b: 2 &amp;#125; const source2 = &amp;#123; c: 3 &amp;#125; Object.assign(target, source1, source2); console.log(target); //&amp;#123;a: 1, b: 2, c: 3&amp;#125; 声明对象简写 // 2. 声明对象简写 const age = 23; const name = \"张三\" const person1 = &#123; age, name &#125;; //声明对象简写 console.log(person1); 对象的属性简写 // 对象的函数属性简写 let person3 = &amp;#123; name: \"张三\", age: 25, // 以前 eat: function(food) &amp;#123; console.log(this.name + \"再吃\" + food); &amp;#125;, //现在使用箭头函数, 箭头函数中 this不能使用, 对象.属性 eat2: food => console.log(person3.name + \"在吃\" + food), eat3(food) &amp;#123; console.log(person3.name + \"再吃\" + food); &amp;#125; &amp;#125; person3.eat(\"苹果\"); person3.eat2(\"香蕉\"); person3.eat3(\"橘子\"); 对象扩展运算符 对象拷贝(深拷贝) //(1) 拷贝对象(深拷贝) let p1 = &amp;#123; name: \"张三\", age: 13 &amp;#125; let someone = &amp;#123; ...p1 &amp;#125;; console.log(someone); // &amp;#123;name: \"张三\", age: 13&amp;#125; 合并对象 //(2)合并对象 let age1 = &amp;#123; age: 16 &amp;#125;; let name1 = &amp;#123; name: \"zhangsan\" &amp;#125; let p2 = &amp;#123; name: \"张三\" &amp;#125; // ...代表取出该对象的所有属性拷贝到当前对象中 p2 = &amp;#123; ...age1, ...name1 &amp;#125;; console.log(p2); // &amp;#123;age: 16, name: \"zhangsan\"&amp;#125; 5. map和reducemap map()：接收一个函数，将原数组中的所有元素用这个函数处理后放入新数组返回。// 数组中新增了map和reduce方法 // map(): 接受一个函数,将原数组中的所有元素用这个函数处理后放入新数组返回. let arr = [\"1\", \"2\", \"3\"]; let arr1 = arr.map((item) => &amp;#123; return item + 2; &amp;#125;); let arr2 = arr.map(item => item + 2); console.log(arr1); console.log(arr2); reduce 为数组中的每一个元素依次执行回调函数,不包含数组中被删除的元素或者从未被赋值的函数, arr.reduce(callback,[initialValue]); * 1. previousValue 上一次调用回调返回的值, 或者是提供的初始的值(initialValue) * 2. currentValue 数组中当前被处理的元素 * 3. idnex 当前元素在数组中的索引 * 4. array 调用 reduce的数组 //reduce() 为数组中的每一个元素依次执行回调函数,不包含数组中被删除的元素或者从未被赋值的函数 // [2,40,3,4] // arr.reduce(callback,[initialValue]); /** * 1. previousValue 上一次调用回调返回的值, 或者是提供的初始的值(initialValue) * 2. currentValue 数组中当前被处理的元素 * 3. idnex 当前元素在数组中的索引 * 4. array 调用 reduce的数组 */ let result = arr.reduce((a,b) => &amp;#123; console.log(\"上一次处理后:\" + a); console.log(\"当前正在处理:\" + b); return a + b; &amp;#125;, 100); console.log(result); 6. promise所谓Primise 就是一个对象,用来传递异步操作的消息,它代表了某个未来才会知道结果的事件(通常是一个异步操作), 并且这个事件提供了统一的API, 可供进一步处理. Promise 构造函数接受一个函数作为参数,该函数的两个参数分别为resolve 方法和reject 方法. 如果异步操作成功, 则用resolve 方法将Promise对象的状态, 从未完成 变成成功, 即从pending 变为resolved 如果异步操作失败,则用reject 方法将Promise 对象的状态从未完成 变成失败,即从pending 变为rejected 这里演示一个使用ajax 的复杂查询 先准备数据 user.json 用户 user_corse_1.json 课程 corse_score_10.json得分 以前的操作 // 1.查出当前的用户信息 // 2. 根据当前用户的id查询它的课程 // 3. 根据当前课程id查询分数 $.ajax(&amp;#123; url: \"mock/user.json\", success(data) &amp;#123; console.log(\"查询用户\", data); $.ajax(&amp;#123; url: `mock/user_corse_$&amp;#123;data.id&amp;#125;.json`, success(data) &amp;#123; console.log(\"查询到课程\", data); $.ajax(&amp;#123; url: `mock/corse_score_$&amp;#123;data.id&amp;#125;.json`, success(data) &amp;#123; console.log(\"查询到分数\", data); &amp;#125;, error(error) &amp;#123; console.log(\"查询分数出现异常\", error); &amp;#125; &amp;#125;); &amp;#125;, error(error) &amp;#123; console.log(\"查询课程出现异常\", error); &amp;#125; &amp;#125;); &amp;#125;, error(error) &amp;#123; console.log(\"出现异常了\", error); &amp;#125; &amp;#125;); 嵌套比较复杂 使用Promise //Promise可以封装异步操作 let p = new Promise((resolve, reject) => &amp;#123; //传入成功解析,失败则拒绝 // 1.异步操作 $.ajax(&amp;#123; url: \"mock/user.json\", success(data) &amp;#123; console.log(\"查询到用户:\", data); resolve(data); &amp;#125;, error(error) &amp;#123; reject(error); &amp;#125; &amp;#125;); &amp;#125;); //成功之后做什么 p.then((obj) => &amp;#123; return new Promise((resolve, reject) => &amp;#123; $.ajax(&amp;#123; url: `mock/user_corse_$&amp;#123;obj.id&amp;#125;.json`, success(data) &amp;#123; console.log(\"查询到用户课程:\", data); resolve(data); &amp;#125;, error(error) &amp;#123; reject(error); &amp;#125; &amp;#125;); &amp;#125;); &amp;#125;).then((obj) => &amp;#123; return new Promise((resolve, reject) => &amp;#123; $.ajax(&amp;#123; url: `mock/corse_score_$&amp;#123;obj.id&amp;#125;.json`, success(data) &amp;#123; console.log(\"查询到用户分数:\", data); resolve(data); &amp;#125;, error(error) &amp;#123; reject(error); &amp;#125; &amp;#125;); &amp;#125;); &amp;#125;) 还是有点复杂, 抽象一下方法 // 自己定义一个方法整合一下 function get(url, data) &amp;#123; return new Promise((resolve, reject) => &amp;#123; $.ajax(&amp;#123; url: url, data: data, success(data) &amp;#123; resolve(data); &amp;#125;, error(error) &amp;#123; reject(error); &amp;#125; &amp;#125;); &amp;#125;); &amp;#125; get(\"mock/user.json\") .then((data) => &amp;#123; console.log(\"查询到用户\", data); return get(`mock/user_corse_$&amp;#123;data.id&amp;#125;.json`); &amp;#125;).then((data) => &amp;#123; console.log(\"查询到课程\", data); return get(`mock/corse_score_$&amp;#123;data.id&amp;#125;.json`); &amp;#125;).then((data) => &amp;#123; console.log(\"查询到分数\", data); &amp;#125;).catch((error) => &amp;#123; console.log(\"出现异常\", error);; &amp;#125;); 7. 模块化模块化就是把代码进行拆分,方便重复使用，类似于java 中的导包,而js 只是换了个概念,是导模块 模块功能主要有两个命令组成, export 和import export:用于规定模块的对外接口 import:用于导入其他模块提供的功能 user.js var name = \"张三\" var age = 12 function add(a, b) &amp;#123; return a + b; &amp;#125; export &amp;#123; name, age, add &amp;#125; hello.js // export const util = &amp;#123; // sum(a, b) &amp;#123; // return a + b; // &amp;#125; // &amp;#125; export default &amp;#123; sum(a, b) &amp;#123; return a + b; &amp;#125; &amp;#125; // export &amp;#123;util&amp;#125; // export 不仅可以到处对象,一切js变量都可以导出, 比如基本类型变量, 函数、数组、对象 main.js import hello from \"./hello.js\" import &amp;#123; name, add &amp;#125; from \"./user.js\" hello.sum(1, 2); console.log(name); add(2, 3) 本笔记所演示代码: https://github.com/lyn-workspace/webNotes.git","categories":[{"name":"ES6","slug":"ES6","permalink":"https://rainsoil.github.io/categories/ES6/"},{"name":"前端","slug":"ES6/前端","permalink":"https://rainsoil.github.io/categories/ES6/%E5%89%8D%E7%AB%AF/"},{"name":"前端","slug":"ES6/前端/前端","permalink":"https://rainsoil.github.io/categories/ES6/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/"},{"name":"ES6","slug":"ES6/前端/前端/ES6","permalink":"https://rainsoil.github.io/categories/ES6/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/ES6/"}],"tags":[]},{"title":"序列化和反序列化","slug":"分布式/2. 分布式架构基础/序列化和反序列化","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/fen-bu-shi/2.fen-bu-shi-jia-gou-ji-chu/xu-lie-hua-he-fan-xu-lie-hua/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/fen-bu-shi/2.fen-bu-shi-jia-gou-ji-chu/xu-lie-hua-he-fan-xu-lie-hua/","excerpt":"","text":"序列化和反序列化Java领域中对象如何传输基于socket 进行对象传输User package com.notes.serial; /** * @author luyanan * @since 2019/9/2 * &lt;p>&lt;/p> **/ public class User &amp;#123; private String name; private Integer age; public User(String name, Integer age) &amp;#123; this.name = name; this.age = age; &amp;#125; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; public Integer getAge() &amp;#123; return age; &amp;#125; public void setAge(Integer age) &amp;#123; this.age = age; &amp;#125; @Override public String toString() &amp;#123; return \"User&amp;#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&amp;#125;'; &amp;#125; &amp;#125; SocketServerProvider package com.notes.serial; import java.io.IOException; import java.io.ObjectInputStream; import java.net.ServerSocket; import java.net.Socket; /** * @author luyanan * @since 2019/9/2 * &lt;p>socker Service&lt;/p> **/ public class SocketServerProvider &amp;#123; public static void main(String[] args) &amp;#123; ServerSocket serverSocket = null; ObjectInputStream ois = null; Socket socket = null; try &amp;#123; serverSocket = new ServerSocket(8080); socket = serverSocket.accept(); ois = new ObjectInputStream(socket.getInputStream()); User user = (User) ois.readObject(); System.out.println(user); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; try &amp;#123; serverSocket.close(); socket.close(); ois.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; SocketClientConsumer package com.notes.serial; import java.io.IOException; import java.io.ObjectOutputStream; import java.net.Socket; /** * @author luyanan * @since 2019/9/2 * &lt;p>&lt;/p> **/ public class SocketClientConsumer &amp;#123; public static void main(String[] args) &amp;#123; Socket socket = null; ObjectOutputStream oos = null; try &amp;#123; socket = new Socket(\"localhost\", 8080); oos = new ObjectOutputStream(socket.getOutputStream()); User user = new User(\"tom\", 18); oos.writeObject(user); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; try &amp;#123; socket.close(); oos.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 运行结果 java.io.NotSerializableException: com.notes.serial.User at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1184) at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348) at com.notes.serial.SocketClientConsumer.main(SocketClientConsumer.java:21) 如何解决这个问题呢?对User对象实现一个Serializable 接口,再次运行就可以看到对象能够正常传输了 package com.notes.serial; import java.io.Serializable; /** * @author luyanan * @since 2019/9/2 * &lt;p>&lt;/p> **/ public class User implements Serializable &amp;#123; private static final long serialVersionUID = 2771514728172982823L; private String name; private Integer age; public User(String name, Integer age) &amp;#123; this.name = name; this.age = age; &amp;#125; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; public Integer getAge() &amp;#123; return age; &amp;#125; public void setAge(Integer age) &amp;#123; this.age = age; &amp;#125; @Override public String toString() &amp;#123; return \"User&amp;#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&amp;#125;'; &amp;#125; &amp;#125; 运行结果 User&amp;#123;name='tom', age=18&amp;#125; 了解序列化的意义我们发现User这个类增加一个Serializable ,就可以解决java对象的网络传输问题,这就是今天给大家讲解序列化这块的意义. java平台允许我们在内存中创建可复用的java对象.但一般情况下,只有当JVM处于运行时，这些对象才可能存在. 即这些对象的生命周期不会比JVM的生命周期更长. 但是在现实应用中,就可能要求在JVM停止运行之后能够保存(持久化)指定的对象.并在将来重新读取被保存的对象.Java对象序列化就能够帮助我们实现该功能. 简单来说: 序列化就是把对象的状态信息转化为可存储或者传输的形式过程,也就是把对象转换为字节序列化的过程称为对象的序列化. 反序列化是序列化的逆向过程, 把字节数组反序列化为对象,把字节序列恢复为对象的过程称为对象的反序列化. 序列化的高阶认识简单认识一下java原生序列化前面的代码中演示了,如何通过JDK提供了java 对象的序列化方式实现对象序列化传输, 主要通过输出流ObjectOutputStream和对象输入流 ObjectInputStream来实现. ObjectOutputStream: 表示对象输出流, 他的 writeObject(Object obj) 方法可以对参数指定的obj对象进行序列化,把得到的字节序列写到一个目标输出流中. ObjectInputStream: 表示对象输入流, 它的 readObject() 方法从输入流中读取字节序列, 再把他们反序列化称为一个对象, 并将其返回. 需要注意的是, 被序列化的对象需要实现 Serializable 接口., 序列化的高级认识serialVersionUID 的作用 在IDEA中通过如下设置可以生成 serialVersionUID 字面意思是序列化的版本号, 凡是实现Serializable 接口的类 都有一个表示序列化版本标识符的静态变量 演示步骤: 先将user 对象序列化到文件中 然后修改user对象,增加 serialVersionUID 字段 然后通过反序列化来把对象提取出来 演示结果: 提示无法反序列化 结论:java的序列化机制是通过判断类的 serialVersionUID 来验证版本一致的. 在进行反序列化时，JVM会把传来的字节流中的 serialVersionUID 于本地相应实体类的 serialVersionUID 进行比较,如果相同就认为是一致的. 可以进行反序列化. 否则就会出现序列化版本不一致的异常. 即是 InvalidCastException 从结果可以看出, 文件流中的class 和classpath 中的class ,也就是修改过后的 class, 不兼容了,处于安全机制考虑,程序抛出了错误,并且拒绝载入, 从错误结果来看, 如果没有为指定的class 配置serialVersionUID , 那么java 编译器会自动给这个class 进行一个摘要算法,类似于一个指纹算法,只要这个文件有任何改动, 得到的UID 就会截然不同， 可以保证在这么多类中, 这个编号是唯一的. 所以,由于没有显式的指定 serialVersionUID , 编译器又为我们生成了一个UID， 当然和前面保存在文件中的那个会不一样了, 于是就出现了2个序列化版本号不一致的算法. 因此, 只要我们自己指定了 serialVersionUID ,就可以在序列化后,去添加一个字段, 或者方法,而不会影响到后期的还原, 还原后的对象照样可以使用, 而且还多了方法或者属性可以用. tips: serialVersionUID 有两种显示的生成方式. 一种是默认的1L,比如 private static final long serialVersionUID = 1L; 二是根据类名,接口名、成员方法以及属性等来生成一个64位的哈希字段 当实现 Serializable 接口的类没有显式的定义一个 serialVersionUID 变量的时候, java序列化机制会根据编译器的Class自动的生成一个 serialVersionUID 作为序列化版本使用, 这种情况下，如果Class文件(类名、方法名)没有发生变化(增加空格、换行、增加注释等等),就算再编译多次,serialVersionUID 也不会发生变化的. Transient 关键字Transient 关键字的作用是控制变量的序列化, 在变量声明前加上该关键字, 可以阻止该变量被序列化到文件中, 在反序列化后, Transient 变量的值被设置为初始值, 如Int 类型的值是0,对象型的是null. 绕开Transient 机制的办法虽然字段被Transient 修饰,但是可以通过重写 writeObject 和readObject 方法仍然使得 字段正确的被序列化和反序列化。 package com.notes.serial; import java.io.IOException; import java.io.Serializable; /** * @author luyanan * @since 2019/9/2 * &lt;p>&lt;/p> **/ public class User implements Serializable &amp;#123; private static final long serialVersionUID = 2771514728172982823L; private transient String name; private Integer age; public User(String name, Integer age) &amp;#123; this.name = name; this.age = age; &amp;#125; public String getName() &amp;#123; return name; &amp;#125; public void setName(String name) &amp;#123; this.name = name; &amp;#125; public Integer getAge() &amp;#123; return age; &amp;#125; public void setAge(Integer age) &amp;#123; this.age = age; &amp;#125; @Override public String toString() &amp;#123; return \"User&amp;#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&amp;#125;'; &amp;#125; private void writeObject(java.io.ObjectOutputStream s) throws IOException &amp;#123; s.defaultWriteObject(); s.writeObject(name); &amp;#125; private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &amp;#123; s.defaultReadObject(); name = (String) s.readObject(); &amp;#125; &amp;#125; writeObject 和readObject 原理writeObject 和readObject 是两个私有方法， 他们是什么时候被调用的呢? 从运行结果上看,它确实被调用， 而且他们并不存在于Object,也没有在Serializable 中去声明, 我们唯一的猜想应该还是和ObjectInputStream和ObjectOutputStream 有关系, 所以 基于这个入口去看看在哪个地方调用. void invokeReadObject(Object obj, ObjectInputStream in) throws ClassNotFoundException, IOException, UnsupportedOperationException &amp;#123; requireInitialized(); if (readObjectMethod != null) &amp;#123; try &amp;#123; readObjectMethod.invoke(obj, new Object[]&amp;#123; in &amp;#125;); &amp;#125; catch (InvocationTargetException ex) &amp;#123; Throwable th = ex.getTargetException(); if (th instanceof ClassNotFoundException) &amp;#123; throw (ClassNotFoundException) th; &amp;#125; else if (th instanceof IOException) &amp;#123; throw (IOException) th; &amp;#125; else &amp;#123; throwMiscException(th); &amp;#125; &amp;#125; catch (IllegalAccessException ex) &amp;#123; // should not occur, as access checks have been suppressed throw new InternalError(ex); &amp;#125; &amp;#125; else &amp;#123; throw new UnsupportedOperationException(); &amp;#125; &amp;#125; 从源码的层面来可以分析到, readObject 是通过反射调用的., 其实我们在很多地方可以看到 readObject 和writeObject 的调用，比如HashMap . Java序列化的一些简单总结 Java 序列化只是针对对象的状态进行保存,至于对象里的方法, 序列化不关心 当一个父类实现了序列化， 那么子类会自动实现序列化,不需要显示实现序列化接口. 当一个对象的实例变量引用了其他对象,序列化和这个对象的时候会自动把引入的对象也进行序列化(实现深度克隆) 当某个字段被声明为 transient 后,默认的序列化机制会忽略这个字段. 被申明为 transient 的字段,如果需要被序列化，可以添加两个私有方法 readObject 和writeObject 分布式架构下的常见的序列化技术初步了解了java序列化的知识以后,我们又回到了分布式架构中,了解序列化的发展过程. 了解序列化的发展随着分布式架构、微服务架构的普及,服务于服务之间的通信成了最基本的需求. 这个时候, 我们不仅需要考虑通信的性能, 也需要考虑到语言多元化的问题. 所以,对于序列化来说,如何去提升序列化性能以及解决跨语言问题,就成了一个重点考虑的问题. 由于java本身提供的序列化机制存在两个问题: 序列化的数据比较大, 传输效率低 其他语言无法识别和对接. 以至于在后来的很长一段时间, 基于XML 格式编码的对象序列化机制成为主流, 一方面解决了多语言兼容的问题,另一方面比二进制序列化的方式更容易理解. 以至于基于XML的SOAP协议以及对应的WebService 框架在很长一段时间内成为各个主流开发语言的必备的技术. 再到后来, 基于SJON的简单文本格式编码的HTTP REST 接口又基本取代了复杂的Web Service接口, 成为分布式架构中远程通信的首要选择. 但是,JSON 序列化存储占用的空间大,性能低的问题, 同时移动客户端应用需要更高效的传输数据来提升用户体验. 在这种情况下于语言无关并且高效的二进制编码协议就成了大家追求的热点技术之一, 首先诞生的一个开源的二进制序列化框架-MessagePack. 他比google的Protocol Buffers 出现的还早. 简单了解各种序列化技术XML 序列化框架介绍XML序列化的好处在于可读性好,方便阅读和调试, 但是序列化后的字节码文件比较大, 而且效率不高, 适用于对性能不高,而且QPS 较低的企业级内部系统之间的数据交换的场景, 同时XML 又具有语言无关性,所以还可以用于异构系统之间的数据交换和协议, 比如我们熟知的WebService,就是采用XML格式对数据进行序列化. XML 序列化/反序列化的实现方式有很多, 熟知的方式有XStream 和java自带的XML序列化和反序列化两种. JSON序列化框架JSON(JavaScript Object Notaion) 是一种轻量级的数据交换格式, 相对于XML来说, JSON 的字节流更小, 而且可读性也非常好. 现在的JSON数据格式在企业中运行是最普遍的. jackson （https://github.com/FasterXML/jackson） 阿里开源的FastJson （https://github.com/alibaba/fastjon） Google 的GSON (https://github.com/google/gson) 这几种json序列化工具中, jackson 和fastjson 要比GSON的性能要好,但是 jackson、GSON 的稳定性要比Fastjson 好, 而fastjson 的优势在于提供的api 非常容易使用. Hessian 序列化框架Hessian 是一个支持跨语言传输的二进制序列化协议, 相对于java默认的 序列化机制来说,Hessian 具有更好的性能和易用性, 而且支持多种不同的语言。 实际上Dubbo 采用的就是Hessian序列化来实现, 只不过Dubbo 对Hessian 进行了重构, 性能更高. Avro 序列化Avro是一个数据序列化系统, 设计用于支持大批量数据交换的应用.它的主要特点有: 支持二进制序列化方式,可以便携,快速的处理大量数据,动态语言友好,Avro提供的机制使动态语言可以方便的处理Avro数据. Kyro序列化框架Kyro 是一种非常成熟的序列化实现, 已经在Hive、Storm 中使用的比较广泛, 不过他不能跨语言, 目前dubbo 已经在2.6 版本支持了 kyro 的序列化机制, 它的性能要优于之前的hessian2 Protobuf 序列化框架Protobuf是Google 的一种数据交换格式, 它独立于语言,独立于平台.Google 提供了多种语言来实现, 比如Java、C、Go、Python,每一种实现都包含了相应语言的编译器和库文件, Protobuf 是一个纯粹的表示层协议, 可以和各种传输层协议一起使用. Protobuf 使用比较广泛, 主要是内存开销小,和性能比较好, 非常适用于公司内部对性能要求高的RPC调用,. 另外由于解析比较高, 序列化以后数据量相对较少, 所以也可以应用在对象的持久化场景中. 但是要使用 Protobuf 会相对来说比较麻烦, 因为它有自己的语法, 有自己的编译器, 如果需要用到的话必须投入到成本在这个技术的学习中. Protobuf 有个缺点就是要传输的每一个类的结构都要生成对应的proto 文件, 如果某个类发生修改, 还得重新生成该类对应的proto 文件。 Protobuf 序列化原理使用Protobuf 开发的一般步骤是: 配置开发环境, 按照 Protobuf compiler 代码编译器 编写.proto 文件, 定义序列化对象的数据结构. 基于编写的 .proto 文件,使用 Protobuf compiler 编译器生成对应的序列化/反序列化工具类 基于自动生成的代码, 编写自己的序列化应用. Protobuf 案例演示下载 Protobuf 工具 https://github.com/google/protobuf/releases 找到 protoc-3.5.1-win32.zip 编写proto文件 syntax = \"proto2\"; package com.notes.serial; option java_package = \"com.notes.serial\"; option java_outer_classname = \"UserProtos\"; message User&amp;#123; required string name = 1; required int32 age = 2; &amp;#125; 数据类型 string/bytes/bool/int32(4个字节)/int64/float/double enum 枚举类 message 自定义类 修饰符: required 表示必填的字段 optional 表示可选字段 repeated 可重复 表示集合 1,2,3,4 需要在当前范围内是唯一的, 表示顺序 生成实体类解压文件,到bin目录下 ,执行 ./protoc.exe –java_out ./ ./user.proto 会生成一个UserProtos的文件 实现序列化 项目导入 &lt;dependency> &lt;groupId>com.google.protobuf&lt;/groupId> &lt;artifactId>protobuf-java&lt;/artifactId> &lt;version>3.9.1&lt;/version> &lt;/dependency> public static void main(String[] args) &amp;#123; UserProtos.User user = UserProtos.User.newBuilder().setAge(300).setName(\"TOM\").build(); byte[] bytes = user.toByteArray(); for (byte aByte : bytes) &amp;#123; System.out.print(aByte+\" \"); &amp;#125; System.out.println(\"\\n\"); try &amp;#123; UserProtos.User parse = UserProtos.User.parseFrom(bytes); System.out.println(parse); &amp;#125; catch (InvalidProtocolBufferException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; 运行结果 10 3 84 79 77 16 -84 2 name: \"TOM\" age: 18 序列化出来的结果为 10 3 84 79 77 16 -84 2, 序列化出来的数字基本看不懂, 但是序列化之后的数据缺失小了, 那我们接下来带大家去了解一下底层的原理 正常来说, 要达到最小的序列化结果,一定会用到压缩的技术, 而 protobuf 里面用到了两种压缩 算法, 一种是 varint, 一种是 zigzag. varint先说第一种, 我们先来看 age = 300 这个数字是如何被压缩的. 这两个字节分别的结果是: -84、2 -84 怎么计算来的呢? 我们知道在二进制中表示负数的方法, 高位设置为1, 并且是对应数组的二进制取反以后再计算补码表示(补码是反码+1) 所以如果要反过来计算 [补码] 10101100 -1 得到 10101011 [反码] 01010100 得到的结果为84, 由于最高位是1, 表示负数, 所以为 -84 字符串如何编码呢?“TOM” 这个字符,需要根据ASCII对照表转换为数字 T = 84，O = 79, M = 77 所以结果为 84 79 77 大家肯定有一个疑问, 这里的结果为什么直接就是ASCII编码的值呢? 怎么没有做压缩呢? 原因是 varint是对字节码做压缩, 但是如果这个数字的二进制只需要一个字节表示的时候, 其实最终编码出来的结果是不会变化的. 还有两个数字，3 和16 表示什么呢? 这就要了解protobuf 的存储格式了 存储格式protobuf 采用T-L-V 作为存储格式 tag的计算方式是 field_number(当前字段的编号) &lt;&lt;3|wire_type 比如 TOM 的字段编号是1,类型 wire_type 的值为2, 所以 1 &lt;&lt; 3 |2 = 10 age = 300 的字段编号是2, 类型 wire_type 的值为0, 所以 2 &lt;&lt;3 | 0 = 16 第一个数字10,代表的是key,剩下的为value 负数的存储(zigzag)在计算机中, 负数会被表示为很大的整数, 因为计算机定义负数符号位为数字的最高位, 所以如果采用 varint 编码表示一个负数, 那么一定需要5个比特位, 所以在 protobuf 中通过 sint32/sint64 类型表示负数, 负数的处理形式是先采用 zigzag 编码(把符号数转换为无符号数),再采用 varint 编码 sint32: ( n &lt;&lt; 1)^ (n &gt;&gt;31) sint64: (n &lt;&lt; 1) ^ (n&gt;&gt; 63) 比如要存储一个(-300)的值, -300 原码 : 0001 0010 1100 取反: 1110 1101 0011 加1 : 1110 1101 0100 n &lt;&lt;1: 整体左移1位, 右边补零 -&gt;1101 1010 1000 n &gt;&gt; 31 : 整体右移31位, 左边补1 -&gt; 1111 1111 1111 n &lt;&lt;1 ^ n &gt;&gt;31 1101 1010 1000 ^ 1111 1111 1111 = 0020 0202 0222 十进制 0010 0101 0111 = 599 varint 算法: 从右往左, 选取7位, 高位补 1/0 (取决于字节数) 得到两个字节 1101 0111 0000 0100 ​ -41 4 总结Protobuf Buffer 的性能好, 主要体现在 序列化后的数据体积小, 序列化速度快, 最终使得传输效率高, 其原因如下： 序列化速度快的原因 编码/解码 方式简单(只需要简单的数学运算 = 位移等等) 采用Protobuf Buffer 自身的框架代码和编译器 共同完成 序列化后的数据量体积小,(即数据压缩效果好) 的原因: 采用了独特的编码方式, 如 varint、 zigzag 编码方式等 采用 T - L - V的数据存储方式, 减少了分隔符的使用,使得数据存储的更加紧凑 序列化技术的选型技术层面 序列化空间开销, 也就是序列化产生的结果太小, 这个影响到传输的性能 序列化过程中消耗的时长, 序列化消耗时间过长影响到业务的响应时间 序列化协议是否支持跨平台、跨语言. 因为现在的架构更加灵活,如果存在异构系统通信需求,那么这个是必须要考虑的. 可扩展性、兼容性,在实际业务开发中,系统往往需要随着需求的迭代来实现快速更新,这就要求我们采用的序列化协议基于良好的可扩展性/兼容性, 比如在现在的序列化数据结构中新增一个业务字段, 不会影响到现在的服务. 技术的流行程序, 越流行的技术意味着使用的公司多,那么很多坑都已经淌过并且得到了解决,技术解决方案也相对成熟 学习难度和易用性 选型建议 对性能要求不高的场景,可以采用基于XML的SOAP协议 对性能和间接性有比较高要求的场景, 那么Hessian、Protobuf、Thrift、Avro都可以. 基于前后端分离, 或者独立的对外的API 服务, 选用JSON 是比较好的, 对于调试, 可读性都不错. Avro 设计理念偏于动态类型语言, 那么这类的场景使用Acro是可以的 各个序列化技术的性能比较这个地址有针对不同序列化技术进行性能比较：https://github.com/eishay/jvmserializers/wiki","categories":[{"name":"2. 分布式架构基础","slug":"2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"},{"name":"分布式","slug":"2-分布式架构基础/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式","slug":"2-分布式架构基础/分布式/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"2. 分布式架构基础","slug":"2-分布式架构基础/分布式/分布式/2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"Http 通信协议","slug":"分布式/2. 分布式架构基础/Http 通信协议","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/fen-bu-shi/2.fen-bu-shi-jia-gou-ji-chu/http-tong-xin-xie-yi/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/fen-bu-shi/2.fen-bu-shi-jia-gou-ji-chu/http-tong-xin-xie-yi/","excerpt":"","text":"Http 通信协议Http通信协议的基本原理http协议在远程通信场景中的应用还是挺广泛的,包括现在主流的微服务架构的通信都是基于http协议,. 由于经常使用的关系,所以大家对于http协议的理解还是比较深刻的,我这里就直接帮大家梳理一下http协议的基本原理 一次Http协议的基本请求我们先来思考一个问题,我们在浏览器输入一个网址后,浏览器是如何展示目标网址中的内容的? 内容是从哪里来的? 来通过图形来把这个过程画一下 DNS:（Domain Name System） 服务是和http协议一样处于应用层的协议. 它提供域名到IP地址的解析服务,用户通常使用主机名或者域名来访问对方的计算机，而不是直接通过IP地址访问. 因为与IP地址的一组数字相比,用字母配合数字的表示形式来指定计算机名更符合人类的习惯, 但是要让计算机去理解名称，相对而言就比较困难了. 因为计算机擅长处理一长串数字,为了解决上述的问题,DNS服务应运而生.DNS协议提供通过域名查找IP服务,或逆向从ip查找域名的行为. Http 通信协议的组成.刚刚我们已经得知Http协议的工作过程,同时我们也应该知道HTTP协议是基于应用层的协议,并且在传输层使用的TCP的k可靠性通信协议, 既然是协议,那么就已应该符合协议的定义: 协议是两个需要网络通讯的程序达成的一种约定,它规定了报文的交换方式和包含的意义. 所以,接下来我们去深入的剖析HTTP协议的组成和原理. 请求URL 定位资源我们在浏览器输入一个地址,浏览器是如何根据地址去找到服务器对应的资源并返回的? 以及这个地址包含了哪些有价值的i信息? 这就需要我们了解URL(Uniform Resource Locator) , 统一资源定位符,用于描述一个网络上的资源,具体格式如下: URI用字符串标识某一互联网资源,而URL标识资源的地点(互联网所处的位置),可见URL是URI的子集。 https://www.baidu.com/s?ie=utf-8&amp;f=8#head schema://host[:port#]/path/…/?[url-params]#[query-string] schema 指定应用层使用的协议(例如http,https/ftp) host HTTP服务器的ip地址或者域名 port# HTTP服务器的默认的端口号是80,这种情况下端口号可以省略,如果使用了别的端口号,必须指定端口号，例如 http://csdn:8080/ path 访问资源的路径 url-params 查询字符串 query-string 片段标识符(使用片段标识符通常可标记已获取资源中的子资源(文档中的某个位置)) 通过这个url地址,我们就可以读到,当前用户要使用http协议访问指定服务器上对应进程中的资源, 并且携带了请求参数。 MIME TYPE服务器根据用户请求的资源找到对应的文件以后,会返回一个资源给到客户端浏览器,浏览器会对这个资源解析并且渲染. 但是服务器上的资源类型有很多,比如图片类型,视频类型,JS、CSS、文本等. 浏览器是如何识别当前类型做不同的渲染的呢?MIME Type: 是描述消息内容类型的因特网标准,常见的几种类型: 文本文件: text/html,text/plain,text/css,application/xhtml+xml,application/xml 图片文件: image/jpeg,image/gif,image/png. 视频文件: video/mpeg,video/quicktime 我们可以通过两种方式来设置文件的渲染类型,第一种是Accept, 第二种是Content-type Accept: 表示客户端希望接受的数据类型,即告诉服务器我需要什么媒体类型的数据,此时服务器应该根据Accept 请求头生产指定媒体类型的数据. Content-type: 表示发送端发送的实体数据类型,比如我们应该写过类似的: resposne.setContentType(“application/json;charset=utf-8”)的代码.表示服务器返回的数据格式是json 如果Accept 和 Content-type 不一致, 假如说 Accept 要接受的类型是 image/gif, dan是服务器端返回的数据是text/html,那么浏览器将会无法解析。 如果用户访问一个不存在的地址呢?如果用户访问的地址没问题, 或者服务器也能正常解析以及处理当前用户的请求, 那就能返回正确的信息给到客户端. 但是如果用户访问的地址有问题, 或者服务端在解析用户请求以及处理请求逻辑时出现问题,怎么办呢? 浏览器应该怎么告诉用户当前是怎么处理失败的呢? 因为这里就设计到了一个状态码的概念 类别 原因短语 1XX informational(信息性状态码) 接受的请求正在处理 2XX Success(成功状态码) 请求正常处理完毕 3XX Redirection(重定向状态吗) 需要进行附加操作以完成请求 4XX Client Error(客户端错误状态码) 服务器无法处理请求 5XX Server Error(服务器端错误状态码) 服务器处理请求出错 大家见的比较多的错误码: 200: 一切正常 301: 永久重定向 404: 请求资源不存在 500: 服务器内部错误 有了状态码,在用户访问某个网站出现非正常状态时, 浏览器就可以友好的提示用户. 告诉服务器端当前请求的意图有了url、mimetype、状态码 能够基本满足用户的需求. 但是, 很多时候一个网站不单纯只是不断的从服务端获取资源并做渲染, 可能还需要做一个数据的提交、删除等功能. 所以浏览器定义了8中方法来表示对于不同请求的操作方式,当然最常用的还是GET 和POST GETGET 一般是用户客户端发送一个URL地址去获取服务器资源(一般用于查询操作),Get不支持的传输数据有限制,具体限制由浏览器决定 POST一般用于客户端传输一个实体给服务器端,让服务带你去保存(一般用户创建操作), PUT向服务器发送数据,一般用户更新数据操作 DELETE客户端发起一个Delete请求 要求服务端把某个数据删除(一般用于删除操作) HEAD获取报文首部 OPTIONS询问支持 的方法 TRACE追踪路径 CONNECT用隧道协议连接代理 在REST 架构风格中,由严格规定对于不同的请求类型要设置合适的请求方式, 也是避免出现乱用导致的混乱问题. 这里说一下为什么要定义REST这个架构风格 我个人认为是这样的: 随着服务化的普及,http协议的使用频次越来越高. 很多人在错误的使用 http协议定义接口, 比如 各种各样的命名, 什么getUserInfoById\\deleteById 之类的, 有状态和无状态请求混用. 对于http协议本身提供的规则并没有很好的利用, 所以, 为了更好的解决这些问题, 干脆就定义了一套规则, 这套规则并没有引入新的东西, 无非就是对http协议本身的使用做了一些约束,比如说: REST 是面向资源的, 每一个URI 代表一个资源 强调无状态化, 服务器端不能存储来自某个客户的某个请求中的信息, 并在该客户的其他请求中使用. 强调URL 暴露资源时,不要在URI中出现动词 合理的使用http状态码,请求方法. 因此大家在参照这种标准去使用REST 风格的时候,要明白你遵循的是什么以及要解决什么问题. http协议的完整组成ok,推演到这里,基本明白了一个http协议的基本组成,接下来简单总结一下, http协议包含两个报文, 一个是请求报文, 一个是响应报文. 请求报文请求报文格式包含三个部分(起始行,首部字段,主体) 响应报文响应的报文格式也是一样的, 分为三部分 HTTP协议中的扩展http协议除了这两种组成以外, 还由很多大家比较常见的属性或者配置, 我也简单的罗列一下 如果上传的文件过大怎么办?服务器返回的资源文件比较大,比如有些js文件大小可能就几兆. 文件过大可能就会影响传输的效率.同时也会带来带宽的消耗,怎么办呢? 常见的手段是 对文件进行压缩,减少文件大小. 那压缩或者解压缩的流程怎么实现呢? 首先服务器端需要能支持文件的压缩功能,其次浏览器能够针对被压缩的文件及逆行解压缩. 浏览器可以指定 Accept-Encoding 来告诉服务器我当前支持的编码类型.Accept-Encoding:gzip,deflate . 那服务器端会根据支持的编码类型,选择合适的类型进行压缩, 常见的编码方式由: gzip/deflate 分割传输 在传输大容量数据的时候,通过把数据分割多块,能够让浏览器逐步显示页面, 这种把实体主体分块的功能成为 分块传输编码(Chunked Transfer Coding) 每次请求都要建立连接吗?在最早的http协议中,每进行一次http通信,就需要做一次http通信. 而一次连接需要进行三次握手,这种通信方式会增加通信量的开销. 所以在http /1.1中改用了持久连接, 就是在一个连接建立之后,只要客户端或者服务端没有明确断开连接,那么这个tcp连接会一直保持连接状态. 持久连接的一个最大的好处是: 大大减少了连接的建立以及关闭时延. HTTP 1.1 中有一个Transport 段 会携带一个 Connection: Keep-Alive ,表示希望将此条连接作为持久连接. HTTP 1.1 持久连接在默认情况下是激活的,除非特别指明,否则HTTP 1.1 假定所有的连接都是持久的,要在事务处理结束后将连接关闭,HTTP 1.1 应用程序必须向报文中显示的添加一个Connection: close 首部. HTTP 1.1 客户端 在收到响应后, 除非响应中包含了Conection: close 首部, 不然HTTP 1.1 连接就仍然维持在打开的状态,但是,客户端和服务器仍然可以随时关闭空闲的连接. 不发送Connection:close 并不意味着服务器承诺永远将连接保持在打开的状态. 管道化连接: http1.1 允许在持久连接上使用请求管道,以前发送请求后需要等待并收到响应, 才能发送下一个请求. 管线化技术出现后, 不用等待响应也可以直接发送下一个请求,这样就能够做到同时并行发送多个请求, 而不需要一个接一个的等待响应了. HTTP协议的特点http 无状态协议HTTP 协议是无状态的, 什么是无状态呢? 就是说HTTP协议本身不会对请求和响应之间的通信状态做保存. 但是现在的应用都是由状态的,如果是无状态M那么这些应用基本没人用,你想想, 访问一个电商网站,先登陆,然后去选购商品, 当点击一个商品加入购物车以后又提示你登陆,这种用户体验根本不会有人去使用. 那么我们是怎么实现带状态的协议的呢? 客户端支持的Cookiehttp协议中引入了Cookie技术,用来解决http协议无状态的问题, 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态，Cookie 会根据从服务器发送的响应报文中 一个叫Set-Cookie的首部字段信息, 通知客户端保存Cookie. 当下次客户端再往该服务求发送请求时，客户端会自动在请求报文中加入Cookie值后发送出去. 服务端支持的Session服务端是通过什么方式来保存状态的呢? 在基于tomcat 这类的jsp/servlet 容器中,会提供Session 这样的机制来保存服务端的对象状态, 服务器会使用一种类似于散列表的结构来保存信息,当程序需要为某个客户端的请求创建一个session的时候,服务端首先先检查这个客户端的请求中是否包含了一个session标识 - session id 如果已经包含了一个session id 则说明以前已经为客户端创建过session, 服务器就按照session id 把session检索出来使用(如果检索不到,就新建一个)。 如果客户端请求不包含session id, 则为此客户端创建一个session 并且生成一个与此session 相关联的session id, session id的值是一个既不会重复,又不容易被找出规律的仿造字符串,这个session id 将会返回给客户端保存. Tomcat 实现session的代码逻辑分析我们以 HttpServletRequest# getSession() 作为切入点, 对Session的创建过程进行分析, 我们的应用程序拿到的HttpServletRequest 是org.apache.catalina.connector.RequestFacade(除非某些Filter 进行的特殊处理),它是 org.apache.catalina.connector.Request的门面模式. 首先,会判断Request 对象中是否存在Session, 如果存在并且未失效则直接返回. 如果不存在Session, 则尝试根据 requestdSessionId 查找Session,如果存在Session的话则直接返回, 如果不存在的话,则创建新的Session,并且把Sessionid 添加到Cookie 中, 后续的请求会携带该Cookid,这样便可以根据Cookie中的sessionId 找到原来创建的Session了 if (this.session != null &amp;&amp; context.getServletContext().getEffectiveSessionTrackingModes().contains(SessionTrackingMode.COOKIE)) &amp;#123; Cookie cookie = ApplicationSessionCookieConfig.createSessionCookie(context, this.session.getIdInternal(), this.isSecure()); this.response.addSessionCookieInternal(cookie); &amp;#125; HTTP 协议自动分析由于HTTP协议在通信过程中,是基于明文传输, 并且底层是基于TCP/IP 协议进行通信, 那么按照TCP/IP协议的工作机制,通信内容在所有的通信线路上都有可能遭到拦截和窃取. 窃取这个过程其实非常简单, 通过抓包工具 Wireshark 就可以截获请求和响应的内容. http安全传输由于HTTP协议通信的不安全性,所以人们为了防止信息在传输过程中操作泄露或者篡改, 就像出来对传输通道进行加密的方式 https https 是一种加密的超文本传输协议, 它与http 在协议差异在对数据传输的过程中,https 对数据做了完全加密. 由于 http协议或者https 协议都是处于tcp传输层之上,同时网络协议又是一个分层的结构,所以在tcp 协议层之上增加了 一层ssl(Secure Socket Layer ,安全层) 或者TLS(Transport Layer Security) 安全层传输协议组合使用 用于构造加密通道. SSL 是netscape 公司设计的(Secure socket layer ),后来互联网标准化组织ISOC接替了NetScapt 公司,发布了SSL的升级版TLS. 接着TLS的版本 又进行了多次升级, 实际上我们现在的HTTPS都是用的TLS协议, 但是由于SSL出现的时间较早,并且依旧被现在的浏览器支持,因此SSL依然是HTTPS的代名词 逆向推导https的设计过程我们先不去探究ssl的实现原理, 我们先从设计者的角度去思考如何去建立一个安全的传输通道. 从第一个消息开始客户端A 向服务端B 发送一条消息,这个消息可能会被拦截以及篡改, 我们如何做到A发送给B的数据包,即使被拦截了，也没办法得知消息内容并且也不能查看呢？ 利用对称加密要做到消息不能被第三方查看以及篡改, 那么第一想法就是对内容进行加密,同时, 该消息还需要能被服务端进行解密,. 所以我们可以使用对称加密算法来实现, 密钥S 扮演者加密和解密的角色.在密钥S 不公开的情况下,就可以保证安全性? 没那么简单在互联网世界,通信不会这么简单, 也许是这样 会存在多个客户端和服务端产生连接, 而这个客户端也许是一个潜伏着, 如果它也有对称密钥S,那相当于上面的方案是不可行的, 如果服务端和每个客户端通信的时候使用不同的加密算法呢? 似乎能够完美的解决问题, 然后? 密钥如何分配呢? 那就是服务端告诉客户端该使用哪种对称加密算法呢? 解决方法似乎只能通过建立会话以后进行协商了. 协商过程又是不安全的协商过程意味着又是基于一个网络传输的情况下去动态分配密钥,可是这个协商过程又是不安全的? 怎么破? 非对称加密出马非对称加密算法的特点是: 私钥加密后的密文, 只要有公钥, 都能解密, 但是公钥加密后的密文只有私钥可以解密, 私钥只有一个人有, 而公钥可以发给所有人. 这样就可以保证A/B 向服务器方向发送的消息是安全的, 似乎我们可以通过非对称加密算法解决了密钥的协商的问题,但是 公钥怎么拿?使用非对称加密,那么如何让A、B 客户端安全的持有公钥呢? 那么我们逐步思考, 有两种我们能想到的方案: 服务器端将公钥发送给每一个客户端 服务端将公钥放到一个远程服务器上,客户端可以请求到(多了一次请求,还得解决公钥的放置问题) 方案一似乎是不可行的, 因为传输过程又是不安全的, 公钥可能会被掉包 引入第三方机构到上面这一步,最关键的问题是客户端如何直到给我 公钥的是黄蓉还是小龙女? 只能找本人去证实, 或者有一个第三者来帮你证实,并且第三者是绝对公平的. 所以,引入一个可信任的第三者是最好的方案 服务端把需要传递给客户端的公钥,通过第三方机构提供的私钥对公钥内容进行加密后,再传递给客户端,.通过第三方机构私钥对服务器端公钥加密以后的内容, 就是一个简陋版本的 “数字证书”, 这个证书中包含了[服务器公钥] 客户端拿到这个证书后,因为证书是第三方机构使用私钥加密的, 客户端必须要有第三方机构提供的公钥才能解密证书.这块又涉及到第三方机构的公钥怎么传输? (假设是先内置在系统中)以及还有一个问题, 第三方机构颁发的证书是面向所有用户, 不会只针对一家发放, 如果不法分子也去申请一个证书呢? 如果不法分子也拿到证书?如果不法分子也申请了证书,那它就可以对证书进行调包. 客户端在这种情况下是无法分辨出收到的是你的证书还是中间人的, 因为不论是中间人的还是你的证书，都能使用第三方机构的公钥进行解密. 验证证书的有效性事情发展到现在,问题演变成了,客户端如何识别证书的真伪? 在现实生活中,要验证一个东西的真伪,绝大部分都是基于编号去验证的, 所以在这里 ,解决方案也是一样的,如果给这个证书添加一个证书编号,是不是就能达到目的呢? 证书上写了如何根据证书的内容生成证书编号. 客户端拿到证书后根据证书上的方法自己生成一个证书编号,如果生成的证书编号与证书上的证书编号相同,那么说明这个证书是真实的. 这块有点类似于md5的验证, 我们下载一个软件包,都会提供一个md5的值,我们可以拿到这个软件包以后通过一个第三方软件去生成一个md5值去做比较,是不是一样, 如果一样就表示这个软件包没有被篡改过. 对服务器端的数据进行MD5算法得到一个MD5的值,生成证书编号,使用第三方机构的私钥对这个证书编号进行加密,并且会在证书中添加证书编号的生成算法. 浏览器内置的CA公钥可以解密服务端CA私钥加密的证书,通过浏览器内置的CA证书的证书编号算法对服务端返回的证书编号进行验签. 第三方机构的公钥证书存在哪里?浏览器和操作系统都会维护一个权威的第三方机构列表(包括他们的公钥) 因为客户端接受到的证书中会有颁发机构,客户端会根据这个颁发机构的值在本地找到相应的公钥. 说到这里,我想大家一定知道了,证书就是HTTPS中的数字证书, 证书编号就是数字签名,而第三方机构就是数字证书的签发机构(CA) HTTPS 原理分析HTTPS证书的申请过程 服务器上生成的CSR文件(证书申请文件,内容包括证书公钥、使用的HASH签名算法、申请的域名、公司名称、职位等) 把CSR文件和其他可能的证书上传到CA认证机构, CA机构收到证书申请后使用申请中的HASH算法,对部分内容进行摘要,然后使用CA 机构自己的私钥对这段摘要进行签名(相当于证书的唯一编号) 然后CA机构把签名过的证书通过邮件形式发送到申请者手中 申请者收到证书后部署到自己的web服务器上 客户端请求交互流程 客户端发起i请求(Client Hello包) 三次握手,建立TCP连接 支持的协议版本(TLS/SSL) 客户端生成的随机数 client.random,后续用于生成 “对话密钥” 客户端支持的加密算法 sessionId, 用于保持同一个会话(如果客户端与服务器端费尽周折建立了一个HTTPS连接,刚建完就断了,太可惜了) 服务端收到请求,然后响应(Server Hello) 确认加密通道协议版本 服务端生成的随机数 server.random ,后续用于生成”对话密钥” 确认使用的加密算法(用于后续的握手消息进行签名防止篡改) 服务器证书(CA机构颁发给服务器端的证书) 客户端收到证书进行验证 验证证书是否是上级CA 签发的，在验证证书的时候,浏览器会调用系统的证书管理器接口对证书路径中的所有证书进行一级一级的验证, 只有路径i中的所有证书是受信任的,这个验证的结果才是可信的. 服务端返回的证书中会包含证书的有效期,可以通过失效日期来验证证书是否过期 验证证书是否被吊销了 前面我们知道CA机构在签发证书的时候,都会使用自己的私钥对证书进行前面, 证书里面的签名算法字段 sha256RSA 表示CA机构使用sha256 对证书进行摘要,然后使用RSA算法对进行私钥签名, 而我们也知道RSA算法中, 使用私钥签名后,只有公钥才能进行验签. 浏览器内置在操作系统上的CA机构的公钥对服务器的证书进行验签, 确定这个证书是不是由正规机构签发的, 验证之后得到CA 机构使用sha256 进行证书摘要, 然后客户端再使用sha256 对证书内容进行一次摘要, 如果得到的值和服务区端返回的证书验签之后的摘要相同， 表示证书没有被修改过 验证通过后, 就会显示绿色的安全字样 客户端生成随机数, 验证通过后,客户端会生成一个随机数 pre-master secret ,客户端根据之前的 Client.random + server.random + pre-master 生成对称密钥然后使用证书中的公钥进行加密,同时利用前面协商好的HASH算法,把握手消息取HASH值, 然后用随机数加密”握手消息+握手消息、Hash值(签名)”,并一起发送给服务端(在这里之所以要取握手消息的HASH值,主要是把握手消息的HASH值做一个签名,用于验证握手消息在传输过程中没有被篡改过) 服务端接受随机数 服务端收到客户端的加密数据以后, 用自己的私钥对密文进行解密,然后得到 client.random/server.random/pre-master secret,Hash值,并与传过来的HASH值做对比确认是否一致. 然后用随机密码加密一段握手消息(握手消息+握手消息的HASH值)给客户端 客户端接受消息 客户端用随机数解析并计算握手消息的HASH值,如果与服务端发来的HASH一致.此时握手过程结束. 之后所有的通信数据将由之前交互过程中产生的 pre-master secret/client.random/server.random 通过算法得到session key,作为后续交互过程中的对称密钥 https 应用实战接下来,为来让大家更好的理解https的原理, 我们基于Nginx 配置一个https的证书., 在生产环境中的SSL证书都是需要通过第三方认证机构购买的, 分为专业版OV证书(浏览器地址栏上不显示企业名称)和高级版EV(可以显示企业名称)证书, 证书所保护的域名数不同也会影响价格(比如只对www认证和通配*认证,价格是不一样的),且不支持三级域名. 代表证书过期或者无效.,如果是黄色的话代表网站有部分连接使用的仍然是http协议.如果大家自己买了域名的话,可以在阿里云上申请一个免费的证书来使用 我们为了演示证书的申请过程,直接使用openssl, 自己作为证书颁发机构来制作证书， 但是这个证书是不受信任的.,所以到时候演示的结果浏览器上会提示证书不受信任的错误. 证书的申请过程生成服务器证书的申请文件和私钥文件在nginx的 conf 目录下创建 cert 文件夹, 在该文件夹下生成公私钥 openssl req -nodes -newkey rsa:2048 -out myreq.csr -keyout privatekey.key req: 表示发出一个申请数字证书的请求 rsa:2048 表示加密算法以及长度 out : 输出一个请求文件 keyout: 生成私钥 myreq.csr: 证书签名请求, 这个并不是一个证书, 而是向权威机构获取签名证书的申请，它是主要内容是一个公钥. privatekey.key : 与公钥相匹配的私钥. CSR(证书请求文件),用来向CA机构申请的文件,一般以CSR结尾， 包含申请证书所需要的相关信息,其中最重要的是域名, 添加的域名必须是你要https 方式访问的那个域名. 一个是KEY文件,这个文件一定要保存好,这个文件就是对应server端的私钥, 如果key文件没有保存好, 是无法找回的, 因为key生成的过程是不可逆的, 即使添加的过程都是一样的, 生成的KEY 是不同的, 具有随机性. 模拟CA机构制作CA 机构证书CA机构由自己的公私钥, CA会使用自己的公私钥对证书申请者提交的公钥进行加密, 所以为了模拟CA机构的工作流程,首先要创建一个CA的证书 openssl的配置文件 /etc/pki/tls/openssl.conf 以下是 openssl CA的默认配置, 我们需要配置CA的证书,就需要在指定的目录下创建相应的文件 创建所需要的文件 touch /etc/pki/CA/index.txt 生成证书索引数据库文件 echo 01 &gt; /etc/pki/CA/serial 指定第一个颁发证书的序列号, 必须是两位十六进制数, 99之后是9A ​ CA 自签证书- 生成私钥 cd /etc/pki/CA openssl genrsa -out /etc/pki/CA/private/cakey.pem 20148 生成自签名证书 openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 365 -out /etc/pki/CA/cacert.pem 颁发证书 openssl ca -policy policy_anything -in myreq.csr -out mycert.crt -days 3654 policy policy_anything policy 参数允许签名的CA 和网站证书可以有不同的国家、地名等信息 out : ca颁发的证书文件 days: 证书有效期 ​ nginx 配置https在nginx.conf 中配置 server段， 将证书 mycert.pem 和私钥 pem 添加到指定文件中 server &#123; listen 443 ssl; ssl on; ssl_certificate cert/mycert.crt; ssl_certificate_key cert/privatekey.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125; &#125; 小tips为什么证书一下子是以pem 结尾,一下又是以crt 结尾,一下又是key结尾 到底是什么意思？ 其实,x509标准的证书,有两种编码格式, 一种的PEM，一种是 DER 但是实际上我们呢在创建证书和私钥的时候,并不一定要以PEM或者DER 作为扩展名, 比如证书的表示形式有: PEM、DER、CRT、CER 私钥或者公钥的表示形式: PEM、DER、KEY 只是对应的编码格式不同而已.","categories":[{"name":"2. 分布式架构基础","slug":"2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"},{"name":"分布式","slug":"2-分布式架构基础/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式","slug":"2-分布式架构基础/分布式/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"2. 分布式架构基础","slug":"2-分布式架构基础/分布式/分布式/2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"Linux环境下搭建VPS服务","slug":"vpn/Linux环境下搭建VPS服务","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/vpn/linux-huan-jing-xia-da-jian-vps-fu-wu/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/vpn/linux-huan-jing-xia-da-jian-vps-fu-wu/","excerpt":"","text":"linux 环境下搭建vps 服务 说明: 由于大部分的VPN被封,无意间接触到了VPS（Virtual Private Server 虚拟专用服务器，可用于FQ），所以简单记录下VPS服务搭建流程。 此教程基于centos7,使用阿里服务器(香港区域,可访问外网)进行搭建 1. 安装组件1.1 安装python 组件yum install m2crypto python-setuptools easy_install pip 1.2 配置参数 新建并编辑文件: vim /etc/shadowsocks.json 拷贝如下配置至文件末尾: &#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8388, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;password&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;:false, &quot;workers&quot;:1 &#125; 主要参数说明: server_port 表示开放VPS 服务端口,password 表示登录密码, 启动服务: 启动命令: ssserver -c /etc/shadowsocks.json 2. 链接VPS 去 https://github.com/shadowsocks 下载 shadowsocks的window客户端(https://github.com/shadowsocks/shadowsocks-windows/releases),将vps服务器ip,端口号,密码都填写成功就可以链接了 注意: 如果链接不上,查看端口是否开放 3.后台启动 由于以上启动方式为直接启动,关闭会话框窗户就会关闭服务,所以使用supervisor 实现后台运行 安装python工具 yum install python-setuptools 安装supervisor easy_install supervisor 创建配置文件 echo_supervisord_conf &gt;/etc/supervisord.conf 添加任务 vi /etc/supervisord.conf 拷贝如下配置至文件末尾: [program:ssserver]command = ssserver -c /etc/shadowsocks.json autostart=true autorestart=true startsecs=3 测试配置是否成功: supervisord -c /etc/supervisord.conf,再使用ps -ef | grep shadowsocks查看进程是否存在，如果进程存在则配置成功。 配置开机启动 vi /etc/rc.d/rc.local 在末尾行添加supervisord，此外centos7还需要配置文件权限：chmod +x /etc/rc.local，重启服务器即可自动运行。 PS","categories":[{"name":"vpn","slug":"vpn","permalink":"https://rainsoil.github.io/categories/vpn/"},{"name":"vpn","slug":"vpn/vpn","permalink":"https://rainsoil.github.io/categories/vpn/vpn/"}],"tags":[]},{"title":"window10 定时任务","slug":"window/window10 定时任务","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/window/window10-ding-shi-ren-wu/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/window/window10-ding-shi-ren-wu/","excerpt":"","text":"window10 定时任务首先，我们肯定是要用到Windows下的【计划任务】功能，如下图所示： 之后点击右侧的【创建基本任务】，输入任务名称以及可选的任务描述： 点击下一步，设置任务的开始时间，这个应该没什么难度，我这里设置为每天早上10点运行此计划任务： 点击下一步，设置【操作】为【启动程序】，再点击下一步，最关键的地方来了，这里该怎么填写才能保证系统正确地运行Python程序呢？ 废话不多说，先看具体的设置： 这里解释一下三个文本框内容的含义，【程序或脚本】文本框中填的是Python编译器的名称，一般就是python.exe，这里用的是pythonw.exe,这样就不会有IDE的弹窗出现，【起始于】文本框中填的是Python编译器的目录，上图中假设你的Python编译器的完整路径是“C:\\Python37\\python.exe”，【添加参数】文本框中填的是你的Python程序的完整路径，这里假设在C盘的Users文件夹下面有一个叫做code.py的文件。如果你的Python程序包含命令行参数，将其添加到Python程序的完整路径之后即可。 相信聪明的读者已经发现了，如果将这三部分连在一起，就是“C:\\Python37\\python.exe C:\\Users\\code.py”，这其实就是在Windows命令行下输入“python C:\\Users\\code.py”（或“python code.py”，如果你正好在C:\\Users目录下），只是在计划任务的设置中需要给出完整的python编译器的路径而已。","categories":[{"name":"window","slug":"window","permalink":"https://rainsoil.github.io/categories/window/"},{"name":"window","slug":"window/window","permalink":"https://rainsoil.github.io/categories/window/window/"}],"tags":[]},{"title":"任务调度之Quartz","slug":"任务调度/任务调度之Quartz","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/ren-wu-diao-du/ren-wu-diao-du-zhi-quartz/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/ren-wu-diao-du/ren-wu-diao-du-zhi-quartz/","excerpt":"","text":"任务调度之Quartz1. 漫谈任务调度1.1 什么时候需要任务调度1.1.1 任务调度的背景在业务系统中,有很多这样的场景: 账单日或者还款日上午10点, 给每个信用卡客户发送账单通知, 还款通知。 如何判断客户的账单日、还款日,完成通知的发送. 银行业务系统,夜间要完成跑批的一系列流程, 清理数据、下载文件、解析文件、对账清算、切换结算日期等, 如何触发一系列流程的执行? 金融机构跟人民银行二代支付系统对接, 人民银行要求小于5W的金额(小额支付)半小时打一次包发送, 以缓解并发压力. 所以, 银行的跨行转账分成了多个流程:录入、复核、发送. 如何把半个小时以内的数据一次性发送. 类似于这种: 基于准确的时刻或者固定的时间间隔发送的任务 有批量数据需要处理 要实现两个动作的解耦 这种场景, 我们都可以用任务调度来实现. 1.2 任务调度需求分析任务调度的实现方式有很多, 如果要实现我们的调度需求, 我们对这个工具有什么样的基本要求呢? 1.2.1 基本需求 可以定义触发的规则, 比如基于时刻、时间间隔、表达式 可以定义需要执行的任务, 比如执行一个脚本或者一段代码.任务或者规则是分开的. 集中管理配置, 持久配置. 不用把规则写在代码里面,可以看到所有的任务配置,方便维护. 重启之后任务还可以再次调度, 支持任务的串行执行, 例如执行A任务之后再执行任务B再执行任务C 支持多个任务并发执行, 互不干扰. 有自己的调度系统, 可以启动、中断、停止任务 容易集成到Spring中. 1.3 任务调度工具对比 层次 举例 特点 操作系统 linux crontabwindows计划任务 只能执行简单的脚本或者命令 数据库 Mysql、Oracle 可以操作数据, 但是不能执行代码 工具 Kettle 可以操作数据,执行脚本,没有集中配置 开发语言 JDK Timer、SchedultThreadPool Timer:单线程JDK1.5 之后：ScheduledThreadPool（Cache、Fiexed、 Single）:没有集中配置，日程管理不够灵活 容器 Spring Task、@Scheduled 不支持集群 分布式框架 xxl-job、Elastic-Job @Scheduled 也是用 JUC 的 ScheduledExecutorService 实现的 简单分析一下实现流程: org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor 的org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor#postProcessAfterInitialization 将@Scheduled 的方法包装为指定的task 添加到ScheduledTaskRegistra中. 我们看一下代码 if (bean instanceof AopInfrastructureBean || bean instanceof TaskScheduler || bean instanceof ScheduledExecutorService) &amp;#123; // Ignore AOP infrastructure such as scoped proxies. return bean; &amp;#125; Class&lt;?> targetClass = AopProxyUtils.ultimateTargetClass(bean); if (!this.nonAnnotatedClasses.contains(targetClass) &amp;&amp; AnnotationUtils.isCandidateClass(targetClass, Arrays.asList(Scheduled.class, Schedules.class))) &amp;#123; Map&lt;Method, Set&lt;Scheduled>> annotatedMethods = MethodIntrospector.selectMethods(targetClass, (MethodIntrospector.MetadataLookup&lt;Set&lt;Scheduled>>) method -> &amp;#123; Set&lt;Scheduled> scheduledMethods = AnnotatedElementUtils.getMergedRepeatableAnnotations( method, Scheduled.class, Schedules.class); return (!scheduledMethods.isEmpty() ? scheduledMethods : null); &amp;#125;); if (annotatedMethods.isEmpty()) &amp;#123; this.nonAnnotatedClasses.add(targetClass); if (logger.isTraceEnabled()) &amp;#123; logger.trace(\"No @Scheduled annotations found on bean class: \" + targetClass); &amp;#125; &amp;#125; else &amp;#123; // Non-empty set of methods annotatedMethods.forEach((method, scheduledMethods) -> scheduledMethods.forEach(scheduled -> processScheduled(scheduled, method, bean))); if (logger.isTraceEnabled()) &amp;#123; logger.trace(annotatedMethods.size() + \" @Scheduled methods processed on bean '\" + beanName + \"': \" + annotatedMethods); &amp;#125; &amp;#125; &amp;#125; return bean; &amp;#125; ScheduledAnnotationBeanPostProcessor 会监听Spring容器初始化事件,在Spring容器初始化完成的时候进行TaskScheduler 实现类实例的查找,若发现有SchedulingConfigurer的实现类实例, 会跳过3 @Override public void onApplicationEvent(ContextRefreshedEvent event) &amp;#123; if (event.getApplicationContext() == this.applicationContext) &amp;#123; // Running in an ApplicationContext -> register tasks this late... // giving other ContextRefreshedEvent listeners a chance to perform // their work at the same time (e.g. Spring Batch's job registration). finishRegistration(); &amp;#125; &amp;#125; private void finishRegistration() &amp;#123; if (this.scheduler != null) &amp;#123; this.registrar.setScheduler(this.scheduler); &amp;#125; if (this.beanFactory instanceof ListableBeanFactory) &amp;#123; Map&lt;String, SchedulingConfigurer> beans = ((ListableBeanFactory) this.beanFactory).getBeansOfType(SchedulingConfigurer.class); List&lt;SchedulingConfigurer> configurers = new ArrayList&lt;>(beans.values()); AnnotationAwareOrderComparator.sort(configurers); for (SchedulingConfigurer configurer : configurers) &amp;#123; configurer.configureTasks(this.registrar); &amp;#125; &amp;#125; if (this.registrar.hasTasks() &amp;&amp; this.registrar.getScheduler() == null) &amp;#123; Assert.state(this.beanFactory != null, \"BeanFactory must be set to find scheduler by type\"); try &amp;#123; // Search for TaskScheduler bean... this.registrar.setTaskScheduler(resolveSchedulerBean(this.beanFactory, TaskScheduler.class, false)); &amp;#125; catch (NoUniqueBeanDefinitionException ex) &amp;#123; logger.trace(\"Could not find unique TaskScheduler bean\", ex); try &amp;#123; this.registrar.setTaskScheduler(resolveSchedulerBean(this.beanFactory, TaskScheduler.class, true)); &amp;#125; catch (NoSuchBeanDefinitionException ex2) &amp;#123; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"More than one TaskScheduler bean exists within the context, and \" + \"none is named 'taskScheduler'. Mark one of them as primary or name it 'taskScheduler' \" + \"(possibly as an alias); or implement the SchedulingConfigurer interface and call \" + \"ScheduledTaskRegistrar#setScheduler explicitly within the configureTasks() callback: \" + ex.getBeanNamesFound()); &amp;#125; &amp;#125; &amp;#125; catch (NoSuchBeanDefinitionException ex) &amp;#123; logger.trace(\"Could not find default TaskScheduler bean\", ex); // Search for ScheduledExecutorService bean next... try &amp;#123; this.registrar.setScheduler(resolveSchedulerBean(this.beanFactory, ScheduledExecutorService.class, false)); &amp;#125; catch (NoUniqueBeanDefinitionException ex2) &amp;#123; logger.trace(\"Could not find unique ScheduledExecutorService bean\", ex2); try &amp;#123; this.registrar.setScheduler(resolveSchedulerBean(this.beanFactory, ScheduledExecutorService.class, true)); &amp;#125; catch (NoSuchBeanDefinitionException ex3) &amp;#123; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"More than one ScheduledExecutorService bean exists within the context, and \" + \"none is named 'taskScheduler'. Mark one of them as primary or name it 'taskScheduler' \" + \"(possibly as an alias); or implement the SchedulingConfigurer interface and call \" + \"ScheduledTaskRegistrar#setScheduler explicitly within the configureTasks() callback: \" + ex2.getBeanNamesFound()); &amp;#125; &amp;#125; &amp;#125; catch (NoSuchBeanDefinitionException ex2) &amp;#123; logger.trace(\"Could not find default ScheduledExecutorService bean\", ex2); // Giving up -> falling back to default scheduler within the registrar... logger.info(\"No TaskScheduler/ScheduledExecutorService bean found for scheduled processing\"); &amp;#125; &amp;#125; &amp;#125; this.registrar.afterPropertiesSet(); &amp;#125; 查找TaskScheduler的实现类实例默认是通过类型查找,若有多个实现类则会查找名字为&quot;taskScheduler&quot;的实现bean, 如没有找见则在ScheduledTaskRegistrar调度任务的时候创建一个newSingleThreadScheduledExecutor,将TaskScheduler 的实现类实例设置到 ScheduledTaskRegistrar 属性中 ScheduledTaskRegistrar 的 scheduleTasks 方法触发任务调度 真正调度任务的类是 TaskScheduler 实现类中的 ScheduledExecutorService，由 J.U.C 提供 2. Quartz 基本介绍官网: http://www.quartz-scheduler.org/ Quartz的意思是石英, 像石英表一样精确. Quartz is a richly featured, open source job scheduling library that can be integrated within virtually any Java application - from the smallest stand-alone application to the largest e-commerce system. Quartz can be used to create simple or complex schedules for executing tens, hundreds, or even tens-of-thousands of jobs; jobs whose tasks are defined as standard Java components that may execute virtually anything you may program them to do. The Quartz Scheduler includes many enterprise-class features, such as support for JTA transactions and clustering. Quatz 是一个特性丰富的，开源的任务调度库，它几乎可以嵌入所有的 Java 程序，从很小的独立应用程序到大型 商业系统。Quartz 可以用来创建成百上千的简单的或者复杂的任务，这些任务可以用来执行任何程序可以做的事情。 Quartz 拥有很多企业级的特性，包括支持 JTA 事务和集群。 Quartz 是一个老牌的任务调度系统, 98年构思, 01年发布到sourceforge.现在更新比较慢, 因为已经非常成熟了. https://github.com/quartz-scheduler/quartz Quzrtz的目的就是让任务调度变得更加简单, 开发人员只需要关注即可, 它是用java语言编写的. Java代码能够做的任何事情,Quartz 都可以调度. 特点： 精确到毫秒级别的调度 可以独立运行, 也可以集成到容器中 支持事务(JobStoreCMT) 支持集群 支持持久化 3. Quartz Java编程http://www.quartz-scheduler.org/documentation/quartz-2.3.0/ http://www.quartz-scheduler.org/documentation/quartz-2.3.0/quick-start.html 3.1 引入依赖 &lt;dependency> &lt;groupId>org.quartz-scheduler&lt;/groupId> &lt;artifactId>quartz&lt;/artifactId> &lt;version>2.3.0&lt;/version> &lt;/dependency> 3.2 默认的配置文件org.quartz.core包下, 有一个默认的配置文件, quartz.properties,当我们没有定义一个同名的配置文件的时候, 会使用默认配置文件的配置. # quartz 配置文件 org.quartz.scheduler.instanceName: DefaultQuartzScheduler org.quartz.scheduler.rmi.export: false org.quartz.scheduler.rmi.proxy: false org.quartz.scheduler.wrapJobExecutionInUserTransaction: false org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount: 10 org.quartz.threadPool.threadPriority: 5 org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true org.quartz.jobStore.misfireThreshold: 60000 org.quartz.jobStore.class: org.quartz.simpl.RAMJobStore 3.3 创建Job实现唯一的方法execute,方法里的代码就是任务执行的内容, /** * @author luyanan * @since 2020/4/9 * &lt;p>任务&lt;/p> **/ public class MyJob implements Job &amp;#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &amp;#123; System.out.println(\"收破烂了。。。\" + LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); &amp;#125; &amp;#125; 然后需要将Job进一步的包装成JobDetail, 必须要指定JobName和groupName, 两个合起来是唯一标识. 可以携带KV 的数据(jobDataMap), 用于扩展属性,在运行的时候, 可以从JobExecutionContext 中获取到 JobDetail jobDetail = JobBuilder.newJob(MyJob.class).withIdentity(\"job1\", \"group1\") .usingJobData(\"name\", \"张三\") .build(); 3.4 创建Trigger基于SimpleTrigger 定义了一个每2秒钟运行一次, 不断重复的Trigger Trigger trigger = TriggerBuilder .newTrigger() .withIdentity(\"trigger1\", \"group1\") .startNow().withSchedule(SimpleScheduleBuilder .simpleSchedule() .withIntervalInSeconds(2) .repeatForever()) .build(); 3.5创建Scheduler通过Factory 获取调度器的实例, 把JobDetail 和 Trigger 绑定, 注册到调度器中. Scheduler 先启动还是后启动无所谓,只要有Trigger到达 触发条件, 就会执行任务. SchedulerFactory factory = new StdSchedulerFactory(); Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); 3.6 体系结构总结 3.6.1 JobDetail我们创建一个实现Job接口的类, 使用JobBuilder 包装成JobDetail, 它可以携带KV的数据 3.6.2 Trigger定义任务触发的规律,Trigger,使用TriggerBuilder 来构建. JobDetail 跟 Trigger 是 1:N 的关系。 思考： 为什么要解耦呢? Trigger 接口在Quartz 有4个继承的子接口. 子接口 描述 特点 SimpleTrigger 简单触发器 固定时刻或者时间间隔, 毫秒 CalendarIntervalTrigger 基于日历的触发器 比简单触发器更多时间单位,支持非固定时间的触发,例如一年可能有365/366,一个月可能29/29/30/31 DailyTimeIntervalTrigger 基于日期的触发器 每天的某个时间段 CronTrigger 基于corn 表达式的触发器 MutableTrigger 和CoreTrigger 最终也是用到了四个类的实现类 SimpleTriggerSimpleTrigger 可以定义固定时刻或者固定时间间隔的调度规则(精确到毫秒) 例如: 每天9点运行一次, 每隔30分钟运行一次. CalendarIntervalTriggerCalendarIntervalTrigger 可以定义更多的时间单位的调度需求, 精确到秒 好处是不需要去计算时间间隔, 比如1个小时等于多少毫秒 例如: 每年、每月、每周、每天、每小时、每分钟、每秒 每年的月数和每个月的天数是不固定的, 这种情况也适用. DailyTimeIntervalTrigger每天的某个时间段内, 以一定的时间间隔执行任务 . 例如: 每天早上9点到晚上9点, 每隔半小时执行一次, 并且只在周一到周六执行. CronTriggerCronTrigger 可以定义基于Cron表达式的调度规则, 是最常用的触发器类型. Cron 表达式 位置 时间域 特殊值 1 秒 0-59 , - * / 2 分钟 0-59 , - * / 3 小时 0-23 , - * / 4 日期 1-31 , - * ? / L W C 5 月份呢 1-12 , - * / 6 星期 1-7 , - * ? / L W C 7 年份(可选) 1-31 , - * / 星号(*): 可用在所有字段中,标识对应时间域的每一个时刻, 例如, 在分钟字段时, 表示每分钟 问号?: 该字符只在日期和星期字段中使用, 它通常指定为:无意义的值,相当于点位符 减号(-): 表达一个范围, 如在小时字段中使用10-12, 则表示从10点到12点, 即10、11、12 逗号(,): 表达一个列表, 如在星期字段中使用“MON,WED,FRI”,则表示星期一,星期三和星期五 斜杠(/)：x/y 表达一个等步长序列，x 为起始值，y 为增量步长值。如在分钟字段中使用 0/15，则表示为 0,15,30 和 45 秒，而 5/15 在分钟字段中表示 5,20,35,50，你也可以使用*/y，它等同于 0/y； L：该字符只在日期和星期字段中使用，代表“Last”的意思，但它在两个字段中意思不同。L 在日期字段中，表示 这个月份的最后一天，如一月的 31 号，非闰年二月的 28 号；如果 L 用在星期中，则表示星期六，等同于 7。但是，如 果 L 出现在星期字段里，而且在前面有一个数值 X，则表示“这个月的最后 X 天”，例如，6L 表示该月的最后星期五； W：该字符只能出现在日期字段里，是对前导日期的修饰，表示离该日期最近的工作日。例如 15W 表示离该月 15 号最近的工作日，如果该月 15 号是星期六，则匹配 14 号星期五；如果 15 日是星期日，则匹配 16 号星期一；如果 15 号是星期二，那结果就是 15 号星期二。但必须注意关联的匹配日期不能够跨月，如你指定 1W，如果 1 号是星期六， 结果匹配的是 3 号星期一，而非上个月最后的那天。W 字符串只能指定单一日期，而不能指定日期范围； LW 组合：在日期字段可以组合使用 LW，它的意思是当月的最后一个工作日； 井号(#)：该字符只能在星期字段中使用，表示当月某个工作日。如 6#3 表示当月的第三个星期五(6 表示星期五， #3 表示当前的第三个)，而 4#5 表示当月的第五个星期三，假设当月没有第五个星期三，忽略不触发； C：该字符只在日期和星期字段中使用，代表“Calendar”的意思。它的意思是计划所关联的日期，如果日期没有 被关联，则相当于日历中所有日期。例如 5C 在日期字段中就相当于日历 5 日以后的第一天。1C 在星期字段中相当于 星期日后的第一天。 Cron 表达式对特殊字符的大小写不敏感，对代表星期的缩写英文大小写也不敏感。 上面定义的都是在什么时间执行, 但是我们有一些在什么时间不执行的需求. 比如: 理财周末和法定节假日购买不计息,证券公司周末和法定假日休市. 是不是要日期写在数据库, 然后读取基于当前时间进行判断呢? 基于Calendar的排除规则如果要在触发器的基础上, 排除一些时间区间不执行任务,就要用到Quartz 的Calendar 类(注意不是JDK的Calendar), 可以按照年、月、日、特定的日期、Corn表达式来排除. 调用Trigger的modifiedByCalendar() 添加到触发器中, 并且调用调度器的addCalendar() 添加注册排除规则. public static void main(String[] args) throws Exception &amp;#123; SchedulerFactory sf = new StdSchedulerFactory(); Scheduler scheduler = sf.getScheduler(); scheduler.start(); // 定义日历 AnnualCalendar holidays = new AnnualCalendar(); // 排除咕泡日 Calendar gupaoDay = (Calendar) new GregorianCalendar(2019, 8, 8); holidays.setDayExcluded(gupaoDay, true); // 排除中秋节 Calendar midAutumn = new GregorianCalendar(2019, 9, 13); holidays.setDayExcluded(midAutumn, true); // 排除圣诞节 Calendar christmas = new GregorianCalendar(2019, 12, 25); holidays.setDayExcluded(christmas, true); // 调度器添加日历 scheduler.addCalendar(\"holidays\", holidays, false, false); JobDetail jobDetail = JobBuilder.newJob(MyJob.class) .withIdentity(\"job1\", \"group1\") .build(); Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"trigger1\", \"group1\") .startNow() .modifiedByCalendar(\"holidays\") .withSchedule(SimpleScheduleBuilder.simpleSchedule() .withIntervalInSeconds(2) .repeatForever()) .build(); Date firstRunTime = scheduler.scheduleJob(jobDetail, trigger); System.out.println(jobDetail.getKey() + \" 第一次触发： \" + firstRunTime); &amp;#125; Calendar 名称 用法 BaseCalendar 为高级的 Calendar 实现了基本的功能，实现了 org.quartz.Calendar 接口 AnnualCalendar 排除年中一天或多天 CronCalendar 日历的这种实现排除了由给定的 CronExpression 表达的时间集合。 例如， 您可以使用此日历使用表达式* * 0-7,18-23？* *每天排除所有营业时 间（上午 8 点至下午 5 点）。 如果 CronTrigger 具有给定的 cron 表达式并 且与具有相同表达式的 CronCalendar 相关联，则日历将排除触发器包含的 所有时间，并且它们将彼此抵消 DailyCalendar 您可以使用此日历来排除营业时间（上午 8 点 - 5 点）每天。 每个 DailyCalendar 仅允许指定单个时间范围，并且该时间范围可能不会跨越每 日边界（即，您不能指定从上午 8 点至凌晨 5 点的时间范围）。 如果属 性 invertTimeRange 为 false（默认），则时间范围定义触发器不允许触发 的时间范围。 如果 invertTimeRange 为 true，则时间范围被反转 - 也就是 排除在定义的时间范围之外的所有时间。 HolidayCalendar 特别的用于从 Trigger 中排除节假日 MonthlyCalendar 排除月份中的指定数天，例如，可用于排除每月的最后一天 WeeklyCalendar 排除星期中的任意周几，例如，可用于排除周末，默认周六和周日 3.6.3 Scheduler调度器是Quartz的指挥官,由StdSchedulerFactory 产生, 是单例的. 并且是Quartz 中最重要的API, 默认的实现类是StdScheduler, 里面包含了一个QuartzScheduler,QuartzScheduler 里面包含了一个QuartzSchedulerThread. Scheduler 中的方法主要分为三大类： 调度器本身,例如调度器的启动start(), 调度器的关闭shutdown() 调用Trigger,例如pauseTriggers()、resumeTrigger()。 操纵Job, 例如scheduleJob()、unscheduleJob()、rescheduleJob() 这些方法非常重要,可以获取任务的动态调度. 3.6.4 Listener我们有这么一种需求,再每个任务运行结束后发送通知给运维管理人员,那是不是要再每个任务的最后添加一行代码呢? 这种方式对原来的代码造成了入侵,不利于维护. 如果代码不是写在任务代码的最后一行, 怎么知道任务执行完了呢? 或者说, 怎么检测到任务的生命周期呢? 观察者模式:定义对象间一种一对多的依赖关系,使得每当一个对象改变状态, 则所有依赖它的对象都会得到通知并自动更新. Quartz 中提供了三种Listener,监听Scheduler的, 监听Trigger的, 监听Job的. 只需要创建类实现相应的接口, 并在Scheduler 上注册Listener,便可以实现对核心对象的监听. 代码演示：我们这里先准备一个job public class MyJob implements Job &amp;#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &amp;#123; System.out.println(\"收破烂了。。。\" + LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); &amp;#125; &amp;#125; 监听Job public class MyJobListener implements JobListener &amp;#123; public String getName() &amp;#123; String name = getClass().getSimpleName(); System.out.println( \"Method 111111 :\"+ \"获取到监听器名称：\"+name); return name; &amp;#125; public void jobToBeExecuted(JobExecutionContext context) &amp;#123; String jobName = context.getJobDetail().getKey().getName(); System.out.println(\"Method 222222 :\"+ jobName + \" ——任务即将执行 \"); &amp;#125; public void jobExecutionVetoed(JobExecutionContext context) &amp;#123; String jobName = context.getJobDetail().getKey().getName(); System.out.println(\"Method 333333 :\"+ jobName + \" ——任务被否决 \"); &amp;#125; public void jobWasExecuted(JobExecutionContext context, JobExecutionException jobException) &amp;#123; String jobName = context.getJobDetail().getKey().getName(); System.out.println(\"Method 444444 :\"+ jobName + \" ——执行完毕 \"); System.out.println(\"------------------\"); &amp;#125; &amp;#125; 测试类 public class MyJobListenerTest &amp;#123; public static void main(String[] args) throws SchedulerException &amp;#123; // JobDetail JobDetail jobDetail = JobBuilder.newJob(MyJob.class).withIdentity(\"job1\", \"group1\").build(); // Trigger Trigger trigger = TriggerBuilder.newTrigger().withIdentity(\"trigger1\", \"group1\").startNow() .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(5).repeatForever()).build(); // SchedulerFactory SchedulerFactory factory = new StdSchedulerFactory(); // Scheduler Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, trigger); // 创建并注册一个全局的Job Listener scheduler.getListenerManager().addJobListener(new MyJobListener(), EverythingMatcher.allJobs()); scheduler.start(); &amp;#125; &amp;#125; 四个方法: 方法 作用或者执行实际 getName() 返回JobListener的名称 jobToBeExecuted() Scheduler 在 JobDetail 将要被执行时调用这个方法 jobExecutionVetoed() Scheduler 在 JobDetail 即将被执行，但又被 TriggerListener 否决了时调用这个 方法 jobWasExecuted() Scheduler 在 JobDetail 被执行之后调用这个方法 工具类： ListenerManager, 用于添加、获取、移除监听器. 工具类： Matcher，主要是基于 groupName 和 keyName 进行匹配。 监听Triggerpublic class MyTriggerListener implements TriggerListener &amp;#123; private String name; public MyTriggerListener(String name) &amp;#123; this.name = name; &amp;#125; public String getName() &amp;#123; return name; &amp;#125; // Trigger 被触发，Job 上的 execute() 方法将要被执行时 public void triggerFired(Trigger trigger, JobExecutionContext context) &amp;#123; String triggerName = trigger.getKey().getName(); System.out.println(\"Method 11111 \" + triggerName + \" was fired\"); &amp;#125; // 在 Trigger 触发后，Job 将要被执行时由 Scheduler 调用这个方法 // 返回true时，这个任务不会被触发 public boolean vetoJobExecution(Trigger trigger, JobExecutionContext context) &amp;#123; String triggerName = trigger.getKey().getName(); System.out.println(\"Method 222222 \" + triggerName + \" was not vetoed\"); return false; &amp;#125; public void triggerMisfired(Trigger trigger) &amp;#123; String triggerName = trigger.getKey().getName(); System.out.println(\"Method 333333 \" + triggerName + \" misfired\"); &amp;#125; public void triggerComplete(Trigger trigger, JobExecutionContext context, Trigger.CompletedExecutionInstruction triggerInstructionCode) &amp;#123; String triggerName = trigger.getKey().getName(); System.out.println(\"Method 444444 \" + triggerName + \" is complete\"); System.out.println(\"------------\"); &amp;#125; &amp;#125; 测试 public class MyTriggerListenerTest &amp;#123; public static void main(String[] args) throws SchedulerException &amp;#123; // JobDetail JobDetail jobDetail = JobBuilder.newJob(MyJob.class).withIdentity(\"job1\", \"group1\").build(); // Trigger Trigger trigger = TriggerBuilder.newTrigger().withIdentity(\"trigger1\", \"group1\").startNow() .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(10).repeatForever()).build(); // SchedulerFactory SchedulerFactory factory = new StdSchedulerFactory(); // Scheduler Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, trigger); // 创建并注册一个全局的Trigger Listener scheduler.getListenerManager().addTriggerListener(new MyTriggerListener(\"myListener1\"), EverythingMatcher.allTriggers()); // 创建并注册一个局部的Trigger Listener scheduler.getListenerManager().addTriggerListener(new MyTriggerListener(\"myListener2\"), KeyMatcher.keyEquals(TriggerKey.triggerKey(\"trigger1\", \"gourp1\"))); // 创建并注册一个特定组的Trigger Listener GroupMatcher&lt;TriggerKey> matcher = GroupMatcher.triggerGroupEquals(\"gourp1\"); scheduler.getListenerManager().addTriggerListener(new MyTriggerListener(\"myListener3\"), matcher); scheduler.start(); &amp;#125; &amp;#125; 方法 作用或者执行实际 getName() 返回监听器的名称 triggerFired() Trigger 被触发，Job 上的 execute() 方法将要被执行时，Scheduler 就调用这个 方法 vetoJobExecution() 在 Trigger 触 发 后 ， Job 将 要 被 执 行 时 由 Scheduler 调 用 这 个 方 法 。 TriggerListener 给了一个选择去否决 Job 的执行。假如这个方法返回 true，这 个 Job 将不会为此次 Trigger 触发而得到执行 triggerMisfired() Trigger 错过触发时调用 triggerComplete() Trigger 被触发并且完成了 Job 的执行时，Scheduler 调用这个方法 监听Scheduler public class MySchedulerListener implements SchedulerListener &amp;#123; public void jobScheduled(Trigger trigger) &amp;#123; String jobName = trigger.getJobKey().getName(); System.out.println( jobName + \" has been scheduled\"); &amp;#125; public void jobUnscheduled(TriggerKey triggerKey) &amp;#123; System.out.println(triggerKey + \" is being unscheduled\"); &amp;#125; public void triggerFinalized(Trigger trigger) &amp;#123; System.out.println(\"Trigger is finished for \" + trigger.getJobKey().getName()); &amp;#125; public void triggerPaused(TriggerKey triggerKey) &amp;#123; System.out.println(triggerKey + \" is being paused\"); &amp;#125; public void triggersPaused(String triggerGroup) &amp;#123; System.out.println(\"trigger group \"+triggerGroup + \" is being paused\"); &amp;#125; public void triggerResumed(TriggerKey triggerKey) &amp;#123; System.out.println(triggerKey + \" is being resumed\"); &amp;#125; public void triggersResumed(String triggerGroup) &amp;#123; System.out.println(\"trigger group \"+triggerGroup + \" is being resumed\"); &amp;#125; public void jobAdded(JobDetail jobDetail) &amp;#123; System.out.println(jobDetail.getKey()+\" is added\"); &amp;#125; public void jobDeleted(JobKey jobKey) &amp;#123; System.out.println(jobKey+\" is deleted\"); &amp;#125; public void jobPaused(JobKey jobKey) &amp;#123; System.out.println(jobKey+\" is paused\"); &amp;#125; public void jobsPaused(String jobGroup) &amp;#123; System.out.println(\"job group \"+jobGroup+\" is paused\"); &amp;#125; public void jobResumed(JobKey jobKey) &amp;#123; System.out.println(jobKey+\" is resumed\"); &amp;#125; public void jobsResumed(String jobGroup) &amp;#123; System.out.println(\"job group \"+jobGroup+\" is resumed\"); &amp;#125; public void schedulerError(String msg, SchedulerException cause) &amp;#123; System.out.println(msg + cause.getUnderlyingException().getStackTrace()); &amp;#125; public void schedulerInStandbyMode() &amp;#123; System.out.println(\"scheduler is in standby mode\"); &amp;#125; public void schedulerStarted() &amp;#123; System.out.println(\"scheduler has been started\"); &amp;#125; public void schedulerStarting() &amp;#123; System.out.println(\"scheduler is being started\"); &amp;#125; public void schedulerShutdown() &amp;#123; System.out.println(\"scheduler has been shutdown\"); &amp;#125; public void schedulerShuttingdown() &amp;#123; System.out.println(\"scheduler is being shutdown\"); &amp;#125; public void schedulingDataCleared() &amp;#123; System.out.println(\"scheduler has cleared all data\"); &amp;#125; &amp;#125; 测试 public class MySchedulerListenerTest &amp;#123; public static void main(String[] args) throws SchedulerException &amp;#123; // JobDetail JobDetail jobDetail = JobBuilder.newJob(MyJob.class).withIdentity(\"job1\", \"group1\").build(); // Trigger Trigger trigger = TriggerBuilder.newTrigger().withIdentity(\"trigger1\", \"group1\").startNow() .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(5).repeatForever()).build(); // SchedulerFactory SchedulerFactory factory = new StdSchedulerFactory(); // Scheduler Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, trigger); // 创建Scheduler Listener scheduler.getListenerManager().addSchedulerListener(new MySchedulerListener()); scheduler.start(); &amp;#125; &amp;#125; 3.6.5 jobStoreJobStore 用来存储任务和触发器的相关的信息. 例如所有任务的名称、数量、状态等等. Quartz 中有两种存储任务的方式, 一种是在内存中, 一种是在数据库. RAMJobStoreQuartz 默认的JobStore 是RAMJobStore,也就是把任务和触发器信息运行的信息存储到内存中, 用到了HashMap、TreeSet、HashSet. 如果程序崩溃或者重启, 所有存储在内存中的数据都会丢失, 所以我们需要把这些数据持久化到磁盘. JDBCJobStoreJDBCJobStore 可以通过JDBC 接口,将任务运行数据保存到数据库. JDBC的实现方式有两种: JobStoreSupport 类的两个子类: JobStoreTX: 在独立的程序中使用, 自己管理事务, 不参与外部事务. JobStoreCMT：(Container Managed Transactions (CMT),如果需要容器管理事务时, 使用它. 使用JDBCJobSotre时, 需要配置数据库信息。 org.quartz.jobStore.class:org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass:org.quartz.impl.jdbcjobstore.StdJDBCDelegate # 使用 quartz.properties，不使用默认配置 org.quartz.jobStore.useProperties:true #数据库中 quartz 表的表名前缀 org.quartz.jobStore.tablePrefix:QRTZ_ org.quartz.jobStore.dataSource:myDS #配置数据源 org.quartz.dataSource.myDS.driver:com.mysql.jdbc.Driver org.quartz.dataSource.myDS.URL:jdbc:mysql://localhost:3306/quartz?useUnicode=true&amp;characterEncoding=utf8 org.quartz.dataSource.myDS.user:root org.quartz.dataSource.myDS.password:rootroot org.quartz.dataSource.myDS.validationQuery=select 0 from dual 问题来了? 需要建什么表? 表里面有什么字段? 字段类型和长度是什么? 在官网的Downloads 链接中, 提供了11张表的建表语句 quartz-2.2.3-distribution\\quartz-2.2.3\\docs\\dbTables 2.3 的版本在这个路径下：src\\org\\quartz\\impl\\jdbcjobstore 表名和作用 表名 作用 QRTZ_BLOB_TRIGGERS Trigger 作为 Blob 类型存储 QRTZ_CALENDARS 存储 Quartz 的 Calendar 信息 QRTZ_CRON_TRIGGERS 存储 CronTrigger，包括Cron 表达式和时区信息 QRTZ_FIRED_TRIGGERS 存储与已触发的 Trigger 相关的状态信息，以及相关 Job 的执行信息 QRTZ_JOB_DETAILS 存储每一个已配置的 Job的详细信息 QRTZ_LOCKS 存储程序的悲观锁的信息 QRTZ_PAUSED_TRIGGER_GRPS 存储已暂停的 Trigger 组的信息 QRTZ_SCHEDULER_STATE 存储少量的有关 Scheduler 的状态信息，和别的 Scheduler 实例 QRTZ_SIMPLE_TRIGGERS 存储 SimpleTrigger 的信息，包括重复次数、间隔、以及已触的次数 QRTZ_SIMPROP_TRIGGERS 存储 CalendarIntervalTrigger 和 DailyTimeIntervalTrigger 两种类型的触发器 QRTZ_TRIGGERS 存储已配置的 Trigger 的信息 4.Quartz 继承到Spring中Spring 在 spring-context-support.jar 中直接提供了对 Quartz 的支持。 可以在配置文件中把JobDetail、Trigger、Scheduler 定义成 Bean。 @Configuration public class QuartzConfig &amp;#123; @Bean public JobDetail myJobJobDetail() &amp;#123; return JobBuilder.newJob(MyJob.class) .withIdentity(\"myjob\") .usingJobData(\"name\", \"张三\") .storeDurably() .build(); &amp;#125; @Bean public Trigger myJobTrigger() &amp;#123; CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(\"0/5 * * * * ?\"); return TriggerBuilder .newTrigger() .forJob(myJobJobDetail()) .withIdentity(\"quartzTaskService\") .withSchedule(cronScheduleBuilder) .build(); &amp;#125; &amp;#125; 5. 动态调度的实现传统的Spring 方式集成, 由于任务信息全部配置在xml 文件中, 如果需要操作任务或者修改任务运行频率, 只能重新编译、打包、部署、重启,如果有紧急问题需要处理, 会浪费很多时间. 有没有可以动态调度任务的方法? 比如停止一个Job?启动一个Job? 修改Job的触发频率. 读取配置文件、写入配置文件、重启Scheduler 或者重启应用明显不可取的. 对于这种频繁变更并且需要实时生效的配置信息, 我们放到哪里呢? ZK、Redis、DB 并且我们可以提供一个页面, 实现对数据表的轻松操作. 5.1 配置管理这里我们用最简单的数据库实现. 问题 1：建一张什么样的表？参考 JobDetail 的属性。 CREATE TABLE `sys_job` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'ID', `job_name` varchar(512) NOT NULL COMMENT '任务名称', `job_group` varchar(512) NOT NULL COMMENT '任务组名', `job_cron` varchar(512) NOT NULL COMMENT '时间表达式', `job_class_path` varchar(1024) NOT NULL COMMENT '类路径,全类型', `job_data_map` varchar(1024) DEFAULT NULL COMMENT '传递 map 参数', `job_status` int(2) NOT NULL COMMENT '状态:1 启用 0 停用', `job_describe` varchar(1024) DEFAULT NULL COMMENT '任务功能描述', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8; 5.2 数据操作和任务调度操作数据表非常简单， SSM 增删改查 但是在修改了表的数据之后, 怎么让调度器知道呢? 调度器的接口: ：Scheduler 在我们的需求中,我们需要做的事情: 新增一个任务 删除一个任务 启动、停止一个任务 修改任务的信息(包括调度规则) 因此我们可以将相关的操作封装到一个工具类里 5.3 前端页面 接下来我们有两个问题 需要解决. 5.4 容器启动和Service注入5.4.1 容器启动因为任务没有定义在ApplicationContext.xm中,而是放到了数据库中, Spring Boot 启动时, 怎么读取任务信息? 或者说, 怎么在Spring 启动完成的时候做一些事情呢? 创建一些类,实现CommandLineRunner 接口, 实现run方法. 从表中查出来的是1的任务, 然后构建. 5.4.2 Service 类注入到job 中Spring Bean 如何注入到实现了Job 接口的类中. 例如在Task 类中, 需要注入Service 查询数据库执行一些操作。 如果没有任务配置, 注入就会报空指针. 原因: 因为定时任务Job 对象的实例化过程是在Quartz 中进行的, 而Service Bean 是由Spring 容器管理的，Quartz 察觉不到Service Bean的存在,所以无法将Service Bean 装配到Job 对象中. 分析: Quartz 集成到Spring中, 用到了SchedulerFactoryBean,其内实现了InitializingBean 方法, 在唯一的方法afterPropertiesSet() 在Bean 的属性初始化后调用. 调度器用AdaptableJobFactory 对Job 对象进行实例化. 所以我们可以把这个JobFactory 指定为我们自定义的工厂的话, 就可以在Job 实例化之后, 把Job纳入到Spring容器中管理. 解决这个问题的步骤: 定义一个AdaptableJobFactory ,实现JobFactory 接口,实现接口定义的newJob 方法, 在这里返回Job实例. /** * * 将Spring的对象注入到Quartz Job 1 */ public class AdaptableJobFactory implements JobFactory &amp;#123; @Override public Job newJob(TriggerFiredBundle bundle, Scheduler arg1) throws SchedulerException &amp;#123; return newJob(bundle); &amp;#125; public Job newJob(TriggerFiredBundle bundle) throws SchedulerException &amp;#123; try &amp;#123; // 返回Job实例 Object jobObject = createJobInstance(bundle); return adaptJob(jobObject); &amp;#125; catch (Exception ex) &amp;#123; throw new SchedulerException(\"Job instantiation failed\", ex); &amp;#125; &amp;#125; // 通过反射的方式创建实例 protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &amp;#123; Method getJobDetail = bundle.getClass().getMethod(\"getJobDetail\"); Object jobDetail = ReflectionUtils.invokeMethod(getJobDetail, bundle); Method getJobClass = jobDetail.getClass().getMethod(\"getJobClass\"); Class jobClass = (Class) ReflectionUtils.invokeMethod(getJobClass, jobDetail); return jobClass.newInstance(); &amp;#125; protected Job adaptJob(Object jobObject) throws Exception &amp;#123; if (jobObject instanceof Job) &amp;#123; return (Job) jobObject; &amp;#125; else if (jobObject instanceof Runnable) &amp;#123; return new DelegatingJob((Runnable) jobObject); &amp;#125; else &amp;#123; throw new IllegalArgumentException(\"Unable to execute job class [\" + jobObject.getClass().getName() + \"]: only [org.quartz.Job] and [java.lang.Runnable] supported.\"); &amp;#125; &amp;#125; &amp;#125; 定义一个MyJobFactory,继承AdaptableJobFactory. 使用Spring的AutowireCapableBeanFactory,把Job 实例注入到容器中. @Component public class MyJobFactory extends AdaptableJobFactory &amp;#123; @Autowired private AutowireCapableBeanFactory capableBeanFactory; protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &amp;#123; //调用父类的方法 Object jobInstance = super.createJobInstance(bundle); capableBeanFactory.autowireBean(jobInstance); return jobInstance; &amp;#125; &amp;#125; 指定Scheduler的JobFactory为自定义的JobFactory. // 通过SchedulerFactory获取一个调度器实例 SchedulerFactory sf = new StdSchedulerFactory(); Scheduler scheduler = sf.getScheduler(); // 如果不设置JobFactory，Service注入到Job会报空指针 scheduler.setJobFactory(myJobFactory); // 启动调度器 scheduler.start(); 考虑这么一种情况: 正在运行的Quzrtz节点挂了, 而所有人完全不知情. 6. Quartz集群部署6.1 为什么需要集群呢? 防止单点故障, 减少对业务的影响. 减少节点的压力, 例如在10点要触发1000个任务, 如果由10个节点, 则每个节点只需要执行100个任务. 6.2 集群需要解决的问题? 任务重跑,因为节点部署的内容是一样的,到10点的时候,每个节点都会执行相同的操作,引入数据混乱.比如跑批, 绝对不能执行多次. 任务漏跑,假如任务是平均分配的，本来应该是在某个节点上执行的任务, 因为节点故障,一直没有得到执行. 水平集群需要注意的是时间同步 问题. Quartz 使用的是随机的负载均衡算法,不能指定节点执行. 所以必须由一种共享数据或者通信的机制, 在分布式系统的不同节点, 我们可以采用什么样的方式, 实现数据共享. 两两通信, 或者基于分布式服务, 实现数据共享. 例如ZK、Redis、DB 在Quartz 中, 提供了一种简单的方式,基于数据库共享任务执行信息,也就是i说, 一个节点执行任务的时候, 会操作数据库,其他的节点查询数据库,便可以感知到了. 同样的问题,建什么表? 哪些字段? 依旧使用系统自带的11张表. 6.3 集群配置与验证quertz.properties配置 #调度器名称 org.quartz.scheduler.instanceName: MyScheduler #如果使用集群，instanceId必须唯一，设置成AUTO org.quartz.scheduler.instanceId = AUTO org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool org.quartz.threadPool.threadCount: 10 org.quartz.threadPool.threadPriority: 5 org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true org.quartz.jobStore.misfireThreshold: 60000 #是否使用集群 org.quartz.jobStore.isClustered = true # jobStore 持久化配置 #存储方式使用JobStoreTX，也就是数据库 org.quartz.jobStore.class:org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass:org.quartz.impl.jdbcjobstore.StdJDBCDelegate # 使用quartz.properties，不使用默认配置 org.quartz.jobStore.useProperties:true #数据库中quartz表的表名前缀 org.quartz.jobStore.tablePrefix:QRTZ_ org.quartz.jobStore.dataSource:myDS #配置数据源 org.quartz.dataSource.myDS.driver:com.mysql.jdbc.Driver org.quartz.dataSource.myDS.URL:jdbc:mysql://localhost:3306/quartz?useUnicode=true&amp;characterEncoding=utf8 org.quartz.dataSource.myDS.user:root org.quartz.dataSource.myDS.password:luyanan org.quartz.dataSource.myDS.validationQuery=select 0 from dual 四个配置: 集群实例ID、集群开关、数据持久化、数据源信息. 7. Quartz 调度原理问题: Job 没有继承Thread 和实现Runnable,是怎么被调用的呢? 通过反射还是什么? 任务是什么时候被调度的? 是谁在监视任务还是监视Trigger 任务是怎么被调用的? 谁执行了任务? 任务本身有状态吗? 还是触发器有状态? 看源码的入口 SchedulerFactory factory = new StdSchedulerFactory(); Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); 7.1 获取调度器实例7.1.1 读取配置文件 public Scheduler getScheduler() throws SchedulerException &amp;#123; if (cfg == null) &amp;#123; // 读取quartz.properties 配置文件 initialize(); &amp;#125; // 这个类是一个HashMap,用来基于调度器的名称保证调度器的唯一性 SchedulerRepository schedRep = SchedulerRepository.getInstance(); // 如果调度器已经存在了 Scheduler sched = schedRep.lookup(getSchedulerName()); if (sched != null) &amp;#123; // 调度器关闭了, 移除 if (sched.isShutdown()) &amp;#123; schedRep.remove(getSchedulerName()); &amp;#125; else &amp;#123; // 返回调度器 return sched; &amp;#125; &amp;#125; // 调度器不存在,初始化 sched = instantiate(); return sched; &amp;#125; instantiate()方法里面做了初始化的所有工作 private Scheduler instantiate() throws SchedulerException &amp;#123; if (cfg == null) &amp;#123; initialize(); &amp;#125; if (initException != null) &amp;#123; throw initException; &amp;#125; // 存储任务信息的JobStore JobStore js = null; // 创建线程池,默认是`SimpleThreadPool` ThreadPool tp = null; // 创建调度器 QuartzScheduler qs = null; //连接数据库的连接管理器 DBConnectionManager dbMgr = null; // 自动生成ID String instanceIdGeneratorClass = null; Properties tProps = null; String userTXLocation = null; boolean wrapJobInTx = false; boolean autoId = false; long idleWaitTime = -1; long dbFailureRetry = 15000L; // 15 secs String classLoadHelperClass; String jobFactoryClass; // 创建线程执行器, 默认为`DefaultThreadExecutor` ThreadExecutor threadExecutor; .... &amp;#125; 7.1.2 创建线程池(包工头)830行和839行,创建了一个线程池,默认是配置文件中指定的SimpleThreadPool // Get ThreadPool Properties // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ String tpClass = cfg.getStringProperty(PROP_THREAD_POOL_CLASS, SimpleThreadPool.class.getName()); if (tpClass == null) &amp;#123; initException = new SchedulerException( \"ThreadPool class not specified. \"); throw initException; &amp;#125; try &amp;#123; tp = (ThreadPool) loadHelper.loadClass(tpClass).newInstance(); &amp;#125; catch (Exception e) &amp;#123; initException = new SchedulerException(\"ThreadPool class '\" + tpClass + \"' could not be instantiated.\", e); throw initException; &amp;#125; SimpleThreadPool 里面维护了三个list, 分别存放所有的工作线程、空闲的工作线程和忙碌的工作线程, 我们可以把SimpleThreadPool 理解为包工头. private List&lt;WorkerThread> workers; private LinkedList&lt;WorkerThread> availWorkers = new LinkedList&lt;WorkerThread>(); private LinkedList&lt;WorkerThread> busyWorkers = new LinkedList&lt;WorkerThread>(); tp的runInThread()方法是线程池运行的接口方法, 存数Runnable是执行的任务内容. 取出WorkerThread 去执行参数里面的runnable（JobRunShell） org.quartz.simpl.SimpleThreadPool#runInThread WorkerThread wt = (WorkerThread)availWorkers.removeFirst(); busyWorkers.add(wt); wt.run(runnable); 7.1.3 WorkerThread(工人)WorkerThread是SimpleThreadPool的内部类,用来执行任务,我们把WorkerThread 理解为工人, 在WorkerThread的run 方法中, 执行传入的参数runnable任务. @Override public void run() &amp;#123; boolean ran = false; while (run.get()) &amp;#123; try &amp;#123; synchronized(lock) &amp;#123; while (runnable == null &amp;&amp; run.get()) &amp;#123; lock.wait(500); &amp;#125; if (runnable != null) &amp;#123; ran = true; // 执行任务 runnable.run(); &amp;#125; &amp;#125; &amp;#125; catch (InterruptedException unblock) &amp;#123; // do nothing (loop will terminate if shutdown() was called try &amp;#123; getLog().error(\"Worker thread was interrupt()'ed.\", unblock); &amp;#125; catch(Exception e) &amp;#123; // ignore to help with a tomcat glitch &amp;#125; &amp;#125; catch (Throwable exceptionInRunnable) &amp;#123; try &amp;#123; getLog().error(\"Error while executing the Runnable: \", exceptionInRunnable); &amp;#125; catch(Exception e) &amp;#123; // ignore to help with a tomcat glitch &amp;#125; &amp;#125; finally &amp;#123; synchronized(lock) &amp;#123; runnable = null; &amp;#125; // repair the thread in case the runnable mucked it up... if(getPriority() != tp.getThreadPriority()) &amp;#123; setPriority(tp.getThreadPriority()); &amp;#125; if (runOnce) &amp;#123; run.set(false); clearFromBusyWorkersList(this); &amp;#125; else if(ran) &amp;#123; ran = false; makeAvailable(this); &amp;#125; &amp;#125; &amp;#125; //if (log.isDebugEnabled()) try &amp;#123; getLog().debug(\"WorkerThread is shut down.\"); &amp;#125; catch(Exception e) &amp;#123; // ignore to help with a tomcat glitch &amp;#125; &amp;#125; 7.1.4 创建调度线程(项目经历)org.quartz.impl.StdSchedulerFactory的1321行,创建了调度器QuartzScheduler. qs = new QuartzScheduler(rsrcs, idleWaitTime, dbFailureRetry); 在QuartzScheduler的构造函数中, 创建了QuartzSchedulerThread,我们把他理解为项目经理, 他会调用包工头的工人资源, 给他们安排任务. 并且创建了线程执行器schedThreadExecutor,执行了这个QuartzSchedulerThread,也就是调用了他的run 方法. public QuartzScheduler(QuartzSchedulerResources resources, long idleWaitTime, @Deprecated long dbRetryInterval) throws SchedulerException &amp;#123; this.resources = resources; if (resources.getJobStore() instanceof JobListener) &amp;#123; addInternalJobListener((JobListener)resources.getJobStore()); &amp;#125; // 创建一个线程, resources 里面有线程名称 this.schedThread = new QuartzSchedulerThread(this, resources); // 线程执行器 ThreadExecutor schedThreadExecutor = resources.getThreadExecutor(); // 执行这个线程, 也就是调用了线程的run方法 schedThreadExecutor.execute(this.schedThread); if (idleWaitTime > 0) &amp;#123; this.schedThread.setIdleWaitTime(idleWaitTime); &amp;#125; jobMgr = new ExecutingJobsManager(); addInternalJobListener(jobMgr); errLogger = new ErrorLogger(); addInternalSchedulerListener(errLogger); signaler = new SchedulerSignalerImpl(this, this.schedThread); getLog().info(\"Quartz Scheduler v.\" + getVersion() + \" created.\"); &amp;#125; 点开QuartzSchedulerThread 类, 找到run 方法,这个就是Quartz 任务调度的核心方法 @Override public void run() &amp;#123; int acquiresFailed = 0; // 检查scheduler 是否为停止状态 while (!halted.get()) &amp;#123; try &amp;#123; // check if we're supposed to pause... synchronized (sigLock) &amp;#123; // 检查是否为暂停状态 while (paused &amp;&amp; !halted.get()) &amp;#123; try &amp;#123; // wait until togglePause(false) is called... // 暂停的话会尝试去获取信号锁, 并wait一会儿 sigLock.wait(1000L); &amp;#125; catch (InterruptedException ignore) &amp;#123; &amp;#125; // reset failure counter when paused, so that we don't // wait again after unpausing acquiresFailed = 0; &amp;#125; if (halted.get()) &amp;#123; break; &amp;#125; &amp;#125; // wait a bit, if reading from job store is consistently // failing (e.g. DB is down or restarting).. // 从JobStore 中获取job持续失败, sleep一下 if (acquiresFailed > 1) &amp;#123; try &amp;#123; long delay = computeDelayForRepeatedErrors(qsRsrcs.getJobStore(), acquiresFailed); Thread.sleep(delay); &amp;#125; catch (Exception ignore) &amp;#123; &amp;#125; &amp;#125; // 从线程获取可用的线程 int availThreadCount = qsRsrcs.getThreadPool().blockForAvailableThreads(); if(availThreadCount > 0) &amp;#123; // will always be true, due to semantics of blockForAvailableThreads... List&lt;OperableTrigger> triggers; long now = System.currentTimeMillis(); clearSignaledSchedulingChange(); try &amp;#123; // 获取需要下次执行的 triggers // idleWaitTime： 默认 30s // availThreadCount：获取可用（空闲）的工作线程数量，总会大于 1，因为该方法会一直阻塞，直到有工作线程空闲下来。 // maxBatchSize：一次拉取 trigger 的最大数量，默认是 1 // batchTimeWindow：时间窗口调节参数，默认是 0 // misfireThreshold： 超过这个时间还未触发的 trigger，被认为发生了 misfire，默认 60s // 调度线程一次会拉取 NEXT_FIRETIME 小于（now + idleWaitTime +batchTimeWindow）,大于（now - misfireThreshold）的，min(availThreadCount,maxBatchSize)个 triggers，默认情况下，会拉取未来 30s、过去 60s 之间还未 fire 的 1 个 trigger triggers = qsRsrcs.getJobStore().acquireNextTriggers( now + idleWaitTime, Math.min(availThreadCount, qsRsrcs.getMaxBatchSize()), qsRsrcs.getBatchTimeWindow()); acquiresFailed = 0; if (log.isDebugEnabled()) log.debug(\"batch acquisition of \" + (triggers == null ? 0 : triggers.size()) + \" triggers\"); &amp;#125; catch (JobPersistenceException jpe) &amp;#123; if (acquiresFailed == 0) &amp;#123; qs.notifySchedulerListenersError( \"An error occurred while scanning for the next triggers to fire.\", jpe); &amp;#125; if (acquiresFailed &lt; Integer.MAX_VALUE) acquiresFailed++; continue; &amp;#125; catch (RuntimeException e) &amp;#123; if (acquiresFailed == 0) &amp;#123; getLog().error(\"quartzSchedulerThreadLoop: RuntimeException \" +e.getMessage(), e); &amp;#125; if (acquiresFailed &lt; Integer.MAX_VALUE) acquiresFailed++; continue; &amp;#125; if (triggers != null &amp;&amp; !triggers.isEmpty()) &amp;#123; now = System.currentTimeMillis(); long triggerTime = triggers.get(0).getNextFireTime().getTime(); long timeUntilTrigger = triggerTime - now; while(timeUntilTrigger > 2) &amp;#123; synchronized (sigLock) &amp;#123; if (halted.get()) &amp;#123; break; &amp;#125; if (!isCandidateNewTimeEarlierWithinReason(triggerTime, false)) &amp;#123; try &amp;#123; // we could have blocked a long while // on 'synchronize', so we must recompute now = System.currentTimeMillis(); timeUntilTrigger = triggerTime - now; if(timeUntilTrigger >= 1) sigLock.wait(timeUntilTrigger); &amp;#125; catch (InterruptedException ignore) &amp;#123; &amp;#125; &amp;#125; &amp;#125; if(releaseIfScheduleChangedSignificantly(triggers, triggerTime)) &amp;#123; break; &amp;#125; now = System.currentTimeMillis(); timeUntilTrigger = triggerTime - now; &amp;#125; // this happens if releaseIfScheduleChangedSignificantly decided to release triggers if(triggers.isEmpty()) continue; // set triggers to 'executing' List&lt;TriggerFiredResult> bndles = new ArrayList&lt;TriggerFiredResult>(); boolean goAhead = true; synchronized(sigLock) &amp;#123; goAhead = !halted.get(); &amp;#125; if(goAhead) &amp;#123; try &amp;#123; // 触发 Trigger，把 ACQUIRED 状态改成 EXECUTING // 如果这个 trigger 的 NEXTFIRETIME 为空，也就是未来不再触发，就将其状态改为COMPLETE // 如果 trigger 不允许并发执行（即 Job 的实现类标注了@DisallowConcurrentExecution），则将状态变为 BLOCKED，否则就将状态改为 WAITING List&lt;TriggerFiredResult> res = qsRsrcs.getJobStore().triggersFired(triggers); if(res != null) bndles = res; &amp;#125; catch (SchedulerException se) &amp;#123; qs.notifySchedulerListenersError( \"An error occurred while firing triggers '\" + triggers + \"'\", se); //QTZ-179 : a problem occurred interacting with the triggers from the db //we release them and loop again for (int i = 0; i &lt; triggers.size(); i++) &amp;#123; qsRsrcs.getJobStore().releaseAcquiredTrigger(triggers.get(i)); &amp;#125; continue; &amp;#125; &amp;#125; // 循环处理Trigger for (int i = 0; i &lt; bndles.size(); i++) &amp;#123; TriggerFiredResult result = bndles.get(i); TriggerFiredBundle bndle = result.getTriggerFiredBundle(); Exception exception = result.getException(); if (exception instanceof RuntimeException) &amp;#123; getLog().error(\"RuntimeException while firing trigger \" + triggers.get(i), exception); qsRsrcs.getJobStore().releaseAcquiredTrigger(triggers.get(i)); continue; &amp;#125; // it's possible to get 'null' if the triggers was paused, // blocked, or other similar occurrences that prevent it being // fired at this time... or if the scheduler was shutdown (halted) if (bndle == null) &amp;#123; qsRsrcs.getJobStore().releaseAcquiredTrigger(triggers.get(i)); continue; &amp;#125; JobRunShell shell = null; try &amp;#123; // 根据trigger 信息实例化JobRunShell(implements Runnable),同时依据JOB_CLASS_NAME 实例化 Job，随后我们将 JobRunShell 实例丢入工作线。 shell = qsRsrcs.getJobRunShellFactory().createJobRunShell(bndle); shell.initialize(qs); &amp;#125; catch (SchedulerException se) &amp;#123; qsRsrcs.getJobStore().triggeredJobComplete(triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR); continue; &amp;#125; // 执行JobRunShell的run方法 if (qsRsrcs.getThreadPool().runInThread(shell) == false) &amp;#123; // this case should never happen, as it is indicative of the // scheduler being shutdown or a bug in the thread pool or // a thread pool being used concurrently - which the docs // say not to do... getLog().error(\"ThreadPool.runInThread() return false!\"); qsRsrcs.getJobStore().triggeredJobComplete(triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR); &amp;#125; &amp;#125; continue; // while (!halted) &amp;#125; &amp;#125; else &amp;#123; // if(availThreadCount > 0) // should never happen, if threadPool.blockForAvailableThreads() follows contract continue; // while (!halted) &amp;#125; long now = System.currentTimeMillis(); long waitTime = now + getRandomizedIdleWaitTime(); long timeUntilContinue = waitTime - now; synchronized(sigLock) &amp;#123; try &amp;#123; if(!halted.get()) &amp;#123; // QTZ-336 A job might have been completed in the mean time and we might have // missed the scheduled changed signal by not waiting for the notify() yet // Check that before waiting for too long in case this very job needs to be // scheduled very soon if (!isScheduleChanged()) &amp;#123; sigLock.wait(timeUntilContinue); &amp;#125; &amp;#125; &amp;#125; catch (InterruptedException ignore) &amp;#123; &amp;#125; &amp;#125; &amp;#125; catch(RuntimeException re) &amp;#123; getLog().error(\"Runtime error occurred in main trigger firing loop.\", re); &amp;#125; &amp;#125; // while (!halted) // drop references to scheduler stuff to aid garbage collection... qs = null; qsRsrcs = null; &amp;#125; JobRunShell的作用 JobRunShell instances are responsible for providing the ‘safe’ environment for Job s to run in, and for performing all of the work of executing the Job, catching ANY thrown exceptions, updating the Trigger with the Job’s completion code, etc. A JobRunShell instance is created by a JobRunShellFactory on behalf of the QuartzSchedulerThread which then runs the shell in a thread from the configured ThreadPool when the scheduler determines that a Job has been triggered. JobRunShell 用来为 Job 提供安全的运行环境的，执行 Job 中所有的作业，捕获运行中的异常，在任务执行完毕的 时候更新 Trigger 状态，等等。 JobRunShell 实例是用 JobRunShellFactory 为 QuartzSchedulerThread 创建的，在调度器决定一个 Job 被触发的时候， 它从线程池中取出一个线程来执行任务。 7.1.5 线程模型总结SimpleThreadPool：包工头，管理所有 WorkerThread WorkerThread：工人，把 Job 包装成 JobRunShell，执行 QuartSchedulerThread：项目经理，获取即将触发的 Trigger，从包工头出拿到 worker，执行 Trigger 绑定的任务 7.2 绑定JobDetail和Trigger //存储JobDetail和Trigger resources.getJobStore().storeJobAndTrigger(jobDetail, trig); // 通知相关的Listener notifySchedulerListenersJobAdded(jobDetail); notifySchedulerThread(trigger.getNextFireTime().getTime()); notifySchedulerListenersSchduled(trigger); 7.3 启动调度器 // QTZ-212 : calling new schedulerStarting() method on the listeners // right after entering start() // 通知监听器 notifySchedulerListenersStarting(); if (initialStart == null) &amp;#123; initialStart = new Date(); this.resources.getJobStore().schedulerStarted(); startPlugins(); &amp;#125; else &amp;#123; resources.getJobStore().schedulerResumed(); &amp;#125; // 通知QuartzSchedulerThread 不再等待, 开始干活 schedThread.togglePause(false); getLog().info( \"Scheduler \" + resources.getUniqueIdentifier() + \" started.\"); // 通知监听器 notifySchedulerListenersStarted(); 7.4 源码总结getScheduler 方法创建线程池 ThreadPool，创建调度器 QuartzScheduler，创建 调度线程 QuartzSchedulerThread，调度线程初始处于暂停状态。 scheduleJob 将任务添加到 JobStore 中。 scheduler.start()方法激活调度器，QuartzSchedulerThread 从 timeTrriger 取出待 触 发 的 任 务 ， 并 包 装 成 TriggerFiredBundle ， 然 后 由 JobRunShellFactory 创 建 TriggerFiredBundle 的 执 行 线 程 JobRunShell ， 调 度 执 行 通 过 线 程 池 SimpleThreadPool 去执行 JobRunShell，而 JobRunShell 执行的就是任务类的 execute 方法：job.execute(JobExecutionContext context)。 7.5 集群原理基于数据库,如何实现任务的不重跑不漏跑. 问题1: 如果任务执行中的资源是”下一个即将触发的任务”, 怎么基于数据库实现这个资源的竞争的? 问题2: 怎么对数据进行行加锁? QuartzSchedulerThread 第287行, 获取下一个即将触发的Trigger triggers = qsRsrcs.getJobStore().acquireNextTriggers( 调用 JobStoreSupport 的 acquireNextTriggers()方法，2793 行 调用 JobStoreSupport.executeInNonManagedTXLock()方法，3829 行： return executeInNonManagedTXLock(lockName 尝试获取锁,3843行 transOwner = getLockHandler().obtainLock(conn, lockName); 下面有回滚和释放锁的语句, 即时发生异常,锁同样能够释放. 调用 DBSemaphore 的 obtainLock()方法，103 行 public boolean obtainLock(Connection conn, String lockName) throws LockException &amp;#123; if(log.isDebugEnabled()) &amp;#123; log.debug( \"Lock '\" + lockName + \"' is desired by: \" + Thread.currentThread().getName()); &amp;#125; if (!isLockOwner(lockName)) &amp;#123; executeSQL(conn, lockName, expandedSQL, expandedInsertSQL); if(log.isDebugEnabled()) &amp;#123; log.debug( \"Lock '\" + lockName + \"' given to: \" + Thread.currentThread().getName()); &amp;#125; getThreadLocks().add(lockName); //getThreadLocksObtainer().put(lockName, new // Exception(\"Obtainer...\")); &amp;#125; else if(log.isDebugEnabled()) &amp;#123; log.debug( \"Lock '\" + lockName + \"' Is already owned by: \" + Thread.currentThread().getName()); &amp;#125; return true; &amp;#125; 调用org.quartz.impl.jdbcjobstore.DBSemaphore#executeSQL 方法. 最终调用JDBC 执行SQL语句, 语句内容是expandedSQL 和 expandedInsertSQL。 ps = conn.prepareStatement(expandedSQL); 问题：expandedSQL 和 expandedInsertSQL 是一条什么 SQL 语句？似乎我们没 有赋值？ 在StdRowLockSemaphore 的构造函数中, 把定义的两条SQL 传进去 public StdRowLockSemaphore() &amp;#123; super(DEFAULT_TABLE_PREFIX, null, SELECT_FOR_LOCK, INSERT_LOCK); &amp;#125; public static final String SELECT_FOR_LOCK = \"SELECT * FROM \" + TABLE_PREFIX_SUBST + TABLE_LOCKS + \" WHERE \" + COL_SCHEDULER_NAME + \" = \" + SCHED_NAME_SUBST + \" AND \" + COL_LOCK_NAME + \" = ? FOR UPDATE\"; public static final String INSERT_LOCK = \"INSERT INTO \" + TABLE_PREFIX_SUBST + TABLE_LOCKS + \"(\" + COL_SCHEDULER_NAME + \", \" + COL_LOCK_NAME + \") VALUES (\" + SCHED_NAME_SUBST + \", ?)\"; 他调用了父类**DBSemaphore**的构造函数 public DBSemaphore(String tablePrefix, String schedName, String defaultSQL, String defaultInsertSQL) &amp;#123; this.tablePrefix = tablePrefix; this.schedName = schedName; setSQL(defaultSQL); setInsertSQL(defaultInsertSQL); &amp;#125; 在 setSQL()和 setInsertSQL()中为 expandedSQL 和 expandedInsertSQL 赋值。 执行的SQL语句: select * from QRTZ_LOCKS t where t.lock_name='TRIGGER_ACCESS' for update 在我们执行官方的建表脚本的时候,QRTZ_LOCKS 表,他会为每个调度器创建两行数据， 获取Trigger 和触发Trigger是两把锁 7.6 任务为什么重复执行?在多个调度器中,任务没有重复执行, 也就是默认会加锁, 什么情况下不会上锁呢? JobStoreSupport 的 executeInNonManagedTXLock() 方法 如果lockName 为空, 则不上锁. protected &lt;T> T executeInNonManagedTXLock( String lockName, TransactionCallback&lt;T> txCallback, final TransactionValidator&lt;T> txValidator) throws JobPersistenceException &amp;#123; boolean transOwner = false; Connection conn = null; try &amp;#123; if (lockName != null) &amp;#123; // If we aren't using db locks, then delay getting DB connection // until after acquiring the lock since it isn't needed. if (getLockHandler().requiresConnection()) &amp;#123; conn = getNonManagedTXConnection(); &amp;#125; transOwner = getLockHandler().obtainLock(conn, lockName); &amp;#125; if (conn == null) &amp;#123; conn = getNonManagedTXConnection(); &amp;#125; final T result = txCallback.execute(conn); try &amp;#123; commitConnection(conn); &amp;#125; catch (JobPersistenceException e) &amp;#123; rollbackConnection(conn); if (txValidator == null || !retryExecuteInNonManagedTXLock(lockName, new TransactionCallback&lt;Boolean>() &amp;#123; @Override public Boolean execute(Connection conn) throws JobPersistenceException &amp;#123; return txValidator.validate(conn, result); &amp;#125; &amp;#125;)) &amp;#123; throw e; &amp;#125; &amp;#125; Long sigTime = clearAndGetSignalSchedulingChangeOnTxCompletion(); if(sigTime != null &amp;&amp; sigTime >= 0) &amp;#123; signalSchedulingChangeImmediately(sigTime); &amp;#125; return result; &amp;#125; catch (JobPersistenceException e) &amp;#123; rollbackConnection(conn); throw e; &amp;#125; catch (RuntimeException e) &amp;#123; rollbackConnection(conn); throw new JobPersistenceException(\"Unexpected runtime exception: \" + e.getMessage(), e); &amp;#125; finally &amp;#123; try &amp;#123; releaseLock(lockName, transOwner); &amp;#125; finally &amp;#123; cleanupConnection(conn); &amp;#125; &amp;#125; &amp;#125; 而上一步 JobStoreSupport 的 acquireNextTriggers()方法， 如果acquireTriggersWithinLock=true 或 者 batchTriggerAcquisitionMaxCount&gt;1 时 ， locaName 赋 值 为 LOCK_TRIGGER_ACCESS，此时获取 Trigger 会加锁。 否则，如果 isAcquireTriggersWithinLock()值是 false 并且 maxCount=1 的话， lockName 赋值为 null，这种情况获取 Trigger 下不加锁。 public List&lt;OperableTrigger> acquireNextTriggers(final long noLaterThan, final int maxCount, final long timeWindow) throws JobPersistenceException &amp;#123; String lockName; if(isAcquireTriggersWithinLock() || maxCount > 1) &amp;#123; lockName = LOCK_TRIGGER_ACCESS; &amp;#125; else &amp;#123; lockName = null; &amp;#125; return executeInNonManagedTXLock(lockName, new TransactionCallback&lt;List&lt;OperableTrigger>>() &amp;#123; public List&lt;OperableTrigger> execute(Connection conn) throws JobPersistenceException &amp;#123; return acquireNextTrigger(conn, noLaterThan, maxCount, timeWindow); &amp;#125; &amp;#125;, new TransactionValidator&lt;List&lt;OperableTrigger>>() &amp;#123; public Boolean validate(Connection conn, List&lt;OperableTrigger> result) throws JobPersistenceException &amp;#123; try &amp;#123; List&lt;FiredTriggerRecord> acquired = getDelegate().selectInstancesFiredTriggerRecords(conn, getInstanceId()); Set&lt;String> fireInstanceIds = new HashSet&lt;String>(); for (FiredTriggerRecord ft : acquired) &amp;#123; fireInstanceIds.add(ft.getFireInstanceId()); &amp;#125; for (OperableTrigger tr : result) &amp;#123; if (fireInstanceIds.contains(tr.getFireInstanceId())) &amp;#123; return true; &amp;#125; &amp;#125; return false; &amp;#125; catch (SQLException e) &amp;#123; throw new JobPersistenceException(\"error validating trigger acquisition\", e); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; acquireTriggersWithinLock 变量默认是 false： private boolean acquireTriggersWithinLock = false; maxCount 来自 QuartzSchedulerThread： triggers = qsRsrcs.getJobStore().acquireNextTriggers( now + idleWaitTime, Math.min(availThreadCount, qsRsrcs.getMaxBatchSize()), qsRsrcs.getBatchTimeWindow()); getMaxBatchSize()来自 QuartzSchedulerResources，代表 Scheduler 一次拉取 trigger 的最大数量，默认是 1： private int maxBatchSize = 1; 这个值可以通过参数修改, 代表允许调度程序节点获取(用于触发)的触发器的最大量,默认值是1 org.quartz.scheduler.batchTriggerAcquisitionMaxCount=1 根据以上两个默认值，理论上在获取 Trigger 的时候不会上锁，但是实际上为什么没 有出现频繁的重复执行问题？因为每个调度器的线程持有锁的时间太短了，单机的测试 无法体现，而在高并发的情况下，有可能会出现这个问题。 QuartzSchedulerThread 的 triggersFired()方法： List&lt;TriggerFiredResult> res = qsRsrcs.getJobStore().triggersFired(triggers); 调用了 JobStoreSupport 的 triggersFired()方法，接着又调用了一个 triggerFired triggerFired(Connection conn, OperableTrigger trigger)方法： 如果 Trigger 的状态不是 ACQUIRED，也就是说被其他的线程 fire 了，返回空。但 是这种乐观锁的检查在高并发下难免会出现 ABA 的问题，比如线程 A 拿到的时候还是ACQUIRED 状态，但是刚准备执行的时候已经变成了 EXECUTING 状态，这个时候就会 出现重复执行的问题。 if (!state.equals(STATE_ACQUIRED)) &amp;#123; return null; &amp;#125; 总结，如果： 如果设置的数量为 1（默认值），并且使用 JDBC JobStore（RAMJobStore 不支持 分 布 式 ， 只 有 一 个 调 度 器 实 例 ， 所 以 不 加 锁 ） ， 则 属 性 org.quartz.jobStore.acquireTriggersWithinLock 应设置为 true。否则不加锁可能会导 致任务重复执行。 8. Quzrtz-Misfire**什么情况下会错过触发? 错过触发怎么样? ** 线程池只有5个线程,当有5个任务都在执行的时候,第六个任务即将触发,这个时候任务就不能得到执行.在quartz.properties中有一个属性misfireThresh,用来定义触发器超时的临界值, 也就是超过了这个时间,就算错过了触发. 例如, 如果misfireThresh 是6000(6秒),9点整应该执行的任务, 9点零1分还没有可用的线程去执行它,就是超时(misfires) 下面这些原因可能造成misfires job: 没有可用的线程 Trigger被暂停 系统重启 禁止并发执行的任务在到达触发时间的时候,上次执行的任务还没有结束. 错过触发怎么办? misfire 策略设置: 每一种Trigger 都定义了自己的 Misfire 策略,不同的策略通过不同的方法来设置, // Trigger1 Trigger trigger = TriggerBuilder.newTrigger().withIdentity(\"trigger1\", \"group1\").startNow() .withSchedule(SimpleScheduleBuilder.simpleSchedule(). withMisfireHandlingInstructionNowWithExistingCount(). withIntervalInSeconds(1). repeatForever()).build(); 大体来说 , 可以分为三种: 忽略 立即跑一次 下次跑 详细内容参考： Quartz Scheduler misfireThreshold属性的意义与触发器超时后的处理策略 quartz-misfire 错失、补偿执行 怎么避免任务错过触发: 合理的设置线程池数量,以及任务触发间隔.","categories":[{"name":"任务调度","slug":"任务调度","permalink":"https://rainsoil.github.io/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"},{"name":"任务调度","slug":"任务调度/任务调度","permalink":"https://rainsoil.github.io/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"}],"tags":[]},{"title":"分布式架构的演进过程(1)","slug":"分布式/1. 漫谈分布式架构/分布式架构的演进过程(1)","date":"2022-01-04T02:42:07.261Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/fen-bu-shi/1.man-tan-fen-bu-shi-jia-gou/fen-bu-shi-jia-gou-de-yan-jin-guo-cheng-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/fen-bu-shi/1.man-tan-fen-bu-shi-jia-gou/fen-bu-shi-jia-gou-de-yan-jin-guo-cheng-1/","excerpt":"","text":"分布式架构的演进过程架构的本质一个软件系统随着功能越来越多,调用量急剧增长,整个系统逐渐碎片化,越来越无序,最终无法维护和扩展,所以系统在一段时间的野蛮生长之后,也需要及时干预,避免越来越无序.架构的本质就是对系统进行有序化的重构,使系统不断进化, 那架构是怎么实现无序带有序的呢？基本的手段就是分和合,先把系统打散,然后重新组合.分的过程是把系统拆分成各个子系统/模块/组件.拆的时候,首先要解决每个组件的定位问题,然后才能划分彼此的边界,实现合理的拆分.合就是根据最终要求,把各个分离的组件有机整合在一起,相对来说,第一步的拆分更难. 拆分的结果使得开发人员能够做到业务聚焦,技能聚焦,实现开发敏捷,合的结果是系统变得柔性,可以因需而变,实现业务敏捷. 架构的分类架构一般可以分为业务架构、应用结构、技术结构。 业务架构从概念层面帮助开发人员更好的理解系统,比如 业务流程、业务模块、输入输出、业务域. 应用架构从逻辑层面帮助开发落地系统,如数据交互关系、应用形式、交互方式、使得整个系统逻辑上更容易理解.比如大家熟知的SOA就属于应用架构的范畴. 技术架构主要解决技术平台选型,如操作系统、中间件、设备、多机房、水平扩展、高可用等问题 需要注意的是,系统或者架构首先都是为人服务的,系统的有序度高,使用逻辑合理,业务概念清晰是第一位,现在大家讨论的更多的是技术架构,如高并发设计、分布式事务等等,只是因为这个不需要业务上下文背景,比较好相互沟通.具体架构设计时,首先要关注业务架构和应用架构,这个架构新手要特别注意,也是面试时候的痛点. 大型网站的架构演进 ps: 以下内容部分图片参考《大型网站系统与java中间价实战.pdf》 从一个电商网站开始为了更好的理解,我们用电商网站来举例,作为一个交易类型的网站,一定会具备用户(用户注册、用户管理)、商品(商品展示、商品管理)、交易(下单、支付)这些功能,加入我们只需要支持这几个基本的功能,那么我们最开始的架构应该可能是这样的 这个地方注意的是各个功能模块之间通过JVM内部的方法调用来进行交互的,而应用和数据库之间是通过JDBC进行访问的 单机负载告警,数据库于应用分离随着网站的开发,访问量不断增加,那么这个时候服务器的负载势必会持续增长,必须要采取一些方法来应对,这里先不考虑更换机器和各种软件层面的优化,先从架构的结构上来做一些调整,我们可以把数据库与应用从一台机器分到两台机器上 变化：网站服务器从一台变成了两台,这个变化对我们来说影响非常小.单机的情况下我们应该采用JDBC的方式来和数据库进行连接,现在数据库与应用分开了,我们只需要在配置文件中把数据库的地址从本机改成数据库服务器的ip地址就行. 对于开发、测试、部署都没有影响 调整以后我们能够缓解当前的系统压力,不过随着时间的推移,访问量继续增加的话,我们的系统还是需要改造的. 为什么这么分呢?从计算机的本身的角度来考虑的话，一个请求的访问到处理最终到返回,性能瓶颈只会是:CPU、文件IO、网络IO、内存等因素。而一台计算机中这些维度是性能瓶颈的,如果某个资源消耗过多,通常会造成系统的响应速度较慢,所以增加一台机器,使得数据库的IO和CPU资源独占一台机器从而增加性能. 这个地方插入一点题外话,就是检点说一下各个资源的消耗原因: CPU/IO/内存: 主要上下文的切换,因为每个CPU核心在同一时刻只能执行一个线程,而CPU的调度有几种方式，比如抢占式和轮询,以抢占式为例,每个线程会分配一定的执行时间,当达到执行时间,线程中有IO阻塞或者有高优先级的线程要执行时,CPU会切换执行其他线程. 而在切换的过程中,需要存储当前线程的执行状态并恢复要执行线程的线程状态,这个过程就是上下文切换. 比如IO、锁等待等场景也会触发上下文切换,当上下文切换过多就会造成内核占用比较多的CPU 文件IO,比如频繁的日志写入,磁盘本身的处理速度较慢,都会造成IO性能问题。 网络IO问题,带宽不够 内存:包括内存溢出、内存泄漏、内存不足 实际上不管是应用层的调优也好,还是硬件的升级也好,其实无非就是这几个因素的调整. 应用服务器复杂告警,如何让应用服务器走向集群假如说这个时候应用服务器的压力变大了,根据对应用的检测结果,可以针对性的对性能压力大的地方进行优化.我们这里考虑通过水平扩容来进行优化,把单机变集群, 应用服务器从一台变成两台,这两个应用服务器之间没有直接的交互,他们都依赖数据库对外提供服务,那么这个时候会抛出两个问题 最终用户对应两个应用服务器访问的选择,对于这个问题,可以采用DNS解决,也可以通过负载均衡设备来解决 session 的问题 水平和垂直扩容对于大型的分布式架构而言,我们一直在追求一种简单,优雅的方式来应对访问量和数据库的增长.而这种方式通常指的是不需要改动软件程序,仅仅通过硬件升级或者增加机器就可以解决. 而这种就是分布式架构下的伸缩设计, 伸缩分为垂直伸缩和水平伸缩两种 垂直伸缩: 表示通过升级或者增加单台机器的硬件来支持访问量以及数据增长的方式,垂直伸缩的好处在于技术难度比较低,运营和改动成本也相对较低. 但是缺点是机器性能是由瓶颈的,同时升级高性能的小型机或者大型机,成本是非常大的. 这也是阿里去IOE的一个原因之一. 增加CPU核心数: 增加CPU后系统的服务能力能够得到大的增长,比如响应速度,同时可以处理的线程数, 但是引入CPU后也会带来一些显著的问题。 锁竞争加剧: 多个线程同时访问某个共享数据,那么就涉及到了锁竞争,锁竞争激烈的时候会导致很多线程都在等待锁,所以即使增加CPU也无法让线程得到更快的处理. 当然这里也是有调优手段的,可以通过调优手段来降低锁竞争. 支撑并发请求的线程数是固定的,那么即使增加CPU,系统的服务能力也不会得到提升. 对于单线程任务,多核心CPU是没有太大的左右的 增加内存：增加内存可以直接提升系统的响应速度,当然也有可能达不到效果,就是如果JVM堆内存是固定的. 水平伸缩: 通过增加机器来支撑访问量以及数据量增长的方式,称为水平伸缩, 水平伸缩理论上来说没有瓶颈,但是缺点是技术要求比较高,同时给运维带来了更大的挑战. 垂直伸缩和水平伸缩都有各自的特点,我们在实际过程中都会对两者做结合,一方面要考虑硬件升级成本,一方面要考虑软件改造的成本. 引入负载均衡设备服务路由,基于负载均衡设备来实现 引入负载均衡器以后,会带来session相关的问题 负载均衡算法轮询(Round Robin)法将请求按顺序轮流分配到后台服务器上,均衡的对待每一台服务器,而不关心服务器实际的连接数和当前的系统负载. 缺点: 当集群中服务器硬件配置不同,性能差别大的时候,无法区别对待. 随机法通过系统随机函数,根据后台服务器列表的大小值来随机选取其中一台进行访问.随着调用量的增加,其实际效果越来越接近于平均分配流量到后台的每一台服务器上,也就是轮询法的效果. 优点: 简单使用,不需要额外的配置和算法 缺点: 随机数的特点是在数据量大到一定量的时候才能保证均衡,所以如果请求量有限的话,可能会到不到均衡负载的要求, 源地址哈希法根据服务消费者请求客户端的ip地址,通过哈希函数就是计算得到一个哈希值,将这个哈希值和服务器列表的大小进行取模运算,得到的结果便是要访问的服务器地址的序号. 采用源地址哈希法 进行负载均衡,相同的ip客户端,如果服务器列表不变,将映射到同一个后台服务器进行访问, 加权轮询(Weight Round Robin) 法不同的后台服务器可能机器的配置和当前系统的负载并不相同,因为他们的抗压能力也不一样,. 跟配置高,负载低的机器分配更高的权重,使其能处理更多的请求,而配置低,负载高的机器,则给其分配较低的权重,降低其系统负载. 加权轮询很好的处理了这一问题,并将请求按照顺序且根据权重分配给后端. 最小连接数法前面几种方式都是通过将请求次数的合理分配最大可能提高服务器的利用率,但是实际上,请求次数的均衡并不能代表负载的均衡, 所以,引入了最小连接数法. 它正是根据后端服务器当前的链接情况,动态的选取其中当前积压连接数最少的一台服务器来处理当前请求,尽可能的提高后台服务器利用率,将负载合理的分流到每一台服务器, session问题我们打开一个网页，基本上需要浏览器和web服务器进行多次交互,我们都知道http协议本身是无状态的,这也是http协议设计的初衷,客户端只需要简单的向服务器请求下载某些文件,无论是客户端还是服务器都没必要记录彼此过去的行文,每一次请求之间是独立的,好比一个顾客和一个自动售货机之间的关系一样. 而实际上,我们很多的场景都需要带有状态的特性,因此聪明的我们引入了 session+cookie 机制来记住每次请求的会话. 在会话开始时,给当前会话分配一个唯一的会话标识(sessionId),然后通过cookie 把这个标识告诉浏览器,以后在每次请求的时候,浏览器都会带上这个会话标识来告诉web服务器请求属于哪个会话. 在web服务器上,各个会话有独立的存储,保存不同会话的信息,如果遇到禁用cookie的情况,一般的做法就是把这个会话标识放到url参数中. 而我们的应用服务器从一台变成两台之后,就会遇到session问题 分布式环境下的session共享session共享在当前这个互联网背景下,已经不是一个新鲜的话题了, 而且如何解决session共享其实也有很多非常成熟的方案. 服务器实现的session复制 或session共享,这类型的共享session是和服务器紧密相关的. 我们在WEB服务器之间增加了会话数据的同步,通过同步就保证了不同WEB 服务器之间Session数据的一致. 一般应用容器都支持Session Replication 方式. 存在问题: 同步session数据 造成了网络带宽的开销, 只要Session 数据有变化,就需要将数据同步到所有的其他机器上,机器越多,同步带来的网络带宽开销就越大. 每台web服务器都要保存所有Session 数据,如果整个集群的Session 数据很多(很多人同时访问网站)的话,每台机器用于保存Session 数据的内存占用会很严重的, 这个方案是靠应用容器来完成Session复制从而解决Session问题的,应用本身并不关心这个事情,这个方案不适合集群机器数多的场景. 利用成熟的技术做Session复制,比如12306使用的gemfire,比如常见的内存数据库如Redis Session数据不保存本机而且存放到一个集中存储的地方,修改Session 也是发生在集中存储的地方.Web 服务器使用Session 从集中存储的地方读取. 这样保证了不同WEB 服务器读取到的Session 数据都是一样的, 存储Session的具体方式可以是数据库. 存在问题: 读写Session数据引入了网络操作,这相对于本机的数据读取来说,问题就在于存在延时和不稳定性,不过我们的通讯基本都是发生在内网,问题不大. 如果集中存储Session的机器或者集群有问题,就会影响到我们的应用. 相对于Session Replication ,当Web服务器数量大,Session数比较多的时候,这个集中存储的方案的优势还是非常明显的. 将session维护在客户端很容易想到的就是利用Cookie,但是客户端存在风险,数据不安全,而且可以存放的数据量比较小,所以在session维护在客户端还要对Session中的信息加密 我们的Session数据放到Cookie中,然后在web服务器上从cookie中生成对应的Session数据, 这就好比我们每次都把自己的碗筷带在身上,这样去哪家饭店吃饭就可以随便选择了. 相对于前面的集中存储方案,不会依赖外部的存储系统,也就不存在从外部系统获取,写入Session数据的网络延时,不稳定性了, 存在问题: 安全性: Session数据本来都是服务器数据,而这个方案是让这些服务端数据到了外部网络及客户端,因此存在安全性上的问题, 我们可以对写入的Cookie上的Session数据做加密,不过对于安全来说,物理上不接触才是安全的. 数据库压力变大,读写分离随着业务的继续增长,数据量和访问量持续增加,对于大型网站来说,有不少业务是读多写少,这个情况也会直接反馈到数据库上. 那么对于这种情况来说,我们可以考虑采用读写分离的方式来优化数据库的压力. 这个结构的变化会带来两个问题: 数据同步 我们希望通过读库来分担主库上读的压力,数据库一般都提供了数据复制的能力,比如Mysql支持 Master-slave 应用对数据库如何路由 对于应用来说,增加一个读库对结构变化产生了变化,应用应该根据不同的情况来选择不同的数据库源 搜索引擎其实就是一个读库搜索引擎其实可以理解成一个读库,我们的商品存储在数据库中,而网站需要提供用户实时检索的功能,尤其是在商品搜索这块. 对于这样的读请求.如果全部走读库,其实性能也会存在一个瓶颈, 而使用搜索引擎,不仅仅能大大的提高检索速度,还能减轻读数据库的压力,而搜索引擎最重要的工作,就是需要根据被搜索的数据来构建索引,而随着被搜索的数据的变化,索引也需要相应的变化, 加速数据读取的利器-缓存以及分布式存储在大型网站中,基本上就是在解决存储和计算的问题,所以存储是一个很重要的支撑系统. 网站建设初期我们都是从关系型数据库开始的,而且很多时候为了方便,我们会把一些业务的逻辑放在数据库里面去做,比如触发器、存储过程. 虽然在前期能够很方便的解决问题,但是在未来的发展过程中会带来很多的麻烦,比如数据量大了以后,要做分库分表等操作. 同时,业务发展到了一定的量以后,对存储的需要不能完全通过关系型数据库来满足. 分布式文件系统对一些图片、大文本,使用数据库就不合适了,所以我们会采用分布式文件系统来实现文件存储,分布式文件系统有很多产品,比如淘宝的TFS、google的GFS、还有开源的HDFS NoSQLNoSQL 我们可以理解为Not Only SQL,或者是No SQL. 两种意思都是为了表达在大型网站中,关系型数据库可以解决大部分的问题,但是对于不同内容的特征、访问特征、事务特征等对存储的要求是不一样的. NoSQL 是定位于文件系统和SQL 关系型数据库之间的范畴. 数据缓存大型网站内部都会用到一些数据缓存,主要用于分担数据库的读的压力,缓存系统一般是用来保存和查询键值对的. 应用系统中一般会把热点数据放入到缓存中,而缓存的填充也应该是由应用系统完成的, 如果数据不存在,则从数据库读出数据后放入到缓存中. 随着时间的推移,当缓存的容量不够需要清除数据的时候,最近不被访问的数据就会被清理掉. 还有一种方式就是在数据库的数据发生变化后,主动把数据放入到缓存系统中,这样的好处是数据变化的时候能够及时的更新缓存的数据,不会造成读取失效. 页面缓存除了数据缓存外, 我们还可以对页面做缓存,数据缓存可以加速应用在响应请求时的数据读取速度,但是最终展示给用户的还是页面,有些动态产生的页面或者访问量特别高的页面,我们会对页面或者内容做一些缓存。 弥补关系型数据库的不足,引入分布式存储我们应用最好的主要还是关系型数据库,但是在有些场景下，关系型数据库不是很合适,. 所以我们会引入分布式存储系统,比如redis、mongoDB、cassandra、HBase等. 根据不同的场景和数据结构类型,选择合适的分布式存储系统可以极大的提高性能. 分布式系统通过集群提供一个高容量、高并发访问、数据冗余的支持. 读写分离后,数据库又遇到瓶颈通过读写分离以及在某些场景用分布式存储系统替换关系型数据库的方式,能够降低主库的压力,解决数据存储方面的问题,不过随着业务的发展,我们的主库也会遇到瓶颈. 推演到现在,我们的网站的各个模块:交易、商品、用户数据都还是存储在同一个数据库,尽管增加了缓存、读写分离的方式,但是数据库的压力仍然在持续的增加,因此我们可以对数据垂直拆分和水平拆分来解决数据库压力的问题。 专库专用,数据垂直拆分垂直拆分的意思是把数据库中不同的业务数据拆分到不同的数据库中,那么根据我们推演的例子,把用户、交易、商品的数据分开 不同的业务的数据从原来的一个数据库拆分到了多个数据库中,那么就需要考虑到如何处理原来单机跨业务的事务. 使用分布式事务解决 去掉事务或者不追求事物的支持 对数据进行垂直拆分后,解决了把所有业务数据放在一个数据库中的压力问题,并且也可以根据不同业务的特点进行更多的优化. 垂直拆分后,遇到瓶颈,数据水平拆分与垂直拆分对应的还是数据水平拆分,数据水平拆分就是把同一个表的数据拆分到两个数据库中,产生数据水平拆分的原因是某个业务的数据表的数据量或者更新量达到了单个数据库的瓶颈,这个时候就可以把表拆到两个或者多个数据库中, 数据水平拆分于读写分离的区别是:,读写分离解决的是读压力大的问题,对于数据量大的或者更新量大的情况并不起作用. 数据水平拆分于数据垂直拆分的区别是: 垂直拆分是把不同的表拆分到不同的数据库中,而水平拆分是把同一个表拆分到不同的数据库中. 我们可以进一步把用户表拆分到两个数据库中,他们拥有结构一模一样的用户表,而且每个库中的用户表都只涵盖了一部分用户,两个数据库的用户和在一起就相当于没有拆分之前的用户表. 水平拆分带来的影响 sql路由问题,需要根据一个条件来决定当前请求发到哪个数据库中 主键的处理,不能采用自增id,需要全局id 由于同一个业务的数据被拆分到不同的数据库,因此涉及到一些查询需要跨两个数据库获取,如果数据量太大并且需要分页,就比较难处理了. 数据库问题解决后,应用面对的挑战前面讲的读写分离、分布式存储、数据垂直拆分和水平拆分都是解决数据方面的问题,接下来我们要看看应用方面的变化. 随着业务的发展,应用的功能会越来越多,应用也会越来越大.我们需要思考如何不让应用持续变大,这就需要把应用分开,从一个应用变为两个甚至多个. 第一种方式: 根据业务的特性把应用拆分,在我们的例子中,主要业务功能分为三个部分 用户、商品、交易.我们可以把原来的一个应用拆分成分别以交易和商品为主的两个应用, 对于交易和商品都会有涉及到用户的地方,我们让这两个系统自己完成涉及用户的操作,而类似于用户注册、登录等的基础的用户工作,可以暂时交给这两个系统中的任何一个来完成, 我们还可以按照用户注册、用户登录、用户信息维护等再拆分,变成三个系统. 不过这样拆分后不同系统中会有一些相似的代码, 比如用户相关的代码,如何能保障这部分代码的一致以及如何对其他模块提供复用也是需要解决的问题. 而且, 这样拆分出来的新系统之间没有直接的相互调用 服务化道路我们再来看一下服务化的做法,我们把应用分为三层,处于最上端的是web系统,用于完成不同的业务功能,处于中间的是一些服务中心,不同的服务中心提供不同的业务服务,处于最下层的则是业务的数据库。 与之前相比的有几个重要的变化,首先业务功能之间的访问不仅仅是单机内部的方法调用.还引入了远程的服务调用. 其次,共享代码不再是散落在不同的应用中,这些实现被放在各个服务中心. 最后,数据库的链接也发生了一些变化, 我们把数据库的交互工作放到了服务中心,让前端的web应用更加注重于浏览器的交互工作,而不必过多的关注业务逻辑的事情. 链接数据库的任务交给相应的业务服务中心,这样可以降低数据库的连接数, 而服务中心不仅把一些可以共同的代码集中管理,而且还使得这些代码变得好维护, 服务化的方式会带来很多好处,首先,从结构上来看,系统架构更加清晰了, 比原本的架构更加立体,. 从稳定性上看, 一些散落在多个应用系统中的代码变成了服务并由专门的团队进行统一维护,一方面可以提高代码的质量,另一方面由于基础核心模块相对稳定,修改和发布的频次相对于业务系统来说会少很多,这也会提高整个架构的稳定性. 最后,更加底层的资源由服务层统一管理,架构更加清晰,对于团队开发效率来说有比较大的提高. 服务化的方式,对于研发也会有很大的影响,以前的开发模式是几个大团队负责几个大的应用,随着服务化的落地,我们的应用数量也会飞速增加, 系统内部的依赖关系也会变得错综复杂,同时团队也进行了拆分,每个小团队专注于某个具体的服务或者应用上,迭代效率也会更高. 什么是分布式架构分布式架构的定义简单来说,分布式系统是指位于网络计算机上的组件仅通过传递消息来通信和协调目标系统. 这里面有两个重要因素: 组件是分布在网络计算机上的 组件之间仅仅是通过消息传递来通信并协调行动的. 分布式系统其实也可以认为是一种去中心化的实现思路,对于用户来说是无感知的. 分布式架构的意义从单机单用户到单机多用户,再到现在的网络时代,应用系统发生了很多的变化,为什么还要用分布式系统呢? 升级单机处理能力的性价比越来越低 单机处理能力存在瓶颈 对于稳定性和可用性的要求 我们知道,单台机器的处理能力包括CPU、内存、磁盘和网络 大家听说过摩尔定律吧,当价格不变的时候,每隔18个月,集成电路上可容纳的晶体管数量会增加一倍,性能也会增加一倍. 意味着随着时间的推移,单位成本的支出所能购买的计算能力在提升,但是我们要求处理器的性能越高,所需要付出的成本也就越高. 所以通过不断提升单台机器的性能锁带来的产值是不划算的, 同时, 处理器本身也存在性能瓶颈. 还有一个很重要的因素, 稳定性和可用性方面,在单机环境中是提供不了的, 所以势必需要分布式系统来解决.","categories":[{"name":"1. 漫谈分布式架构","slug":"1-漫谈分布式架构","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"},{"name":"分布式","slug":"1-漫谈分布式架构/分布式","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式","slug":"1-漫谈分布式架构/分布式/分布式","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"1. 漫谈分布式架构","slug":"1-漫谈分布式架构/分布式/分布式/1-漫谈分布式架构","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"}],"tags":[]},{"title":"spring 注解大全(12)","slug":"spring/spring 注解大全(12)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-zhu-jie-da-quan-12/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-zhu-jie-da-quan-12/","excerpt":"","text":"Spring 注解大全核心注解 注解 介绍 @Documented 将会在被此注解注解的元素的javadoc文档中列出注解，一般都打上这个注解没坏处 @Target 注解能被应用的目标元素，比如类、方法、属性、参数等等 @Retention @Inherited 如果子类没有定义注解的话，能自动从父类获取定义了继承属性的注解，比如Spring的@Service是没有继承特性的，但是@Transactional是有继承特性的，在OO继承体系中使用Spring注解的时候请特别注意这点，理所当然认为注解是能被子类继承的话可能会引起不必要的Bug，需要仔细斟酌是否开启继承 @Repeatable Java 8 引入的特性，通过关联注解容器定义可重复注解，小小语法糖提高了代码可读性，对于元素有多个重复注解其实是很常见的事情，比如某方法可以是A角色可以访问也可以是B角色可以访问，某方法需要定时任务执行，要在A条件执行也需要在B条件执行 @Native 是否在.h头文件中生成被标记的字段，除非原生程序需要和Java程序交互，否则很少会用到这个元注解 spring 核心注解 注解 介绍 @Controller 定义表现层组件 @Service 定义业务逻辑层组件 @Repository 定义数据访问层组件 @Component 定义其他组件 @Autowired 自动装配 @Required 用于在setter方法标记属性值需要由Spring 进行装配,目前这个方法已经被spring 废弃,推荐使用构造方法注入 @Qualifier 用于给Bean定义修饰语来注入相应的bean @Value 用于注入属性配置或者Spel表达式 @Lookup 可以实现方法的注入,如果我们的类是单例的,但是又希望Spring注入的依赖的对象是Prototype生命周期（每次new一个出来）的，这个时候可以通过此注解进行方法注入 @EnableTransactionManagement 用于开启事务管理，使用Spring Boot如果引入Spring Data的话不需要手动开启（不过建议大家在使用事务的时候还是通过日志来验证事务管理是否生效） @Transactional 用于开启事务以及设置传播性、隔离性、回滚条件等； @TransactionalEventListener 用于配置事务的回调方法，可以在事务提交前、提交后、完成后以及回滚后几个阶段接受回调事件。 @Order 可以设置Spring管理对象的加载顺序，在之前介绍AOP的文章中我们看到有的时候我们必须通过设置合理的@Order来合理安排切面的切入顺序避免一些问题，还有在一些业务场景中，我们往往会去定义一组类似于Filter的@Component，然后会从容器获得一组Bean，这个时候业务组件的运行顺序往往会比较重要，也可以通过这个方式进行排序 @AliasFor 注解可以设置一组注解属性相互作为别名，对于有歧义的时候会使代码更清晰，此外还有一个用途是创建复合注解，Spring MVC的@GetMapping注解就是基于@RequestMapping这个注解创建的复合注解，我们可以很方便得通过这种方式来实现注解的继承 spring 上下文注解 注解 解释 @Configuration 用于标注配置类，启用Java配置方式的Bean配置 @Bean 用于配置一个Bean @ComponentScan （@ComponentScans用于配置一组@ComponentScan，Java 8可以直接使用重复注解特性配置多个@ComponentScan）用于扫描包方式配置Bean； @PropertySource 以及 @PropertySources用于导入配置文件； @Conditional 用于设置关联的条件类，在合适的时候启用Bean的配置（Spring Boot自动配置根基） @Import 用于导入其他配置类 @ImportResource 用于导入非java配置方式的XML配置 @Profile 用于指定在核实的Profile下启动配置 @Lazy 用于告知容器延迟到使用的时候实例化Bean @Description 用于给Bean设置描述 @Scope 用于设置Bean的生命周期 @Primary 用于在定义多个Bean的时候指定首选的Bean @EventListener 用于设置回调方法监听Spring指定的以及自定义的各种事件 @EnableAspectJAutoProxy 用于开启支持Aspectj的@Aspect的切面配置支持,使用Spring Boot引入了AOP启动器的话不需要显式开启 Spring Web 注解 注解 解释 @RequestScope bean 跟随请求的生命周期创建 @SessionScope Bean 跟随会话的生命周期创建 @ApplicationScope Bean 跟谁应用程序的生命周期创建 @ResponseStatus 可以用到方法上,也可以用到异常上,前者会直接使请求得到指定的响应代码或者原因(可以配合@ExpectionHandler使用),后者可以实现遇到指定的异常的时候给出指定的相应代码或原因 @ResponseBody 将返回的内容序列化之后输出到请求体 @RequestBody 接受请求数据 @RequestHeader 从header中获取 @CookieValue 从cookie 获取 @SessionAttribute 从会话中 @RequestAttribute 从请求的Attribute中（比如过滤器和拦截器手动设置的一些临时数据） @RequestParam 从请求参数（处理简单数据，键值对） @PathVariable 从路径片段 @MatrixAttribute 矩阵变量允许我们采用特殊的规则在URL路径后加参数（分号区分不同参数，逗号为参数增加多个值） @ControllerAdvice 允许我们在集中的地方配置控制器（有@RequestMapping的方法）相关的增强（@RestControllerAdvice也是差不多的，只是相当于为@ExceptionHandler加上了@ResponseBody） @ExceptionHandler 进行统一的全局异常处理； @InitBinder 用来设置WebDataBinder，WebDataBinder用来自动绑定前台请求参数到Model中；第三是 @ModelAttribute让全局的@RequestMapping都能获得在此处设置的键值 SpringBoot 注解 注解 解释 @ConfigurationProperties 很常用（配合 @EnableConfigurationProperties注解来设置需要启用的配置类），用来自定义配置类和配置文件进行关联 @DeprecatedConfigurationProperty 用于标记废弃的配置以及设置替代配置和告知废弃原因； @ConfigurationPropertiesBinding 用于指定自定义的转换器用于配置解析的时的类型转换； @NestedConfigurationProperty 用于关联外部的类型作为嵌套配置类 @EnableAutoConfiguration 可以启用自动配置 @ConditionalOnBean 用于仅当容器中已经包含指定的Bean类型或名称时才匹配条件 @ConditionalOnClass 仅当classpath上存在指定类时条件匹配； @ConditionalOnCloudPlatform 仅当指定的云平台处于活动状态时条件匹配； @ConditionalOnExpression 依赖于SpEL表达式的值的条件元素的配置注解； @ConditionalOnJava 基于应用运行的JVM版本的条件匹配； @ConditionalOnJndi 基于JNDI可用和可以查找指定位置的条件匹配； @ConditionalOnMissingBean 仅当容器中不包含指定的Bean类型或名称时条件匹配； @ConditionalOnMissingClass 仅当classpath上不存在指定类时条件匹配； @ConditionalOnNotWebApplication 仅当不是WebApplicationContext（非Web项目）时条件匹配，对应 @ConditionalOnWebApplication；@ConditionalOnProperty是检查指定的属性是否具有指定的值； @ConditionalOnResource 表示仅当 classpath 上存在指定资源时条件匹配； @ConditionalOnSingleCandidate 仅当容器中包含指定的Bean类并且可以判断只有单个候选者时条件匹配。其实所有这些实现原理都是扩展SpringBootCondition抽象类（实现之前提到的Condition接口），我们完全可以实现自己的条件注解（配合 @Conditional注解关联到自己实现的SpringBootCondition）","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"浅谈分布式事务(13)","slug":"spring/浅谈分布式事务(13)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/qian-tan-fen-bu-shi-shi-wu-13/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/qian-tan-fen-bu-shi-shi-wu-13/","excerpt":"","text":"浅谈分布式事务 现今互联网界，分布式系统和微服务架构盛行。一个简单操作，在服务端非常可能是由多个服务和数据库实例协同完成的。在一致性要求较高的场景下，多个独立操作之间的一致性问题显得格外棘手。 基于水平扩容能力和成本考虑，传统的强一致的解决方案（e.g.单机事务）纷纷被抛弃。其理论依据就是响当当的 CAP 原理。往往为了可用性和分区容错性，忍痛放弃强一致支持，转而追求最终一致性。 分布式系统的特性在分布式系统中，同时满足 CAP 定律中的一致性 Consistency、可用性 Availability 和分区容错性 Partition Tolerance 三者是不可能的。在绝大多数的场景，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证最终一致性。分布式事务服务（Distributed Transaction Service，DTS）是一个分布式事务框架，用来保障在大规模分布式环境下事务的最终一致性。 CAP 理论告诉我们在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的，所以我们只能在一致性和可用性之间进行权衡。 为了保障系统的可用性，互联网系统大多将强一致性需求转换成最终一致性的需求，并通过系统执行幂等性的保证，保证数据的最终一致性。 数据一致性理解：强一致性：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要牺牲可用性。 弱一致性：系统并不保证后续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。 最终一致性：弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS 是一个典型的最终一致性系统。","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"tomcat基础认知(1)","slug":"tomcat/tomcat基础认知(1)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/tomcat/tomcat-ji-chu-ren-zhi-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/tomcat/tomcat-ji-chu-ren-zhi-1/","excerpt":"","text":"tomcat基础认知1. What is Tomcat1.1 Tomcat 官网官网: https://tomcat.apache.org The Apache Tomcat® software is an open source implementation of the Java Servlet, JavaServer Pages, Java Expression Language and Java WebSocket technologies. 1.2 Understand为什么tomcat 是Servlet技术的实现呢? 在我们的理解中,Tomcat 可以被称为web容器或者Servlet容器不妨手写一个tomcat 来推导一下 1.2.1 创建Tomcat类java 是一门面对对象的语言 //这就是我们写的Tomcat class MyTomcat&amp;#123; .... &amp;#125; 1.2.2 web容器思考: 怎么让TOmcat 具备web 服务的功能? 在服务端用Http 来监听, 协议不好写，不妨用java封装好的socket 作为监听 class MyTomcat&amp;#123; ServerSocket server=new ServerSocket(8080); // 等待客户端的连接请求 Socket socket=server.accept(); &amp;#125; 1.2.3 Servlet 容器思考: 怎么样让Tomcat 具有Servlet 容器的功能呢? 说白了就是能够装一个个的Servlet servlet 是啥?public interface Servlet &amp;#123; void init(ServletConfig config) throws ServletException; ServletConfig getServletConfig(); void service(ServletRequest req, ServletResponse res）throws ServletException,IOException; String getServletInfo(); void destroy(); &amp;#125; class LoginServlet extends HttpServlet&amp;#123; doGet(request,response)&amp;#123;&amp;#125; doPost(request,response)&amp;#123;&amp;#125; &amp;#125; &lt;servlet> &lt;servlet-name>LoginServlet&lt;/servlet-name> &lt;servlet-class>com.web.servlet.LoginServlet&lt;/servlet-class> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>LoginServlet&lt;/servlet-name> &lt;url-pattern>/login&lt;/url-pattern> &lt;/servlet-mapping> 1.2.4 优化Tomcatclass MyTomcat&amp;#123; List list=new ArrayList(); ServerSocket server=new ServerSocket(8080); Socket socket=server.accept(); // 把请求和响应都封装在业务代码中的servlet // 只要把业务代码中一个个servlets添加到tomcat中即可 list.add(servlets); &amp;#125; 1.2.5 画个图 1.2.6 获得的信息 tomcat需要支持servlet 规范 tomcat/lib/servlet-api.jar web容器 希望tomcat 源码中也有new ServerSocket(8080) 的代码 servlet 容器 希望tomcat源码中也会有list.add(servlets)的代码 2. 产品和源码2.1 Version Choose这里选择的的Tomcat8.0.11 各个版本下载地址： https://archive.apache.org/dist/tomcat 2.2 产品目录文件含义 bin: 主要用来存放命令,.bat的window下的,.sh是linux下的 conf:主要用来存放tomcat的配置文件 lib: 存放tomcat依赖的一些jar包 logs:存放tomcat 在运行的时候产生的日志文件 temp: 存放运行时产生的临时文件 webapps: 存放应用程序 work: 存放tomcat 运行时编译后的文件, 比如jsp 编译后的文件 2.3 源码导入与调试先从官网下载源码包https://archive.apache.org/dist/tomcat/tomcat-8/v8.0.11/src/apache-tomcat-8.0.11-src.zip 解压后,用idea 打开tomcat 源码 在源码目录下新建pom.xml 文件 pom.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>org.apache.tomcat&lt;/groupId> &lt;artifactId>Tomcat8.0&lt;/artifactId> &lt;name>Tomcat8.0&lt;/name> &lt;version>8.0&lt;/version> &lt;build> &lt;finalName>Tomcat8.0&lt;/finalName> &lt;sourceDirectory>java&lt;/sourceDirectory> &lt;testSourceDirectory>test&lt;/testSourceDirectory> &lt;resources> &lt;resource> &lt;directory>java&lt;/directory> &lt;/resource> &lt;/resources> &lt;testResources> &lt;testResource> &lt;directory>test&lt;/directory> &lt;/testResource> &lt;/testResources> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;version>2.3&lt;/version> &lt;configuration> &lt;encoding>UTF-8&lt;/encoding> &lt;source>1.8&lt;/source> &lt;target>1.8&lt;/target> &lt;/configuration> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;dependencies> &lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactId>junit&lt;/artifactId> &lt;version>4.12&lt;/version> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.easymock&lt;/groupId> &lt;artifactId>easymock&lt;/artifactId> &lt;version>3.4&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>ant&lt;/groupId> &lt;artifactId>ant&lt;/artifactId> &lt;version>1.7.0&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>wsdl4j&lt;/groupId> &lt;artifactId>wsdl4j&lt;/artifactId> &lt;version>1.6.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>javax.xml&lt;/groupId> &lt;artifactId>jaxrpc&lt;/artifactId> &lt;version>1.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.eclipse.jdt.core.compiler&lt;/groupId> &lt;artifactId>ecj&lt;/artifactId> &lt;version>4.5.1&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;/project> 然后右键AS a Maven Project 即可. 3. Tomcat 架构设计 3.1 各个组件的定义官网：https://tomcat.apache.org/tomcat-8.0-doc/architecture/overview.html server In the Tomcat world, a Server represents the whole container. Tomcat provides a default implementation of the Server interface which is rarely customized by users. Service A Service is an intermediate component which lives inside a Server and ties one or more Connectors to exactly one Engine. The Service element is rarely customized by users, as the default implementation is simple and sufficient: Serviceinterface.Engine Connector A Connector handles communications with the client. There are multiple connectors available with Tomcat. These include the HTTP connector which is used for most HTTP traffic, especially when running Tomcat as a standalone server, and the AJP connector which implements the AJP protocol used when connecting Tomcat to a web server such as Apache HTTPD server. Creating a customized connector is a significant effort. Engine An Engine represents request processing pipeline for a specific Service. As a Service may have multiple Connectors, the Engine receives and processes all requests from these connectors, handing the response back to the appropriate connector for transmission to the client. The Engine interface may be implemented to supply custom Engines, though this is uncommon.Note that the Engine may be used for Tomcat server clustering via the jvmRoute parameter. Read the Clustering documentation for more information. Host A Host is an association of a network name, e.g. www.yourcompany.com, to the Tomcat server. An Engine may contain multiple hosts, and the Host element also supports network aliases such as yourcompany.com and abc.yourcompany.com. Users rarely create custom Hosts because the StandardHost implementation provides significant additional functionality. Context A Context represents a web application. A Host may contain multiple contexts, each with a unique path. The Context interface may be implemented to create custom Contexts, but this is rarely the case because the StandardContext provides significant additional functionality. 3.2 两个核心组件Connector: 主要负责处理Socket连接,以及Request与Response的转化 Contailer: 包括Engine、Host、Context 与Wrapper,主要负责内部的处理以及Servlet 的管理 3.2.1 Connector思想: 高内聚、低耦合 EndPoint:提供字节给Processor Processor: 提供Tomcat Request对象给Adapter Adapter : 提供ServletRequest给容器 3.1.1.1 EndPoint监听通讯端口, 是对传输层的抽象,用来实现TCP/IP协议的. 对应的的抽象类为AbstractEndPoint, 有很多的实现类, 比如NioEndPoint，JIoEndPoint等。在其中有两个组件，一个是Acceptor，另外一个是SocketProcessor。 Acceptor 用于监听Socket连接请求,SocketProcessor用于处理接收到的Socket 请求. 3.2.1.2 ProcessorProcessor 是用于实现http协议的,也就是说Processor 是针对应用层协议的抽象 Processor 接受来自EndPoint的Socket,然后解析成Tomcat Request和Tomcat Response对象,最后通过Adapter 提交给容器 对应的抽象类为AbstractProcessor,有很多的实现类, 比如AjpProcessor、Http11Processor等。 3.2.1.3 AdapterProcessHandler接口负责解析请求并生成Tomcat Request 需要把这个Request对象转换为ServletRequest. Tomcat优化CoyoteAdapter, 这是适配器模式的经典运用,连接器调用CoyoteAdapter 的service 方法,传入的是Tomcat Request 对象,CoyoteAdapter 负责将Tomcat Request 转化为ServletRequest, 再调用容器的service 方法, 3.2.1.4 优化图解Endpoint接收Socket连接，生成一个SocketProcessor任务提交到线程池去处理SocketProcessor的run方法会调用Processor组件去解析应用层协议，Processor通过解析生成Request对象后，会调用Adapter的service方法。 3.2.2 Contailer通过Connector后, 我们已经能够获取到对应的Servlet 4.3 Request Process Flow官网：https://tomcat.apache.org/tomcat-8.0-doc/architecture/requestProcess/request-process.png 5. 思维扩展5.1 自定义类加载器WebAppClassLoader,打破了双亲委派模式,先自己尝试去加载这个类,找不到再委托给父类加载器,通过复写findClass和loadClass 实现. 5.2 Session管理Context 中的Manage 对象, 查看Manage 中的方法,可以发现有跟Session的方法. Session 的核心原理是通过Filter拦截Servlet请求, 将标准的ServletRequest 包装一下,换成Spring的Request对象,这样当我们调用Request对象的getSession 方法的时候,Spring在背后为我们创建和管理Session","categories":[{"name":"tomcat","slug":"tomcat","permalink":"https://rainsoil.github.io/categories/tomcat/"},{"name":"tomcat","slug":"tomcat/tomcat","permalink":"https://rainsoil.github.io/categories/tomcat/tomcat/"}],"tags":[]},{"title":"tomcat源码解读和性能优化(2)","slug":"tomcat/tomcat源码解读和性能优化(2)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.261Z","comments":true,"path":"2022/01/04/tomcat/tomcat-yuan-ma-jie-du-he-xing-neng-you-hua-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/tomcat/tomcat-yuan-ma-jie-du-he-xing-neng-you-hua-2/","excerpt":"","text":"tomcat源码解读和性能优化1. 源码解读1.1 BootStrapBootStrap 是tomcat的入口类. org.apache.catalina.startup.Bootstrap#main /** * Main method and entry point when starting Tomcat via the provided * scripts. * * @param args Command line arguments to be processed */ public static void main(String args[]) &amp;#123; if (daemon == null) &amp;#123; // Don't set daemon until init() has completed Bootstrap bootstrap = new Bootstrap(); try &amp;#123; bootstrap.init(); &amp;#125; catch (Throwable t) &amp;#123; handleThrowable(t); t.printStackTrace(); return; &amp;#125; daemon = bootstrap; &amp;#125; else &amp;#123; // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to prevent // a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); &amp;#125; try &amp;#123; String command = \"start\"; if (args.length > 0) &amp;#123; command = args[args.length - 1]; &amp;#125; if (command.equals(\"startd\")) &amp;#123; args[args.length - 1] = \"start\"; daemon.load(args); daemon.start(); &amp;#125; else if (command.equals(\"stopd\")) &amp;#123; args[args.length - 1] = \"stop\"; daemon.stop(); &amp;#125; else if (command.equals(\"start\")) &amp;#123; daemon.setAwait(true); daemon.load(args); daemon.start(); &amp;#125; else if (command.equals(\"stop\")) &amp;#123; daemon.stopServer(args); &amp;#125; else if (command.equals(\"configtest\")) &amp;#123; daemon.load(args); if (null==daemon.getServer()) &amp;#123; System.exit(1); &amp;#125; System.exit(0); &amp;#125; else &amp;#123; log.warn(\"Bootstrap: command \\\"\" + command + \"\\\" does not exist.\"); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; // Unwrap the Exception for clearer error reporting if (t instanceof InvocationTargetException &amp;&amp; t.getCause() != null) &amp;#123; t = t.getCause(); &amp;#125; handleThrowable(t); t.printStackTrace(); System.exit(1); &amp;#125; &amp;#125; bootstrap.init() 和 创建Catalina 1.2 Catalina解析server.xml 配置文件 创建Server组件,并且调用其init和start方法 当调用daemon.load(args);的时候, 进入到org.apache.catalina.startup.Bootstrap#load /** * Load daemon. */ private void load(String[] arguments) throws Exception &amp;#123; // Call the load() method String methodName = \"load\"; Object param[]; Class&lt;?> paramTypes[]; if (arguments==null || arguments.length==0) &amp;#123; paramTypes = null; param = null; &amp;#125; else &amp;#123; paramTypes = new Class[1]; paramTypes[0] = arguments.getClass(); param = new Object[1]; param[0] = arguments; &amp;#125; Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes); if (log.isDebugEnabled()) log.debug(\"Calling startup class \" + method); method.invoke(catalinaDaemon, param); &amp;#125; 我们看到用反射调用了org.apache.catalina.startup.Catalina#load() 方法 真正的执行步骤 /** * Start a new server instance. */ public void load() &amp;#123; long t1 = System.nanoTime(); initDirs(); // Before digester - it may be needed initNaming(); // Create and execute our Digester Digester digester = createStartDigester(); InputSource inputSource = null; InputStream inputStream = null; File file = null; try &amp;#123; file = configFile(); inputStream = new FileInputStream(file); inputSource = new InputSource(file.toURI().toURL().toString()); &amp;#125; catch (Exception e) &amp;#123; if (log.isDebugEnabled()) &amp;#123; log.debug(sm.getString(\"catalina.configFail\", file), e); &amp;#125; &amp;#125; if (inputStream == null) &amp;#123; try &amp;#123; inputStream = getClass().getClassLoader() .getResourceAsStream(getConfigFile()); inputSource = new InputSource (getClass().getClassLoader() .getResource(getConfigFile()).toString()); &amp;#125; catch (Exception e) &amp;#123; if (log.isDebugEnabled()) &amp;#123; log.debug(sm.getString(\"catalina.configFail\", getConfigFile()), e); &amp;#125; &amp;#125; &amp;#125; // This should be included in catalina.jar // Alternative: don't bother with xml, just create it manually. if (inputStream == null) &amp;#123; try &amp;#123; inputStream = getClass().getClassLoader() .getResourceAsStream(\"server-embed.xml\"); inputSource = new InputSource (getClass().getClassLoader() .getResource(\"server-embed.xml\").toString()); &amp;#125; catch (Exception e) &amp;#123; if (log.isDebugEnabled()) &amp;#123; log.debug(sm.getString(\"catalina.configFail\", \"server-embed.xml\"), e); &amp;#125; &amp;#125; &amp;#125; if (inputStream == null || inputSource == null) &amp;#123; if (file == null) &amp;#123; log.warn(sm.getString(\"catalina.configFail\", getConfigFile() + \"] or [server-embed.xml]\")); &amp;#125; else &amp;#123; log.warn(sm.getString(\"catalina.configFail\", file.getAbsolutePath())); if (file.exists() &amp;&amp; !file.canRead()) &amp;#123; log.warn(\"Permissions incorrect, read permission is not allowed on the file.\"); &amp;#125; &amp;#125; return; &amp;#125; try &amp;#123; inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &amp;#125; catch (SAXParseException spe) &amp;#123; log.warn(\"Catalina.start using \" + getConfigFile() + \": \" + spe.getMessage()); return; &amp;#125; catch (Exception e) &amp;#123; log.warn(\"Catalina.start using \" + getConfigFile() + \": \" , e); return; &amp;#125; finally &amp;#123; try &amp;#123; inputStream.close(); &amp;#125; catch (IOException e) &amp;#123; // Ignore &amp;#125; &amp;#125; getServer().setCatalina(this); getServer().setCatalinaHome(Bootstrap.getCatalinaHomeFile()); getServer().setCatalinaBase(Bootstrap.getCatalinaBaseFile()); // Stream redirection initStreams(); // Start the new server try &amp;#123; getServer().init(); &amp;#125; catch (LifecycleException e) &amp;#123; if (Boolean.getBoolean(\"org.apache.catalina.startup.EXIT_ON_INIT_FAILURE\")) &amp;#123; throw new java.lang.Error(e); &amp;#125; else &amp;#123; log.error(\"Catalina.start\", e); &amp;#125; &amp;#125; long t2 = System.nanoTime(); if(log.isInfoEnabled()) &amp;#123; log.info(\"Initialization processed in \" + ((t2 - t1) / 1000000) + \" ms\"); &amp;#125; &amp;#125; 1.3 Lifecycle用来管理各个组件的生命周期 init、start、stop、destroy LifecycleBase 实现了Lifecycle, 使用的是模板设计模式 * &lt;pre> * start() * ----------------------------- * | | * | init() | * NEW ->-- INITIALIZING | * | | | | ------------------&lt;----------------------- * | | |auto | | | * | | \\|/ start() \\|/ \\|/ auto auto stop() | * | | INITIALIZED -->-- STARTING_PREP -->- STARTING -->- STARTED -->--- | * | | | | | | * | | | | | | * | | | | | | * | |destroy()| | | | * | -->-----&lt;-- auto auto | | | * | | ---------&lt;----- MUST_STOP ---------------------&lt;-- | | * | | | | | * | \\|/ ---------------------------&lt;-------------------------------- ^ * | | | | * | | \\|/ auto auto start() | * | | STOPPING_PREP ------>----- STOPPING ------>----- STOPPED ---->------ * | | ^ | | ^ * | | stop() | | | | * | | -------------------------- | | | * | | | auto | | | * | | | MUST_DESTROY------&lt;------- | | * | | | | | | * | | | |auto | | * | | | destroy() \\|/ destroy() | | * | | FAILED ---->------ DESTROYING ---&lt;----------------- | * | | ^ | | * | | destroy() | |auto | * | -------->----------------- \\|/ | * | DESTROYED | * | | * | stop() | * --->------------------------------>------------------------------ public interface Lifecycle &amp;#123; ... public void init() throws LifecycleException; /** * Prepare for the beginning of active use of the public methods other than * property getters/setters and life cycle methods of this component. This * method should be called before any of the public methods other than * property getters/setters and life cycle methods of this component are * utilized. The following &amp;#123;@link LifecycleEvent&amp;#125;s will be fired in the * following order: * &lt;ol> * &lt;li>BEFORE_START_EVENT: At the beginning of the method. It is as this * point the state transitions to * &amp;#123;@link LifecycleState#STARTING_PREP&amp;#125;.&lt;/li> * &lt;li>START_EVENT: During the method once it is safe to call start() for * any child components. It is at this point that the * state transitions to &amp;#123;@link LifecycleState#STARTING&amp;#125; * and that the public methods other than property * getters/setters and life cycle methods may be * used.&lt;/li> * &lt;li>AFTER_START_EVENT: At the end of the method, immediately before it * returns. It is at this point that the state * transitions to &amp;#123;@link LifecycleState#STARTED&amp;#125;. * &lt;/li> * &lt;/ol> * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ public void start() throws LifecycleException; /** * Gracefully terminate the active use of the public methods other than * property getters/setters and life cycle methods of this component. Once * the STOP_EVENT is fired, the public methods other than property * getters/setters and life cycle methods should not be used. The following * &amp;#123;@link LifecycleEvent&amp;#125;s will be fired in the following order: * &lt;ol> * &lt;li>BEFORE_STOP_EVENT: At the beginning of the method. It is at this * point that the state transitions to * &amp;#123;@link LifecycleState#STOPPING_PREP&amp;#125;.&lt;/li> * &lt;li>STOP_EVENT: During the method once it is safe to call stop() for * any child components. It is at this point that the * state transitions to &amp;#123;@link LifecycleState#STOPPING&amp;#125; * and that the public methods other than property * getters/setters and life cycle methods may no longer be * used.&lt;/li> * &lt;li>AFTER_STOP_EVENT: At the end of the method, immediately before it * returns. It is at this point that the state * transitions to &amp;#123;@link LifecycleState#STOPPED&amp;#125;. * &lt;/li> * &lt;/ol> * * Note that if transitioning from &amp;#123;@link LifecycleState#FAILED&amp;#125; then the * three events above will be fired but the component will transition * directly from &amp;#123;@link LifecycleState#FAILED&amp;#125; to * &amp;#123;@link LifecycleState#STOPPING&amp;#125;, bypassing * &amp;#123;@link LifecycleState#STOPPING_PREP&amp;#125; * * @exception LifecycleException if this component detects a fatal error * that needs to be reported */ public void stop() throws LifecycleException; /** * Prepare to discard the object. The following &amp;#123;@link LifecycleEvent&amp;#125;s will * be fired in the following order: * &lt;ol> * &lt;li>DESTROY_EVENT: On the successful completion of component * destruction.&lt;/li> * &lt;/ol> * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ public void destroy() throws LifecycleException; ... &amp;#125; 1.4 Server管理Service组件, 调用的其init和start 方法 org.apache.catalina.Server是一个接口类, 其唯一的实现类org.apache.catalina.core.StandardServer @Override protected void initInternal() throws LifecycleException &amp;#123; super.initInternal(); // Register global String cache // Note although the cache is global, if there are multiple Servers // present in the JVM (may happen when embedding) then the same cache // will be registered under multiple names onameStringCache = register(new StringCache(), \"type=StringCache\"); // Register the MBeanFactory MBeanFactory factory = new MBeanFactory(); factory.setContainer(this); onameMBeanFactory = register(factory, \"type=MBeanFactory\"); // Register the naming resources globalNamingResources.init(); // Populate the extension validator with JARs from common and shared // class loaders if (getCatalina() != null) &amp;#123; ClassLoader cl = getCatalina().getParentClassLoader(); // Walk the class loader hierarchy. Stop at the system class loader. // This will add the shared (if present) and common class loaders while (cl != null &amp;&amp; cl != ClassLoader.getSystemClassLoader()) &amp;#123; if (cl instanceof URLClassLoader) &amp;#123; URL[] urls = ((URLClassLoader) cl).getURLs(); for (URL url : urls) &amp;#123; if (url.getProtocol().equals(\"file\")) &amp;#123; try &amp;#123; File f = new File (url.toURI()); if (f.isFile() &amp;&amp; f.getName().endsWith(\".jar\")) &amp;#123; ExtensionValidator.addSystemResource(f); &amp;#125; &amp;#125; catch (URISyntaxException e) &amp;#123; // Ignore &amp;#125; catch (IOException e) &amp;#123; // Ignore &amp;#125; &amp;#125; &amp;#125; &amp;#125; cl = cl.getParent(); &amp;#125; &amp;#125; // Initialize our defined Services for (int i = 0; i &lt; services.length; i++) &amp;#123; services[i].init(); &amp;#125; &amp;#125; 1.5 Service管理连接器和Engine org.apache.catalina.Service 同样是一个接口类,有唯一的实现org.apache.catalina.core.StandardService ContainerBase的类关系图 关注到上图图解中的ContainerBase.startInternal() 方法 @Override protected synchronized void startInternal() throws LifecycleException &amp;#123; // Start our subordinate components, if any logger = null; getLogger(); Cluster cluster = getClusterInternal(); if ((cluster != null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm = getRealmInternal(); if ((realm != null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); // Start our child containers, if any Container children[] = findChildren(); List&lt;Future&lt;Void>> results = new ArrayList&lt;>(); for (int i = 0; i &lt; children.length; i++) &amp;#123; // 这句代码的意思就是调用`contailerBase`下面的一个个子容器的`call`方法 results.add(startStopExecutor.submit(new StartChild(children[i]))); &amp;#125; boolean fail = false; for (Future&lt;Void> result : results) &amp;#123; try &amp;#123; result.get(); &amp;#125; catch (Exception e) &amp;#123; log.error(sm.getString(\"containerBase.threadedStartFailed\"), e); fail = true; &amp;#125; &amp;#125; if (fail) &amp;#123; throw new LifecycleException( sm.getString(\"containerBase.threadedStartFailed\")); &amp;#125; // Start the Valves in our pipeline (including the basic), if any if (pipeline instanceof Lifecycle) ((Lifecycle) pipeline).start(); setState(LifecycleState.STARTING); // Start our thread threadStart(); &amp;#125; 查看new StartChild 要执行的call 方法 private static class StartChild implements Callable&lt;Void> &amp;#123; private Container child; public StartChild(Container child) &amp;#123; this.child = child; &amp;#125; @Override public Void call() throws LifecycleException &amp;#123; child.start(); return null; &amp;#125; &amp;#125; StandardHost 将一个个web项目部署起来 org.apache.catalina.startup.HostConfig#deployApps() protected void deployApps() &amp;#123; File appBase = host.getAppBaseFile(); File configBase = host.getConfigBaseFile(); String[] filteredAppPaths = filterAppPaths(appBase.list()); // Deploy XML descriptors from configBase deployDescriptors(configBase, configBase.list()); // Deploy WARs deployWARs(appBase, filteredAppPaths); // Deploy expanded folders deployDirectories(appBase, filteredAppPaths); &amp;#125; StandardContext.startInternal()解析web.xml文件和添加wrapper ContextConfig.webConfig() 的step9解析到servlets 包装成wrapper 对象 StandardContext.startInternal()-&gt;最终会调用if (!loadOnStartup(findChildren())) 官网： https://tomcat.apache.org/tomcat-8.0-doc/architecture/startup/serverStartup.pdf 2. 性能优化tomcat 性能指标: 吞吐量、响应时间、错误数、线程池、CPU、内存等. 使用jmeter 进行压测,然后观察相应指标. 使用命令查看相关指标 查看tomcat进程pid ps -ef | grep tomcat 查看进程的信息 cat /pro/pid/status 查看进程的CPU和内存 top -p pid 使用工具查看相应的指标 jconsole、jvisualvm、arthas、psi-probe等 2.1 优化思路2.1.1 conf/server.xml 等核心组件 Server 官网描述 :Server interface which is rarely customized by users. 【pass】 Service 官网描述 :The Service element is rarely customized by users. 【pass】 Connector 官网描述 :Creating a customized connector is a significant effort. 【 need 】 Engine 官网描述 :The Engine interface may be implemented to supply custom Engines, though this is uncommon. 【pass】 Host 官网描述 :Users rarely create custom Hosts because the StandardHost implementation provides significant additional functionality. 【pass】 Context 官网描述 :The Context interface may be implemented to create custom Contexts, but this is rarely the case because the StandardContext provides significant additional functionality. 【 maybe 】 context 既然代表的是web应用,是和我们比较接近的,这块我们考虑对其进行适当的优化. 2.1.2 conf/server.xml 非核心组件官网: https://tomcat.apache.org/tomcat-8.0-doc/config/index.html Listener Listener(即监听器) 定义的组件,可以在特定事件发生时执行特定的操作, 被监听的事件通常是Tomcat的启动和停止 &lt;Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\" /> &lt;!-- Prevent memory leaks due to use of particular java/javax APIs--> &lt;Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\" /> &lt;Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" /> &lt;Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" /> Global Resources GlobalNamingResources 元素定义了全局资源,通过配置可以看出,该配置是通过读取$TOMCAT_HOME/ conf/tomcat-users.xml 实现的. &lt;!-- Global JNDI resources Documentation at /docs/jndi-resources-howto.html --> &lt;GlobalNamingResources> &lt;!-- Editable user database that can also be used by UserDatabaseRealm to authenticate users --> &lt;Resource name=\"UserDatabase\" auth=\"Container\" type=\"org.apache.catalina.UserDatabase\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" pathname=\"conf/tomcat-users.xml\" /> &lt;/GlobalNamingResources> Valve Realm Realm 可以理解为”域”, Realm 提供了一种用户密码与web应用的映射关系,从而达到角色安全管理的作用,在本例中, Realm 的配置使用name为UserDatabase的资源实现,而该资源在Server元素中使用GlobalNamingResources 配置 &lt;!-- Use the LockOutRealm to prevent attempts to guess user passwords via a brute-force attack --> &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"> &lt;!-- This Realm uses the UserDatabase configured in the global JNDI resources under the key \"UserDatabase\". Any edits that are performed against this UserDatabase are immediately available for use by the Realm. --> &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/> &lt;/Realm> 2.1.3 conf/web.xml全局的web.xml 文件有些标签用不到,可以删除掉 2.1.4 JVM层面因为Tomcat本身就是一个java进程,所以可以使用优化JVM的方式进行优化 3. 配置优化3.1 减少web.xml/server.xml中标签最终观察tomcat 启动日志(时间/内容)、线程开销、内存大小、GC等. DefaultServlet 官网 :User Guide-&gt;Default Servlet The default servlet is the servlet which serves static resources as well as serves the directory listings (if directory listings are enabled). &lt;servlet> &lt;servlet-name>default&lt;/servlet-name> &lt;servlet-class>org.apache.catalina.servlets.DefaultServlet&lt;/servlet-class> &lt;init-param> &lt;param-name>debug&lt;/param-name> &lt;param-value>0&lt;/param-value> &lt;/init-param> &lt;init-param> &lt;param-name>listings&lt;/param-name> &lt;param-value>false&lt;/param-value> &lt;/init-param> &lt;load-on-startup>1&lt;/load-on-startup> &lt;/servlet> JspServlet &lt;servlet> &lt;servlet-name>jsp&lt;/servlet-name> &lt;servlet-class>org.apache.jasper.servlet.JspServlet&lt;/servlet-class> &lt;init-param> &lt;param-name>fork&lt;/param-name> &lt;param-value>false&lt;/param-value> &lt;/init-param> &lt;init-param> &lt;param-name>xpoweredBy&lt;/param-name> &lt;param-value>false&lt;/param-value> &lt;/init-param> &lt;load-on-startup>3&lt;/load-on-startup> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>default&lt;/servlet-name> &lt;url-pattern>/&lt;/url-pattern> &lt;/servlet-mapping> &lt;!-- The mappings for the JSP servlet --> &lt;servlet-mapping> &lt;servlet-name>jsp&lt;/servlet-name> &lt;url-pattern>*.jsp&lt;/url-pattern> &lt;url-pattern>*.jspx&lt;/url-pattern> &lt;/servlet-mapping> welcome-list-file &lt;welcome-file-list> &lt;welcome-file>index.html&lt;/welcome-file> &lt;welcome-file>index.htm&lt;/welcome-file> &lt;welcome-file>index.jsp&lt;/welcome-file> &lt;/welcome-file-list> mime-mapping移除响应的内容 支持的下载打开类型 &lt;mime-mapping> &lt;extension>123&lt;/extension> &lt;mime-type>application/vnd.lotus-1-2-3&lt;/mime-type> &lt;/mime-mapping> &lt;mime-mapping> &lt;extension>3dml&lt;/extension> &lt;mime-type>text/vnd.in3d.3dml&lt;/mime-type> &lt;/mime-mapping> .... session-config 默认的jsp 页面有session, 就是在于这个配置 &lt;session-config> &lt;session-timeout>30&lt;/session-timeout> &lt;/session-config> 3.2 调整优化server.xml 中标签3.2.1 Connector 标签 protocol 属性 &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /> 对于protocol=&quot;HTTP/1.1&quot; ,查看源码 public Connector(String protocol) &amp;#123; setProtocol(protocol); // Instantiate protocol handler ProtocolHandler p = null; try &amp;#123; Class&lt;?> clazz = Class.forName(protocolHandlerClassName); p = (ProtocolHandler) clazz.newInstance(); &amp;#125; catch (Exception e) &amp;#123; log.error(sm.getString( \"coyoteConnector.protocolHandlerInstantiationFailed\"), e); &amp;#125; finally &amp;#123; this.protocolHandler = p; &amp;#125; if (!Globals.STRICT_SERVLET_COMPLIANCE) &amp;#123; URIEncoding = \"UTF-8\"; URIEncodingLower = URIEncoding.toLowerCase(Locale.ENGLISH); &amp;#125; &amp;#125; setProtocol(protocol); 因为配置文件中传入的是 HTTP/1.1 if (\"HTTP/1.1\".equals(protocol)) &amp;#123; setProtocolHandlerClassName (\"org.apache.coyote.http11.Http11NioProtocol\"); &amp;#125; else if (\"AJP/1.3\".equals(protocol)) &amp;#123; setProtocolHandlerClassName (\"org.apache.coyote.ajp.AjpNioProtocol\"); &amp;#125; else if (protocol != null) &amp;#123; setProtocolHandlerClassName(protocol); &amp;#125; 发现这里调用的是Http11NioProtocol，, 说明tomcat8中默认的是NIO 使用同样的方式看tomcat7和tomcat8.5, 你会发现tomcat7中默认使用的是BIO,tomcat8.5 中默认使用的是NIO BIO 来到tomcat官网Configuration/HTTP/protocol org.apache.coyote.http11.Http11Protocol - blocking Java connector org.apache.coyote.http11.Http11NioProtocol - non blocking Java NIO connector org.apache.coyote.http11.Http11Nio2Protocol - non blocking Java NIO2 connector org.apache.coyote.http11.Http11AprProtocol - the APR/native connector. NIO tomcat8.0 中默认使用的就是NIO APR 调用本地方法库进行io操作 executor属性 最佳线程公式: （(线程等待时间+线程CPU时间)/线程CPU时间）*CPU数量 The Executor represents a thread pool that can be shared between components in Tomcat. Historically there has been a thread pool per connector created but this allows you to share a thread pool, between (primarily) connector but also other components when those get configured to support executors 默认的可以查看StandardExecutor 类 设置一些属性 官网： https://tomcat.apache.org/tomcat-8.0-doc/config/http.html acceptCount 达到最大连接数之后, 等待队列中还能放多少连接, 超过即拒绝, 配置太多也没有意义. The maximum queue length for incoming connection requests when all possible request processing threads are in use. Any requests received when the queue is full will be refused. The default value is 100. maxConnections 超过这个值后,将继续接受连接,但是不处理,能继续接受多少根据acceptCount的值. BIO:maxThreads NIO/NIO2:10000 ——— AbstractEndpoint.maxConnections APR:8192 The maximum number of connections that the server will accept and process at any given time. When this number has been reached, the server will accept, but not process, one further connection. This additional connection be blocked until the number of connections being processed falls below maxConnections at which point the server will start accepting and processing new connections again. Note that once the limit has been reached, the operating system may still accept connections based on the acceptCount setting. The default value varies by connector type. For BIO the default is the value of maxThreads unless an Executor is used in which case the default will be the value of maxThreads from the executor. For NIO and NIO2 the default is 10000. For APR/native, the default is 8192. Note that for APR/native on Windows, the configured value will be reduced to the highest multiple of 1024 that is less than or equal to maxConnections. This is done for performance reasons. If set to a value of -1, the maxConnections feature is disabled and connections are not counted. maxThreads 最大工作线程数,也就是用来处理request请求的,默认是200, 如果自己配置了executor, 并且和Connector有关联了,则之前默认的200就会被忽略,取决于CPU的配置. 监控中就可以看到所有的工作线程是什么状态, 通过监控就可以知道开启多少线程合适. The maximum number of request processing threads to be created by this Connector, which therefore determines the maximum number of simultaneous requests that can be handled. If not specified, this attribute is set to 200. If an executor is associated with this connector, this attribute is ignored as the connector will execute tasks using the executor rather than an internal thread pool. Note that if an executor is configured any value set for this attribute will be recorded correctly but it will be reported (e.g. via JMX) as -1 to make clear that it is not used. minSpareThreads 最小空闲线程数 The minimum number of threads always kept running. This includes both active and idle threads. If not specified, the default of 10 is used. If an executor is associated with this connector, this attribute is ignored as the connector will execute tasks using the executor rather than an internal thread pool. Note that if an executor is configured any value set for this attribute will be recorded correctly but it will be reported (e.g. via JMX) as -1 to make clear that it is not used. 可以实践一下,connector 配置自定义的线程池 &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /> &lt;Executor name=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\" maxThreads=\"150\" minSpareThreads=\"4\"/> 其实这块最好的方式就是结合BIO来查看,因为BIO是一个request 对应一个线程. 值太低, 并发请求多了之后, 多余的则会进入到等待状态. 值太高,启动tomcat 将花费更多的时间 enableLookups 设置为fasle 删掉AJP的Connector 3.2.2 Host 标签 autoDeploy tomcat 运行时,要用一个线程来进行检查, 生产环境下一定要改成fasle This flag value indicates if Tomcat should check periodically for new or updated web applications while Tomcat is running. If true, Tomcat periodically checks the appBase and xmlBase directories and deploys any new web applications or context XML descriptors found. Updated web applications or context XML descriptors will trigger a reload of the web application. The flag’s value defaults to true. See Automatic Application Deployment for more information. 3.2.3 Context 标签reloadable:false reloadable 如果设置为true, tomcat 服务器会在运行状态下监视在WEB-INFO/classes和WEB-INFO/lib 目录下class文件的改动,如果检测到有class 文件被更新,服务器会自动加载web应用. 在开发阶段, 将reloadable 属性设置为true, 有助于调试servlet和其他的class文件,但是这样会加重服务器运行负荷,建议在web 应用的发行阶段将reloadable设置为false Set to true if you want Catalina to monitor classes in /WEB-INF/classes/ and /WEB-INF/lib for changes, and automatically reload the web application if a change is detected. This feature is very useful during application development, but it requires significant runtime overhead and is not recommended for use on deployed production applications. That’s why the default setting for this attribute is false. You can use the Manager web application, however, to trigger reloads of deployed applications on demand. 4. 启动速度慢优化 删除没用的web应用 因为tomcat启动每次都会部署这些应用 关闭webSocket 如果项目中用不到webSocket的话，可以删除这两个websocket-api.jar和tomcat-websocket.jar 随机数优化 设置JVM参数 -Djava.security.egd=file:/dev/./urandom 多个线程启动web应用 &lt;Host startStopThreads=\"0\"> &lt;/Host> 5. 其他方面的优化 Connector 配置压缩属性compression=&quot;500&quot;, 文件大于500bytes 才会被压缩 数据库优化 减少对数据库访问等待的时间,可以从数据库的层面进行优化,或者加缓存等等各种方案 开启浏览器缓存,nginx 静态资源部署 6. 常见问题排查6.1 CPU 使用率过高可能原因 GC频繁或者创建了很多的业务线程 排查 哪些线程比较消耗CPU 或者多线程上下文频繁切换 解决思路 top -H pid 查看某个java进程各个线程使用CPU的情况,找到哪个线程占用CPU比较高. jstack pid 打印出线程信息,定位到上述线程名称 6.2 拒绝连接 java.net.BindException: Address already in use: JVM_Bind 端口被占用,可以使用netstat -an 查看端口占用情况,关闭对应的进程或者tomcat修改端口 java.net.ConnectException: Connection refused: connect ping一下服务端的ip,可能服务端机器有问题 java.net.SocketException: Too many open files 可能在高并发的情况下,创建的socket过多,文件句柄不够用了,可以关闭无用的句柄,如果都有用,可以增加文件句柄数 ulimit -n 10000","categories":[{"name":"tomcat","slug":"tomcat","permalink":"https://rainsoil.github.io/categories/tomcat/"},{"name":"tomcat","slug":"tomcat/tomcat","permalink":"https://rainsoil.github.io/categories/tomcat/tomcat/"}],"tags":[]},{"title":"Spring框架的前生今世(2)","slug":"spring/Spring框架的前生今世(2)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-kuang-jia-de-qian-sheng-jin-shi-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-kuang-jia-de-qian-sheng-jin-shi-2/","excerpt":"","text":"2 . Spring的前世今生&emsp;&emsp;相信经历过不使用框架开发Web项目的70后、80后都会有如此感触，如今的程序员开发项目太轻松了，基本只需要关心业务如何实现，通用技术问题只需要集成框架便可。早在2007年，一个基于Java语言的开源框架正式发布，取了一个非常有活力且美好的名字，叫做 Spring。它是一个开源的轻量级Java SE（Java标准版本）/Java EE（Java企业版本）开发应用框架，其目的是用于简化企业级应用程序开发。应用程序是由一组相互协作的对象组成。而在传统应用程序开发中，一个完整的应用是由一组相互协作的对象组成。所以开发一个应用除了要开发业务逻辑之外，最多的是关注如何使这些对象协作来完成所需功能，而且要低耦合、高聚合。业务逻辑开发是不可避免的，那如果有个框架出来帮我们来创建对象及管理这些对象之间的依赖关系。可能有人说了，比如“抽象工厂、工厂方法模式”不也可以 帮我们创建对象，“生成器模式”帮我们处理对象间的依赖关系，不也能完成这些功能吗？可是这些又需要我们创建另一些工厂类、生成器类，我们又要而外管理这些类，增加了我们的负担，如果能有种通过配置方式来创建对象，管理对象之间依赖关系，我们不需要通过工厂和生成器来创建及管理对象之间的依赖关系，这样我们是不是减少了许多工作，加速了开发，能节省出很多时间来干其他事。Spring框架刚出来时主要就是来完成这个功能。 &emsp;&emsp;Spring框架除了帮我们管理对象及其依赖关系，还提供像通用日志记录、性能统计、安全控制、异常处理等面向切面的能力，还能帮我管理最头疼的数据库事务，本身提供了一套简单的JDBC访问实现，提供与第三方数据访问框架集成（如Hibernate、JPA），与各种 JavaEE技术整合（如JavaMail、任务调度等等），提供一套自己的Web层框架SpringMVC、而且还能非常简单的与第三方Web框架集成。从这里我们可以认为 Spring 是一个超级粘合大平台，除了自己提供功能外，还提供粘合其他技术和框架的能力，从而使我们可以更自由的选择到底使用什么技术进行开发。而且不管是JAVASE（C/S架构）应用程序还是 JAVA EE（B/S架构）应用程序都可以使用这个平台进行开发。如今的 Spring 已经不再是一个框架，早已成为了一种生态。SpringBoot的便捷式开发实现了零配置，SpringCloud全家桶，提供了非常方便的解决方案。接下来，让我们来深入探讨Spring到底能给我们带来什么？ 一切从Bean开始&emsp;&emsp;说到 Bean这个概念，还得从 Java的起源说起。早在 1996 年，Java还只是一个新兴的、初出茅庐的编程语言。人们之所以关注她仅仅是因为，可以使用Java的Applet来开发Web应用，作为浏览器组件。但开发者们很快就发现这个新兴的语言还能做更多的事情。与之前的所有语言不同，Java让模块化构建复杂的系统成为可能（当时的软件行业虽然在业务上突飞猛进，但当时开发用的是传统的面向过程开发思想，软件的开发效率一直踟蹰不前。伴随着业务复杂性的不断加深，开发也变得越发困难。其实，当时也是OOP 思想飞速发展的时期，她在80年代末被提出，成熟于90年代，现今大多数编程语言都已经是面向对象的）。 &emsp;&emsp;同年12月，Sun公司发布了当时还名不见经传但后来人尽皆知的 JavaBean 1.00-A规范。早期的JavaBean规范针对于Java，她定义了软件组件模型。这个规范规定了一整套编码策略，使简单的Java对象不仅可以被重用，而且还可以轻松地构建更为复杂的应用。尽管 JavaBean最初是为重用应用组件而设计的，但当时他们却是主要用作构建窗体控件，毕竟在PC 时代那才是主流。但相比于当时正如日中天的Delphi、VB和C++，它看起来还是太简易了，以至于无法胜任任何”实际的”工作需要。 &emsp;&emsp;复杂的应用通常需要事务、安全、分布式等服务的支持，但JavaBean并未直接提供。所以到了 1998年 3 月，Sun 公司发布了EJB 1.0 规范，该规范把 Java组件的设计理念延伸到了服务器端，并提供了许多必须的企业级服务，但他也不再像早期的 JavaBean 那么简单了。实际上，除了名字叫 EJB Bean以外，其他的和JavaBean关系不大了。 &emsp;&emsp;尽管现实中有很多系统是基于EJB 构建的，但EJB从来没有实现它最初的设想：简化开发。EJB 的声明式编程模型的确简化了很多基础架构层面的开发，例如事务和安全；但另一方面EJB在部署描述符和配套代码实现等方面变得异常复杂。随着时间的推移，很多开发者对EJB已经不再抱有幻想，开始寻求更简洁的方法。 &emsp;&emsp;现在Java组件开发理念重新回归正轨。新的编程技术AOP和 DI的不断出现，他们为JavaBean提供了之前EJB才能拥有的强大功能。这些技术为POJO提供了类似EJB 的声明式编程模型，而没有引入任何EJB的复杂性。当简单的JavaBean足以胜任时，人们便不愿编写笨重的EJB组件了。 &emsp;&emsp;客观地讲，EJB 的发展甚至促进了基于POJO的编程模型。引入新的理念，最新的 EJB规范相比之前的规范有了前所未有的简化，但对很多开发者而言，这一切的一切都来得太迟了。到了EJB 3规范发布时，其他基于 POJO的开发架构已经成为事实的标准了，而 Spring 框架也就是在这样的大环境下出现的。 Spring的设计初衷&emsp;&emsp;Spring是为解决企业级应用开发的复杂性而设计，她可以做很多事。但归根到底支撑 Spring的仅仅是少许的基本理念，而所有的这些基本理念都能可以追溯到一个最根本的使命：简化开发。这是一个郑重的承诺，其实许多框架都声称在某些方面做了简化。而Spring 则立志于全方面的简化Java开发。对此，她主要采取了4个关键策略： 基于POJO的轻量级和最小侵入性编程； 通过依赖注入和面向接口松耦合； 基于切面和惯性进行声明式编程； 通过切面和模板减少样板式代码； 而他主要是通过：面向Bean(BOP)、依赖注入（DI）以及面向切面（AOP）这三种方式来达成的。 BOP编程伊始&emsp;&emsp;Spring 是面向Bean的编程（Bean Oriented Programming, BOP），Bean在 Spring中才是真正的主角。Bean在Spring中作用就像 Object对 OOP 的意义一样，Spring中没有Bean也就没有Spring存在的意义。Spring提供了IOC 容器通过配置文件或者注解的方式来管理对象之间的依赖关系。 &emsp;&emsp;控制反转(其中最常见的实现方式叫做依赖注入（Dependency Injection，DI），还有一种方式叫“依赖查找”（DependencyLookup，DL），她在 C++、Java、PHP 以及.NET中都运用。在最早的Spring中是包含有依赖注入方法和依赖查询的，但因为依赖查询使用频率过低，不久就被Spring移除了，所以在Spring中控制反转也被直接称作依赖注入)，她的基本概念是：不创建对象，但是描述创建它们的方式。在代码中不直接与对象和服务连接，但在配置文件中描述哪一个组件需要哪一项服务。容器 （在Spring 框架中是 IOC 容器）负责将这些联系在一起。 &emsp;&emsp; 在典型的IOC 场景中，容器创建了所有对象，并设置必要的属性将它们连接在一起，决定什么时间调用方法。 依赖注入的基本概念&emsp;&emsp;Spring 设计的核心 org.springframework.beans 包（架构核心是 org.springframework.core包），它的设计目标是与JavaBean组件一起使用。这个包通常不是由用户直接使用，而是由服务器将其用作其他多数功能的底层中介。下一个最高级抽象是BeanFactory 接口，它是工厂设计模式的实现，允许通过名称创建和检索对象。BeanFactory 也可以管理对象之间的关系。 BeanFactory 最底层支持两个对象模型。 单例：提供了具有特定名称的全局共享实例对象，可以在查询时对其进行检索。Singleton 是默认的也是最常用的对象模型。 原型：确保每次检索都会创建单独的实例对象。在每个用户都需要自己的对象时，采用原型模式。Bean工厂的概念是Spring作为IOC 容器的基础。 IOC 则将处理事情的责任从应用程序代码转移到框架。 AOP编程理念&emsp;&emsp; 面向切面编程，即AOP，是一种编程思想，它允许程序员对横切关注点或横切典型的职责分界线的行为（例如日志和事务管理）进行模块化。AOP 的核心构造是方面（切面），它将那些影响多个类的行为封装到可重用的模块中。 &emsp;&emsp; AOP 和 IOC 是补充性的技术，它们都运用模块化方式解决企业应用程序开发中的复杂问题。在典型的面向对象开发方式中，可能要将日志记录语句放在所有方法和Java类中才能实现日志功能。在AOP方式中，可以反过来将日志服务模块化，并以声明的方式将它们应用到需要日志的组件上。当然，优势就是 Java类不需要知道日志服务的存在，也不需要考虑相关的代码。所以，用 Spring AOP 编写的应用程序代码是松散耦合的。 AOP的功能完全集成到了Spring 事务管理、日志和其他各种特性的上下文中。 AOP 编程的常用场景有： Authentication（权限认证）、 AutoCaching（自动缓存处理）、ErrorHandling（统一错误处理）、Debugging（调试信息输出）、Logging（日志记录）、Transactions（事务处理）等。 Spring5系统架构&emsp;&emsp; Spring总共大约有 20个模块，由1300多个不同的文件构成。而这些组件被分别整合在核心容器（CoreContainer）、AOP（Aspect Oriented Programming）和设备支持（Instrmentation）、数据访问及集成（Data Access/Integeration）、Web、报文发送（Messaging）、Test，6个模块集合中。以下是 Spring 5 的模块结构图： 组成Spring框架的每个模块集合或者模块都可以单独存在，也可以一个或多个模块联合实现。每个模块的组成和功能如下： 核心容器由spring-beans、 spring-core、 spring-context和spring-expression（SpringExpressionLanguage,SpEL） 4个模块组成。 &emsp;&emsp; spring-core和spring-beans模块是Spring框架的核心模块，包含了控制反转（Inversion ofControl, IOC）和依赖注入（Dependency Injection, DI）。BeanFactory 接口是Spring 框架中的核心接口，它是工厂模式的具体实现。BeanFactory 使用控制反转对应用程序的配置和依赖性规范与实际的应用程序代码进行了分离。但BeanFactory 容器实例化后并不会自动实例化Bean，只有当Bean 被使用时 BeanFactory 容器才会对该 Bean 进行实例化与依赖关系的装配。 &emsp;&emsp; spring-context模块构架于核心模块之上，他扩展了BeanFactory，为她添加了Bean生命周期控制、框架事件体系以及资源加载透明化等功能。此外该模块还提供了许多企业级支持，如邮件访问、远程访问、任务调度等，ApplicationContext是该模块的核心接口，她的超类是BeanFactory。与BeanFactory 不同，ApplicationContext容器实例化后会自动对所有的单实例Bean进行实例化与依赖关系的装配，使之处于待用状态。 &emsp;&emsp; spring-context-support 模块是对Spring IOC 容器的扩展支持，以及IOC子容器。 &emsp;&emsp; spring-context-indexer模块是Spring的类管理组件和Classpath扫描。 &emsp;&emsp;spring-expression模块是统一表达式语言（EL）的扩展模块，可以查询、管理运行中的对象，同时也方便的可以调用对象方法、操作数组、集合等。它的语法类似于传统EL，但提供了额外的功能，最出色的要数函数调用和简单字符串的模板函数。这种语言的特性是基于Spring产品的需求而设计，他可以非常方便地同Spring IOC 进行交互。 AOP和设备支持由spring-aop、spring-aspects 和spring-instrument 3个模块组成。 &emsp;&emsp;spring-aop是Spring 的另一个核心模块，是AOP 主要的实现模块。作为继OOP 后，对程序员影响最大的编程思想之一，AOP极大地开拓了人们对于编程的思路。在Spring 中，他是以JVM的动态代理技术为基础，然后设计出了一系列的AOP横切实现，比如前置通知、返回通知、异常通知等，同时，Pointcut接口来匹配切入点，可以使用现有的切入点来设计横切面，也可以扩展相关方法根据需求进行切入。 &emsp;&emsp; spring-aspects 模块集成自AspectJ框架，主要是为Spring AOP提供多种AOP 实现方法。 &emsp;&emsp; spring-instrument模块是基于JAVA SE中的”java.lang.instrument”进行设计的，应该算是AOP的一个支援模块，主要作用是在JVM启用时，生成一个代理类，程序员通过代理类在运行时修改类的字节，从而改变一个类的功能，实现AOP 的功能。在分类里，我把他分在了AOP 模块下，在Spring 官方文档里对这个地方也有点含糊不清，这里是纯个人观点。 数据访问与集成由spring-jdbc、spring-tx、spring-orm、spring-jms和spring-oxm 5个模块组成。 &emsp;&emsp; spring-jdbc模块是Spring 提供的JDBC抽象框架的主要实现模块，用于简化SpringJDBC操作 。主要是提供JDBC模板方式、关系数据库对象化方式、SimpleJdbc方式、事务管理来简化JDBC编程，主要实现类是JdbcTemplate、SimpleJdbcTemplate以及NamedParameterJdbcTemplate。 &emsp;&emsp; spring-tx模块是Spring JDBC事务控制实现模块。使用Spring框架，它对事务做了很好的封装，通过它的AOP配置，可以灵活的配置在任何一层；但是在很多的需求和应用，直接使用JDBC事务控制还是有其优势的。其实，事务是以业务逻辑为基础的；一个完整的业务应该对应业务层里的一个方法；如果业务操作失败，则整个事务回滚；所以，事务控制是绝对应该放在业务层的；但是，持久层的设计则应该遵循一个很重要的原则：保证操作的原子性，即持久层里的每个方法都应该是不可以分割的。所以，在使用Spring JDBC事务控制时，应该注意其特殊性。 &emsp;&emsp; spring-orm模块是ORM 框架支持模块，主要集成 Hibernate, Java Persistence API (JPA) 和Java Data Objects (JDO) 用于资源管理、数据访问对象(DAO)的实现和事务策略。spring-oxm模块主要提供一个抽象层以支撑OXM（OXM是Object-to-XML-Mapping的缩写，它是一个O/M-mapper，将java对象映射成XML数据，或者将XML数据映射成java对象），例如：JAXB, Castor, XMLBeans, JiBX 和 XStream等。 &emsp;&emsp; spring-jms模块（JavaMessagingService）能够发送和接收信息，自SpringFramework4.1以后，他还提供了对spring-messaging模块的支撑。 Web组件&emsp;&emsp; 由spring-web、spring-webmvc、spring-websocket 和spring-webflux 4个模块组成。 &emsp;&emsp; spring-web模块为Spring提供了最基础Web支持，主要建立于核心容器之上，通过Servlet或者Listeners 来初始化IOC 容器，也包含一些与Web相关的支持。 &emsp;&emsp;spring-webmvc模块众所周知是一个的Web-Servlet模块，实现了Spring MVC（model-view-Controller）的Web应用。 &emsp;&emsp; spring-websocket模块主要是与Web前端的全双工通讯的协议。 &emsp;&emsp; spring-webflux是一个新的非堵塞函数式 Reactive Web 框架，可以用来建立异步的，非阻塞，事件驱动的服务，并且扩展性非常好。 通信报文&emsp;&emsp; 即spring-messaging模块，是从Spring4开始新加入的一个模块，主要职责是为Spring 框架集成一些基础的报文传送应用。 集成测试&emsp;&emsp; 即spring-test 模块，主要为测试提供支持的，毕竟在不需要发布（程序）到你的应用服务器或者连接到其他企业设施的情况下能够执行一些集成测试或者其他测试对于任何企业都是非常重要的。 集成兼容&emsp;&emsp; 即spring-framework-bom模块，Bill of Materials.解决Spring的不同模块依赖版本不同问题。 各模块之间的依赖关系Spring官网对Spring5各模块之间的关系也做了详细说明： 我本人也对Spring5 各模块做了一次系统的总结，描述模块之间的依赖关系，希望能对小伙伴们有所帮助。","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring 事务详谈(9)","slug":"spring/Spring 事务详谈(9)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-shi-wu-xiang-tan-9/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-shi-wu-xiang-tan-9/","excerpt":"","text":"9. Spring 事务详谈 从Spring事务配置说起先看看Spring事务的基础配置 &lt;aop:aspectj-autoproxy proxy-target-class=\"true\"/> &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> &lt;property name=\"dataSource\" ref=\"dataSource\"/> &lt;/bean> &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/> &lt;!-- 配置事务传播特性 --> &lt;tx:advice id=\"transactionAdvice\" transaction-manager=\"transactionManager\"> &lt;tx:attributes> &lt;tx:method name=\"add*\" propagation=\"REQUIRED\" rollback-for=\"Exception,RuntimeException,SQLException\"/> &lt;tx:method name=\"remove*\" propagation=\"REQUIRED\" rollback-for=\"Exception,RuntimeException,SQLException\"/> &lt;tx:method name=\"modify*\" propagation=\"REQUIRED\" rollback-for=\"Exception,RuntimeException,SQLException\"/> &lt;tx:method name=\"login\" propagation=\"NOT_SUPPORTED\"/> &lt;tx:method name=\"query*\" read-only=\"true\"/> &lt;/tx:attributes> &lt;/tx:advice> &lt;aop:config> &lt;aop:pointcut expression=\"execution(public * com.gupaoedu.vip..*.service..*Service.*(..))\" id=\"transactionPointcut\"/> &lt;aop:advisor pointcut-ref=\"transactionPointcut\" advice-ref=\"transactionAdvice\"/> &lt;/aop:config> 数据库事务原理详解1. 事务基本概念事务(Transaction)是访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。特点：事务是恢复和并发控制的基本单位。事务应该具有 4 个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为 ACID 特性。 原子性（Automicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。 一致性（Consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性（Isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性（Durability）。持久性也称永久性（Permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 2、事务的基本原理Spring 事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，Spring 是无法提供事务功能的。对于纯 JDBC 操作数据库，想要用到事务，可以按照以下步骤进行： 获取连接 Connection con = DriverManager.getConnection() 开启事务 con.setAutoCommit(true/false); 执行 CRUD 提交事务/回滚事务 con.commit() / con.rollback(); 关闭连接 conn.close(); 使用 Spring 的事务管理功能后，我们可以不再写步骤 2 和 4 的代码，而是由 Spirng 自动完成。 那么 Spring 是如何在我们书写的 CRUD 之前和之后开启事务和关闭事务的呢？解决这个问题，也就可以从整体上理解 Spring 的事务管理实现原理了。下面简单地介绍下，注解方式为例子 配置文件开启注解驱动，在相关的类和方法上通过注解@Transactional 标识。Spring 在启动的时候会去解析生成相关的 bean，这时候会查看拥有相关注解的类和方法，并且为这些类和方法生成代理，并根据@Transaction 的相关参数进行相关配置注入，这样就在代理中为我们把相关的事务处理掉了（开启正常提交事务，异常回滚事务）。真正的数据库层的事务提交和回滚是通过 binlog 或者 redo log 实现的。 3、Spring 事务的传播属性所谓 spring 事务的传播属性，就是定义在存在多个事务同时存在的时候，spring 应该如何处理这些事务的行为。这些属性在 TransactionDefinition 中定义，具体常量的解释见下表：| 常量名称 | 常量解释 | || ————————- | ———————————————————— | —- || PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择，也是 Spring默认的事务的传播。 | || PROPAGATION_REQUIRES_NEW | 新建事务,如果当前存在事务,把当前事务挂起。新建的事务将和被挂起的事务没有任何关系两个独立的事务，外层事务失败回滚之后，不能回滚内层事务执行的结果，内层事务失败抛出异常，外层事务捕获，也可以不处理回滚操作 | || PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 | || PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 | || PROPAGATION_NOT_SUPPORTED | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 | || PROPAGATION_NEVER | 以非事务方式执行，如果当前存在事务，则抛出异常。 | || PROPAGATION_NESTED | 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED 属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager 事务管理器起效。 | | 4、数据库隔离级别 隔离级别 隔离级别的值 导致的问题 Read-Uncommitted 0 导致脏读 Read-Committed 1 避免脏读，允许不可重复读和幻读 Repeatable-Read 2 避免脏读，不可重复读，允许幻读 Serializable 3 串行化读，事务只能一个一个执行，避免了脏读、不可重复读、幻读。执行效率慢，使用时慎重 脏读：一事务对数据进行了增删改，但未提交，另一事务可以读取到未提交的数据。如果第一个事务这时候回滚了，那么第二个事务就读到了脏数据。 不可重复读：一个事务中发生了两次读操作，第一次读操作和第二次操作之间，另外一个事务对数据进行了修改，这时候两次读取的数据是不一致的。 幻读：第一个事务对一定范围的数据进行批量修改，第二个事务在这个范围增加一条数据，这时候第一个事务就会丢失对新增数据的修改。 总结： 隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。大多数的数据库默认隔离级别为 Read Commited，比如 SqlServer、Oracle少数数据库默认隔离级别为：Repeatable Read 比如： MySQL InnoDB 5、Spring 中的隔离级别 常量 解释 ISOLATION_DEFAULT 这是个 PlatfromTransactionManager 默认的隔离级别，使用数据库默认的事务隔离级别。另外四个与 JDBC 的隔离级别相对应。 ISOLATION_READ_UNCOMMITTED 这是事务最低的隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻像读。 ISOLATION_READ_COMMITTED 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。 ISOLATION_REPEATABLE_READ 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。 6、事务的嵌套通过上面的理论知识的铺垫，我们大致知道了数据库事务和 Spring 事务的一些属性和特点，接下来我们通过分析一些嵌套事务的场景，来深入理解 Spring 事务传播的机制。 假设外层事务 Service A 的 Method A() 调用 内层 Service B 的 Method B()PROPAGATION_REQUIRED(Spring 默认) 如果 ServiceB.MethodB() 的事务级别定义为 PROPAGATION_REQUIRED，那么执行ServiceA.MethodA() 的时候 Spring 已经起了事务，这时调用 ServiceB.MethodB()，ServiceB.MethodB() 看到自己已经运行在 ServiceA.MethodA() 的事务内部，就不再起新的事务。 假如 ServiceB.MethodB() 运行的时候发现自己没有在事务中，他就会为自己分配一个事务。 这样，在 ServiceA.MethodA() 或者在 ServiceB.MethodB() 内的任何地方出现异常，事务都会被回滚。 PROPAGATION_REQUIRES_NEW 比如我们设计 ServiceA.MethodA() 的事务级别为 PROPAGATION_REQUIRED，ServiceB.MethodB() 的事务级别为 PROPAGATION_REQUIRES_NEW。 那么当执行到 ServiceB.MethodB() 的时候，ServiceA.MethodA() 所在的事务就会挂起，ServiceB.MethodB() 会起一个新的事务，等待 ServiceB.MethodB() 的事务完成以后，它才继续执行。 他 与 PROPAGATION_REQUIRED 的 事 务 区 别 在 于 事 务 的 回 滚 程 度 了 。 因 为ServiceB.MethodB() 是 新 起 一 个 事 务 ， 那 么 就 是 存 在 两 个 不 同 的 事 务 。 如 果ServiceB.MethodB() 已 经 提 交 ， 那 么 ServiceA.MethodA() 失 败 回 滚 ，ServiceB.MethodB() 是不会回滚的。如果 ServiceB.MethodB() 失败回滚，如果他抛 出的异常被 ServiceA.MethodA() 捕获，ServiceA.MethodA() 事务仍然可能提交(主要看 B 抛出的异常是不是 A 会回滚的异常)。 PROPAGATION_SUPPORTS &nbsp;&nbsp;假设 ServiceB.MethodB() 的事务级别为 PROPAGATION_SUPPORTS，那么当执行到ServiceB.MethodB()时，如果发现 ServiceA.MethodA()已经开启了一个事务，则加入当前的事务，如果发现 ServiceA.MethodA()没有开启事务，则自己也不开启事务。这种时候，内部方法的事务性完全依赖于最外层的事务。 PROPAGATION_NESTED &nbsp;&nbsp;现 在 的 情 况 就 变 得 比 较 复 杂 了 , ServiceB.MethodB() 的 事 务 属 性 被 配 置 为PROPAGATION_NESTED, 此时两者之间又将如何协作呢? ServiceB.MethodB() 如果 rollback, 那么内部事务(即 ServiceB.MethodB()) 将回滚到它执行前的 SavePoint而外部事务(即 ServiceA.MethodA()) 可以有以下两种处理方式:捕获异常，执行异常分支逻辑 void MethodA() &amp;#123; try &amp;#123; ServiceB.MethodB(); &amp;#125; catch (SomeException) &amp;#123; // 执行其他业务, 如 ServiceC.MethodC(); &amp;#125; &amp;#125; 这 种 方 式 也 是 嵌 套 事 务 最 有 价 值 的 地 方 , 它 起 到 了 分 支 执 行 的 效 果 , 如 果ServiceB.MethodB()失败, 那么执行 ServiceC.MethodC(), 而 ServiceB.MethodB()已经回滚到它执行之前的 SavePoint, 所以不会产生脏数据(相当于此方法从未执行过), 这 种 特 性 可 以 用 在 某 些 特 殊 的 业 务 中 , 而 PROPAGATION_REQUIRED 和PROPAGATION_REQUIRES_NEW 都没有办法做到这一点。 外部事务回滚/提交 代码不做任何修改, 那么如果内部事务(ServiceB.MethodB())rollback, 那么首先 ServiceB.MethodB() 回滚到它执行之前的 SavePoint(在任何情况下都会如此), 外部事务(即 ServiceA.MethodA()) 将根据具体的配置决定自己是commit 还是 rollback。 另外三种事务传播属性基本用不到，在此不做分析 7、Spring 事务 API 架构图 使用 Spring 进行基本的 JDBC 访问数据库有多种选择。Spring 至少提供了三种不同的工作模式：JdbcTemplate, 一个在 Spring2.5 中新提供的 SimpleJdbc 类能够更好的处理数据库元数据; 还有一种称之为 RDBMS Object 的风格的面向对象封装方式, 有点类似于 JDO 的查询设计。 我们在这里简要列举你采取某一种工作方式的主要理由. 不过请注意, 即使你选择了其中的一种工作模式, 你依然可以在你的代码中混用其他任何一种模式以获取其带来的好处和优势。 所有的工作模式都必须要求 JDBC 2.0 以上的数据库驱动的支持, 其中一些高级的功能可能需要 JDBC 3.0 以上的数据库驱动支持。JdbcTemplate - 这是经典的也是最常用的 Spring 对于 JDBC 访问的方案。这也是最低级别的封装, 其他的工作模式事实上在底层使用了 JdbcTemplate 作为其底层的实现基础。JdbcTemplate 在 JDK 1.4 以上的环境上工作得很好。NamedParameterJdbcTemplate - 对 JdbcTemplate 做了封装，提供了更加便捷的基于命名参数的使用方式而不是传统的 JDBC 所使用的“?”作为参数的占位符。这种方式在你需要为某个 SQL 指定许多个参数时，显得更加直观而易用。该特性必须工作在 JDK1.4 以上。 SimpleJdbcTemplate - 这 个 类 结 合 了 JdbcTemplate 和NamedParameterJdbcTemplate 的最常用的功能，同时它也利用了一些 Java 5 的特性所带来的优势，例如泛型、varargs 和 autoboxing 等，从而提供了更加简便的 API 访问方式。需要工作在 Java 5 以上的环境中。SimpleJdbcInsert 和 SimpleJdbcCall - 这两个类可以充分利用数据库元数据的特性来简化配置。通过使用这两个类进行编程，你可以仅仅提供数据库表名或者存储过程的名称以及一个 Map 作为参数。其中 Map 的 key 需要与数据库表中的字段保持一致。这两个类通常和 SimpleJdbcTemplate 配合使用。这两个类需要工作在 JDK 5 以上，同时数据库需要提供足够的元数据信息。 RDBMS 对象包括 MappingSqlQuery, SqlUpdate and StoredProcedure - 这种方式允许你在初始化你的数据访问层时创建可重用并且线程安全的对象。该对象在你定义了你的查询语句，声明查询参数并编译相应的 Query 之后被模型化。一旦模型化完成，任何执行函数就可以传入不同的参数对之进行多次调用。这种方式需要工作在 JDK 1.4 以上。 异常处理异常结构如下：SQLExceptionTranslator 是 一 个 接 口 ， 如 果 你 需 要 在 SQLException 和org.springframework.dao.DataAccessException 之间作转换，那么必须实现该接口。转换器类的实现可以采用一般通用的做法(比如使用 JDBC 的 SQLState code)，如果为了使转换更准确，也可以进行定制（比如使用 Oracle 的 error code）。SQLErrorCodeSQLExceptionTranslator 是 SQLExceptionTranslator 的默认实现。 该实现使用指定数据库厂商的 error code，比采用 SQLState 更精确。转换过程基于一个JavaBean （ 类 型 为 SQLErrorCodes ） 中 的 error code 。 这 个 JavaBean 由SQLErrorCodesFactory 工厂类创建，其中的内容来自于 “sql-error-codes.xml”配置文 件 。 该 文 件 中 的 数 据 库 厂 商 代 码 基 于 Database MetaData 信 息 中 的DatabaseProductName，从而配合当前数据库的使用。 SQLErrorCodeSQLExceptionTranslator 使用以下的匹配规则： 首 先 检 查 是 否 存 在 完 成 定 制 转 换 的 子 类 实 现 。 通 常SQLErrorCodeSQLExceptionTranslator 这个类可以作为一个具体类使用，不需要进行定制，那么这个规则将不适用。 接着将 SQLException 的 error code 与错误代码集中的 error code 进行匹配。 默认情况下错误代码集将从 SQLErrorCodesFactory 取得。 错误代码集来自 classpath 下的sql-error-codes.xml 文件，它们将与数据库 metadata 信息中的 database name 进行映射。 使用 fallback 翻译器。SQLStateSQLExceptionTranslator 类是缺省的 fallback 翻译器。config 模块 NamespaceHandler 接口，DefaultBeanDefinitionDocumentReader 使用该接口来处理在 spring xml 配置文件中自定义的命名空间。 在 jdbc 模块，我们使用 JdbcNamespaceHandler 来处理 jdbc 配置的命名空间，其代码如下： public class JdbcNamespaceHandler extends NamespaceHandlerSupport &amp;#123; @Override public void init() &amp;#123; registerBeanDefinitionParser(\"embedded-database\", new EmbeddedDatabaseBeanDefinitionParser()); registerBeanDefinitionParser(\"initialize-database\", new InitializeDatabaseBeanDefinitionParser()); &amp;#125; &amp;#125; 其 中 ， EmbeddedDatabaseBeanDefinitionParser 继 承 了AbstractBeanDefinitionParser ， 解 析 元 素 ， 并 使 用EmbeddedDatabaseFactoryBean 创建一个 BeanDefinition。顺便介绍一下用到的软件包 org.w3c.dom。 软件包 org.w3c.dom:为文档对象模型 (DOM) 提供接口，该模型是 Java API for XMLProcessing 的组件 API。该 Document Object Model Level 2 Core API 允许程序动态访问和更新文档的内容和结构。 Attr：Attr 接口表示 Element 对象中的属性。 CDATASection： CDATA 节用于转义文本块，该文本块包含的字符如果不转义则会被视为标记。 CharacterData： CharacterData 接口使用属性集合和用于访问 DOM 中字符数据的方法扩展节点。 Comment： 此接口继承自 CharacterData 表示注释的内容，即起始 ‘‘ 之间的所有字符。 Document： Document 接口表示整个 HTML 或 XML 文档。 DocumentFragment： DocumentFragment 是“轻量级”或“最小”Document 对象。 DocumentType： 每个 Document 都有 doctype 属性，该属性的值可以为 null，也可以为 DocumentType 对象。 DOMConfiguration： 该 DOMConfiguration 接口表示文档的配置，并维护一个可识别的参数表。 DOMError： DOMError 是一个描述错误的接口。 DOMErrorHandler： DOMErrorHandler 是在报告处理 XML 数据时发生的错误或在进行某些其他处理（如验证文档）时 DOM 实现可以调用的回调接口。 DOMImplementation： DOMImplementation 接口为执行独立于文档对象模型的任何特定实例的操作提供了许多方法。 DOMImplementationList： DOMImplementationList 接口提供对 DOM 实现的有序集合的抽象，没有定义或约束如何实现此集合。 DOMImplementationSource： 此接口允许 DOM 实现程序根据请求的功能和版本提供一个或多个实现，如下所述。 DOMLocator： DOMLocator 是一个描述位置（如发生错误的位置）的接口。 DOMStringList： DOMStringList 接口提供对 DOMString 值的有序集合的抽象，没有定义或约束此集合是如何实现的。 Element： Element 接口表示 HTML 或 XML 文档中的一个元素。 Entity： 此接口表示在 XML 文档中解析和未解析的已知实体。 EntityReference： EntityReference 节点可以用来在树中表示实体引用。 NamedNodeMap： 实现 NamedNodeMap 接口的对象用于表示可以通过名称访问的节点的集合。 NameList NameList 接口提供对并行的名称和名称空间值对（可以为 null 值）的有序集合的抽象，无需定义或约束如何实现此集合。 Node： 该 Node 接口是整个文档对象模型的主要数据类型。 NodeList： NodeList 接口提供对节点的有序集合的抽象，没有定义或约束如何实现此集合。 Notation： 此接口表示在 DTD 中声明的表示法。 ProcessingInstruction： ProcessingInstruction 接口表示“处理指令”，该指令作为一种在文档的文本中保持特定于处理器的信息的方法在 XML 中使用。 Text： 该 Text 接口继承自 CharacterData，并且表示 Element 或 Attr 的文本内容（在 XML 中称为 字符数据）。 TypeInfo： TypeInfo 接口表示从 Element 或 Attr 节点引用的类型，用与文档相关的模式指定。 UserDataHandler： 当使用 Node.setUserData() 将一个对象与节点上的键相关联时，当克隆、导入或重命名该对象关联的节点时应用程序可以提供调用的处理程序。 core 模块 1.JdbcTeamplate 对象，其结构如下： 2.RowMapper3.元数据 metaData 模块本节中 Spring 应用到工厂模式，结合代码可以更具体了解。CallMetaDataProviderFactory 创建 CallMetaDataProvider 的工厂类，其代码如下： public static final List&lt;String> supportedDatabaseProductsForProcedures = Arrays.asList( \"Apache Derby\", \"DB2\", \"MySQL\", \"Microsoft SQL Server\", \"Oracle\", \"PostgreSQL\", \"Sybase\" ); /** List of supported database products for function calls */ public static final List&lt;String> supportedDatabaseProductsForFunctions = Arrays.asList( \"MySQL\", \"Microsoft SQL Server\", \"Oracle\", \"PostgreSQL\" ); static public CallMetaDataProvider createMetaDataProvider(DataSource dataSource, final CallMetaDataContext context) &amp;#123; try &amp;#123; CallMetaDataProvider result = (CallMetaDataProvider) JdbcUtils.extractDatabaseMetaData(dataSource, databaseMetaData -> &amp;#123; String databaseProductName = JdbcUtils.commonDatabaseName(databaseMetaData.getDatabaseProductName()); boolean accessProcedureColumnMetaData = context.isAccessCallParameterMetaData(); if (context.isFunction()) &amp;#123; if (!supportedDatabaseProductsForFunctions.contains(databaseProductName)) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(databaseProductName + \" is not one of the databases fully supported for function calls \" + \"-- supported are: \" + supportedDatabaseProductsForFunctions); &amp;#125; if (accessProcedureColumnMetaData) &amp;#123; logger.warn(\"Metadata processing disabled - you must specify all parameters explicitly\"); accessProcedureColumnMetaData = false; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; if (!supportedDatabaseProductsForProcedures.contains(databaseProductName)) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(databaseProductName + \" is not one of the databases fully supported for procedure calls \" + \"-- supported are: \" + supportedDatabaseProductsForProcedures); &amp;#125; if (accessProcedureColumnMetaData) &amp;#123; logger.warn(\"Metadata processing disabled - you must specify all parameters explicitly\"); accessProcedureColumnMetaData = false; &amp;#125; &amp;#125; &amp;#125; CallMetaDataProvider provider; if (\"Oracle\".equals(databaseProductName)) &amp;#123; provider = new OracleCallMetaDataProvider(databaseMetaData); &amp;#125; else if (\"DB2\".equals(databaseProductName)) &amp;#123; provider = new Db2CallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"Apache Derby\".equals(databaseProductName)) &amp;#123; provider = new DerbyCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"PostgreSQL\".equals(databaseProductName)) &amp;#123; provider = new PostgresCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"Sybase\".equals(databaseProductName)) &amp;#123; provider = new SybaseCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"Microsoft SQL Server\".equals(databaseProductName)) &amp;#123; provider = new SqlServerCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"HDB\".equals(databaseProductName)) &amp;#123; provider = new HanaCallMetaDataProvider((databaseMetaData)); &amp;#125; else &amp;#123; provider = new GenericCallMetaDataProvider(databaseMetaData); &amp;#125; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Using \" + provider.getClass().getName()); &amp;#125; provider.initializeWithMetaData(databaseMetaData); if (accessProcedureColumnMetaData) &amp;#123; provider.initializeWithProcedureColumnMetaData(databaseMetaData, context.getCatalogName(), context.getSchemaName(), context.getProcedureName()); &amp;#125; return provider; &amp;#125;); return result; &amp;#125; catch (MetaDataAccessException ex) &amp;#123; throw new DataAccessResourceFailureException(\"Error retrieving database metadata\", ex); &amp;#125; &amp;#125; TableMetaDataProviderFactory 创建 TableMetaDataProvider 工厂类，其创建过程如下： static public CallMetaDataProvider createMetaDataProvider(DataSource dataSource, final CallMetaDataContext context) &amp;#123; try &amp;#123; CallMetaDataProvider result = (CallMetaDataProvider) JdbcUtils.extractDatabaseMetaData(dataSource, databaseMetaData -> &amp;#123; String databaseProductName = JdbcUtils.commonDatabaseName(databaseMetaData.getDatabaseProductName()); boolean accessProcedureColumnMetaData = context.isAccessCallParameterMetaData(); if (context.isFunction()) &amp;#123; if (!supportedDatabaseProductsForFunctions.contains(databaseProductName)) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(databaseProductName + \" is not one of the databases fully supported for function calls \" + \"-- supported are: \" + supportedDatabaseProductsForFunctions); &amp;#125; if (accessProcedureColumnMetaData) &amp;#123; logger.warn(\"Metadata processing disabled - you must specify all parameters explicitly\"); accessProcedureColumnMetaData = false; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; if (!supportedDatabaseProductsForProcedures.contains(databaseProductName)) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(databaseProductName + \" is not one of the databases fully supported for procedure calls \" + \"-- supported are: \" + supportedDatabaseProductsForProcedures); &amp;#125; if (accessProcedureColumnMetaData) &amp;#123; logger.warn(\"Metadata processing disabled - you must specify all parameters explicitly\"); accessProcedureColumnMetaData = false; &amp;#125; &amp;#125; &amp;#125; CallMetaDataProvider provider; if (\"Oracle\".equals(databaseProductName)) &amp;#123; provider = new OracleCallMetaDataProvider(databaseMetaData); &amp;#125; else if (\"DB2\".equals(databaseProductName)) &amp;#123; provider = new Db2CallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"Apache Derby\".equals(databaseProductName)) &amp;#123; provider = new DerbyCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"PostgreSQL\".equals(databaseProductName)) &amp;#123; provider = new PostgresCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"Sybase\".equals(databaseProductName)) &amp;#123; provider = new SybaseCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"Microsoft SQL Server\".equals(databaseProductName)) &amp;#123; provider = new SqlServerCallMetaDataProvider((databaseMetaData)); &amp;#125; else if (\"HDB\".equals(databaseProductName)) &amp;#123; provider = new HanaCallMetaDataProvider((databaseMetaData)); &amp;#125; else &amp;#123; provider = new GenericCallMetaDataProvider(databaseMetaData); &amp;#125; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Using \" + provider.getClass().getName()); &amp;#125; provider.initializeWithMetaData(databaseMetaData); if (accessProcedureColumnMetaData) &amp;#123; provider.initializeWithProcedureColumnMetaData(databaseMetaData, context.getCatalogName(), context.getSchemaName(), context.getProcedureName()); &amp;#125; return provider; &amp;#125;); return result; &amp;#125; catch (MetaDataAccessException ex) &amp;#123; throw new DataAccessResourceFailureException(\"Error retrieving database metadata\", ex); &amp;#125; &amp;#125; 使用 SqlParameterSource 提供参数值使用 Map 来指定参数值有时候工作得非常好，但是这并不是最简单的使用方式。Spring提供了一些其他的 SqlParameterSource 实现类来指定参数值。 我们首先可以看看BeanPropertySqlParameterSource 类，这是一个非常简便的指定参数的实现类，只要你有一个符合 JavaBean 规范的类就行了。它将使用其中的 getter 方法来获取参数值。 SqlParameter 封 装 了 定 义 sql 参 数 的 对 象 。 CallableStateMentCallback ，PrePareStateMentCallback，StateMentCallback，ConnectionCallback 回调类分别对应 JdbcTemplate 中的不同处理方法。 simple 实现Spring 通过 DataSource 获取数据库的连接。Datasource 是 jdbc 规范的一部分，它通过 ConnectionFactory 获取。一个容器和框架可以在应用代码层中隐藏连接池和事务管理。 当使用 spring 的 jdbc 层，你可以通过 JNDI 来获取 DataSource，也可以通过你自己配置的第三方连接池实现来获取。流行的第三方实现由 apache Jakarta Commonsdbcp 和 c3p0。 TransactionAwareDataSourceProxy 作为目标 DataSource 的一个代理， 在对目标DataSource 包装的同时，还增加了 Spring 的事务管理能力， 在这一点上，这个类的功能非常像 J2EE 服务器所提供的事务化的 JNDI DataSource。 该类几乎很少被用到，除非现有代码在被调用的时候需要一个标准的 JDBC DataSource接口实现作为参数。 这种情况下，这个类可以使现有代码参与 Spring 的事务管理。通常最好的做法是使用更高层的抽象 来对数据源进行管理，比如 JdbcTemplate 和DataSourceUtils 等等。 注意：DriverManagerDataSource 仅限于测试使用，因为它没有提供池的功能，这会导致在多个请求获取连接时性能很差。 object 模块 JdbcTemplateJdbcTemplate 是 core 包的核心类。它替我们完成了资源的创建以及释放工作，从而简化了我们对 JDBC 的使用。 它还可以帮助我们避免一些常见的错误，比如忘记关闭数据库连接。 JdbcTemplate 将完成 JDBC 核心处理流程，比如 SQL 语句的创建、执行，而把 SQL 语句的生成以及查询结果的提取工作留给我们的应用代码。 它可以完成 SQL 查询、更新以及调用存储过程，可以对 ResultSet 进行遍历并加以提取。它还可以捕获 JDBC异常并将其转换成 org.springframework.dao 包中定义的，通用的，信息更丰富的异常。使用 JdbcTemplate 进行编码只需要根据明确定义的一组契约来实现回调接口。PreparedStatementCreator 回调接口通过给定的 Connection 创建一个PreparedStatement，包含 SQL 和任何相关的参数。 CallableStatementCreateor 实 现同样的处理，只不过它创建的是 CallableStatement。 RowCallbackHandler 接口则从数据集的每一行中提取值。 我们可以在 DAO 实现类中通过传递一个 DataSource 引用来完成 JdbcTemplate 的实例化，也可以在 Spring 的 IOC 容器中配置一个 JdbcTemplate 的 bean 并赋予 DAO 实现类作为一个实例。 需要注意的是 DataSource 在 Spring 的 IOC 容器中总是配制成一个bean，第一种情况下，DataSource bean 将传递给 service，第二种情况下 DataSourcebean 传递给 JdbcTemplate bean。 NamedParameterJdbcTemplate NamedParameterJdbcTemplate 类为 JDBC 操作增加了命名参数的特性支持，而不是传 统 的 使 用 （ ‘?’ ） 作 为 参 数 的 占 位 符 。 NamedParameterJdbcTemplate 类 对JdbcTemplate 类进行了封装， 在底层，JdbcTemplate 完成了多数的工作。","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring 中经典的高频面试题(11)","slug":"spring/Spring 中经典的高频面试题(11)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-zhong-jing-dian-de-gao-pin-mian-shi-ti-11/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-zhong-jing-dian-de-gao-pin-mian-shi-ti-11/","excerpt":"","text":"11 . Spring 中经典的高频面试题1、什么是 Spring 框架？Spring 框架有哪些主要模块？Spring 框架是一个为 Java 应用程序的开发提供了综合、广泛的基础性支持的 Java 平台。Spring 帮助开发者解决了开发中基础性的问题，使得开发人员可以专注于应用程序的开发。Spring 框架本身亦是按照设计模式精心打造，这使得我们可以在开发环境中安心的集成 Spring 框架，不必担心 Spring 是如何在后台进行工作的。 Spring 框架至今已集成了 20 多个模块。这些模块主要被分如下图所示的核心容器、数据访问/集成,、 Web、AOP（面向切面编程）、工具、消息和测试模块。 2、使用 Spring 框架能带来哪些好处？下面列举了一些使用 Spring 框架带来的主要好处： Dependency Injection(DI) 方法使得构造器和 JavaBean properties 文件中的依赖关系一目了然。 与 EJB 容器相比较，IOC 容器更加趋向于轻量级。这样一来 IOC 容器在有限的内存和 CPU 资源的情况下进行应用程序的开发和发布就变得十分有利。 Spring 并没有闭门造车，Spring 利用了已有的技术比如 ORM 框架、logging 框架、J2EE、Quartz和 JDK Timer，以及其他视图技术。 Spring 框架是按照模块的形式来组织的。由包和类的编号就可以看出其所属的模块，开发者仅仅需要选用他们需要的模块即可。 要测试一项用 Spring 开发的应用程序十分简单，因为测试相关的环境代码都已经囊括在框架中了。更加简单的是，利用 JavaBean 形式的 POJO 类，可以很方便的利用依赖注入来写入测试数据。 Spring 的 Web 框架亦是一个精心设计的 Web MVC 框架，为开发者们在 web 框架的选择上提供了一个除了主流框架比如 Struts、过度设计的、不流行 web 框架的以外的有力选项。 Spring 提供了一个便捷的事务管理接口，适用于小型的本地事务处理（比如在单 DB 的环境下）和复杂的共同事务处理（比如利用 JTA 的复杂 DB 环境）。 3、什么是控制反转(IOC)？什么是依赖注入？ 控制反转是应用于软件工程领域中的，在运行时被装配器对象来绑定耦合对象的一种编程技巧，对象之间耦合关系在编译时通常是未知的。在传统的编程方式中，业务逻辑的流程是由应用程序中的早已被设定好关联关系的对象来决定的。在使用控制反转的情况下，业务逻辑的流程是由对象关系图来决定的，该对象关系图由装配器负责实例化，这种实现方式还可以将对象之间的关联关系的定义抽象化。而绑定的过程是通过“依赖注入”实现的。 控制反转是一种以给予应用程序中目标组件更多控制为目的设计范式，并在我们的实际工作中起到了有效的作用。 依赖注入是在编译阶段尚未知所需的功能是来自哪个的类的情况下，将其他对象所依赖的功能对象实例化的模式。这就需要一种机制用来激活相应的组件以提供特定的功能，所以依赖注入是控制反转的基础。否则如果在组件不受框架控制的情况下，框架又怎么知道要创建哪个组件？ 4、在 Java 中依赖注入有哪些方式？ 构造器注入 Setter 方法注入 接口注入 5 BeanFactory 和 ApplicationContext 有什么区别？BeanFactory 可以理解为含有 bean 集合的工厂类。BeanFactory 包含了种 bean 的定义，以便在接收到客户端请求时将对应的 bean 实例化。 BeanFactory 还能在实例化对象的时生成协作类之间的关系。此举将 bean 自身与 bean 客户端的配置中解放出来。BeanFactory 还包含了 bean 生命周期的控制，调用客户端的初始化方法（initializationMethods）和销毁方法（destruction Methods）。 从表面上看，ApplicationContext 如同 bean factory 一样具有 bean 定义、bean 关联关系的设置，根据请求分发 bean 的功能。但 ApplicationContext 在此基础上还提供了其他的功能。 提供了支持国际化的文本消息 统一的资源文件读取方式 已在监听器中注册的 bean 的事件 以下是三种较常见的 ApplicationContext 实现方式： ClassPathXmlApplicationContext：从 classpath 的 XML 配置文件中读取上下文，并生成上下文定义。应用程序上下文从程序环境变量中取得。ApplicationContext context = new ClassPathXmlApplicationContext(“application.xml”); FileSystemXmlApplicationContext ：由文件系统中的 XML 配置文件读取上下文。ApplicationContext context = new FileSystemXmlApplicationContext(“application.xml”); XmlWebApplicationContext：由 Web 应用的 XML 文件读取上下文。 6、Spring 提供几种配置方式来设置元数据？将 Spring 配置到应用开发中有以下三种方式： 基于 XML 的配置 基于注解的配置 基于 Java 的配置 7、如何使用 XML 配置的方式配置 Spring？在 Spring 框架中，依赖和服务需要在专门的配置文件来实现，我常用的 XML 格式的配置文件。这些配置文件的格式通常用开头，然后一系列的 SpringXML 配置的主要目的时候是使所有的 Spring 组件都可以用 xml 文件的形式来进行配置。这意味着不会出现其他的 Spring 配置类型（比如声明的方式或基于 Java Class 的配置方式） Spring 的 XML 配置方式是使用被 Spring 命名空间的所支持的一系列的 XML 标签来实现的。Spring有以下主要的命名空间：context、beans、jdbc、tx、aop、mvc 和 aso。 &lt;beans> &lt;!-- JSON Support --> &lt;bean name=\"viewResolver\" class=\"org.springframework.web.servlet.view.BeanNameViewResolver\"/> &lt;bean name=\"jsonTemplate\" class=\"org.springframework.web.servlet.view.json.MappingJackson2JsonView\"/> &lt;bean id=\"restTemplate\" class=\"org.springframework.web.client.RestTemplate\"/> &lt;/beans> 下面这个 web.xml 仅仅配置了 DispatcherServlet，这件最简单的配置便能满足应用程序配置运行时组件的需求。 &lt;web-app> &lt;display-name>Archetype Created Web Application&lt;/display-name> &lt;servlet> &lt;servlet-name>spring&lt;/servlet-name> &lt;servlet-class> org.springframework.web.servlet.DispatcherServlet &lt;/servlet-class> &lt;load-on-startup>1&lt;/load-on-startup> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>spring&lt;/servlet-name> &lt;url-pattern>/&lt;/url-pattern> &lt;/servlet-mapping> &lt;/web-app> 8、Spring 提供哪些配置形式？Spring 对 Java 配置的支持是由@Configuration 注解和@Bean 注解来实现的。由@Bean 注解的方法将会实例化、配置和初始化一个新对象，这个对象将由 Spring 的 IOC 容器来管理。@Bean 声明所起到的作用与 元素类似。被@Configuration 所注解的类则表示这个类的主要目的是作为 bean 定义的资源。被@Configuration 声明的类可以通过在同一个类的内部调用@bean 方法来设置嵌入 bean 的依赖关系。 最简单的@Configuration 声明类请参考下面的代码： @Configuration public class AppConfig&amp;#123; @Bean public MyService myService() &amp;#123; return new MyServiceImpl(); &amp;#125; &amp;#125; 对于上面的@Beans 配置文件相同的 XML 配置文件如下： &lt;beans> &lt;bean id=\"myService\" class=\"com.services.MyServiceImpl\"/> &lt;/beans> 上述配置方式的实例化方式如下：利用 AnnotationConfigApplicationContext 类进行实例化 public static void main(String[] args) &amp;#123; ApplicationContext ctx = new AnnotationConfigApplicationContext(AppConfig.class); MyService myService = ctx.getBean(MyService.class); myService.doStuff(); &amp;#125; 要使用组件组建扫描，仅需用@Configuration 进行注解即可： @Configuration @ComponentScan(basePackages = \"com\") public class AppConfig &amp;#123; &amp;#125; 在上面的例子中，com.gupaoedu 包首先会被扫到，然后再容器内查找被@Component 声明的类，找到后将这些类按照 Spring bean 定义进行注册。 如 果 你 要 在 你 的 web 应 用 开 发 中 选 用 上 述 的 配 置 的 方 式 的 话 ， 需 要 用AnnotationConfigWebApplicationContext 类来读取配置文件，可以用来配置 Spring 的 Servlet 监听器 ContrextLoaderListener 或者 Spring MVC 的 DispatcherServlet。 &lt;web-app> &lt;context-param> &lt;param-name>contextClass&lt;/param-name> &lt;param-value> org.springframework.web.context.support.AnnotationConfigWebApplicationContext &lt;/param-value> &lt;/context-param> &lt;context-param> &lt;param-name>contextConfigLocation&lt;/param-name> &lt;param-value>com.AppConfig&lt;/param-value> &lt;/context-param> &lt;listener> &lt;listener-class>org.springframework.web.context.ContextLoaderListener&lt;/listener-class> &lt;/listener> &lt;servlet> &lt;servlet-name>dispatcher&lt;/servlet-name> &lt;servlet-class>org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class> &lt;init-param> &lt;param-name>contextClass&lt;/param-name> &lt;param-value> org.springframework.web.context.support.AnnotationConfigWebApplicationContext &lt;/param-value> &lt;/init-param> &lt;init-param> &lt;param-name>contextConfigLocation&lt;/param-name> &lt;param-value>com.web.MVCConfig&lt;/param-value> &lt;/init-param> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>dispatcher&lt;/servlet-name> &lt;url-pattern>/web/*&lt;/url-pattern> &lt;/servlet-mapping> &lt;/web-app> 9、怎样用注解的方式配置 Spring？Spring 在 2.5 版本以后开始支持用注解的方式来配置依赖注入。可以用注解的方式来替代 XML 方式的bean 描述，可以将 bean 描述转移到组件类的内部，只需要在相关类上、方法上或者字段声明上使用注解即可。注解注入将会被容器在 XML 注入之前被处理，所以后者会覆盖掉前者对于同一个属性的处理结果。 注解装配在Spring 中是默认关闭的。所以需要在Spring文件中配置一下才能使用基于注解的装配模式。如果你想要在你的应用程序中使用关于注解的方法的话，请参考如下的配置。 &lt;beans> &lt;context:annotation-config/> &lt;/beans> 在标签配置完成以后，就可以用注解的方式在 Spring 中向属性、方法和构造方法中自动装配变量。下面是几种比较重要的注解类型： @Required：该注解应用于设值方法。 @Autowired：该注解应用于有值设值方法、非设值方法、构造方法和变量。 @Qualifier：该注解和@Autowired 注解搭配使用，用于消除特定 bean 自动装配的歧义。 JSR-250 Annotations：Spring 支持基于 JSR-250 注解的以下注解，@Resource、@PostConstruct和 @PreDestroy。 10、请解释 Spring Bean 的生命周期？Spring Bean 的生命周期简单易懂。在一个 bean 实例被初始化时，需要执行一系列的初始化操作以达到可用的状态。同样的，当一个 bean 不在被调用时需要进行相关的析构操作，并从 bean 容器中移除。 Spring bean factory 负责管理在 spring 容器中被创建的 bean 的生命周期。Bean 的生命周期由两组回调（call back）方法组成 初始化之后调用的回调方法。 销毁之前调用的回调方法。 Spring 框架提供了以下四种方式来管理 bean 的生命周期事件： InitializingBean 和 DisposableBean 回调接口 针对特殊行为的其他 Aware 接口 Bean 配置文件中的 Custom init()方法和 destroy()方法 @PostConstruct 和@PreDestroy 注解方式使用 customInit()和 customDestroy()方法管理 bean 生命周期的代码样例如下： &lt;beans> &lt;bean id=\"demoBean\" class=\"com.task.DemoBean\" init-Method=\"customInit\" destroy-Method=\"customDestroy\"> &lt;/bean> &lt;/beans> 11、Spring Bean 作用域之间的区别？Spring 容器中的 bean 可以分为 5 个范围。所有范围的名称都是自说明的，但是为了避免混淆，还是让我们来解释一下： singleton：这种 bean 范围是默认的，这种范围确保不管接受到多少个请求，每个容器中只有一个bean 的实例，单例的模式由 bean factory 自身来维护。 prototype：原形范围与单例范围相反，为每一个 bean 请求提供一个实例。 request：在请求 bean 范围内会每一个来自客户端的网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收。 Session：与请求范围类似，确保每个 session 中有一个 bean 的实例，在 session 过期后，bean 会随之失效。 global-session：global-session 和 Portlet 应用相关。当你的应用部署在 Portlet 容器中工作时，它包含很多 portlet。如果你想要声明让所有的 portlet 共用全局的存储变量的话，那么这全局变量需要存储在 global-session 中。 全局作用域与 Servlet 中的 session 作用域效果相同。 12、什么是 Spring inner beans？在 Spring 框架中，无论何时 bean 被使用时，当仅被调用了一个属性。一个明智的做法是将这个 bean声明为内部 bean。内部 bean 可以用 setter 注入“属性”和构造方法注入“构造参数”的方式来实现。比如，在我们的应用程序中，一个 Customer 类引用了一个 Person 类，我们的要做的是创建一个 Person的实例，然后在 Customer 内部使用。 public class Customer&amp;#123; private Person person; &amp;#125; public class Person&amp;#123; private String name; private String address; private int age; &amp;#125; 内部 bean 的声明方式如下： &lt;bean id=\"CustomerBean\" class=\"com.common.Customer\"> &lt;property name=\"person\"> &lt;bean class=\"com.common.Person\"> &lt;property name=\"name\" value=\"lokesh\" /> &lt;property name=\"address\" value=\"India\" /> &lt;property name=\"age\" value=\"34\" /> &lt;/bean> &lt;/property> &lt;/bean> 13、Spring 框架中的单例 Beans 是线程安全的么？Spring 框架并没有对单例 bean 进行任何多线程的封装处理。关于单例 bean 的线程安全和并发问题需要开发者自行去搞定。但实际上，大部分的 Spring bean 并没有可变的状态(比如 Serview 类和 DAO类)，所以在某种程度上说 Spring 的单例 bean 是线程安全的。如果你的 bean 有多种状态的话（比如View Model 对象），就需要自行保证线程安全。 最浅显的解决办法就是将多态 bean 的作用域由“singleton”变更为“prototype”。 14、请举例说明如何在 Spring 中注入一个 Java 集合？Spring 提供了以下四种集合类的配置元素： : 该标签用来装配可重复的 list 值。 : 该标签用来装配没有重复的 set 值。 : 该标签可用来注入键和值可以为任何类型的键值对。 : 该标签支持注入键和值都是字符串类型的键值对。 下面看一下具体的例子： &lt;beans> &lt;bean id=\"javaCollection\" class=\"com.JavaCollection\"> &lt;property name=\"customList\"> &lt;list> &lt;value>INDIA&lt;/value> &lt;value>Pakistan&lt;/value> &lt;value>USA&lt;/value> &lt;value>UK&lt;/value> &lt;/list> &lt;/property> &lt;property name=\"customSet\"> &lt;set> &lt;value>INDIA&lt;/value> &lt;value>Pakistan&lt;/value> &lt;value>USA&lt;/value> &lt;value>UK&lt;/value> &lt;/set> &lt;/property> &lt;property name=\"customMap\"> &lt;map> &lt;entry key=\"1\" value=\"INDIA\"/> &lt;entry key=\"2\" value=\"Pakistan\"/> &lt;entry key=\"3\" value=\"USA\"/> &lt;entry key=\"4\" value=\"UK\"/> &lt;/map> &lt;/property> &lt;property name=\"customProperies\"> &lt;props> &lt;prop key=\"admin\">admin@111.com&lt;/prop> &lt;prop key=\"support\">support@111.com&lt;/prop> &lt;/props> &lt;/property> &lt;/bean> &lt;/beans> 15、如何向 Spring Bean 中注入 java.util.Properties？第一种方法是使用如下面代码所示的 标签： &lt;bean id=\"adminUser\" class=\"com.common.Customer\"> &lt;property name=\"emails\"> &lt;props> &lt;prop key=\"admin\">admin@aaa.com&lt;/prop> &lt;prop key=\"support\">support@aaa.com&lt;/prop> &lt;/props> &lt;/property> &lt;/bean> 也可用”util:”命名空间来从 properties 文件中创建出一个 propertiesbean，然后利用 setter 方法注入 bean 的引用。 16、请解释 Spring Bean 的自动装配？在 Spring 框架中，在配置文件中设定 bean 的依赖关系是一个很好的机制，Spring 容器还可以自动装配合作关系 bean 之间的关联关系。这意味着 Spring 可以通过向 Bean Factory 中注入的方式自动搞定bean 之间的依赖关系。自动装配可以设置在每个 bean 上，也可以设定在特定的 bean 上。下面的 XML 配置文件表明了如何根据名称将一个 bean 设置为自动装配： &lt;bean id=\"employeeDAO\" class=\"com.EmployeeDAOImpl\" autowire=\"byName\" /> 除了 bean 配置文件中提供的自动装配模式，还可以使用@Autowired 注解来自动装配指定的 bean。在使用@Autowired 注解之前需要在按照如下的配置方式在 Spring 配置文件进行配置才可以使用。 &lt;context:annotation-config /> 也可以通过在配置文件中配置 AutowiredAnnotationBeanPostProcessor 达到相同的效果。 &lt;bean class =\"org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor\"/> 配置好以后就可以使用@Autowired 来标注了。 @Autowired public EmployeeDAOImpl ( EmployeeManager manager ) &amp;#123; this.manager = manager; &amp;#125; 17、自动装配有哪些局限性？自动装配有如下局限性： 重写：你仍然需要使用 和&lt; property&gt;设置指明依赖，这意味着总要重写自动装配。 原生数据类型:你不能自动装配简单的属性，如原生类型、字符串和类。 模糊特性：自动装配总是没有自定义装配精确，因此，如果可能尽量使用自定义装配。 18、请解释各种自动装配模式的区别？在 Spring 框架中共有 5 种自动装配，让我们逐一分析。 no：这是 Spring 框架的默认设置，在该设置下自动装配是关闭的，开发者需要自行在 bean 定义中用标签明确的设置依赖关系。 byName：该选项可以根据 bean 名称设置依赖关系。当向一个 bean 中自动装配一个属性时，容器将根据 bean 的名称自动在在配置文件中查询一个匹配的 bean。如果找到的话，就装配这个属性，如果没找到的话就报错。 byType：该选项可以根据 bean 类型设置依赖关系。当向一个 bean 中自动装配一个属性时，容器将根据 bean 的类型自动在在配置文件中查询一个匹配的 bean。如果找到的话，就装配这个属性，如果没找到的话就报错。 constructor：造器的自动装配和 byType 模式类似，但是仅仅适用于与有构造器相同参数的 bean，如果在容器中没有找到与构造器参数类型一致的 bean，那么将会抛出异常。 autodetect：该模式自动探测使用构造器自动装配或者 byType 自动装配。首先，首先会尝试找合适的带参数的构造器，如果找到的话就是用构造器自动装配，如果在 bean 内部没有找到相应的构造器或者是无参构造器，容器就会自动选择 byTpe 的自动装配方式。 19、请举例解释@Required Annotation？在产品级别的应用中，IOC 容器可能声明了数十万了 bean，bean 与 bean 之间有着复杂的依赖关系。设值注解方法的短板之一就是验证所有的属性是否被注解是一项十分困难的操作。可以通过在中设置“dependency-check”来解决这个问题。 在应用程序的生命周期中，你可能不大愿意花时间在验证所有 bean 的属性是否按照上下文文件正确配置。或者你宁可验证某个 bean 的特定属性是否被正确的设置。即使是用“dependency-check”属性也不能很好的解决这个问题，在这种情况下，你需要使用@Required 注解。 需要用如下的方式使用来标明 bean 的设值方法。 public class EmployeeFactoryBean extends AbstractFactoryBean&lt;Object> &amp;#123; private String designation; public String getDesignation() &amp;#123; return designation; &amp;#125; @Required public void setDesignation(String designation) &amp;#123; this.designation = designation; &amp;#125; &amp;#125; RequiredAnnotationBeanPostProcessor 是 Spring 中的后置处理用来验证被@Required 注解的bean 属性是否被正确的设置了。在使用 RequiredAnnotationBeanPostProcesso 来验证 bean 属性之前，首先要在 IOC 容器中对其进行注册： &lt;bean class=\"org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor\" /> 但是如果没有属性被用 @Required 注解过的话，后置处理器会抛出一个 BeanInitializationException异常。 20、请举例说明@Qualifier 注解？@Qualifier注解意味着可以在被标注bean的字段上可以自动装配。Qualifier注解可以用来取消Spring不能取消的 bean 应用。 21、构造方法注入和设值注入有什么区别？请注意以下明显的区别： 在设值注入方法支持大部分的依赖注入，如果我们仅需要注入 int、string 和 long 型的变量，我们不要用设值的方法注入。对于基本类型，如果我们没有注入的话，可以为基本类型设置默认值。在构造方法注入不支持大部分的依赖注入，因为在调用构造方法中必须传入正确的构造参数，否则的话为报错。 设值注入不会重写构造方法的值。如果我们对同一个变量同时使用了构造方法注入又使用了设置方法注入的话，那么构造方法将不能覆盖由设值方法注入的值。很明显，因为构造方法尽在对象被创建时调用。 在使用设值注入时有可能还不能保证某种依赖是否已经被注入，也就是说这时对象的依赖关系有可能是不完整的。而在另一种情况下，构造器注入则不允许生成依赖关系不完整的对象。 在 设 值 注 入 时 如 果 对 象 A 和 对 象 B 互 相 依 赖 ， 在 创 建 对 象 A 时 Spring 会 抛 出sObjectCurrentlyInCreationException 异常，因为在 B 对象被创建之前 A 对象是不能被创建的，反之亦然。所以 Spring 用设值注入的方法解决了循环依赖的问题，因对象的设值方法是在对象被创建之前被调用的。 22、Spring 框架中有哪些不同类型的事件？Spring 的 ApplicationContext 提供了支持事件和代码中监听器的功能。我们可以创建 bean 用来监听在 ApplicationContext 中发布的事件。ApplicationEvent 类和在ApplicationContext 接口中处理的事件，如果一个 bean 实现了 ApplicationListener 接口，当一个ApplicationEvent 被发布以后，bean 会自动被通知。 public class AllApplicationEventListener implements ApplicationListener&lt;ApplicationEvent> &amp;#123; @Override public void onApplicationEvent(ApplicationEvent applicationEvent) &amp;#123; //process event &amp;#125; &amp;#125; Spring 提供了以下 5 中标准的事件： 上下文更新事件（ContextRefreshedEvent）：该事件会在 ApplicationContext 被初始化或者更新时发布。也可以在调用 ConfigurableApplicationContext 接口中的 refresh()方法时被触发。 上下文开始事件（ContextStartedEvent）：当容器调用 ConfigurableApplicationContext 的 Start()方法开始/重新开始容器时触发该事件。 上下文停止事件（ContextStoppedEvent）：当容器调用 ConfigurableApplicationContext 的 Stop()方法停止容器时触发该事件。 上下文关闭事件（ContextClosedEvent）：当 ApplicationContext 被关闭时触发该事件。容器被关闭时，其管理的所有单例 Bean 都被销毁。 请求处理事件（RequestHandledEvent）：在 Web 应用中，当一个 http 请求（request）结束触发该事件。 除了上面介绍的事件以外，还可以通过扩展 ApplicationEvent 类来开发自定义的事件。 public class CustomApplicationEvent extends ApplicationEvent &amp;#123; public CustomApplicationEvent ( Object source, final String msg )&amp;#123; super(source); System.out.println(\"Created a Custom event\"); &amp;#125; &amp;#125; 为了监听这个事件，还需要创建一个监听器： public class CustomEventListener implements ApplicationListener &lt; CustomApplicationEvent >&amp;#123; @Override public void onApplicationEvent(CustomApplicationEvent applicationEvent) &amp;#123; &amp;#125; &amp;#125; 之后通过 applicationContext 接口的 publishEvent()方法来发布自定义事件。CustomApplicationEvent customEvent = new CustomApplicationEvent(applicationContext, “Test message”);applicationContext.publishEvent(customEvent); 23、FileSystemResource 和 ClassPathResource 有何区别？在 FileSystemResource 中需要给出 spring-config.xml 文件在你项目中的相对路径或者绝对路径。在ClassPathResource 中 spring 会在 ClassPath 中自动搜寻配置文件，所以要把 ClassPathResource 文件放在 ClassPath 下。 如果将 spring-config.xml 保存在了 src 文件夹下的话，只需给出配置文件的名称即可，因为 src 文件夹是默认。 简而言之，ClassPathResource 在环境变量中读取配置文件，FileSystemResource 在配置文件中读取配置文件。 24、Spring 框架中都用到了哪些设计模式？Spring 框架中使用到了大量的设计模式，下面列举了比较有代表性的： 代理模式—在 AOP 和 remoting 中被用的比较多。 单例模式：在 spring 配置文件中定义的 bean 默认为单例模式。 模板模式：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。 委派模式：Srping 提供了 DispatcherServlet 来对请求进行分发。 工厂模式：BeanFactory 用来创建对象的实例，贯穿于 BeanFactory / ApplicationContext 接口的核心理念。 代理模式：AOP 思想的底层实现技术，Spring 中采用 JDK Proxy 和 CgLib 类库。 25、在 Spring 框架中如何更有效的使用 JDBC？使用 Spring JDBC 框架，资源管理以及错误处理的代价都会减轻。开发人员只需通过 statements 和queries 语句从数据库中存取数据。Spring 框架中通过使用模板类能更有效的使用 JDBC，也就是所谓的 JdbcTemplate。 26、请解释下 Spring 框架中的 IOC 容器？Spring 中的 org.springframework.beans 包和 org.springframework.context 包构成了 Spring 框架 IOC 容器的基础。 BeanFactory 接 口 提 供 了 一 个 先 进 的 配 置 机 制 ， 使 得 任 何 类 型 的 对 象 的 配 置 成 为 可 能 。ApplicationContex 接口对 BeanFactory（是一个子接口）进行了扩展，在 BeanFactory 的基础上添加了其他功能，比如与 Spring 的 AOP 更容易集成，也提供了处理 message resource 的机制（用于国际化）、事件传播以及应用层的特别配置，比如针对 Web 应用的 WebApplicationContext。 27、在 Spring 中可以注入 null 或空字符串吗？完全可以","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring MVC 源码分析(8)","slug":"spring/Spring MVC 源码分析(8)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-mvc-yuan-ma-fen-xi-8/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-mvc-yuan-ma-fen-xi-8/","excerpt":"","text":"8. Spring MVC 源码分析Spring MVC初体验 初探Spring MVC请求处理流程SpringMVC相对于前面的章节算是比较简单的，我们首先引用《SpringinAction》上的一张图来了解Spring MVC的核心组件和大致处理流程： 从上图中看到 ①、 DispatcherServlet是SpringMVC中的前端控制器(FrontController),负责接收Request并将Request转发给对应的处理组件。 ② 、 HanlerMapping 是 SpringMVC 中 完 成 url 到 Controller 映 射 的 组 件 。DispatcherServlet 接收 Request,然后从 HandlerMapping 查找处理 Request 的Controller。 ③、Controller 处理 Request,并返回 ModelAndView 对象,Controller 是 SpringMVC中负责处理 Request 的组件(类似于 Struts2 中的 Action),ModelAndView 是封装结果视图的组件。 ④、⑤、⑥视图解析器解析ModelAndView对象并返回对应的视图给客户端。在前面的章节中我们已经大致了解到，容器初始化时会建立所有url 和Controller 中的Method 的对应关系，保存到 HandlerMapping 中，用户请求是根据 Request 请求的url快速定位到Controller 中的某个方法。在Spring中先将url和Controller的对应关系,保存到 Map&lt;url,Controller&gt;中。Web 容器启动时会通知 Spring 初始化容器(加载Bean的定义信息和初始化所有单例Bean),然后SpringMVC会遍历容器中的Bean，获取每一个Controller中的所有方法访问的url，然后将url和Controller保存到一个Map中；这样就可以根据 Request 快速定位到 Controller，因为最终处理 Request 的是Controller 中的方法，Map 中只保留了 url 和 Controller 中的对应关系，所以要根据Request 的 url 进一步确认 Controller 中的 Method，这一步工作的原理就是拼接Controller 的 url(Controller 上@RequestMapping 的值)和方法的 url(Method 上@RequestMapping的值)，与request的url进行匹配，找到匹配的那个方法；确定处理请求的Method后，接下来的任务就是参数绑定，把Request中参数绑定到方法的形式参数上，这一步是整个请求处理过程中最复杂的一个步骤。 Spring MVC九大组件HandlerMappingsHandlerMapping是用来查找Handler的，也就是处理器，具体的表现形式可以是类也可以是方法。比如，标注了@RequestMapping 的每个 method 都可以看成是一个Handler，由 Handler 来负责实际的请求处理。 HandlerMapping 在请求到达之后，它的作用便是找到请求相应的处理器Handler和Interceptors。 HandlerAdapters从名字上看，这是一个适配器。因为SpringMVC中Handler可以是任意形式的，只要能够处理请求便行, 但是把请求交给 Servlet 的时候，由于 Servlet 的方法结构都是如doService(HttpServletRequestreq,HttpServletResponseresp) 这样的形式，让固定的Servlet 处理方法调用 Handler 来进行处理，这一步工作便是HandlerAdapter 要做的事。 HandlerExceptionResolvers从这个组件的名字上看，这个就是用来处理Handler过程中产生的异常情况的组件。 具体来说，此组件的作用是根据异常设置ModelAndView, 之后再交给 render()方法进行渲 染 ， 而 render() 便 将 ModelAndView 渲 染 成 页 面 。 不 过 有 一 点 ，HandlerExceptionResolver 只是用于解析对请求做处理阶段产生的异常，而渲染阶段的异常则不归他管了，这也是Spring MVC 组件设计的一大原则分工明确互不干涉。 ViewResolvers视图解析器，相信大家对这个应该都很熟悉了。因为通常在SpringMVC的配置文件中，都会配上一个该接口的实现类来进行视图的解析。 这个组件的主要作用，便是将String 类型的视图名和Locale解析为View类型的视图。这个接口只有一个resolveViewName()方法。从方法的定义就可以看出，Controller层返回的String类型的视图名viewName，最终会在这里被解析成为View。View 是用来渲染页面的，也就是说，它会将程序返回的参数和数据填入模板中，最终生成 html 文件。ViewResolver在这个过程中，主要做两件大事，即，ViewResolver会找到渲染所用的模板（使用什么模板来渲染？）和所用的技术（其实也就是视图的类型，如JSP啊还是其他什么Blabla的）填入参数。默认情况下，SpringMVC会为我们自动配置一个InternalResourceViewResolver，这个是针对JSP类型视图的。 RequestToViewNameTranslator这个组件的作用，在于从 Request 中获取 viewName. 因为 ViewResolver 是根据ViewName 查找 View, 但有的 Handler 处理完成之后，没有设置 View 也没有设置ViewName， 便要通过这个组件来从Request中查找viewName。 LocaleResolver 在上面我们有看到ViewResolver 的resolveViewName()方法，需要两个参数。那么第二个参数Locale是从哪来的呢，这就是LocaleResolver 要做的事了。 LocaleResolver用于从 request 中解析出 Locale, 在中国大陆地区，Locale当然就会是zh-CN之类，用来表示一个区域。这个类也是i18n的基础。 ThemeResolver从名字便可看出，这个类是用来解析主题的。主题，就是样式，图片以及它们所形成的显示效果的集合。Spring MVC中一套主题对应一个properties文件，里面存放着跟当前主题相关的所有资源，如图片，css样式等。创建主题非常简单，只需准备好资源，然后新建一个 “主题名.properties” 并将资源设置进去，放在classpath下，便可以在页面 中使用了。 Spring MVC 中跟主题有关的类有 ThemeResolver, ThemeSource 和Theme。 ThemeResolver 负责从request中解析出主题名， ThemeSource则根据主题名找到具体的主题， 其抽象也就是 Theme, 通过Theme来获取主题和具体的资源。 MultipartResolver其实这是一个大家很熟悉的组件，MultipartResolver用于处理上传请求，通过将普通的Request包装成MultipartHttpServletRequest来实现。MultipartHttpServletRequest可以通过getFile() 直接获得文件，如果是多个文件上传，还可以通过调用getFileMap得到Map&lt;FileName,File&gt; 这样的结构。MultipartResolver的作用就是用来封装普通的request，使其拥有处理文件上传的功能。 FlashMapManager说到FlashMapManager，就得先提一下FlashMap。FlashMap用于重定向Redirect时的参数数据传递，比如，在处理用户订单提交时，为了避免重复提交，可以处理完post请求后redirect到一个get请求，这个get请求可以用来显示订单详情之类的信息。这样做虽然可以规避用户刷新重新提交表单的问题，但是在这个页面上要显示订单的信息，那这些数据从哪里去获取呢，因为redirect重定向是没有传递参数这一功能的，如果不想把参数写进url(其实也不推荐这么做，url有长度限制不说，把参数都直接暴露，感觉也不安全)， 那么就可以通过flashMap来传递。只需 要 在 redirect 之 前 ， 将 要 传 递 的 数 据 写 入 request （ 可 以 通 过ServletRequestAttributes.getRequest() 获 得 ） 的 属 性OUTPUT_FLASH_MAP_ATTRIBUTE 中，这样在 redirect 之后的 handler 中 Spring 就会自动将其设置到Model中，在显示订单信息的页面上，就可以直接从Model 中取得数据了。而FlashMapManager就是用来管理FlashMap的。 Spring MVC源码分析根据上面分析的Spring MVC工作机制，从三个部分来分析Spring MVC的源代码。 其一，ApplicationContext初始化时用Map保存所有url和Controller类的对应关系； 其二，根据请求url找到对应的Controller，并从Controller中找到处理请求的方法; 其三，Request参数绑定到方法的形参，执行方法处理请求，并返回结果视图。 初始化阶段我们首先找到DispatcherServlet这个类，必然是寻找init()方法。然后，我们发现其init方法其实在父类HttpServletBean中，其源码如下： @Override public final void init() throws ServletException &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Initializing servlet '\" + getServletName() + \"'\"); &amp;#125; // Set bean properties from init parameters. PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &amp;#123; try &amp;#123; //定位资源 BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); //加载配置信息 ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &amp;#125; catch (BeansException ex) &amp;#123; if (logger.isErrorEnabled()) &amp;#123; logger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex); &amp;#125; throw ex; &amp;#125; &amp;#125; // Let subclasses do whatever initialization they like. initServletBean(); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\"); &amp;#125; &amp;#125; 我们看到在这段代码中，又调用了一个重要的 initServletBean()方法。进入initServletBean()方法看到以下源码： @Override protected final void initServletBean() throws ServletException &amp;#123; getServletContext().log(\"Initializing Spring FrameworkServlet '\" + getServletName() + \"'\"); if (this.logger.isInfoEnabled()) &amp;#123; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization started\"); &amp;#125; long startTime = System.currentTimeMillis(); try &amp;#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &amp;#125; catch (ServletException ex) &amp;#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &amp;#125; catch (RuntimeException ex) &amp;#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &amp;#125; if (this.logger.isInfoEnabled()) &amp;#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization completed in \" + elapsedTime + \" ms\"); &amp;#125; &amp;#125; 这段代码中最主要的逻辑就是初始化IOC容器，最终会调用refresh()方法，前面的章节中对IOC容器的初始化细节我们已经详细掌握，在此我们不再赘述。我们看到上面的代 码中，IOC 容器初始化之后，最后有调用了 onRefresh()方法。这个方法最终是在DisptcherServlet 中实现，来看源码： @Override protected void onRefresh(ApplicationContext context) &amp;#123; initStrategies(context); &amp;#125; /** * Initialize the strategy objects that this servlet uses. * &lt;p>May be overridden in subclasses in order to initialize further strategy objects. */ //初始化策略 protected void initStrategies(ApplicationContext context) &amp;#123; //多文件上传的组件 initMultipartResolver(context); //初始化本地语言环境 initLocaleResolver(context); //初始化模板处理器 initThemeResolver(context); //handlerMapping initHandlerMappings(context); //初始化参数适配器 initHandlerAdapters(context); //初始化异常拦截器 initHandlerExceptionResolvers(context); //初始化视图预处理器 initRequestToViewNameTranslator(context); //初始化视图转换器 initViewResolvers(context); // initFlashMapManager(context); &amp;#125; 到这一步就完成了SpringMVC的九大组件的初始化。 接下来， 我们来看url和Controller的 关 系 是 如 何 建 立 的 呢 ？ HandlerMapping 的 子 类AbstractDetectingUrlHandlerMapping 实现了 initApplicationContext()方法，所以我们直接看子类中的初始化容器方法。 @Override public void initApplicationContext() throws ApplicationContextException &amp;#123; super.initApplicationContext(); detectHandlers(); &amp;#125; /** * Register all handlers found in the current ApplicationContext. * &lt;p>The actual URL determination for a handler is up to the concrete * &amp;#123;@link #determineUrlsForHandler(String)&amp;#125; implementation. A bean for * which no such URLs could be determined is simply not considered a handler. * @throws org.springframework.beans.BeansException if the handler couldn't be registered * @see #determineUrlsForHandler(String) */ /** * 建立当前ApplicationContext中的所有controller和url的对应关系 */ protected void detectHandlers() throws BeansException &amp;#123; ApplicationContext applicationContext = obtainApplicationContext(); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Looking for URL mappings in application context: \" + applicationContext); &amp;#125; // 获取ApplicationContext容器中所有bean的Name String[] beanNames = (this.detectHandlersInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class) : applicationContext.getBeanNamesForType(Object.class)); // Take any bean name that we can determine URLs for. // 遍历beanNames,并找到这些bean对应的url for (String beanName : beanNames) &amp;#123; // 找bean上的所有url(controller上的url+方法上的url),该方法由对应的子类实现 String[] urls = determineUrlsForHandler(beanName); if (!ObjectUtils.isEmpty(urls)) &amp;#123; // URL paths found: Let's consider it a handler. // 保存urls和beanName的对应关系,put it to Map&lt;urls,beanName>,该方法在父类AbstractUrlHandlerMapping中实现 registerHandler(urls, beanName); &amp;#125; else &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Rejected bean name '\" + beanName + \"': no URL paths identified\"); &amp;#125; &amp;#125; &amp;#125; &amp;#125; determineUrlsForHandler(String beanName)方法的作用是获取每个Controller 中的url，不同的子类有不同的实现，这是一个典型的模板设计模式。因为开发中我们用的最多的就是用注解来配置 Controller 中的 url，BeanNameUrlHandlerMapping 是AbstractDetectingUrlHandlerMapping的子类,处理注解形式的url映射.所以我们这里 以 BeanNameUrlHandlerMapping 来 进 行 分 析 。 我 们 看BeanNameUrlHandlerMapping是如何查beanName上所有映射的url。 /** * Checks name and aliases of the given bean for URLs, starting with \"/\". */ @Override protected String[] determineUrlsForHandler(String beanName) &amp;#123; List&lt;String> urls = new ArrayList&lt;>(); if (beanName.startsWith(\"/\")) &amp;#123; urls.add(beanName); &amp;#125; String[] aliases = obtainApplicationContext().getAliases(beanName); for (String alias : aliases) &amp;#123; if (alias.startsWith(\"/\")) &amp;#123; urls.add(alias); &amp;#125; &amp;#125; return StringUtils.toStringArray(urls); &amp;#125; 到这里HandlerMapping组件就已经建立所有url和Controller的对应关系。 运行调用阶段这一步步是由请求触发的，所以入口为DispatcherServlet 的核心方法为doService()，doService()中的核心逻辑由doDispatch()实现，源代码如下： protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &amp;#123; if (logger.isDebugEnabled()) &amp;#123; String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? \" resumed\" : \"\"; logger.debug(\"DispatcherServlet with name '\" + getServletName() + \"'\" + resumed + \" processing \" + request.getMethod() + \" request for [\" + getRequestUri(request) + \"]\"); &amp;#125; // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object> attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &amp;#123; attributesSnapshot = new HashMap&lt;>(); Enumeration&lt;?> attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &amp;#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) &amp;#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &amp;#125; &amp;#125; &amp;#125; // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); if (this.flashMapManager != null) &amp;#123; FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &amp;#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &amp;#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); &amp;#125; try &amp;#123; doDispatch(request, response); &amp;#125; finally &amp;#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &amp;#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &amp;#123; restoreAttributesAfterInclude(request, attributesSnapshot); &amp;#125; &amp;#125; &amp;#125; &amp;#125; /** 中央控制器,控制请求的转发 **/ protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &amp;#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &amp;#123; ModelAndView mv = null; Exception dispatchException = null; try &amp;#123; // 1.检查是否是文件上传的请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. // 2.取得处理当前请求的controller,这里也称为hanlder,处理器, // 第一个步骤的意义就在这里体现了.这里并不是直接返回controller, // 而是返回的HandlerExecutionChain请求处理器链对象, // 该对象封装了handler和interceptors. mappedHandler = getHandler(processedRequest); // 如果handler为空,则返回404 if (mappedHandler == null) &amp;#123; noHandlerFound(processedRequest, response); return; &amp;#125; // Determine handler adapter for the current request. //3. 获取处理request的处理器适配器handler adapter HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. // 处理 last-modified 请求头 String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &amp;#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &amp;#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &amp;#123; return; &amp;#125; &amp;#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &amp;#123; return; &amp;#125; // Actually invoke the handler. // 4.实际的处理器处理请求,返回结果视图对象 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &amp;#123; return; &amp;#125; // 结果视图对象的处理 applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &amp;#125; catch (Exception ex) &amp;#123; dispatchException = ex; &amp;#125; catch (Throwable err) &amp;#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &amp;#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &amp;#125; catch (Exception ex) &amp;#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &amp;#125; catch (Throwable err) &amp;#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &amp;#125; finally &amp;#123; if (asyncManager.isConcurrentHandlingStarted()) &amp;#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &amp;#123; // 请求成功响应之后的方法 mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &amp;#125; &amp;#125; else &amp;#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &amp;#123; cleanupMultipart(processedRequest); &amp;#125; &amp;#125; &amp;#125; &amp;#125; getHandler(processedRequest)方法实际上就是从 HandlerMapping 中找到 url 和Controller的对应关系。也就是Map&lt;url,Controller&gt;。我们知道，最终处理Request的是Controller中的方法，我们现在只是知道了Controller，我们如何确认Controller中处理Request的方法呢？继续往下看。 从Map&lt;urls,beanName&gt;中取得Controller 后，经过拦截器的预处理方法，再通过反射获取该方法上的注解和参数，解析方法和参数上的注解，然后反射调用方法获取 ModelAndView 结果视图。最后，调用的就是 RequestMappingHandlerAdapter 的handle()中的核心逻辑由handleInternal(request, response, handler)实现。 @Override protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &amp;#123; ModelAndView mav; checkRequest(request); // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &amp;#123; HttpSession session = request.getSession(false); if (session != null) &amp;#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &amp;#123; mav = invokeHandlerMethod(request, response, handlerMethod); &amp;#125; &amp;#125; else &amp;#123; // No HttpSession available -> no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); &amp;#125; &amp;#125; else &amp;#123; // No synchronization on session demanded at all... mav = invokeHandlerMethod(request, response, handlerMethod); &amp;#125; if (!response.containsHeader(HEADER_CACHE_CONTROL)) &amp;#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &amp;#123; applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); &amp;#125; else &amp;#123; prepareResponse(response); &amp;#125; &amp;#125; return mav; &amp;#125; 整个处理过程中最核心的逻辑其实就是拼接Controller的url和方法的url，与Request的url进行匹配，找到匹配的方法。 @Override protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &amp;#123; String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Looking up handler method for path \" + lookupPath); &amp;#125; this.mappingRegistry.acquireReadLock(); try &amp;#123; HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); if (logger.isDebugEnabled()) &amp;#123; if (handlerMethod != null) &amp;#123; logger.debug(\"Returning handler method [\" + handlerMethod + \"]\"); &amp;#125; else &amp;#123; logger.debug(\"Did not find handler method for [\" + lookupPath + \"]\"); &amp;#125; &amp;#125; return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &amp;#125; finally &amp;#123; this.mappingRegistry.releaseReadLock(); &amp;#125; &amp;#125; 通过上面的代码分析，已经可以找到处理Request的Controller 中的方法了，现在看如何解析该方法上的参数，并反射调用该方法。 /** 获取处理请求的方法,执行并返回结果视图 **/ @Nullable protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &amp;#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); try &amp;#123; WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod); ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory); ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); if (this.argumentResolvers != null) &amp;#123; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); &amp;#125; if (this.returnValueHandlers != null) &amp;#123; invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); &amp;#125; invocableMethod.setDataBinderFactory(binderFactory); invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); modelFactory.initModel(webRequest, mavContainer, invocableMethod); mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); if (asyncManager.hasConcurrentResult()) &amp;#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Found concurrent result value [\" + result + \"]\"); &amp;#125; invocableMethod = invocableMethod.wrapConcurrentResult(result); &amp;#125; invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) &amp;#123; return null; &amp;#125; return getModelAndView(mavContainer, modelFactory, webRequest); &amp;#125; finally &amp;#123; webRequest.requestCompleted(); &amp;#125; &amp;#125; invocableMethod.invokeAndHandle()最终要实现的目的就是：完成 Request 中的参数和方法参数上数据的绑定。Spring MVC中提供两种Request参数到方法中参数的绑定方式： 1、通过注解进行绑定，@RequestParam。 2、通过参数名称进行绑定。使用注解进行绑定，我们只要在方法参数前面声明@RequestParam(“name”)，就可以将request中参数name的值绑定到方法的该参数上。使用参数名称进行绑定的前提是必须要获取方法中参数的名称，Java反射只提供了获取方法的参数的类型，并没有提供获取参数名称的方法。SpringMVC解决这个问题的方法是用asm框架读取字节码文件，来获取方法的参数名称。asm框架是一个字节码操作框架，关于asm更多介绍可以参考其官网。个人建议，使用注解来完成参数绑定，这样就可以省去asm框架的读取字节码的操作。 @Nullable public Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &amp;#123; Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) &amp;#123; logger.trace(\"Invoking '\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"' with arguments \" + Arrays.toString(args)); &amp;#125; Object returnValue = doInvoke(args); if (logger.isTraceEnabled()) &amp;#123; logger.trace(\"Method [\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"] returned [\" + returnValue + \"]\"); &amp;#125; return returnValue; &amp;#125; /** * Get the method argument values for the current request. */ private Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &amp;#123; MethodParameter[] parameters = getMethodParameters(); Object[] args = new Object[parameters.length]; for (int i = 0; i &lt; parameters.length; i++) &amp;#123; MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); args[i] = resolveProvidedArgument(parameter, providedArgs); if (args[i] != null) &amp;#123; continue; &amp;#125; if (this.argumentResolvers.supportsParameter(parameter)) &amp;#123; try &amp;#123; args[i] = this.argumentResolvers.resolveArgument( parameter, mavContainer, request, this.dataBinderFactory); continue; &amp;#125; catch (Exception ex) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(getArgumentResolutionErrorMessage(\"Failed to resolve\", i), ex); &amp;#125; throw ex; &amp;#125; &amp;#125; if (args[i] == null) &amp;#123; throw new IllegalStateException(\"Could not resolve method parameter at index \" + parameter.getParameterIndex() + \" in \" + parameter.getExecutable().toGenericString() + \": \" + getArgumentResolutionErrorMessage(\"No suitable resolver for\", i)); &amp;#125; &amp;#125; return args; &amp;#125; 关于asm框架获取方法参数的部分,这里就不再进行分析了。感兴趣的小伙伴可以继续深入了解这个处理过程。到这里,方法的参数值列表也获取到了,就可以直接进行方法的调用了。整个请求过程中最复杂的一步就是在这里了。到这里整个请求处理过程的关键步骤都已了解。理解了Spring MVC 中的请求处理流程,整个代码还是比较清晰的。 最后来一张时序图： Spring MVC使用优化建议上面我们已经对SpringMVC的工作原理和源码进行了分析，在这个过程发现了几个优化点: 1、Controller如果能保持单例，尽量使用单例这样可以减少创建对象和回收对象的开销。也就是说，如果Controller的类变量和实例变量可以以方法形参声明的尽量以方法的形参声明，不要以类变量和实例变量声明，这样可以避免线程安全问题。 2、处理Request的方法中的形参务必加上@RequestParam注解这样可以避免Spring MVC使用asm框架读取class文件获取方法参数名的过程。即便Spring MVC对读取出的方法参数名进行了缓存，如果不要读取class文件当然是更好。 3、缓存URL阅读源码的过程中，我们发现Spring MVC并没有对处理 url的方法进行缓存，也就是说每次都要根据请求url去匹配Controller中的方法url，如果把url和Method的关系 缓存起来，会不会带来性能上的提升呢？有点恶心的是，负责解析url和Method对应关系的 ServletHandlerMethodResolver 是一个 private的内部类，不能直接继承该类增强代码，必须要该代码后重新编译。当然，如果缓存起来，必须要考虑缓存的线程安全问题。","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring DI 源码解析(6)","slug":"spring/Spring DI 源码解析(6)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-di-yuan-ma-jie-xi-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-di-yuan-ma-jie-xi-6/","excerpt":"","text":"6. Spring DI 源码解析Spring自动装配之依赖注入依赖注入发生的时间当SpringIOC 容器完成了Bean定义资源的定位、载入和解析注册以后，IOC 容器中已经管理类Bean定义的相关数据，但是此时 IOC容器还没有对所管理的 Bean进行依赖注入，依赖注入在以下两种情况发生： 1)、用户第一次调用getBean()方法时，IOC 容器触发依赖注入。2)、当用户在配置文件中将元素配置了lazy-init=false属性，即让容器在解析注册 Bean定义时进行预实例化，触发依赖注入。 BeanFactory 接口定义了 Spring IOC 容器的基本功能规范，是 Spring IOC 容器所应遵守的最底层和最基本的编程规范。BeanFactory 接口中定义了几个 getBean()方法，就是用户向IOC 容器索取管理的Bean的方法，我们通过分析其子类的具体实现，理解 SpringIOC 容器在用户索取Bean时如何完成依赖注入。 在BeanFactory中我们可以看到getBean(String…)方法，但它具体实现在AbstractBeanFactory中。 寻找获取Bean的入口AbstractBeanFactory 的getBean()相关方法的源码如下： //获取IOC容器中指定名称的Bean @Override public Object getBean(String name) throws BeansException &amp;#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, null, null, false); &amp;#125; //获取IOC容器中指定名称和类型的Bean @Override public &lt;T> T getBean(String name, @Nullable Class&lt;T> requiredType) throws BeansException &amp;#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, requiredType, null, false); &amp;#125; //获取IOC容器中指定名称和参数的Bean @Override public Object getBean(String name, Object... args) throws BeansException &amp;#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, null, args, false); &amp;#125; /** * Return an instance, which may be shared or independent, of the specified bean. * @param name the name of the bean to retrieve * @param requiredType the required type of the bean to retrieve * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @return an instance of the bean * @throws BeansException if the bean could not be created */ //获取IOC容器中指定名称、类型和参数的Bean public &lt;T> T getBean(String name, @Nullable Class&lt;T> requiredType, @Nullable Object... args) throws BeansException &amp;#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, requiredType, args, false); &amp;#125; /** * Return an instance, which may be shared or independent, of the specified bean. * @param name the name of the bean to retrieve * @param requiredType the required type of the bean to retrieve * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @param typeCheckOnly whether the instance is obtained for a type check, * not for actual use * @return an instance of the bean * @throws BeansException if the bean could not be created */ @SuppressWarnings(\"unchecked\") //真正实现向IOC容器获取Bean的功能，也是触发依赖注入功能的地方 protected &lt;T> T doGetBean(final String name, @Nullable final Class&lt;T> requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &amp;#123; //根据指定的名称获取被管理Bean的名称，剥离指定名称中对容器的相关依赖 //如果指定的是别名，将别名转换为规范的Bean名称 final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. //先从缓存中取是否已经有被创建过的单态类型的Bean //对于单例模式的Bean整个IOC容器中只创建一次，不需要重复创建 Object sharedInstance = getSingleton(beanName); //IOC容器创建单例模式Bean实例对象 if (sharedInstance != null &amp;&amp; args == null) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; //如果指定名称的Bean在容器中已有单例模式的Bean被创建 //直接返回已经创建的Bean if (isSingletonCurrentlyInCreation(beanName)) &amp;#123; logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &amp;#125; else &amp;#123; logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &amp;#125; &amp;#125; //获取给定Bean的实例对象，主要是完成FactoryBean的相关处理 //注意：BeanFactory是管理容器中Bean的工厂，而FactoryBean是 //创建创建对象的工厂Bean，两者之间有区别 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &amp;#125; else &amp;#123; // Fail if we're already creating this bean instance: // We're assumably within a circular reference. //缓存没有正在创建的单例模式Bean //缓存中已经有已经创建的原型模式Bean //但是由于循环引用的问题导致实例化对象失败 if (isPrototypeCurrentlyInCreation(beanName)) &amp;#123; throw new BeanCurrentlyInCreationException(beanName); &amp;#125; // Check if bean definition exists in this factory. //对IOC容器中是否存在指定名称的BeanDefinition进行检查，首先检查是否 //能在当前的BeanFactory中获取的所需要的Bean，如果不能则委托当前容器 //的父级容器去查找，如果还是找不到则沿着容器的继承体系向父级容器查找 BeanFactory parentBeanFactory = getParentBeanFactory(); //当前容器的父级容器存在，且当前容器中不存在指定名称的Bean if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &amp;#123; // Not found -> check parent. //解析指定Bean名称的原始名称 String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &amp;#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); &amp;#125; else if (args != null) &amp;#123; // Delegation to parent with explicit args. //委派父级容器根据指定名称和显式的参数查找 return (T) parentBeanFactory.getBean(nameToLookup, args); &amp;#125; else &amp;#123; // No args -> delegate to standard getBean method. //委派父级容器根据指定名称和类型查找 return parentBeanFactory.getBean(nameToLookup, requiredType); &amp;#125; &amp;#125; //创建的Bean是否需要进行类型验证，一般不需要 if (!typeCheckOnly) &amp;#123; //向容器标记指定的Bean已经被创建 markBeanAsCreated(beanName); &amp;#125; try &amp;#123; //根据指定Bean名称获取其父级的Bean定义 //主要解决Bean继承时子类合并父类公共属性问题 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. //获取当前Bean所有依赖Bean的名称 String[] dependsOn = mbd.getDependsOn(); //如果当前Bean有依赖Bean if (dependsOn != null) &amp;#123; for (String dep : dependsOn) &amp;#123; if (isDependent(beanName, dep)) &amp;#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &amp;#125; //递归调用getBean方法，获取当前Bean的依赖Bean registerDependentBean(dep, beanName); //把被依赖Bean注册给当前依赖的Bean getBean(dep); &amp;#125; &amp;#125; // Create bean instance. //创建单例模式Bean的实例对象 if (mbd.isSingleton()) &amp;#123; //这里使用了一个匿名内部类，创建Bean实例对象，并且注册给所依赖的对象 sharedInstance = getSingleton(beanName, () -> &amp;#123; try &amp;#123; //创建一个指定Bean实例对象，如果有父级继承，则合并子类和父类的定义 return createBean(beanName, mbd, args); &amp;#125; catch (BeansException ex) &amp;#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. //显式地从容器单例模式Bean缓存中清除实例对象 destroySingleton(beanName); throw ex; &amp;#125; &amp;#125;); //获取给定Bean的实例对象 bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &amp;#125; //IOC容器创建原型模式Bean实例对象 else if (mbd.isPrototype()) &amp;#123; // It's a prototype -> create a new instance. //原型模式(Prototype)是每次都会创建一个新的对象 Object prototypeInstance = null; try &amp;#123; //回调beforePrototypeCreation方法，默认的功能是注册当前创建的原型对象 beforePrototypeCreation(beanName); //创建指定Bean对象实例 prototypeInstance = createBean(beanName, mbd, args); &amp;#125; finally &amp;#123; //回调afterPrototypeCreation方法，默认的功能告诉IOC容器指定Bean的原型对象不再创建 afterPrototypeCreation(beanName); &amp;#125; //获取给定Bean的实例对象 bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &amp;#125; //要创建的Bean既不是单例模式，也不是原型模式，则根据Bean定义资源中 //配置的生命周期范围，选择实例化Bean的合适方法，这种在Web应用程序中 //比较常用，如：request、session、application等生命周期 else &amp;#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); //Bean定义资源中没有配置生命周期范围，则Bean定义不合法 if (scope == null) &amp;#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &amp;#125; try &amp;#123; //这里又使用了一个匿名内部类，获取一个指定生命周期范围的实例 Object scopedInstance = scope.get(beanName, () -> &amp;#123; beforePrototypeCreation(beanName); try &amp;#123; return createBean(beanName, mbd, args); &amp;#125; finally &amp;#123; afterPrototypeCreation(beanName); &amp;#125; &amp;#125;); //获取给定Bean的实例对象 bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &amp;#125; catch (IllegalStateException ex) &amp;#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &amp;#125; &amp;#125; &amp;#125; catch (BeansException ex) &amp;#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &amp;#125; &amp;#125; // Check if required type matches the type of the actual bean instance. //对创建的Bean实例对象进行类型检查 if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &amp;#123; try &amp;#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &amp;#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &amp;#125; return convertedBean; &amp;#125; catch (TypeMismatchException ex) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Failed to convert bean '\" + name + \"' to required type '\" + ClassUtils.getQualifiedName(requiredType) + \"'\", ex); &amp;#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &amp;#125; &amp;#125; return (T) bean; &amp;#125; 通过上面对向 IOC 容器获取 Bean方法的分析，我们可以看到在 Spring 中，如果 Bean 定义的单例模式(Singleton)，则容器在创建之前先从缓存中查找，以确保整个容器中只存在一个实例对象。如果Bean定义的是原型模式(Prototype)，则容器每次都会创建一个新的实例对象。除此之外，Bean定义还可以扩展为指定其生命周期范围。 上面的源码只是定义了根据 Bean 定义的模式，采取的不同创建 Bean实例对象的策略，具体的 Bean实例对象的创建过程由实现了 ObjectFactory 接口的匿名内部类的 createBean()方法完成， ObjectFactory 使 用 委 派 模 式 ， 具 体 的 Bean 实 例 创 建 过 程 交 由 其 实 现 类AbstractAutowireCapableBeanFactory完成，我们继续分析AbstractAutowireCapableBeanFactory的createBean()方法的源码，理解其创建Bean实例的具体实现过程。 开始实例化AbstractAutowireCapableBeanFactory 类实现了ObjectFactory 接口，创建容器指定的 Bean实例对象，同时还对创建的Bean实例对象进行初始化处理。其创建Bean实例对象的方法源码如下： //创建Bean实例对象 @Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Creating instance of bean '\" + beanName + \"'\"); &amp;#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. //判断需要创建的Bean是否可以实例化，即是否可以通过当前的类加载器加载 Class&lt;?> resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &amp;#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &amp;#125; // Prepare method overrides. //校验和准备Bean中的方法覆盖 try &amp;#123; mbdToUse.prepareMethodOverrides(); &amp;#125; catch (BeanDefinitionValidationException ex) &amp;#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex); &amp;#125; try &amp;#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. //如果Bean配置了初始化前和初始化后的处理器，则试图返回一个需要创建Bean的代理对象 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &amp;#123; return bean; &amp;#125; &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); &amp;#125; try &amp;#123; //创建Bean的入口 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Finished creating instance of bean '\" + beanName + \"'\"); &amp;#125; return beanInstance; &amp;#125; catch (BeanCreationException ex) &amp;#123; // A previously detected exception with proper bean creation context already... throw ex; &amp;#125; catch (ImplicitlyAppearedSingletonException ex) &amp;#123; // An IllegalStateException to be communicated up to DefaultSingletonBeanRegistry... throw ex; &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, \"Unexpected exception during bean creation\", ex); &amp;#125; &amp;#125; /** * Actually create the specified bean. Pre-creation processing has already happened * at this point, e.g. checking &amp;#123;@code postProcessBeforeInstantiation&amp;#125; callbacks. * &lt;p>Differentiates between default bean instantiation, use of a * factory method, and autowiring a constructor. * @param beanName the name of the bean * @param mbd the merged bean definition for the bean * @param args explicit arguments to use for constructor or factory method invocation * @return a new instance of the bean * @throws BeanCreationException if the bean could not be created * @see #instantiateBean * @see #instantiateUsingFactoryMethod * @see #autowireConstructor */ //真正创建Bean的方法 protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &amp;#123; // Instantiate the bean. //封装被创建的Bean对象 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &amp;#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &amp;#125; if (instanceWrapper == null) &amp;#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &amp;#125; final Object bean = instanceWrapper.getWrappedInstance(); //获取实例化对象的类型 Class&lt;?> beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &amp;#123; mbd.resolvedTargetType = beanType; &amp;#125; // Allow post-processors to modify the merged bean definition. //调用PostProcessor后置处理器 synchronized (mbd.postProcessingLock) &amp;#123; if (!mbd.postProcessed) &amp;#123; try &amp;#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Post-processing of merged bean definition failed\", ex); &amp;#125; mbd.postProcessed = true; &amp;#125; &amp;#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. //向容器中缓存单例模式的Bean对象，以防循环引用 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); &amp;#125; //这里是一个匿名内部类，为了防止循环引用，尽早持有对象的引用 addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean)); &amp;#125; // Initialize the bean instance. //Bean对象的初始化，依赖注入在此触发 //这个exposedObject在初始化完成之后返回作为依赖注入完成后的Bean Object exposedObject = bean; try &amp;#123; //将Bean实例对象封装，并且Bean定义中配置的属性值赋值给实例对象 populateBean(beanName, mbd, instanceWrapper); //初始化Bean对象 exposedObject = initializeBean(beanName, exposedObject, mbd); &amp;#125; catch (Throwable ex) &amp;#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &amp;#123; throw (BeanCreationException) ex; &amp;#125; else &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); &amp;#125; &amp;#125; if (earlySingletonExposure) &amp;#123; //获取指定名称的已注册的单例模式Bean对象 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &amp;#123; //根据名称获取的已注册的Bean和正在实例化的Bean是同一个 if (exposedObject == bean) &amp;#123; //当前实例化的Bean初始化完成 exposedObject = earlySingletonReference; &amp;#125; //当前Bean依赖其他Bean，并且当发生循环引用时不允许新创建实例对象 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &amp;#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String> actualDependentBeans = new LinkedHashSet&lt;>(dependentBeans.length); //获取当前Bean所依赖的其他Bean for (String dependentBean : dependentBeans) &amp;#123; //对依赖Bean进行类型检查 if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &amp;#123; actualDependentBeans.add(dependentBean); &amp;#125; &amp;#125; if (!actualDependentBeans.isEmpty()) &amp;#123; throw new BeanCurrentlyInCreationException(beanName, \"Bean with name '\" + beanName + \"' has been injected into other beans [\" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + \"] in its raw version as part of a circular reference, but has eventually been \" + \"wrapped. This means that said other beans do not use the final version of the \" + \"bean. This is often the result of over-eager type matching - consider using \" + \"'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.\"); &amp;#125; &amp;#125; &amp;#125; &amp;#125; // Register bean as disposable. //注册完成依赖注入的Bean try &amp;#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &amp;#125; catch (BeanDefinitionValidationException ex) &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); &amp;#125; return exposedObject; &amp;#125; 通过上面的源码注释，我们看到具体的依赖注入实现其实就在以下两个方法中： 1)、createBeanInstance()方法，生成Bean所包含的java对象实例。 2)、populateBean()方法，对Bean属性的依赖注入进行处理。 下面继续分析这两个方法的代码实现。 选择Bean实例化策略在createBeanInstance()方法中，根据指定的初始化策略，使用简单工厂、工厂方法或者容器的自动装配特性生成Java实例对象，创建对象的源码如下： //创建Bean的实例对象 protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &amp;#123; // Make sure bean class is actually resolved at this point. //检查确认Bean是可实例化的 Class&lt;?> beanClass = resolveBeanClass(mbd, beanName); //使用工厂方法对Bean进行实例化 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &amp;#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Bean class isn't public, and non-public access not allowed: \" + beanClass.getName()); &amp;#125; Supplier&lt;?> instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &amp;#123; return obtainFromSupplier(instanceSupplier, beanName); &amp;#125; if (mbd.getFactoryMethodName() != null) &amp;#123; //调用工厂方法实例化 return instantiateUsingFactoryMethod(beanName, mbd, args); &amp;#125; // Shortcut when re-creating the same bean... //使用容器的自动装配方法进行实例化 boolean resolved = false; boolean autowireNecessary = false; if (args == null) &amp;#123; synchronized (mbd.constructorArgumentLock) &amp;#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &amp;#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &amp;#125; &amp;#125; &amp;#125; if (resolved) &amp;#123; if (autowireNecessary) &amp;#123; //配置了自动装配属性，使用容器的自动装配实例化 //容器的自动装配是根据参数类型匹配Bean的构造方法 return autowireConstructor(beanName, mbd, null, null); &amp;#125; else &amp;#123; //使用默认的无参构造方法实例化 return instantiateBean(beanName, mbd); &amp;#125; &amp;#125; // Need to determine the constructor... //使用Bean的构造方法进行实例化 Constructor&lt;?>[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &amp;#123; //使用容器的自动装配特性，调用匹配的构造方法实例化 return autowireConstructor(beanName, mbd, ctors, args); &amp;#125; // No special handling: simply use no-arg constructor. //使用默认的无参构造方法实例化 return instantiateBean(beanName, mbd); &amp;#125; //使用默认的无参构造方法实例化Bean对象 protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &amp;#123; try &amp;#123; Object beanInstance; final BeanFactory parent = this; //获取系统的安全管理接口，JDK标准的安全管理API if (System.getSecurityManager() != null) &amp;#123; //这里是一个匿名内置类，根据实例化策略创建实例对象 beanInstance = AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> getInstantiationStrategy().instantiate(mbd, beanName, parent), getAccessControlContext()); &amp;#125; else &amp;#123; //将实例化的对象封装起来 beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); &amp;#125; BeanWrapper bw = new BeanWrapperImpl(beanInstance); initBeanWrapper(bw); return bw; &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Instantiation of bean failed\", ex); &amp;#125; &amp;#125; 经过对上面的代码分析，我们可以看出，对使用工厂方法和自动装配特性的Bean的实例化相当比较清楚，调用相应的工厂方法或者参数匹配的构造方法即可完成实例化对象的工作，但是对于我们最常使用的默认无参构造方法就需要使用相应的初始化策略(JDK的反射机制或者CGLib)来进行初始化了，在方法getInstantiationStrategy().instantiate()中就具体实现类使用初始策略实例化对象。 执行Bean实例化在使用默认的无参构造方法创建Bean的实例化对象时，方法getInstantiationStrategy().instantiate()调用了SimpleInstantiationStrategy类中的实例化Bean的方法，其源码如下： //使用初始化策略实例化Bean对象 @Override public Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) &amp;#123; // Don't override the class with CGLIB if no overrides. //如果Bean定义中没有方法覆盖，则就不需要CGLIB父类类的方法 if (!bd.hasMethodOverrides()) &amp;#123; Constructor&lt;?> constructorToUse; synchronized (bd.constructorArgumentLock) &amp;#123; //获取对象的构造方法或工厂方法 constructorToUse = (Constructor&lt;?>) bd.resolvedConstructorOrFactoryMethod; //如果没有构造方法且没有工厂方法 if (constructorToUse == null) &amp;#123; //使用JDK的反射机制，判断要实例化的Bean是否是接口 final Class&lt;?> clazz = bd.getBeanClass(); if (clazz.isInterface()) &amp;#123; throw new BeanInstantiationException(clazz, \"Specified class is an interface\"); &amp;#125; try &amp;#123; if (System.getSecurityManager() != null) &amp;#123; //这里是一个匿名内置类，使用反射机制获取Bean的构造方法 constructorToUse = AccessController.doPrivileged( (PrivilegedExceptionAction&lt;Constructor&lt;?>>) () -> clazz.getDeclaredConstructor()); &amp;#125; else &amp;#123; constructorToUse = clazz.getDeclaredConstructor(); &amp;#125; bd.resolvedConstructorOrFactoryMethod = constructorToUse; &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanInstantiationException(clazz, \"No default constructor found\", ex); &amp;#125; &amp;#125; &amp;#125; //使用BeanUtils实例化，通过反射机制调用”构造方法.newInstance(arg)”来进行实例化 return BeanUtils.instantiateClass(constructorToUse); &amp;#125; else &amp;#123; // Must generate CGLIB subclass. //使用CGLIB来实例化对象 return instantiateWithMethodInjection(bd, beanName, owner); &amp;#125; &amp;#125; 通过上面的代码分析，我们看到了如果Bean有方法被覆盖了，则使用JDK的反射机制进行实例化，否则，使用CGLib进行实例化。instantiateWithMethodInjection() 方 法 调 用 SimpleInstantiationStrategy 的 子 类CGLibSubclassingInstantiationStrategy使用CGLib来进行初始化，其源码如下： //使用CGLIB进行Bean对象实例化 public Object instantiate(@Nullable Constructor&lt;?> ctor, @Nullable Object... args) &amp;#123; //创建代理子类 Class&lt;?> subclass = createEnhancedSubclass(this.beanDefinition); Object instance; if (ctor == null) &amp;#123; instance = BeanUtils.instantiateClass(subclass); &amp;#125; else &amp;#123; try &amp;#123; Constructor&lt;?> enhancedSubclassConstructor = subclass.getConstructor(ctor.getParameterTypes()); instance = enhancedSubclassConstructor.newInstance(args); &amp;#125; catch (Exception ex) &amp;#123; throw new BeanInstantiationException(this.beanDefinition.getBeanClass(), \"Failed to invoke constructor for CGLIB enhanced subclass [\" + subclass.getName() + \"]\", ex); &amp;#125; &amp;#125; // SPR-10785: set callbacks directly on the instance instead of in the // enhanced class (via the Enhancer) in order to avoid memory leaks. Factory factory = (Factory) instance; factory.setCallbacks(new Callback[] &amp;#123;NoOp.INSTANCE, new LookupOverrideMethodInterceptor(this.beanDefinition, this.owner), new ReplaceOverrideMethodInterceptor(this.beanDefinition, this.owner)&amp;#125;); return instance; &amp;#125; /** * Create an enhanced subclass of the bean class for the provided bean * definition, using CGLIB. */ private Class&lt;?> createEnhancedSubclass(RootBeanDefinition beanDefinition) &amp;#123; //CGLIB中的类 Enhancer enhancer = new Enhancer(); //将Bean本身作为其基类 enhancer.setSuperclass(beanDefinition.getBeanClass()); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); if (this.owner instanceof ConfigurableBeanFactory) &amp;#123; ClassLoader cl = ((ConfigurableBeanFactory) this.owner).getBeanClassLoader(); enhancer.setStrategy(new ClassLoaderAwareGeneratorStrategy(cl)); &amp;#125; enhancer.setCallbackFilter(new MethodOverrideCallbackFilter(beanDefinition)); enhancer.setCallbackTypes(CALLBACK_TYPES); //使用CGLIB的createClass方法生成实例对象 return enhancer.createClass(); &amp;#125; &amp;#125; CGLib是一个常用的字节码生成器的类库，它提供了一系列API 实现Java字节码的生成和转换功能。我们在学习JDK的动态代理时都知道，JDK的动态代理只能针对接口，如果一个类没有实现任何接口，要对其进行动态代理只能使用CGLib。 准备依赖注入在前面的分析中我们已经了解到Bean的依赖注入主要分为两个步骤，首先调用createBeanInstance()方法生成 Bean所包含的 Java对象实例。然后，调用 populateBean()方法，对 Bean属性的依赖注入进行处理。 上面我们已经分析了容器初始化生成Bean所包含的Java实例对象的过程，现在我们继续分析生成对象后，Spring IOC 容器是如何将 Bean 的属性依赖关系注入 Bean 实例对象中并设置好的，回到AbstractAutowireCapableBeanFactory 的populateBean()方法，对属性依赖注入的代码如下： //将Bean属性设置到生成的实例对象上 protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &amp;#123; if (bw == null) &amp;#123; if (mbd.hasPropertyValues()) &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\"); &amp;#125; else &amp;#123; // Skip property population phase for null instance. return; &amp;#125; &amp;#125; // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &amp;#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &amp;#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &amp;#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &amp;#123; continueWithPropertyPopulation = false; break; &amp;#125; &amp;#125; &amp;#125; &amp;#125; if (!continueWithPropertyPopulation) &amp;#123; return; &amp;#125; //获取容器在解析Bean定义资源时为BeanDefiniton中设置的属性值 PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); //对依赖注入处理，首先处理autowiring自动装配的依赖注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &amp;#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. //根据Bean名称进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &amp;#123; autowireByName(beanName, mbd, bw, newPvs); &amp;#125; // Add property values based on autowire by type if applicable. //根据Bean类型进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &amp;#123; autowireByType(beanName, mbd, bw, newPvs); &amp;#125; pvs = newPvs; &amp;#125; //对非autowiring的属性进行依赖注入处理 boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &amp;#123; if (pvs == null) &amp;#123; pvs = mbd.getPropertyValues(); &amp;#125; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &amp;#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &amp;#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &amp;#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &amp;#123; return; &amp;#125; &amp;#125; &amp;#125; &amp;#125; if (needsDepCheck) &amp;#123; checkDependencies(beanName, mbd, filteredPds, pvs); &amp;#125; &amp;#125; if (pvs != null) &amp;#123; //对属性进行注入 applyPropertyValues(beanName, mbd, bw, pvs); &amp;#125; &amp;#125; //解析并注入依赖属性的过程 protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) &amp;#123; if (pvs.isEmpty()) &amp;#123; return; &amp;#125; //封装属性值 MutablePropertyValues mpvs = null; List&lt;PropertyValue> original; if (System.getSecurityManager() != null) &amp;#123; if (bw instanceof BeanWrapperImpl) &amp;#123; //设置安全上下文，JDK安全机制 ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext()); &amp;#125; &amp;#125; if (pvs instanceof MutablePropertyValues) &amp;#123; mpvs = (MutablePropertyValues) pvs; //属性值已经转换 if (mpvs.isConverted()) &amp;#123; // Shortcut: use the pre-converted values as-is. try &amp;#123; //为实例化对象设置属性值 bw.setPropertyValues(mpvs); return; &amp;#125; catch (BeansException ex) &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Error setting property values\", ex); &amp;#125; &amp;#125; //获取属性值对象的原始类型值 original = mpvs.getPropertyValueList(); &amp;#125; else &amp;#123; original = Arrays.asList(pvs.getPropertyValues()); &amp;#125; //获取用户自定义的类型转换 TypeConverter converter = getCustomTypeConverter(); if (converter == null) &amp;#123; converter = bw; &amp;#125; //创建一个Bean定义属性值解析器，将Bean定义中的属性值解析为Bean实例对象的实际值 BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // Create a deep copy, resolving any references for values. //为属性的解析值创建一个拷贝，将拷贝的数据注入到实例对象中 List&lt;PropertyValue> deepCopy = new ArrayList&lt;>(original.size()); boolean resolveNecessary = false; for (PropertyValue pv : original) &amp;#123; //属性值不需要转换 if (pv.isConverted()) &amp;#123; deepCopy.add(pv); &amp;#125; //属性值需要转换 else &amp;#123; String propertyName = pv.getName(); //原始的属性值，即转换之前的属性值 Object originalValue = pv.getValue(); //转换属性值，例如将引用转换为IOC容器中实例化对象引用 Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); //转换之后的属性值 Object convertedValue = resolvedValue; //属性值是否可以转换 boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) &amp;#123; //使用用户自定义的类型转换器转换属性值 convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); &amp;#125; // Possibly store converted value in merged bean definition, // in order to avoid re-conversion for every created bean instance. //存储转换后的属性值，避免每次属性注入时的转换工作 if (resolvedValue == originalValue) &amp;#123; if (convertible) &amp;#123; //设置属性转换之后的值 pv.setConvertedValue(convertedValue); &amp;#125; deepCopy.add(pv); &amp;#125; //属性是可转换的，且属性原始值是字符串类型，且属性的原始类型值不是 //动态生成的字符串，且属性的原始值不是集合或者数组类型 else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &amp;#123; pv.setConvertedValue(convertedValue); //重新封装属性的值 deepCopy.add(pv); &amp;#125; else &amp;#123; resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); &amp;#125; &amp;#125; &amp;#125; if (mpvs != null &amp;&amp; !resolveNecessary) &amp;#123; //标记属性值已经转换过 mpvs.setConverted(); &amp;#125; // Set our (possibly massaged) deep copy. //进行属性依赖注入 try &amp;#123; bw.setPropertyValues(new MutablePropertyValues(deepCopy)); &amp;#125; catch (BeansException ex) &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Error setting property values\", ex); &amp;#125; &amp;#125; } 分析上述代码，我们可以看出，对属性的注入过程分以下两种情况： 1)、属性值类型不需要强制转换时，不需要解析属性值，直接准备进行依赖注入。 2)、属性值需要进行类型强制转换时，如对其他对象的引用等，首先需要解析属性值，然后对解析后的属性值进行依赖注入。 对属性值的解析是在BeanDefinitionValueResolver类中的resolveValueIfNecessary()方法中进行的， 对属性值的依赖注入是通过bw.setPropertyValues()方法实现的，在分析属性值的依赖注入之前，我们 先分析一下对属性值的解析过程。 解析属性注入规则当容器在对属性进行依赖注入时，如果发现属性值需要进行类型转换，如属性值是容器中另一个 Bean实例对象的引用，则容器首先需要根据属性值解析出所引用的对象，然后才能将该引用对象注入到目标实例对象的属性上去，对属性进行解析的由resolveValueIfNecessary()方法实现，其源码如下： //解析属性值，对注入类型进行转换 @Nullable public Object resolveValueIfNecessary(Object argName, @Nullable Object value) &amp;#123; // We must check each value to see whether it requires a runtime reference // to another bean to be resolved. //对引用类型的属性进行解析 if (value instanceof RuntimeBeanReference) &amp;#123; RuntimeBeanReference ref = (RuntimeBeanReference) value; //调用引用类型属性的解析方法 return resolveReference(argName, ref); &amp;#125; //对属性值是引用容器中另一个Bean名称的解析 else if (value instanceof RuntimeBeanNameReference) &amp;#123; String refName = ((RuntimeBeanNameReference) value).getBeanName(); refName = String.valueOf(doEvaluate(refName)); //从容器中获取指定名称的Bean if (!this.beanFactory.containsBean(refName)) &amp;#123; throw new BeanDefinitionStoreException( \"Invalid bean name '\" + refName + \"' in bean reference for \" + argName); &amp;#125; return refName; &amp;#125; //对Bean类型属性的解析，主要是Bean中的内部类 else if (value instanceof BeanDefinitionHolder) &amp;#123; // Resolve BeanDefinitionHolder: contains BeanDefinition with name and aliases. BeanDefinitionHolder bdHolder = (BeanDefinitionHolder) value; return resolveInnerBean(argName, bdHolder.getBeanName(), bdHolder.getBeanDefinition()); &amp;#125; else if (value instanceof BeanDefinition) &amp;#123; // Resolve plain BeanDefinition, without contained name: use dummy name. BeanDefinition bd = (BeanDefinition) value; String innerBeanName = \"(inner bean)\" + BeanFactoryUtils.GENERATED_BEAN_NAME_SEPARATOR + ObjectUtils.getIdentityHexString(bd); return resolveInnerBean(argName, innerBeanName, bd); &amp;#125; //对集合数组类型的属性解析 else if (value instanceof ManagedArray) &amp;#123; // May need to resolve contained runtime references. ManagedArray array = (ManagedArray) value; //获取数组的类型 Class&lt;?> elementType = array.resolvedElementType; if (elementType == null) &amp;#123; //获取数组元素的类型 String elementTypeName = array.getElementTypeName(); if (StringUtils.hasText(elementTypeName)) &amp;#123; try &amp;#123; //使用反射机制创建指定类型的对象 elementType = ClassUtils.forName(elementTypeName, this.beanFactory.getBeanClassLoader()); array.resolvedElementType = elementType; &amp;#125; catch (Throwable ex) &amp;#123; // Improve the message by showing the context. throw new BeanCreationException( this.beanDefinition.getResourceDescription(), this.beanName, \"Error resolving array type for \" + argName, ex); &amp;#125; &amp;#125; //没有获取到数组的类型，也没有获取到数组元素的类型 //则直接设置数组的类型为Object else &amp;#123; elementType = Object.class; &amp;#125; &amp;#125; //创建指定类型的数组 return resolveManagedArray(argName, (List&lt;?>) value, elementType); &amp;#125; //解析list类型的属性值 else if (value instanceof ManagedList) &amp;#123; // May need to resolve contained runtime references. return resolveManagedList(argName, (List&lt;?>) value); &amp;#125; //解析set类型的属性值 else if (value instanceof ManagedSet) &amp;#123; // May need to resolve contained runtime references. return resolveManagedSet(argName, (Set&lt;?>) value); &amp;#125; //解析map类型的属性值 else if (value instanceof ManagedMap) &amp;#123; // May need to resolve contained runtime references. return resolveManagedMap(argName, (Map&lt;?, ?>) value); &amp;#125; //解析props类型的属性值，props其实就是key和value均为字符串的map else if (value instanceof ManagedProperties) &amp;#123; Properties original = (Properties) value; //创建一个拷贝，用于作为解析后的返回值 Properties copy = new Properties(); original.forEach((propKey, propValue) -> &amp;#123; if (propKey instanceof TypedStringValue) &amp;#123; propKey = evaluate((TypedStringValue) propKey); &amp;#125; if (propValue instanceof TypedStringValue) &amp;#123; propValue = evaluate((TypedStringValue) propValue); &amp;#125; if (propKey == null || propValue == null) &amp;#123; throw new BeanCreationException( this.beanDefinition.getResourceDescription(), this.beanName, \"Error converting Properties key/value pair for \" + argName + \": resolved to null\"); &amp;#125; copy.put(propKey, propValue); &amp;#125;); return copy; &amp;#125; //解析字符串类型的属性值 else if (value instanceof TypedStringValue) &amp;#123; // Convert value to target type here. TypedStringValue typedStringValue = (TypedStringValue) value; Object valueObject = evaluate(typedStringValue); try &amp;#123; //获取属性的目标类型 Class&lt;?> resolvedTargetType = resolveTargetType(typedStringValue); if (resolvedTargetType != null) &amp;#123; //对目标类型的属性进行解析，递归调用 return this.typeConverter.convertIfNecessary(valueObject, resolvedTargetType); &amp;#125; //没有获取到属性的目标对象，则按Object类型返回 else &amp;#123; return valueObject; &amp;#125; &amp;#125; catch (Throwable ex) &amp;#123; // Improve the message by showing the context. throw new BeanCreationException( this.beanDefinition.getResourceDescription(), this.beanName, \"Error converting typed String value for \" + argName, ex); &amp;#125; &amp;#125; else if (value instanceof NullBean) &amp;#123; return null; &amp;#125; else &amp;#123; return evaluate(value); &amp;#125; &amp;#125; //解析引用类型的属性值 @Nullable private Object resolveReference(Object argName, RuntimeBeanReference ref) &amp;#123; try &amp;#123; Object bean; //获取引用的Bean名称 String refName = ref.getBeanName(); refName = String.valueOf(doEvaluate(refName)); //如果引用的对象在父类容器中，则从父类容器中获取指定的引用对象 if (ref.isToParent()) &amp;#123; if (this.beanFactory.getParentBeanFactory() == null) &amp;#123; throw new BeanCreationException( this.beanDefinition.getResourceDescription(), this.beanName, \"Can't resolve reference to bean '\" + refName + \"' in parent factory: no parent factory available\"); &amp;#125; bean = this.beanFactory.getParentBeanFactory().getBean(refName); &amp;#125; //从当前的容器中获取指定的引用Bean对象，如果指定的Bean没有被实例化 //则会递归触发引用Bean的初始化和依赖注入 else &amp;#123; bean = this.beanFactory.getBean(refName); //将当前实例化对象的依赖引用对象 this.beanFactory.registerDependentBean(refName, this.beanName); &amp;#125; if (bean instanceof NullBean) &amp;#123; bean = null; &amp;#125; return bean; &amp;#125; catch (BeansException ex) &amp;#123; throw new BeanCreationException( this.beanDefinition.getResourceDescription(), this.beanName, \"Cannot resolve reference to bean '\" + ref.getBeanName() + \"' while setting \" + argName, ex); &amp;#125; &amp;#125; /** * For each element in the managed array, resolve reference if necessary. */ //解析array类型的属性 private Object resolveManagedArray(Object argName, List&lt;?> ml, Class&lt;?> elementType) &amp;#123; //创建一个指定类型的数组，用于存放和返回解析后的数组 Object resolved = Array.newInstance(elementType, ml.size()); for (int i = 0; i &lt; ml.size(); i++) &amp;#123; //递归解析array的每一个元素，并将解析后的值设置到resolved数组中，索引为i Array.set(resolved, i, resolveValueIfNecessary(new KeyedArgName(argName, i), ml.get(i))); &amp;#125; return resolved; &amp;#125; /** * For each element in the managed list, resolve reference if necessary. */ //解析list类型的属性 private List&lt;?> resolveManagedList(Object argName, List&lt;?> ml) &amp;#123; List&lt;Object> resolved = new ArrayList&lt;>(ml.size()); for (int i = 0; i &lt; ml.size(); i++) &amp;#123; //递归解析list的每一个元素 resolved.add( resolveValueIfNecessary(new KeyedArgName(argName, i), ml.get(i))); &amp;#125; return resolved; &amp;#125; /** * For each element in the managed set, resolve reference if necessary. */ //解析set类型的属性 private Set&lt;?> resolveManagedSet(Object argName, Set&lt;?> ms) &amp;#123; Set&lt;Object> resolved = new LinkedHashSet&lt;>(ms.size()); int i = 0; //递归解析set的每一个元素 for (Object m : ms) &amp;#123; resolved.add(resolveValueIfNecessary(new KeyedArgName(argName, i), m)); i++; &amp;#125; return resolved; &amp;#125; /** * For each element in the managed map, resolve reference if necessary. */ //解析map类型的属性 private Map&lt;?, ?> resolveManagedMap(Object argName, Map&lt;?, ?> mm) &amp;#123; Map&lt;Object, Object> resolved = new LinkedHashMap&lt;>(mm.size()); //递归解析map中每一个元素的key和value for (Map.Entry&lt;?, ?> entry : mm.entrySet()) &amp;#123; Object resolvedKey = resolveValueIfNecessary(argName, entry.getKey()); Object resolvedValue = resolveValueIfNecessary( new KeyedArgName(argName, entry.getKey()), entry.getValue()); resolved.put(resolvedKey, resolvedValue); &amp;#125; return resolved; &amp;#125; 通过上面的代码分析，我们明白了Spring是如何将引用类型，内部类以及集合类型等属性进行解析的，属性值解析完成后就可以进行依赖注入了，依赖注入的过程就是Bean对象实例设置到它所依赖的Bean对象属性上去。而真正的依赖注入是通过bw.setPropertyValues()方法实现的，该方法也使用了委托模式，在 BeanWrapper 接口中至少定义了方法声明，依赖注入的具体实现交由其实现类BeanWrapperImpl来完成，下面我们就分析依BeanWrapperImpl中赖注入相关的源码。 注入赋值BeanWrapperImpl类主要是对容器中完成初始化的 Bean 实例对象进行属性的依赖注入，即把 Bean对象设置到它所依赖的另一个 Bean 的属性中去。然而，BeanWrapperImpl 中的注入方法实际上由AbstractNestablePropertyAccessor来实现的，其相关源码如下： //实现属性依赖注入功能 protected void setPropertyValue(PropertyTokenHolder tokens, PropertyValue pv) throws BeansException &amp;#123; if (tokens.keys != null) &amp;#123; processKeyedProperty(tokens, pv); &amp;#125; else &amp;#123; processLocalProperty(tokens, pv); &amp;#125; &amp;#125; //实现属性依赖注入功能 @SuppressWarnings(\"unchecked\") private void processKeyedProperty(PropertyTokenHolder tokens, PropertyValue pv) &amp;#123; //调用属性的getter方法，获取属性的值 Object propValue = getPropertyHoldingValue(tokens); PropertyHandler ph = getLocalPropertyHandler(tokens.actualName); if (ph == null) &amp;#123; throw new InvalidPropertyException( getRootClass(), this.nestedPath + tokens.actualName, \"No property handler found\"); &amp;#125; Assert.state(tokens.keys != null, \"No token keys\"); String lastKey = tokens.keys[tokens.keys.length - 1]; //注入array类型的属性值 if (propValue.getClass().isArray()) &amp;#123; Class&lt;?> requiredType = propValue.getClass().getComponentType(); int arrayIndex = Integer.parseInt(lastKey); Object oldValue = null; try &amp;#123; if (isExtractOldValueForEditor() &amp;&amp; arrayIndex &lt; Array.getLength(propValue)) &amp;#123; oldValue = Array.get(propValue, arrayIndex); &amp;#125; Object convertedValue = convertIfNecessary(tokens.canonicalName, oldValue, pv.getValue(), requiredType, ph.nested(tokens.keys.length)); //获取集合类型属性的长度 int length = Array.getLength(propValue); if (arrayIndex >= length &amp;&amp; arrayIndex &lt; this.autoGrowCollectionLimit) &amp;#123; Class&lt;?> componentType = propValue.getClass().getComponentType(); Object newArray = Array.newInstance(componentType, arrayIndex + 1); System.arraycopy(propValue, 0, newArray, 0, length); setPropertyValue(tokens.actualName, newArray); //调用属性的getter方法，获取属性的值 propValue = getPropertyValue(tokens.actualName); &amp;#125; //将属性的值赋值给数组中的元素 Array.set(propValue, arrayIndex, convertedValue); &amp;#125; catch (IndexOutOfBoundsException ex) &amp;#123; throw new InvalidPropertyException(getRootClass(), this.nestedPath + tokens.canonicalName, \"Invalid array index in property path '\" + tokens.canonicalName + \"'\", ex); &amp;#125; &amp;#125; //注入list类型的属性值 else if (propValue instanceof List) &amp;#123; //获取list集合的类型 Class&lt;?> requiredType = ph.getCollectionType(tokens.keys.length); List&lt;Object> list = (List&lt;Object>) propValue; //获取list集合的size int index = Integer.parseInt(lastKey); Object oldValue = null; if (isExtractOldValueForEditor() &amp;&amp; index &lt; list.size()) &amp;#123; oldValue = list.get(index); &amp;#125; //获取list解析后的属性值 Object convertedValue = convertIfNecessary(tokens.canonicalName, oldValue, pv.getValue(), requiredType, ph.nested(tokens.keys.length)); int size = list.size(); //如果list的长度大于属性值的长度，则多余的元素赋值为null if (index >= size &amp;&amp; index &lt; this.autoGrowCollectionLimit) &amp;#123; for (int i = size; i &lt; index; i++) &amp;#123; try &amp;#123; list.add(null); &amp;#125; catch (NullPointerException ex) &amp;#123; throw new InvalidPropertyException(getRootClass(), this.nestedPath + tokens.canonicalName, \"Cannot set element with index \" + index + \" in List of size \" + size + \", accessed using property path '\" + tokens.canonicalName + \"': List does not support filling up gaps with null elements\"); &amp;#125; &amp;#125; list.add(convertedValue); &amp;#125; else &amp;#123; try &amp;#123; //将值添加到list中 list.set(index, convertedValue); &amp;#125; catch (IndexOutOfBoundsException ex) &amp;#123; throw new InvalidPropertyException(getRootClass(), this.nestedPath + tokens.canonicalName, \"Invalid list index in property path '\" + tokens.canonicalName + \"'\", ex); &amp;#125; &amp;#125; &amp;#125; //注入map类型的属性值 else if (propValue instanceof Map) &amp;#123; //获取map集合key的类型 Class&lt;?> mapKeyType = ph.getMapKeyType(tokens.keys.length); //获取map集合value的类型 Class&lt;?> mapValueType = ph.getMapValueType(tokens.keys.length); Map&lt;Object, Object> map = (Map&lt;Object, Object>) propValue; // IMPORTANT: Do not pass full property name in here - property editors // must not kick in for map keys but rather only for map values. TypeDescriptor typeDescriptor = TypeDescriptor.valueOf(mapKeyType); //解析map类型属性key值 Object convertedMapKey = convertIfNecessary(null, null, lastKey, mapKeyType, typeDescriptor); Object oldValue = null; if (isExtractOldValueForEditor()) &amp;#123; oldValue = map.get(convertedMapKey); &amp;#125; // Pass full property name and old value in here, since we want full // conversion ability for map values. //解析map类型属性value值 Object convertedMapValue = convertIfNecessary(tokens.canonicalName, oldValue, pv.getValue(), mapValueType, ph.nested(tokens.keys.length)); //将解析后的key和value值赋值给map集合属性 map.put(convertedMapKey, convertedMapValue); &amp;#125; else &amp;#123; throw new InvalidPropertyException(getRootClass(), this.nestedPath + tokens.canonicalName, \"Property referenced in indexed property path '\" + tokens.canonicalName + \"' is neither an array nor a List nor a Map; returned value was [\" + propValue + \"]\"); &amp;#125; &amp;#125; private Object getPropertyHoldingValue(PropertyTokenHolder tokens) &amp;#123; // Apply indexes and map keys: fetch value for all keys but the last one. Assert.state(tokens.keys != null, \"No token keys\"); PropertyTokenHolder getterTokens = new PropertyTokenHolder(tokens.actualName); getterTokens.canonicalName = tokens.canonicalName; getterTokens.keys = new String[tokens.keys.length - 1]; System.arraycopy(tokens.keys, 0, getterTokens.keys, 0, tokens.keys.length - 1); Object propValue; try &amp;#123; //获取属性值 propValue = getPropertyValue(getterTokens); &amp;#125; catch (NotReadablePropertyException ex) &amp;#123; throw new NotWritablePropertyException(getRootClass(), this.nestedPath + tokens.canonicalName, \"Cannot access indexed value in property referenced \" + \"in indexed property path '\" + tokens.canonicalName + \"'\", ex); &amp;#125; if (propValue == null) &amp;#123; // null map value case if (isAutoGrowNestedPaths()) &amp;#123; int lastKeyIndex = tokens.canonicalName.lastIndexOf('['); getterTokens.canonicalName = tokens.canonicalName.substring(0, lastKeyIndex); propValue = setDefaultValue(getterTokens); &amp;#125; else &amp;#123; throw new NullValueInNestedPathException(getRootClass(), this.nestedPath + tokens.canonicalName, \"Cannot access indexed value in property referenced \" + \"in indexed property path '\" + tokens.canonicalName + \"': returned null\"); &amp;#125; &amp;#125; return propValue; &amp;#125; 通过对上面注入依赖代码的分析，我们已经明白了 Spring IOC 容器是如何将属性的值注入到 Bean实例对象中去的： 1)、对于集合类型的属性，将其属性值解析为目标类型的集合后直接赋值给属性。 2)、对于非集合类型的属性，大量使用了JDK的反射机制，通过属性的getter()方法获取指定属性注入以前的值，同时调用属性的 setter()方法为属性设置注入后的值。看到这里相信很多人都明白了Spring的setter()注入原理。 至此 Spring IOC 容器对 Bean定义资源文件的定位，载入、解析和依赖注入已经全部分析完毕，现在SpringIOC 容器中管理了一系列靠依赖关系联系起来的Bean，程序不需要应用自己手动创建所需的对象，Spring IOC 容器会在我们使用的时候自动为我们创建，并且为我们注入好相关的依赖，这就是Spring核心功能的控制反转和依赖注入的相关功能。 IOC容器中那些鲜为人知的细节通过前面章节中对Spring IOC 容器的源码分析，我们已经基本上了解了Spring IOC 容器对Bean定义资源的定位、载入和注册过程，同时也清楚了当用户通过 getBean()方法向IOC 容器获取被管理的Bean时，IOC 容器对 Bean 进行的初始化和依赖注入过程，这些是 Spring IOC 容器的基本功能特性。Spring IOC 容器还有一些高级特性，如使用lazy-init 属性对Bean预初始化、FactoryBean 产生或者修饰 Bean对象的生成、 IOC 容器初始化 Bean过程中使用 BeanPostProcessor后置处理器对 Bean声明周期事件管理等。 关于延时加载通过前面我们对 IOC 容器的实现和工作原理分析，我们已经知道 IOC 容器的初始化过程就是对 Bean定义资源的定位、载入和注册，此时容器对Bean的依赖注入并没有发生，依赖注入主要是在应用程序第一次向容器索取Bean时，通过getBean()方法的调用完成。当Bean定义资源的元素中配置了 lazy-init=false属性时，容器将会在初始化的时候对所配置的 Bean 进行预实例化，Bean 的依赖注入在容器初始化的时候就已经完成。这样，当应用程序第一次向容器索取被管理的 Bean时，就不用再初始化和对 Bean进行依赖注入了，直接从容器中获取已经完成依赖注入的现成Bean，可以提高应用第一次向容器获取Bean的性能。 1、refresh()方法先从IOC 容器的初始化过程开始，我们知道 IOC 容器读入已经定位的 Bean定义资源是从refresh()方法开始的，我们首先从AbstractApplicationContext类的refresh()方法入手分析，源码如下： @Override public void refresh() throws BeansException, IllegalStateException &amp;#123; synchronized (this.startupShutdownMonitor) &amp;#123; // Prepare this context for refreshing. //1、调用容器准备刷新的方法，获取容器的当时时间，同时给容器设置同步标识 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. //2、告诉子类启动refreshBeanFactory()方法，Bean定义资源文件的载入从 //子类的refreshBeanFactory()方法启动 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. //3、为BeanFactory配置容器特性，例如类加载器、事件处理器等 prepareBeanFactory(beanFactory); try &amp;#123; // Allows post-processing of the bean factory in context subclasses. //4、为容器的某些子类指定特殊的BeanPost事件处理器 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. //5、调用所有注册的BeanFactoryPostProcessor的Bean invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. //6、为BeanFactory注册BeanPost事件处理器. //BeanPostProcessor是Bean后置处理器，用于监听容器触发的事件 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. //7、初始化信息源，和国际化相关. initMessageSource(); // Initialize event multicaster for this context. //8、初始化容器事件传播器. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. //9、调用子类的某些特殊Bean初始化方法 onRefresh(); // Check for listener beans and register them. //10、为事件传播器注册事件监听器. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. //11、初始化所有剩余的单例Bean finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. //12、初始化容器的生命周期事件处理器，并发布容器的生命周期事件 finishRefresh(); &amp;#125; catch (BeansException ex) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &amp;#125; // Destroy already created singletons to avoid dangling resources. //13、销毁已创建的Bean destroyBeans(); // Reset 'active' flag. //14、取消refresh操作，重置容器的同步标识。 cancelRefresh(ex); // Propagate exception to caller. throw ex; &amp;#125; finally &amp;#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... //15、重设公共缓存 resetCommonCaches(); &amp;#125; &amp;#125; &amp;#125; 在refresh()方法中ConfigurableListableBeanFactorybeanFactory = obtainFreshBeanFactory();启动了Bean定义资源的载入、注册过程，而finishBeanFactoryInitialization方法是对注册后的Bean定义中的预实例化(lazy-init=false,Spring默认就是预实例化,即为true)的Bean进行处理的地方。 2、finishBeanFactoryInitialization处理预实例化Bean当 Bean 定义资源被载入 IOC 容器之后，容器将 Bean 定义资源解析为容器内部的数据结构BeanDefinition注册到容器中， AbstractApplicationContext类中的finishBeanFactoryInitialization()方法对配置了预实例化属性的Bean进行预初始化过程，源码如下： //对配置了lazy-init属性的Bean进行预实例化处理 protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &amp;#123; // Initialize conversion service for this context. //这是Spring3以后新加的代码，为容器指定一个转换服务(ConversionService) //在对某些Bean属性进行转换时使用 if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &amp;#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &amp;#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &amp;#123; beanFactory.addEmbeddedValueResolver(strVal -> getEnvironment().resolvePlaceholders(strVal)); &amp;#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &amp;#123; getBean(weaverAwareName); &amp;#125; // Stop using the temporary ClassLoader for type matching. //为了类型匹配，停止使用临时的类加载器 beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. //缓存容器中所有注册的BeanDefinition元数据，以防被修改 beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. //对配置了lazy-init属性的单态模式Bean进行预实例化处理 beanFactory.preInstantiateSingletons(); &amp;#125; } ConfigurableListableBeanFactory 是一个接口， 其 preInstantiateSingletons()方法由其子类DefaultListableBeanFactory 提供。 3、DefaultListableBeanFactory 对配置lazy-init属性单态Bean的预实例化 //对配置lazy-init属性单态Bean的预实例化 @Override public void preInstantiateSingletons() throws BeansException &amp;#123; if (this.logger.isDebugEnabled()) &amp;#123; this.logger.debug(\"Pre-instantiating singletons in \" + this); &amp;#125; // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String> beanNames = new ArrayList&lt;>(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) &amp;#123; //获取指定名称的Bean定义 RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); //Bean不是抽象的，是单态模式的，且lazy-init属性配置为false if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &amp;#123; //如果指定名称的bean是创建容器的Bean if (isFactoryBean(beanName)) &amp;#123; //FACTORY_BEAN_PREFIX=”&amp;”，当Bean名称前面加”&amp;”符号 //时，获取的是产生容器对象本身，而不是容器产生的Bean. //调用getBean方法，触发容器对Bean实例化和依赖注入过程 final FactoryBean&lt;?> factory = (FactoryBean&lt;?>) getBean(FACTORY_BEAN_PREFIX + beanName); //标识是否需要预实例化 boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &amp;#123; //一个匿名内部类 isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean>) () -> ((SmartFactoryBean&lt;?>) factory).isEagerInit(), getAccessControlContext()); &amp;#125; else &amp;#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?>) factory).isEagerInit()); &amp;#125; if (isEagerInit) &amp;#123; //调用getBean方法，触发容器对Bean实例化和依赖注入过程 getBean(beanName); &amp;#125; &amp;#125; else &amp;#123; getBean(beanName); &amp;#125; &amp;#125; &amp;#125; // Trigger post-initialization callback for all applicable beans... for (String beanName : beanNames) &amp;#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &amp;#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &amp;#123; AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> &amp;#123; smartSingleton.afterSingletonsInstantiated(); return null; &amp;#125;, getAccessControlContext()); &amp;#125; else &amp;#123; smartSingleton.afterSingletonsInstantiated(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 通过对 lazy-init处理源码的分析，我们可以看出，如果设置了 lazy-init 属性，则容器在完成 Bean 定义的注册之后，会通过getBean方法，触发对指定Bean的初始化和依赖注入过程，这样当应用第一次 向容器索取所需的 Bean时，容器不再需要对 Bean进行初始化和依赖注入，直接从已经完成实例化和依赖注入的Bean中取一个现成的Bean，这样就提高了第一次获取Bean的性能。 关于FactoryBean和BeanFactory在Spring中，有两个很容易混淆的类：BeanFactory 和FactoryBean。 BeanFactory：Bean 工厂，是一个工厂(Factory)，我们 Spring IOC 容器的最顶层接口就是这个BeanFactory，它的作用是管理 Bean，即实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。 FactoryBean：工厂Bean，是一个 Bean，作用是产生其他 bean实例。通常情况下，这种Bean没有什么特别的要求，仅需要提供一个工厂方法，该方法用来返回其他 Bean实例。通常情况下，Bean无须自己实现工厂模式，Spring容器担任工厂角色；但少数情况下，容器中的Bean本身就是工厂，其作用是产生其它Bean实例。 当用户使用容器本身时，可以使用转义字符”&amp;”来得到FactoryBean本身，以区别通过FactoryBean产生的实例对象和FactoryBean对象本身。在BeanFactory 中通过如下代码定义了该转义字符：String FACTORY_BEAN_PREFIX = “&amp;”; 如果 myJndiObject是一个 FactoryBean，则使用&amp;myJndiObject 得到的是 myJndiObject 对象，而不是myJndiObject产生出来的对象。 1、FactoryBean源码：//工厂Bean，用于产生其他对象 public interface FactoryBean&lt;T> &amp;#123; /** * Return an instance (possibly shared or independent) of the object * managed by this factory. * &lt;p>As with a &amp;#123;@link BeanFactory&amp;#125;, this allows support for both the * Singleton and Prototype design pattern. * &lt;p>If this FactoryBean is not fully initialized yet at the time of * the call (for example because it is involved in a circular reference), * throw a corresponding &amp;#123;@link FactoryBeanNotInitializedException&amp;#125;. * &lt;p>As of Spring 2.0, FactoryBeans are allowed to return &amp;#123;@code null&amp;#125; * objects. The factory will consider this as normal value to be used; it * will not throw a FactoryBeanNotInitializedException in this case anymore. * FactoryBean implementations are encouraged to throw * FactoryBeanNotInitializedException themselves now, as appropriate. * @return an instance of the bean (can be &amp;#123;@code null&amp;#125;) * @throws Exception in case of creation errors * @see FactoryBeanNotInitializedException */ //获取容器管理的对象实例 @Nullable T getObject() throws Exception; /** * Return the type of object that this FactoryBean creates, * or &amp;#123;@code null&amp;#125; if not known in advance. * &lt;p>This allows one to check for specific types of beans without * instantiating objects, for example on autowiring. * &lt;p>In the case of implementations that are creating a singleton object, * this method should try to avoid singleton creation as far as possible; * it should rather estimate the type in advance. * For prototypes, returning a meaningful type here is advisable too. * &lt;p>This method can be called &lt;i>before&lt;/i> this FactoryBean has * been fully initialized. It must not rely on state created during * initialization; of course, it can still use such state if available. * &lt;p>&lt;b>NOTE:&lt;/b> Autowiring will simply ignore FactoryBeans that return * &amp;#123;@code null&amp;#125; here. Therefore it is highly recommended to implement * this method properly, using the current state of the FactoryBean. * @return the type of object that this FactoryBean creates, * or &amp;#123;@code null&amp;#125; if not known at the time of the call * @see ListableBeanFactory#getBeansOfType */ //获取Bean工厂创建的对象的类型 @Nullable Class&lt;?> getObjectType(); /** * Is the object managed by this factory a singleton? That is, * will &amp;#123;@link #getObject()&amp;#125; always return the same object * (a reference that can be cached)? * &lt;p>&lt;b>NOTE:&lt;/b> If a FactoryBean indicates to hold a singleton object, * the object returned from &amp;#123;@code getObject()&amp;#125; might get cached * by the owning BeanFactory. Hence, do not return &amp;#123;@code true&amp;#125; * unless the FactoryBean always exposes the same reference. * &lt;p>The singleton status of the FactoryBean itself will generally * be provided by the owning BeanFactory; usually, it has to be * defined as singleton there. * &lt;p>&lt;b>NOTE:&lt;/b> This method returning &amp;#123;@code false&amp;#125; does not * necessarily indicate that returned objects are independent instances. * An implementation of the extended &amp;#123;@link SmartFactoryBean&amp;#125; interface * may explicitly indicate independent instances through its * &amp;#123;@link SmartFactoryBean#isPrototype()&amp;#125; method. Plain &amp;#123;@link FactoryBean&amp;#125; * implementations which do not implement this extended interface are * simply assumed to always return independent instances if the * &amp;#123;@code isSingleton()&amp;#125; implementation returns &amp;#123;@code false&amp;#125;. * &lt;p>The default implementation returns &amp;#123;@code true&amp;#125;, since a * &amp;#123;@code FactoryBean&amp;#125; typically manages a singleton instance. * @return whether the exposed object is a singleton * @see #getObject() * @see SmartFactoryBean#isPrototype() */ //Bean工厂创建的对象是否是单态模式，如果是单态模式，则整个容器中只有一个实例 //对象，每次请求都返回同一个实例对象 default boolean isSingleton() &amp;#123; return true; &amp;#125; 2、AbstractBeanFactory的getBean()方法调用FactoryBean：在前面我们分析 Spring IOC 容器实例化 Bean并进行依赖注入过程的源码时，提到在 getBean()方法触发容器实例化Bean的时候会调用AbstractBeanFactory的doGetBean()方法来进行实例化的过程，源码如下： //真正实现向IOC容器获取Bean的功能，也是触发依赖注入功能的地方 protected &lt;T> T doGetBean(final String name, @Nullable final Class&lt;T> requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &amp;#123; //根据指定的名称获取被管理Bean的名称，剥离指定名称中对容器的相关依赖 //如果指定的是别名，将别名转换为规范的Bean名称 final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. //先从缓存中取是否已经有被创建过的单态类型的Bean //对于单例模式的Bean整个IOC容器中只创建一次，不需要重复创建 Object sharedInstance = getSingleton(beanName); //IOC容器创建单例模式Bean实例对象 if (sharedInstance != null &amp;&amp; args == null) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; //如果指定名称的Bean在容器中已有单例模式的Bean被创建 //直接返回已经创建的Bean if (isSingletonCurrentlyInCreation(beanName)) &amp;#123; logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &amp;#125; else &amp;#123; logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &amp;#125; &amp;#125; //获取给定Bean的实例对象，主要是完成FactoryBean的相关处理 //注意：BeanFactory是管理容器中Bean的工厂，而FactoryBean是 //创建创建对象的工厂Bean，两者之间有区别 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &amp;#125; else &amp;#123; // Fail if we're already creating this bean instance: // We're assumably within a circular reference. //缓存没有正在创建的单例模式Bean //缓存中已经有已经创建的原型模式Bean //但是由于循环引用的问题导致实例化对象失败 if (isPrototypeCurrentlyInCreation(beanName)) &amp;#123; throw new BeanCurrentlyInCreationException(beanName); &amp;#125; // Check if bean definition exists in this factory. //对IOC容器中是否存在指定名称的BeanDefinition进行检查，首先检查是否 //能在当前的BeanFactory中获取的所需要的Bean，如果不能则委托当前容器 //的父级容器去查找，如果还是找不到则沿着容器的继承体系向父级容器查找 BeanFactory parentBeanFactory = getParentBeanFactory(); //当前容器的父级容器存在，且当前容器中不存在指定名称的Bean if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &amp;#123; // Not found -> check parent. //解析指定Bean名称的原始名称 String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &amp;#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); &amp;#125; else if (args != null) &amp;#123; // Delegation to parent with explicit args. //委派父级容器根据指定名称和显式的参数查找 return (T) parentBeanFactory.getBean(nameToLookup, args); &amp;#125; else &amp;#123; // No args -> delegate to standard getBean method. //委派父级容器根据指定名称和类型查找 return parentBeanFactory.getBean(nameToLookup, requiredType); &amp;#125; &amp;#125; //创建的Bean是否需要进行类型验证，一般不需要 if (!typeCheckOnly) &amp;#123; //向容器标记指定的Bean已经被创建 markBeanAsCreated(beanName); &amp;#125; try &amp;#123; //根据指定Bean名称获取其父级的Bean定义 //主要解决Bean继承时子类合并父类公共属性问题 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. //获取当前Bean所有依赖Bean的名称 String[] dependsOn = mbd.getDependsOn(); //如果当前Bean有依赖Bean if (dependsOn != null) &amp;#123; for (String dep : dependsOn) &amp;#123; if (isDependent(beanName, dep)) &amp;#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &amp;#125; //递归调用getBean方法，获取当前Bean的依赖Bean registerDependentBean(dep, beanName); //把被依赖Bean注册给当前依赖的Bean getBean(dep); &amp;#125; &amp;#125; // Create bean instance. //创建单例模式Bean的实例对象 if (mbd.isSingleton()) &amp;#123; //这里使用了一个匿名内部类，创建Bean实例对象，并且注册给所依赖的对象 sharedInstance = getSingleton(beanName, () -> &amp;#123; try &amp;#123; //创建一个指定Bean实例对象，如果有父级继承，则合并子类和父类的定义 return createBean(beanName, mbd, args); &amp;#125; catch (BeansException ex) &amp;#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. //显式地从容器单例模式Bean缓存中清除实例对象 destroySingleton(beanName); throw ex; &amp;#125; &amp;#125;); //获取给定Bean的实例对象 bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &amp;#125; //IOC容器创建原型模式Bean实例对象 else if (mbd.isPrototype()) &amp;#123; // It's a prototype -> create a new instance. //原型模式(Prototype)是每次都会创建一个新的对象 Object prototypeInstance = null; try &amp;#123; //回调beforePrototypeCreation方法，默认的功能是注册当前创建的原型对象 beforePrototypeCreation(beanName); //创建指定Bean对象实例 prototypeInstance = createBean(beanName, mbd, args); &amp;#125; finally &amp;#123; //回调afterPrototypeCreation方法，默认的功能告诉IOC容器指定Bean的原型对象不再创建 afterPrototypeCreation(beanName); &amp;#125; //获取给定Bean的实例对象 bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &amp;#125; //要创建的Bean既不是单例模式，也不是原型模式，则根据Bean定义资源中 //配置的生命周期范围，选择实例化Bean的合适方法，这种在Web应用程序中 //比较常用，如：request、session、application等生命周期 else &amp;#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); //Bean定义资源中没有配置生命周期范围，则Bean定义不合法 if (scope == null) &amp;#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &amp;#125; try &amp;#123; //这里又使用了一个匿名内部类，获取一个指定生命周期范围的实例 Object scopedInstance = scope.get(beanName, () -> &amp;#123; beforePrototypeCreation(beanName); try &amp;#123; return createBean(beanName, mbd, args); &amp;#125; finally &amp;#123; afterPrototypeCreation(beanName); &amp;#125; &amp;#125;); //获取给定Bean的实例对象 bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &amp;#125; catch (IllegalStateException ex) &amp;#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &amp;#125; &amp;#125; &amp;#125; catch (BeansException ex) &amp;#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &amp;#125; &amp;#125; // Check if required type matches the type of the actual bean instance. //对创建的Bean实例对象进行类型检查 if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &amp;#123; try &amp;#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &amp;#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &amp;#125; return convertedBean; &amp;#125; catch (TypeMismatchException ex) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Failed to convert bean '\" + name + \"' to required type '\" + ClassUtils.getQualifiedName(requiredType) + \"'\", ex); &amp;#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &amp;#125; &amp;#125; return (T) bean; &amp;#125; //获取给定Bean的实例对象，主要是完成FactoryBean的相关处理 protected Object getObjectForBeanInstance( Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) &amp;#123; // Don't let calling code try to dereference the factory if the bean isn't a factory. //容器已经得到了Bean实例对象，这个实例对象可能是一个普通的Bean， //也可能是一个工厂Bean，如果是一个工厂Bean，则使用它创建一个Bean实例对象， //如果调用本身就想获得一个容器的引用，则指定返回这个工厂Bean实例对象 //如果指定的名称是容器的解引用(dereference，即是对象本身而非内存地址)， //且Bean实例也不是创建Bean实例对象的工厂Bean if (BeanFactoryUtils.isFactoryDereference(name) &amp;&amp; !(beanInstance instanceof FactoryBean)) &amp;#123; throw new BeanIsNotAFactoryException(transformedBeanName(name), beanInstance.getClass()); &amp;#125; // Now we have the bean instance, which may be a normal bean or a FactoryBean. // If it's a FactoryBean, we use it to create a bean instance, unless the // caller actually wants a reference to the factory. //如果Bean实例不是工厂Bean，或者指定名称是容器的解引用， //调用者向获取对容器的引用，则直接返回当前的Bean实例 if (!(beanInstance instanceof FactoryBean) || BeanFactoryUtils.isFactoryDereference(name)) &amp;#123; return beanInstance; &amp;#125; //处理指定名称不是容器的解引用，或者根据名称获取的Bean实例对象是一个工厂Bean //使用工厂Bean创建一个Bean的实例对象 Object object = null; if (mbd == null) &amp;#123; //从Bean工厂缓存中获取给定名称的Bean实例对象 object = getCachedObjectForFactoryBean(beanName); &amp;#125; //让Bean工厂生产给定名称的Bean对象实例 if (object == null) &amp;#123; // Return bean instance from factory. FactoryBean&lt;?> factory = (FactoryBean&lt;?>) beanInstance; // Caches object obtained from FactoryBean if it is a singleton. //如果从Bean工厂生产的Bean是单态模式的，则缓存 if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) &amp;#123; //从容器中获取指定名称的Bean定义，如果继承基类，则合并基类相关属性 mbd = getMergedLocalBeanDefinition(beanName); &amp;#125; //如果从容器得到Bean定义信息，并且Bean定义信息不是虚构的， //则让工厂Bean生产Bean实例对象 boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic()); //调用FactoryBeanRegistrySupport类的getObjectFromFactoryBean方法， //实现工厂Bean生产Bean对象实例的过程 object = getObjectFromFactoryBean(factory, beanName, !synthetic); &amp;#125; return object; &amp;#125; 在 上 面 获 取 给 定 Bean 的 实 例 对 象 的 getObjectForBeanInstance() 方 法 中 ， 会 调 用FactoryBeanRegistrySupport 类的 getObjectFromFactoryBean()方法，该方法实现了 Bean 工厂生产Bean实例对象。 Dereference(解引用)：一个在C/C++中应用比较多的术语，在C++中，”*”是解引用符号，而”&amp;”是引用符号，解引用是指变量指向的是所引用对象的本身数据，而不是引用对象的内存地址。 3、AbstractBeanFactory生产Bean实例对象AbstractBeanFactory 类中生产Bean实例对象的主要源码如下： //Bean工厂生产Bean实例对象 protected Object getObjectFromFactoryBean(FactoryBean&lt;?> factory, String beanName, boolean shouldPostProcess) &amp;#123; //Bean工厂是单态模式，并且Bean工厂缓存中存在指定名称的Bean实例对象 if (factory.isSingleton() &amp;&amp; containsSingleton(beanName)) &amp;#123; //多线程同步，以防止数据不一致 synchronized (getSingletonMutex()) &amp;#123; //直接从Bean工厂缓存中获取指定名称的Bean实例对象 Object object = this.factoryBeanObjectCache.get(beanName); //Bean工厂缓存中没有指定名称的实例对象，则生产该实例对象 if (object == null) &amp;#123; //调用Bean工厂的getObject方法生产指定Bean的实例对象 object = doGetObjectFromFactoryBean(factory, beanName); // Only post-process and store if not put there already during getObject() call above // (e.g. because of circular reference processing triggered by custom getBean calls) Object alreadyThere = this.factoryBeanObjectCache.get(beanName); if (alreadyThere != null) &amp;#123; object = alreadyThere; &amp;#125; else &amp;#123; if (shouldPostProcess) &amp;#123; try &amp;#123; object = postProcessObjectFromFactoryBean(object, beanName); &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's singleton object failed\", ex); &amp;#125; &amp;#125; //将生产的实例对象添加到Bean工厂缓存中 this.factoryBeanObjectCache.put(beanName, object); &amp;#125; &amp;#125; return object; &amp;#125; &amp;#125; //调用Bean工厂的getObject方法生产指定Bean的实例对象 else &amp;#123; Object object = doGetObjectFromFactoryBean(factory, beanName); if (shouldPostProcess) &amp;#123; try &amp;#123; object = postProcessObjectFromFactoryBean(object, beanName); &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's object failed\", ex); &amp;#125; &amp;#125; return object; &amp;#125; &amp;#125; /** * Obtain an object to expose from the given FactoryBean. * @param factory the FactoryBean instance * @param beanName the name of the bean * @return the object obtained from the FactoryBean * @throws BeanCreationException if FactoryBean object creation failed * @see org.springframework.beans.factory.FactoryBean#getObject() */ //调用Bean工厂的getObject方法生产指定Bean的实例对象 private Object doGetObjectFromFactoryBean(final FactoryBean&lt;?> factory, final String beanName) throws BeanCreationException &amp;#123; Object object; try &amp;#123; if (System.getSecurityManager() != null) &amp;#123; AccessControlContext acc = getAccessControlContext(); try &amp;#123; //实现PrivilegedExceptionAction接口的匿名内置类 //根据JVM检查权限，然后决定BeanFactory创建实例对象 object = AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object>) () -> factory.getObject(), acc); &amp;#125; catch (PrivilegedActionException pae) &amp;#123; throw pae.getException(); &amp;#125; &amp;#125; else &amp;#123; //调用BeanFactory接口实现类的创建对象方法 object = factory.getObject(); &amp;#125; &amp;#125; catch (FactoryBeanNotInitializedException ex) &amp;#123; throw new BeanCurrentlyInCreationException(beanName, ex.toString()); &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException(beanName, \"FactoryBean threw exception on object creation\", ex); &amp;#125; // Do not accept a null value for a FactoryBean that's not fully // initialized yet: Many FactoryBeans just return null then. //创建出来的实例对象为null，或者因为单态对象正在创建而返回null if (object == null) &amp;#123; if (isSingletonCurrentlyInCreation(beanName)) &amp;#123; throw new BeanCurrentlyInCreationException( beanName, \"FactoryBean which is currently in creation returned null from getObject\"); &amp;#125; object = new NullBean(); &amp;#125; return object; &amp;#125; 从上面的源码分析中，我们可以看出，BeanFactory 接口调用其实现类的 getObject 方法来实现创建Bean实例对象的功能。 4、工厂Bean的实现类getObject方法创建Bean实例对象FactoryBean 的实现类有非常多，比如：Proxy、RMI、JNDI、ServletContextFactoryBean 等等，FactoryBean 接口为 Spring 容器提供了一个很好的封装机制，具体的 getObject()有不同的实现类根据不同的实现策略来具体提供，我们分析一个最简单的AnnotationTestFactoryBean的实现源码： public class AnnotationTestBeanFactory implements FactoryBean&lt;FactoryCreatedAnnotationTestBean> &amp;#123; private final FactoryCreatedAnnotationTestBean instance = new FactoryCreatedAnnotationTestBean(); public AnnotationTestBeanFactory() &amp;#123; this.instance.setName(\"FACTORY\"); &amp;#125; @Override public FactoryCreatedAnnotationTestBean getObject() throws Exception &amp;#123; return this.instance; &amp;#125; //AnnotationTestBeanFactory产生Bean实例对象的实现 @Override public Class&lt;? extends IJmxTestBean> getObjectType() &amp;#123; return FactoryCreatedAnnotationTestBean.class; &amp;#125; @Override public boolean isSingleton() &amp;#123; return true; &amp;#125; &amp;#125; 其他的Proxy，RMI，JNDI等等，都是根据相应的策略提供getObject()的实现。这里不做一一分析，这已经不是Spring的核心功能，感兴趣的小伙可以再去深入研究。 再述autowiringSpring IOC 容器提供了两种管理Bean依赖关系的方式： 1)、显式管理：通过BeanDefinition的属性值和构造方法实现Bean依赖关系管理。 2)、 autowiring： Spring IOC 容器的依赖自动装配功能，不需要对Bean属性的依赖关系做显式的声明，只需要在配置好 autowiring 属性，IOC 容器会自动使用反射查找属性的类型和名称，然后基于属性的类型或者名称来自动匹配容器中管理的Bean，从而自动地完成依赖注入。通过对 autowiring自动装配特性的理解，我们知道容器对Bean的自动装配发生在容器对Bean依赖注入的过程中。在前面对 Spring IOC 容器的依赖注入过程源码分析中，我们已经知道了容器对Bean实例对象的属性注入的处理发生在 AbstractAutoWireCapableBeanFactory 类中的 populateBean()方法中，我们通过程序流程分析autowiring的实现原理： 1、AbstractAutoWireCapableBeanFactory 对Bean实例进行属性依赖注入应用第一次通过getBean()方法(配置了 lazy-init预实例化属性的除外)向IOC 容器索取 Bean时，容器创 建 Bean 实 例 对 象 ， 并 且 对 Bean 实 例 对 象 进 行 属 性 依 赖 注 入 ，AbstractAutoWireCapableBeanFactory 的 populateBean()方法就是实现 Bean 属性依赖注入的功能，其主要源码如下： //将Bean属性设置到生成的实例对象上 protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &amp;#123; if (bw == null) &amp;#123; if (mbd.hasPropertyValues()) &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\"); &amp;#125; else &amp;#123; // Skip property population phase for null instance. return; &amp;#125; &amp;#125; // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &amp;#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &amp;#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &amp;#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &amp;#123; continueWithPropertyPopulation = false; break; &amp;#125; &amp;#125; &amp;#125; &amp;#125; if (!continueWithPropertyPopulation) &amp;#123; return; &amp;#125; //获取容器在解析Bean定义资源时为BeanDefiniton中设置的属性值 PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); //对依赖注入处理，首先处理autowiring自动装配的依赖注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &amp;#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. //根据Bean名称进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &amp;#123; autowireByName(beanName, mbd, bw, newPvs); &amp;#125; // Add property values based on autowire by type if applicable. //根据Bean类型进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &amp;#123; autowireByType(beanName, mbd, bw, newPvs); &amp;#125; pvs = newPvs; &amp;#125; //对非autowiring的属性进行依赖注入处理 boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &amp;#123; if (pvs == null) &amp;#123; pvs = mbd.getPropertyValues(); &amp;#125; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &amp;#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &amp;#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &amp;#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &amp;#123; return; &amp;#125; &amp;#125; &amp;#125; &amp;#125; if (needsDepCheck) &amp;#123; checkDependencies(beanName, mbd, filteredPds, pvs); &amp;#125; &amp;#125; if (pvs != null) &amp;#123; //对属性进行注入 applyPropertyValues(beanName, mbd, bw, pvs); &amp;#125; &amp;#125; 2、Spring IOC容器根据Bean名称或者类型进行autowiring自动依赖注入//根据类型对属性进行自动依赖注入 protected void autowireByType( String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) &amp;#123; //获取用户定义的类型转换器 TypeConverter converter = getCustomTypeConverter(); if (converter == null) &amp;#123; converter = bw; &amp;#125; //存放解析的要注入的属性 Set&lt;String> autowiredBeanNames = new LinkedHashSet&lt;>(4); //对Bean对象中非简单属性(不是简单继承的对象，如8中原始类型，字符 //URL等都是简单属性)进行处理 String[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw); for (String propertyName : propertyNames) &amp;#123; try &amp;#123; //获取指定属性名称的属性描述器 PropertyDescriptor pd = bw.getPropertyDescriptor(propertyName); // Don't try autowiring by type for type Object: never makes sense, // even if it technically is a unsatisfied, non-simple property. //不对Object类型的属性进行autowiring自动依赖注入 if (Object.class != pd.getPropertyType()) &amp;#123; //获取属性的setter方法 MethodParameter methodParam = BeanUtils.getWriteMethodParameter(pd); // Do not allow eager init for type matching in case of a prioritized post-processor. //检查指定类型是否可以被转换为目标对象的类型 boolean eager = !PriorityOrdered.class.isInstance(bw.getWrappedInstance()); //创建一个要被注入的依赖描述 DependencyDescriptor desc = new AutowireByTypeDependencyDescriptor(methodParam, eager); //根据容器的Bean定义解析依赖关系，返回所有要被注入的Bean对象 Object autowiredArgument = resolveDependency(desc, beanName, autowiredBeanNames, converter); if (autowiredArgument != null) &amp;#123; //为属性赋值所引用的对象 pvs.add(propertyName, autowiredArgument); &amp;#125; for (String autowiredBeanName : autowiredBeanNames) &amp;#123; //指定名称属性注册依赖Bean名称，进行属性依赖注入 registerDependentBean(autowiredBeanName, beanName); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Autowiring by type from bean name '\" + beanName + \"' via property '\" + propertyName + \"' to bean named '\" + autowiredBeanName + \"'\"); &amp;#125; &amp;#125; //释放已自动注入的属性 autowiredBeanNames.clear(); &amp;#125; &amp;#125; catch (BeansException ex) &amp;#123; throw new UnsatisfiedDependencyException(mbd.getResourceDescription(), beanName, propertyName, ex); &amp;#125; &amp;#125; &amp;#125; 通过上面的源码分析，我们可以看出来通过属性名进行自动依赖注入的相对比通过属性类型进行自动依赖注入要稍微简单一些，但是真正实现属性注入的是 DefaultSingletonBeanRegistry 类的registerDependentBean()方法。 3、DefaultSingletonBeanRegistry 的registerDependentBean()方法对属性注入 //为指定的Bean注入依赖的Bean public void registerDependentBean(String beanName, String dependentBeanName) &amp;#123; // A quick check for an existing entry upfront, avoiding synchronization... //处理Bean名称，将别名转换为规范的Bean名称 String canonicalName = canonicalName(beanName); Set&lt;String> dependentBeans = this.dependentBeanMap.get(canonicalName); if (dependentBeans != null &amp;&amp; dependentBeans.contains(dependentBeanName)) &amp;#123; return; &amp;#125; // No entry yet -> fully synchronized manipulation of the dependentBeans Set //多线程同步，保证容器内数据的一致性 //先从容器中：bean名称-->全部依赖Bean名称集合找查找给定名称Bean的依赖Bean synchronized (this.dependentBeanMap) &amp;#123; //获取给定名称Bean的所有依赖Bean名称 dependentBeans = this.dependentBeanMap.get(canonicalName); if (dependentBeans == null) &amp;#123; //为Bean设置依赖Bean信息 dependentBeans = new LinkedHashSet&lt;>(8); this.dependentBeanMap.put(canonicalName, dependentBeans); &amp;#125; //向容器中：bean名称-->全部依赖Bean名称集合添加Bean的依赖信息 //即，将Bean所依赖的Bean添加到容器的集合中 dependentBeans.add(dependentBeanName); &amp;#125; //从容器中：bean名称-->指定名称Bean的依赖Bean集合找查找给定名称Bean的依赖Bean synchronized (this.dependenciesForBeanMap) &amp;#123; Set&lt;String> dependenciesForBean = this.dependenciesForBeanMap.get(dependentBeanName); if (dependenciesForBean == null) &amp;#123; dependenciesForBean = new LinkedHashSet&lt;>(8); this.dependenciesForBeanMap.put(dependentBeanName, dependenciesForBean); &amp;#125; //向容器中：bean名称-->指定Bean的依赖Bean名称集合添加Bean的依赖信息 //即，将Bean所依赖的Bean添加到容器的集合中 dependenciesForBean.add(canonicalName); &amp;#125; &amp;#125; 通过对autowiring的源码分析，我们可以看出，autowiring的实现过程： a、对Bean的属性代调用getBean()方法，完成依赖Bean的初始化和依赖注入。 b、将依赖Bean的属性引用设置到被依赖的Bean属性上。 c、将依赖Bean的名称和被依赖Bean的名称存储在IOC 容器的集合中。SpringIOC 容器的 autowiring属性自动依赖注入是一个很方便的特性，可以简化开发时的配置，但是凡是都有两面性，自动属性依赖注入也有不足，首先，Bean的依赖关系在 配置文件中无法很清楚地看出来，对于维护造成一定困难。其次，由于自动依赖注入是 Spring容器自动执行的，容器是不会智能判断的，如果配置不当，将会带来无法预料的后果，所以自动依赖注入特性在使用时还是综合考虑。","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring IOC的 源码解析(5)","slug":"spring/Spring IOC的 源码解析(5)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-ioc-de-yuan-ma-jie-xi-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-ioc-de-yuan-ma-jie-xi-5/","excerpt":"","text":"5. Spring核心之IOC源码解析再谈IOC与DI&emsp;&emsp; IOC(Inversion of Control)控制反转：所谓控制反转，就是把原先我们代码里面需要实现的对象创建、依赖的代码，反转给容器来帮忙实现。那么必然的我们需要创建一个容器，同时需要一种描述来让容器知道需要创建的对象与对象的关系。这个描述最具体表现就是我们所看到的配置文件。DI(DependencyInjection)依赖注入：就是指对象是被动接受依赖类而不是自己主动去找，换句话说就是指对象不是从容器中查找它依赖的类，而是在容器实例化对象的时候主动将它依赖的类注入给它。先从我们自己设计这样一个视角来考虑： 对象和对象的关系怎么表示？ 可以用xml，properties文件等语义化配置文件表示。2. 描述对象关系的文件存放在哪里？ 可能是classpath，filesystem，或者是URL网络资源，servletContext等。回到正题，有了配置文件，还需要对配置文件解析。 不同的配置文件对对象的描述不一样，如标准的，自定义声明式的，如何统一？在内部需要有一个统一的关于对象的定义，所有外部的描述都必须转化成统一的描述定义。 如何对不同的配置文件进行解析？需要对不同的配置文件语法，采用不同的解析器。 Spring核心容器类图1. BeanFactory&emsp;&emsp; Spring Bean的创建是典型的工厂模式，这一系列的Bean工厂，也即 IOC容器为开发者管理对象间的依赖关系提供了很多便利和基础服务，在Spring中有许多的 IOC容器的实现供用户选择和使用，其相互关系如下： 其中BeanFactory 作为最顶层的一个接口类，它定义了 IOC 容器的基本功能规范，BeanFactory 有三个重要的子类：ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory。但是从类图中我们可以发现最终的默认实现类是 DefaultListableBeanFactory，它实现了所有的接口。 那为何要定义这么多层次的接口呢？查阅这些接口的源码和说明发现，每个接口都有它使用的场合，它主要是为了区分在Spring内部在操作过程中对象的传递和转化过程时，对对象的数据访问所做的限制。例如ListableBeanFactory 接口表示这些 Bean是可列表化的，而 HierarchicalBeanFactory 表示的是这些 Bean是有继承关系的，也就是每个 Bean 有可能有父 Bean。AutowireCapableBeanFactory 接口定义Bean的自动装配规则。这三个接口共同定义了Bean的集合、Bean之间的关系、以及Bean行为。最基本的IOC 容器接口BeanFactory，来看一下它的源码： /* * Copyright 2002-2017 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package org.springframework.beans.factory; import org.springframework.beans.BeansException; import org.springframework.core.ResolvableType; import org.springframework.lang.Nullable; /** * The root interface for accessing a Spring bean container. * This is the basic client view of a bean container; * further interfaces such as &amp;#123;@link ListableBeanFactory&amp;#125; and * &amp;#123;@link org.springframework.beans.factory.config.ConfigurableBeanFactory&amp;#125; * are available for specific purposes. * * &lt;p>This interface is implemented by objects that hold a number of bean definitions, * each uniquely identified by a String name. Depending on the bean definition, * the factory will return either an independent instance of a contained object * (the Prototype design pattern), or a single shared instance (a superior * alternative to the Singleton design pattern, in which the instance is a * singleton in the scope of the factory). Which type of instance will be returned * depends on the bean factory configuration: the API is the same. Since Spring * 2.0, further scopes are available depending on the concrete application * context (e.g. \"request\" and \"session\" scopes in a web environment). * * &lt;p>The point of this approach is that the BeanFactory is a central registry * of application components, and centralizes configuration of application * components (no more do individual objects need to read properties files, * for example). See chapters 4 and 11 of \"Expert One-on-One J2EE Design and * Development\" for a discussion of the benefits of this approach. * * &lt;p>Note that it is generally better to rely on Dependency Injection * (\"push\" configuration) to configure application objects through setters * or constructors, rather than use any form of \"pull\" configuration like a * BeanFactory lookup. Spring's Dependency Injection functionality is * implemented using this BeanFactory interface and its subinterfaces. * * &lt;p>Normally a BeanFactory will load bean definitions stored in a configuration * source (such as an XML document), and use the &amp;#123;@code org.springframework.beans&amp;#125; * package to configure the beans. However, an implementation could simply return * Java objects it creates as necessary directly in Java code. There are no * constraints on how the definitions could be stored: LDAP, RDBMS, XML, * properties file, etc. Implementations are encouraged to support references * amongst beans (Dependency Injection). * * &lt;p>In contrast to the methods in &amp;#123;@link ListableBeanFactory&amp;#125;, all of the * operations in this interface will also check parent factories if this is a * &amp;#123;@link HierarchicalBeanFactory&amp;#125;. If a bean is not found in this factory instance, * the immediate parent factory will be asked. Beans in this factory instance * are supposed to override beans of the same name in any parent factory. * * &lt;p>Bean factory implementations should support the standard bean lifecycle interfaces * as far as possible. The full set of initialization methods and their standard order is: * &lt;ol> * &lt;li>BeanNameAware's &amp;#123;@code setBeanName&amp;#125; * &lt;li>BeanClassLoaderAware's &amp;#123;@code setBeanClassLoader&amp;#125; * &lt;li>BeanFactoryAware's &amp;#123;@code setBeanFactory&amp;#125; * &lt;li>EnvironmentAware's &amp;#123;@code setEnvironment&amp;#125; * &lt;li>EmbeddedValueResolverAware's &amp;#123;@code setEmbeddedValueResolver&amp;#125; * &lt;li>ResourceLoaderAware's &amp;#123;@code setResourceLoader&amp;#125; * (only applicable when running in an application context) * &lt;li>ApplicationEventPublisherAware's &amp;#123;@code setApplicationEventPublisher&amp;#125; * (only applicable when running in an application context) * &lt;li>MessageSourceAware's &amp;#123;@code setMessageSource&amp;#125; * (only applicable when running in an application context) * &lt;li>ApplicationContextAware's &amp;#123;@code setApplicationContext&amp;#125; * (only applicable when running in an application context) * &lt;li>ServletContextAware's &amp;#123;@code setServletContext&amp;#125; * (only applicable when running in a web application context) * &lt;li>&amp;#123;@code postProcessBeforeInitialization&amp;#125; methods of BeanPostProcessors * &lt;li>InitializingBean's &amp;#123;@code afterPropertiesSet&amp;#125; * &lt;li>a custom init-method definition * &lt;li>&amp;#123;@code postProcessAfterInitialization&amp;#125; methods of BeanPostProcessors * &lt;/ol> * * &lt;p>On shutdown of a bean factory, the following lifecycle methods apply: * &lt;ol> * &lt;li>&amp;#123;@code postProcessBeforeDestruction&amp;#125; methods of DestructionAwareBeanPostProcessors * &lt;li>DisposableBean's &amp;#123;@code destroy&amp;#125; * &lt;li>a custom destroy-method definition * &lt;/ol> * * @author Rod Johnson * @author Juergen Hoeller * @author Chris Beams * @since 13 April 2001 * @see BeanNameAware#setBeanName * @see BeanClassLoaderAware#setBeanClassLoader * @see BeanFactoryAware#setBeanFactory * @see org.springframework.context.ResourceLoaderAware#setResourceLoader * @see org.springframework.context.ApplicationEventPublisherAware#setApplicationEventPublisher * @see org.springframework.context.MessageSourceAware#setMessageSource * @see org.springframework.context.ApplicationContextAware#setApplicationContext * @see org.springframework.web.context.ServletContextAware#setServletContext * @see org.springframework.beans.factory.config.BeanPostProcessor#postProcessBeforeInitialization * @see InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.support.RootBeanDefinition#getInitMethodName * @see org.springframework.beans.factory.config.BeanPostProcessor#postProcessAfterInitialization * @see DisposableBean#destroy * @see org.springframework.beans.factory.support.RootBeanDefinition#getDestroyMethodName */ public interface BeanFactory &amp;#123; /** * Used to dereference a &amp;#123;@link FactoryBean&amp;#125; instance and distinguish it from * beans &lt;i>created&lt;/i> by the FactoryBean. For example, if the bean named * &amp;#123;@code myJndiObject&amp;#125; is a FactoryBean, getting &amp;#123;@code &amp;myJndiObject&amp;#125; * will return the factory, not the instance returned by the factory. */ //对FactoryBean的转义定义，因为如果使用bean的名字检索FactoryBean得到的对象是工厂生成的对象， //如果需要得到工厂本身，需要转义 String FACTORY_BEAN_PREFIX = \"&amp;\"; /** * Return an instance, which may be shared or independent, of the specified bean. * &lt;p>This method allows a Spring BeanFactory to be used as a replacement for the * Singleton or Prototype design pattern. Callers may retain references to * returned objects in the case of Singleton beans. * &lt;p>Translates aliases back to the corresponding canonical bean name. * Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the name of the bean to retrieve * @return an instance of the bean * @throws NoSuchBeanDefinitionException if there is no bean definition * with the specified name * @throws BeansException if the bean could not be obtained */ //根据bean的名字，获取在IOC容器中得到bean实例 Object getBean(String name) throws BeansException; /** * Return an instance, which may be shared or independent, of the specified bean. * &lt;p>Behaves the same as &amp;#123;@link #getBean(String)&amp;#125;, but provides a measure of type * safety by throwing a BeanNotOfRequiredTypeException if the bean is not of the * required type. This means that ClassCastException can't be thrown on casting * the result correctly, as can happen with &amp;#123;@link #getBean(String)&amp;#125;. * &lt;p>Translates aliases back to the corresponding canonical bean name. * Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the name of the bean to retrieve * @param requiredType type the bean must match. Can be an interface or superclass * of the actual class, or &amp;#123;@code null&amp;#125; for any match. For example, if the value * is &amp;#123;@code Object.class&amp;#125;, this method will succeed whatever the class of the * returned instance. * @return an instance of the bean * @throws NoSuchBeanDefinitionException if there is no such bean definition * @throws BeanNotOfRequiredTypeException if the bean is not of the required type * @throws BeansException if the bean could not be created */ //根据bean的名字和Class类型来得到bean实例，增加了类型安全验证机制。 &lt;T> T getBean(String name, @Nullable Class&lt;T> requiredType) throws BeansException; /** * Return an instance, which may be shared or independent, of the specified bean. * &lt;p>Allows for specifying explicit constructor arguments / factory method arguments, * overriding the specified default arguments (if any) in the bean definition. * @param name the name of the bean to retrieve * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @return an instance of the bean * @throws NoSuchBeanDefinitionException if there is no such bean definition * @throws BeanDefinitionStoreException if arguments have been given but * the affected bean isn't a prototype * @throws BeansException if the bean could not be created * @since 2.5 */ Object getBean(String name, Object... args) throws BeansException; /** * Return the bean instance that uniquely matches the given object type, if any. * &lt;p>This method goes into &amp;#123;@link ListableBeanFactory&amp;#125; by-type lookup territory * but may also be translated into a conventional by-name lookup based on the name * of the given type. For more extensive retrieval operations across sets of beans, * use &amp;#123;@link ListableBeanFactory&amp;#125; and/or &amp;#123;@link BeanFactoryUtils&amp;#125;. * @param requiredType type the bean must match; can be an interface or superclass. * &amp;#123;@code null&amp;#125; is disallowed. * @return an instance of the single bean matching the required type * @throws NoSuchBeanDefinitionException if no bean of the given type was found * @throws NoUniqueBeanDefinitionException if more than one bean of the given type was found * @throws BeansException if the bean could not be created * @since 3.0 * @see ListableBeanFactory */ &lt;T> T getBean(Class&lt;T> requiredType) throws BeansException; /** * Return an instance, which may be shared or independent, of the specified bean. * &lt;p>Allows for specifying explicit constructor arguments / factory method arguments, * overriding the specified default arguments (if any) in the bean definition. * &lt;p>This method goes into &amp;#123;@link ListableBeanFactory&amp;#125; by-type lookup territory * but may also be translated into a conventional by-name lookup based on the name * of the given type. For more extensive retrieval operations across sets of beans, * use &amp;#123;@link ListableBeanFactory&amp;#125; and/or &amp;#123;@link BeanFactoryUtils&amp;#125;. * @param requiredType type the bean must match; can be an interface or superclass. * &amp;#123;@code null&amp;#125; is disallowed. * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @return an instance of the bean * @throws NoSuchBeanDefinitionException if there is no such bean definition * @throws BeanDefinitionStoreException if arguments have been given but * the affected bean isn't a prototype * @throws BeansException if the bean could not be created * @since 4.1 */ &lt;T> T getBean(Class&lt;T> requiredType, Object... args) throws BeansException; /** * Does this bean factory contain a bean definition or externally registered singleton * instance with the given name? * &lt;p>If the given name is an alias, it will be translated back to the corresponding * canonical bean name. * &lt;p>If this factory is hierarchical, will ask any parent factory if the bean cannot * be found in this factory instance. * &lt;p>If a bean definition or singleton instance matching the given name is found, * this method will return &amp;#123;@code true&amp;#125; whether the named bean definition is concrete * or abstract, lazy or eager, in scope or not. Therefore, note that a &amp;#123;@code true&amp;#125; * return value from this method does not necessarily indicate that &amp;#123;@link #getBean&amp;#125; * will be able to obtain an instance for the same name. * @param name the name of the bean to query * @return whether a bean with the given name is present */ //提供对bean的检索，看看是否在IOC容器有这个名字的bean boolean containsBean(String name); /** * Is this bean a shared singleton? That is, will &amp;#123;@link #getBean&amp;#125; always * return the same instance? * &lt;p>Note: This method returning &amp;#123;@code false&amp;#125; does not clearly indicate * independent instances. It indicates non-singleton instances, which may correspond * to a scoped bean as well. Use the &amp;#123;@link #isPrototype&amp;#125; operation to explicitly * check for independent instances. * &lt;p>Translates aliases back to the corresponding canonical bean name. * Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the name of the bean to query * @return whether this bean corresponds to a singleton instance * @throws NoSuchBeanDefinitionException if there is no bean with the given name * @see #getBean * @see #isPrototype */ //根据bean名字得到bean实例，并同时判断这个bean是不是单例 boolean isSingleton(String name) throws NoSuchBeanDefinitionException; /** * Is this bean a prototype? That is, will &amp;#123;@link #getBean&amp;#125; always return * independent instances? * &lt;p>Note: This method returning &amp;#123;@code false&amp;#125; does not clearly indicate * a singleton object. It indicates non-independent instances, which may correspond * to a scoped bean as well. Use the &amp;#123;@link #isSingleton&amp;#125; operation to explicitly * check for a shared singleton instance. * &lt;p>Translates aliases back to the corresponding canonical bean name. * Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the name of the bean to query * @return whether this bean will always deliver independent instances * @throws NoSuchBeanDefinitionException if there is no bean with the given name * @since 2.0.3 * @see #getBean * @see #isSingleton */ boolean isPrototype(String name) throws NoSuchBeanDefinitionException; /** * Check whether the bean with the given name matches the specified type. * More specifically, check whether a &amp;#123;@link #getBean&amp;#125; call for the given name * would return an object that is assignable to the specified target type. * &lt;p>Translates aliases back to the corresponding canonical bean name. * Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the name of the bean to query * @param typeToMatch the type to match against (as a &amp;#123;@code ResolvableType&amp;#125;) * @return &amp;#123;@code true&amp;#125; if the bean type matches, * &amp;#123;@code false&amp;#125; if it doesn't match or cannot be determined yet * @throws NoSuchBeanDefinitionException if there is no bean with the given name * @since 4.2 * @see #getBean * @see #getType */ boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException; /** * Check whether the bean with the given name matches the specified type. * More specifically, check whether a &amp;#123;@link #getBean&amp;#125; call for the given name * would return an object that is assignable to the specified target type. * &lt;p>Translates aliases back to the corresponding canonical bean name. * Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the name of the bean to query * @param typeToMatch the type to match against (as a &amp;#123;@code Class&amp;#125;) * @return &amp;#123;@code true&amp;#125; if the bean type matches, * &amp;#123;@code false&amp;#125; if it doesn't match or cannot be determined yet * @throws NoSuchBeanDefinitionException if there is no bean with the given name * @since 2.0.1 * @see #getBean * @see #getType */ boolean isTypeMatch(String name, @Nullable Class&lt;?> typeToMatch) throws NoSuchBeanDefinitionException; /** * Determine the type of the bean with the given name. More specifically, * determine the type of object that &amp;#123;@link #getBean&amp;#125; would return for the given name. * &lt;p>For a &amp;#123;@link FactoryBean&amp;#125;, return the type of object that the FactoryBean creates, * as exposed by &amp;#123;@link FactoryBean#getObjectType()&amp;#125;. * &lt;p>Translates aliases back to the corresponding canonical bean name. * Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the name of the bean to query * @return the type of the bean, or &amp;#123;@code null&amp;#125; if not determinable * @throws NoSuchBeanDefinitionException if there is no bean with the given name * @since 1.1.2 * @see #getBean * @see #isTypeMatch */ //得到bean实例的Class类型 @Nullable Class&lt;?> getType(String name) throws NoSuchBeanDefinitionException; /** * Return the aliases for the given bean name, if any. * All of those aliases point to the same bean when used in a &amp;#123;@link #getBean&amp;#125; call. * &lt;p>If the given name is an alias, the corresponding original bean name * and other aliases (if any) will be returned, with the original bean name * being the first element in the array. * &lt;p>Will ask the parent factory if the bean cannot be found in this factory instance. * @param name the bean name to check for aliases * @return the aliases, or an empty array if none * @see #getBean */ //得到bean的别名，如果根据别名检索，那么其原名也会被检索出来 String[] getAliases(String name); &amp;#125; 在BeanFactory 里只对 IOC 容器的基本行为作了定义，根本不关心你的Bean是如何定义怎样加载的。正如我们只关心工厂里得到什么的产品对象，至于工厂是怎么生产这些对象的，这个基本的接口不关心。 &emsp;&emsp;而要知道工厂是如何产生对象的，我们需要看具体的 IOC 容器实现，Spring 提供了许多IOC 容器的 实 现 。 比 如 GenericApplicationContext ， ClasspathXmlApplicationContext 等 。 &emsp;&emsp;ApplicationContext是Spring 提供的一个高级的IOC 容器，它除了能够提供IOC 容器的基本功能外，还为用户提供了以下的附加服务。从ApplicationContext接口的实现，我们看出其特点： 支持信息源，可以实现国际化。（实现MessageSource接口） 访问资源。(实现ResourcePatternResolver接口，后面章节会讲到) 支持应用事件。(实现ApplicationEventPublisher接口) 2、BeanDefinition&emsp;&emsp; SpringIOC 容器管理了我们定义的各种Bean对象及其相互的关系，Bean对象在Spring 实现中是以BeanDefinition来描述的，其继承体系如下： 3、BeanDefinitionReaderBean的解析过程非常复杂，功能被分的很细，因为这里需要被扩展的地方很多，必须保证有足够的灵活性，以应对可能的变化。Bean 的解析主要就是对 Spring 配置文件的解析。这个解析过程主要通过BeanDefintionReader来完成，最后看看Spring中BeanDefintionReader的类结构图： Web IOC容器初体验&emsp;&emsp; 我们还是从大家最熟悉的DispatcherServlet开始，我们最先想到的还是DispatcherServlet 的init()方法。我们发现在DispatherServlet 中并没有找到init()方法。但是经过探索，往上追索在其父类HttpServletBean中找到了我们想要的init()方法，如下： /** * Map config parameters onto bean properties of this servlet, and * invoke subclass initialization. * @throws ServletException if bean properties are invalid (or required * properties are missing), or if subclass initialization fails. */ @Override public final void init() throws ServletException &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Initializing servlet '\" + getServletName() + \"'\"); &amp;#125; // Set bean properties from init parameters. PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &amp;#123; try &amp;#123; //定位资源 BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); //加载配置信息 ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &amp;#125; catch (BeansException ex) &amp;#123; if (logger.isErrorEnabled()) &amp;#123; logger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex); &amp;#125; throw ex; &amp;#125; &amp;#125; // Let subclasses do whatever initialization they like. initServletBean(); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\"); &amp;#125; &amp;#125; 在init()方法中，真正完成初始化容器动作的逻辑其实在initServletBean()方法中，我们继续跟进initServletBean()中的代码在FrameworkServlet 类中： /** * Overridden method of &amp;#123;@link HttpServletBean&amp;#125;, invoked after any bean properties * have been set. Creates this servlet's WebApplicationContext. */ @Override protected final void initServletBean() throws ServletException &amp;#123; getServletContext().log(\"Initializing Spring FrameworkServlet '\" + getServletName() + \"'\"); if (this.logger.isInfoEnabled()) &amp;#123; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization started\"); &amp;#125; long startTime = System.currentTimeMillis(); try &amp;#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &amp;#125; catch (ServletException ex) &amp;#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &amp;#125; catch (RuntimeException ex) &amp;#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &amp;#125; if (this.logger.isInfoEnabled()) &amp;#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization completed in \" + elapsedTime + \" ms\"); &amp;#125; &amp;#125; 在上面的代码中终于看到了我们似曾相识的代码initWebAppplicationContext()，继续跟进： /** * Initialize and publish the WebApplicationContext for this servlet. * &lt;p>Delegates to &amp;#123;@link #createWebApplicationContext&amp;#125; for actual creation * of the context. Can be overridden in subclasses. * @return the WebApplicationContext instance * @see #FrameworkServlet(WebApplicationContext) * @see #setContextClass * @see #setContextConfigLocation */ protected WebApplicationContext initWebApplicationContext() &amp;#123; //先从ServletContext中获得父容器WebAppliationContext WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); //声明子容器 WebApplicationContext wac = null; //建立父、子容器之间的关联关系 if (this.webApplicationContext != null) &amp;#123; // A context instance was injected at construction time -> use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &amp;#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &amp;#123; // The context has not yet been refreshed -> provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &amp;#123; // The context instance was injected without an explicit parent -> set // the root application context (if any; may be null) as the parent cwac.setParent(rootContext); &amp;#125; //这个方法里面调用了AbatractApplication的refresh()方法 //模板方法，规定IOC初始化基本流程 configureAndRefreshWebApplicationContext(cwac); &amp;#125; &amp;#125; &amp;#125; //先去ServletContext中查找Web容器的引用是否存在，并创建好默认的空IOC容器 if (wac == null) &amp;#123; // No context instance was injected at construction time -> see if one // has been registered in the servlet context. If one exists, it is assumed // that the parent context (if any) has already been set and that the // user has performed any initialization such as setting the context id wac = findWebApplicationContext(); &amp;#125; //给上一步创建好的IOC容器赋值 if (wac == null) &amp;#123; // No context instance is defined for this servlet -> create a local one wac = createWebApplicationContext(rootContext); &amp;#125; //触发onRefresh方法 if (!this.refreshEventReceived) &amp;#123; // Either the context is not a ConfigurableApplicationContext with refresh // support or the context injected at construction time had already been // refreshed -> trigger initial onRefresh manually here. onRefresh(wac); &amp;#125; if (this.publishContext) &amp;#123; // Publish the context as a servlet context attribute. String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); if (this.logger.isDebugEnabled()) &amp;#123; this.logger.debug(\"Published WebApplicationContext of servlet '\" + getServletName() + \"' as ServletContext attribute with name [\" + attrName + \"]\"); &amp;#125; &amp;#125; return wac; &amp;#125; /** * Instantiate the WebApplicationContext for this servlet, either a default * &amp;#123;@link org.springframework.web.context.support.XmlWebApplicationContext&amp;#125; * or a &amp;#123;@link #setContextClass custom context class&amp;#125;, if set. * &lt;p>This implementation expects custom contexts to implement the * &amp;#123;@link org.springframework.web.context.ConfigurableWebApplicationContext&amp;#125; * interface. Can be overridden in subclasses. * &lt;p>Do not forget to register this servlet instance as application listener on the * created context (for triggering its &amp;#123;@link #onRefresh callback&amp;#125;, and to call * &amp;#123;@link org.springframework.context.ConfigurableApplicationContext#refresh()&amp;#125; * before returning the context instance. * @param parent the parent ApplicationContext to use, or &amp;#123;@code null&amp;#125; if none * @return the WebApplicationContext for this servlet * @see org.springframework.web.context.support.XmlWebApplicationContext */ protected WebApplicationContext createWebApplicationContext(@Nullable ApplicationContext parent) &amp;#123; Class&lt;?> contextClass = getContextClass(); if (this.logger.isDebugEnabled()) &amp;#123; this.logger.debug(\"Servlet with name '\" + getServletName() + \"' will try to create custom WebApplicationContext context of class '\" + contextClass.getName() + \"'\" + \", using parent context [\" + parent + \"]\"); &amp;#125; if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &amp;#123; throw new ApplicationContextException( \"Fatal initialization error in servlet with name '\" + getServletName() + \"': custom WebApplicationContext class [\" + contextClass.getName() + \"] is not of type ConfigurableWebApplicationContext\"); &amp;#125; ConfigurableWebApplicationContext wac = (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass); wac.setEnvironment(getEnvironment()); wac.setParent(parent); String configLocation = getContextConfigLocation(); if (configLocation != null) &amp;#123; wac.setConfigLocation(configLocation); &amp;#125; configureAndRefreshWebApplicationContext(wac); return wac; &amp;#125; protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) &amp;#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &amp;#123; // The application context id is still set to its original default value // -> assign a more useful id based on available information if (this.contextId != null) &amp;#123; wac.setId(this.contextId); &amp;#125; else &amp;#123; // Generate default id... wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(getServletContext().getContextPath()) + '/' + getServletName()); &amp;#125; &amp;#125; wac.setServletContext(getServletContext()); wac.setServletConfig(getServletConfig()); wac.setNamespace(getNamespace()); wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener())); // The wac environment's #initPropertySources will be called in any case when the context // is refreshed; do it eagerly here to ensure servlet property sources are in place for // use in any post-processing or initialization that occurs below prior to #refresh ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &amp;#123; ((ConfigurableWebEnvironment) env).initPropertySources(getServletContext(), getServletConfig()); &amp;#125; postProcessWebApplicationContext(wac); applyInitializers(wac); wac.refresh(); &amp;#125; 从上面的代码中可以看出，在configAndRefreshWebApplicationContext()方法中，调用refresh()方法，这个是真正启动IOC 容器的入口，后面会详细介绍。IOC 容器初始化以后，最后调用了DispatcherServlet的onRefresh()方法，在onRefresh()方法中又是直接调用initStrategies()方法初始化SpringMVC的九大组件： /** * Initialize the strategy objects that this servlet uses. * &lt;p>May be overridden in subclasses in order to initialize further strategy objects. */ //初始化策略 protected void initStrategies(ApplicationContext context) &amp;#123; //多文件上传的组件 initMultipartResolver(context); //初始化本地语言环境 initLocaleResolver(context); //初始化模板处理器 initThemeResolver(context); //handlerMapping initHandlerMappings(context); //初始化参数适配器 initHandlerAdapters(context); //初始化异常拦截器 initHandlerExceptionResolvers(context); //初始化视图预处理器 initRequestToViewNameTranslator(context); //初始化视图转换器 initViewResolvers(context); // initFlashMapManager(context); &amp;#125; 基于Xml的IOC容器的初始化&emsp;&emsp; IOC 容器的初始化包括BeanDefinition的Resource定位、加载和注册这三个基本的过程。我们以ApplicationContext 为例讲解，ApplicationContext 系列容器也许是我们最熟悉的，因为 Web 项目 中使用的XmlWebApplicationContext就属于这个继承体系，还有ClasspathXmlApplicationContext等，其继承体系如下图所示： ApplicationContext允许上下文嵌套，通过保持父上下文可以维持一个上下文体系。对于Bean的查找可以在这个上下文体系中发生，首先检查当前上下文，其次是父上下文，逐级向上，这样为不同的Spring应用提供了一个共享的Bean定义环境。 1、寻找入口&emsp;&emsp; 还有一个我们用的比较多的ClassPathXmlApplicationContext，通过main()方法启动: ApplicationContext app = new ClassPathXmlApplicationContext(\"application.xml\"); 先看其构造函数的调用： /** * Create a new ClassPathXmlApplicationContext, loading the definitions * from the given XML file and automatically refreshing the context. * @param configLocation resource location * @throws BeansException if context creation failed */ public ClassPathXmlApplicationContext(String configLocation) throws BeansException &amp;#123; this(new String[] &amp;#123;configLocation&amp;#125;, true, null); &amp;#125; 其实际调用的构造函数为： /** * Create a new ClassPathXmlApplicationContext with the given parent, * loading the definitions from the given XML files. * @param configLocations array of resource locations * @param refresh whether to automatically refresh the context, * loading all bean definitions and creating all singletons. * Alternatively, call refresh manually after further configuring the context. * @param parent the parent context * @throws BeansException if context creation failed * @see #refresh() */ public ClassPathXmlApplicationContext( String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException &amp;#123; super(parent); setConfigLocations(configLocations); if (refresh) &amp;#123; refresh(); &amp;#125; &amp;#125; 还 有 像 AnnotationConfigApplicationContext 、 FileSystemXmlApplicationContext 、XmlWebApplicationContext等都继承自父容器AbstractApplicationContext主要用到了装饰器模式和策略模式，最终都是调用refresh()方法。 2、获得配置路径&emsp;&emsp; 通 过 分 析 ClassPathXmlApplicationContext 的 源 代 码 可 以 知 道 ， 在 创 建ClassPathXmlApplicationContext容器时，构造方法做以下两项重要工作： 首先，调用父类容器的构造方法(super(parent)方法)为容器设置好Bean资源加载器。 然 后 ， 再 调 用 父 类 AbstractRefreshableConfigApplicationContext 的setConfigLocations(configLocations)方法设置Bean配置信息的定位路径。通 过 追 踪 ClassPathXmlApplicationContext 的 继 承 体 系 ， 发 现 其 父 类 的 父 类AbstractApplicationContext中初始化IOC容器所做的主要源码如下： public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &amp;#123; /** * Name of the MessageSource bean in the factory. * If none is supplied, message resolution is delegated to the parent. * @see MessageSource */ public static final String MESSAGE_SOURCE_BEAN_NAME = \"messageSource\"; /** * Name of the LifecycleProcessor bean in the factory. * If none is supplied, a DefaultLifecycleProcessor is used. * @see org.springframework.context.LifecycleProcessor * @see org.springframework.context.support.DefaultLifecycleProcessor */ public static final String LIFECYCLE_PROCESSOR_BEAN_NAME = \"lifecycleProcessor\"; /** * Name of the ApplicationEventMulticaster bean in the factory. * If none is supplied, a default SimpleApplicationEventMulticaster is used. * @see org.springframework.context.event.ApplicationEventMulticaster * @see org.springframework.context.event.SimpleApplicationEventMulticaster */ public static final String APPLICATION_EVENT_MULTICASTER_BEAN_NAME = \"applicationEventMulticaster\"; //静态初始化块，在整个容器创建过程中只执行一次 static &amp;#123; // Eagerly load the ContextClosedEvent class to avoid weird classloader issues // on application shutdown in WebLogic 8.1. (Reported by Dustin Woods.) //为了避免应用程序在Weblogic8.1关闭时出现类加载异常加载问题，加载IoC容 //器关闭事件(ContextClosedEvent)类 ContextClosedEvent.class.getName(); &amp;#125; /** * Create a new AbstractApplicationContext with no parent. */ public AbstractApplicationContext() &amp;#123; this.resourcePatternResolver = getResourcePatternResolver(); &amp;#125; /** * Create a new AbstractApplicationContext with the given parent context. * @param parent the parent context */ public AbstractApplicationContext(@Nullable ApplicationContext parent) &amp;#123; this(); setParent(parent); &amp;#125; /** * Return the ResourcePatternResolver to use for resolving location patterns * into Resource instances. Default is a * &amp;#123;@link org.springframework.core.io.support.PathMatchingResourcePatternResolver&amp;#125;, * supporting Ant-style location patterns. * &lt;p>Can be overridden in subclasses, for extended resolution strategies, * for example in a web environment. * &lt;p>&lt;b>Do not call this when needing to resolve a location pattern.&lt;/b> * Call the context's &amp;#123;@code getResources&amp;#125; method instead, which * will delegate to the ResourcePatternResolver. * @return the ResourcePatternResolver for this context * @see #getResources * @see org.springframework.core.io.support.PathMatchingResourcePatternResolver */ //获取一个Spring Source的加载器用于读入Spring Bean定义资源文件 protected ResourcePatternResolver getResourcePatternResolver() &amp;#123; //AbstractApplicationContext继承DefaultResourceLoader，因此也是一个资源加载器 //Spring资源加载器，其getResource(String location)方法用于载入资源 return new PathMatchingResourcePatternResolver(this); &amp;#125; AbstractApplicationContext 的默认构造方法中有调用 PathMatchingResourcePatternResolver 的构造方法创建Spring资源加载器： /** * Create a new PathMatchingResourcePatternResolver. * &lt;p>ClassLoader access will happen via the thread context class loader. * @param resourceLoader the ResourceLoader to load root directories and * actual resources with */ public PathMatchingResourcePatternResolver(ResourceLoader resourceLoader) &amp;#123; Assert.notNull(resourceLoader, \"ResourceLoader must not be null\"); //设置Spring的资源加载器 this.resourceLoader = resourceLoader; &amp;#125; 在设置容器的资源加载器之后，接下来 ClassPathXmlApplicationContext 执行setConfigLocations()方法通过调用其父类AbstractRefreshableConfigApplicationContext的方法进行对Bean配置信息的定位，该方法的源码如下： /** * Set the config locations for this application context in init-param style, * i.e. with distinct locations separated by commas, semicolons or whitespace. * &lt;p>If not set, the implementation may use a default as appropriate. */ //处理单个资源文件路径为一个字符串的情况 public void setConfigLocation(String location) &amp;#123; //String CONFIG_LOCATION_DELIMITERS = \",; /t/n\"; //即多个资源文件路径之间用” ,; \\t\\n”分隔，解析成数组形式 setConfigLocations(StringUtils.tokenizeToStringArray(location, CONFIG_LOCATION_DELIMITERS)); &amp;#125; /** * Set the config locations for this application context. * &lt;p>If not set, the implementation may use a default as appropriate. */ //解析Bean定义资源文件的路径，处理多个资源文件字符串数组 public void setConfigLocations(@Nullable String... locations) &amp;#123; if (locations != null) &amp;#123; Assert.noNullElements(locations, \"Config locations must not be null\"); this.configLocations = new String[locations.length]; for (int i = 0; i &lt; locations.length; i++) &amp;#123; // resolvePath为同一个类中将字符串解析为路径的方法 this.configLocations[i] = resolvePath(locations[i]).trim(); &amp;#125; &amp;#125; else &amp;#123; this.configLocations = null; &amp;#125; &amp;#125; 通过这两个方法的源码我们可以看出，我们既可以使用一个字符串来配置多个Spring Bean配置信息，也可以使用字符串数组，即下面两种方式都是可以的： ClassPathResource res = new ClassPathResource(\"a.xml,b.xml\"); 多个资源文件路径之间可以是用” , ; \\t\\n”等分隔。 ClassPathResource res =new ClassPathResource(new String[]&amp;#123;\"a.xml\",\"b.xml\"&amp;#125;); 至此，SpringIOC 容器在初始化时将配置的Bean配置信息定位为Spring封装的Resource。 3、开始启动&emsp;&emsp; SpringIOC 容器对 Bean配置资源的载入是从 refresh()函数开始的，refresh()是一个模板方法，规定了IOC 容器的启动流程，有些逻辑要交给其子类去实现。它对 Bean 配置资源进行载入ClassPathXmlApplicationContext 通过调用其父类 AbstractApplicationContext 的 refresh()函数启动整个IOC 容器对Bean定义的载入过程，现在我们来详细看看refresh()中的逻辑处理： @Override public void refresh() throws BeansException, IllegalStateException &amp;#123; synchronized (this.startupShutdownMonitor) &amp;#123; // Prepare this context for refreshing. //1、调用容器准备刷新的方法，获取容器的当时时间，同时给容器设置同步标识 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. //2、告诉子类启动refreshBeanFactory()方法，Bean定义资源文件的载入从 //子类的refreshBeanFactory()方法启动 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. //3、为BeanFactory配置容器特性，例如类加载器、事件处理器等 prepareBeanFactory(beanFactory); try &amp;#123; // Allows post-processing of the bean factory in context subclasses. //4、为容器的某些子类指定特殊的BeanPost事件处理器 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. //5、调用所有注册的BeanFactoryPostProcessor的Bean invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. //6、为BeanFactory注册BeanPost事件处理器. //BeanPostProcessor是Bean后置处理器，用于监听容器触发的事件 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. //7、初始化信息源，和国际化相关. initMessageSource(); // Initialize event multicaster for this context. //8、初始化容器事件传播器. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. //9、调用子类的某些特殊Bean初始化方法 onRefresh(); // Check for listener beans and register them. //10、为事件传播器注册事件监听器. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. //11、初始化所有剩余的单例Bean finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. //12、初始化容器的生命周期事件处理器，并发布容器的生命周期事件 finishRefresh(); &amp;#125; catch (BeansException ex) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &amp;#125; // Destroy already created singletons to avoid dangling resources. //13、销毁已创建的Bean destroyBeans(); // Reset 'active' flag. //14、取消refresh操作，重置容器的同步标识。 cancelRefresh(ex); // Propagate exception to caller. throw ex; &amp;#125; finally &amp;#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... //15、重设公共缓存 resetCommonCaches(); &amp;#125; &amp;#125; &amp;#125; refresh()方法主要为 IOC 容器 Bean 的生命周期管理提供条件，Spring IOC 容器载入 Bean 配置信息从 其 子 类 容 器 的 refreshBeanFactory() 方 法 启 动 ， 所 以 整 个 refresh() 中“ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();”这句以后代码的都是注册容器的信息源和生命周期事件，我们前面说的载入就是从这句代码开始启动。 refresh()方法的主要作用是：在创建 IOC 容器前，如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的 IOC容器。它类似于对IOC 容器的重启，在新建立好的容器中对容器进行初始化，对Bean配置资源进行载入。 4、创建容器obtainFreshBeanFactory()方法调用子类容器的 refreshBeanFactory()方法，启动容器载入Bean配置信息的过程，代码如下： /** * Tell the subclass to refresh the internal bean factory. * @return the fresh BeanFactory instance * @see #refreshBeanFactory() * @see #getBeanFactory() */ protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &amp;#123; //这里使用了委派设计模式，父类定义了抽象的refreshBeanFactory()方法，具体实现调用子类容器的refreshBeanFactory()方法 refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Bean factory for \" + getDisplayName() + \": \" + beanFactory); &amp;#125; return beanFactory; &amp;#125; AbstractApplicationContext 类中只抽象定义了 refreshBeanFactory()方法，容器真正调用的是 其子类 AbstractRefreshableApplicationContext 实现的 refreshBeanFactory()方法，方法的源 码如下： /** * This implementation performs an actual refresh of this context's underlying * bean factory, shutting down the previous bean factory (if any) and * initializing a fresh bean factory for the next phase of the context's lifecycle. */ @Override protected final void refreshBeanFactory() throws BeansException &amp;#123; //如果已经有容器，销毁容器中的bean，关闭容器 if (hasBeanFactory()) &amp;#123; destroyBeans(); closeBeanFactory(); &amp;#125; try &amp;#123; //创建IOC容器 DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); //对IOC容器进行定制化，如设置启动参数，开启注解的自动装配等 customizeBeanFactory(beanFactory); //调用载入Bean定义的方法，主要这里又使用了一个委派模式，在当前类中只定义了抽象的loadBeanDefinitions方法，具体的实现调用子类容器 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &amp;#123; this.beanFactory = beanFactory; &amp;#125; &amp;#125; catch (IOException ex) &amp;#123; throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + getDisplayName(), ex); &amp;#125; &amp;#125; 在这个方法中，先判断 BeanFactory 是否存在，如果存在则先销毁 beans并关闭beanFactory，接着创建DefaultListableBeanFactory，并调用loadBeanDefinitions(beanFactory)装载bean定义。 5、载入配置路径AbstractRefreshableApplicationContext 中只定义了抽象的 loadBeanDefinitions 方法，容器真正调用的是其子类 AbstractXmlApplicationContext 对该方法的实现，AbstractXmlApplicationContext的主要源码如下： loadBeanDefinitions() 方 法 同 样 是 抽 象 方 法 ， 是 由 其 子 类 实 现 的 ， 也 即 在AbstractXmlApplicationContext中。 /** * Loads the bean definitions via an XmlBeanDefinitionReader. * @see org.springframework.beans.factory.xml.XmlBeanDefinitionReader * @see #initBeanDefinitionReader * @see #loadBeanDefinitions */ //实现父类抽象的载入Bean定义方法 @Override protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &amp;#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. //创建XmlBeanDefinitionReader，即创建Bean读取器，并通过回调设置到容器中去，容 器使用该读取器读取Bean定义资源 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. //为Bean读取器设置Spring资源加载器，AbstractXmlApplicationContext的 //祖先父类AbstractApplicationContext继承DefaultResourceLoader，因此，容器本身也是一个资源加载器 beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); //为Bean读取器设置SAX xml解析器 beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. //当Bean读取器读取Bean定义的Xml资源文件时，启用Xml的校验机制 initBeanDefinitionReader(beanDefinitionReader); //Bean读取器真正实现加载的方法 loadBeanDefinitions(beanDefinitionReader); &amp;#125; /** * Initialize the bean definition reader used for loading the bean * definitions of this context. Default implementation is empty. * &lt;p>Can be overridden in subclasses, e.g. for turning off XML validation * or using a different XmlBeanDefinitionParser implementation. * @param reader the bean definition reader used by this context * @see org.springframework.beans.factory.xml.XmlBeanDefinitionReader#setDocumentReaderClass */ protected void initBeanDefinitionReader(XmlBeanDefinitionReader reader) &amp;#123; reader.setValidating(this.validating); &amp;#125; /** * Load the bean definitions with the given XmlBeanDefinitionReader. * &lt;p>The lifecycle of the bean factory is handled by the &amp;#123;@link #refreshBeanFactory&amp;#125; * method; hence this method is just supposed to load and/or register bean definitions. * @param reader the XmlBeanDefinitionReader to use * @throws BeansException in case of bean registration errors * @throws IOException if the required XML document isn't found * @see #refreshBeanFactory * @see #getConfigLocations * @see #getResources * @see #getResourcePatternResolver */ //Xml Bean读取器加载Bean定义资源 protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &amp;#123; //获取Bean定义资源的定位 Resource[] configResources = getConfigResources(); if (configResources != null) &amp;#123; //Xml Bean读取器调用其父类AbstractBeanDefinitionReader读取定位 //的Bean定义资源 reader.loadBeanDefinitions(configResources); &amp;#125; //如果子类中获取的Bean定义资源定位为空，则获取FileSystemXmlApplicationContext构造方法中setConfigLocations方法设置的资源 String[] configLocations = getConfigLocations(); if (configLocations != null) &amp;#123; //Xml Bean读取器调用其父类AbstractBeanDefinitionReader读取定位 //的Bean定义资源 reader.loadBeanDefinitions(configLocations); &amp;#125; &amp;#125; /** * Return an array of Resource objects, referring to the XML bean definition * files that this context should be built with. * &lt;p>The default implementation returns &amp;#123;@code null&amp;#125;. Subclasses can override * this to provide pre-built Resource objects rather than location Strings. * @return an array of Resource objects, or &amp;#123;@code null&amp;#125; if none * @see #getConfigLocations() */ //这里又使用了一个委托模式，调用子类的获取Bean定义资源定位的方法 //该方法在ClassPathXmlApplicationContext中进行实现，对于我们 //举例分析源码的FileSystemXmlApplicationContext没有使用该方法 @Nullable protected Resource[] getConfigResources() &amp;#123; return null; &amp;#125; 以 XmlBean 读取器的其中一种策略 XmlBeanDefinitionReader 为例。XmlBeanDefinitionReader调用其父类AbstractBeanDefinitionReader的 reader.loadBeanDefinitions()方法读取Bean配置资源。由于我们使用ClassPathXmlApplicationContext 作为例子分析，因此getConfigResources 的返回值为null，因此程序执行reader.loadBeanDefinitions(configLocations)分支。 6、分配路径处理策略在XmlBeanDefinitionReader的抽象父类AbstractBeanDefinitionReader中定义了载入过程。 AbstractBeanDefinitionReader的loadBeanDefinitions()方法源码如下： //重载方法，调用下面的loadBeanDefinitions(String, Set&lt;Resource>);方法 @Override public int loadBeanDefinitions(String location) throws BeanDefinitionStoreException &amp;#123; return loadBeanDefinitions(location, null); &amp;#125; /** * Load bean definitions from the specified resource location. * &lt;p>The location can also be a location pattern, provided that the * ResourceLoader of this bean definition reader is a ResourcePatternResolver. * @param location the resource location, to be loaded with the ResourceLoader * (or ResourcePatternResolver) of this bean definition reader * @param actualResources a Set to be filled with the actual Resource objects * that have been resolved during the loading process. May be &amp;#123;@code null&amp;#125; * to indicate that the caller is not interested in those Resource objects. * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #getResourceLoader() * @see #loadBeanDefinitions(org.springframework.core.io.Resource) * @see #loadBeanDefinitions(org.springframework.core.io.Resource[]) */ public int loadBeanDefinitions(String location, @Nullable Set&lt;Resource> actualResources) throws BeanDefinitionStoreException &amp;#123; //获取在IoC容器初始化过程中设置的资源加载器 ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &amp;#123; throw new BeanDefinitionStoreException( \"Cannot import bean definitions from location [\" + location + \"]: no ResourceLoader available\"); &amp;#125; if (resourceLoader instanceof ResourcePatternResolver) &amp;#123; // Resource pattern matching available. try &amp;#123; //将指定位置的Bean定义资源文件解析为Spring IOC容器封装的资源 //加载多个指定位置的Bean定义资源文件 Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); //委派调用其子类XmlBeanDefinitionReader的方法，实现加载功能 int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &amp;#123; for (Resource resource : resources) &amp;#123; actualResources.add(resource); &amp;#125; &amp;#125; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location pattern [\" + location + \"]\"); &amp;#125; return loadCount; &amp;#125; catch (IOException ex) &amp;#123; throw new BeanDefinitionStoreException( \"Could not resolve bean definition resource pattern [\" + location + \"]\", ex); &amp;#125; &amp;#125; else &amp;#123; // Can only load single resources by absolute URL. //将指定位置的Bean定义资源文件解析为Spring IOC容器封装的资源 //加载单个指定位置的Bean定义资源文件 Resource resource = resourceLoader.getResource(location); //委派调用其子类XmlBeanDefinitionReader的方法，实现加载功能 int loadCount = loadBeanDefinitions(resource); if (actualResources != null) &amp;#123; actualResources.add(resource); &amp;#125; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location [\" + location + \"]\"); &amp;#125; return loadCount; &amp;#125; &amp;#125; //重载方法，调用loadBeanDefinitions(String); @Override public int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &amp;#123; Assert.notNull(locations, \"Location array must not be null\"); int counter = 0; for (String location : locations) &amp;#123; counter += loadBeanDefinitions(location); &amp;#125; return counter; &amp;#125; &emsp;&emsp; AbstractRefreshableConfigApplicationContext 的 loadBeanDefinitions(Resource…resources)方法实际上是调用AbstractBeanDefinitionReader的loadBeanDefinitions()方法。从对 AbstractBeanDefinitionReader 的 loadBeanDefinitions()方法源码分析可以看出该方法就做了两件事： 首先，调用资源加载器的获取资源方法resourceLoader.getResource(location)，获取到要加载的资源。 其次，真正执行加载功能是其子类 XmlBeanDefinitionReader 的 loadBeanDefinitions()方法。在loadBeanDefinitions()方法中调用了 AbstractApplicationContext的 getResources()方法，跟进去之后发现 getResources()方法其实定义在 ResourcePatternResolver 中，此时，我们有必要来看一下ResourcePatternResolver的全类图： 从上面可以看到 ResourceLoader 与 ApplicationContext 的继承关系，可以看出其实际调用的是DefaultResourceLoader 中 的 getSource() 方 法 定 位 Resource ， 因 为ClassPathXmlApplicationContext 本身就是 DefaultResourceLoader 的实现类，所以此时又回到了ClassPathXmlApplicationContext中来。 7、解析配置文件路径XmlBeanDefinitionReader 通 过 调 用 ClassPathXmlApplicationContext 的 父 类DefaultResourceLoader的getResource()方法获取要加载的资源，其源码如下 //获取Resource的具体实现方法 @Override public Resource getResource(String location) &amp;#123; Assert.notNull(location, \"Location must not be null\"); for (ProtocolResolver protocolResolver : this.protocolResolvers) &amp;#123; Resource resource = protocolResolver.resolve(location, this); if (resource != null) &amp;#123; return resource; &amp;#125; &amp;#125; //如果是类路径的方式，那需要使用ClassPathResource 来得到bean 文件的资源对象 if (location.startsWith(\"/\")) &amp;#123; return getResourceByPath(location); &amp;#125; else if (location.startsWith(CLASSPATH_URL_PREFIX)) &amp;#123; return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader()); &amp;#125; else &amp;#123; try &amp;#123; // Try to parse the location as a URL... // 如果是URL 方式，使用UrlResource 作为bean 文件的资源对象 URL url = new URL(location); return (ResourceUtils.isFileURL(url) ? new FileUrlResource(url) : new UrlResource(url)); &amp;#125; catch (MalformedURLException ex) &amp;#123; // No URL -> resolve as resource path. //如果既不是classpath标识，又不是URL标识的Resource定位，则调用 //容器本身的getResourceByPath方法获取Resource return getResourceByPath(location); &amp;#125; &amp;#125; &amp;#125; DefaultResourceLoader 提供了 getResourceByPath()方法的实现，就是为了处理既不是 classpath标识，又不是URL标识的Resource定位这种情况。 /** * Return a Resource handle for the resource at the given path. * &lt;p>The default implementation supports class path locations. This should * be appropriate for standalone implementations but can be overridden, * e.g. for implementations targeted at a Servlet container. * @param path the path to the resource * @return the corresponding Resource handle * @see ClassPathResource * @see org.springframework.context.support.FileSystemXmlApplicationContext#getResourceByPath * @see org.springframework.web.context.support.XmlWebApplicationContext#getResourceByPath */ protected Resource getResourceByPath(String path) &amp;#123; return new ClassPathContextResource(path, getClassLoader()); &amp;#125; 在 ClassPathResource中完成了对整个路径的解析。这样，就可以从类路径上对 IOC 配置文件进行加载，当然我们可以按照这个逻辑从任何地方加载，在 Spring中我们看到它提供的各种资源抽象，比如ClassPathResource、URLResource、FileSystemResource等来供我们使用。上面我们看到的是定位 Resource 的一个过程，而这只是加载过程的一部分。例如 FileSystemXmlApplication 容器就重写了getResourceByPath()方法： @Override protected Resource getResourceByPath(String path) &amp;#123; if (path.startsWith(\"/\")) &amp;#123; path = path.substring(1); &amp;#125; return new FileSystemContextResource(path); &amp;#125; 通过子类的覆盖，巧妙地完成了将类路径变为文件路径的转换。 8、开始读取配置内容继续回到 XmlBeanDefinitionReader 的 loadBeanDefinitions(Resource …)方法看到代表 bean 文件的资源定义以后的载入过程。 /** * Load bean definitions from the specified XML file. * @param resource the resource descriptor for the XML file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */ //XmlBeanDefinitionReader加载资源的入口方法 @Override public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &amp;#123; //将读入的XML资源进行特殊编码处理 return loadBeanDefinitions(new EncodedResource(resource)); &amp;#125; /** * Load bean definitions from the specified XML file. * @param encodedResource the resource descriptor for the XML file, * allowing to specify an encoding to use for parsing the file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */ //这里是载入XML形式Bean定义资源文件方法 public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &amp;#123; Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Loading XML bean definitions from \" + encodedResource.getResource()); &amp;#125; Set&lt;EncodedResource> currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &amp;#123; currentResources = new HashSet&lt;>(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &amp;#125; if (!currentResources.add(encodedResource)) &amp;#123; throw new BeanDefinitionStoreException( \"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); &amp;#125; try &amp;#123; //将资源文件转为InputStream的IO流 InputStream inputStream = encodedResource.getResource().getInputStream(); try &amp;#123; //从InputStream中得到XML的解析源 InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &amp;#123; inputSource.setEncoding(encodedResource.getEncoding()); &amp;#125; //这里是具体的读取过程 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &amp;#125; finally &amp;#123; //关闭从Resource中得到的IO流 inputStream.close(); &amp;#125; &amp;#125; catch (IOException ex) &amp;#123; throw new BeanDefinitionStoreException( \"IOException parsing XML document from \" + encodedResource.getResource(), ex); &amp;#125; finally &amp;#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &amp;#123; this.resourcesCurrentlyBeingLoaded.remove(); &amp;#125; &amp;#125; &amp;#125; /** * Actually load bean definitions from the specified XML file. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #doLoadDocument * @see #registerBeanDefinitions */ //从特定XML文件中实际载入Bean定义资源的方法 protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &amp;#123; try &amp;#123; //将XML文件转换为DOM对象，解析过程由documentLoader实现 Document doc = doLoadDocument(inputSource, resource); //这里是启动对Bean定义解析的详细过程，该解析过程会用到Spring的Bean配置规则 return registerBeanDefinitions(doc, resource); &amp;#125; catch (BeanDefinitionStoreException ex) &amp;#123; throw ex; &amp;#125; catch (SAXParseException ex) &amp;#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); &amp;#125; catch (SAXException ex) &amp;#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); &amp;#125; catch (ParserConfigurationException ex) &amp;#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); &amp;#125; catch (IOException ex) &amp;#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); &amp;#125; &amp;#125; 通过源码分析，载入 Bean配置信息的最后一步是将Bean配置信息转换为Document对象，该过程由documentLoader()方法实现。 9、准备文档对象DocumentLoader将Bean配置资源转换成Document对象的源码如下： /** * Load the &amp;#123;@link Document&amp;#125; at the supplied &amp;#123;@link InputSource&amp;#125; using the standard JAXP-configured * XML parser. */ //使用标准的JAXP将载入的Bean定义资源转换成document对象 @Override public Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception &amp;#123; //创建文件解析器工厂 DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Using JAXP provider [\" + factory.getClass().getName() + \"]\"); &amp;#125; //创建文档解析器 DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); //解析Spring的Bean定义资源 return builder.parse(inputSource); &amp;#125; /** * Create the &amp;#123;@link DocumentBuilderFactory&amp;#125; instance. * @param validationMode the type of validation: &amp;#123;@link XmlValidationModeDetector#VALIDATION_DTD DTD&amp;#125; * or &amp;#123;@link XmlValidationModeDetector#VALIDATION_XSD XSD&amp;#125;) * @param namespaceAware whether the returned factory is to provide support for XML namespaces * @return the JAXP DocumentBuilderFactory * @throws ParserConfigurationException if we failed to build a proper DocumentBuilderFactory */ protected DocumentBuilderFactory createDocumentBuilderFactory(int validationMode, boolean namespaceAware) throws ParserConfigurationException &amp;#123; //创建文档解析工厂 DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setNamespaceAware(namespaceAware); //设置解析XML的校验 if (validationMode != XmlValidationModeDetector.VALIDATION_NONE) &amp;#123; factory.setValidating(true); if (validationMode == XmlValidationModeDetector.VALIDATION_XSD) &amp;#123; // Enforce namespace aware for XSD... factory.setNamespaceAware(true); try &amp;#123; factory.setAttribute(SCHEMA_LANGUAGE_ATTRIBUTE, XSD_SCHEMA_LANGUAGE); &amp;#125; catch (IllegalArgumentException ex) &amp;#123; ParserConfigurationException pcex = new ParserConfigurationException( \"Unable to validate using XSD: Your JAXP provider [\" + factory + \"] does not support XML Schema. Are you running on Java 1.4 with Apache Crimson? \" + \"Upgrade to Apache Xerces (or Java 1.5) for full XSD support.\"); pcex.initCause(ex); throw pcex; &amp;#125; &amp;#125; &amp;#125; return factory; &amp;#125; 上面的解析过程是调用 JavaEE 标准的 JAXP 标准进行处理。至此 SpringIOC 容器根据定位的 Bean 配 置信息，将其加载读入并转换成为 Document 对象过程完成。接下来我们要继续分析 Spring IOC 容器 将载入的 Bean 配置信息转换为 Document 对象之后，是如何将其解析为 SpringIOC 管理的 Bean 对象 并将其注册到容器中的。 10、分配解析策略 XmlBeanDefinitionReader 类中的 doLoadBeanDefinition()方法是从特定 XML 文件中实际载入 Bean 配置资源的方法，该方法在载入 Bean 配置资源之后将其转换为 Document 对象，接下来调用 registerBeanDefinitions() 启 动 Spring IOC 容 器 对 Bean 定 义 的 解 析 过 程 ， registerBeanDefinitions()方法源码如下： //按照Spring的Bean语义要求将Bean定义资源解析并转换为容器内部数据结构 public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &amp;#123; //得到BeanDefinitionDocumentReader来对xml格式的BeanDefinition解析 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); //获得容器中注册的Bean数量 int countBefore = getRegistry().getBeanDefinitionCount(); //解析过程入口，这里使用了委派模式，BeanDefinitionDocumentReader只是个接口, //具体的解析实现过程有实现类DefaultBeanDefinitionDocumentReader完成 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); //统计解析的Bean数量 return getRegistry().getBeanDefinitionCount() - countBefore; &amp;#125; } Bean配置资源的载入解析分为以下两个过程：首先，通过调用 XML解析器将 Bean 配置信息转换得到 Document对象，但是这些 Document对象并没有按照Spring的Bean规则进行解析。这一步是载入的过程其次，在完成通用的 XML解析之后，按照 Spring Bean 的定义规则对 Document 对象进行解析，其解 析 过 程 是 在 接 口 BeanDefinitionDocumentReader 的 实 现 类DefaultBeanDefinitionDocumentReader中实现。 11、将配置载入内存BeanDefinitionDocumentReader 接 口 通 过 registerBeanDefinitions() 方 法 调 用 其 实 现 类DefaultBeanDefinitionDocumentReader对Document对象进行解析，解析的代码如下： @Override public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &amp;#123; //获得XML描述符 this.readerContext = readerContext; logger.debug(\"Loading bean definitions\"); //获得Document的根元素 Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root); &amp;#125; /** * Register each bean definition within the given root &amp;#123;@code &lt;beans/>&amp;#125; element. */ protected void doRegisterBeanDefinitions(Element root) &amp;#123; // Any nested &lt;beans> elements will cause recursion in this method. In // order to propagate and preserve &lt;beans> default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. //具体的解析过程由BeanDefinitionParserDelegate实现， //BeanDefinitionParserDelegate中定义了Spring Bean定义XML文件的各种元素 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &amp;#123; String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &amp;#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &amp;#123; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec + \"] not matching: \" + getReaderContext().getResource()); &amp;#125; return; &amp;#125; &amp;#125; &amp;#125; //在解析Bean定义之前，进行自定义的解析，增强解析过程的可扩展性 preProcessXml(root); //从Document的根元素开始进行Bean定义的Document对象 parseBeanDefinitions(root, this.delegate); //在解析Bean定义之后，进行自定义的解析，增加解析过程的可扩展性 postProcessXml(root); this.delegate = parent; &amp;#125; //创建BeanDefinitionParserDelegate，用于完成真正的解析过程 protected BeanDefinitionParserDelegate createDelegate( XmlReaderContext readerContext, Element root, @Nullable BeanDefinitionParserDelegate parentDelegate) &amp;#123; BeanDefinitionParserDelegate delegate = new BeanDefinitionParserDelegate(readerContext); //BeanDefinitionParserDelegate初始化Document根元素 delegate.initDefaults(root, parentDelegate); return delegate; &amp;#125; /** * Parse the elements at the root level in the document: * \"import\", \"alias\", \"bean\". * @param root the DOM root element of the document */ //使用Spring的Bean规则从Document的根元素开始进行Bean定义的Document对象 protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &amp;#123; //Bean定义的Document对象使用了Spring默认的XML命名空间 if (delegate.isDefaultNamespace(root)) &amp;#123; //获取Bean定义的Document对象根元素的所有子节点 NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &amp;#123; Node node = nl.item(i); //获得Document节点是XML元素节点 if (node instanceof Element) &amp;#123; Element ele = (Element) node; //Bean定义的Document的元素节点使用的是Spring默认的XML命名空间 if (delegate.isDefaultNamespace(ele)) &amp;#123; //使用Spring的Bean规则解析元素节点 parseDefaultElement(ele, delegate); &amp;#125; else &amp;#123; //没有使用Spring默认的XML命名空间，则使用用户自定义的解//析规则解析元素节点 delegate.parseCustomElement(ele); &amp;#125; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; //Document的根节点没有使用Spring默认的命名空间，则使用用户自定义的 //解析规则解析Document根节点 delegate.parseCustomElement(root); &amp;#125; &amp;#125; //使用Spring的Bean规则解析Document元素节点 private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &amp;#123; //如果元素节点是&lt;Import>导入元素，进行导入解析 if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &amp;#123; importBeanDefinitionResource(ele); &amp;#125; //如果元素节点是&lt;Alias>别名元素，进行别名解析 else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &amp;#123; processAliasRegistration(ele); &amp;#125; //元素节点既不是导入元素，也不是别名元素，即普通的&lt;Bean>元素， //按照Spring的Bean规则解析元素 else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &amp;#123; processBeanDefinition(ele, delegate); &amp;#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &amp;#123; // recurse doRegisterBeanDefinitions(ele); &amp;#125; &amp;#125; /** * Parse an \"import\" element and load the bean definitions * from the given resource into the bean factory. */ //解析&lt;Import>导入元素，从给定的导入路径加载Bean定义资源到Spring IoC容器中 protected void importBeanDefinitionResource(Element ele) &amp;#123; //获取给定的导入元素的location属性 String location = ele.getAttribute(RESOURCE_ATTRIBUTE); //如果导入元素的location属性值为空，则没有导入任何资源，直接返回 if (!StringUtils.hasText(location)) &amp;#123; getReaderContext().error(\"Resource location must not be empty\", ele); return; &amp;#125; // Resolve system properties: e.g. \"$&amp;#123;user.dir&amp;#125;\" //使用系统变量值解析location属性值 location = getReaderContext().getEnvironment().resolveRequiredPlaceholders(location); Set&lt;Resource> actualResources = new LinkedHashSet&lt;>(4); // Discover whether the location is an absolute or relative URI //标识给定的导入元素的location是否是绝对路径 boolean absoluteLocation = false; try &amp;#123; absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); &amp;#125; catch (URISyntaxException ex) &amp;#123; // cannot convert to an URI, considering the location relative // unless it is the well-known Spring prefix \"classpath*:\" //给定的导入元素的location不是绝对路径 &amp;#125; // Absolute or relative? //给定的导入元素的location是绝对路径 if (absoluteLocation) &amp;#123; try &amp;#123; //使用资源读入器加载给定路径的Bean定义资源 int importCount = getReaderContext().getReader().loadBeanDefinitions(location, actualResources); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Imported \" + importCount + \" bean definitions from URL location [\" + location + \"]\"); &amp;#125; &amp;#125; catch (BeanDefinitionStoreException ex) &amp;#123; getReaderContext().error( \"Failed to import bean definitions from URL location [\" + location + \"]\", ele, ex); &amp;#125; &amp;#125; else &amp;#123; // No URL -> considering resource location as relative to the current file. //给定的导入元素的location是相对路径 try &amp;#123; int importCount; //将给定导入元素的location封装为相对路径资源 Resource relativeResource = getReaderContext().getResource().createRelative(location); //封装的相对路径资源存在 if (relativeResource.exists()) &amp;#123; //使用资源读入器加载Bean定义资源 importCount = getReaderContext().getReader().loadBeanDefinitions(relativeResource); actualResources.add(relativeResource); &amp;#125; //封装的相对路径资源不存在 else &amp;#123; //获取Spring IOC容器资源读入器的基本路径 String baseLocation = getReaderContext().getResource().getURL().toString(); //根据Spring IOC容器资源读入器的基本路径加载给定导入路径的资源 importCount = getReaderContext().getReader().loadBeanDefinitions( StringUtils.applyRelativePath(baseLocation, location), actualResources); &amp;#125; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Imported \" + importCount + \" bean definitions from relative location [\" + location + \"]\"); &amp;#125; &amp;#125; catch (IOException ex) &amp;#123; getReaderContext().error(\"Failed to resolve current resource location\", ele, ex); &amp;#125; catch (BeanDefinitionStoreException ex) &amp;#123; getReaderContext().error(\"Failed to import bean definitions from relative location [\" + location + \"]\", ele, ex); &amp;#125; &amp;#125; Resource[] actResArray = actualResources.toArray(new Resource[actualResources.size()]); //在解析完&lt;Import>元素之后，发送容器导入其他资源处理完成事件 getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele)); &amp;#125; /** * Process the given alias element, registering the alias with the registry. */ //解析&lt;Alias>别名元素，为Bean向Spring IoC容器注册别名 protected void processAliasRegistration(Element ele) &amp;#123; //获取&lt;Alias>别名元素中name的属性值 String name = ele.getAttribute(NAME_ATTRIBUTE); //获取&lt;Alias>别名元素中alias的属性值 String alias = ele.getAttribute(ALIAS_ATTRIBUTE); boolean valid = true; //&lt;alias>别名元素的name属性值为空 if (!StringUtils.hasText(name)) &amp;#123; getReaderContext().error(\"Name must not be empty\", ele); valid = false; &amp;#125; //&lt;alias>别名元素的alias属性值为空 if (!StringUtils.hasText(alias)) &amp;#123; getReaderContext().error(\"Alias must not be empty\", ele); valid = false; &amp;#125; if (valid) &amp;#123; try &amp;#123; //向容器的资源读入器注册别名 getReaderContext().getRegistry().registerAlias(name, alias); &amp;#125; catch (Exception ex) &amp;#123; getReaderContext().error(\"Failed to register alias '\" + alias + \"' for bean with name '\" + name + \"'\", ele, ex); &amp;#125; //在解析完&lt;Alias>元素之后，发送容器别名处理完成事件 getReaderContext().fireAliasRegistered(name, alias, extractSource(ele)); &amp;#125; &amp;#125; /** * Process the given bean element, parsing the bean definition * and registering it with the registry. */ //解析Bean定义资源Document对象的普通元素 protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &amp;#123; BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); // BeanDefinitionHolder是对BeanDefinition的封装，即Bean定义的封装类 //对Document对象中&lt;Bean>元素的解析由BeanDefinitionParserDelegate实现 // BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &amp;#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &amp;#123; // Register the final decorated instance. //向Spring IOC容器注册解析得到的Bean定义，这是Bean定义向IOC容器注册的入口 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &amp;#125; catch (BeanDefinitionStoreException ex) &amp;#123; getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); &amp;#125; // Send registration event. //在完成向Spring IOC容器注册解析得到的Bean定义之后，发送注册事件 getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &amp;#125; &amp;#125; 通过上述 Spring IOC 容器对载入的 Bean 定义 Document 解析可以看出，我们使用 Spring 时，在Spring配置文件中可以使用元素来导入 IOC 容器所需要的其他资源，Spring IOC 容器在解析时会首先将指定导入的资源加载进容器中。使用别名时，SpringIOC 容器首先将别名元素所定义的别名注册到容器中。 对于既不是元素，又不是元素的元素，即 Spring配置文件中普通的元素的解析由BeanDefinitionParserDelegate 类的parseBeanDefinitionElement()方法来实现。这个解析的过程非常复杂，我们在mini版本的时候，就用properties文件代替了。 12、载入元素Bean 配置信息中的和元素解析在 DefaultBeanDefinitionDocumentReader 中已经完成，对 Bean 配置信息中使用最多的元素交由 BeanDefinitionParserDelegate 来解析，其解析实现的源码如下： /** * Parses the supplied &amp;#123;@code &lt;bean>&amp;#125; element. May return &amp;#123;@code null&amp;#125; * if there were errors during parse. Errors are reported to the * &amp;#123;@link org.springframework.beans.factory.parsing.ProblemReporter&amp;#125;. */ //解析&lt;Bean>元素的入口 @Nullable public BeanDefinitionHolder parseBeanDefinitionElement(Element ele) &amp;#123; return parseBeanDefinitionElement(ele, null); &amp;#125; /** * Parses the supplied &amp;#123;@code &lt;bean>&amp;#125; element. May return &amp;#123;@code null&amp;#125; * if there were errors during parse. Errors are reported to the * &amp;#123;@link org.springframework.beans.factory.parsing.ProblemReporter&amp;#125;. */ //解析Bean定义资源文件中的&lt;Bean>元素，这个方法中主要处理&lt;Bean>元素的id，name和别名属性 @Nullable public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, @Nullable BeanDefinition containingBean) &amp;#123; //获取&lt;Bean>元素中的id属性值 String id = ele.getAttribute(ID_ATTRIBUTE); //获取&lt;Bean>元素中的name属性值 String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); //获取&lt;Bean>元素中的alias属性值 List&lt;String> aliases = new ArrayList&lt;>(); //将&lt;Bean>元素中的所有name属性值存放到别名中 if (StringUtils.hasLength(nameAttr)) &amp;#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &amp;#125; String beanName = id; //如果&lt;Bean>元素中没有配置id属性时，将别名中的第一个值赋值给beanName if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &amp;#123; beanName = aliases.remove(0); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"No XML 'id' specified - using '\" + beanName + \"' as bean name and \" + aliases + \" as aliases\"); &amp;#125; &amp;#125; //检查&lt;Bean>元素所配置的id或者name的唯一性，containingBean标识&lt;Bean> //元素中是否包含子&lt;Bean>元素 if (containingBean == null) &amp;#123; //检查&lt;Bean>元素所配置的id、name或者别名是否重复 checkNameUniqueness(beanName, aliases, ele); &amp;#125; //详细对&lt;Bean>元素中配置的Bean定义进行解析的地方 AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); if (beanDefinition != null) &amp;#123; if (!StringUtils.hasText(beanName)) &amp;#123; try &amp;#123; if (containingBean != null) &amp;#123; //如果&lt;Bean>元素中没有配置id、别名或者name，且没有包含子元素 //&lt;Bean>元素，为解析的Bean生成一个唯一beanName并注册 beanName = BeanDefinitionReaderUtils.generateBeanName( beanDefinition, this.readerContext.getRegistry(), true); &amp;#125; else &amp;#123; //如果&lt;Bean>元素中没有配置id、别名或者name，且包含了子元素 //&lt;Bean>元素，为解析的Bean使用别名向IOC容器注册 beanName = this.readerContext.generateBeanName(beanDefinition); // Register an alias for the plain bean class name, if still possible, // if the generator returned the class name plus a suffix. // This is expected for Spring 1.2/2.0 backwards compatibility. //为解析的Bean使用别名注册时，为了向后兼容 //Spring1.2/2.0，给别名添加类名后缀 String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() > beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &amp;#123; aliases.add(beanClassName); &amp;#125; &amp;#125; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Neither XML 'id' nor 'name' specified - \" + \"using generated bean name [\" + beanName + \"]\"); &amp;#125; &amp;#125; catch (Exception ex) &amp;#123; error(ex.getMessage(), ele); return null; &amp;#125; &amp;#125; String[] aliasesArray = StringUtils.toStringArray(aliases); return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &amp;#125; //当解析出错时，返回null return null; &amp;#125; /** * Validate that the specified bean name and aliases have not been used already * within the current level of beans element nesting. */ protected void checkNameUniqueness(String beanName, List&lt;String> aliases, Element beanElement) &amp;#123; String foundName = null; if (StringUtils.hasText(beanName) &amp;&amp; this.usedNames.contains(beanName)) &amp;#123; foundName = beanName; &amp;#125; if (foundName == null) &amp;#123; foundName = CollectionUtils.findFirstMatch(this.usedNames, aliases); &amp;#125; if (foundName != null) &amp;#123; error(\"Bean name '\" + foundName + \"' is already used in this &lt;beans> element\", beanElement); &amp;#125; this.usedNames.add(beanName); this.usedNames.addAll(aliases); &amp;#125; /** * Parse the bean definition itself, without regard to name or aliases. May return * &amp;#123;@code null&amp;#125; if problems occurred during the parsing of the bean definition. */ //详细对&lt;Bean>元素中配置的Bean定义其他属性进行解析 //由于上面的方法中已经对Bean的id、name和别名等属性进行了处理 //该方法中主要处理除这三个以外的其他属性数据 @Nullable public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, @Nullable BeanDefinition containingBean) &amp;#123; //记录解析的&lt;Bean> this.parseState.push(new BeanEntry(beanName)); //这里只读取&lt;Bean>元素中配置的class名字，然后载入到BeanDefinition中去 //只是记录配置的class名字，不做实例化，对象的实例化在依赖注入时完成 String className = null; //如果&lt;Bean>元素中配置了parent属性，则获取parent属性的值 if (ele.hasAttribute(CLASS_ATTRIBUTE)) &amp;#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &amp;#125; String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &amp;#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &amp;#125; try &amp;#123; //根据&lt;Bean>元素配置的class名称和parent属性值创建BeanDefinition //为载入Bean定义信息做准备 AbstractBeanDefinition bd = createBeanDefinition(className, parent); //对当前的&lt;Bean>元素中配置的一些属性进行解析和设置，如配置的单态(singleton)属性等 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); //为&lt;Bean>元素解析的Bean设置description信息 bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); //对&lt;Bean>元素的meta(元信息)属性解析 parseMetaElements(ele, bd); //对&lt;Bean>元素的lookup-method属性解析 parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); //对&lt;Bean>元素的replaced-method属性解析 parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); //解析&lt;Bean>元素的构造方法设置 parseConstructorArgElements(ele, bd); //解析&lt;Bean>元素的&lt;property>设置 parsePropertyElements(ele, bd); //解析&lt;Bean>元素的qualifier属性 parseQualifierElements(ele, bd); //为当前解析的Bean设置所需的资源和依赖对象 bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &amp;#125; catch (ClassNotFoundException ex) &amp;#123; error(\"Bean class [\" + className + \"] not found\", ele, ex); &amp;#125; catch (NoClassDefFoundError err) &amp;#123; error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err); &amp;#125; catch (Throwable ex) &amp;#123; error(\"Unexpected failure during bean definition parsing\", ele, ex); &amp;#125; finally &amp;#123; this.parseState.pop(); &amp;#125; //解析&lt;Bean>元素出错时，返回null return null; &amp;#125; 只要使用过Spring，对Spring配置文件比较熟悉的人，通过对上述源码的分析，就会明白我们在Spring配置文件中元素的中配置的属性就是通过该方法解析和设置到Bean中去的。 注意：在解析元素过程中没有创建和实例化 Bean 对象，只是创建了 Bean 对象的定义类BeanDefinition，将元素中的配置信息设置到 BeanDefinition 中作为记录，当依赖注入时才使用这些记录信息创建和实例化具体的Bean对象。 上面方法中一些对一些配置如元信息(meta)、qualifier 等的解析，我们在Spring中配置时使用的也不多，我们在使用Spring的元素时，配置最多的是属性，因此我们下面继续分析源码，了解Bean的属性在解析时是如何设置的。 13、载入元素BeanDefinitionParserDelegate 在解析调用 parsePropertyElements()方法解析元素中的属性子元素，解析源码如下： /** * Parse property sub-elements of the given bean element. */ //解析&lt;Bean>元素中的&lt;property>子元素 public void parsePropertyElements(Element beanEle, BeanDefinition bd) &amp;#123; //获取&lt;Bean>元素中所有的子元素 NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &amp;#123; Node node = nl.item(i); //如果子元素是&lt;property>子元素，则调用解析&lt;property>子元素方法解析 if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, PROPERTY_ELEMENT)) &amp;#123; parsePropertyElement((Element) node, bd); &amp;#125; &amp;#125; &amp;#125; /** * Parse a property element. */ //解析&lt;property>元素 public void parsePropertyElement(Element ele, BeanDefinition bd) &amp;#123; //获取&lt;property>元素的名字 String propertyName = ele.getAttribute(NAME_ATTRIBUTE); if (!StringUtils.hasLength(propertyName)) &amp;#123; error(\"Tag 'property' must have a 'name' attribute\", ele); return; &amp;#125; this.parseState.push(new PropertyEntry(propertyName)); try &amp;#123; //如果一个Bean中已经有同名的property存在，则不进行解析，直接返回。 //即如果在同一个Bean中配置同名的property，则只有第一个起作用 if (bd.getPropertyValues().contains(propertyName)) &amp;#123; error(\"Multiple 'property' definitions for property '\" + propertyName + \"'\", ele); return; &amp;#125; //解析获取property的值 Object val = parsePropertyValue(ele, bd, propertyName); //根据property的名字和值创建property实例 PropertyValue pv = new PropertyValue(propertyName, val); //解析&lt;property>元素中的属性 parseMetaElements(ele, pv); pv.setSource(extractSource(ele)); bd.getPropertyValues().addPropertyValue(pv); &amp;#125; finally &amp;#123; this.parseState.pop(); &amp;#125; &amp;#125; /** * Get the value of a property element. May be a list etc. * Also used for constructor arguments, \"propertyName\" being null in this case. */ //解析获取property值 @Nullable public Object parsePropertyValue(Element ele, BeanDefinition bd, @Nullable String propertyName) &amp;#123; String elementName = (propertyName != null) ? \"&lt;property> element for property '\" + propertyName + \"'\" : \"&lt;constructor-arg> element\"; // Should only have one child element: ref, value, list, etc. //获取&lt;property>的所有子元素，只能是其中一种类型:ref,value,list,etc等 NodeList nl = ele.getChildNodes(); Element subElement = null; for (int i = 0; i &lt; nl.getLength(); i++) &amp;#123; Node node = nl.item(i); //子元素不是description和meta属性 if (node instanceof Element &amp;&amp; !nodeNameEquals(node, DESCRIPTION_ELEMENT) &amp;&amp; !nodeNameEquals(node, META_ELEMENT)) &amp;#123; // Child element is what we're looking for. if (subElement != null) &amp;#123; error(elementName + \" must not contain more than one sub-element\", ele); &amp;#125; else &amp;#123; //当前&lt;property>元素包含有子元素 subElement = (Element) node; &amp;#125; &amp;#125; &amp;#125; //判断property的属性值是ref还是value，不允许既是ref又是value boolean hasRefAttribute = ele.hasAttribute(REF_ATTRIBUTE); boolean hasValueAttribute = ele.hasAttribute(VALUE_ATTRIBUTE); if ((hasRefAttribute &amp;&amp; hasValueAttribute) || ((hasRefAttribute || hasValueAttribute) &amp;&amp; subElement != null)) &amp;#123; error(elementName + \" is only allowed to contain either 'ref' attribute OR 'value' attribute OR sub-element\", ele); &amp;#125; //如果属性是ref，创建一个ref的数据对象RuntimeBeanReference //这个对象封装了ref信息 if (hasRefAttribute) &amp;#123; String refName = ele.getAttribute(REF_ATTRIBUTE); if (!StringUtils.hasText(refName)) &amp;#123; error(elementName + \" contains empty 'ref' attribute\", ele); &amp;#125; //一个指向运行时所依赖对象的引用 RuntimeBeanReference ref = new RuntimeBeanReference(refName); //设置这个ref的数据对象是被当前的property对象所引用 ref.setSource(extractSource(ele)); return ref; &amp;#125; //如果属性是value，创建一个value的数据对象TypedStringValue //这个对象封装了value信息 else if (hasValueAttribute) &amp;#123; //一个持有String类型值的对象 TypedStringValue valueHolder = new TypedStringValue(ele.getAttribute(VALUE_ATTRIBUTE)); //设置这个value数据对象是被当前的property对象所引用 valueHolder.setSource(extractSource(ele)); return valueHolder; &amp;#125; //如果当前&lt;property>元素还有子元素 else if (subElement != null) &amp;#123; //解析&lt;property>的子元素 return parsePropertySubElement(subElement, bd); &amp;#125; else &amp;#123; // Neither child element nor \"ref\" or \"value\" attribute found. //propery属性中既不是ref，也不是value属性，解析出错返回null error(elementName + \" must specify a ref or value\", ele); return null; &amp;#125; &amp;#125; 通过对上述源码的分析，我们可以了解在Spring配置文件中，元素中元素的相关配置是如何处理的： ref被封装为指向依赖对象一个引用。 value配置都会封装成一个字符串类型的对象。 ref和value都通过“解析的数据类型属性值.setSource(extractSource(ele));”方法将属性值/引用与所引用的属性关联起来。 在方法的最后对于元素的子元素通过 parsePropertySubElement ()方法解析，我们继续分析该方法的源码，了解其解析过程。 14、载入的子元素在 BeanDefinitionParserDelegate 类中的 parsePropertySubElement()方法对中的子元素解析，源码如下： @Nullable public Object parsePropertySubElement(Element ele, @Nullable BeanDefinition bd, @Nullable String defaultValueType) &amp;#123; //如果&lt;property>没有使用Spring默认的命名空间，则使用用户自定义的规则解析内嵌元素 if (!isDefaultNamespace(ele)) &amp;#123; return parseNestedCustomElement(ele, bd); &amp;#125; //如果子元素是bean，则使用解析&lt;Bean>元素的方法解析 else if (nodeNameEquals(ele, BEAN_ELEMENT)) &amp;#123; BeanDefinitionHolder nestedBd = parseBeanDefinitionElement(ele, bd); if (nestedBd != null) &amp;#123; nestedBd = decorateBeanDefinitionIfRequired(ele, nestedBd, bd); &amp;#125; return nestedBd; &amp;#125; //如果子元素是ref，ref中只能有以下3个属性：bean、local、parent else if (nodeNameEquals(ele, REF_ELEMENT)) &amp;#123; // A generic reference to any name of any bean. //可以不再同一个Spring配置文件中，具体请参考Spring对ref的配置规则 String refName = ele.getAttribute(BEAN_REF_ATTRIBUTE); boolean toParent = false; if (!StringUtils.hasLength(refName)) &amp;#123; // A reference to the id of another bean in a parent context. //获取&lt;property>元素中parent属性值，引用父级容器中的Bean refName = ele.getAttribute(PARENT_REF_ATTRIBUTE); toParent = true; if (!StringUtils.hasLength(refName)) &amp;#123; error(\"'bean' or 'parent' is required for &lt;ref> element\", ele); return null; &amp;#125; &amp;#125; if (!StringUtils.hasText(refName)) &amp;#123; error(\"&lt;ref> element contains empty target attribute\", ele); return null; &amp;#125; //创建ref类型数据，指向被引用的对象 RuntimeBeanReference ref = new RuntimeBeanReference(refName, toParent); //设置引用类型值是被当前子元素所引用 ref.setSource(extractSource(ele)); return ref; &amp;#125; //如果子元素是&lt;idref>，使用解析ref元素的方法解析 else if (nodeNameEquals(ele, IDREF_ELEMENT)) &amp;#123; return parseIdRefElement(ele); &amp;#125; //如果子元素是&lt;value>，使用解析value元素的方法解析 else if (nodeNameEquals(ele, VALUE_ELEMENT)) &amp;#123; return parseValueElement(ele, defaultValueType); &amp;#125; //如果子元素是null，为&lt;property>设置一个封装null值的字符串数据 else if (nodeNameEquals(ele, NULL_ELEMENT)) &amp;#123; // It's a distinguished null value. Let's wrap it in a TypedStringValue // object in order to preserve the source location. TypedStringValue nullHolder = new TypedStringValue(null); nullHolder.setSource(extractSource(ele)); return nullHolder; &amp;#125; //如果子元素是&lt;array>，使用解析array集合子元素的方法解析 else if (nodeNameEquals(ele, ARRAY_ELEMENT)) &amp;#123; return parseArrayElement(ele, bd); &amp;#125; //如果子元素是&lt;list>，使用解析list集合子元素的方法解析 else if (nodeNameEquals(ele, LIST_ELEMENT)) &amp;#123; return parseListElement(ele, bd); &amp;#125; //如果子元素是&lt;set>，使用解析set集合子元素的方法解析 else if (nodeNameEquals(ele, SET_ELEMENT)) &amp;#123; return parseSetElement(ele, bd); &amp;#125; //如果子元素是&lt;map>，使用解析map集合子元素的方法解析 else if (nodeNameEquals(ele, MAP_ELEMENT)) &amp;#123; return parseMapElement(ele, bd); &amp;#125; //如果子元素是&lt;props>，使用解析props集合子元素的方法解析 else if (nodeNameEquals(ele, PROPS_ELEMENT)) &amp;#123; return parsePropsElement(ele); &amp;#125; //既不是ref，又不是value，也不是集合，则子元素配置错误，返回null else &amp;#123; error(\"Unknown property sub-element: [\" + ele.getNodeName() + \"]\", ele); return null; &amp;#125; &amp;#125; 通过上述源码分析，我们明白了在Spring配置文件中，对元素中配置的array、list、set、map、prop 等各种集合子元素的都通过上述方法解析，生成对应的数据对象，比如 ManagedList、ManagedArray、ManagedSet 等，这些Managed类是 Spring对象BeanDefiniton的数据封装，对集合数据类型的具体解析有各自的解析方法实现，解析方法的命名非常规范，一目了然，我们对集合元素的解析方法进行源码分析，了解其实现过程。 15、载入的子元素在 BeanDefinitionParserDelegate 类中的 parseListElement()方法就是具体实现解析元素中的集合子元素，源码如下： /** * Parse a list element. */ //解析&lt;list>集合子元素 public List&lt;Object> parseListElement(Element collectionEle, @Nullable BeanDefinition bd) &amp;#123; //获取&lt;list>元素中的value-type属性，即获取集合元素的数据类型 String defaultElementType = collectionEle.getAttribute(VALUE_TYPE_ATTRIBUTE); //获取&lt;list>集合元素中的所有子节点 NodeList nl = collectionEle.getChildNodes(); //Spring中将List封装为ManagedList ManagedList&lt;Object> target = new ManagedList&lt;>(nl.getLength()); target.setSource(extractSource(collectionEle)); //设置集合目标数据类型 target.setElementTypeName(defaultElementType); target.setMergeEnabled(parseMergeAttribute(collectionEle)); //具体的&lt;list>元素解析 parseCollectionElements(nl, target, bd, defaultElementType); return target; &amp;#125; //具体解析&lt;list>集合元素，&lt;array>、&lt;list>和&lt;set>都使用该方法解析 protected void parseCollectionElements( NodeList elementNodes, Collection&lt;Object> target, @Nullable BeanDefinition bd, String defaultElementType) &amp;#123; //遍历集合所有节点 for (int i = 0; i &lt; elementNodes.getLength(); i++) &amp;#123; Node node = elementNodes.item(i); //节点不是description节点 if (node instanceof Element &amp;&amp; !nodeNameEquals(node, DESCRIPTION_ELEMENT)) &amp;#123; //将解析的元素加入集合中，递归调用下一个子元素 target.add(parsePropertySubElement((Element) node, bd, defaultElementType)); &amp;#125; &amp;#125; &amp;#125; 经过对Spring Bean配置信息转换的Document对象中的元素层层解析， Spring IOC现在已经将XML形式定义的 Bean配置信息转换为 Spring IOC 所识别的数据结构——BeanDefinition，它是 Bean配置信息中配置的 POJO 对象在 Spring IOC 容器中的映射，我们可以通过 AbstractBeanDefinition 为入口，看到了IOC 容器进行索引、查询和操作。 通过 Spring IOC 容器对 Bean 配置资源的解析后，IOC 容器大致完成了管理 Bean 对象的准备工作，即初始化过程，但是最为重要的依赖注入还没有发生，现在在IOC 容器中 BeanDefinition存储的只是一些静态信息，接下来需要向容器注册Bean定义信息才能全部完成IOC 容器的初始化过程 16、分配注册策略让我们继续跟踪程序的执行顺序，接下来我们来分析 DefaultBeanDefinitionDocumentReader 对Bean 定义转换的 Document 对象解析的流程中，在其 parseDefaultElement()方法中完成对Document 对象的解析后得到封装 BeanDefinition 的 BeanDefinitionHold 对象，然后调用 BeanDefinitionReaderUtils 的 registerBeanDefinition()方法向 IOC 容器注册解析的 Bean，BeanDefinitionReaderUtils的注册的源码如下： /** * Register the given bean definition with the given bean factory. * @param definitionHolder the bean definition including name and aliases * @param registry the bean factory to register with * @throws BeanDefinitionStoreException if registration failed */ //将解析的BeanDefinitionHold注册到容器中 public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &amp;#123; // Register bean definition under primary name. //获取解析的BeanDefinition的名称 String beanName = definitionHolder.getBeanName(); //向IOC容器注册BeanDefinition registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. //如果解析的BeanDefinition有别名，向容器为其注册别名 String[] aliases = definitionHolder.getAliases(); if (aliases != null) &amp;#123; for (String alias : aliases) &amp;#123; registry.registerAlias(beanName, alias); &amp;#125; &amp;#125; &amp;#125; 当调用BeanDefinitionReaderUtils向 IOC 容器注册解析的BeanDefinition时，真正完成注册功能的是DefaultListableBeanFactory。 17、向容器注册DefaultListableBeanFactory 中使用一个 HashMap 的集合对象存放 IOC 容器中注册解析的BeanDefinition，向IOC 容器注册的主要源码如下： //向IOC容器注册解析的BeanDefiniton @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &amp;#123; Assert.hasText(beanName, \"Bean name must not be empty\"); Assert.notNull(beanDefinition, \"BeanDefinition must not be null\"); //校验解析的BeanDefiniton if (beanDefinition instanceof AbstractBeanDefinition) &amp;#123; try &amp;#123; ((AbstractBeanDefinition) beanDefinition).validate(); &amp;#125; catch (BeanDefinitionValidationException ex) &amp;#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \"Validation of bean definition failed\", ex); &amp;#125; &amp;#125; BeanDefinition oldBeanDefinition; oldBeanDefinition = this.beanDefinitionMap.get(beanName); if (oldBeanDefinition != null) &amp;#123; if (!isAllowBeanDefinitionOverriding()) &amp;#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \"Cannot register bean definition [\" + beanDefinition + \"] for bean '\" + beanName + \"': There is already [\" + oldBeanDefinition + \"] bound.\"); &amp;#125; else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &amp;#123; // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE if (this.logger.isWarnEnabled()) &amp;#123; this.logger.warn(\"Overriding user-defined bean definition for bean '\" + beanName + \"' with a framework-generated bean definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &amp;#125; &amp;#125; else if (!beanDefinition.equals(oldBeanDefinition)) &amp;#123; if (this.logger.isInfoEnabled()) &amp;#123; this.logger.info(\"Overriding bean definition for bean '\" + beanName + \"' with a different definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &amp;#125; &amp;#125; else &amp;#123; if (this.logger.isDebugEnabled()) &amp;#123; this.logger.debug(\"Overriding bean definition for bean '\" + beanName + \"' with an equivalent definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &amp;#125; &amp;#125; this.beanDefinitionMap.put(beanName, beanDefinition); &amp;#125; else &amp;#123; if (hasBeanCreationStarted()) &amp;#123; // Cannot modify startup-time collection elements anymore (for stable iteration) //注册的过程中需要线程同步，以保证数据的一致性 synchronized (this.beanDefinitionMap) &amp;#123; this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String> updatedDefinitions = new ArrayList&lt;>(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) &amp;#123; Set&lt;String> updatedSingletons = new LinkedHashSet&lt;>(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; // Still in startup registration phase this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); &amp;#125; this.frozenBeanDefinitionNames = null; &amp;#125; //检查是否有同名的BeanDefinition已经在IOC容器中注册 if (oldBeanDefinition != null || containsSingleton(beanName)) &amp;#123; //重置所有已经注册过的BeanDefinition的缓存 resetBeanDefinition(beanName); &amp;#125; &amp;#125; 至此，Bean配置信息中配置的Bean被解析过后，已经注册到IOC 容器中，被容器管理起来，真正成了 IOC 容器初始化所做的全部工作。现在 IOC 容器中已经建立了整个 Bean 的配置信息，这些BeanDefinition信息已经可以使用，并且可以被检索， IOC 容器的作用就是对这些注册的Bean定义信息进行处理和维护。这些的注册的 Bean定义信息是IOC 容器控制反转的基础，正是有了这些注册的数据，容器才可以进行依赖注入。 基于Annotation的IOC初始化Annotation的前世今生从 Spring2.0 以后的版本中，Spring 也引入了基于注解(Annotation)方式的配置，注解(Annotation)是 JDK1.5 中引入的一个新特性，用于简化 Bean 的配置，可以取代 XML配置文件。开发人员对注解(Annotation)的态度也是萝卜青菜各有所爱，个人认为注解可以大大简化配置，提高开发速度，但也给后期维护增加了难度。目前来说 XML方式发展的相对成熟，方便于统一管理。随着Spring Boot的兴起，基于注解的开发甚至实现了零配置。但作为个人的习惯而言，还是倾向于 XML 配置文件和注解(Annotation)相互配合使用。SpringIOC 容器对于类级别的注解和类内部的注解分以下两种处理策略： 1)、类级别的注解：如@Component、@Repository、@Controller、@Service 以及 JavaEE6 的@ManagedBean和@Named 注解，都是添加在类上面的类级别注解，Spring容器根据注解的过滤规则扫描读取注解Bean定义类，并将其注册到Spring IOC 容器中。 2)、类内部的注解：如@Autowire、@Value、@Resource以及EJB 和 WebService 相关的注解等，都是添加在类内部的字段或者方法上的类内部注解，SpringIOC 容器通过 Bean 后置注解处理器解析Bean内部的注解。下面将根据这两种处理策略，分别分析Spring 处理注解相关的源码。 定位Bean扫描路径在 Spring 中管理注解 Bean 定义的容器有两个 ：AnnotationConfigApplicationContext 和AnnotationConfigWebApplicationContex。这两个类是专门处理Spring 注解方式配置的容器，直接依赖于注解作为容器配置信息来源的 IOC 容器。AnnotationConfigWebApplicationContext 是AnnotationConfigApplicationContext 的 Web版本，两者的用法以及对注解的处理方式几乎没有差别。现在我们以AnnotationConfigApplicationContext为例看看它的源码： public class AnnotationConfigApplicationContext extends GenericApplicationContext implements AnnotationConfigRegistry &amp;#123; //保存一个读取注解的Bean定义读取器，并将其设置到容器中 private final AnnotatedBeanDefinitionReader reader; //保存一个扫描指定类路径中注解Bean定义的扫描器，并将其设置到容器中 private final ClassPathBeanDefinitionScanner scanner; /** * Create a new AnnotationConfigApplicationContext that needs to be populated * through &amp;#123;@link #register&amp;#125; calls and then manually &amp;#123;@linkplain #refresh refreshed&amp;#125;. */ //默认构造函数，初始化一个空容器，容器不包含任何 Bean 信息，需要在稍后通过调用其register() //方法注册配置类，并调用refresh()方法刷新容器，触发容器对注解Bean的载入、解析和注册过程 public AnnotationConfigApplicationContext() &amp;#123; this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this); &amp;#125; /** * Create a new AnnotationConfigApplicationContext with the given DefaultListableBeanFactory. * @param beanFactory the DefaultListableBeanFactory instance to use for this context */ public AnnotationConfigApplicationContext(DefaultListableBeanFactory beanFactory) &amp;#123; super(beanFactory); this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this); &amp;#125; /** * Create a new AnnotationConfigApplicationContext, deriving bean definitions * from the given annotated classes and automatically refreshing the context. * @param annotatedClasses one or more annotated classes, * e.g. &amp;#123;@link Configuration @Configuration&amp;#125; classes */ //最常用的构造函数，通过将涉及到的配置类传递给该构造函数，以实现将相应配置类中的Bean自动注册到容器中 public AnnotationConfigApplicationContext(Class&lt;?>... annotatedClasses) &amp;#123; this(); register(annotatedClasses); refresh(); &amp;#125; /** * Create a new AnnotationConfigApplicationContext, scanning for bean definitions * in the given packages and automatically refreshing the context. * @param basePackages the packages to check for annotated classes */ //该构造函数会自动扫描以给定的包及其子包下的所有类，并自动识别所有的Spring Bean，将其注册到容器中 public AnnotationConfigApplicationContext(String... basePackages) &amp;#123; this(); scan(basePackages); refresh(); &amp;#125; /** * &amp;#123;@inheritDoc&amp;#125; * &lt;p>Delegates given environment to underlying &amp;#123;@link AnnotatedBeanDefinitionReader&amp;#125; * and &amp;#123;@link ClassPathBeanDefinitionScanner&amp;#125; members. */ @Override public void setEnvironment(ConfigurableEnvironment environment) &amp;#123; super.setEnvironment(environment); this.reader.setEnvironment(environment); this.scanner.setEnvironment(environment); &amp;#125; /** * Provide a custom &amp;#123;@link BeanNameGenerator&amp;#125; for use with &amp;#123;@link AnnotatedBeanDefinitionReader&amp;#125; * and/or &amp;#123;@link ClassPathBeanDefinitionScanner&amp;#125;, if any. * &lt;p>Default is &amp;#123;@link org.springframework.context.annotation.AnnotationBeanNameGenerator&amp;#125;. * &lt;p>Any call to this method must occur prior to calls to &amp;#123;@link #register(Class...)&amp;#125; * and/or &amp;#123;@link #scan(String...)&amp;#125;. * @see AnnotatedBeanDefinitionReader#setBeanNameGenerator * @see ClassPathBeanDefinitionScanner#setBeanNameGenerator */ //为容器的注解Bean读取器和注解Bean扫描器设置Bean名称产生器 public void setBeanNameGenerator(BeanNameGenerator beanNameGenerator) &amp;#123; this.reader.setBeanNameGenerator(beanNameGenerator); this.scanner.setBeanNameGenerator(beanNameGenerator); getBeanFactory().registerSingleton( AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, beanNameGenerator); &amp;#125; /** * Set the &amp;#123;@link ScopeMetadataResolver&amp;#125; to use for detected bean classes. * &lt;p>The default is an &amp;#123;@link AnnotationScopeMetadataResolver&amp;#125;. * &lt;p>Any call to this method must occur prior to calls to &amp;#123;@link #register(Class...)&amp;#125; * and/or &amp;#123;@link #scan(String...)&amp;#125;. */ //为容器的注解Bean读取器和注解Bean扫描器设置作用范围元信息解析器 public void setScopeMetadataResolver(ScopeMetadataResolver scopeMetadataResolver) &amp;#123; this.reader.setScopeMetadataResolver(scopeMetadataResolver); this.scanner.setScopeMetadataResolver(scopeMetadataResolver); &amp;#125; //--------------------------------------------------------------------- // Implementation of AnnotationConfigRegistry //--------------------------------------------------------------------- /** * Register one or more annotated classes to be processed. * &lt;p>Note that &amp;#123;@link #refresh()&amp;#125; must be called in order for the context * to fully process the new classes. * @param annotatedClasses one or more annotated classes, * e.g. &amp;#123;@link Configuration @Configuration&amp;#125; classes * @see #scan(String...) * @see #refresh() */ //为容器注册一个要被处理的注解Bean，新注册的Bean，必须手动调用容器的 //refresh()方法刷新容器，触发容器对新注册的Bean的处理 public void register(Class&lt;?>... annotatedClasses) &amp;#123; Assert.notEmpty(annotatedClasses, \"At least one annotated class must be specified\"); this.reader.register(annotatedClasses); &amp;#125; /** * Perform a scan within the specified base packages. * &lt;p>Note that &amp;#123;@link #refresh()&amp;#125; must be called in order for the context * to fully process the new classes. * @param basePackages the packages to check for annotated classes * @see #register(Class...) * @see #refresh() */ //扫描指定包路径及其子包下的注解类，为了使新添加的类被处理，必须手动调用 //refresh()方法刷新容器 public void scan(String... basePackages) &amp;#123; Assert.notEmpty(basePackages, \"At least one base package must be specified\"); this.scanner.scan(basePackages); &amp;#125; //--------------------------------------------------------------------- // Convenient methods for registering individual beans //--------------------------------------------------------------------- /** * Register a bean from the given bean class, deriving its metadata from * class-declared annotations, and optionally providing explicit constructor * arguments for consideration in the autowiring process. * &lt;p>The bean name will be generated according to annotated component rules. * @param annotatedClass the class of the bean * @param constructorArguments argument values to be fed into Spring's * constructor resolution algorithm, resolving either all arguments or just * specific ones, with the rest to be resolved through regular autowiring * (may be &amp;#123;@code null&amp;#125; or empty) * @since 5.0 */ public &lt;T> void registerBean(Class&lt;T> annotatedClass, Object... constructorArguments) &amp;#123; registerBean(null, annotatedClass, constructorArguments); &amp;#125; /** * Register a bean from the given bean class, deriving its metadata from * class-declared annotations, and optionally providing explicit constructor * arguments for consideration in the autowiring process. * @param beanName the name of the bean (may be &amp;#123;@code null&amp;#125;) * @param annotatedClass the class of the bean * @param constructorArguments argument values to be fed into Spring's * constructor resolution algorithm, resolving either all arguments or just * specific ones, with the rest to be resolved through regular autowiring * (may be &amp;#123;@code null&amp;#125; or empty) * @since 5.0 */ public &lt;T> void registerBean(@Nullable String beanName, Class&lt;T> annotatedClass, Object... constructorArguments) &amp;#123; this.reader.doRegisterBean(annotatedClass, null, beanName, null, bd -> &amp;#123; for (Object arg : constructorArguments) &amp;#123; bd.getConstructorArgumentValues().addGenericArgumentValue(arg); &amp;#125; &amp;#125;); &amp;#125; @Override public &lt;T> void registerBean(@Nullable String beanName, Class&lt;T> beanClass, @Nullable Supplier&lt;T> supplier, BeanDefinitionCustomizer... customizers) &amp;#123; this.reader.doRegisterBean(beanClass, supplier, beanName, null, customizers); &amp;#125; &amp;#125; 通过上面的源码分析，我们可以看啊到Spring对注解的处理分为两种方式： 1)、直接将注解Bean注册到容器中可以在初始化容器时注册；也可以在容器创建之后手动调用注册方法向容器注册，然后通过手动刷新容器，使得容器对注册的注解Bean进行处理。 2)、通过扫描指定的包及其子包下的所有类在初始化注解容器时指定要自动扫描的路径，如果容器创建以后向给定路径动态添加了注解Bean，则需要手动调用容器扫描的方法，然后手动刷新容器，使得容器对所注册的Bean进行处理。接下来，将会对两种处理方式详细分析其实现过程。 读取Annotation元数据当创建注解处理容器时，如果传入的初始参数是具体的注解Bean定义类时，注解容器读取并注册。 1)、AnnotationConfigApplicationContext通过调用注解Bean定义读取器AnnotatedBeanDefinitionReader的register()方法向容器注册指定的注解Bean，注解Bean定义读取器向容器注册注解Bean的源码如下： //为容器注册一个要被处理的注解Bean，新注册的Bean，必须手动调用容器的 //refresh()方法刷新容器，触发容器对新注册的Bean的处理 public void register(Class&lt;?>... annotatedClasses) &amp;#123; Assert.notEmpty(annotatedClasses, \"At least one annotated class must be specified\"); this.reader.register(annotatedClasses); &amp;#125; //注册多个注解Bean定义类 public void register(Class&lt;?>... annotatedClasses) &amp;#123; for (Class&lt;?> annotatedClass : annotatedClasses) &amp;#123; registerBean(annotatedClass); &amp;#125; &amp;#125; //注册一个注解Bean定义类 public void registerBean(Class&lt;?> annotatedClass) &amp;#123; doRegisterBean(annotatedClass, null, null, null); &amp;#125; //Bean定义读取器向容器注册注解Bean定义类 &lt;T> void doRegisterBean(Class&lt;T> annotatedClass, @Nullable Supplier&lt;T> instanceSupplier, @Nullable String name, @Nullable Class&lt;? extends Annotation>[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) &amp;#123; //根据指定的注解Bean定义类，创建Spring容器中对注解Bean的封装的数据结构 AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(annotatedClass); if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) &amp;#123; return; &amp;#125; abd.setInstanceSupplier(instanceSupplier); //解析注解Bean定义的作用域，若@Scope(\"prototype\")，则Bean为原型类型； //若@Scope(\"singleton\")，则Bean为单态类型 ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); //为注解Bean定义设置作用域 abd.setScope(scopeMetadata.getScopeName()); //为注解Bean定义生成Bean名称 String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry)); //处理注解Bean定义中的通用注解 AnnotationConfigUtils.processCommonDefinitionAnnotations(abd); //如果在向容器注册注解Bean定义时，使用了额外的限定符注解，则解析限定符注解。 //主要是配置的关于autowiring自动依赖注入装配的限定条件，即@Qualifier注解 //Spring自动依赖注入装配默认是按类型装配，如果使用@Qualifier则按名称 if (qualifiers != null) &amp;#123; for (Class&lt;? extends Annotation> qualifier : qualifiers) &amp;#123; //如果配置了@Primary注解，设置该Bean为autowiring自动依赖注入装//配时的首选 if (Primary.class == qualifier) &amp;#123; abd.setPrimary(true); &amp;#125; //如果配置了@Lazy注解，则设置该Bean为非延迟初始化，如果没有配置， //则该Bean为预实例化 else if (Lazy.class == qualifier) &amp;#123; abd.setLazyInit(true); &amp;#125; //如果使用了除@Primary和@Lazy以外的其他注解，则为该Bean添加一 //个autowiring自动依赖注入装配限定符，该Bean在进autowiring //自动依赖注入装配时，根据名称装配限定符指定的Bean else &amp;#123; abd.addQualifier(new AutowireCandidateQualifier(qualifier)); &amp;#125; &amp;#125; &amp;#125; for (BeanDefinitionCustomizer customizer : definitionCustomizers) &amp;#123; customizer.customize(abd); &amp;#125; //创建一个指定Bean名称的Bean定义对象，封装注解Bean定义类数据 BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName); //根据注解Bean定义类中配置的作用域，创建相应的代理对象 definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); //向IOC容器注册注解Bean类定义对象 BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry); &amp;#125; 从上面的源码我们可以看出，注册注解Bean定义类的基本步骤： a、需要使用注解元数据解析器解析注解Bean中关于作用域的配置。b、使用 AnnotationConfigUtils 的 processCommonDefinitionAnnotations()方法处理注解 Bean 定义类中通用的注解。 c、使用AnnotationConfigUtils的applyScopedProxyMode()方法创建对于作用域的代理对象。d、通过BeanDefinitionReaderUtils向容器注册Bean。下面我们继续分析这4步的具体实现过程 2)、AnnotationScopeMetadataResolver解析作用域元数据AnnotationScopeMetadataResolver 通过 resolveScopeMetadata()方法解析注解 Bean 定义类的作用域元信息，即判断注册的Bean是原生类型(prototype)还是单态(singleton)类型，其源码如下： //解析注解Bean定义类中的作用域元信息 @Override public ScopeMetadata resolveScopeMetadata(BeanDefinition definition) &amp;#123; ScopeMetadata metadata = new ScopeMetadata(); if (definition instanceof AnnotatedBeanDefinition) &amp;#123; AnnotatedBeanDefinition annDef = (AnnotatedBeanDefinition) definition; //从注解Bean定义类的属性中查找属性为”Scope”的值，即@Scope注解的值 //annDef.getMetadata().getAnnotationAttributes()方法将Bean //中所有的注解和注解的值存放在一个map集合中 AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor( annDef.getMetadata(), this.scopeAnnotationType); //将获取到的@Scope注解的值设置到要返回的对象中 if (attributes != null) &amp;#123; metadata.setScopeName(attributes.getString(\"value\")); //获取@Scope注解中的proxyMode属性值，在创建代理对象时会用到 ScopedProxyMode proxyMode = attributes.getEnum(\"proxyMode\"); //如果@Scope的proxyMode属性为DEFAULT或者NO if (proxyMode == ScopedProxyMode.DEFAULT) &amp;#123; //设置proxyMode为NO proxyMode = this.defaultProxyMode; &amp;#125; //为返回的元数据设置proxyMode metadata.setScopedProxyMode(proxyMode); &amp;#125; &amp;#125; //返回解析的作用域元信息对象 return metadata; &amp;#125; 上述代码中的 annDef.getMetadata().getAnnotationAttributes()方法就是获取对象中指定类型的注解的值。 3)、AnnotationConfigUtils处理注解Bean定义类中的通用注解AnnotationConfigUtils 类的 processCommonDefinitionAnnotations()在向容器注册 Bean 之前，首先对注解Bean定义类中的通用Spring 注解进行处理，源码如下： //处理Bean定义中通用注解 static void processCommonDefinitionAnnotations(AnnotatedBeanDefinition abd, AnnotatedTypeMetadata metadata) &amp;#123; AnnotationAttributes lazy = attributesFor(metadata, Lazy.class); //如果Bean定义中有@Lazy注解，则将该Bean预实例化属性设置为@lazy注解的值 if (lazy != null) &amp;#123; abd.setLazyInit(lazy.getBoolean(\"value\")); &amp;#125; else if (abd.getMetadata() != metadata) &amp;#123; lazy = attributesFor(abd.getMetadata(), Lazy.class); if (lazy != null) &amp;#123; abd.setLazyInit(lazy.getBoolean(\"value\")); &amp;#125; &amp;#125; //如果Bean定义中有@Primary注解，则为该Bean设置为autowiring自动依赖注入装配的首选对象 if (metadata.isAnnotated(Primary.class.getName())) &amp;#123; abd.setPrimary(true); &amp;#125; //如果Bean定义中有@ DependsOn注解，则为该Bean设置所依赖的Bean名称， //容器将确保在实例化该Bean之前首先实例化所依赖的Bean AnnotationAttributes dependsOn = attributesFor(metadata, DependsOn.class); if (dependsOn != null) &amp;#123; abd.setDependsOn(dependsOn.getStringArray(\"value\")); &amp;#125; if (abd instanceof AbstractBeanDefinition) &amp;#123; AbstractBeanDefinition absBd = (AbstractBeanDefinition) abd; AnnotationAttributes role = attributesFor(metadata, Role.class); if (role != null) &amp;#123; absBd.setRole(role.getNumber(\"value\").intValue()); &amp;#125; AnnotationAttributes description = attributesFor(metadata, Description.class); if (description != null) &amp;#123; absBd.setDescription(description.getString(\"value\")); &amp;#125; &amp;#125; &amp;#125; 4)、AnnotationConfigUtils根据注解Bean定义类中配置的作用域为其应用相应的代理策略AnnotationConfigUtils 类的 applyScopedProxyMode()方法根据注解 Bean 定义类中配置的作用域@Scope注解的值，为Bean定义应用相应的代理模式，主要是在Spring 面向切面编程(AOP)中使用。源码如下： //根据作用域为Bean应用引用的代码模式 static BeanDefinitionHolder applyScopedProxyMode( ScopeMetadata metadata, BeanDefinitionHolder definition, BeanDefinitionRegistry registry) &amp;#123; //获取注解Bean定义类中@Scope注解的proxyMode属性值 ScopedProxyMode scopedProxyMode = metadata.getScopedProxyMode(); //如果配置的@Scope注解的proxyMode属性值为NO，则不应用代理模式 if (scopedProxyMode.equals(ScopedProxyMode.NO)) &amp;#123; return definition; &amp;#125; //获取配置的@Scope注解的proxyMode属性值，如果为TARGET_CLASS //则返回true，如果为INTERFACES，则返回false boolean proxyTargetClass = scopedProxyMode.equals(ScopedProxyMode.TARGET_CLASS); //为注册的Bean创建相应模式的代理对象 return ScopedProxyCreator.createScopedProxy(definition, registry, proxyTargetClass); &amp;#125; 这段为Bean引用创建相应模式的代理，这里不做深入的分析。 5)、BeanDefinitionReaderUtils向容器注册BeanBeanDefinitionReaderUtils 主要是校验 BeanDefinition 信息，然后将 Bean 添加到容器中一个管理BeanDefinition的HashMap中。 扫描指定包并解析为BeanDefinition当创建注解处理容器时，如果传入的初始参数是注解Bean定义类所在的包时，注解容器将扫描给定的包及其子包，将扫描到的注解Bean定义载入并注册。 1)、ClassPathBeanDefinitionScanner扫描给定的包及其子包AnnotationConfigApplicationContext 通 过 调 用 类 路 径 Bean 定 义 扫 描 器ClassPathBeanDefinitionScanner扫描给定包及其子包下的所有类，主要源码如下： public class ClassPathBeanDefinitionScanner extends ClassPathScanningCandidateComponentProvider &amp;#123; private final BeanDefinitionRegistry registry; private BeanDefinitionDefaults beanDefinitionDefaults = new BeanDefinitionDefaults(); @Nullable private String[] autowireCandidatePatterns; private BeanNameGenerator beanNameGenerator = new AnnotationBeanNameGenerator(); private ScopeMetadataResolver scopeMetadataResolver = new AnnotationScopeMetadataResolver(); private boolean includeAnnotationConfig = true; /** * Create a new &amp;#123;@code ClassPathBeanDefinitionScanner&amp;#125; for the given bean factory. * @param registry the &amp;#123;@code BeanFactory&amp;#125; to load bean definitions into, in the form * of a &amp;#123;@code BeanDefinitionRegistry&amp;#125; */ //创建一个类路径Bean定义扫描器 public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry) &amp;#123; this(registry, true); &amp;#125; /** * Create a new &amp;#123;@code ClassPathBeanDefinitionScanner&amp;#125; for the given bean factory. * &lt;p>If the passed-in bean factory does not only implement the * &amp;#123;@code BeanDefinitionRegistry&amp;#125; interface but also the &amp;#123;@code ResourceLoader&amp;#125; * interface, it will be used as default &amp;#123;@code ResourceLoader&amp;#125; as well. This will * usually be the case for &amp;#123;@link org.springframework.context.ApplicationContext&amp;#125; * implementations. * &lt;p>If given a plain &amp;#123;@code BeanDefinitionRegistry&amp;#125;, the default &amp;#123;@code ResourceLoader&amp;#125; * will be a &amp;#123;@link org.springframework.core.io.support.PathMatchingResourcePatternResolver&amp;#125;. * &lt;p>If the passed-in bean factory also implements &amp;#123;@link EnvironmentCapable&amp;#125; its * environment will be used by this reader. Otherwise, the reader will initialize and * use a &amp;#123;@link org.springframework.core.env.StandardEnvironment&amp;#125;. All * &amp;#123;@code ApplicationContext&amp;#125; implementations are &amp;#123;@code EnvironmentCapable&amp;#125;, while * normal &amp;#123;@code BeanFactory&amp;#125; implementations are not. * @param registry the &amp;#123;@code BeanFactory&amp;#125; to load bean definitions into, in the form * of a &amp;#123;@code BeanDefinitionRegistry&amp;#125; * @param useDefaultFilters whether to include the default filters for the * &amp;#123;@link org.springframework.stereotype.Component @Component&amp;#125;, * &amp;#123;@link org.springframework.stereotype.Repository @Repository&amp;#125;, * &amp;#123;@link org.springframework.stereotype.Service @Service&amp;#125;, and * &amp;#123;@link org.springframework.stereotype.Controller @Controller&amp;#125; stereotype annotations * @see #setResourceLoader * @see #setEnvironment */ //为容器创建一个类路径Bean定义扫描器，并指定是否使用默认的扫描过滤规则。 //即Spring默认扫描配置：@Component、@Repository、@Service、@Controller //注解的Bean，同时也支持JavaEE6的@ManagedBean和JSR-330的@Named注解 public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters) &amp;#123; this(registry, useDefaultFilters, getOrCreateEnvironment(registry)); &amp;#125; /** * Create a new &amp;#123;@code ClassPathBeanDefinitionScanner&amp;#125; for the given bean factory and * using the given &amp;#123;@link Environment&amp;#125; when evaluating bean definition profile metadata. * &lt;p>If the passed-in bean factory does not only implement the &amp;#123;@code * BeanDefinitionRegistry&amp;#125; interface but also the &amp;#123;@link ResourceLoader&amp;#125; interface, it * will be used as default &amp;#123;@code ResourceLoader&amp;#125; as well. This will usually be the * case for &amp;#123;@link org.springframework.context.ApplicationContext&amp;#125; implementations. * &lt;p>If given a plain &amp;#123;@code BeanDefinitionRegistry&amp;#125;, the default &amp;#123;@code ResourceLoader&amp;#125; * will be a &amp;#123;@link org.springframework.core.io.support.PathMatchingResourcePatternResolver&amp;#125;. * @param registry the &amp;#123;@code BeanFactory&amp;#125; to load bean definitions into, in the form * of a &amp;#123;@code BeanDefinitionRegistry&amp;#125; * @param useDefaultFilters whether to include the default filters for the * &amp;#123;@link org.springframework.stereotype.Component @Component&amp;#125;, * &amp;#123;@link org.springframework.stereotype.Repository @Repository&amp;#125;, * &amp;#123;@link org.springframework.stereotype.Service @Service&amp;#125;, and * &amp;#123;@link org.springframework.stereotype.Controller @Controller&amp;#125; stereotype annotations * @param environment the Spring &amp;#123;@link Environment&amp;#125; to use when evaluating bean * definition profile metadata * @since 3.1 * @see #setResourceLoader */ public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters, Environment environment) &amp;#123; this(registry, useDefaultFilters, environment, (registry instanceof ResourceLoader ? (ResourceLoader) registry : null)); &amp;#125; /** * Create a new &amp;#123;@code ClassPathBeanDefinitionScanner&amp;#125; for the given bean factory and * using the given &amp;#123;@link Environment&amp;#125; when evaluating bean definition profile metadata. * @param registry the &amp;#123;@code BeanFactory&amp;#125; to load bean definitions into, in the form * of a &amp;#123;@code BeanDefinitionRegistry&amp;#125; * @param useDefaultFilters whether to include the default filters for the * &amp;#123;@link org.springframework.stereotype.Component @Component&amp;#125;, * &amp;#123;@link org.springframework.stereotype.Repository @Repository&amp;#125;, * &amp;#123;@link org.springframework.stereotype.Service @Service&amp;#125;, and * &amp;#123;@link org.springframework.stereotype.Controller @Controller&amp;#125; stereotype annotations * @param environment the Spring &amp;#123;@link Environment&amp;#125; to use when evaluating bean * definition profile metadata * @param resourceLoader the &amp;#123;@link ResourceLoader&amp;#125; to use * @since 4.3.6 */ public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters, Environment environment, @Nullable ResourceLoader resourceLoader) &amp;#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); //为容器设置加载Bean定义的注册器 this.registry = registry; if (useDefaultFilters) &amp;#123; registerDefaultFilters(); &amp;#125; setEnvironment(environment); //为容器设置资源加载器 setResourceLoader(resourceLoader); &amp;#125; /** * Return the BeanDefinitionRegistry that this scanner operates on. */ @Override public final BeanDefinitionRegistry getRegistry() &amp;#123; return this.registry; &amp;#125; /** * Set the defaults to use for detected beans. * @see BeanDefinitionDefaults */ public void setBeanDefinitionDefaults(@Nullable BeanDefinitionDefaults beanDefinitionDefaults) &amp;#123; this.beanDefinitionDefaults = (beanDefinitionDefaults != null ? beanDefinitionDefaults : new BeanDefinitionDefaults()); &amp;#125; /** * Return the defaults to use for detected beans (never &amp;#123;@code null&amp;#125;). * @since 4.1 */ public BeanDefinitionDefaults getBeanDefinitionDefaults() &amp;#123; return this.beanDefinitionDefaults; &amp;#125; /** * Set the name-matching patterns for determining autowire candidates. * @param autowireCandidatePatterns the patterns to match against */ public void setAutowireCandidatePatterns(@Nullable String... autowireCandidatePatterns) &amp;#123; this.autowireCandidatePatterns = autowireCandidatePatterns; &amp;#125; /** * Set the BeanNameGenerator to use for detected bean classes. * &lt;p>Default is a &amp;#123;@link AnnotationBeanNameGenerator&amp;#125;. */ public void setBeanNameGenerator(@Nullable BeanNameGenerator beanNameGenerator) &amp;#123; this.beanNameGenerator = (beanNameGenerator != null ? beanNameGenerator : new AnnotationBeanNameGenerator()); &amp;#125; /** * Set the ScopeMetadataResolver to use for detected bean classes. * Note that this will override any custom \"scopedProxyMode\" setting. * &lt;p>The default is an &amp;#123;@link AnnotationScopeMetadataResolver&amp;#125;. * @see #setScopedProxyMode */ public void setScopeMetadataResolver(@Nullable ScopeMetadataResolver scopeMetadataResolver) &amp;#123; this.scopeMetadataResolver = (scopeMetadataResolver != null ? scopeMetadataResolver : new AnnotationScopeMetadataResolver()); &amp;#125; /** * Specify the proxy behavior for non-singleton scoped beans. * Note that this will override any custom \"scopeMetadataResolver\" setting. * &lt;p>The default is &amp;#123;@link ScopedProxyMode#NO&amp;#125;. * @see #setScopeMetadataResolver */ public void setScopedProxyMode(ScopedProxyMode scopedProxyMode) &amp;#123; this.scopeMetadataResolver = new AnnotationScopeMetadataResolver(scopedProxyMode); &amp;#125; /** * Specify whether to register annotation config post-processors. * &lt;p>The default is to register the post-processors. Turn this off * to be able to ignore the annotations or to process them differently. */ public void setIncludeAnnotationConfig(boolean includeAnnotationConfig) &amp;#123; this.includeAnnotationConfig = includeAnnotationConfig; &amp;#125; /** * Perform a scan within the specified base packages. * @param basePackages the packages to check for annotated classes * @return number of beans registered */ //调用类路径Bean定义扫描器入口方法 public int scan(String... basePackages) &amp;#123; //获取容器中已经注册的Bean个数 int beanCountAtScanStart = this.registry.getBeanDefinitionCount(); //启动扫描器扫描给定包 doScan(basePackages); // Register annotation config processors, if necessary. //注册注解配置(Annotation config)处理器 if (this.includeAnnotationConfig) &amp;#123; AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &amp;#125; //返回注册的Bean个数 return (this.registry.getBeanDefinitionCount() - beanCountAtScanStart); &amp;#125; /** * Perform a scan within the specified base packages, * returning the registered bean definitions. * &lt;p>This method does &lt;i>not&lt;/i> register an annotation config processor * but rather leaves this up to the caller. * @param basePackages the packages to check for annotated classes * @return set of beans registered if any for tooling registration purposes (never &amp;#123;@code null&amp;#125;) */ //类路径Bean定义扫描器扫描给定包及其子包 protected Set&lt;BeanDefinitionHolder> doScan(String... basePackages) &amp;#123; Assert.notEmpty(basePackages, \"At least one base package must be specified\"); //创建一个集合，存放扫描到Bean定义的封装类 Set&lt;BeanDefinitionHolder> beanDefinitions = new LinkedHashSet&lt;>(); //遍历扫描所有给定的包 for (String basePackage : basePackages) &amp;#123; //调用父类ClassPathScanningCandidateComponentProvider的方法 //扫描给定类路径，获取符合条件的Bean定义 Set&lt;BeanDefinition> candidates = findCandidateComponents(basePackage); //遍历扫描到的Bean for (BeanDefinition candidate : candidates) &amp;#123; //获取Bean定义类中@Scope注解的值，即获取Bean的作用域 ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); //为Bean设置注解配置的作用域 candidate.setScope(scopeMetadata.getScopeName()); //为Bean生成名称 String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); //如果扫描到的Bean不是Spring的注解Bean，则为Bean设置默认值， //设置Bean的自动依赖注入装配属性等 if (candidate instanceof AbstractBeanDefinition) &amp;#123; postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &amp;#125; //如果扫描到的Bean是Spring的注解Bean，则处理其通用的Spring注解 if (candidate instanceof AnnotatedBeanDefinition) &amp;#123; //处理注解Bean中通用的注解，在分析注解Bean定义类读取器时已经分析过 AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &amp;#125; //根据Bean名称检查指定的Bean是否需要在容器中注册，或者在容器中冲突 if (checkCandidate(beanName, candidate)) &amp;#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); //根据注解中配置的作用域，为Bean应用相应的代理模式 definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); //向容器注册扫描到的Bean registerBeanDefinition(definitionHolder, this.registry); &amp;#125; &amp;#125; &amp;#125; return beanDefinitions; &amp;#125; /** * Apply further settings to the given bean definition, * beyond the contents retrieved from scanning the component class. * @param beanDefinition the scanned bean definition * @param beanName the generated bean name for the given bean */ protected void postProcessBeanDefinition(AbstractBeanDefinition beanDefinition, String beanName) &amp;#123; beanDefinition.applyDefaults(this.beanDefinitionDefaults); if (this.autowireCandidatePatterns != null) &amp;#123; beanDefinition.setAutowireCandidate(PatternMatchUtils.simpleMatch(this.autowireCandidatePatterns, beanName)); &amp;#125; &amp;#125; /** * Register the specified bean with the given registry. * &lt;p>Can be overridden in subclasses, e.g. to adapt the registration * process or to register further bean definitions for each scanned bean. * @param definitionHolder the bean definition plus bean name for the bean * @param registry the BeanDefinitionRegistry to register the bean with */ protected void registerBeanDefinition(BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) &amp;#123; BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, registry); &amp;#125; /** * Check the given candidate's bean name, determining whether the corresponding * bean definition needs to be registered or conflicts with an existing definition. * @param beanName the suggested name for the bean * @param beanDefinition the corresponding bean definition * @return &amp;#123;@code true&amp;#125; if the bean can be registered as-is; * &amp;#123;@code false&amp;#125; if it should be skipped because there is an * existing, compatible bean definition for the specified name * @throws ConflictingBeanDefinitionException if an existing, incompatible * bean definition has been found for the specified name */ protected boolean checkCandidate(String beanName, BeanDefinition beanDefinition) throws IllegalStateException &amp;#123; if (!this.registry.containsBeanDefinition(beanName)) &amp;#123; return true; &amp;#125; BeanDefinition existingDef = this.registry.getBeanDefinition(beanName); BeanDefinition originatingDef = existingDef.getOriginatingBeanDefinition(); if (originatingDef != null) &amp;#123; existingDef = originatingDef; &amp;#125; if (isCompatible(beanDefinition, existingDef)) &amp;#123; return false; &amp;#125; throw new ConflictingBeanDefinitionException(\"Annotation-specified bean name '\" + beanName + \"' for bean class [\" + beanDefinition.getBeanClassName() + \"] conflicts with existing, \" + \"non-compatible bean definition of same name and class [\" + existingDef.getBeanClassName() + \"]\"); &amp;#125; /** * Determine whether the given new bean definition is compatible with * the given existing bean definition. * &lt;p>The default implementation considers them as compatible when the existing * bean definition comes from the same source or from a non-scanning source. * @param newDefinition the new bean definition, originated from scanning * @param existingDefinition the existing bean definition, potentially an * explicitly defined one or a previously generated one from scanning * @return whether the definitions are considered as compatible, with the * new definition to be skipped in favor of the existing definition */ protected boolean isCompatible(BeanDefinition newDefinition, BeanDefinition existingDefinition) &amp;#123; return (!(existingDefinition instanceof ScannedGenericBeanDefinition) || // explicitly registered overriding bean (newDefinition.getSource() != null &amp;&amp; newDefinition.getSource().equals(existingDefinition.getSource())) || // scanned same file twice newDefinition.equals(existingDefinition)); // scanned equivalent class twice &amp;#125; /** * Get the Environment from the given registry if possible, otherwise return a new * StandardEnvironment. */ private static Environment getOrCreateEnvironment(BeanDefinitionRegistry registry) &amp;#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); if (registry instanceof EnvironmentCapable) &amp;#123; return ((EnvironmentCapable) registry).getEnvironment(); &amp;#125; return new StandardEnvironment(); &amp;#125; &amp;#125; 类路径 Bean 定义扫描器 ClassPathBeanDefinitionScanner 主要通过 findCandidateComponents()方法调用其父类ClassPathScanningCandidateComponentProvider类来扫描获取给定包及其子包下的类。 2)、ClassPathScanningCandidateComponentProvider扫描给定包及其子包的类ClassPathScanningCandidateComponentProvider 类的 findCandidateComponents()方法具体实现扫描给定类路径包的功能，主要源码如下： public class ClassPathScanningCandidateComponentProvider implements EnvironmentCapable, ResourceLoaderAware &amp;#123; static final String DEFAULT_RESOURCE_PATTERN = \"**/*.class\"; protected final Log logger = LogFactory.getLog(getClass()); private String resourcePattern = DEFAULT_RESOURCE_PATTERN; //保存过滤规则要包含的注解，即Spring默认的@Component、@Repository、@Service、 //@Controller注解的Bean，以及JavaEE6的@ManagedBean和JSR-330的@Named注解 private final List&lt;TypeFilter> includeFilters = new LinkedList&lt;>(); //保存过滤规则要排除的注解 private final List&lt;TypeFilter> excludeFilters = new LinkedList&lt;>(); @Nullable private Environment environment; @Nullable private ConditionEvaluator conditionEvaluator; @Nullable private ResourcePatternResolver resourcePatternResolver; @Nullable private MetadataReaderFactory metadataReaderFactory; @Nullable private CandidateComponentsIndex componentsIndex; /** * Protected constructor for flexible subclass initialization. * @since 4.3.6 */ protected ClassPathScanningCandidateComponentProvider() &amp;#123; &amp;#125; /** * Create a ClassPathScanningCandidateComponentProvider with a &amp;#123;@link StandardEnvironment&amp;#125;. * @param useDefaultFilters whether to register the default filters for the * &amp;#123;@link Component @Component&amp;#125;, &amp;#123;@link Repository @Repository&amp;#125;, * &amp;#123;@link Service @Service&amp;#125;, and &amp;#123;@link Controller @Controller&amp;#125; * stereotype annotations * @see #registerDefaultFilters() */ //构造方法，该方法在子类ClassPathBeanDefinitionScanner的构造方法中被调用 public ClassPathScanningCandidateComponentProvider(boolean useDefaultFilters) &amp;#123; this(useDefaultFilters, new StandardEnvironment()); &amp;#125; /** * Create a ClassPathScanningCandidateComponentProvider with the given &amp;#123;@link Environment&amp;#125;. * @param useDefaultFilters whether to register the default filters for the * &amp;#123;@link Component @Component&amp;#125;, &amp;#123;@link Repository @Repository&amp;#125;, * &amp;#123;@link Service @Service&amp;#125;, and &amp;#123;@link Controller @Controller&amp;#125; * stereotype annotations * @param environment the Environment to use * @see #registerDefaultFilters() */ public ClassPathScanningCandidateComponentProvider(boolean useDefaultFilters, Environment environment) &amp;#123; //如果使用Spring默认的过滤规则，则向容器注册过滤规则 if (useDefaultFilters) &amp;#123; registerDefaultFilters(); &amp;#125; setEnvironment(environment); setResourceLoader(null); &amp;#125; /** * Set the resource pattern to use when scanning the classpath. * This value will be appended to each base package name. * @see #findCandidateComponents(String) * @see #DEFAULT_RESOURCE_PATTERN */ public void setResourcePattern(String resourcePattern) &amp;#123; Assert.notNull(resourcePattern, \"'resourcePattern' must not be null\"); this.resourcePattern = resourcePattern; &amp;#125; /** * Add an include type filter to the &lt;i>end&lt;/i> of the inclusion list. */ public void addIncludeFilter(TypeFilter includeFilter) &amp;#123; this.includeFilters.add(includeFilter); &amp;#125; /** * Add an exclude type filter to the &lt;i>front&lt;/i> of the exclusion list. */ public void addExcludeFilter(TypeFilter excludeFilter) &amp;#123; this.excludeFilters.add(0, excludeFilter); &amp;#125; /** * Reset the configured type filters. * @param useDefaultFilters whether to re-register the default filters for * the &amp;#123;@link Component @Component&amp;#125;, &amp;#123;@link Repository @Repository&amp;#125;, * &amp;#123;@link Service @Service&amp;#125;, and &amp;#123;@link Controller @Controller&amp;#125; * stereotype annotations * @see #registerDefaultFilters() */ public void resetFilters(boolean useDefaultFilters) &amp;#123; this.includeFilters.clear(); this.excludeFilters.clear(); if (useDefaultFilters) &amp;#123; registerDefaultFilters(); &amp;#125; &amp;#125; /** * Register the default filter for &amp;#123;@link Component @Component&amp;#125;. * &lt;p>This will implicitly register all annotations that have the * &amp;#123;@link Component @Component&amp;#125; meta-annotation including the * &amp;#123;@link Repository @Repository&amp;#125;, &amp;#123;@link Service @Service&amp;#125;, and * &amp;#123;@link Controller @Controller&amp;#125; stereotype annotations. * &lt;p>Also supports Java EE 6's &amp;#123;@link javax.annotation.ManagedBean&amp;#125; and * JSR-330's &amp;#123;@link javax.inject.Named&amp;#125; annotations, if available. * */ //向容器注册过滤规则 @SuppressWarnings(\"unchecked\") protected void registerDefaultFilters() &amp;#123; //向要包含的过滤规则中添加@Component注解类，注意Spring中@Repository //@Service和@Controller都是Component，因为这些注解都添加了@Component注解 this.includeFilters.add(new AnnotationTypeFilter(Component.class)); //获取当前类的类加载器 ClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader(); try &amp;#123; //向要包含的过滤规则添加JavaEE6的@ManagedBean注解 this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation>) ClassUtils.forName(\"javax.annotation.ManagedBean\", cl)), false)); logger.debug(\"JSR-250 'javax.annotation.ManagedBean' found and supported for component scanning\"); &amp;#125; catch (ClassNotFoundException ex) &amp;#123; // JSR-250 1.1 API (as included in Java EE 6) not available - simply skip. &amp;#125; try &amp;#123; //向要包含的过滤规则添加@Named注解 this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation>) ClassUtils.forName(\"javax.inject.Named\", cl)), false)); logger.debug(\"JSR-330 'javax.inject.Named' annotation found and supported for component scanning\"); &amp;#125; catch (ClassNotFoundException ex) &amp;#123; // JSR-330 API not available - simply skip. &amp;#125; &amp;#125; /** * Set the Environment to use when resolving placeholders and evaluating * &amp;#123;@link Conditional @Conditional&amp;#125;-annotated component classes. * &lt;p>The default is a &amp;#123;@link StandardEnvironment&amp;#125;. * @param environment the Environment to use */ public void setEnvironment(Environment environment) &amp;#123; Assert.notNull(environment, \"Environment must not be null\"); this.environment = environment; this.conditionEvaluator = null; &amp;#125; @Override public final Environment getEnvironment() &amp;#123; if (this.environment == null) &amp;#123; this.environment = new StandardEnvironment(); &amp;#125; return this.environment; &amp;#125; /** * Return the &amp;#123;@link BeanDefinitionRegistry&amp;#125; used by this scanner, if any. */ @Nullable protected BeanDefinitionRegistry getRegistry() &amp;#123; return null; &amp;#125; /** * Set the &amp;#123;@link ResourceLoader&amp;#125; to use for resource locations. * This will typically be a &amp;#123;@link ResourcePatternResolver&amp;#125; implementation. * &lt;p>Default is a &amp;#123;@code PathMatchingResourcePatternResolver&amp;#125;, also capable of * resource pattern resolving through the &amp;#123;@code ResourcePatternResolver&amp;#125; interface. * @see org.springframework.core.io.support.ResourcePatternResolver * @see org.springframework.core.io.support.PathMatchingResourcePatternResolver */ @Override public void setResourceLoader(@Nullable ResourceLoader resourceLoader) &amp;#123; this.resourcePatternResolver = ResourcePatternUtils.getResourcePatternResolver(resourceLoader); this.metadataReaderFactory = new CachingMetadataReaderFactory(resourceLoader); this.componentsIndex = CandidateComponentsIndexLoader.loadIndex(this.resourcePatternResolver.getClassLoader()); &amp;#125; /** * Return the ResourceLoader that this component provider uses. */ public final ResourceLoader getResourceLoader() &amp;#123; return getResourcePatternResolver(); &amp;#125; private ResourcePatternResolver getResourcePatternResolver() &amp;#123; if (this.resourcePatternResolver == null) &amp;#123; this.resourcePatternResolver = new PathMatchingResourcePatternResolver(); &amp;#125; return this.resourcePatternResolver; &amp;#125; /** * Set the &amp;#123;@link MetadataReaderFactory&amp;#125; to use. * &lt;p>Default is a &amp;#123;@link CachingMetadataReaderFactory&amp;#125; for the specified * &amp;#123;@linkplain #setResourceLoader resource loader&amp;#125;. * &lt;p>Call this setter method &lt;i>after&lt;/i> &amp;#123;@link #setResourceLoader&amp;#125; in order * for the given MetadataReaderFactory to override the default factory. */ public void setMetadataReaderFactory(MetadataReaderFactory metadataReaderFactory) &amp;#123; this.metadataReaderFactory = metadataReaderFactory; &amp;#125; /** * Return the MetadataReaderFactory used by this component provider. */ public final MetadataReaderFactory getMetadataReaderFactory() &amp;#123; if (this.metadataReaderFactory == null) &amp;#123; this.metadataReaderFactory = new CachingMetadataReaderFactory(); &amp;#125; return this.metadataReaderFactory; &amp;#125; /** * Scan the class path for candidate components. * @param basePackage the package to check for annotated classes * @return a corresponding Set of autodetected bean definitions */ //扫描给定类路径的包 public Set&lt;BeanDefinition> findCandidateComponents(String basePackage) &amp;#123; if (this.componentsIndex != null &amp;&amp; indexSupportsIncludeFilters()) &amp;#123; return addCandidateComponentsFromIndex(this.componentsIndex, basePackage); &amp;#125; else &amp;#123; return scanCandidateComponents(basePackage); &amp;#125; &amp;#125; /** * Determine if the index can be used by this instance. * @return &amp;#123;@code true&amp;#125; if the index is available and the configuration of this * instance is supported by it, &amp;#123;@code false&amp;#125; otherwise * @since 5.0 */ private boolean indexSupportsIncludeFilters() &amp;#123; for (TypeFilter includeFilter : this.includeFilters) &amp;#123; if (!indexSupportsIncludeFilter(includeFilter)) &amp;#123; return false; &amp;#125; &amp;#125; return true; &amp;#125; /** * Determine if the specified include &amp;#123;@link TypeFilter&amp;#125; is supported by the index. * @param filter the filter to check * @return whether the index supports this include filter * @since 5.0 * @see #extractStereotype(TypeFilter) */ private boolean indexSupportsIncludeFilter(TypeFilter filter) &amp;#123; if (filter instanceof AnnotationTypeFilter) &amp;#123; Class&lt;? extends Annotation> annotation = ((AnnotationTypeFilter) filter).getAnnotationType(); return (AnnotationUtils.isAnnotationDeclaredLocally(Indexed.class, annotation) || annotation.getName().startsWith(\"javax.\")); &amp;#125; if (filter instanceof AssignableTypeFilter) &amp;#123; Class&lt;?> target = ((AssignableTypeFilter) filter).getTargetType(); return AnnotationUtils.isAnnotationDeclaredLocally(Indexed.class, target); &amp;#125; return false; &amp;#125; /** * Extract the stereotype to use for the specified compatible filter. * @param filter the filter to handle * @return the stereotype in the index matching this filter * @since 5.0 * @see #indexSupportsIncludeFilter(TypeFilter) */ @Nullable private String extractStereotype(TypeFilter filter) &amp;#123; if (filter instanceof AnnotationTypeFilter) &amp;#123; return ((AnnotationTypeFilter) filter).getAnnotationType().getName(); &amp;#125; if (filter instanceof AssignableTypeFilter) &amp;#123; return ((AssignableTypeFilter) filter).getTargetType().getName(); &amp;#125; return null; &amp;#125; private Set&lt;BeanDefinition> addCandidateComponentsFromIndex(CandidateComponentsIndex index, String basePackage) &amp;#123; //创建存储扫描到的类的集合 Set&lt;BeanDefinition> candidates = new LinkedHashSet&lt;>(); try &amp;#123; Set&lt;String> types = new HashSet&lt;>(); for (TypeFilter filter : this.includeFilters) &amp;#123; String stereotype = extractStereotype(filter); if (stereotype == null) &amp;#123; throw new IllegalArgumentException(\"Failed to extract stereotype from \"+ filter); &amp;#125; types.addAll(index.getCandidateTypes(basePackage, stereotype)); &amp;#125; boolean traceEnabled = logger.isTraceEnabled(); boolean debugEnabled = logger.isDebugEnabled(); for (String type : types) &amp;#123; //为指定资源获取元数据读取器，元信息读取器通过汇编(ASM)读//取资源元信息 MetadataReader metadataReader = getMetadataReaderFactory().getMetadataReader(type); //如果扫描到的类符合容器配置的过滤规则 if (isCandidateComponent(metadataReader)) &amp;#123; //通过汇编(ASM)读取资源字节码中的Bean定义元信息 AnnotatedGenericBeanDefinition sbd = new AnnotatedGenericBeanDefinition( metadataReader.getAnnotationMetadata()); if (isCandidateComponent(sbd)) &amp;#123; if (debugEnabled) &amp;#123; logger.debug(\"Using candidate component class from index: \" + type); &amp;#125; candidates.add(sbd); &amp;#125; else &amp;#123; if (debugEnabled) &amp;#123; logger.debug(\"Ignored because not a concrete top-level class: \" + type); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; if (traceEnabled) &amp;#123; logger.trace(\"Ignored because matching an exclude filter: \" + type); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (IOException ex) &amp;#123; throw new BeanDefinitionStoreException(\"I/O failure during classpath scanning\", ex); &amp;#125; return candidates; &amp;#125; private Set&lt;BeanDefinition> scanCandidateComponents(String basePackage) &amp;#123; Set&lt;BeanDefinition> candidates = new LinkedHashSet&lt;>(); try &amp;#123; String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + resolveBasePackage(basePackage) + '/' + this.resourcePattern; Resource[] resources = getResourcePatternResolver().getResources(packageSearchPath); boolean traceEnabled = logger.isTraceEnabled(); boolean debugEnabled = logger.isDebugEnabled(); for (Resource resource : resources) &amp;#123; if (traceEnabled) &amp;#123; logger.trace(\"Scanning \" + resource); &amp;#125; if (resource.isReadable()) &amp;#123; try &amp;#123; MetadataReader metadataReader = getMetadataReaderFactory().getMetadataReader(resource); if (isCandidateComponent(metadataReader)) &amp;#123; ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader); sbd.setResource(resource); sbd.setSource(resource); if (isCandidateComponent(sbd)) &amp;#123; if (debugEnabled) &amp;#123; logger.debug(\"Identified candidate component class: \" + resource); &amp;#125; candidates.add(sbd); &amp;#125; else &amp;#123; if (debugEnabled) &amp;#123; logger.debug(\"Ignored because not a concrete top-level class: \" + resource); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; if (traceEnabled) &amp;#123; logger.trace(\"Ignored because not matching any filter: \" + resource); &amp;#125; &amp;#125; &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanDefinitionStoreException( \"Failed to read candidate component class: \" + resource, ex); &amp;#125; &amp;#125; else &amp;#123; if (traceEnabled) &amp;#123; logger.trace(\"Ignored because not readable: \" + resource); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (IOException ex) &amp;#123; throw new BeanDefinitionStoreException(\"I/O failure during classpath scanning\", ex); &amp;#125; return candidates; &amp;#125; /** * Resolve the specified base package into a pattern specification for * the package search path. * &lt;p>The default implementation resolves placeholders against system properties, * and converts a \".\"-based package path to a \"/\"-based resource path. * @param basePackage the base package as specified by the user * @return the pattern specification to be used for package searching */ protected String resolveBasePackage(String basePackage) &amp;#123; return ClassUtils.convertClassNameToResourcePath(getEnvironment().resolveRequiredPlaceholders(basePackage)); &amp;#125; /** * Determine whether the given class does not match any exclude filter * and does match at least one include filter. * @param metadataReader the ASM ClassReader for the class * @return whether the class qualifies as a candidate component */ //判断元信息读取器读取的类是否符合容器定义的注解过滤规则 protected boolean isCandidateComponent(MetadataReader metadataReader) throws IOException &amp;#123; //如果读取的类的注解在排除注解过滤规则中，返回false for (TypeFilter tf : this.excludeFilters) &amp;#123; if (tf.match(metadataReader, getMetadataReaderFactory())) &amp;#123; return false; &amp;#125; &amp;#125; //如果读取的类的注解在包含的注解的过滤规则中，则返回ture for (TypeFilter tf : this.includeFilters) &amp;#123; if (tf.match(metadataReader, getMetadataReaderFactory())) &amp;#123; return isConditionMatch(metadataReader); &amp;#125; &amp;#125; //如果读取的类的注解既不在排除规则，也不在包含规则中，则返回false return false; &amp;#125; /** * Determine whether the given class is a candidate component based on any * &amp;#123;@code @Conditional&amp;#125; annotations. * @param metadataReader the ASM ClassReader for the class * @return whether the class qualifies as a candidate component */ private boolean isConditionMatch(MetadataReader metadataReader) &amp;#123; if (this.conditionEvaluator == null) &amp;#123; this.conditionEvaluator = new ConditionEvaluator(getRegistry(), this.environment, this.resourcePatternResolver); &amp;#125; return !this.conditionEvaluator.shouldSkip(metadataReader.getAnnotationMetadata()); &amp;#125; /** * Determine whether the given bean definition qualifies as candidate. * &lt;p>The default implementation checks whether the class is not an interface * and not dependent on an enclosing class. * &lt;p>Can be overridden in subclasses. * @param beanDefinition the bean definition to check * @return whether the bean definition qualifies as a candidate component */ protected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) &amp;#123; AnnotationMetadata metadata = beanDefinition.getMetadata(); return (metadata.isIndependent() &amp;&amp; (metadata.isConcrete() || (metadata.isAbstract() &amp;&amp; metadata.hasAnnotatedMethods(Lookup.class.getName())))); &amp;#125; /** * Clear the local metadata cache, if any, removing all cached class metadata. */ public void clearCache() &amp;#123; if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &amp;#123; // Clear cache in externally provided MetadataReaderFactory; this is a no-op // for a shared cache since it'll be cleared by the ApplicationContext. ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); &amp;#125; &amp;#125; 注册注解BeanDefinitionAnnotationConfigWebApplicationContext 是 AnnotationConfigApplicationContext 的 Web 版，它们对于注解 Bean 的注册和扫描是基本相同的，但是 AnnotationConfigWebApplicationContext对注解Bean 定义的载入稍有不同，AnnotationConfigWebApplicationContext 注入注解Bean定义源码如下： //载入注解Bean定义资源 @Override protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) &amp;#123; //为容器设置注解Bean定义读取器 AnnotatedBeanDefinitionReader reader = getAnnotatedBeanDefinitionReader(beanFactory); //为容器设置类路径Bean定义扫描器 ClassPathBeanDefinitionScanner scanner = getClassPathBeanDefinitionScanner(beanFactory); //获取容器的Bean名称生成器 BeanNameGenerator beanNameGenerator = getBeanNameGenerator(); //为注解Bean定义读取器和类路径扫描器设置Bean名称生成器 if (beanNameGenerator != null) &amp;#123; reader.setBeanNameGenerator(beanNameGenerator); scanner.setBeanNameGenerator(beanNameGenerator); beanFactory.registerSingleton(AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, beanNameGenerator); &amp;#125; //获取容器的作用域元信息解析器 ScopeMetadataResolver scopeMetadataResolver = getScopeMetadataResolver(); //为注解Bean定义读取器和类路径扫描器设置作用域元信息解析器 if (scopeMetadataResolver != null) &amp;#123; reader.setScopeMetadataResolver(scopeMetadataResolver); scanner.setScopeMetadataResolver(scopeMetadataResolver); &amp;#125; if (!this.annotatedClasses.isEmpty()) &amp;#123; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Registering annotated classes: [\" + StringUtils.collectionToCommaDelimitedString(this.annotatedClasses) + \"]\"); &amp;#125; reader.register(this.annotatedClasses.toArray(new Class&lt;?>[this.annotatedClasses.size()])); &amp;#125; if (!this.basePackages.isEmpty()) &amp;#123; if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Scanning base packages: [\" + StringUtils.collectionToCommaDelimitedString(this.basePackages) + \"]\"); &amp;#125; scanner.scan(this.basePackages.toArray(new String[this.basePackages.size()])); &amp;#125; //获取容器定义的Bean定义资源路径 String[] configLocations = getConfigLocations(); //如果定位的Bean定义资源路径不为空 if (configLocations != null) &amp;#123; for (String configLocation : configLocations) &amp;#123; try &amp;#123; //使用当前容器的类加载器加载定位路径的字节码类文件 Class&lt;?> clazz = ClassUtils.forName(configLocation, getClassLoader()); if (logger.isInfoEnabled()) &amp;#123; logger.info(\"Successfully resolved class for [\" + configLocation + \"]\"); &amp;#125; reader.register(clazz); &amp;#125; catch (ClassNotFoundException ex) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Could not load class for config location [\" + configLocation + \"] - trying package scan. \" + ex); &amp;#125; //如果容器类加载器加载定义路径的Bean定义资源失败 //则启用容器类路径扫描器扫描给定路径包及其子包中的类 int count = scanner.scan(configLocation); if (logger.isInfoEnabled()) &amp;#123; if (count == 0) &amp;#123; logger.info(\"No annotated classes found for specified class/package [\" + configLocation + \"]\"); &amp;#125; else &amp;#123; logger.info(\"Found \" + count + \" annotated classes in package [\" + configLocation + \"]\"); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 以上就是解析和注入注解配置资源的全过程分析。 IOC容器初始化小结 现在通过上面的代码，总结一下IOC 容器初始化的基本步骤: 初始化的入口在容器实现中的refresh()调用来完成。 对Bean定义载入IOC 容器使用的方法是loadBeanDefinition(),其中的大致过程如下：通过 ResourceLoader 来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给出了 ResourceLoader 的实现，可以从类路径，文件系统,URL等方式来定为资源位置。如果是XmlBeanFactory 作为 IOC容器，那么需要为它指定 Bean定义的资源，也 就 是 说 Bean 定 义 文 件 时 通 过 抽 象 成 Resource 来 被 IOC 容 器 处 理 的 ， 容 器 通 过BeanDefinitionReader 来 完 成 定 义 信 息 的 解 析 和 Bean 信 息 的 注 册 , 往 往 使 用 的 是XmlBeanDefinitionReader 来 解 析 Bean 的 XML 定 义 文 件 - 实 际 的 处 理 过 程 是 委 托 给BeanDefinitionParserDelegate 来完成的，从而得到 bean 的定义信息，这些信息在 Spring 中使用BeanDefinition对象来表示-这个名字可以让我们想到loadBeanDefinition(),registerBeanDefinition()这些相关方法。它们都是为处理BeanDefinitin服务的，容器解析得到 BeanDefinition 以后，需要把它在 IOC 容器中注册，这由 IOC 实现BeanDefinitionRegistry 接口来实现。注册过程就是在IOC 容器内部维护的一个 HashMap 来保存得到的 BeanDefinition 的过程。这个 HashMap 是 IOC 容器持有Bean信息的场所，以后对Bean的操作都是围绕这个HashMap来实现的。然后我们就可以通过BeanFactory和ApplicationContext来享受到Spring IOC的服务了,在使用IOC容器的时候，我们注意到除了少量粘合代码，绝大多数以正确IOC 风格编写的应用程序代码完全不用关心如何到达工厂，因为容器将把这些对象与容器管理的其他对象钩在一起。基本的策略是把工厂放到已知的地方，最好是放在对预期使用的上下文有意义的地方，以及代码将实际需要访问工厂的地方。 Spring本身提供了对声明式载入web应用程序用法的应用程序上下文,并将其存储在ServletContext中的框架实现。 以下是容器初始化全过程的时序图：","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring 源码编译和安装(1)","slug":"spring/Spring 源码编译和安装(1)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-yuan-ma-bian-yi-he-an-zhuang-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-yuan-ma-bian-yi-he-an-zhuang-1/","excerpt":"","text":"1. Spring 源码编译和安装 Spring5源码下载注意事项首先你的JDK需要升级到1.8以上。Spring3.0开始,Spring源码采用github托管，不再提供官网下载链接。这里不做过多赘述，大家可自行去github网站下载，我们使用的版本下载链接为：https://github.com/spring-projects/spring-framework/archive/v5.0.2.RELEASE.zip，下载完成后，解压源码包会看到以下文件目录： 基于Gradle的源码构建技巧由于Spirng5以后都是采用Gradle来编译，所以构建源码前需要先安装Gradle环境。Gradle下载地址：https://gradle.org/releases，我使用的是Spring5官方推荐的版本Gradle4.0,下载链接为：https://gradle.org/next-steps/?version=4.0&amp;format=bin，下载完成后按以下步骤操作，以Windows操作系统为例：第一步：配置环境变量第二步：添加环境变量：Path：%GRADLE_HOME%\\bin第三步：检测环境，输入gradle -v命令，得到以下结果：第四步：编译源码,cmd 切到 spring-framework-5.0.2.RELEASE 目录，运行gradlew.bat第五步：转换为eclipse项目，执行import-into-eclipse.bat命令，构建前，请确保网络状态良好，按任意键继续。第六步：等待构建成功（若中途出现错误，大部分情况是由于网络中断造成的，重试之后一般都能解决问题），构建成功后，会出现如下界面：到这一步为止，还在使用Eclipse的小伙伴已经可以将项目导入到Eclipse中了。而我们推荐使用的IDEA也比较智能，可以直接兼容Eclipse项目。接下来看下面的步骤：第七步：导入IDEA。打开IntelliJ IDEA，点击Import Project，弹出如下界面，选择spring-framework-5.0.2.RELEASE文件夹: 第八步：等待构建完成，在网络良好的情况下大约需要10分钟便可自动构建完成，你会看到如下界面： 第九步：在IDEA中，如果Project下的子项目文件夹变成粗体字之后，说明已经构建成功。还有一种验证方式是：找到ApplicationContext类，按Ctrl + Shift + Alt + U，出现类图界面说明构建成功。 Gradle构建过程中的坑如果项目环境一直无法构建，项目文件夹没有变粗体字，类图无法自动生成。那么你一定是踩到了这样一个坑。第一步：首先打开 View-&gt;Tool Windows -&gt; Gradle然后，点击右侧Gradle 视图中的 Refresh，会出现如下的错误： 第二步：看错误，显然跟Gradle 没有任何关系，解决办法：1.关闭 IDEA，打开任务管理器，结束跟 java有关的所有进程。2.找到 JAVA_HOME -&gt; jre -&gt; lib目录，将 tools.jar 重命名 tools.jar.bak。3.重启 IDEA，再次点击refresh，等待构建完成。","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring5 新特性简述(3)","slug":"spring/Spring5 新特性简述(3)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring5-xin-te-xing-jian-shu-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring5-xin-te-xing-jian-shu-3/","excerpt":"","text":"3. Spring5 新特性简述 Spring 5 于 2017 年 9 月发布了通用版本 (GA)，它标志着自 2013 年 12 月以来第一个主要Spring Framework 版本。它提供了一些人们期待已久的改进，还采用了一种全新的编程范例，以反应式描述中陈述的反应式原则为基础。 这个版本是很长时间以来最令人激动的 Spring Framework 版本。Spring 5 兼容 Java™8 和 JDK 9，它集成了反应式流，以方便后续提供一种颠覆性方法来实现端点和 Web 应用程序开发。当然，反应式编程不仅是此版本的主题，还是令许多程序员激动不已的重大特性。人们对能够针对负载波动进行无缝扩展的容灾和响应式服务的需求在不断增加，Spring 5 很好地满足了这一需求。我们将介绍 Java SE 8 和 Java EE 7 API 升级的基本内容、Spring 5 的新反应式编程模型、对 HTTP/2支持，以及 Spring 通过 Kotlin 对函数式编程的全面支持。我还会简要介绍测试和性能增强，最后介绍对 Spring 核心和容器的一般性修订。 升级到 Java SE 8 和 Java EE 7以前的 Spring Framework 中一直在支持一些弃用的 Java 版本，而 Spring 5 已从旧包袱中解放出来。为了充分利用 Java 8 特性，它的代码库已进行了改进，而且该框架要求将 Java 8 作为最低的 JDK版本。 Spring 5 在类路径（和模块路径）上完全兼容 Java 9，而且它通过了 JDK 9 测试套件的测试。对 Java9 爱好者而言，这是一条好消息，因为在 Java 9 发布后，Spring 能立即使用它。在 API 级别上，Spring 5 兼容 Java EE 8 技术，满足对 Servlet 4.0、Bean Validation 2.0 和全新的 JSON Binding API 的需求。对 Java EE API 的最低要求为 V7，该版本引入了针对 Servlet、JPA和 Bean Validation API 的次要版本。 反应式编程模型Spring 5 最令人兴奋的新特性是它的反应式编程模型。Spring 5 Framework 基于一种反应式基础而构建，而且是完全异步和非阻塞的。只需少量的线程，新的事件循环执行模型就可以垂直扩展。该框架采用反应式流来提供在反应式组件中传播负压的机制。负压是一个确保来自多个生产者的数据不会让使用者不堪重负的概念。 Spring WebFlux 是 Spring 5 的反应式核心，它为开发人员提供了两种为 Spring Web 编程而设计的编程模型：一种基于注解的模型和 Functional Web Framework (WebFlux.fn)。基于注解的模型是 Spring WebMVC 的现代替代方案，该模型基于反应式基础而构建，而 FunctionalWeb Framework 是基于 @Controller 注解的编程模型的替代方案。这些模型都通过同一种反应式基础来运行，后者调整非阻塞 HTTP 使用注解进行编程Web MVC 程序员应该对 Spring 5 的基于注解的编程模型非常熟悉。Spring 5 调整了 Web MVC的 @Controller 编程模型，采用了相同的注解。 在下面的代码中 BookController 类提供了两个方法，分别响应针对某个图书列表的 HTTP 请求，以及针对具有给定 id 的图书的 HTTP 请求。请注意 resource 方法返回的对象（Mono 和 Flux）。这些对象是实现反应式流规范中的 Publisher 接口的反应式类型。它们的职责是处理数据流。Mono 对象处理一个仅含 1 个元素的流，而 Flux 表示一个包含 N 个元素的流。 反应式控制器 @RestController public class BookController &amp;#123; @GetMapping(\"/book\") Flux&lt;Book> list() &amp;#123; return this.repository.findAll(); &amp;#125; @GetMapping(\"/book/&amp;#123;id&amp;#125;\") Mono&lt;Book> findById(@PathVariable String id) &amp;#123; return this.repository.findOne(id); &amp;#125; &amp;#125; 这是针对 Spring Web 编程的注解。现在我们使用函数式 Web 框架来解决同一个问题 支持函数式编程Spring 5 的新函数式方法将请求委托给处理函数，这些函数接受一个服务器请求实例并返回一种反应式类型。来看一段代码，创建 BookHandler 类，其中 listBook() 和 getBook() 方法相当于 Controller中的功能。 public class BookHandler &amp;#123; public Mono&lt;ServerResponse> listBooks(ServerRequest request) &amp;#123; return ServerResponse.ok() .contentType(APPLICATION_JSON) .body(repository.allPeople(), Book.class); &amp;#125; public Mono&lt;ServerResponse> getBook(ServerRequest request) &amp;#123; return repository.getBook(request.pathVariable(\"id\")) .then(book -> ServerResponse.ok() .contentType(APPLICATION_JSON) .body(fromObject(book))) .otherwiseIfEmpty(ServerResponse.notFound().build()); &amp;#125; &amp;#125; 通过路由函数来匹配 HTTP 请求参数与媒体类型，将客户端请求路由到处理函数。下面的代码展示了图书资源端点 URI 将调用委托给合适的处理函数： BookHandler handler = new BookHandler(); RouterFunction&lt;ServerResponse> personRoute = route( GET(\"/books/&amp;#123;id&amp;#125;\") .and(accept(APPLICATION_JSON)), handler::getBook) .andRoute( GET(\"/books\") .and(accept(APPLICATION_JSON)), handler::listBooks); 这些示例背后的数据存储库也支持完整的反应式体验，该体验是通过 Spring Data 对反应式Couchbase、Reactive MongoDB 和 Cassandra 的支持来实现的 使用 REST 端点执行反应式编程新的编程模型脱离了传统的 Spring WebMVC 模型，引入了一些很不错的新特性。举例来说，WebFlux 模块为 RestTemplate 提供了一种完全非阻塞、反应式的替代方案，名为WebClient。下面创建一个 WebClient，并调用 books 端点来请求一本给定 id 为 1234 的图书。通过 WebClient 调用 REST 端点 Mono&lt;Book> book = WebClient.create(\"http://localhost:8080\") .get() .url(\"/books/&amp;#123;id&amp;#125;\", 1234) .accept(APPLICATION_JSON) .exchange(request) .then(response -> response.bodyToMono(Book.class)); 对 HTTP/2 支持HTTP/2 幕后原理：要了解 HTTP/2 如何提高传输性能，减少延迟，并帮助提高应用程序吞吐量，从而提供经过改进的丰富 Web 体验。 Spring Framework 5.0 提供专门的 HTTP/2 特性支持，还支持人们期望出现在 JDK 9 中的新 HTTP客户端。尽管 HTTP/2 的服务器推送功能已通过 Jetty Servlet 引擎的 ServerPushFilter 类向Spring 开发人员公开了很长一段时间，但如果发现 Spring 5 中开箱即用地提供了 HTTP/2 性能增强，Web 优化者们一定会为此欢呼雀跃。 Servlet 4.0 支持在 Spring 5.1 中提供。到那时，HTTP/2 新特性将由 Tomcat 9.0、Jetty 9.3 和Undertow 1.4 原生提供 Kotlin 和 Spring WebFluxKotlin 是一种来自 JetBrains 的面向对象的语言，它支持函数式编程。它的主要优势之一是与 Java 有非常高的互操作性。通过引入对 Kotlin 的专门支持，Spring 在 V5 中全面吸纳了这一优势。它的函数式编程风格与 Spring WebFlux 模块完美匹配，它的新路由 DSL 利用了函数式 Web 框架以及干净且符合语言习惯的代码。可以像下面代码中这样简单地表达端点路由：Kotlin 的用于定义端点的路由 DSL @Bean fun apiRouter() = router &amp;#123; (accept(APPLICATION_JSON) and \"/api\").nest &amp;#123; \"/book\".nest &amp;#123; GET(\"/\", bookHandler::findAll) GET(\"/&amp;#123;id&amp;#125;\", bookHandler::findOne) &amp;#125; \"/video\".nest &amp;#123; GET(\"/\", videoHandler::findAll) GET(\"/&amp;#123;genre&amp;#125;\", videoHandler::findByGenre) &amp;#125; &amp;#125; &amp;#125; 使用 Kotlin 1.1.4+ 时，还添加了对 Kotlin 的不可变类的支持（通过带默认值的可选参数），以及对完全支持 null 的 API 的支持。 使用 Lambda 表达式注册 Bean作为传统 XML 和 JavaConfig 的替代方案，现在可以使用 lambda 表达式注册 Spring bean，使bean 可以实际注册为提供者。下面代码中使用 lambda 表达式注册了一个 Book bean。将 Bean 注册为提供者 GenericApplicationContext context = new GenericApplicationContext(); context.registerBean(Book.class, () -> new Book(context.getBean(Author.class)) ); Spring Web MVC 支持最新的 API全新的 WebFlux 模块提供了许多新的、令人兴奋的功能，但 Spring 5 也迎合了愿意继续使用 SpringMVC 的开发人员的需求。Spring 5 中更新了模型-视图-控制器框架，以兼容 WebFlux 和最新版的Jackson 2.9 和 Protobuf 3.0，甚至包括对新的 Java EE 8 JSON-Binding API 的支持。 除了 HTTP/2 特性的基础服务器实现之外，Spring WebMVC 还通过 MVC 控制器方法的一个参数来支持 Servlet 4.0 的 PushBuilder。最后，WebMVC 全面支持 Reactor 3.1 的 Flux 和 Mono 对象，以及 RxJava 1.3 和 2.1，它们被视为来自 MVC 控制器方法的返回值。这项支持的最终目的是支持Spring Data 中的新的反应式 WebClient 和反应式存储库。 使用 JUnit 5 执行条件和并发测试JUnit 和 Spring 5：Spring 5 全面接纳了函数式范例，并支持 JUnit 5 及其新的函数式测试风格。还提供了对 JUnit 4 的向后兼容性，以确保不会破坏旧代码。 Spring 5 的测试套件通过多种方式得到了增强，但最明显的是它对 JUnit 5 的支持。现在可以在您的单元测试中利用 Java 8 中提供的函数式编程特性。以下代码演示了这一支持： JUnit 5 全面接纳了 Java 8 @Test void givenStreamOfInts_SumShouldBeMoreThanFive() &amp;#123; assertTrue(Stream.of(20, 40, 50) .stream() .mapToInt(i -> i) .sum() > 110, () -> \"Total should be &amp;#125; 迁移到 JUnit 5：如果您对升级到 JUnit 5 持观望态度，Steve Perry 的分两部分的深入剖析教程将说服您冒险尝试。 Spring 5 继承了 JUnit 5 在 Spring TestContext Framework 内实现多个扩展 API 的灵活性。举例而言，开发人员可以使用 JUnit 5 的条件测试执行注解 @EnabledIf 和 @DisabledIf 来自动计算一个 SpEL (Spring Expression Language) 表达式，并适当地启用或禁用测试。借助这些注解，Spring 5支持以前很难实现的复杂的条件测试方案。Spring TextContext Framework 现在能够并发执行测试。 使用 Spring WebFlux 执行集成测试 Spring Test 现在包含一个 WebTestClient，后者支持对 Spring WebFlux 服务器端点执行集成测试。 WebTestClient 使用模拟请求和响应来避免耗尽服务器资源，并能直接绑定到 WebFlux 服务器基础架构。 WebTestClient 可绑定到真实的服务器，或者使用控制器或函数。在下面的代码中，WebTestClient 被绑定到 localhost： 绑定到 localhost 的 WebTestClient WebTestClient testClient = WebTestClient .bindToServer() .baseUrl(\"http://localhost:8080\") .build(); 将 WebTestClient 绑定到 RouterFunction RouterFunction bookRouter = RouterFunctions.route( RequestPredicates.GET(\"/books\"), request -> ServerResponse.ok().build() ); WebTestClient .bindToRouterFunction(bookRouter) .build().get().uri(\"/books\") .exchange() .expectStatus().isOk() .expectBody().isEmpty(); 包清理和弃用Spring 5 中止了对一些过时 API 的支持。遭此厄运的还有 Hibernate 3 和 4，为了支持 Hibernate5，它们遭到了弃用。另外，对 Portlet、Velocity、JasperReports、XMLBeans、JDO 和 Guava 的支持也已中止。 包级别上的清理工作仍在继续：Spring 5 不再支持 beans.factory.access、jdbc.support.nativejdbc、mock.staticmock（来自 spring-aspects 模块）或 web.view.tiles2M。Tiles 3 现在是 Spring 的最低要求。 Spring 核心和容器的一般更新Spring Framework 5 改进了扫描和识别组件的方法，使大型项目的性能得到提升。目前，扫描是在编译时执行的，而且向 META-INF/spring.components 文件中的索引文件添加了组件坐标。该索引是通过一个为项目定义的特定于平台的应用程序构建任务来生成的。 标有来自 javax 包的注解的组件会添加到索引中，任何带 @Index 注解的类或接口都会添加到索引中。Spring 的传统类路径扫描方式没有删除，而是保留为一种后备选择。有许多针对大型代码库的明显性能优势，而托管许多 Spring 项目的服务器也会缩短启动时间。 Spring 5 还添加了对 @Nullable 的支持，后者可用于指示可选的注入点。使用者现在必须准备接受null 值。此外，还可以使用此注解来标记可以为 null 的参数、字段和返回值。@Nullable 主要用于IntelliJ IDEA 等 IDE，但也可用于 Eclipse 和 FindBugs，它使得在编译时处理 null 值变得更方便，而无需在运行时发送 NullPointerExceptions。 Spring Logging 还提升了性能，自带开箱即用的 Commons Logging 桥接器。现在已通过资源抽象支持防御性编程，为 getFile 访问提供了 isFile 指示器。 我如何看 Spring5？Spring 5 的首要特性是新的反应式编程模型，这代表着对提供可无缝扩展、基于 Spring 的响应式服务的重大保障。随着人们对 Spring 5 的采用，开发人员有望看到反应式编程将会成为使用 Java 语言的 Web 和企业应用程序开发的未来发展道路。 未来的 Spring Framework 版本将继续体现这一承诺，因为 Spring Security、Spring Data 和Spring Integration 有望采用反应式编程的特征和优势。 总之，Spring 5 代表着一次大受 Spring 开发人员欢迎的华丽转变，同时也为其他框架指出了一条发展之路。Spring5 的升级也为 Spring Boot、Spring Cloud 提供非常丰富的经验，Spring 不仅仅只是一个框架，已然成为了一种编程生态。","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring版本 命名规范(4)","slug":"spring/Spring版本 命名规范(4)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-ban-ben-ming-ming-gui-fan-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-ban-ben-ming-ming-gui-fan-4/","excerpt":"","text":"4. Spring 版本命名规范常见软件的版本号命名 软件 升级过程 说明 linux Kernel 0.0.1 ,1.0.0,2.6.32 若用X.Y.Z表示,则偶数Y 表示稳定版本,奇书Y 表示开发版本 Window Windows 98,windows 2000,windows XP 最大的特点就是杂乱无章,毫无规律 SSH Cleint 0.9.8 OpenStack 2014.1.3 2015.1.1.dev8 日期命令 从上可以看出,不同的软件版本号风格各异,随着系统的规模越大,依赖的软件越多,如果这些软件没有遵循一套规范的命名风格,容易造成 Dependency Hell.所以 当我们发布版本的时候,版本号的命名需要遵循某种规则,其中Semantic Versionong2.0.0 定义了一套简单的规则以及条件来约束版本号的配置和增长.本文根据Semantic Versioning2.0.0 和Semantic Versioning3.0.0 选择性的整理出版本号命名规则指南. 语义化版本命名通行规则该规则对版本的迭代顺序命名做了很好的规范,其版本号的格式为X.Y.Z(又称 Major.Monor.Patch),递增的规则为: 序号 格式要求 说明 X 非负整数 表示主版本号(Major),当API的兼容性变化的时候,需要递增 Y 非负整数 表示次版本号(Minor),当增加功能的时候(不影响API的兼容性),Y需要递增 Z 非负整数 表示修订好(Patch),当做Bug修复的时候(不影响API兼容性的时候),Z需要递增 详细的使用规则如下: X,Y,Z 必须是非负整数,且不得包含前导零,必须按照数值进行递增,如1.9.0-&gt;1.10.0-&gt;1.11.0 0.Y.Z 的版本号表示软件处于初始开发阶段,意味着API 可能不稳定;1.0.0 表示版本已有稳定的API 当API的兼容性发现变化的时候,X必须递增,Y和Z 同时设置为0,当新增功能(不影响API兼容性)或者API被标记为Deprecated时,Y必须递增,同时Z 设置为0,当进行bug fix时,Z 必须递增. 先行版本号(Pre-release)意味该版本不稳定,可能存在兼容性问题,其合适为:X.Y.Z.[a-c][正整数].如1.0.0.a1,1.0.0.b99. 开发版本号常用于Cl-CD,格式为 X.Y.Z.dev[正整数],如 1.0.1.dev4 版本号的排列规则为依次比较主版本号,次版本号和修订号的数值,如 1.0.0 &lt; 1.0.1 &lt; 1.1.1 &lt; 2.0.0 ;对于先行版本号和开发版本号,有l 1.0.0.a100 &lt; 1.0.0 , 2.1.0.dev3 &lt; 2.1.0 ;当存在字母的时候,以ASCII的排序来比较.如 1.0.0.a1 &lt; 1.0.0.b1 商业软件中 常用的修饰词 描述方式 说明 含义 Snapshot 快照版 尚不稳定,尚处于开发中的版本 Alpha 内部版 严重缺陷基本完成修正并通过复测,但需要完整的功能测试 Beta 测试版本 相对Alpha 有很大的改进,消除了严重的错误,但是还存在一些缺陷 PC 终测版 Release Candidate(最终测试),即将作为正式版发布 Demo 演示版 只集成了正式版部分功能升级,无法升级 SP SP1 是 service pack 的意思表示升级包, Release 稳定版 功能相对稳定,可以对外发布,但是有时间限制 Trial 试用版 试用版,仅对部分用户发行 Full Version 完整版 既正式版,已发布 Unregistered 未注册 有功能或时间限制的版本 Standard 标准版 能满足正常使用的功能的版本 Lite 精简版 只含有正式版的核心功能 Enhance 增强版 正式版,功能优化的版本 Ultimate 旗舰版 在标配版本升级体验感更好的版本 Professiona 专业版 针对更高要求功能,专业性更强的使用群体发行的版本 Free 自由版 自由免费使用的版本 Upgrade 升级版 有功能增强或修复已知bug Retail 零售版 单独发售 Cardware 共享版 公用许可证(IOS签证) LTS 维护版 该版本需要长期维护 Spring 版本命名规则 描述方式 说明 含义 Snapshot 快照版 尚不稳定,尚处于开发中的版本 Release 稳定版 功能相对稳定,可以对外发布,但是有时间限制 GA 正式版 代表广泛可用的稳定版 M 里程碑版 具有一些全新的功能或者具有里程碑意义的版本 RC 终测版 Release Candidate(最终测试),即将作为正式版发布","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"Spring编程思想总结(10)","slug":"spring/Spring编程思想总结(10)","date":"2022-01-04T02:42:07.257Z","updated":"2022-01-04T02:42:07.257Z","comments":true,"path":"2022/01/04/spring/spring-bian-cheng-si-xiang-zong-jie-10/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-bian-cheng-si-xiang-zong-jie-10/","excerpt":"","text":"10 . Spring 编程思想总结 Spring思想 应用场景(特点) 一句话归纳 OOP Object Oriented Programming(面向对象编程)用程序归纳总结生活中的一切事物 封装,继承,多态 BOP Bean Oriented Programming(面向Bean 编程) 面向Bean(普通的java类)设计程序 一切从Bean开始 AOP Aspect Origented Programming(面向切面编程) 找出多个类中有一定规律的代码,开发时拆开,运行时再合并,面向切面编程,既面向规则编程 解耦,专人做专事 IOC Inversion of Control(控制反转) 将new对象的动作交给Spring管理,并由Spring保存已经创建的对象(IOC容器) 转交控制权(既控制权反转) DL/DI Dependency Injection (依赖注入)或者Dependency Lookup(依赖查找) 依赖注入,依赖查找,Spring不仅保存自己创建的对象,而且保存对象和对象之间的关系.注入既赋值,主要三种方式:构造方法,set方法,直接赋值 赋值 AOP在Spring中的应用SpingAOP是一种编程范式,主要目的是将非功能性需求从功能性需求中分离出来,达到解耦的目的.主要应用场景由:Authentication(权限认证),Auto Caching(自动缓存处理),Error Handling(统一错误处理),Debugging(调式信息输出),Logging(日志记录),transactions(事务处理).现实生活中也常常用AOP思维来解决问题,如飞机组装,汽车组装等.飞机各部件的零件会交给不同的厂家区生产,最终由组装工厂将各个部件组装成一个整理.将零件的生产交出去的主要目的是解耦,但是解耦之前必须由统一的标准.","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"redis实战之高并发(17)","slug":"redis/redis实战之高并发(17)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-shi-zhan-zhi-gao-bing-fa-17/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-shi-zhan-zhi-gao-bing-fa-17/","excerpt":"","text":"redis实战之高并发在redis 存储的所有数据中, 有一部分是被频繁访问的. 有两种情况可能会导致热点问题的产生, 一种是用户集中访问的数据, 例如抢购的商品, 明星结婚或者明星出轨的微博. 还有一种问题是在数据进行分片的情况下, 负载不均衡, 超过了单个服务器的承受能力. 热点数据可能引起缓存服务的不可用, 最终造成压力堆积到数据库. 处于存储和流量优化的角度, 我们必须要找到这些热点数据. 1. 热点数据的发现除了自动的缓存淘汰机制之外，怎么找出那些访问频率最高的key呢?或者说, 我们可以在哪里记录key被访问的情况呢? 1.1 客户端第一个当然是在客户端了, 比如我们可以不可以在所有调用了get 、set 方法的地方, 加上key 的计数. 但是这样的话, 每一个地方都需要修改， 重复的代码也多。如果我们用的是jedis的客户端, 我们可以在jedis的connection类的sendCommand() 里面, 用一个HashMap 进行key 的计数. 但是这种方式有几个问题： 不知道要存多少个key, 可能会发生内存泄漏的问题 会对客户端的代码造成入侵 只能统计当前客户端的热点key 1.2 代理层第二种方式就是在代理层实现,比如TwemProxy 或者Codis,但是不是所有的项目都是用了代理的架构 1.3 服务端第三种就是在服务端统计, redis有一个monitor 的命令, 可以监控到所有redis 执行的命令. public static void main(String[] args) &amp;#123; Jedis jedis = JedisUtil.getJedisUtil().getJedis(); jedis.monitor(new JedisMonitor() &amp;#123; @Override public void onCommand(String command) &amp;#123; System.out.println(\"#monitor: \" + command); &amp;#125; &amp;#125;); &amp;#125; Facebook 的开源项目 redis-faina 就是基于这个原理实现的, 它是一个python 脚本,可以分析monitor 的数据 redis-cli -p 6379 monitor | head -n 100000 | ./redis-faina.py 这种方法也有两个问题, monitor 命令在高并发的场景下, 会影响性能, 所以不适合长时间使用. 只能统计一个redis 节点的热点key 1.4 机器层面还有一种方法就是机器层面的, 通过TCP协议进行抓包,也有一些开源的方案, 比如ELK的packetbeat插件 当我们发现了热点key之后, 我们来看下热点数据在高并发的场景下可能会出现哪些问题呢? 以及怎么去解决? 2. 缓存雪崩1. 什么是缓存雪崩缓存雪崩就是redis 的大量热点数据同时过期(失效),因为设置了相同的过期时间, 刚好这个时候redis请求的并发量又很大, 就会导致所有的请求落到数据库. 2. 缓存雪崩的解决方案 加互斥锁或者使用队列, 针对同一个key只允许一个线程到数据库查询 缓存定时预更新,避免同时失效. 通过加随机数, 使key 在不同的时间过期. 缓存永不过期. 3. 缓存穿透3.1 缓存穿透何时发生?当数据在数据库和redis 里面都不存在, 可能是一次条件错误的查询, 在这种情况下, 因为数据库值是不存在的, 所以肯定不会写入到redis, 那么下一次查询相同的key的时候, 肯定还会到数据库查询一次. 那么这种循环查询数据库中不存在的值, 并且每次都是使用的相同的key 的情况下, 我们有没有办法避免应用直接到数据库查询呢? 缓存空数据 缓存特殊字符串 我们可以在数据库缓存一个空字符串,或者缓存一个特殊的字符串, 那么在应用里面拿到这个特殊的字符串的时候, 就知道数据库没有值了, 也没有必要到数据库中查询了. 这个是应用重复查询同一个存在的值的情况, 如果应用每一次查询的不存在的值是不一样的呢? 即使你每次都缓存特殊字符串也没用, 因为它的值不一样, 比如我们的用户系统登录的场景, 如果是恶意的请求, 它每次都生成了一个符合ID规则的账号, 但是这个账号在我们的数据库是不存在的, 那redis 就完全失去了作用. 这种因为每次查询的值都不存在导致的redis失效的情况, 我们就把它叫做缓存穿透. 这个问题我们应该怎么去解决呢? 3.2 经典面试题其实它也是一个通用的问题, 关键在于我们怎么知道请求的key 在我们的数据库是否存在, 如果数据量特别大的情况, 我们怎么去快速判断呢? 这也是一个非常经典的面试题: 如何在海量元素中(例如10亿无序、不定长、不重复)快速判断一个元素是否存在? 如果是缓存穿透的这个问题, 我们要避免到数据库查询不存的数据, 肯定要把这10亿放到别的地方. 这些数据在redis 里面也是没有的, 为了加快检索速度, 我们要把数据放到内存里面来判断, 问题来了: 如果我们直接把这些元素的值放到基本的数据结构(List、Map，Tree)里面, 比如一个元素1字节的字段, 10亿的数据大概需要900G的内存空间, 这个对于普通的服务器来说是承受不了的. 所以, 我们存储这几十亿个元素,不能直接存值, 我们应该找到一种最简单的最节省空间的数据结构, 用来标记这个元素没有出现. 这个东西我们就把它叫做位图, 它是一个有序的数组, 只有两个值, 0和1, 0代表不存在, 1代表存在. 那我们怎么用这个数组里面的有序的位置来标记这10亿个元素是否存在? 我们是不是必须要有一个映射的方法, 把元素映射到一个下标位置上? 对于这个映射方法, 我们有几个基本的要求: 因为我们的值长度是不固定的, 我希望不同长度的输入, 可以得到固定长度的输出. 转换成下标的时候, 我希望它在我的这个有序数组里面是分布均匀的, 不然的话全部都挤到一对了, 我也没法判断到底哪个元素存了? 哪个元素没存? 这个是哈希函数, 比如MD5、SHA-1 等等这些都是常见的哈希算法 比如, 这6个元素, 我们经过哈希函数和位运算, 得到了相应的下标. 3.3 哈希碰撞这个时候, Tom和Mic 经过计算得到的哈希值是一样的, 那么再经过位运算得到的下标肯定是一样的, 我们把这种情况叫做哈希冲突或者哈希碰撞. 如果发生了哈希碰撞, 这个时候对于我们的容器存值肯定是有影响的, 我们可以用过哪些方式去降低哈希碰撞的概率呢? 第一种是扩大位数组的长度或者说位图容量, 因为我们的函数是分布均匀的, 所以,位图容量越大, 在同一个位置发生哈希碰撞的概率就越小. 是不是位图容量越大就越好呢? 不管存多少个元素, 都创建一个几万亿大小的位图, 可以吗?当然不可以,因为越大的位图容量, 意味着越多的内存消耗, 所以我们要创建一个合适大小的位图容量. 除了扩大位图容量, 我们还有什么降低哈希碰撞概率的方法呢? 如果两个元素经过一次哈希计算, 得到的相同下标的概率比较高， 我可以不可以计算多次呢? 原来我只用一个哈希函数, 现在我对于每一个要存储的都用多个哈希函数去计算, 这样每次计算出来的下标都相同的概率就小得多了. 同样的,我们能不能引入很多歌哈希函数呢? 比如都计算100次, 都可以吗? 当然也会有问题, 第一个就是他会填满位图的更多的空间， 第二个是计算是需要消耗时间的. 所以总的来说, 我们既要节省空间， 又要很高的计算概率, 就必须在位图容量和函数个数之间找到一个最佳的平衡. 比如;我们存放100万个元素, 到底需要多大的位图容量, 需要多少个哈希函数呢? 3.4 布隆过滤器原理当然, 这个事情早就有人研究过了, 在1970年的时候, 有一个叫做布隆的前辈对于判断海量元素中元素是否存在的问题进行了研究, 也就是到底需要多大的位图容量和多少个哈希函数, 它发表了一篇论文, 提出的这个容器就叫做布隆过滤器. 我们来看一下布隆过滤器的工作原理 首先, 布隆过滤器的本质就是我们刚才分析的, 一个位数组, 和若干个哈希函数. 集合里面有3个元素, 要把它存到布隆过滤器里面去, 应该怎么做呢? 首先是a元素, 这里我们用3次计算, b、c元素也是一样. 元素都存进去以后, 现在我要来判断一个元素在这个容器中是否存在, 就要使用同样的三个函数进行计算. 比如d元素, 我用第一个函数f1 计算, 发现这个位置上是1, 没问题, 第二个位置也是1, 第三个位置上也是1. 如果经过三次计算得到的下标位置值都是1, 这种情况下, 能不能确定d元素一定在这个容器里面呢? 实际上是不能的. 比如这张图里面, 这三个位置分别是把a、b、c 存进去的时候置成1， 所以即使d 元素之前没有存进去, 也会得到三个1, 判断返回true 所以 这个是布隆过滤器的一个很重要的特性, 因为哈希碰撞是不可避免的, 所以它会存在一定的误判率. 这种把本来不存在布隆过滤器中的元素误判为存在的情况, 我们把它叫做 假阳性(False Positive Probability，FPP) 我们再来看另一个元素, 我们要判断它在容器中是否存在， 一样的要用这三个函数去计算, 第一个位置是1, 第二个位置是1, 第三个位置是0 e元素是不是一定不在这个容器里面呢? 可以确定一定不存在,如果说当时已经把e元素存到布隆过滤器里面去了, 那么这三个位置肯定都是1, 不可能会出现0 总结: 布隆过滤器的特点： 从容器的角度来说： 如果布隆过滤器判断元素在集合中存在, 不一定存在. 如果布隆过滤器判断不存在, 则一定不存在. 从元素的角度来说： 如果元素实际存在, 布隆过滤器一定判断存在 如果元素实际不存在,布隆过滤器可能判断存在 利用第二个特性, 我们是不是就可以解决持续从数据库查询不存在的值的问题呢? 3.5 Guava的实现谷歌的Guava 里面就提供了一个现成的布隆过滤器 &lt;dependency> &lt;groupId>com.google.guava&lt;/groupId> &lt;artifactId>guava&lt;/artifactId> &lt;version>21.0&lt;/version> &lt;/dependency> 创建布隆过滤器 BloomFilter&lt;String> bf = BloomFilter.create( Funnels.stringFunnel(Charsets.UTF_8), insertions); 布隆过滤器提供的存放元素的方法是put() 布隆过滤器提供的判断元素是否存在的方法是mightContain() if (bf.mightContain(data)) &amp;#123; if (sets.contains(data)) &amp;#123; // 判断存在实际存在的时候，命中 right++; continue; &amp;#125; // 判断存在却不存在的时候，错误 wrong++; &amp;#125; 布隆过滤器把误判率默认设置为0.03, 也可以在创建的时候指定 public static &lt;T> BloomFilter&lt;T> create(Funnel&lt;? super T> funnel, long expectedInsertions) &amp;#123; return create(funnel, expectedInsertions, 0.03D); &amp;#125; 位图的容量是基于元素个数和误判率计算出来的. long numBits = optimalNumOfBits(expectedInsertions, fpp); 根据位数组的大小, 我们进一步计算哈希函数的个数 int numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits); 存储100万个元素, 只占用了0.87M的内存, 生成了5个哈希函数. https://hur.st/bloomfilter/?n=1000000&amp;p=0.03&amp;m=&amp;k= 3.6 布隆过滤器在项目中的使用布隆过滤器的工作位置: 因为要判断数据库的值是否存在, 所以第一步是加载数据库所有的数据, 在去redis 查询之前, 先用布隆过滤器查询, 如果bf 说没有, 那数据库也没有, 也就不同去查了. 如果bf说有, 才走之前的路程. 3.7 布隆过滤器的其他应用场景布隆过滤器解决的问题是什么呢? 如何在海量的元素中快速判断一个元素是否存在, 所以除了解决缓存穿透的问题之外， 还有很多其他的用途. 比如爬数据的爬虫, 爬过的url 我们不需要进行重复的爬, 那么在几十亿的url里面， 怎么判断一个url 是否已经爬过呢? 还有我们的邮箱服务器, 发送垃圾邮件的账号我们把它叫做spamer, 在这么多的邮箱账号里面, 怎么判断一个账号是不是spamer 等等一些场景, 我们都可以用到布隆过滤器.","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis的持久化机制(13)","slug":"redis/redis的持久化机制(13)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-de-chi-jiu-hua-ji-zhi-13/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-de-chi-jiu-hua-ji-zhi-13/","excerpt":"","text":"redis的持久化机制https://redis.io/topics/persistence redis速度快 , 很大一部分原因是因为他所有的数据都存储在内存中, 如果断电或者宕机, 都会导致内存中的数据丢失. 为了实现重启后数据不丢失, redis提供了两种数据持久化方案, 一种是RDB 快照(Redis DataBase), 另外一种是AOF（Append Only File）. 1. RDBRDB是redis默认的持久化方案, 当满足一定条件后, 会把当前内存中的数据写入到磁盘中, 生成一个快照文件dump.rdb. redis 重启会通过加载dump.rdb 文件恢复数据. 那什么时候写入dump.rdb 文件呢? 1.1 RDB触发1.1.1 自动触发1.1.1.1 配置规则触发redis.conf 配置文件中的SNAPSHOTTING 定义了触发把数据保存到磁盘的触发频率. 如果不需要RDB 方案, 注释save 或者配置成空字符串”” save 900 1 # 900 秒内至少有一个 key 被修改（包括添加） save 300 10 # 400 秒内至少有 10 个 key 被修改 save 60 10000 # 60 秒内至少有 10000 个 key 被修改 注意上面的配置是不冲突的, 只要任一一个满足都会触发的. RDB 文件位置和目录 # 文件路径， dir ./ # 文件名称 dbfilename dump.rdb # 是否是 LZF 压缩 rdb 文件 rdbcompression yes # 开启数据校验 rdbchecksum yes 参数 说明 dir rdb 文件默认在启动目录下（相对路径）config get dir 获取 dbfilename 文件名称 rdbcompression 开启压缩可以节省存储空间，但是会消耗一些 CPU 的计算时间，默认开启 rdbchecksum 使用 CRC64 算法来进行数据校验，但是这样做会增加大约 10%的性能消耗，如果希望获取到最 大的性能提升，可以关闭此功能。 1.1.1.2 shutdonw 触发,保证服务器正常关闭 1.1.1.3 flushall触发``RDB`文件里面是空的, 没什么意义 1.1.2 手动触发如果我们需要重启服务或者迁移数据, 这个时候就需要手动触发RDB快照保存。redis 提供了两条命令: save save在生成快照的时候会阻塞当前的redis服务器, redis 不能处理其他的命令。 如果内存中的数据比较多, 会造成redis 长时间的阻塞。 生产环境不建议使用这个命令. 为了解决这个问题, redis 提供了第二种方式 bgsave 执行bgsave 的时候, redis会在后台异步进行快照操作, 快照同时还可以响应客户端的请求. 具体操作是redis 进程fork 操作系统子进程(copy-on-write),RDB 持久化过程由子进程负责, 完成后自动结束. 他不会记录fork 之后后续的命令. 阻塞只发生在fork 阶段, 一般时间很短. 用lastsave 命令可以查看最近一次生成快照的时间 1.2 RDB数据的恢复(演示)1.2.1 shutdown 持久化 添加键值 redis> set k1 1 redis> set k2 2 redis> set k3 3 redis> set k4 4 redis> set k5 5 停止服务器 ，触发save redis> shutdown 备份:dump.rdb 文件 cp dump.rdb dump.rdb.bak 启动服务器 /usr/local/soft/redis-5.0.5/src/redis-server /usr/local/soft/redis-5.0.5/redis.conf 数据都在 redis> keys * 1.2.2 模拟数据丢失模拟数据丢失,触发save redis> flushall 停服务器 redis> shutdown 启动服务器 /usr/local/soft/redis-5.0.5/src/redis-server /usr/local/soft/redis-5.0.5/redis.conf 结果： 啥都没有 redis> keys * 1.2.3 通过备份文件恢复数据停止服务器 redis> shutdown 重命名备份文件 mv dump.rdb.bak dump.rdb 启动服务器 /usr/local/soft/redis-5.0.5/src/redis-server /usr/local/soft/redis-5.0.5/redis.conf 查看服务器 redis> keys * 1.3 RDB 文件的优势和劣势1.3.1 优势 RDB 是一个非常紧凑(compact)的文件, 他保存了redis在某个时间点上的数据集, 这种文件非常适合于进行备份和灾难恢复. 生成RDB 文件的时候, redis主进程会fork一个子进程来处理所有的保存工作, 主进程不需要进行进行任何磁盘I/O 工作. RDB在恢复大数据集时的速度比AOF 的恢复速度要快. 1.3.2 劣势 RDB 方式数据没办法做到实时持久化/秒级持久化. 因为bgsave 每次运行都要执行fork 操作创建子进程, 频繁执行成本过高 . 在一定间隔时间做一次备份, 所以如果redis 意外down 掉的话， 就会丢失掉最后一次快照之后的所有修改(数据又丢失) 如果数据相对来说比较重要，希望将损失降到最低, 则可以使用AOF 方式进行持久化. 2. AOFAppend Only File AOF: redis默认不开启.AOF 采用日志的形式来记录每个写操作, 并追加到文件中. 开启后, 执行更改redis数据的命名时, 就会把命令追加到AOF 文件中. redis 重启的时候 会根据日志文件的内容把写命令从前到后执行一次以完成数据的恢复工作. 2.1 AOF 配置配置文件redis.conf # 开关 appendonly no # 文件名 appendfilename \"appendonly.aof 参数 说明 appendonly Redis 默认只开启 RDB 持久化，开启 AOF 需要修改为 yes appendfilename &quot;appendonly.aof&quot; 路径也是通过 dir 参数配置 config get dir **问题：数据都是实时持久化到磁盘吗? ** 由于操作系统的缓存机制, AOF 数据并没有真正的写入到磁盘, 而是进入了系统的硬盘缓存. 什么时候把缓冲区的内容写入到AOF 文件? appendfsync everysec 参数说明 AOF 持久化策略（硬盘缓存到磁盘），默认 everysec no 表示不执行 fsync，由操作系统保证数据同步到磁盘，速度最快，但是不太安全； always 表示每次写入都执行 fsync，以保证数据同步到磁盘，效率很低； everysec 表示每秒执行一次 fsync，可能会导致丢失这 1s 数据。通常选择 everysec ， 兼顾安全性和效率。 **文件越来越大怎么办? ** 由于AOF 持久化是redis 不断的将命令记录到AOF 文件中, 随着redis 不断的进行, AOF 的文件会越来越大 ,文件越大, 占用服务器内存越大以及AOF 恢复要求的时间越长. 例如set test 666 ,执行了1000次, 结果都是test = 666 为了解决这个问题, Redis 新增了重写机制, 当AOF 的文件超过大小所设定的阈值的时候, redis 就会启动AOF 文件的内容压缩, 只保留可以恢复的数据的最小指令集. 可以使用命令bgrewriteaof 来重写. AOF 文件重写并不是对原文件进行重写整理, 而是直接读取服务器现有的键值对, 然后用一条命令去代替之前记录这个键值对的多条命令, 生成一个新的文件去替换原来的AOF 文件. # 重写触发机制 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb 参数 说明 auto-aof-rewrite-percentag e 默认值为 100。aof 自动重写配置，当目前 aof 文件大小超过上一次重写的 aof 文件大小的 百分之多少进行重写，即当 aof 文件增长到一定大小的时候，Redis 能够调用 bgrewriteaof 对日志文件进行重写。当前 AOF 文件大小是上次日志重写得到 AOF 文件大小的二倍（设 置为 100）时，自动启动新的日志重写过程。 auto-aof-rewrite-min-size 默认64M, 设置允许重写的最小aof 文件大小, 避免到了约定百分比但尺寸仍然很小的情况下还要重写. **重写过程中, AOF 文件被修改了怎么办呢? ** 另外有两个与AOF 相关的参数: no-appendfsync-on-rewrite 在aof 重写或者写入rdb 文件的时候, 会执行大量IO, 此时对于everysec 和always 的aof 模式来说, 执行fsync 会造成阻塞过长时间, no-appendfsync-on-rewrite 字段设置为默认设置为no.如果对延迟要求很高的应用, 这个字段可以设置为yes, 否则还是设置为no, 这样对持久化特性来说这是更安全的选择, 设置为yes 表示rewrite 期间对新写操作不fsync,暂时存在内存中,等rewrite 完成后在写入, 默认为no, 建议修改为yes. linux 的默认fsync 的策略是30秒, 所以可能会丢失30秒的数据. aof-load-truncated aof 文件可能在尾部是不完整的, 当redis 启动的时候, aof文件的数据被载入到内存中. 重启可能会发生在redis 所在的主机操作系统宕机后, 尤其是ext4 文件系统没有加上data=ordered 选项, 出现这种现象 . redis 宕机或者出现异常终止不止会造成尾部不完整现象, 可以选择让redis退出或者导入尽可能多的数据. 如果选择的是yes ,当截断的aof 文件被导入的时候, 会自动发布一个log给客户端然后load, 如果是no, 用户必须手动redis-check-aof 修复aof 文件才可以, 默认为yes. 2.2 AOF 数据恢复重启redis之后就会进行AOF 文件的恢复. 2.3 AOF 优势和劣势2.3.1 优势 AOF 持久化的方法提供了多种的同步频率, 即时使用默认的同步频率每秒同步一次, redis 最多也就丢失一秒的数据. 2.3.2 缺点 对于具有相同数据的redis, AOF 文件通常会比RDB 文件提交更大(RDB文件存的是数据快照) 虽然AOF 提供了多种同步的频率, 默认情况下, 每秒同步一次的频率也是具有较高的性能. 在高并发的情况下, RDB 比AOF 具有更好的性能保证. 3. 两种方案比较那么对于AOF 和RDB 这两种持久化方式, 我们应该如何做选择呢? 如果能够忍受一小段时间内数据的丢失, 毫无疑问是RDB 最好了.定时生成RDB 快照(snapshot) 非常便于进行数据库备份, 并且RDB 恢复数据集的速度也是要比AOF 恢复的速度要快. 否则就使用AOF 重写, 但是一般情况下不建议单独使用一种持久化方式, 而是应该两种一起用, 在这种情况下, 当redis 重启的时候会优先载入AOF 文件来恢复原始的数据, 因为在通常的情况下AOF 文件保存的数据集要比RDB 文件保存的数据集要完整.","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis基础(1)","slug":"redis/redis基础(1)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-ji-chu-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-ji-chu-1/","excerpt":"","text":"redis基础本节,基于Redis最新版本5.05 进行讲解. 1. Redis入门1.1 Redis的诞生历程1.1.1 从一个故事说起 08年的时候, 有一个意大利西西里岛的小伙子, 笔名 antirez（http://invece.org/）,创建了一个访客信息网站`LLOOGG.COM`. 有的时候我们需要知道访客的访问情况, 比如访客的ip、操作系统、浏览器、使用的搜索关键词、所在地区、访问的网页地址等等. 在国内, 有很多网站提供了这些功能,比如CNZZ、百度统计,国外也有谷歌的Google Analytics.我们不需要自己写代码去实现这个功能, 只需要在全局的footer 里面嵌入一段js代码就可以了, 当页面被访问的时候, 就会自动的把访客的信息发送到这些网站的服务器, 然后我们登陆后台就可以查看数据. ​ LLOOGG.COM 提供的就是这些功能, 他可以查看最多10000条的最新的访客记录. 这样的话，他需要为每个网站创建一个列表(List), 不同网站的访问记录进入到不同的列表。如果列表的长度超过了用户指定的长度, 他需要把最早的记录删除(先进先出). ​ ​ 当LLOOGG.COM的用户越来越多的时候, 他需要维护的列表数量也越来越多, 这种记录最新的请求和删除最早的请求的操作也越来越多。 LLOOGG.COM最初使用的数据库是MYSQL, 可想而知, 因为每一次记录和删除都要读写磁盘,因为数据量和并发量太大, 在这种情况下无论怎么去优化数据库都不管用了. ​ 考虑到最终限制数据库性能的瓶颈在于磁盘,所以antirez 打算放弃磁盘, 自己去实现一个具有列表结构的数据库的原型, 把数据放在内存里面而不是磁盘, 这样可以大大的提高列表的push和pop的效率. antirez 发现这种思路确实能解决这个问题, 所以用C语言重写了这个内存数据库, 并且加上了持久化的功能, 09年的时候,Redis 横空出世了. 从最开始只支持列表的数据库，到现在支持多种数据类型，并且提供了一系列的高级特性,Redis 已经成为了一个在全世界广泛使用的开源项目. ​ 为什么叫REDIS呢? 他的全称是REmote DIctionary Service， 直接翻译过来就是 远程字典服务. ​ 从Redis 的诞生历程我们可以看到, 在某些场景中, 关系型数据库并不适合存储我们的web应用的数据. 那么,关系型数据库和非关系型数据库, 或者说SQL 和NoSQL 到底有什么不一样呢? 1.2 Redis 的定位和特性.1.2.1 SQL和NoSQL​ 在绝大部分的场景中, 我们都会首先考虑使用关系型数据库来存储我们的数据， 比如SQLServer,Oracle、MySQL等等. ​ 关系型数据库的特点: 他以表格的形式,基于行存储数据, 是一个二维的模式. 他存储的是结构化的数据, 数据存储有固定的模式(schema), 数据需要使用表结构. 表与表之间存在关联(Relationship). 大部分关系型数据库都支持SQL(结构化查询语言)的操作, 支持复杂的关联查询 通过支持事务(ACID)来提供严格或者实时的数据一致性. 使用关系型数据库也有一些限制, 比如: 要实现扩容的话，只能实现向上(垂直)扩容,比如磁盘限制了数据的存储, 就要扩大磁盘容量,通过堆硬件的方式,不支持动态的扩缩容. 水平扩容需要复杂的技术来实现, 比如: 分库分表. 表结构修改困难,因此存储的数据格式受到限制. 在高并发和高数据量的情况下,我们的关系型数据库通常会把数据持久化到磁盘, 基于磁盘的读写压力比较大. 为了规避关系型数据库的一系列问题, 我们就有了非关系型数据库,我们一般把他叫做non-relational 或者Not Only SQL , NoSQL 最开始是不提供SQL的数据库, 但是后来意思就慢慢的发生了变化. ​ 非关系型数据库的特点: 存储非结构化的数据, 比如文本、图片、音频、视频. 表与表之间没有关联, 可扩展性强. 保证数据的最终一致性. 遵循 BASE（碱）理论。 Basically Available（基本 可用）； Soft-state（软状态）； Eventually Consistent（最终一致性）。 支持海量数据的存储和高并发的高效读写. 支持分布式, 能够对数据进行分片存储, 扩缩容简单. 对于不同的存储类型,我们又有各种各样的非关系型数据库, 比如有几种常见的类型: KV存储, 用Key Value的形式来存储数据, 比较常见的有: Redis和MemcacheDB。 文档存储, 比如MongoDB。 列存储, HBase。 图存储，这个图（Graph）是数据结构，不是文件格式。Neo4j。 对象存储 xml存储等等. 这个网页列举了各种各样的NoSQL 数据库http://nosql-database.org/ NewSQL 集合了SQL和NoSQL的特性, 比如PingCAP 的 TiDB 1.2.2 Redis的特性官网, 中文官网 硬件层面有CPU的缓存, 浏览器也有缓存, 手机的应用里面也有缓存. 我们把数据缓存起来的原因就是从原始位置取数据的代价太大了, 放在一个临时的位置存储起来, 取回就可以快一些。 Redis的特性: 更丰富的数据类型 进程内和跨进程, 单机与分布式. 功能丰富: 持久化机制, 过期策略. 支持多种编程语言. 高可用, 集群. 1.3 Redis的安装启动1. 拉取容器 docker pull redis:4.0 2. 查看本地容器 docker images 3. 启动docker run --name redis -p 6379:6379 -v $PWD/data:/data -d --restart=always redis:4.0 r 1.4 redis的基本操作redis默认有16个库(0-15), 可以在配置文件中修改，默认使用第一个db0 databases 16 命令 作用 select 0 切换数据库 flushdb 清空当前数据库 flushall 清空所有数据库 key * 查看所有键 dbsize 获取总键数 del key 删除key rename key1 key2 重命名key1为key2 type key 查看类型 exists key 查看键是否存在 1.5 Redis的基本数据类型Redis 一共有几种数据类型呢? 官网 String、Hash、Set、List、Zset、Hyperloglog、Geo、Streams 参考资料http://redisbook.com/ https://github.com/antirez/redis","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis基本类型之zset(6)","slug":"redis/redis基本类型之zset(6)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-ji-ben-lei-xing-zhi-zset-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-ji-ben-lei-xing-zhi-zset-6/","excerpt":"","text":"redis基本类型之zsetzset是一个有序的不重复集合 1操作命令| zadd key [NX|XX] [CH] [INCR] score member [score member…] | ZADD 参数（options） (&gt;= Redis 3.0.2)ZADD 命令在key后面分数/成员（score/member）对前面支持一些参数，他们是：XX: 仅仅更新存在的成员，不添加新成员。NX: 不更新存在的成员。只添加新成员。CH: 修改返回值为发生变化的成员总数，原始是返回新添加成员的总数 (CH 是 changed 的意 思)。 | 在通常情况下，ZADD返回值只计算新添加成员的数量。 || ————– | ——————————————– | —- || ZINCRBY key increment member | 对有序集合中指定成员的分数加上增量 increment可以通过传递一个负数值 increment ，让分数减去相应的值，比如 ZINCRBY key -5 member ，就是让 member 的 score 值减去 5当 key 不存在，或分数不是 key 的成员时， ZINCRBY key increment member 等同于 ZADD key increment member 。分数值可以是整数值或双精度浮点数。 | || zrange key start stop [WITHSCORES] | 查询有序集合，指定区间的内的元素。集合成员按 score 值从小到大来排序。start，stop 都是 从 0 开始。0 是第一个元素，1 是第二个元素，依次类推。以 -1 表示最后一个成员，-2 表示倒数第二 个成员。WITHSCORES 选项让 score 和 value 一同返回。 | 自定区间的成员集合 || zrevrange key start stop [WITHSCORES] | 返回有序集 key 中，指定区间内的成员。其中成员的位置按 score 值递减(从大到小)来排列。 其它同 zrange 命令。 | 自定区间的成员集合 || zrem key member [member…] | 删除有序集合 key 中的一个或多个成员，不存在的成员被忽略 | 被成功删除的成员数量，不包括被忽略的成员。 || zcard key | 获取有序集 key 的元素成员的个数 | key 存在返回集合元素的个数， key 不存在，返回 0 || zrangebyscore key min max [WITHSCORES ] [LIMIT offset count] | 获取有序集 key 中，所有 score 值介于 min 和 max 之间（包括 min 和 max）的成员，有序 成员是按递增（从小到大）排序。min ,max 是包括在内 ， 使用符号 ( 表示不包括。min ， max 可以使用 -inf ，+inf 表示 最小和最大 limit 用来限制返回结果的数量和区间。withscores 显示 score 和 value | 指定区间的集合数据 || zrevrangebyscore key max min [WITHSCORES ] [LIMIT offset count] | 返回有序集 key 中， score 值介于 max 和 min 之间(默认包括等于 max 或 min )的所有的成 员。有序集成员按 score 值递减(从大到小)的次序排列。其他同 zrangebyscore | || zcount key min max | 返回有序集 key 中， score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max ) 的成员的数量 | | 2存储类型 sorted set，有序的 set，每个元素有个 score。 score 相同时，按照 key 的 ASCII 码排序。 数据结构对比： 数据结构 是否允许重复元素 是否有序 有序实现方式 list 是 是 索引下标 set 否 否 无 zset 否 是 分值 score 3存储(实现)原理同时满足以下条件的时候使用ziplist 编码 元素的数量小于128个 所有member的长度都小于64字节 在ziplist 的内部, 按照score 排序递增来存储。 插入的时候要移动之后的数据 对应 redis.conf 参数： zset-max-ziplist-entries 128 zset-max-ziplist-value 64 超过阈值后, 使用 skiplist + dict存储 问题: 什么是skiplist（跳跃表） 我们先来看一下有序链表 在这样的一个链表中, 如果我们要查找某个数据, 那么需要从头开始逐个进行比较， 直到找到包含数据的那个节点, 或者找到第一个比给定数据大的节点(没找到), 也就是说, 时间复杂度为O(n). 同样 , 当我们要插入新的数据的时候, 也要经历同样的查找过程, 而从确定插入的位置. 而二分查找法只适用于有序数组, 不适用于链表 假设我们每相邻的两个节点增加一个指针(或者理解为有三个元素进入了第二层), 让指针指向下下个节点. 这样所有新增加的指针连成了一个新的链表 ,但他所包含的节点个数只有原来的一半（上图中是 7, 19, 26）。在插入一个数据的时候, 决定要放在那一层, 取决于一个算法（在 redis 中 t_zset.c 有一个 zslRandomLevel 这个方法）。 现在当我们想查找数据的时候, 可以先沿着这个新的链表进行查找。当碰到比待查找的数据大的节点的时候, 再回到原来的链表中的下一层进行查找. 比如: 当我们想查找23, 查找的路径是沿着下图中标红的指针所指向的方法进行的. 23 首先和7比较, 再和19比较, 比他们都大, 继续向后比较. 但23和26比较的时候, 比26要小, 因此回到下面的链表(原链表), 与22 比较. 23要比22大, 沿着下面的指针继续向后和26比, 23比26小, 说明待查询的数据23 在原链表中不存在. 在这个查找的过程中, 由于新增加的指针, 我们不再需要与链表中的每个元素逐个进行比较, 需要比较的节点数大概只有原来的一半, 这就是跳跃表 . 为什么不用AVL树或者红黑树? 因为skiplist 更加简洁. 源码: server.h typedef struct zskiplistNode &amp;#123; sds ele; /* zset 的元素 */ double score; /* 分值 */ struct zskiplistNode *backward; /* 后退指针 */ struct zskiplistLevel &amp;#123; struct zskiplistNode *forward; /* 前进指针，对应 level 的下一个节点 */ unsigned long span; /* 从当前节点到下一个节点的跨度（跨越的节点数） */ &amp;#125; level[]; /* 层 */ &amp;#125; zskiplistNode; typedef struct zskiplist &amp;#123; struct zskiplistNode *header, *tail; /* 指向跳跃表的头结点和尾节点 */ unsigned long length; /* 跳跃表的节点数 */ int level; /* 最大的层数 */ &amp;#125; zskiplist; typedef struct zset &amp;#123; dict *dict; zskiplist *zsl; &amp;#125; zset; 随机获取层数的函数 源码：t_zset.c int zslRandomLevel(void) &amp;#123; int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL; &amp;#125; 4应用场景排行榜id 为 6001 的新闻点击数加 1：zincrby hotNews:20190926 1 n6001 获取今天点击最多的 15 条：zrevrange hotNews:20190926 0 15 withscores","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis基本类型之set(5)","slug":"redis/redis基本类型之set(5)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-ji-ben-lei-xing-zhi-set-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-ji-ben-lei-xing-zhi-set-5/","excerpt":"","text":"redis基本类型之set1存储类型:String类型 无序不重复集合， 最多可以存储2^32-1(40亿左右) 2操作命令 sadd key member [member…] 将一个或者多个member 元素添加到集合key中 返回添加元素的个数 smembers key 获取集合中所有的成员元素 sismember key member 判断 member 是集合key 的成员 是则返回1, 不是则返回0 scard key 获取集合中成员的个数 成员个数 srem key member [member…] 删除集合中一个或者多个member 元素,不存在的成员则被忽略 返回成功删除的成员的个数 srandmember key [count] 随机返回一个元素, 元素不会被删除提供了 count时，count 正数, 返回包含 count 个数元素的集合， 集合元素各不相同。count 是负数，返回一个 count 绝对 值的长度的集合， 集合中元素可能会重复多次。 一个元素；多个元素的集合 spop key [count] 随机从集合中删除一个元素, count 是删除的元素个数。 被删除的元素，key 不存在或空集合返回 nil 3存储(实现)原理Redis 使用 intset 或者hashtable存储set, 如果元素都是整型类型， 则使用intset存储, 如果不是整数类型，则使用hashtable (数组+链表的结构)存储. 问题: KV怎么存储set的元素? key是元素的值? value为null. 如果元素个数超过512个, 也会用hashtable 存储 . 配置文件 redis.conf set-max-intset-entries 512 127.0.0.1:6379> sadd iset 1 2 3 4 5 6 (integer) 6 127.0.0.1:6379> object encoding iset \"intset\" 127.0.0.1:6379> sadd myset a b c d e f (integer) 6 127.0.0.1:6379> object encoding myset \"hashtable\" 4应用场景抽奖随机获取元素 点赞、签到、打卡 这条微博的 ID 是 t1001，用户 ID 是 u3001。 用 like:t1001 来维护 t1001 这条微博的所有点赞用户。 点赞了这条微博：sadd like:t1001 u3001 取消点赞：srem like:t1001 u3001 是否点赞：sismember like:t1001 u3001 点赞的所有用户：smembers like:t1001 点赞数：scard like:t1001 比关系型数据库简单许多。 商品标签用 tags:i5001 来维护商品所有的标签。 sadd tags:i5001 画面清晰细腻 sadd tags:i5001 真彩清晰显示屏 sadd tags:i5001 流畅至极","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis基本类型之hash(3)","slug":"redis/redis基本类型之hash(3)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-ji-ben-lei-xing-zhi-hash-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-ji-ben-lei-xing-zhi-hash-3/","excerpt":"","text":"redis基本类型之hash 1存储类型包含键值对的无序散列表, value只能是字符串, 不能嵌套其他类型. 同样是存储字符串, Hash与String有什么区别呢? 把所有相关的值都聚集到一个key中, 节省内存空间. 只使用一个key, 减少key冲突. 当需要批量获取值的时候, 只需要使用一个命令,减少内存/IO/CPU 的消耗. **Hash不适用的场景: ** Field不能单独设置过期时间 没有bit操作 需要考虑数据量分布的问题(value值非常大的时候, 无法分不到多个节点) 2操作命令 hset key field value 设置值, 如果key不存在, 则新建, 如果field存在, 则覆盖 如果field不存在, 返回1, 如果存在, 覆盖并返回0 hget key field 根据指定key 和field 获取值 如果field不存在返回null hmset key field value [field value„] 将多个 field value设置到哈希表的key中 成功返回”ok”,否则异常 hmget key field [field„] 获取指定key中多个 field 的值 返回指定的值 hgetall key 根据key 获取所有的field和value 返回列表 hdel key field [field„] 根据key和field列表删除指定的值 返回删除的数量 hkeys key 查看指定key 的所有field 返回列表 hvals key 查看指定key 的所有value值 返回value值的列表 hexists key field 查看指定key 的指定field是否存在 存在返回1, 不存在返回0 3存储(实现)原理Redis的Hash本身也是一个KV的结构, 类似于java中的HashMap 外层的哈希(Redis KV 的实现), 只用到了hashtable.当存储hash数据类型的时候, 我们把他叫做内层的哈希, 内层的哈希有两种数据结构的实现. ziplist OBJ_ENCODING_ZIPLIST 压缩列表 hashtable OBJ_ENCODING_HT 哈希表 127.0.0.1:6379> hset h2 f aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa (integer) 1 127.0.0.1:6379> hset h3 f aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa (integer) 1 127.0.0.1:6379> object encoding h2 \"ziplist\" 127.0.0.1:6379> object encoding h3 \"hashtable\" ziplist 压缩列表ziplist 压缩列表是什么? /* ziplist.c 源码头部注释 */ The ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. However, because every operation requires a reallocation of the memory used by the ziplist, the actual complexity is related to the amount of memory used by the ziplist. ziplist 是一个经过特殊编码的双向链表, 他不存储指向上一个链表节点和指向下一个链表节点的指针,而是存储上一个链表节点的长度和当前节点的长度, 通过牺牲部分的读写性能, 来换取高效的内存空间利用率, 是一种时间换空间的思想. 只用在字段个数少, 字段值小的场景中. ziplist的内部结构?ziplist.c 源码第 16 … typedef struct zlentry &amp;#123; unsigned int prevrawlensize; /* 上一个链表节点占用的长度 */ unsigned int prevrawlen; /* 存储上一个链表节点的长度数值所需要的字节数 */ unsigned int lensize; /* 存储当前链表节点长度数值所需要的字节数 */ unsigned int len; /* 当前链表节点占用的长度 */ unsigned int headersize; /* 当前链表节点的头部大小（prevrawlensize + lensize），即非数据域的大小 */ unsigned char encoding; /* 编码方式 */ unsigned char *p; /* 压缩链表以字符串的形式保存，该指针指向当前节点起始位置 */ &amp;#125; zlentry; 编码 encoding（ziplist.c 源码第 204 行） #define ZIP_STR_06B (0 &lt;&lt; 6) //长度小于等于 63 字节 #define ZIP_STR_14B (1 &lt;&lt; 6) //长度小于等于 16383 字节 #define ZIP_STR_32B (2 &lt;&lt; 6) //长度小于等于 4294967295 字节 问题: 什么实时使用 ziplist存储当hash 的对象同时满足以下两个条件的时候, 使用ziplist 编码 所有的键值对的键和值的字符串长度都小于等于64byte(一个英文字母一个字节) 哈希对象中保存的键值对数量小于512个 /* src/redis.conf 配置 */ hash-max-ziplist-value 64 // ziplist 中最大能存放的值长度 hash-max-ziplist-entries 512 // ziplist 中最多能存放的 entry 节点数量 /* 源码位置：t_hash.c ，当达字段个数超过阈值，使用 HT 作为编码 */ if (hashTypeLength(o) > server.hash_max_ziplist_entries) hashTypeConvert(o, OBJ_ENCODING_HT); /*源码位置： t_hash.c，当字段值长度过大，转为 HT */ for (i = start; i &lt;= end; i++) &amp;#123; if (sdsEncodedObject(argv[i]) &amp;&amp; sdslen(argv[i]->ptr) > server.hash_max_ziplist_value) &amp;#123; hashTypeConvert(o, OBJ_ENCODING_HT); break; &amp;#125; &amp;#125; 一个哈希长度超过配置的阈值(键和值的长度有&gt;64byte,键值对小于512个)时, 会转换成 哈希表(hashtable) hahstable(dict)再Redis中, hashtabl 被称之为字典(dictionary),他是一个数组+链表的结构. 源码位置：dict.h 我们知道, Redis 的KV结构是通过一个dictEntry 来实现的. Redis 又对dictEntry 进行了多层封装. typedef struct dictEntry &amp;#123; void *key; /* key 关键字定义 */ union &amp;#123; void *val; uint64_t u64; /* value 定义 */ int64_t s64; double d; &amp;#125; v; struct dictEntry *next; /* 指向下一个键值对节点 */ &amp;#125; dictEntry; dictEntry 放到了dictht(hashtable里面) /* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */ typedef struct dictht &amp;#123; dictEntry **table; /* 哈希表数组 */ unsigned long size; /* 哈希表大小 */ unsigned long sizemask; /* 掩码大小，用于计算索引值。总是等于 size-1 */ unsigned long used; /* 已有节点数 */ &amp;#125; dictht; ht 放到了dict 里面. typedef struct dict &amp;#123; dictType *type; /* 字典类型 */ void *privdata; /* 私有数据 */ dictht ht[2]; /* 一个字典有两个哈希表 */ long rehashidx; /* rehash 索引 */ unsigned long iterators; /* 当前正在使用的迭代器数量 */ &amp;#125; dict; 从最底层到最高层: dictEntry -&gt; dictht -&gt; dict -&gt; OBJ_ENCODING_HT 总结: 哈希的存储结构 注意: dictht后面是NULL 说明第二个ht 还没有用到. dictEntry* 后面是NULL 说明还没有hash到这个位置, dictEntry 后面是NULL 说明没有发生 hash冲突. 为什么要定义两个哈希表呢? ht[2]redis的hash默认使用的是ht[0],ht[1] 是不会初始化和分配空间的. 哈希表dictht 是用链地址法来解决碰撞问题的. 在这种清空下, 哈希表之间的性能取决于他的大小(size属性), 和他所保存的节点的数量(used属性)之间的比率: 比率在1:1 时(一个哈希ht只存储一个节点entry),哈希表的性能最好 如果节点数量比哈希表的大小要大很多的时候(这个比例用ratio 表示, 5表示平均一个ht 存储5个Entry ),那么哈希表就会退化为多个链表, 哈希表本身的性能优势就不再存在. 在这种情况下, 需要扩容, Redis里面的这种操作就叫做rehash. rehash的步骤 为字符ht[1] 哈希表分配空间, 这个哈希表的空间大小取决于要执行的操作, 以及ht[0] 当前包含的键值对的数量 扩展: ht[1] 的大小为第一个大于等于ht[0].used*2 将所有的ht[0] 上的节点rehash到ht[1] 上, 重新计算hash 值和索引, 然后放入指定的位置. 将ht[0] 全部迁移到ht[1]之后, 释放ht[0] 的空间, 将ht[1] 设置为 ht[0] 表, 并创建新的 ht[1], 为下次rehash 做准备 . 什么时候触发扩容负载因子(（源码位置：dict.c): static int dict_can_resize = 1; static unsigned int dict_force_resize_ratio = 5; ratio = used / size: 已经使用的节点于字节大小的比例 dict_can_resize为1并且dict_force_resize_ratio 已使用字节树和字典大小之间的比率超过1:5, 触发扩容. 扩容判断_dictExpandIfNeeded（源码 dict.c） if (d->ht[0].used >= d->ht[0].size &amp;&amp; (dict_can_resize || d->ht[0].used/d->ht[0].size > dict_force_resize_ratio)) &amp;#123; return dictExpand(d, d->ht[0].used*2); &amp;#125; return DICT_OK; 扩容方法 dictExpand（源码 dict.c） /* Expand or create the hash table */ int dictExpand(dict *d, unsigned long size) &amp;#123; /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ if (dictIsRehashing(d) || d->ht[0].used > size) return DICT_ERR; dictht n; /* the new hash table */ unsigned long realsize = _dictNextPower(size); /* Rehashing to the same table size is not useful. */ if (realsize == d->ht[0].size) return DICT_ERR; /* Allocate the new hash table and initialize all pointers to NULL */ n.size = realsize; n.sizemask = realsize-1; n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; /* Is this the first initialization? If so it's not really a rehashing * we just set the first hash table so that it can accept keys. */ if (d->ht[0].table == NULL) &amp;#123; d->ht[0] = n; return DICT_OK; &amp;#125; /* Prepare a second hash table for incremental rehashing */ d->ht[1] = n; d->rehashidx = 0; return DICT_OK; &amp;#125; 缩容: 源码: server.c int htNeedsResize(dict *dict) &amp;#123; long long size, used; size = dictSlots(dict); used = dictSize(dict); return (size > DICT_HT_INITIAL_SIZE &amp;&amp; (used*100/size &lt; HASHTABLE_MIN_FILL)); &amp;#125; 4应用场景StringString能做的事情， hash都能做。 存储对象类型的数据比如对象或者一张表的数据, 比String 节省了更多的key空间, 也更加便于集中管理. 购物车 key：用户 id；field：商品 id；value：商品数量。 +1：hincr。-1：hdecr。删除：hdel。全选：hgetall。商品数：hlen。","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis基本类型之String(2)","slug":"redis/redis基本类型之String(2)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-ji-ben-lei-xing-zhi-string-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-ji-ben-lei-xing-zhi-string-2/","excerpt":"","text":"Redis String类型Redis 最基本的数据类型就是String, 为什么叫Binary-safe strings呢? 1 存储类型可以用来存储字符串、整数、浮点数 2 操作命令 set key value 设置值 get key 取值 mset key1 value1 key2 value2 设置多个值,(批量操作,原子性) setnx key vaue 设置值, 如果key存在, 则不成功,基于此可以实现分布式锁, 用 del key 释放锁, set key value [expiration EX seconds PX milliseconds][NX 使用多参数的方式执行, set lock1 1 EX 10 NX incr key incrby key 100 （整数）值递增 decr key decrby key 100 （整数）值递减 set f 2.6 incrbyfloat f 7.3 浮点数增量 mget key1 key2 获取多个值 strlen key 获取值长度 append key value 字符串追加内容 getrange key 0 8 获取指定范围的字符 3存储实现原理4数据模型​ set Hello World 为例, 因为Redis 是KV的数据库, 他是通过hashtable 实现的(我们把这个叫做外层的哈希).所以每个键值对都会有一个dictEntry(源码位置:dict.h),里面指向了key和value 的指针. next 指向下一个 dictEntry typedef struct dictEntry &amp;#123; void *key; // key 关键字定义 union &amp;#123; void *val; // value定义 uint64_t u64; int64_t s64; double d; &amp;#125; v; struct dictEntry *next; // 指向下一个键值对节点 &amp;#125; dictEntry; key是字符串, 但是redis 并没有直接使用C的字符数组, 而是存储在自定义的SDS中. ​ value 既不是直接作为字符串存储,也不是直接存储在SDS中, 而是存储在redisObject中。 实际上五种常用的数据类型的任何一种,都是通过redisObject来存储的. redisObjectredisObject 定义在src/server.h文件中 #define OBJ_SHARED_REFCOUNT INT_MAX typedef struct redisObject &amp;#123; unsigned type:4;// 对象的类型, 包括OBJ_STRING、OBJ_LIST、OBJ_HASH、OBJ_SET、OBJ_ZSET unsigned encoding:4;// 具体的数据结构 unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ // 24位, 对象最后一次被明明程序访问的时间,与内存回收有关. int refcount; // 引用计数, 当refcount 为0 的时候,表示该对象已经不被任何对象引用, 则可以进行垃圾回收了. void *ptr; // 指向对象实际的数据结构 &amp;#125; robj; 可以使用type命令来查看对外的类型 内部编码 字符串类型的内部编码有三种: int, 存储8个字节的长整型(long , 2^63-1) embstr, 代表embstr格式的SDS(Simple Dynamic String 简单动态字符串),存储小于44个字节的字符串 raw, 存储大于44个字节的字符串(3.2版本之前是39字节. ) /* object.c */ #define OBJ_ENCODING_EMBSTR_SIZE_LIMIT 44 5常见问题问题1: 什么是SDSRedis 中字符串的实现, 在3.2以后的版本中, SDS 又有多种数据结构(sds.h), sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64,用于存储不同长度的字符串, 分别代表 2^5=32byte， 2^8=256byte，2^16=65536byte=64KB，2^32byte=4GB /* sds.h */ struct __attribute__ ((__packed__)) sdshdr8 &amp;#123; uint8_t len; /* 当前字符数组的长度 */ uint8_t alloc; /*当前字符数组总共分配的内存大小 */ unsigned char flags; /* 当前字符数组的属性、用来标识到底是 sdshdr8 还是 sdshdr16 等 */ char buf[]; /* 字符串真正的值 */ &amp;#125;; 问题2： 为什么Redis 要使用SDS 实现字符串我们知道, C语言本身没有字符串类型(只能使用字符数组char[]来实现) 使用字符数组必须先给目标数组分配足够的空间,否则可能会溢出. 如果要获取字符长度, 必须遍历字符数组, 时间复杂度为O(n) C字符串长度的变更会对字符数组做内存重分配. 通过从字符串开始到结尾碰到的第一个 ‘\\0’来标记字符结束 , 因此不能保存图片、音频、视频、压缩文件等二进制(bytes)保存的内容, 二进制不安全. SDS的特点: 不用担心内存溢出问题, 如果需要会对SDS进行扩容. 获取字符串长度时间复杂度为O(1), 因为定义了 len属性 通过”空间预分配”（ sdsMakeRoomFor）和“惰性空间释放”,防止多次重分配内存. 判断是否结束的标志是len属性(它同样以’\\0’结尾是因为这样就可以使用 C语言中函数库操作字符串的函数了），可以包含’\\0’。 C字符串 SDS 获取字符串长度的时间复杂度为O(n) 获取字符串的时间复杂度为O(1) API是不安全的, 可能会造成缓存区溢出 API是安全的, 不会造成缓存区溢出 修改字符串长度N次必然需要执行N次内存重分配 修改字符串N次最多需要执行N次内存重分配 只能保存文本数据 可以保存文本或者二进制数据 可以使用&lt;string.h&gt; 库中的全部函数 可以使用&lt;string.h&gt; 库中的部分函数 问题3 embstr和raw的区别？embstr的使用只分配一次内存空间(因为RedisObject和SDS 是连续的) , 而raw 需要分配两次内存空间(分别是RedisObject和SDS 分配空间) 因此与raw 相比, embstr的好处在于创建时少分配一次内存空间, 删除时少释放一次空间, 以及对象的所有数据连在一起, 寻找方便. 而embstr的坏处也很明显, 如果字符串的长度增加需要重新分配内存的时候, 整个RedisObject和SDS 都需要重新分配空间, 因为Redis 中的 embstr 实现为只读. 问题4. int和embstr 什么时候转化为raw?当int数据不再是整数，或者大小超过了long的范围(2^63-1=9223372036854775807)的时候,自动转化为raw 127.0.0.1:6379> set k1 1 OK 127.0.0.1:6379> append k1 a (integer) 2 127.0.0.1:6379> object encoding k1 \"raw\" 问题5: 明明没有超过阈值, 为什么变成了raw127.0.0.1:6379> set k2 a OK 127.0.0.1:6379> object encoding k2 \"embstr\" 127.0.0.1:6379> append k2 b (integer) 2 127.0.0.1:6379> object encoding k2 \"raw\" 对于embstr ,由于其实现是只读的, 因此在对 embstr 对象进行修改时, 都会先转化为raw 再进行修改. 因为只要改变embstr 对象, 修改之后的对象一定是raw的, 不论是否达到了44个字节 问题6: 当长度小于阈值时, 会还原吗?关于Redis内部编码的转换, 都符合以下规律: 编码转换在Redis 写完数据时完成, 且转换过程不可逆, 只能从小内存编码转换向大内存编码(但是不包括重新set) 问题7: 为什么要对底层的数据结构进行一层包装呢?通过封装,可以根据对象的类型动态的选择存储结构和可以使用的命令, 实现节省内存和优化查询速度. 6应用场景缓存例如: 热点数据的缓存(例如报表、明星出轨),对象缓存、全页缓存 可以提升热点数据的访问速度 数据共享分布式因为Redis是分布式独立的服务,可以在多个应用之间共享. 例如: 分布式session &lt;dependency> &lt;groupId>org.springframework.session&lt;/groupId> &lt;artifactId>spring-session-data-redis&lt;/artifactId> &lt;/dependency> 分布式锁String 类型的 setnx 方法, 只有在不存在的时候才会添加成功, 返回true http://redisdoc.com/string/set.html 建议用参数的形式 public Boolean getLock(Object lockObject)&amp;#123; jedisUtil = getJedisConnetion(); boolean flag = jedisUtil.setNX(lockObj, 1); if(flag)&amp;#123; expire(locakObj,10); &amp;#125; return flag; &amp;#125; public void releaseLock(Object lockObject)&amp;#123; del(lockObj); &amp;#125; 全局idINT 类型，INCRBY，利用原子 incrby userid 1000 计数器int类型, INCR 方法, 例如: 文章的阅读量, 微博点赞数, 允许一定的延迟, 先写入到redis 再定时同步到数据库 限流int类型, INCR 方法, 以访问者的ip和其他信息作为key,访问一次增加一次计数, 超过次数则返回false, 位统计String 类型的 BITCOUNT 字符是以8位二进制存储的 set k1 a setbit k1 6 1 setbit k1 7 0 get k1 a 对应的 ASCII 码是 97，转换为二进制数据是 01100001 b 对应的 ASCII 码是 98，转换为二进制数据是 01100010 因为bit非常节省空间(1 MB=8388608 bit), 可以用来做大数据量的统计, 例如: 在线用户统计、留存用户统计. setbit onlineusers 0 1 setbit onlineusers 1 1 setbit onlineusers 2 0 支持按位与、按位或等等操作BITOP AND destkey key [key ...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。 BITOP OR destkey key [key ...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 BITOP XOR destkey key [key ...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 BITOP NOT destkey key ，对给定 key 求逻辑非，并将结果保存到 destkey 。 # 计算出 7 天都在线的用户 BITOP \"AND\" \"7_days_both_online_users\" \"day_1_online_users\" \"day_2_online_users\" ... \"day_7_online_users\"","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"Spring AOP 源码解析(7)","slug":"spring/Spring AOP 源码解析(7)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/spring/spring-aop-yuan-ma-jie-xi-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring/spring-aop-yuan-ma-jie-xi-7/","excerpt":"","text":"7. Spring AOP 源码解析Spring AOP初体验 再述Spring AOP应用场景AOP 是OOP 的延续，是AspectOrientedProgramming的缩写，意思是面向切面编程。可以通过预编译方式和运行期动态代理实现在不修改源代码的情况下给程序动态统一添加功能的一种技术。AOP设计模式孜孜不倦追求的是调用者和被调用者之间的解耦，AOP可以说也是这种目标的一种实现。我们现在做的一些非业务，如：日志、事务、安全等都会写在业务代码中(也即是说，这些非业务类横切于业务类)，但这些代码往往是重复，复制——粘贴式的代码会给程序的维护带来不便，AOP 就实现了把这些业务需求与系统需求分开来做。这种解决的方式也称代理机制。 AOP中必须明白的几个概念1、切面（Aspect）官方的抽象定义为“一个关注点的模块化，这个关注点可能会横切多个对象”。“切面”在ApplicationContext中aop:aspect来配置。 连接点（Joinpoint） ：程序执行过程中的某一行为，例如，MemberService .get 的调用或者MemberService .delete抛出异常等行为。 2、通知（Advice）“切面”对于某个“连接点”所产生的动作。其中，一个“切面”可以包含多个“Advice”。 3、切入点（Pointcut）匹配连接点的断言，在AOP 中通知和一个切入点表达式关联。切面中的所有通知所关注的连接点，都由切入点表达式来决定。 4、目标对象（Target Object）被一个或者多个切面所通知的对象。例如，AServcieImpl和BServiceImpl，当然在实际运行时， SpringAOP采用代理实现，实际AOP 操作的是TargetObject的代理对象。 5、AOP代理（AOP Proxy）在 Spring AOP 中有两种代理方式，JDK动态代理和 CGLib代理。默认情况下，TargetObject 实现了接口时，则采用 JDK动态代理，例如，AServiceImpl；反之，采用CGLib代理，例如，BServiceImpl。强制使用CGLib代理需要将 aop:config的 proxy-target-class属性设为true。通知（Advice）类型： 6、前置通知（Before Advice）在某连接点（JoinPoint）之前执行的通知，但这个通知不能阻止连接点前的执行。ApplicationContext中在aop:aspect里面使用aop:before元素进行声明。例如，TestAspect中的doBefore方法。 7、后置通知（After Advice）当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。ApplicationContext 中在aop:aspect里面使用aop:after元素进行声明。例如，ServiceAspect 中的 returnAfter 方法，所以Teser中调用UserService.delete抛出异常时，returnAfter 方法仍然执行。 8、返回后通知（After Return Advice）在某连接点正常完成后执行的通知，不包括抛出异常的情况。ApplicationContext中在aop:aspect里面使用元素进行声明。 9、环绕通知（Around Advice）包围一个连接点的通知，类似 Web中 Servlet 规范中的 Filter 的 doFilter 方法。可以在方法的调用前后完成自定义的行为，也可以选择不执行。ApplicationContext 中在aop:aspect里面使用aop:around元素进行声明。例如，ServiceAspect 中的around方法。 10、异常通知（After Throwing Advice）在 方 法 抛 出 异 常 退 出 时 执 行 的 通 知 。 ApplicationContext 中 在 aop:aspect 里 面 使 用aop:after-throwing元素进行声明。例如，ServiceAspect 中的returnThrow方法。注：可以将多个通知应用到一个目标对象上，即可以将多个切面织入到同一目标对象。使用SpringAOP 可以基于两种方式，一种是比较方便和强大的注解方式，另一种则是中规中矩的xml配置方式。 先说注解，使用注解配置 SpringAOP 总体分为两步，第一步是在 xml文件中声明激活自动扫描组件功能，同时激活自动代理功能（来测试AOP的注解功能）： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:util=\"http://www.springframework.org/schema/util\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-2.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd\"> &lt;context:component-scan base-package=\"com\"/> &lt;context:annotation-config /> &lt;/beans> 第二步是为Aspect切面类添加注解： //声明这是一个组件 @Component //声明这是一个切面 Bean @Aspect @Slf4j public class AnnotaionAspect &amp;#123; //配置切入点,该方法无方法体,主要为方便同类中其他方法使用此处配置的切入点 @Pointcut(\"execution(* com.pattern.spring.aop.service..*(..))\") public void aspect()&amp;#123; &amp;#125; /* * 配置前置通知,使用在方法 aspect()上注册的切入点 * 同时接受 JoinPoint 切入点对象,可以没有该参数 */ @Before(\"aspect()\") public void before(JoinPoint joinPoint) &amp;#123; log.info(\"before 通知 \" + joinPoint); &amp;#125; //配置后置通知,使用在方法 aspect()上注册的切入点 @After(\"aspect()\") public void after(JoinPoint joinPoint)&amp;#123; log.info(\"after 通知 \" + joinPoint); &amp;#125; //配置环绕通知,使用在方法 aspect()上注册的切入点 @Around(\"aspect()\") public void around(JoinPoint joinPoint)&amp;#123; long start = System.currentTimeMillis(); try &amp;#123; ((ProceedingJoinPoint) joinPoint).proceed(); long end = System.currentTimeMillis(); log.info(\"around 通知 \" + joinPoint + \"\\tUse time : \" + (end - start) + \" ms!\"); &amp;#125; catch (Throwable e) &amp;#123; long end = System.currentTimeMillis(); log.info(\"around 通知 \" + joinPoint + \"\\tUse time : \" + (end - start) + \" ms with exception : \" + e.getMessage()); &amp;#125; &amp;#125; //配置后置返回通知,使用在方法 aspect()上注册的切入点 @AfterReturning(\"aspect()\") public void afterReturn(JoinPoint joinPoint)&amp;#123; log.info(\"afterReturn 通知 \" + joinPoint); &amp;#125; //配置抛出异常后通知,使用在方法 aspect()上注册的切入点 @AfterThrowing(pointcut=\"aspect()\", throwing=\"ex\") public void afterThrow(JoinPoint joinPoint, Exception ex)&amp;#123; log.info(\"afterThrow 通知 \" + joinPoint + \"\\t\" + ex.getMessage()); &amp;#125; &amp;#125; 测试代码 @ContextConfiguration(locations = &amp;#123;\"classpath*:application-context.xml\"&amp;#125;) @RunWith(SpringJUnit4ClassRunner.class) public class AnnotationTester &amp;#123; @Autowired MemberService annotationService; @Autowired ApplicationContext app; @Test // @Ignore public void test()&amp;#123; System.out.println(\"=====这是一条华丽的分割线======\"); AnnotaionAspect aspect = app.getBean(AnnotaionAspect.class); System.out.println(aspect); annotationService.save(new Member()); System.out.println(\"=====这是一条华丽的分割线======\"); try &amp;#123; annotationService.delete(1L); &amp;#125; catch (Exception e) &amp;#123; //e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 控制台输出如下： =====这是一条华丽的分割线====== com.aop.aspect.AnnotaionAspect@6ef714a0 [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - before execution(void com.aop.service.MemberService.save(Member)) [INFO ] [13:04:46] com.aop.aspect.ArgsAspect - beforeArgUser execution(void com.aop.service.MemberService.save(Member)) [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - save member Method . . . [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - around execution(void com.aop.service.MemberService.save(Member)) Use time : 38 ms! [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - after execution(void com.aop.service.MemberService.save(Member)) [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - afterReturn execution(void com.aop.service.MemberService.save(Member)) =====这是一条华丽的分割线====== [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - before execution(boolean com.aop.service.MemberService.delete(long)) [INFO ] [13:04:46] com.aop.aspect.ArgsAspect - beforeArgId execution(boolean com.aop.service.MemberService.delete(long)) ID:1 [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - delete Method . . . [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - around execution(boolean com.aop.service.MemberService.delete(long)) Use time : 3 ms with exception : spring aop ThrowAdvice 演示 [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - after execution(boolean com.aop.service.MemberService.delete(long)) [INFO ] [13:04:46] com.aop.aspect.AnnotaionAspect - afterReturn execution(boolean com.aop.service.MemberService.delete(long)) 可以看到，正如我们预期的那样，虽然我们并没有对MemberService 类包括其调用方式做任何改变，但是Spring仍然拦截到了其中方法的调用，或许这正是AOP 的魔力所在。再简单说一下xml配置方式，其实也一样简单： &lt;bean id=\"xmlAspect\" class=\"com.pattern.spring.aop.aspect.XmlAspect\">&lt;/bean> &lt;!-- AOP 配置 --> &lt;aop:config> &lt;!-- 声明一个切面,并注入切面 Bean,相当于@Aspect --> &lt;aop:aspect ref=\"xmlAspect\"> &lt;!-- 配置一个切入点,相当于@Pointcut --> &lt;aop:pointcut expression=\"execution(* com.pattern.spring.aop.service..*(..))\" id=\"simplePointcut\"/> &lt;!-- 配置通知,相当于@Before、@After、@AfterReturn、@Around、@AfterThrowing --> &lt;aop:before pointcut-ref=\"simplePointcut\" method=\"before\"/> &lt;aop:after pointcut-ref=\"simplePointcut\" method=\"after\"/> &lt;aop:after-returning pointcut-ref=\"simplePointcut\" method=\"afterReturn\"/> &lt;aop:after-throwing pointcut-ref=\"simplePointcut\" method=\"afterThrow\" throwing=\"ex\"/> &lt;/aop:aspect> &lt;/aop:config> 个人觉得不如注解灵活和强大，你可以不同意这个观点，但是不知道如下的代码会不会让你的想法有所改善： //配置切入点,该方法无方法体,主要为方便同类中其他方法使用此处配置的切入点 @Pointcut(\"execution(* com.aop.service..*(..))\") public void aspect()&amp;#123; &amp;#125; //配置前置通知,拦截返回值为 cn.ysh.studio.spring.mvc.bean.User 的方法 @Before(\"execution(com.model.Member com.aop.service..*(..))\") public void beforeReturnUser(JoinPoint joinPoint)&amp;#123; log.info(\"beforeReturnUser \" + joinPoint); &amp;#125; //配置前置通知,拦截参数为 cn.ysh.studio.spring.mvc.bean.User 的方法 @Before(\"execution(* com.aop.service..*(com.model.Member))\") public void beforeArgUser(JoinPoint joinPoint)&amp;#123; log.info(\"beforeArgUser \" + joinPoint); &amp;#125; //配置前置通知,拦截含有 long 类型参数的方法,并将参数值注入到当前方法的形参 id 中 @Before(\"aspect()&amp;&amp;args(id)\") public void beforeArgId(JoinPoint joinPoint, long id)&amp;#123; log.info(\"beforeArgId \" + joinPoint + \"\\tID:\" + id); &amp;#125; 以下是MemberService的代码： @Service public class MemberService &amp;#123; private final static Logger log = Logger.getLogger(AnnotaionAspect.class); public Member get(long id)&amp;#123; log.info(\"getMemberById Method . . .\"); return new Member(); &amp;#125; public Member get()&amp;#123; log.info(\"getMember Method . . .\"); return new Member(); &amp;#125; public void save(Member member)&amp;#123; log.info(\"save member Method . . .\"); &amp;#125; public boolean delete(long id) throws Exception&amp;#123; log.info(\"delete Method . . .\"); throw new Exception(\"spring aop ThrowAdvice 演示\"); &amp;#125; &amp;#125; 应该说学习 Spring AOP 有两个难点，第一点在于理解 AOP 的理念和相关概念，第二点在于灵活掌握和使用切入点表达式。概念的理解通常不在一朝一夕，慢慢浸泡的时间长了，自然就明白了，下面我们简单地介绍一下切入点表达式的配置规则吧。通常情况下，表达式中使用”execution“就可以满足大部分的要求。表达式格式如下： execution(modifiers-pattern? ret-type-pattern declaring-type-pattern? name-pattern(param-pattern) throws-pattern? modifiers-pattern：方法的操作权限 ret-type-pattern：返回值 declaring-type-pattern：方法所在的包 name-pattern：方法名 parm-pattern：参数名 throws-pattern：异常 其中，除 ret-type-pattern 和 name-pattern 之外，其他都是可选的。上例中，execution(*com.spring.service..(..))表示com.spring.service 包下，返回值为任意类型；方法名任意；参数不作限制的所有方法。 最后说一下通知参数，可以通过args来绑定参数，这样就可以在通知（Advice）中访问具体参数了。例如，aop:aspect配置如下： &lt;aop:config> &lt;aop:aspect ref=\"xmlAspect\"> &lt;aop:pointcut id=\"simplePointcut\" expression=\"execution(* com.aop.service..*(..)) and args(msg,..)\" /> &lt;aop:after pointcut-ref=\"simplePointcut\" Method=\"after\"/> &lt;/aop:aspect> &lt;/aop:config> 上面的代码 args(msg,..)是指将切入点方法上的第一个 String 类型参数添加到参数名为 msg 的通知的入参上，这样就可以直接使用该参数啦。 在上面的Aspect切面Bean中已经看到了，每个通知方法第一个参数都是 JoinPoint。其实，在Spring中，任何通知（Advice）方法都可以将第一个参数定义为 org.aspectj.lang.JoinPoint 类型用以接受当前连接点对象。JoinPoint 接口提供了一系列有用的方法， 比如 getArgs() （返回方法参数）、getThis() （返回代理对象）、getTarget() （返回目标）、getSignature() （返回正在被通知的方法相关信息）和 toString() （打印出正在被通知的方法的有用信息）。 Spring AOP源码分析寻找入口Spring的 AOP是通过接入 BeanPostProcessor后置处理器开始的，它是 Spring IOC 容器经常使用到的一个特性，这个 Bean后置处理器是一个监听器，可以监听容器触发的Bean声明周期事件。后置处理器向容器注册以后，容器中管理的Bean就具备了接收IOC 容器事件回调的能力。 BeanPostProcessor的使用非常简单，只需要提供一个实现接口 BeanPostProcessor的实现类，然后在Bean的配置文件中设置即可。 1、BeanPostProcessor源码public interface BeanPostProcessor &amp;#123; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i>before&lt;/i> any bean * initialization callbacks (like InitializingBean's &amp;#123;@code afterPropertiesSet&amp;#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p>The default implementation returns the given &amp;#123;@code bean&amp;#125; as-is. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if &amp;#123;@code null&amp;#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ //为在Bean的初始化前提供回调入口 @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &amp;#123; return bean; &amp;#125; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i>after&lt;/i> any bean * initialization callbacks (like InitializingBean's &amp;#123;@code afterPropertiesSet&amp;#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p>In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding &amp;#123;@code bean instanceof FactoryBean&amp;#125; checks. * &lt;p>This callback will also be invoked after a short-circuiting triggered by a * &amp;#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&amp;#125; method, * in contrast to all other BeanPostProcessor callbacks. * &lt;p>The default implementation returns the given &amp;#123;@code bean&amp;#125; as-is. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if &amp;#123;@code null&amp;#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ //为在Bean的初始化之后提供回调入口 @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &amp;#123; return bean; &amp;#125; 这两个回调的入口都是和容器管理的 Bean 的生命周期事件紧密相关，可以为用户提供在 Spring IOC容器初始化Bean过程中自定义的处理操作。 2、AbstractAutowireCapableBeanFactory 类对容器生成的Bean添加后置处理器BeanPostProcessor后置处理器的调用发生在 Spring IOC 容器完成对Bean实例对象的创建和属性的依赖注入完成之后，在对Spring依赖注入的源码分析过程中我们知道，当应用程序第一次调用getBean()方法(lazy-init预实例化除外)向Spring IOC 容器索取指定 Bean时触发 Spring IOC 容器创建Bean实例对象并进行依赖注入的过程，其中真正实现创建 Bean 对象并进行依赖注入的方法是AbstractAutowireCapableBeanFactory 类的doCreateBean()方法，主要源码如下： //真正创建Bean的方法 protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &amp;#123; // Instantiate the bean. //封装被创建的Bean对象 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &amp;#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &amp;#125; if (instanceWrapper == null) &amp;#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &amp;#125; final Object bean = instanceWrapper.getWrappedInstance(); //获取实例化对象的类型 Class&lt;?> beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &amp;#123; mbd.resolvedTargetType = beanType; &amp;#125; // Allow post-processors to modify the merged bean definition. //调用PostProcessor后置处理器 synchronized (mbd.postProcessingLock) &amp;#123; if (!mbd.postProcessed) &amp;#123; try &amp;#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Post-processing of merged bean definition failed\", ex); &amp;#125; mbd.postProcessed = true; &amp;#125; &amp;#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. //向容器中缓存单例模式的Bean对象，以防循环引用 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); &amp;#125; //这里是一个匿名内部类，为了防止循环引用，尽早持有对象的引用 addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean)); &amp;#125; // Initialize the bean instance. //Bean对象的初始化，依赖注入在此触发 //这个exposedObject在初始化完成之后返回作为依赖注入完成后的Bean Object exposedObject = bean; try &amp;#123; //将Bean实例对象封装，并且Bean定义中配置的属性值赋值给实例对象 populateBean(beanName, mbd, instanceWrapper); //初始化Bean对象 exposedObject = initializeBean(beanName, exposedObject, mbd); &amp;#125; catch (Throwable ex) &amp;#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &amp;#123; throw (BeanCreationException) ex; &amp;#125; else &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); &amp;#125; &amp;#125; if (earlySingletonExposure) &amp;#123; //获取指定名称的已注册的单例模式Bean对象 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &amp;#123; //根据名称获取的已注册的Bean和正在实例化的Bean是同一个 if (exposedObject == bean) &amp;#123; //当前实例化的Bean初始化完成 exposedObject = earlySingletonReference; &amp;#125; //当前Bean依赖其他Bean，并且当发生循环引用时不允许新创建实例对象 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &amp;#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String> actualDependentBeans = new LinkedHashSet&lt;>(dependentBeans.length); //获取当前Bean所依赖的其他Bean for (String dependentBean : dependentBeans) &amp;#123; //对依赖Bean进行类型检查 if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &amp;#123; actualDependentBeans.add(dependentBean); &amp;#125; &amp;#125; if (!actualDependentBeans.isEmpty()) &amp;#123; throw new BeanCurrentlyInCreationException(beanName, \"Bean with name '\" + beanName + \"' has been injected into other beans [\" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + \"] in its raw version as part of a circular reference, but has eventually been \" + \"wrapped. This means that said other beans do not use the final version of the \" + \"bean. This is often the result of over-eager type matching - consider using \" + \"'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.\"); &amp;#125; &amp;#125; &amp;#125; &amp;#125; // Register bean as disposable. //注册完成依赖注入的Bean try &amp;#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &amp;#125; catch (BeanDefinitionValidationException ex) &amp;#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); &amp;#125; return exposedObject; &amp;#125; 从上面的代码中我们知道，为 Bean 实例对象添加 BeanPostProcessor 后置处理器的入口的是initializeBean()方法。 3、initializeBean()方法为容器产生的Bean实例对象添加BeanPostProcessor后置处理器同样在 AbstractAutowireCapableBeanFactory 类中，initializeBean()方法实现为容器创建的 Bean实例对象添加BeanPostProcessor后置处理器，源码如下： //初始容器创建的Bean实例对象，为其添加BeanPostProcessor后置处理器 protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &amp;#123; //JDK的安全机制验证权限 if (System.getSecurityManager() != null) &amp;#123; //实现PrivilegedAction接口的匿名内部类 AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> &amp;#123; invokeAwareMethods(beanName, bean); return null; &amp;#125;, getAccessControlContext()); &amp;#125; else &amp;#123; //为Bean实例对象包装相关属性，如名称，类加载器，所属容器等信息 invokeAwareMethods(beanName, bean); &amp;#125; Object wrappedBean = bean; //对BeanPostProcessor后置处理器的postProcessBeforeInitialization //回调方法的调用，为Bean实例初始化前做一些处理 if (mbd == null || !mbd.isSynthetic()) &amp;#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &amp;#125; //调用Bean实例对象初始化的方法，这个初始化方法是在Spring Bean定义配置 //文件中通过init-method属性指定的 try &amp;#123; invokeInitMethods(beanName, wrappedBean, mbd); &amp;#125; catch (Throwable ex) &amp;#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &amp;#125; //对BeanPostProcessor后置处理器的postProcessAfterInitialization //回调方法的调用，为Bean实例初始化之后做一些处理 if (mbd == null || !mbd.isSynthetic()) &amp;#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &amp;#125; return wrappedBean; &amp;#125; @Override //调用BeanPostProcessor后置处理器实例对象初始化之后的处理方法 public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &amp;#123; Object result = existingBean; //遍历容器为所创建的Bean添加的所有BeanPostProcessor后置处理器 for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &amp;#123; //调用Bean实例所有的后置处理中的初始化后处理方法，为Bean实例对象在 //初始化之后做一些自定义的处理操作 Object current = beanProcessor.postProcessAfterInitialization(result, beanName); if (current == null) &amp;#123; return result; &amp;#125; result = current; &amp;#125; return result; &amp;#125; @Override //调用BeanPostProcessor后置处理器实例对象初始化之前的处理方法 public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException &amp;#123; Object result = existingBean; //遍历容器为所创建的Bean添加的所有BeanPostProcessor后置处理器 for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &amp;#123; //调用Bean实例所有的后置处理中的初始化前处理方法，为Bean实例对象在 //初始化之前做一些自定义的处理操作 Object current = beanProcessor.postProcessBeforeInitialization(result, beanName); if (current == null) &amp;#123; return result; &amp;#125; result = current; &amp;#125; return result; &amp;#125; BeanPostProcessor是一个接口，其初始化前的操作方法和初始化后的操作方法均委托其实现子类来实现，在Spring中，BeanPostProcessor的实现子类非常的多，分别完成不同的操作，如：AOP 面向切面编程的注册通知适配器、Bean对象的数据校验、Bean继承属性、方法的合并等等，我们以最简单的AOP 切面织入来简单了解其主要的功能。下面我们来分析其中一个创建 AOP 代理对象的子类AbstractAutoProxyCreator类。该类重写了postProcessAfterInitialization()方法。 选择代理策略进入postProcessAfterInitialization()方法，我们发现调到了一个非常核心的方法wrapIfNecessary()，其源码如下： @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) throws BeansException &amp;#123; if (bean != null) &amp;#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &amp;#123; return wrapIfNecessary(bean, beanName, cacheKey); &amp;#125; &amp;#125; return bean; &amp;#125; /** * Wrap the given bean if necessary, i.e. if it is eligible for being proxied. * @param bean the raw bean instance * @param beanName the name of the bean * @param cacheKey the cache key for metadata access * @return a proxy wrapping the bean, or the raw bean instance as-is */ protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &amp;#123; if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &amp;#123; return bean; &amp;#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &amp;#123; return bean; &amp;#125; if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &amp;#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &amp;#125; // Create proxy if we have advice. Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &amp;#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &amp;#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &amp;#125; /** * Create an AOP proxy for the given bean. * @param beanClass the class of the bean * @param beanName the name of the bean * @param specificInterceptors the set of interceptors that is * specific to this bean (may be empty, but not null) * @param targetSource the TargetSource for the proxy, * already pre-configured to access the bean * @return the AOP proxy for the bean * @see #buildAdvisors */ protected Object createProxy(Class&lt;?> beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &amp;#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &amp;#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &amp;#125; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); if (!proxyFactory.isProxyTargetClass()) &amp;#123; if (shouldProxyTargetClass(beanClass, beanName)) &amp;#123; proxyFactory.setProxyTargetClass(true); &amp;#125; else &amp;#123; evaluateProxyInterfaces(beanClass, proxyFactory); &amp;#125; &amp;#125; Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); proxyFactory.addAdvisors(advisors); proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &amp;#123; proxyFactory.setPreFiltered(true); &amp;#125; return proxyFactory.getProxy(getProxyClassLoader()); &amp;#125; 整个过程跟下来，我发现最终调用的是 proxyFactory.getProxy()方法。到这里我们大概能够猜到proxyFactory 有JDK和CGLib的，那么我们该如何选择呢？最终调用的是DefaultAopProxyFactory的createAopProxy()方法： @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &amp;#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &amp;#123; Class&lt;?> targetClass = config.getTargetClass(); if (targetClass == null) &amp;#123; throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); &amp;#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &amp;#123; return new JdkDynamicAopProxy(config); &amp;#125; return new ObjenesisCglibAopProxy(config); &amp;#125; else &amp;#123; return new JdkDynamicAopProxy(config); &amp;#125; &amp;#125; /** * Determine whether the supplied &amp;#123;@link AdvisedSupport&amp;#125; has only the * &amp;#123;@link org.springframework.aop.SpringProxy&amp;#125; interface specified * (or no proxy interfaces specified at all). */ private boolean hasNoUserSuppliedProxyInterfaces(AdvisedSupport config) &amp;#123; Class&lt;?>[] ifcs = config.getProxiedInterfaces(); return (ifcs.length == 0 || (ifcs.length == 1 &amp;&amp; SpringProxy.class.isAssignableFrom(ifcs[0]))); &amp;#125; 调用代理方法分析调用逻辑之前先上类图，看看Spring中主要的AOP 组件： 上面我们已经了解到 Spring 提供了两种方式来生成代理方式有 JDKProxy和 CGLib。下面我们来研究一下Spring 如何使用JDK来生成代理对象，具体的生成代码放在 JdkDynamicAopProxy这个类中，直接上相关代码： /** * 获取代理类要实现的接口,除了Advised对象中配置的,还会加上SpringProxy, Advised(opaque=false) * 检查上面得到的接口中有没有定义 equals或者hashcode的接口 * 调用Proxy.newProxyInstance创建代理对象 */ @Override public Object getProxy(@Nullable ClassLoader classLoader) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Creating JDK dynamic proxy: target source is \" + this.advised.getTargetSource()); &amp;#125; Class&lt;?>[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this); &amp;#125; 通过注释我们应该已经看得非常明白代理对象的生成过程，此处不再赘述。下面的问题是，代理对象生成了，那切面是如何织入的？ 我们知道 InvocationHandler 是 JDK 动态代理的核心，生成的代理对象的方法调用都会委托到InvocationHandler.invoke()方法。而从 JdkDynamicAopProxy 的源码我们可以看到这个类其实也实现了InvocationHandler，下面我们分析SpringAOP 是如何织入切面的，直接上源码看invoke()方法： /** * Implementation of &amp;#123;@code InvocationHandler.invoke&amp;#125;. * &lt;p>Callers will see exactly the exception thrown by the target, * unless a hook method throws an exception. */ @Override @Nullable public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try &amp;#123; //eqauls()方法，具目标对象未实现此方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &amp;#123; // The target does not implement the equals(Object) method itself. return equals(args[0]); &amp;#125; //hashCode()方法，具目标对象未实现此方法 else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &amp;#123; // The target does not implement the hashCode() method itself. return hashCode(); &amp;#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &amp;#123; // There is only getDecoratedClass() declared -> dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &amp;#125; //Advised接口或者其父接口中定义的方法,直接反射调用,不应用通知 else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &amp;#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &amp;#125; Object retVal; if (this.advised.exposeProxy) &amp;#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &amp;#125; // Get as late as possible to minimize the time we \"own\" the target, // in case it comes from a pool. //获得目标对象的类 target = targetSource.getTarget(); Class&lt;?> targetClass = (target != null ? target.getClass() : null); // Get the interception chain for this method. //获取可以应用到此方法上的Interceptor列表 List&lt;Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. //如果没有可以应用到此方法的通知(Interceptor)，此直接反射调用 method.invoke(target, args) if (chain.isEmpty()) &amp;#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &amp;#125; else &amp;#123; // We need to create a method invocation... //创建MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. retVal = invocation.proceed(); &amp;#125; // Massage return value if necessary. Class&lt;?> returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &amp;#123; // Special case: it returned \"this\" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; &amp;#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &amp;#123; throw new AopInvocationException( \"Null return value from advice does not match primitive return type for: \" + method); &amp;#125; return retVal; &amp;#125; finally &amp;#123; if (target != null &amp;&amp; !targetSource.isStatic()) &amp;#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &amp;#125; if (setProxyContext) &amp;#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &amp;#125; &amp;#125; &amp;#125; 主要实现思路可以简述为：首先获取应用到此方法上的通知链（InterceptorChain）。如果有通知，则应用通知，并执行 JoinPoint；如果没有通知，则直接反射执行JoinPoint。而这里的关键是通知链是如何获取的以及它又是如何执行的呢？现在来逐一分析。首先，从上面的代码可以看到，通知链是通过Advised.getInterceptorsAndDynamicInterceptionAdvice()这个方法来获取的，我们来看下这个方法的实现逻辑： public List&lt;Object> getInterceptorsAndDynamicInterceptionAdvice(Method method, @Nullable Class&lt;?> targetClass) &amp;#123; MethodCacheKey cacheKey = new MethodCacheKey(method); List&lt;Object> cached = this.methodCache.get(cacheKey); if (cached == null) &amp;#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this, method, targetClass); this.methodCache.put(cacheKey, cached); &amp;#125; return cached; &amp;#125; 通过上面的源码我们可以看到，实际获取通知的实现逻辑其实是由 AdvisorChainFactory 的getInterceptorsAndDynamicInterceptionAdvice()方法来完成的，且获取到的结果会被缓存。下面来分析getInterceptorsAndDynamicInterceptionAdvice()方法的实现： /** * 从提供的配置实例config中获取advisor列表,遍历处理这些advisor.如果是IntroductionAdvisor, * 则判断此Advisor能否应用到目标类targetClass上.如果是PointcutAdvisor,则判断 * 此Advisor能否应用到目标方法method上.将满足条件的Advisor通过AdvisorAdaptor转化成Interceptor列表返回. */ @Override public List&lt;Object> getInterceptorsAndDynamicInterceptionAdvice( Advised config, Method method, @Nullable Class&lt;?> targetClass) &amp;#123; // This is somewhat tricky... We have to process introductions first, // but we need to preserve order in the ultimate list. List&lt;Object> interceptorList = new ArrayList&lt;>(config.getAdvisors().length); Class&lt;?> actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); //查看是否包含IntroductionAdvisor boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); //这里实际上注册一系列AdvisorAdapter,用于将Advisor转化成MethodInterceptor AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); for (Advisor advisor : config.getAdvisors()) &amp;#123; if (advisor instanceof PointcutAdvisor) &amp;#123; // Add it conditionally. PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &amp;#123; //这个地方这两个方法的位置可以互换下 //将Advisor转化成Interceptor MethodInterceptor[] interceptors = registry.getInterceptors(advisor); //检查当前advisor的pointcut是否可以匹配当前方法 MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &amp;#123; if (mm.isRuntime()) &amp;#123; // Creating a new object instance in the getInterceptors() method // isn't a problem as we normally cache created chains. for (MethodInterceptor interceptor : interceptors) &amp;#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &amp;#125; &amp;#125; else &amp;#123; interceptorList.addAll(Arrays.asList(interceptors)); &amp;#125; &amp;#125; &amp;#125; &amp;#125; else if (advisor instanceof IntroductionAdvisor) &amp;#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &amp;#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &amp;#125; &amp;#125; else &amp;#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &amp;#125; &amp;#125; return interceptorList; &amp;#125; 这个方法执行完成后，Advised 中配置能够应用到连接点（JoinPoint）或者目标类（Target Object）的Advisor全部被转化成了MethodInterceptor，接下来我们再看下得到的拦截器链是怎么起作用的。 if (chain.isEmpty()) &amp;#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &amp;#125; else &amp;#123; // We need to create a method invocation... //创建MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. retVal = invocation.proceed(); &amp;#125; 从这段代码可以看出，如果得到的拦截器链为空，则直接反射调用目标方法，否则创建MethodInvocation，调用其proceed()方法，触发拦截器链的执行，来看下具体代码: @Override @Nullable public Object proceed() throws Throwable &amp;#123; // We start with an index of -1 and increment early. //如果Interceptor执行完了，则执行joinPoint if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &amp;#123; return invokeJoinpoint(); &amp;#125; Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); //如果要动态匹配joinPoint if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &amp;#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; //动态匹配：运行时参数是否满足匹配条件 if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &amp;#123; return dm.interceptor.invoke(this); &amp;#125; else &amp;#123; // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. //动态匹配失败时,略过当前Intercetpor,调用下一个Interceptor return proceed(); &amp;#125; &amp;#125; else &amp;#123; // It's an interceptor, so we just invoke it: The pointcut will have // been evaluated statically before this object was constructed. //执行当前Intercetpor return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &amp;#125; &amp;#125; 至此，通知链就完美地形成了。我们再往下来看 invokeJoinpointUsingReflection()方法，其实就是反射调用： @Nullable public static Object invokeJoinpointUsingReflection(@Nullable Object target, Method method, Object[] args) throws Throwable &amp;#123; // Use reflection to invoke the method. try &amp;#123; ReflectionUtils.makeAccessible(method); return method.invoke(target, args); &amp;#125; catch (InvocationTargetException ex) &amp;#123; // Invoked method threw a checked exception. // We must rethrow it. The client won't see the interceptor. throw ex.getTargetException(); &amp;#125; catch (IllegalArgumentException ex) &amp;#123; throw new AopInvocationException(\"AOP configuration seems to be invalid: tried calling method [\" + method + \"] on target [\" + target + \"]\", ex); &amp;#125; catch (IllegalAccessException ex) &amp;#123; throw new AopInvocationException(\"Could not access method [\" + method + \"]\", ex); &amp;#125; &amp;#125; Spring AOP 源码就分析到这儿，相信小伙伴们应该有了基本思路，下面时序图来一波。 触发通知在为AopProxy代理对象配置拦截器的实现中，有一个取得拦截器的配置过程，这个过程是由 DefaultAdvisorChainFactory 实现的，这个工厂类负责生成拦截器链，在它的getInterceptorsAndDynamicInterceptionAdvice方法中，有一个适配器和注册过程，通过配置Spring 预先设计好的拦截器，Spring 加入了它对AOP实现的处理。 /** * 从提供的配置实例config中获取advisor列表,遍历处理这些advisor.如果是IntroductionAdvisor, * 则判断此Advisor能否应用到目标类targetClass上.如果是PointcutAdvisor,则判断 * 此Advisor能否应用到目标方法method上.将满足条件的Advisor通过AdvisorAdaptor转化成Interceptor列表返回. */ @Override public List&lt;Object> getInterceptorsAndDynamicInterceptionAdvice( Advised config, Method method, @Nullable Class&lt;?> targetClass) &amp;#123; // This is somewhat tricky... We have to process introductions first, // but we need to preserve order in the ultimate list. List&lt;Object> interceptorList = new ArrayList&lt;>(config.getAdvisors().length); Class&lt;?> actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); //查看是否包含IntroductionAdvisor boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); //这里实际上注册一系列AdvisorAdapter,用于将Advisor转化成MethodInterceptor AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); for (Advisor advisor : config.getAdvisors()) &amp;#123; if (advisor instanceof PointcutAdvisor) &amp;#123; // Add it conditionally. PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &amp;#123; //这个地方这两个方法的位置可以互换下 //将Advisor转化成Interceptor MethodInterceptor[] interceptors = registry.getInterceptors(advisor); //检查当前advisor的pointcut是否可以匹配当前方法 MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &amp;#123; if (mm.isRuntime()) &amp;#123; // Creating a new object instance in the getInterceptors() method // isn't a problem as we normally cache created chains. for (MethodInterceptor interceptor : interceptors) &amp;#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &amp;#125; &amp;#125; else &amp;#123; interceptorList.addAll(Arrays.asList(interceptors)); &amp;#125; &amp;#125; &amp;#125; &amp;#125; else if (advisor instanceof IntroductionAdvisor) &amp;#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &amp;#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &amp;#125; &amp;#125; else &amp;#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &amp;#125; &amp;#125; return interceptorList; &amp;#125; GlobalAdvisorAdapterRegistry 负责拦截器的适配和注册过程。 public abstract class GlobalAdvisorAdapterRegistry &amp;#123; /** * Keep track of a single instance so we can return it to classes that request it. */ private static AdvisorAdapterRegistry instance = new DefaultAdvisorAdapterRegistry(); /** * Return the singleton &amp;#123;@link DefaultAdvisorAdapterRegistry&amp;#125; instance. */ public static AdvisorAdapterRegistry getInstance() &amp;#123; return instance; &amp;#125; /** * Reset the singleton &amp;#123;@link DefaultAdvisorAdapterRegistry&amp;#125;, removing any * &amp;#123;@link AdvisorAdapterRegistry#registerAdvisorAdapter(AdvisorAdapter) registered&amp;#125; * adapters. */ static void reset() &amp;#123; instance = new DefaultAdvisorAdapterRegistry(); &amp;#125; &amp;#125; 而 GlobalAdvisorAdapterRegistry 起到了适配器和单例模式的作用，提供了一个DefaultAdvisorAdapterRegistry，它用来完成各种通知的适配和注册过程。 @SuppressWarnings(\"serial\") public class DefaultAdvisorAdapterRegistry implements AdvisorAdapterRegistry, Serializable &amp;#123; private final List&lt;AdvisorAdapter> adapters = new ArrayList&lt;>(3); /** * Create a new DefaultAdvisorAdapterRegistry, registering well-known adapters. */ public DefaultAdvisorAdapterRegistry() &amp;#123; registerAdvisorAdapter(new MethodBeforeAdviceAdapter()); registerAdvisorAdapter(new AfterReturningAdviceAdapter()); registerAdvisorAdapter(new ThrowsAdviceAdapter()); &amp;#125; @Override public Advisor wrap(Object adviceObject) throws UnknownAdviceTypeException &amp;#123; if (adviceObject instanceof Advisor) &amp;#123; return (Advisor) adviceObject; &amp;#125; if (!(adviceObject instanceof Advice)) &amp;#123; throw new UnknownAdviceTypeException(adviceObject); &amp;#125; Advice advice = (Advice) adviceObject; if (advice instanceof MethodInterceptor) &amp;#123; // So well-known it doesn't even need an adapter. return new DefaultPointcutAdvisor(advice); &amp;#125; for (AdvisorAdapter adapter : this.adapters) &amp;#123; // Check that it is supported. if (adapter.supportsAdvice(advice)) &amp;#123; return new DefaultPointcutAdvisor(advice); &amp;#125; &amp;#125; throw new UnknownAdviceTypeException(advice); &amp;#125; @Override public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &amp;#123; List&lt;MethodInterceptor> interceptors = new ArrayList&lt;>(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &amp;#123; interceptors.add((MethodInterceptor) advice); &amp;#125; for (AdvisorAdapter adapter : this.adapters) &amp;#123; if (adapter.supportsAdvice(advice)) &amp;#123; interceptors.add(adapter.getInterceptor(advisor)); &amp;#125; &amp;#125; if (interceptors.isEmpty()) &amp;#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &amp;#125; return interceptors.toArray(new MethodInterceptor[interceptors.size()]); &amp;#125; @Override public void registerAdvisorAdapter(AdvisorAdapter adapter) &amp;#123; this.adapters.add(adapter); &amp;#125; &amp;#125; DefaultAdvisorAdapterRegistry 设置了一系列的是配置，正是这些适配器的实现，为Spring AOP 提供了编织能力。下面以 MethodBeforeAdviceAdapter为例，看具体的实现： @SuppressWarnings(\"serial\") class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &amp;#123; @Override public boolean supportsAdvice(Advice advice) &amp;#123; return (advice instanceof MethodBeforeAdvice); &amp;#125; @Override public MethodInterceptor getInterceptor(Advisor advisor) &amp;#123; MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &amp;#125; &amp;#125; Spring AOP为了实现advice的织入，设计了特定的拦截器对这些功能进行了封装。我们接着看MethodBeforeAdviceInterceptor如何完成封装的？ public class MethodBeforeAdviceInterceptor implements MethodInterceptor, Serializable &amp;#123; private MethodBeforeAdvice advice; /** * Create a new MethodBeforeAdviceInterceptor for the given advice. * @param advice the MethodBeforeAdvice to wrap */ public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &amp;#123; Assert.notNull(advice, \"Advice must not be null\"); this.advice = advice; &amp;#125; @Override public Object invoke(MethodInvocation mi) throws Throwable &amp;#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis() ); return mi.proceed(); &amp;#125; &amp;#125; 可以看到，invoke方法中，首先触发了advice的before回调，然后才是proceed。AfterReturningAdviceInterceptor的源码： public class AfterReturningAdviceInterceptor implements MethodInterceptor, AfterAdvice, Serializable &amp;#123; private final AfterReturningAdvice advice; /** * Create a new AfterReturningAdviceInterceptor for the given advice. * @param advice the AfterReturningAdvice to wrap */ public AfterReturningAdviceInterceptor(AfterReturningAdvice advice) &amp;#123; Assert.notNull(advice, \"Advice must not be null\"); this.advice = advice; &amp;#125; @Override public Object invoke(MethodInvocation mi) throws Throwable &amp;#123; Object retVal = mi.proceed(); this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal; &amp;#125; &amp;#125; 至此，我们知道了对目标对象的增强是通过拦截器实现的，最后还是上时序图：","categories":[{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"}],"tags":[]},{"title":"redis实战之客户端(15)","slug":"redis/redis实战之客户端(15)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-shi-zhan-zhi-ke-hu-duan-15/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-shi-zhan-zhi-ke-hu-duan-15/","excerpt":"","text":"redis客户端1. 客户端通信原理客户端和服务器端通过TCP 连接来进行数据交互, 服务器默认的端口号是6379, 客户端和服务端发送的命令和数据一律以\\r\\n (CRLF 回车+换行) 结尾. 如果使用wireshark 对jedis 抓包 环境: jedis 连接到运行在虚拟机202的redis, 执行命令, 对VMnet8 进行抓包 过滤条件： ip.dst==192.168.8.202 and tcp.port in &#123;6379&#125; set test 2673 转包 可以看到实际发出的数据包是: *3\\r\\n$3\\r\\nSET\\r\\n$4\\r\\ntest\\r\\n$4\\r\\n2673\\r\\n get test 抓包 *2\\r\\n$3\\r\\nGET\\r\\n$4\\r\\ntest\\r\\n 客户端跟redis 之间, 使用一种特殊的编码格式(在AOF文件里面我们能够看到). 叫做Redis Serialization Protocol(redis 序列化协议). 特点: 容易实现、解析快、可读性强. 客户端发送服务端的消息需要经过编码, 服务端收到之后会按约定进行解码,反之亦然. 基于此, 我们可以自己实现自己的一个redis客户端 建立socket连接 OutputStream 写入数据(发送到服务端) InputStream 读取数据(从服务端接口) /** * @author luyanan * @since 2020/4/2 * &lt;p>自己编写客户端&lt;/p> **/ public class MyRedisClient &amp;#123; private Socket socket; private OutputStream write; private InputStream read; public MyRedisClient(String host, int port) throws IOException &amp;#123; socket = new Socket(host, port); write = socket.getOutputStream(); read = socket.getInputStream(); &amp;#125; private static final String LINE_SUFFIX = \"\\r\\n\"; public void set(String key, String val) throws IOException &amp;#123; StringBuffer sb = new StringBuffer(); // 代表3个参数 sb.append(\"*3\").append(LINE_SUFFIX); // 第一个参数(get) 的长度 sb.append(\"$3\").append(LINE_SUFFIX); // 第一个参数的内容 sb.append(\"SET\").append(LINE_SUFFIX); // 第二个参数key的长度 sb.append(\"$\").append(key.getBytes().length).append(LINE_SUFFIX); // 第二个参数key 的内容 sb.append(key).append(LINE_SUFFIX); // 第三个参数value的长度 sb.append(\"$\").append(val.getBytes().length).append(LINE_SUFFIX); // 第三个参数value 的内容 sb.append(val).append(LINE_SUFFIX); write.write(sb.toString().getBytes()); byte[] bytes = new byte[1024]; read.read(bytes); System.out.println(\"----set------的返回结果为:\" + new String(bytes)); &amp;#125; public void get(String key) throws IOException &amp;#123; StringBuffer sb = new StringBuffer(); // 代表2个参数 sb.append(\"*2\").append(LINE_SUFFIX); // 第一个参数(get)的长度 sb.append(\"$3\").append(LINE_SUFFIX); // 第一个参数的内容 sb.append(\"GET\").append(LINE_SUFFIX); //第二个参数的长度 sb.append(\"$\").append(key.getBytes().length).append(LINE_SUFFIX); // 第二个参数的值 sb.append(key).append(LINE_SUFFIX); write.write(sb.toString().getBytes()); byte[] bytes = new byte[1024]; read.read(bytes); System.out.println(\"-------get------的返回结果为:\" + new String(bytes)); &amp;#125; public static void main(String[] args) throws IOException &amp;#123; MyRedisClient redisClient = new MyRedisClient(\"192.168.8.220\", 6379); redisClient.set(\"test\", \"111111\"); redisClient.get(\"test\"); &amp;#125; &amp;#125; 基于这种协议, 我们可以用java实现所有的redis操作命令。当然, 我们不需要这么做, 因为已经有很多成熟的java客户端, 实现了完整的功能和高级特性, 并且提供了很好的性能. https://redis.io/clients 官网推荐的java客户端主要有三个jedis、redisson和luttuce. 客户端 描述 jedis A blazingly small and sane redis java client redisson distributed and scalable Java data structures on top of Redis server luttuce Advanced Redis client for thread-safe sync, async, and reactive usage. Supports Cluster, Sentinel, Pipelining, and codecs. Spring连接redis使用的是什么？ RedisConnectionFactory 接口支持多种实现, 例如: JedisConnectionFactory、LettuceConnectionFactory 等. 2 Jedis1.2.1 特点jedis 是我们最熟悉和最常用的客户端. 轻量、简单、便于集成和改造. public static void main(String[] args) &amp;#123; Jedis jedis = new Jedis(\"localhost\", 6379); jedis.set(\"test\", \"111\"); System.out.println(jedis.get(\"test\")); jedis.close(); &amp;#125; jedis 多个线程使用一个连接的时候线程不安全. 可以使用连接池, 为每个请求创建不同的连接, 基于Apache common pool 实现. 跟数据库是一样的, 可以设置最大连接数等参数. jedis 中有多种连接池的子类. jedis 有3种工作模式: 单节点、分片、哨兵、集群 3种请求模式:client、pipeline和事务. client模式就是客户端发送一个命令, 阻塞等待服务端执行,然后服务返回结果。 pipeline 模式就是一次性发送多条命令, 最后一次性取回所有的返回结果,这种模式通过减少网络的往返时间和io读写, 大幅度提高通信性能. 第三种事务模式, Transaction 模式即开启redis 的事务管理, 事务模式开启后,所有的命令(除了exec、discard、multi和watch) 到达服务端以后不会立即执行, 会进入一个等待队列. 1.2.2 sentinel 获取连接原理问题： jedis 连接sentinel 的时候, 我们配置的是全部哨兵地址, sentinel 是如何返回可用的master地址的呢? 在构造方法: public JedisSentinelPool(String masterName, Set&lt;String> sentinels) &amp;#123; this(masterName, sentinels, new GenericObjectPoolConfig(), 2000, (String)null, 0); &amp;#125; 我们继续往下看, 直到 redis.clients.jedis.JedisSentinelPool#JedisSentinelPool(java.lang.String, java.util.Set&lt;java.lang.String&gt;, org.apache.commons.pool2.impl.GenericObjectPoolConfig, int, int, java.lang.String, int, java.lang.String) public JedisSentinelPool(String masterName, Set&lt;String> sentinels, GenericObjectPoolConfig poolConfig, int connectionTimeout, int soTimeout, String password, int database, String clientName) &amp;#123; this.connectionTimeout = 2000; this.soTimeout = 2000; this.database = 0; this.masterListeners = new HashSet(); this.log = Logger.getLogger(this.getClass().getName()); this.poolConfig = poolConfig; this.connectionTimeout = connectionTimeout; this.soTimeout = soTimeout; this.password = password; this.database = database; this.clientName = clientName; HostAndPort master = this.initSentinels(sentinels, masterName); this.initPool(master); &amp;#125; 我们看到调用了HostAndPort master = this.initSentinels(sentinels, masterName); private HostAndPort initSentinels(Set&lt;String> sentinels, final String masterName) &amp;#123; HostAndPort master = null; boolean sentinelAvailable = false; log.info(\"Trying to find master from available Sentinels...\"); //有多个sentinel 地址转换为一个HostAndPort 对象 for (String sentinel : sentinels) &amp;#123; // host:port 表示的sentinel 地址转换为一个HostAndPort 对象 final HostAndPort hap = HostAndPort.parseString(sentinel); log.fine(\"Connecting to Sentinel \" + hap); Jedis jedis = null; try &amp;#123; // 连接到sentinel jedis = new Jedis(hap.getHost(), hap.getPort()); // 根据masterName 得到一个master地址, 返回一个list, host=list[0], port=list[1] List&lt;String> masterAddr = jedis.sentinelGetMasterAddrByName(masterName); // connected to sentinel... sentinelAvailable = true; if (masterAddr == null || masterAddr.size() != 2) &amp;#123; log.warning(\"Can not get master addr, master name: \" + masterName + \". Sentinel: \" + hap + \".\"); continue; &amp;#125; // 如果在任何一个sentinel 中找到了master, 不再遍历 sentinel master = toHostAndPort(masterAddr); log.fine(\"Found Redis master at \" + master); break; &amp;#125; catch (JedisException e) &amp;#123; // resolves #1036, it should handle JedisException there's another chance // of raising JedisDataException log.warning(\"Cannot get master address from sentinel running @ \" + hap + \". Reason: \" + e + \". Trying next one.\"); &amp;#125; finally &amp;#123; if (jedis != null) &amp;#123; jedis.close(); &amp;#125; &amp;#125; &amp;#125; // 到这里, 如果master为null, 则说明有两种情况, 一种是所有的sentinel节点都down掉了, 另外一种是master没有被存活的sentinel 监控到 if (master == null) &amp;#123; if (sentinelAvailable) &amp;#123; // can connect to sentinel, but master name seems to not // monitored throw new JedisException(\"Can connect to sentinel, but \" + masterName + \" seems to be not monitored...\"); &amp;#125; else &amp;#123; throw new JedisConnectionException(\"All sentinels down, cannot determine where is \" + masterName + \" master is running...\"); &amp;#125; &amp;#125; // 如果走到这里, 说明找到了master的地址 log.info(\"Redis master running at \" + master + \", starting Sentinel listeners...\"); // 启动对每个sentinel 的监控为每个sentinel 都启动一个监听者 `masterListener`. MasterListener 本身是一个线程, 它会去订阅sentinel 上关于master节点地址改变的消息. for (String sentinel : sentinels) &amp;#123; final HostAndPort hap = HostAndPort.parseString(sentinel); MasterListener masterListener = new MasterListener(masterName, hap.getHost(), hap.getPort()); // whether MasterListener threads are alive or not, process can be stopped masterListener.setDaemon(true); masterListeners.add(masterListener); masterListener.start(); &amp;#125; return master; &amp;#125; 1.2.3 Cluster 获取连接原理 public static void main(String[] args) throws IOException &amp;#123; HostAndPort h1 = new HostAndPort(\"192.168.8.207\", 7291); HostAndPort h2 = new HostAndPort(\"192.168.8.207\", 7292); HostAndPort h3 = new HostAndPort(\"192.168.8.207\", 7293); HostAndPort h4 = new HostAndPort(\"192.168.8.207\", 7294); HostAndPort h5 = new HostAndPort(\"192.168.8.207\", 7295); HostAndPort h6 = new HostAndPort(\"192.168.8.207\", 7296); Set nodes = new HashSet(); nodes.add(h1); nodes.add(h2); nodes.add(h3); nodes.add(h4); JedisCluster cluster = new JedisCluster(nodes); cluster.set(\"cluster:test\", \"1111\"); System.out.println(cluster.get(\"cluster:test\")); cluster.close(); &amp;#125; 问题: 使用jedis 连接cluster的时候, 我们只需要连接到任意一个或者多个redis group 中的实例地址, 那我们是怎么获取到需要操作的redis master 实例的? 关键问题: 在于如何存储slot和redis 连接池的关系 程序启动初始化集群环境, 读取配置文件中的节点配置, 无论是主从, 无论多少个, 只拿第一个, 获取redis 连接实例(后面有个break) 从JedisCluster cluster = new JedisCluster(nodes); 进入 到 redis.clients.jedis.BinaryJedisCluster#BinaryJedisCluster(java.util.Set&lt;redis.clients.jedis.HostAndPort&gt;, int, int, org.apache.commons.pool2.impl.GenericObjectPoolConfig) public BinaryJedisCluster(Set&lt;HostAndPort> jedisClusterNode, int timeout, int maxAttempts, final GenericObjectPoolConfig poolConfig) &amp;#123; this.connectionHandler = new JedisSlotBasedConnectionHandler(jedisClusterNode, poolConfig, timeout); this.maxAttempts = maxAttempts; &amp;#125; 最后进入到redis.clients.jedis.JedisClusterConnectionHandler#JedisClusterConnectionHandler public JedisClusterConnectionHandler(Set&lt;HostAndPort> nodes, final GenericObjectPoolConfig poolConfig, int connectionTimeout, int soTimeout, String password) &amp;#123; this.cache = new JedisClusterInfoCache(poolConfig, connectionTimeout, soTimeout, password); initializeSlotsCache(nodes, poolConfig, password); &amp;#125; private void initializeSlotsCache(Set&lt;HostAndPort> startNodes, GenericObjectPoolConfig poolConfig, String password) &amp;#123; for (HostAndPort hostAndPort : startNodes) &amp;#123; // 获取一个jedis实例 Jedis jedis = new Jedis(hostAndPort.getHost(), hostAndPort.getPort()); if (password != null) &amp;#123; jedis.auth(password); &amp;#125; try &amp;#123; // 获取redis节点和slot 虚拟槽 cache.discoverClusterNodesAndSlots(jedis); // 直接跳出循环 break; &amp;#125; catch (JedisConnectionException e) &amp;#123; // try next nodes &amp;#125; finally &amp;#123; if (jedis != null) &amp;#123; jedis.close(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 用获取的redis 连接实例执行clusterSlots() 方法, 实际执行redis 服务端cluster solts 命令, 获取虚拟槽信息. 该集合的基本信息为[long,long,list,list], 第一,二个元素为该节点负责槽点的起始位置, 第三个元素为是主节点信息, 第四个元素为主节点对应的从节点的信息. 该list 的基本信息为[string,int,string]. 第一个是host信息, 第二个是port信息, 第三个为唯一id. 获取有关节点的槽点信息后, 调用getAssignedSlotArray(slotinfo) 来获取所有的槽点值。 再获取主节点的地址信息, 调用generateHostAndPort(hostInfo), 生成一个hostAndPort 对象. 再根据节点地址信息来设置节点对应的jedisPool,即设置Map nodes的值 接下来判断若此时节点信息为主节点信息, 则调用assignSlotsToNodes 方法, 设置每个槽点值对应的连接池信息, 即设置Map slots 的值. redis.clients.jedis.JedisClusterInfoCache#discoverClusterNodesAndSlots public void discoverClusterNodesAndSlots(Jedis jedis) &amp;#123; w.lock(); try &amp;#123; reset(); // 获取节点信息 List&lt;Object> slots = jedis.clusterSlots(); // 遍历3个master节点 for (Object slotInfoObj : slots) &amp;#123; // slotInfo 槽开始，槽结束，主，从 // &amp;#123;[0,5460,7291,7294],[5461,10922,7292,7295],[10923,16383,7293,7296]&amp;#125; List&lt;Object> slotInfo = (List&lt;Object>) slotInfoObj; // 如果&lt;=2,表示没有分配slot if (slotInfo.size() &lt;= MASTER_NODE_INDEX) &amp;#123; continue; &amp;#125; // 获取分配到当前master节点的槽, 例如7291 节点的&amp;#123;0,1,2,3……5460&amp;#125; List&lt;Integer> slotNums = getAssignedSlotArray(slotInfo); // hostInfos int size = slotInfo.size(); // size是4，槽最小最大, 主, 从 // 第3位和第4位是主从端口的信息 for (int i = MASTER_NODE_INDEX; i &lt; size; i++) &amp;#123; List&lt;Object> hostInfos = (List&lt;Object>) slotInfo.get(i); if (hostInfos.size() &lt;= 0) &amp;#123; continue; &amp;#125; // 根据ip端口生成HostAndPort 对象 HostAndPort targetNode = generateHostAndPort(hostInfos); // 根据HostAndPort解析出 ip:port 的 key 值，再根据 key 从缓存中查询对应的 jedisPool 实例。如果没有 jedisPool实例，就创建 JedisPool 实例，最后放入缓存中。nodeKey 和 nodePool 的关系 setupNodeIfNotExist(targetNode); // 把 slot 和 jedisPool 缓存起来（16384 个），key 是 slot 下标，value 是连接池 if (i == MASTER_NODE_INDEX) &amp;#123; assignSlotsToNode(slotNums, targetNode); &amp;#125; &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; w.unlock(); &amp;#125; &amp;#125; 从集群环境中存取值: 把key作为参数, 执行CRC16 算法, 获取key对应的slot值. 通过该slot 值, 去slots的map 集合中获取jedisPool实例. 通过jedisPool 实例获取jedis 实例, 最终完成redis数据存取工作. 1.2.4 pipeline 当我们使用set方法设置几万条数据的时候, 会发现非常慢, 完全没有把redis 的10万的QPS 利用起来, 但是单个命令的执行到底慢在哪里? 慢在哪里?redis 使用的是客户端/服务端(C/S) 模式和请求/响应协议的TCP服务器 , 这意味着通常情况下下一个请求会遵循以下步骤: 客户端向服务端发送一个查询请求, 并监听socket 返回,通常是以阻塞模式, 等待服务端响应. 服务端处理命令, 并将结果返回给客户端. Redis客户端与redis服务端之间使用TCP 协议进行连接, 一个客户端可以通过一个socket 连接发起多个请求命令. 每个请求命令发出后client 通常会阻塞并等待redis服务器处理, Redis处理完成后请求命令会将结果通过响应报文返回给 Client, 因此当执行多条命令的时候都需要等待上一个命令执行完毕才执行 。 Redis 本身提供了一些批量操作的命令, 比如mget、mset,可以减少通信的时间, 但是大部分都是不支持multi操作的, 例如hash就没有. 由于通信会有网络延迟, 例如client 和server 之间的包传输时间需要10毫秒, 一次交互就需要20毫秒(RTT：Round Trip Time), 这样的话, client 1秒钟也只能发送50条命令, 这显然没有充分利用redis 的处理能力. 另外一个, redis 服务端执行I/O的次数过多. pipeline 管道那我们能不能像数据库的batch操作一样, 把一组命令组装在一起发送给redis 服务端执行,然后一次性获取返回结果呢? 这个就是pipeline的作用. pipeline 通过一个队列将所有的命令缓存起来, 然后把多条命令在一次连接中发送给服务器. 我们先来看一下效果： /** * @author luyanan * @since 2020/4/2 * &lt;p>使用pipeline 测试set&lt;/p> **/ public class PipelineTest &amp;#123; private static final String host = \"localhost\"; private static final int port = 6379; private static final int count = 100000; public static void main(String[] args) &amp;#123; // 普通插入 new Thread(() -> &amp;#123; long t1 = System.currentTimeMillis(); Jedis jedis = new Jedis(host, port); for (int i = 0; i &lt; count; i++) &amp;#123; jedis.set(\"aa\" + i, \"\" + i); &amp;#125; long t2 = System.currentTimeMillis(); System.out.println(\"普通插入\" + count + \"条数据,耗时:\" + (t2 - t1) + \"毫秒\"); for (int i = 0; i &lt; count; i++) &amp;#123; jedis.get(\"aa\" + i); &amp;#125; long t3 = System.currentTimeMillis(); System.out.println(\"普通获取\" + count + \"条数据,耗时:\" + (t3 - t2)+ \"毫秒\"); &amp;#125;).start(); // pipeline插入 new Thread(() -> &amp;#123; long t1 = System.currentTimeMillis(); Jedis jedis = new Jedis(host, port); Pipeline pipelined = jedis.pipelined(); for (int i = 0; i &lt; count; i++) &amp;#123; pipelined.set(\"pp\" + i, \"\" + i); &amp;#125; pipelined.syncAndReturnAll(); long t2 = System.currentTimeMillis(); System.out.println(\"pipeline插入\" + count + \"条数据,耗时:\" + (t2 - t1)+ \"毫秒\"); for (int i = 0; i &lt; count; i++) &amp;#123; pipelined.get(\"pp\" + i); &amp;#125; pipelined.syncAndReturnAll(); long t3 = System.currentTimeMillis(); System.out.println(\"pipeline获取\" + count + \"条数据,耗时:\" + (t3 - t2)+ \"毫秒\"); &amp;#125;).start(); &amp;#125; &amp;#125; 查看结果 pipeline插入100000条数据,耗时:1275毫秒 pipeline获取100000条数据,耗时:472毫秒 普通插入100000条数据,耗时:166122毫秒 普通获取100000条数据,耗时:170747毫秒 要实现pipeline , 既要服务端的支持, 也要客户端的支持. 对于服务端来说，需要能够处理客户端通过一个TCP连接发送起来的多个命令, 并且逐个执行命令一起返回. 对于客户端来说, 要把多个命令缓存起来, 达到一定的条件就发送出去, 最后才处理redis的应答(这里也要注意对客户端内存的消耗) jedis-pipeline的client-buffer限制是: 8192bytes, 客户端堆积的命令超过8192bytes 时, 会发送给服务端. 源码: redis.clients.util.RedisOutputStream#RedisOutputStream(java.io.OutputStream) public RedisOutputStream(final OutputStream out) &amp;#123; this(out, 8192); &amp;#125; pipeline 对于命令条数没有限制, 但是命令可能受限于TCP包的大小. 如果jedis 发送了一组命令, 而发送请求还没有结束, redis响应的结果会放在接收缓存区内, 如果接收缓冲区满了, jedis 会通知redis win=0, 此时redis 不会在发送结果给jedis端, 转而把响应结果保存在redis 服务端的输出缓冲区中,. 输出缓冲区的配置redis.conf client-output-buffer-limit &lt;class> &lt;hard limit> &lt;soft limit> &lt;soft seconds> client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 配置 作用 class 客户端类型，分为三种。a）normal：普通客户端；b）slave：slave 客户端，用于复制；c） pubsub：发布订阅客户端 hard limit 如果客户端使用的输出缓冲区大于，客户端会被立即关闭，0 代表不限制 soft limit soft seconds 如果客户端使用的输出缓冲区超过了并且持续了秒，客户端会被立即 关闭 每个客户端使用的输出缓存区的大小可以用client list命令查看 redis> client list id=5 addr=192.168.8.1:10859 fd=8 name= age=5 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=5 qbuf-free=32763 obl=16380 oll=227 omem=4654408 events=rw cmd=set obl: 输出缓冲区的长度(字节为单位, 0表示没有分配输出缓冲区) oll: 输出列表包含的对象数量(当输出缓冲区没有剩余空间时,命令回复会以字符串对象的形式被入队到这个队列里) omen: 输出缓冲区和输出列表占用的内存总量. 使用场景pipeline 适用于什么场景呢？ 如果某些操作需要马上得到redis操作是否成功的结果, 这种场景就不适合. 有些场景, 例如批量写入数据,对于结果的实时性和成功性要求不高的情况, 就可以用pipeline. 1.2.5 jedis 实现分布式锁原文地址, 中文地址 分布式锁的基本特性或者要求: 互斥性：只有一个客户端能够持有锁. 不会产生死锁, 即使持有锁的客户端崩溃, 也能保证后续其他客户端可以获取锁. 只有持有这把锁的客户端才能解锁 /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &amp;#123; // set支持多个参数 NX（not exist） XX（exist） EX（seconds） PX（million seconds） String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &amp;#123; return true; &amp;#125; return false; &amp;#125; 参数解读: lockKey: 是redis key 的名称, 也就是谁添加成功了这个key就代表谁获取锁成功. reqyesuId: 是客户端的id,设置成value, 如果我们要保证只有加锁的客户端才能释放锁, 就必须获取客户端的ID(保证第三点) SET_IF_NOT_EXIST 是我们的命令里面加上NX（保证第一点） SET_WITH_EXPIRE_TIME: PX 代表以毫秒为单位设置key 的过期时间(保证第2点), expireTime 是自动释放锁的时间, 比如5000代表5秒 释放锁, 直接删除key 来释放锁, 可以吗? 就像这样 public static void wrongReleaseLock1(Jedis jedis, String lockKey) &amp;#123; jedis.del(lockKey); &amp;#125; 没有对requestId 进行判断, 可能会释放其他客户端持有的锁. 先判断后删除呢? public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) &amp;#123; // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) &amp;#123; // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); &amp;#125; &amp;#125; 如果在释放锁的时候, 这把锁已经不属于这个客户端了(例如已经过期, 并且已经被别的客户端获取锁成功了)， 那就回出现释放了其他客户端的锁的情况. 所以我们把判断客户端是否相等和删除key的操作放在lua脚本里面执行, /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &amp;#123; String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &amp;#123; return true; &amp;#125; return false; &amp;#125; 这个是jedis 里面分布式锁的实现. 3 Luttuce1.3.1 特点与jedis相比, Luttuce则完全克服了其线程不安全的缺点：Luttuce 是一个可伸缩的线程安全的redis客户端, 支持同步、异步和响应式模式(Reactive).多线程可以共享一个连接实例,而不必担心多线程并发的问题. 同步调用： public static void main(String[] args) &amp;#123; RedisClient redisClient = RedisClient.create(\"redis://127.0.0.1:6379\"); // 线程安全的长连接, 连接丢失的时候会自动创建 StatefulRedisConnection&lt;String, String> connect = redisClient.connect(); // 获取同步执行命令， 默认超时时间, 默认超时时间为60s RedisCommands&lt;String, String> commands = connect.sync(); // 发送get请求, commands.set(\"sync_test\", \"1111\"); String value = commands.get(\"sync_test\"); //关闭连接 connect.close(); //关闭客户端 redisClient.shutdown(); &amp;#125; 异步调用 public static void main(String[] args) throws InterruptedException, ExecutionException, TimeoutException &amp;#123; RedisClient redisClient = RedisClient.create(\"redis://127.0.0.1:6379\"); // 线程安全的长连接, 连接丢失的时候会自动创建 StatefulRedisConnection&lt;String, String> connect = redisClient.connect(); // 获取异步执行命名 RedisAsyncCommands&lt;String, String> commands = connect.async(); // 发送get请求, commands.set(\"async_test\", \"1111\"); RedisFuture&lt;String> future = commands.get(\"sync_test\"); String value = future.get(60, TimeUnit.SECONDS); //关闭连接 connect.close(); //关闭客户端 redisClient.shutdown(); &amp;#125; 它是基于Netty框架构建的, 支持redis 的高级功能, 比如pipeline、发布订阅、事务、sentinel、集群, 支持连接池. Luttuce 是Spring Boot 2.X 默认的客户端, 替换了jedis. 集成之后不需要单独使用它, 直接调用Spring的RedisTemplate 操作, 连接和创建和关闭也是不需要我们自己操心. 4 Redisson文档地址 : https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95 1.4.1 本质Redisson 是一个在redis的基础上实现的java驻内存数据网格(In-Memory Data Grid), 提供了分布式和可扩展的java数据结构. 1.4.2 特点基于Netty实现,采用非阻塞io, 性能高. 支持异步请求. 支持连接池、pipeline、LUA Scripting、Redis Sentinel、Redis Cluster. 不支持事务, 官方建议使用LUA Scripting 代替事务. 主从、哨兵、集群都支持, Spring 也可以配置和注入RedissonClient 1.4.3 实现分布锁在Redisson 里面提供了简单的分布式锁的实现. public class LockTest &amp;#123; private static RedissonClient redissonClient; static &amp;#123; Config config = new Config(); config.useSingleServer().setAddress(\"redis://127.0.0.1:6379\"); redissonClient = Redisson.create(config); &amp;#125; public static void main(String[] args) throws InterruptedException &amp;#123; RLock lock = redissonClient.getLock(\"updateAccount\"); if (lock.tryLock(100, 10, TimeUnit.SECONDS)) &amp;#123; System.out.println(\"获取锁\"); &amp;#125; lock.unlock(); redissonClient.shutdown(); &amp;#125; &amp;#125; 在获得RLock 之后, 有个tryLock 方法, 里面有3个参数: waitTime: 获取锁的最大等待时间, 超过这个时间就不再尝试获取锁了. leaseTime: 如果没有调用unlock 方法 ,超过了这个时间就自动释放锁. timeunit: 释放时间的单位. Redisson 的分布式锁是怎么实现的呢? 在加锁的时候,在redis 写入了一个Hash , key是锁的名字， field 是线程名称, value 是1(表示锁的冲入次数) 源码： tryLock()——tryAcquire()——tryAcquireAsync()——tryLockInnerAsync() &lt;T> RFuture&lt;T> tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T> command) &amp;#123; internalLockLeaseTime = unit.toMillis(leaseTime); return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + \"return redis.call('pttl', KEYS[1]);\", Collections.&lt;Object>singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &amp;#125; 最终调用的是一段lua 脚本,里面有一个参数,两个参数的值. 占位 填充 含义 实际值 KEYS[1] getName() 锁的名称(key) updateAccount ARGV[1] internalLockLeaseTime 锁释放时间(毫秒) 10000 ARGV[2] getLockName(threadId) 线程名称 b60a9c8c-92f8-4bfe-b0e7-308967346336:1 // KEYS[1] 锁名称 updateAccount // ARGV[1] key 过期时间 10000ms // ARGV[2] 线程名称 // 锁名称不存在 if (redis.call('exists', KEYS[1]) == 0) then // 创建一个 hash，key=锁名称，field=线程名，value=1 redis.call('hset', KEYS[1], ARGV[2], 1); // 设置 hash 的过期时间 redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; // 锁名称存在，判断是否当前线程持有的锁 if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then // 如果是，value+1，代表重入次数+1 redis.call('hincrby', KEYS[1], ARGV[2], 1); // 重新获得锁，需要重新设置 Key 的过期时间 redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; // 锁存在，但是不是当前线程持有，返回过期时间（毫秒） return redis.call('pttl', KEYS[1]); 释放锁, 源码: unlock——unlockInnerAsync protected RFuture&lt;Boolean> unlockInnerAsync(long threadId) &amp;#123; return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \" + \"end;\" + \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" + \"return nil;\" + \"end; \" + \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" + \"if (counter > 0) then \" + \"redis.call('pexpire', KEYS[1], ARGV[2]); \" + \"return 0; \" + \"else \" + \"redis.call('del', KEYS[1]); \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \"+ \"end; \" + \"return nil;\", Arrays.&lt;Object>asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId)); &amp;#125; 占位 填充 含义 实际值 KEYS[1] getName() 锁名称 updateAccount KEYS[2] getChannelName() 频道名称 redisson_lock__channel:&#123;updateAccount&#125; ARGV[1] LockPubSub.unlockMessage 解锁的时候的消息 0 ARGV[2] internalLockLeaseTime 释放锁的时间 10000 ARGV[3] getLockName(threadId) 线程名称 b60a9c8c-92f8-4bfe-b0e7-308967346336:1 ​ // KEYS[1] 锁的名称 updateAccount // KEYS[2] 频道名称 redisson_lock__channel:&amp;#123;updateAccount&amp;#125; // ARGV[1] 释放锁的消息 0 // ARGV[2] 锁释放时间 10000 // ARGV[3] 线程名称 // 锁不存在（过期或者已经释放了） if (redis.call('exists', KEYS[1]) == 0) then // 发布锁已经释放的消息 redis.call('publish', KEYS[2], ARGV[1]); return 1; end; // 锁存在，但是不是当前线程加的锁 if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then return nil; end; // 锁存在，是当前线程加的锁 // 重入次数-1 local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); // -1 后大于 0，说明这个线程持有这把锁还有其他的任务需要执行 if (counter > 0) then // 重新设置锁的过期时间 redis.call('pexpire', KEYS[1], ARGV[2]); return 0; else // -1 之后等于 0，现在可以删除锁了 redis.call('del', KEYS[1]); // 删除之后发布释放锁的消息 redis.call('publish', KEYS[2], ARGV[1]); return 1; end; // 其他情况返回 nil return nil; 这个是Redisson 里面分布式锁的实现, 我们在调用的时候非常简单. Redisson跟Jedis 定位不同, 它不是一个单纯的Redis 客户端, 而是基于redis 实现的分布式服务, 如果有需要用到一些分布式的数据结构, 我们我们可以基于Redisson的分布式队列实现分布式事务,就可以引入Redisson 的依赖实现.","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"mysql   百科全书","slug":"mysql/mysql   百科全书","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/mysql/mysql-bai-ke-quan-shu/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mysql/mysql-bai-ke-quan-shu/","excerpt":"","text":"[TOC] Windows服务--### 启动MySQL net start mysql -- 创建Windows服务 sc create mysql binPath= mysqld_bin_path(注意：等号与值之间有空格) 连接与断开服务器mysql -h 地址 -P 端口 -u 用户名 -p 密码 SHOW PROCESSLIST -- 显示哪些线程正在运行 SHOW VARIABLES -- 显示系统变量信息 数据库操作-- 查看当前数据库 SELECT DATABASE(); -- 显示当前时间、用户名、数据库版本 SELECT now(), user(), version(); -- 创建库 CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项 数据库选项： CHARACTER SET charset_name COLLATE collation_name -- 查看已有库 SHOW DATABASES[ LIKE &#39;PATTERN&#39;] -- 查看当前库信息 SHOW CREATE DATABASE 数据库名 -- 修改库的选项信息 ALTER DATABASE 库名 选项信息 -- 删除库 DROP DATABASE[ IF EXISTS] 数据库名 同时删除该数据库相关的目录及其目录内容 表的操作-- 创建表 CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定义 )[ 表选项] 每个字段必须有数据类型 最后一个字段后不能有逗号 TEMPORARY 临时表，会话结束时表自动消失 对于字段的定义： 字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT &#39;string&#39;] -- 表选项 -- 字符集 CHARSET = charset_name 如果表没有设定，则使用数据库字符集 -- 存储引擎 ENGINE = engine_name 表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同 常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive 不同的引擎在保存表的结构和数据时采用不同的方式 MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引 InnoDB表文件含义：.frm表定义，表空间数据和日志文件 SHOW ENGINES -- 显示存储引擎的状态信息 SHOW ENGINE 引擎名 &#123;LOGS|STATUS&#125; -- 显示存储引擎的日志或状态信息 -- 自增起始数 AUTO_INCREMENT = 行数 -- 数据文件目录 DATA DIRECTORY = &#39;目录&#39; -- 索引文件目录 INDEX DIRECTORY = &#39;目录&#39; -- 表注释 COMMENT = &#39;string&#39; -- 分区选项 PARTITION BY ... (详细见手册) -- 查看所有表 SHOW TABLES[ LIKE &#39;pattern&#39;] SHOW TABLES FROM 表名 -- 查看表机构 SHOW CREATE TABLE 表名 （信息更详细） DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE &#39;PATTERN&#39;] SHOW TABLE STATUS [FROM db_name] [LIKE &#39;pattern&#39;] -- 修改表 -- 修改表本身的选项 ALTER TABLE 表名 表的选项 eg: ALTER TABLE 表名 ENGINE=MYISAM; -- 对表进行重命名 RENAME TABLE 原表名 TO 新表名 RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库） -- RENAME可以交换两个表名 -- 修改表的字段机构（13.1.2. ALTER TABLE语法） ALTER TABLE 表名 操作名 -- 操作名 ADD[ COLUMN] 字段定义 -- 增加字段 AFTER 字段名 -- 表示增加在该字段名后面 FIRST -- 表示增加在第一个 ADD PRIMARY KEY(字段名) -- 创建主键 ADD UNIQUE [索引名] (字段名)-- 创建唯一索引 ADD INDEX [索引名] (字段名) -- 创建普通索引 DROP[ COLUMN] 字段名 -- 删除字段 MODIFY[ COLUMN] 字段名 字段属性 -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上) CHANGE[ COLUMN] 原字段名 新字段名 字段属性 -- 支持对字段名修改 DROP PRIMARY KEY -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性) DROP INDEX 索引名 -- 删除索引 DROP FOREIGN KEY 外键 -- 删除外键 -- 删除表 DROP TABLE[ IF EXISTS] 表名 ... -- 清空表数据 TRUNCATE [TABLE] 表名 -- 复制表结构 CREATE TABLE 表名 LIKE 要复制的表名 -- 复制表结构和数据 CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名 -- 检查表是否有错误 CHECK TABLE tbl_name [, tbl_name] ... [option] ... -- 优化表 OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... -- 修复表 REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM] -- 分析表 ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 数据操作-- 增 INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), ...] -- 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。 -- 可同时插入多条数据记录！ REPLACE 与 INSERT 完全一样，可互换。 INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, ...] -- 查 SELECT 字段列表 FROM 表名[ 其他子句] -- 可来自多个表的多个字段 -- 其他子句可以不使用 -- 字段列表可以用*代替，表示所有字段 -- 删 DELETE FROM 表名[ 删除条件子句] 没有条件子句，则会删除全部 -- 改 UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件] 字符集编码-- MySQL、数据库、表、字段均可设置编码 -- 数据编码与客户端编码不需一致 SHOW VARIABLES LIKE &#39;character_set_%&#39; -- 查看所有字符集编码项 character_set_client 客户端向服务器发送数据时使用的编码 character_set_results 服务器端将结果返回给客户端所使用的编码 character_set_connection 连接层编码 SET 变量名 = 变量值 SET character_set_client = gbk; SET character_set_results = gbk; SET character_set_connection = gbk; SET NAMES GBK; -- 相当于完成以上三个设置 -- 校对集 校对集用以排序 SHOW CHARACTER SET [LIKE &#39;pattern&#39;]/SHOW CHARSET [LIKE &#39;pattern&#39;] 查看所有字符集 SHOW COLLATION [LIKE &#39;pattern&#39;] 查看所有校对集 CHARSET 字符集编码 设置字符集编码 COLLATE 校对集编码 设置校对集编码 数据类型（列类型）1. 数值类型 -- a. 整型 ---------- 类型 字节 范围（有符号位） tinyint 1字节 -128 ~ 127 无符号位：0 ~ 255 smallint 2字节 -32768 ~ 32767 mediumint 3字节 -8388608 ~ 8388607 int 4字节 bigint 8字节 int(M) M表示总位数 - 默认存在符号位，unsigned 属性修改 - 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改 例：int(5) 插入一个数&#39;123&#39;，补填后为&#39;00123&#39; - 在满足要求的情况下，越小越好。 - 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。 -- b. 浮点型 ---------- 类型 字节 范围 float(单精度) 4字节 double(双精度) 8字节 浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。 不同于整型，前后均会补填0. 定义浮点型时，需指定总位数和小数位数。 float(M, D) double(M, D) M表示总位数，D表示小数位数。 M和D的大小会决定浮点数的范围。不同于整型的固定范围。 M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。 支持科学计数法表示。 浮点数表示近似值。 -- c. 定点数 ---------- decimal -- 可变长度 decimal(M, D) M也表示总位数，D表示小数位数。 保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。 将浮点数转换为字符串来保存，每9位数字保存为4个字节。 2. 字符串类型 -- a. char, varchar ---------- char 定长字符串，速度快，但浪费空间 varchar 变长字符串，速度慢，但节省空间 M表示能存储的最大长度，此长度是字符数，非字节数。 不同的编码，所占用的空间不同。 char,最多255个字符，与编码无关。 varchar,最多65535字符，与编码有关。 一条有效记录最大不能超过65535个字节。 utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符 varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。 varchar 的最大有效长度由最大行大小和使用的字符集确定。 最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。 例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3 -- b. blob, text ---------- blob 二进制字符串（字节字符串） tinyblob, blob, mediumblob, longblob text 非二进制字符串（字符字符串） tinytext, text, mediumtext, longtext text 在定义时，不需要定义长度，也不会计算总长度。 text 类型在定义时，不可给default值 -- c. binary, varbinary ---------- 类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。 char, varchar, text 对应 binary, varbinary, blob. 3. 日期时间类型 一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。 datetime 8字节 日期及时间 1000-01-01 00:00:00 到 9999-12-31 23:59:59 date 3字节 日期 1000-01-01 到 9999-12-31 timestamp 4字节 时间戳 19700101000000 到 2038-01-19 03:14:07 time 3字节 时间 -838:59:59 到 838:59:59 year 1字节 年份 1901 - 2155 datetime YYYY-MM-DD hh:mm:ss timestamp YY-MM-DD hh:mm:ss YYYYMMDDhhmmss YYMMDDhhmmss YYYYMMDDhhmmss YYMMDDhhmmss date YYYY-MM-DD YY-MM-DD YYYYMMDD YYMMDD YYYYMMDD YYMMDD time hh:mm:ss hhmmss hhmmss year YYYY YY YYYY YY 4. 枚举和集合 -- 枚举(enum) ---------- enum(val1, val2, val3...) 在已知的值中进行单选。最大数量为65535. 枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。 表现为字符串类型，存储却是整型。 NULL值的索引是NULL。 空字符串错误值的索引值是0。 -- 集合（set） ---------- set(val1, val2, val3...) create table tab ( gender set(&#39;男&#39;, &#39;女&#39;, &#39;无&#39;) ); insert into tab values (&#39;男, 女&#39;); 最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。 当创建表时，SET成员值的尾部空格将自动被删除。 选择类型-- PHP角度 1. 功能满足 2. 存储空间尽量小，处理效率更高 3. 考虑兼容问题 -- IP存储 ---------- 1. 只需存储，可用字符串 2. 如果需计算，查找等，可存储为4个字节的无符号int，即unsigned 1) PHP函数转换 ip2long可转换为整型，但会出现携带符号问题。需格式化为无符号的整型。 利用sprintf函数格式化字符串 sprintf(&quot;%u&quot;, ip2long(&#39;192.168.3.134&#39;)); 然后用long2ip将整型转回IP字符串 2) MySQL函数转换(无符号整型，UNSIGNED) INET_ATON(&#39;127.0.0.1&#39;) 将IP转为整型 INET_NTOA(2130706433) 将整型转为IP 列属性（列约束）1. PRIMARY 主键 - 能唯一标识记录的字段，可以作为主键。 - 一个表只能有一个主键。 - 主键具有唯一性。 - 声明字段时，用 primary key 标识。 也可以在字段列表之后声明 例：create table tab ( id int, stu varchar(10), primary key (id)); - 主键字段的值不能为null。 - 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。 例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age)); 2. UNIQUE 唯一索引（唯一约束） 使得某字段的值也不能重复。 3. NULL 约束 null不是数据类型，是列的一个属性。 表示当前列是否可以为null，表示什么都没有。 null, 允许为空。默认。 not null, 不允许为空。 insert into tab values (null, &#39;val&#39;); -- 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null 4. DEFAULT 默认值属性 当前字段的默认值。 insert into tab values (default, &#39;val&#39;); -- 此时表示强制使用默认值。 create table tab ( add_time timestamp default current_timestamp ); -- 表示将当前时间的时间戳设为默认值。 current_date, current_time 5. AUTO_INCREMENT 自动增长约束 自动增长必须为索引（主键或unique） 只能存在一个字段为自动增长。 默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x; 6. COMMENT 注释 例：create table tab ( id int ) comment &#39;注释内容&#39;; 7. FOREIGN KEY 外键约束 用于限制主表与从表数据完整性。 alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references t2(id); -- 将表t1的t1_id外键关联到表t2的id字段。 -- 每个外键都有一个名字，可以通过 constraint 指定 存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。 作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。 MySQL中，可以对InnoDB引擎使用外键约束： 语法： foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作] 此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。 可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。 如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择： 1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。 2. set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。 3. restrict，拒绝父表删除和更新。 注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。 建表规范 -- Normal Format, NF - 每个表保存一个实体信息 - 每个具有一个ID字段作为主键 - ID主键 + 原子表 -- 1NF, 第一范式 字段不能再分，就满足第一范式。 -- 2NF, 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除符合主键就可以避免部分依赖。增加单列关键字。 -- 3NF, 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。 SELECTSELECT [ALL|DISTINCT] select_expr FROM -&gt; WHERE -&gt; GROUP BY [合计函数] -&gt; HAVING -&gt; ORDER BY -&gt; LIMIT a. select_expr -- 可以用 * 表示所有字段。 select * from tb; -- 可以使用表达式（计算公式、函数调用、字段也是个表达式） select stu, 29+25, now() from tb; -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。 - 使用 as 关键字，也可省略 as. select stu+10 as add10 from tb; b. FROM 子句 用于标识查询来源。 -- 可以为表起别名。使用as关键字。 SELECT * FROM tb1 AS tt, tb2 AS bb; -- from子句后，可以同时出现多个表。 -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。 SELECT * FROM tb1, tb2; -- 向优化符提示如何选择索引 USE INDEX、IGNORE INDEX、FORCE INDEX SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3; SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3; c. WHERE 子句 -- 从from获得的数据源中进行筛选。 -- 整型1表示真，0表示假。 -- 表达式由运算符和运算数组成。 -- 运算数：变量（字段）、值、函数返回值 -- 运算符： =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||, in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor is/is not 加上ture/false/unknown，检验某个值的真假 &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较 d. GROUP BY 子句, 分组子句 GROUP BY 字段/别名 [排序方式] 分组后会进行排序。升序：ASC，降序：DESC 以下[合计函数]需配合 GROUP BY 使用： count 返回不同的非NULL值数目 count(*)、count(字段) sum 求和 max 求最大值 min 求最小值 avg 求平均值 group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。 e. HAVING 子句，条件子句 与 where 功能、用法相同，执行时机不同。 where 在开始时执行检测数据，对原数据进行过滤。 having 对筛选出的结果再次进行过滤。 having 字段必须是查询出来的，where 字段必须是数据表存在的。 where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。 where 不可以使用合计函数。一般需用合计函数才会用 having SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。 f. ORDER BY 子句，排序子句 order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]... 升序：ASC，降序：DESC 支持多个字段的排序。 g. LIMIT 子句，限制结果数量子句 仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。 limit 起始位置, 获取条数 省略第一个参数，表示从索引0开始。limit 获取条数 h. DISTINCT, ALL 选项 distinct 去除重复记录 默认为 all, 全部记录 UNION 将多个select查询的结果组合成一个结果集合。 SELECT ... UNION [ALL|DISTINCT] SELECT ... 默认 DISTINCT 方式，即所有返回的行都是唯一的 建议，对每个SELECT查询加上小括号包裹。 ORDER BY 排序时，需加上 LIMIT 进行结合。 需要各select查询的字段数量一样。 每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。 子查询 - 子查询需用括号包裹。 -- from型 from后要求是一个表，必须给子查询结果取个别名。 - 简化每个查询内的条件。 - from型需将结果生成一个临时表格，可用以原表的锁定的释放。 - 子查询返回一个表，表型子查询。 select * from (select * from tb where id&gt;0) as subfrom where id&gt;1; -- where型 - 子查询返回一个值，标量子查询。 - 不需要给子查询取别名。 - where子查询内的表，不能直接用以更新。 select * from tb where money = (select max(money) from tb); -- 列子查询 如果子查询结果返回的是一列。 使用 in 或 not in 完成查询 exists 和 not exists 条件 如果子查询返回数据，则返回1或0。常用于判断条件。 select column1 from t1 where exists (select * from t2); -- 行子查询 查询条件是一个行。 select * from t1 where (id, gender) in (select id, gender from t2); 行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...) 行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。 -- 特殊运算符 != all() 相当于 not in = some() 相当于 in。any 是 some 的别名 != some() 不等同于 not in，不等于其中某一个。 all, some 可以配合其他运算符一起使用。 连接查询(join) 将多个表的字段进行连接，可以指定连接条件。 -- 内连接(inner join) - 默认就是内连接，可省略inner。 - 只有数据存在时才能发送连接。即连接结果不能出现空行。 on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真） 也可用where表示连接条件。 还有 using, 但需字段名相同。 using(字段名) -- 交叉连接 cross join 即，没有条件的内连接。 select * from tb1 cross join tb2; -- 外连接(outer join) - 如果数据不存在，也会出现在连接结果中。 -- 左外连接 left join 如果数据不存在，左表记录会出现，而右表为null填充 -- 右外连接 right join 如果数据不存在，右表记录会出现，而左表为null填充 -- 自然连接(natural join) 自动判断连接条件完成连接。 相当于省略了using，会自动查找相同字段名。 natural join natural left join natural right join select info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id; 导出select * into outfile 文件地址 [控制格式] from 表名; -- 导出表数据 load data [local] infile 文件地址 [replace|ignore] into table 表名 [控制格式]; -- 导入数据 生成的数据默认的分隔符是制表符 local未指定，则数据文件必须在服务器上 replace 和 ignore 关键词控制对现有的唯一键记录的重复的处理 -- 控制格式 fields 控制字段格式 默认：fields terminated by &#39; &#39; enclosed by &#39;&#39; escaped by &#39;\\&#39; terminated by &#39;string&#39; -- 终止 enclosed by &#39;char&#39; -- 包裹 escaped by &#39;char&#39; -- 转义 -- 示例： SELECT a,b,a+b INTO OUTFILE &#39;/tmp/result.text&#39; FIELDS TERMINATED BY &#39;,&#39; OPTIONALLY ENCLOSED BY &#39;&quot;&#39; LINES TERMINATED BY &#39; &#39; FROM test_table; lines 控制行格式 默认：lines terminated by &#39; &#39; terminated by &#39;string&#39; -- 终止 INSERTselect语句获得的数据可以用insert插入。 可以省略对列的指定，要求 values () 括号内，提供给了按照列顺序出现的所有字段的值。 或者使用set语法。 INSERT INTO tbl_name SET field=value,...； 可以一次性使用多个值，采用(), (), ();的形式。 INSERT INTO tbl_name VALUES (), (), (); 可以在列值指定时，使用表达式。 INSERT INTO tbl_name VALUES (field_value, 10+10, now()); 可以使用一个特殊值 DEFAULT，表示该列使用默认值。 INSERT INTO tbl_name VALUES (field_value, DEFAULT); 可以通过一个查询的结果，作为需要插入的值。 INSERT INTO tbl_name SELECT ...; 可以指定在插入的值出现主键（或唯一索引）冲突时，更新其他非主键列的信息。 INSERT INTO tbl_name VALUES/SET/SELECT ON DUPLICATE KEY UPDATE 字段=值, …; DELETEDELETE FROM tbl_name [WHERE where_definition] [ORDER BY ...] [LIMIT row_count] 按照条件删除。where 指定删除的最多记录数。limit 可以通过排序条件删除。order by + limit 支持多表删除，使用类似连接语法。 delete from 需要删除数据多表1，表2 using 表连接操作 条件。 TRUNCATETRUNCATE [TABLE] tbl_name 清空数据 删除重建表 区别： 1，truncate 是删除表再创建，delete 是逐条删除 2，truncate 重置auto_increment的值。而delete不会 3，truncate 不知道删除了几条，而delete知道。 4，当被用于带分区的表时，truncate 会保留分区 备份与还原备份，将数据的结构与表内数据保存起来。 利用 mysqldump 指令完成。 -- 导出 mysqldump [options] db_name [tables] mysqldump [options] ---database DB1 [DB2 DB3...] mysqldump [options] --all--database 1. 导出一张表 mysqldump -u用户名 -p密码 库名 表名 &gt; 文件名(D:/a.sql) 2. 导出多张表 mysqldump -u用户名 -p密码 库名 表1 表2 表3 &gt; 文件名(D:/a.sql) 3. 导出所有表 mysqldump -u用户名 -p密码 库名 &gt; 文件名(D:/a.sql) 4. 导出一个库 mysqldump -u用户名 -p密码 --lock-all-tables --database 库名 &gt; 文件名(D:/a.sql) 可以-w携带WHERE条件 -- 导入 1. 在登录mysql的情况下： source 备份文件 2. 在不登录的情况下 mysql -u用户名 -p密码 库名 &lt; 备份文件 视图什么是视图： 视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。 视图具有表结构文件，但不存在数据文件。 对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。 视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。 -- 创建视图 CREATE [OR REPLACE] [ALGORITHM = &#123;UNDEFINED | MERGE | TEMPTABLE&#125;] VIEW view_name [(column_list)] AS select_statement - 视图名必须唯一，同时不能与表重名。 - 视图可以使用select语句查询到的列名，也可以自己指定相应的列名。 - 可以指定视图执行的算法，通过ALGORITHM指定。 - column_list如果存在，则数目必须等于SELECT语句检索的列数 -- 查看结构 SHOW CREATE VIEW view_name -- 删除视图 - 删除视图后，数据依然存在。 - 可同时删除多个视图。 DROP VIEW [IF EXISTS] view_name ... -- 修改视图结构 - 一般不修改视图，因为不是所有的更新视图都会映射到表上。 ALTER VIEW view_name [(column_list)] AS select_statement -- 视图作用 1. 简化业务逻辑 2. 对客户端隐藏真实的表结构 -- 视图算法(ALGORITHM) MERGE 合并 将视图的查询语句，与外部查询需要先合并再执行！ TEMPTABLE 临时表 将视图执行完毕后，形成临时表，再做外层查询！ UNDEFINED 未定义(默认)，指的是MySQL自主去选择相应的算法。 事务(transaction)事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。 - 支持连续SQL的集体成功或集体撤销。 - 事务是数据库在数据晚自习方面的一个功能。 - 需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。 - InnoDB被称为事务安全型引擎。 -- 事务开启 START TRANSACTION; 或者 BEGIN; 开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。 -- 事务提交 COMMIT; -- 事务回滚 ROLLBACK; 如果部分操作发生问题，映射到事务开启前。 -- 事务的特性 1. 原子性（Atomicity） 事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 2. 一致性（Consistency） 事务前后数据的完整性必须保持一致。 - 事务开始和结束时，外部数据一致 - 在整个事务过程中，操作是连续的 3. 隔离性（Isolation） 多个用户并发访问数据库时，一个用户的事务不能被其它用户的事物所干扰，多个并发事务之间的数据要相互隔离。 4. 持久性（Durability） 一个事务一旦被提交，它对数据库中的数据改变就是永久性的。 -- 事务的实现 1. 要求是事务支持的表类型 2. 执行一组相关的操作前开启事务 3. 整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。 -- 事务的原理 利用InnoDB的自动提交(autocommit)特性完成。 普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。 而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。 -- 注意 1. 数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。 2. 事务不能被嵌套 -- 保存点 SAVEPOINT 保存点名称 -- 设置一个事务保存点 ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点 RELEASE SAVEPOINT 保存点名称 -- 删除保存点 -- InnoDB自动提交特性设置 SET autocommit = 0|1; 0表示关闭自动提交，1表示开启自动提交。 - 如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。 - 也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是， SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接) 而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务) 锁表表锁定只用于防止其它客户端进行不正当地读取和写入 MyISAM 支持表锁，InnoDB 支持行锁 -- 锁定 LOCK TABLES tbl_name [AS alias] -- 解锁 UNLOCK TABLES 触发器 触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象 监听：记录的增加、修改、删除。 -- 创建触发器 CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt 参数： trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。 trigger_event指明了激活触发程序的语句的类型 INSERT：将新行插入表时激活触发程序 UPDATE：更改某一行时激活触发程序 DELETE：从表中删除某一行时激活触发程序 tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。 trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN...END复合语句结构 -- 删除 DROP TRIGGER [schema_name.]trigger_name 可以使用old和new代替旧的和新的数据 更新操作，更新前是old，更新后是new. 删除操作，只有old. 增加操作，只有new. -- 注意 1. 对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。 函数-- 字符连接函数 concat(str1,str2,...]) concat_ws(separator,str1,str2,...) -- 分支语句 if 条件 then 执行语句 elseif 条件 then 执行语句 else 执行语句 end if; -- 修改最外层语句结束符 delimiter 自定义结束符号 SQL语句 自定义结束符号 delimiter ; -- 修改回原来的分号 -- 语句块包裹 begin 语句块 end -- 特殊的执行 1. 只要添加记录，就会触发程序。 2. Insert into on duplicate key update 语法会触发： 如果没有重复记录，会触发 before insert, after insert; 如果有重复记录并更新，会触发 before insert, before update, after update; 如果有重复记录但是没有发生更新，则触发 before insert, before update 3. Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert SQL编程--// 局部变量 ---------- -- 变量声明 declare var_name[,...] type [default value] 这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。 -- 赋值 使用 set 和 select into 语句为变量赋值。 - 注意：在函数内是可以使用全局变量（用户自定义的变量） --// 全局变量 ---------- -- 定义、赋值 set 语句可以定义并为变量赋值。 set @var = value; 也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。 还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。 select @var:=20; select @v1:=id, @v2=name from t1 limit 1; select * from tbl_name where @var:=30; select into 可以将表中查询获得的数据赋给变量。 -| select max(height) into @max_height from tb; -- 自定义变量名 为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。 @var=10; - 变量被定义后，在整个会话周期都有效（登录到退出） --// 控制结构 ---------- -- if语句 if search_condition then statement_list [elseif search_condition then statement_list] ... [else statement_list] end if; -- case语句 CASE value WHEN [compare-value] THEN result [WHEN [compare-value] THEN result ...] [ELSE result] END -- while循环 [begin_label:] while search_condition do statement_list end while [end_label]; - 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。 -- 退出循环 退出整个循环 leave 退出当前循环 iterate 通过退出的标签决定退出哪个循环 --// 内置函数 ---------- -- 数值函数 abs(x) -- 绝对值 abs(-10.9) = 10 format(x, d) -- 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46 ceil(x) -- 向上取整 ceil(10.1) = 11 floor(x) -- 向下取整 floor (10.1) = 10 round(x) -- 四舍五入去整 mod(m, n) -- m%n m mod n 求余 10%3=1 pi() -- 获得圆周率 pow(m, n) -- m^n sqrt(x) -- 算术平方根 rand() -- 随机数 truncate(x, d) -- 截取d位小数 -- 时间日期函数 now(), current_timestamp(); -- 当前日期时间 current_date(); -- 当前日期 current_time(); -- 当前时间 date(&#39;yyyy-mm-dd hh:ii:ss&#39;); -- 获取日期部分 time(&#39;yyyy-mm-dd hh:ii:ss&#39;); -- 获取时间部分 date_format(&#39;yyyy-mm-dd hh:ii:ss&#39;, &#39;%d %y %a %d %m %b %j&#39;); -- 格式化时间 unix_timestamp(); -- 获得unix时间戳 from_unixtime(); -- 从时间戳获得时间 -- 字符串函数 length(string) -- string长度，字节 char_length(string) -- string的字符个数 substring(str, position [,length]) -- 从str的position开始,取length个字符 replace(str ,search_str ,replace_str) -- 在str中用replace_str替换search_str instr(string ,substring) -- 返回substring首次在string中出现的位置 concat(string [,...]) -- 连接字串 charset(str) -- 返回字串字符集 lcase(string) -- 转换成小写 left(string, length) -- 从string2中的左边起取length个字符 load_file(file_name) -- 从文件读取内容 locate(substring, string [,start_position]) -- 同instr,但可指定开始位置 lpad(string, length, pad) -- 重复用pad加在string开头,直到字串长度为length ltrim(string) -- 去除前端空格 repeat(string, count) -- 重复count次 rpad(string, length, pad) --在str后用pad补充,直到长度为length rtrim(string) -- 去除后端空格 strcmp(string1 ,string2) -- 逐字符比较两字串大小 -- 流程函数 case when [condition] then result [when [condition] then result ...] [else result] end 多分支 if(expr1,expr2,expr3) 双分支。 -- 聚合函数 count() sum(); max(); min(); avg(); group_concat() -- 其他常用函数 md5(); default(); --// 存储函数，自定义函数 ---------- -- 新建 CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型 函数体 - 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。 - 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。 - 参数部分，由&quot;参数名&quot;和&quot;参数类型&quot;组成。多个参数用逗号隔开。 - 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。 - 多条语句应该使用 begin...end 语句块包含。 - 一定要有 return 返回值语句。 -- 删除 DROP FUNCTION [IF EXISTS] function_name; -- 查看 SHOW FUNCTION STATUS LIKE &#39;partten&#39; SHOW CREATE FUNCTION function_name; -- 修改 ALTER FUNCTION function_name 函数选项 --// 存储过程，自定义功能 ---------- -- 定义 存储存储过程 是一段代码（过程），存储在数据库中的sql组成。 一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。 而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。 -- 创建 CREATE PROCEDURE sp_name (参数列表) 过程体 参数列表：不同于函数的参数列表，需要指明参数类型 IN，表示输入型 OUT，表示输出型 INOUT，表示混合型 注意，没有返回值。 /* 存储过程 */ ------------------ 存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。 调用：CALL 过程名 -- 注意 - 没有返回值。 - 只能单独调用，不可夹杂在其他语句中 -- 参数 IN|OUT|INOUT 参数名 数据类型 IN 输入：在调用过程中，将数据输入到过程体内部的参数 OUT 输出：在调用过程中，将过程体处理完的结果返回到客户端 INOUT 输入输出：既可输入，也可输出 -- 语法 CREATE PROCEDURE 过程名 (参数列表) BEGIN 过程体 END 用户和权限管理-- root密码重置 1. 停止MySQL服务 2. [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables &amp; [Windows] mysqld --skip-grant-tables 3. use mysql; 4. UPDATE `user` SET PASSWORD=PASSWORD(&quot;密码&quot;) WHERE `user` = &quot;root&quot;; 5. FLUSH PRIVILEGES; 用户信息表：mysql.user -- 刷新权限 FLUSH PRIVILEGES; -- 增加用户 CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串) - 必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。 - 只能创建用户，不能赋予权限。 - 用户名，注意引号：如 &#39;user_name&#39;@&#39;192.168.1.1&#39; - 密码也需引号，纯数字密码也要加引号 - 要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD -- 重命名用户 RENAME USER old_user TO new_user -- 设置密码 SET PASSWORD = PASSWORD(&#39;密码&#39;) -- 为当前用户设置密码 SET PASSWORD FOR 用户名 = PASSWORD(&#39;密码&#39;) -- 为指定用户设置密码 -- 删除用户 DROP USER 用户名 -- 分配权限/添加用户 GRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] &#39;password&#39;] - all privileges 表示所有权限 - *.* 表示所有库的所有表 - 库名.表名 表示某库下面的某表 GRANT ALL PRIVILEGES ON `pms`.* TO &#39;pms&#39;@&#39;%&#39; IDENTIFIED BY &#39;pms0817&#39;; -- 查看权限 SHOW GRANTS FOR 用户名 -- 查看当前用户权限 SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER(); -- 撤消权限 REVOKE 权限列表 ON 表名 FROM 用户名 REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名 -- 撤销所有权限 -- 权限层级 -- 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。 全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。 数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host GRANT ALL ON db_name.*和REVOKE ALL ON db_name.*只授予和撤销数据库权限。 表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。 列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv 当使用REVOKE时，您必须指定与被授权列相同的列。 -- 权限列表 ALL [PRIVILEGES] -- 设置除GRANT OPTION之外的所有简单权限 ALTER -- 允许使用ALTER TABLE ALTER ROUTINE -- 更改或取消已存储的子程序 CREATE -- 允许使用CREATE TABLE CREATE ROUTINE -- 创建已存储的子程序 CREATE TEMPORARY TABLES -- 允许使用CREATE TEMPORARY TABLE CREATE USER -- 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。 CREATE VIEW -- 允许使用CREATE VIEW DELETE -- 允许使用DELETE DROP -- 允许使用DROP TABLE EXECUTE -- 允许用户运行已存储的子程序 FILE -- 允许使用SELECT...INTO OUTFILE和LOAD DATA INFILE INDEX -- 允许使用CREATE INDEX和DROP INDEX INSERT -- 允许使用INSERT LOCK TABLES -- 允许对您拥有SELECT权限的表使用LOCK TABLES PROCESS -- 允许使用SHOW FULL PROCESSLIST REFERENCES -- 未被实施 RELOAD -- 允许使用FLUSH REPLICATION CLIENT -- 允许用户询问从属服务器或主服务器的地址 REPLICATION SLAVE -- 用于复制型从属服务器（从主服务器中读取二进制日志事件） SELECT -- 允许使用SELECT SHOW DATABASES -- 显示所有数据库 SHOW VIEW -- 允许使用SHOW CREATE VIEW SHUTDOWN -- 允许使用mysqladmin shutdown SUPER -- 允许使用CHANGE MASTER, KILL, PURGE MASTER LOGS和SET GLOBAL语句，mysqladmin debug命令；允许您连接（一次），即使已达到max_connections。 UPDATE -- 允许使用UPDATE USAGE -- “无权限”的同义词 GRANT OPTION -- 允许授予权限 表维护-- 分析和存储表的关键字分布 ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE 表名 ... -- 检查一个或多个表是否有错误 CHECK TABLE tbl_name [, tbl_name] ... [option] ... option = &#123;QUICK | FAST | MEDIUM | EXTENDED | CHANGED&#125; -- 整理数据文件的碎片 OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 杂项1. 可用反引号（`）为标识符（库名、表名、字段名、索引、别名）包裹，以避免与关键字重名！中文也可以作为标识符！ 2. 每个库目录存在一个保存当前数据库的选项文件db.opt。 3. 注释： 单行注释 # 注释内容 多行注释 /* 注释内容 */ 单行注释 -- 注释内容 (标准SQL注释风格，要求双破折号后加一空格符（空格、TAB、换行等）) 4. 模式通配符： _ 任意单个字符 % 任意多个字符，甚至包括零字符 单引号需要进行转义 &#39; 5. CMD命令行内的语句结束符可以为 &quot;;&quot;, &quot;G&quot;, &quot;g&quot;，仅影响显示结果。其他地方还是用分号结束。delimiter 可修改当前对话的语句结束符。 6. SQL对大小写不敏感 7. 清除已有语句：c","categories":[{"name":"mysql","slug":"mysql","permalink":"https://rainsoil.github.io/categories/mysql/"},{"name":"mysql","slug":"mysql/mysql","permalink":"https://rainsoil.github.io/categories/mysql/mysql/"}],"tags":[]},{"title":"redis实战之数据一致性(16)","slug":"redis/redis实战之数据一致性(16)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-shi-zhan-zhi-shu-ju-yi-zhi-xing-16/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-shi-zhan-zhi-shu-ju-yi-zhi-xing-16/","excerpt":"","text":"redis实战之数据一致性1 缓存使用场景针对读少写多的高并发场景, 我们可以使用缓存来提升查询速度. 当我们使用reids 作为缓存的时候, 一般流程是这样的: 如果数据在redis 缓存中, 应用就可以直接从redis 拿到数据, 不用访问数据库. 如果redis 里面没有，先到数据库查询, 然后写入到redis,再返回给应用. 2. 数据一致性的问题因为这些数据是很少修改的, 所以在绝大部分的情况下可以命中缓存. 但是, 一旦被缓存的数据发生变化的时候, 我们既要操作数据库的数据, 也要操作redis 的数据, 所以问题来了, 现在我们有两种选择: 先操作reids 的数据再操作数据库的数据 先操作数据库的数据再操作redis 的数据. 到底选哪一种呢? 首先需要明确的是, 不管选择哪一种方案, 我们肯定是希望两个操作要么都成功, 要么都不成功, 要不然就会发生redis 跟数据库的数据不一致的问题. 但是, redis 的数据跟数据库的数据是不可能通过事务达到统一的, 我们只能根据相应的场景和所需要付出的代码来采取一些措施来降低数据不一致的问题出现的概率, 在数据一致性和性能之间取到一个权衡. 对于数据库的实时性一致性要求不是特别高的场合, 比如T+1的报表, 可以采用定时任务查询数据库数据同步到redis 的方案. 由于我们是以数据库的数据为准的, 所以给缓存设置一个过期时间, 是保证最终一致性的解决方案. 3. 方案选择3.1 Redis: 删除还是更新这里我们先要补充一点, 当存储的数据发生变化,redis 的数据也要更新的时候, 我们有两种方案, 一种就是直接更新, 调用set, 还有一种是直接删除缓存, 让应用在下次查询的时候重新写入. 这两种方案怎么选择呢? 这里我们主要考虑更新缓存的代价. 更新缓存之前, 是不是要经过其他表的查询, 接口调用, 计算才能得到最新的数据，而不是直接从数据库拿到的值。如果是的话,建议直接删除缓存, 这种方案更加的简单，而且避免了数据库的数据和缓存不一致的情况. 在一般情况下, 我们也推荐使用删除方案. 这一点明确后, 现在我们就剩一个问题: 到底是先更新数据库,再删除缓存 还是先删除缓存, 再更新数据库呢? 我们先看第一种方案 3.2 先更新数据库, 再删除缓存正常情况： 更新数据库, 成功 删除缓存.成功. 异常情况： 更新数据库失败, 程序捕获异常, 不会走到下一步, 所以数据不会出现不一致. 更新数据库成功,删除缓存失败, 数据库是新数据,缓存是旧数据, 发生了数据不一致的情况. 这种问题怎么解决呢? 我们可以提供一个重试的机制. 比如: 如果删除缓存失败, 我们捕获这个异常, 把需要删除的key发送到消息队列,然后自己创建一个消费者消费, 尝试再次删除这个key. 这种方式有个缺点, 会对业务代码造成入侵. 所以我们就有了第二种方案(异步更新缓存) 因为更新数据库会往binglog 写入日志, 所以我们可以通过一个服务来监听binlog 的变化(例如阿里的canal), 然后在客户端完成删除key 的操作, 如果删除失败的话再发送到消息队列. 总之, 对于后删除缓存失败的情况, 我们的做法是不断的重试删除, 直到成功. 无论是重试还是异步删除, 都是最终一致性的思想. 3.3 先删除缓存, 再更新数据库正常情况: 删除缓存, 成功. 更新数据库, 成功. 异常情况： 删除异常, 程序捕获异常,不会走到下一步, 所以数据不会出现不一致的情况. 删除缓存成功, 更新数据库失败, 因为以数据库的数据为准, 所以不存在数据不一致的情况., 看起来好像没有什么问题,但是如果有程序并发操作的情况. 线程A需要更新数据, 首先删除了redis缓存 线程B 查询数据, 发现缓存不存在, 到数据库查询旧值, 写入到redis, 返回. 线程A 更新了数据库. 这个时候, redis 是旧的值, 数据库是新的值, 发生了数据不一致的情况. 那问题就变成了: 能不能对同一条数据点访问串行化呢? 代码肯定是保证不了, 因为有多个线程, 即使做了任务队列也可能有多个服务实例. 数据库也保证不了, 因为会有多个数据库的连接。 只有一个数据库只提供一个连接的情况下, 才能保证读写的操作是串行的, 或者我们把所有的读写请求放到一个内存队列中, 但是这种情况 吞吐量太低了. 所以我们就有一种延时双删的策略, 在写入数据后, 再删除一次缓存. A线程: 删除缓存 更新数据库 休眠500ms(这个时间根据读取数据库的耗时而定) 再次删除缓存 伪代码: public void write(String key,Object data)&amp;#123; redis.delKey(key); db.updateData(data); Thread.sleep(500); redis.delKey(key); &amp;#125;","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis之分布式篇(14)","slug":"redis/redis之分布式篇(14)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-zhi-fen-bu-shi-pian-14/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-zhi-fen-bu-shi-pian-14/","excerpt":"","text":"redis 之分布式篇1. 为什么需要redis集群1.1 为什么需要集群呢?1.1.1 性能redis本身的QPS 已经很高了, 但是如果在一些并发量非常高的情况下, 性能还是会收到影响的, 这个时候我们希望有更多的redis服务来完成工作. 1.1.2 扩展第二个是处于存储的考虑, 因为redis 所有的数据都是存储到内存中,如果数据量大 , 很容易收到硬件的限制, 升级硬件成效和成本比太低, 所有我们需要有一种横向扩展的方法. 1.1.3 可用性第三个是可用性和安全 的问题, 如果只有一个redis节点, 一旦服务宕机, 那么所有的客户端都无法访问, 会对业务造成很大的影响. 另一个, 如果硬件发生故障, 而单机的数据也是无法恢复, 带来的影响也是灾难性的. 可用性,数据安全,性能都可以通过搭建多个redis服务来实现, 其中一个是主节点(master), 可以有多个从节点(slave), 主从节点通过数据复制, 存储完全相同的数据, 如果节点发生故障, 则将某个从节点改成主节点, 访问新的主节点. 2. redis主从复制(replication)2.1 主从复制配置例如一主多从, 203是主节点, 在每个slave 节点上的redis.conf 配置文件中增加一行. slaveof 192.168.8.203 6379 在主从切换的时候, 这个配置就会被重写为: # Generated by CONFIG REWRITE replicaof 192.168.8.203 6379 或者在启动服务的时候通过参数指定master节点 ./redis-server --slaveof 192.168.8.203 6379 或者在客户端直接执行slaveof xx xx, 使得redis实例成为从节点. 启动后, 查看集群的状态. redis> info replication 从节点不能写入数据(只读), 只能从master节点同步数据.get 成功, set 失败 . 127.0.0.1:6379> set test 666 (error) READONLY You can't write against a read only replica. 主节点写入后，slave 会自动从master 同步数据. 断开复制 redis> slaveof no one 此时从节点会变成自己的主节点, 不再复制数据. 2.2 主从复制原理2.2.1 连接阶段 slave node 启动时(执行slaveof 命令), 会在自己本地保存master node 的信息, 包括master node 的host 和ip. slave node 内部有个定时任务replicationCron （源码replication.c）, 每隔一秒钟检查是否有新的master node 要连接和复制, 如果发现, 就跟master node建立socket 网络连接, 如果连接成功, 从节点为该socket 建立一个专门处理复制工作的文件时间处理器,负责后续的复制工作, 如接受RDB 文件、接受命令传播等. 当从节点变成了主节点的一个客户端后, 会给主节点发送ping 请求. 2.2.2 数据同步阶段 master node 第一次执行全量复制,通过bgsave 命令在本地生成一份PDB 快照, 将RDB 快照发送给slave node(如果超时会重连, 可以调大repl-timeout的值). slave node 首先清除自己的旧数据, 然后用RDB 文件加载数据. **问题: 生成PDB期间, master 接收到的命令怎么处理? ** 开始生成RDB 文件时, master会把所有新的写命令缓存在内存中, 在slave node保存了RDB 之后, 再将新的写命令复制给 slave node, 2.2.3 命令传播阶段 master node持续将写命令, 异步复制给slave node 延迟是不可避免的, 只能通过优化网络. repl-disable-tcp-nodelay no 当设置为yes的时候, TCP会对包进行合并从而减少带宽, 但是发送的频率会降低, 从节点数据延迟增加，一致性变差. 具体发送频率与linux内核的配置有关, 默认配置为40ms.当设置为no时, TCP 会立马将主节点的数据发送给从节点, 带宽增加但是延迟变小. 一般来说, 只有当应用对redis数据不一致的容忍度较高,且主从节点之间的网络状态不好时, 才会设置为yes, 大多数情况下为no 问题: 如果从节点有一段时间断开了与主节点的连接是不是要重新全量复制一遍, 如果可以增量复制, 怎么知道上次复制到了哪里？ 通过master_repl_offset 记录的偏移量 redis> info replication 2.3 主从复制的不足主从模式解决了数据备份和性能(通过读写分离)的问题, 但是还是存在一些不足. RDB 文件过大的情况下, 同步非常耗时. 在一主一从或者一主多从的情况下， 如果主服务器挂了，对外提供的服务就不可用了. 单点问题没有得到解决. 如果每次都是手动把之前的从服务器切换为主服务器, 这个比较费时费力, 还会造成一定时间的服务不可用. 3. 可用性保证值sentinel3.1 Sentinel 原理如何实现主从的自动切换呢? 我们的思路： 创建一台监控服务器来监控所有的Redis服务器的节点状态, 比如master节点超过一定时间没有给监控服务区发送心跳报文, 就把master 标记为下线, 然后把某一个slave 变成master.应用每一次都是从这个监控服务器拿到master的地址. 问题是: 如果监控服务器本身出了问题怎么办? 那我们就拿不到master的地址了,应用也就没办法访问了. 那我们就在创建一个监控服务器, 来监控监控服务器…似乎陷入了死循环中, 这个问题怎么解决? 这个问题先放着. redis 的sentinel 就是这种思路, 通过运行监控服务器来保证服务的可用性. 官网-sentinel的介绍 从redis2.8版本起, 提供了一个稳定版本的sentinel(哨兵),用来解决高可用的问题, 它是一个特殊状态的redis实例. 我们会启动一个或者多个sentinel的服务(通过src/redis-sentinel),它本质上只是一个运行在特殊模式下的redis, sentinel 通过info命令得到被监听的redis机器的master 和slave等信息. 为了保证监控服务的可用性, 我们会对sentinel 做集群的部署. sentinel 既可以监控所有的redis服务, 也可以互相监控. 注意:sentinel 本身没有主从之分,只有redis 节点才会有主从之分. 3.1.1 服务下线sentinel 默认以每秒钟1次的频率向redis服务节点发送ping 命令。如果在down-after-milliseconds 内都没有收到有效回复, sentinel 会将该服务标记为下线(主观下线) # sentinel.conf sentinel down-after-milliseconds &lt;master-name> &lt;milliseconds> 这个时候sentinel节点会继续询问其他的sentinel 节点, 确认这个节点是否下线, 如果多数的sentinel节点都认为master 下线, master 才真正的确认为下线(客观下线), 这个时候就需要重新选举master. 3.1.2 故障转移如果master 标记为下线,就会开始故障转移流程. 既然有那么多的sentinel节点, 那么由谁进行故障转移的事情呢? 故障转移的第一步就是在sentinel 集群里面选择出一个leader, 由leader 完成故障转移流程. sentinel 通过Raft算法, 实现sentinel 选举. Raft 算法在分布式存储系统中, 通常需要维护多个副本来提高系统的可用性, 那么多个节点之间必须要面对数据一致性的问题. Raft的目的就是通过复制的方式,使得所有的节点达成一致, 但是那么多的节点，以哪个节点的数据为准呢? 所以必须选出一个leader. 大体上有两个步骤: 领导选举, 数据复制. Raft 是一个共识算法(consensus algorithm), 例如比特币之类的加密货币, 就需要共识算法. Spring Cloud 的注册中心解决方案Consul 也用到了Raft 算法. Raft 的核心思想就是: 先到先得, 少数服从多数. Rafe算法演示 总结： sentinel的Raft 算法和Raft 论文略有不同. master 客观下线触发选举, 而不是过了election timeout 时间开始选举 leader 并不会把自己成为leader的消息发送给其他sentinel, 其他sentinel 等待leader 从slave选出master后, 检测到新的master正常工作后, 就会去掉客观下线的标识, 从而不需要进入故障转移流程. 故障转移**问题:怎么让一个原来的slave 节点成为主节点呢? ** 选出sentinel leader 之后, 由sentinel leader 向某个节点发送slaveof no one 命令, 让他成为独立的节点. 然后向其他节点发送slaveof x.x.x.x xxxx （本机服务）, 让他们成为这个节点的子节点, 故障转移完成. **问题： 那么多从节点, 选谁成为主节点? ** 关于从节点选举, 一共有四个因素影响选举的结果, 分别是断开连接时长, 优先级排序、复制数量、进程id 如果与哨兵连接断开的时间比较久, 超过了某个阈值, 就直接失去了选举权. 如果拥有选举权, 那就看谁的优先级高, 这个配置文件里面配置设置(replica-priority 100), 数值越小优先级越高. 如果优先级相同, 就看谁从master 中复制的数据最多(复制偏移量最大), 选最多的那个, 如果复制的数量相同,那就选择进程id最小的那个. 3.2 sentinel 的功能总结 Monitoring. Sentinel constantly checks if your master and slave instances are working as expected Notification. Sentinel can notify the system administrator, another computer programs, via an API, that something is wrong with one of the monitored Redis instances. Automatic failover. If a master is not working as expected, Sentinel can start a failover process where a slave is promoted to master, the other additional slaves are reconfigured to use the new master, and the applications using the Redis server informed about the new address to use when connecting. Configuration provider. Sentinel acts as a source of authority for clients service discovery: clients connect to Sentinels in order to ask for the address of the current Redis master responsible for a given service. If a failover occurs, Sentinels will report the new address. 监控: sentinel 会不断检查主服务器和从服务器是否正常运行, 通知： 如果某一个被监视的实例出现了问题, sentinel 可以通过API发出通知. 自动故障转移(failover ): 如果主服务器发生故障, sentinel 可以启动故障转移过程, 把某台服务器升级成主服务器 并发出通知. 配置管理：客户端连接到sentinel , 获取当前的redis 主服务器的地址. 3.3 sentinel 实战3.3.1 sentinel 配置为了保证sentinel 的高可用, sentinel也需要做集群部署, 集群中至少需要三个sentinel实例(推荐奇数个, 防止脑裂)。 hostname ip地址 节点角色和端口 master 192.168.8.203 Master：6379 / Sentinel : 2637 slave1 192.168.8.204 Slave ：6379 / Sentinel : 26379 slave2 192.168.8.205 Slave ：6379 / Sentinel : 26379 以redis安装路径 /usr/local/soft/redis-5.0.5/ 为例 在204、205的src/redis.conf 配置文件中添加 slaveof 192.168.8.203 6379 在203、204、205 创建sentinel配置文件(安装后根目录下默认有sentinel,conf): cd /usr/local/soft/redis-5.0.5 mkdir logs mkdir rdbs mkdir sentinel-tmp vim sentinel.conf 三台服务器的内容相同 daemonize yes port 26379 protected-mode no dir \"/usr/local/soft/redis-5.0.5/sentinel-tmp\" sentinel monitor redis-master 192.168.8.203 6379 2 sentinel down-after-milliseconds redis-master 30000 sentinel failover-timeout redis-master 180000 sentinel parallel-syncs redis-master 1 上面出现了4个redis-master,这个名称要统一, 并且使用客户端(比如jedis),连接的时候名称要正确. protected-mode 是否允许外部网络访问 dir sentinel 的工作目录. sentinel monitor sentinel 监控的redis 主节点 down-after-milliseconds（毫秒） 同一个sentinel 对同一个master 两次failover 之间的间隔时间 当一个slave 从一个错误的master 那里同步数据开始计算时间,直到slave 被纠正为向正确的master那里同步数据. 当想要取消一个正在进行的failover 所需要的时间 当进行failover时,配置所有的slaves 指向新的master 所需的最大时间. parallel-syncs 这个配置指定了在发生failover 主备切换时最多可以有多少个slave 同时对新的master 进行同步, 这个数字越小, 完成failover所需的时间就越长,但是如果这个数字越大, 就意味着越多的slave 因为replication 而不可用. 可以通过将这个值设置为1来保证每次只有一个salve处于不能处理命令请求的状态. 3.3.2 sentinel验证启动redis服务和sentinel服务 cd /usr/local/soft/redis-5.0.5/src # 启动 Redis 节点 ./redis-server ../redis.conf # 启动 Sentinel 节点 ./redis-sentinel ../sentinel.conf # 或者 ./redis-server ../sentinel.conf --sentinel 查看集群状态 redis> info replication 203 204和205 模拟master 宕机, 在203执行 redis> shutdown 205 被选出新出master, 只有一个slave节点 注意看，sentinel.conf 里面的redis-master被修改了. 模拟原master 恢复, 在203启动redis-server , 它还是slave,但是master又有两个slave了. 2.3.3 sentinel 连接使用jedis 连接sentinel master name来自于sentinel.conf 的配置 /** * @author luyanan * @since 2020/4/1 * &lt;p>使用jedis连接sentinel&lt;/p> **/ public class JedisSentinelTest &amp;#123; private static JedisSentinelPool pool; private static JedisSentinelPool createPool() &amp;#123; String masterName = \"redis-master\"; Set&lt;String> sentinels = new HashSet&lt;>(); sentinels.add(\"192.168.8.203:26379\"); sentinels.add(\"192.168.8.204:26379\"); sentinels.add(\"192.168.8.205:26379\"); pool = new JedisSentinelPool(masterName, sentinels); return pool; &amp;#125; public static void main(String[] args) &amp;#123; JedisSentinelPool pool = createPool(); pool.getResource().set(\"test\", \"\" + System.currentTimeMillis()); System.out.println(pool.getResource().get(\"test\")); &amp;#125; &amp;#125; SpringBoot 连接sentinel spring.redis.sentinel.master=redis-master spring.redis.sentinel.nodes=192.168.8.203:26379,192.168.8.204:26379,192.168.8.205:26379 无论是jedis 还是Springboot (2.X版本默认是lettuce),都只需要配置全部哨兵的地址，由哨兵返回当前的`master节点地址. 3.4 哨兵机制的不足主从切换的的过程中丢失数据, 因为只有一个master 只能单点写, 没有解决水平扩容的问题. 如果数据量比较大, 这个时候我们需要多个master-slave的group, 把数据分不到不同的group 问题来了, 数据怎么分片? 分片之后, 怎么实现路由呢 ? 4. redis 分布式方案如果要实现redis 数据的分片, 我们有三种方案. 第一种是在客户端实现相关的逻辑, 例如用取模或者一致性哈希对key进行分片, 查询和修改都先判断key 的路由. 第二种是把分片处理的逻辑抽取出来,运行一个独立的代理服务, 客户端连接到这个代理服务, 代理服务做请求的转发. 第三种就是基于服务端实现. 4.1客户端Sharding jedis 客户端提供了redis sharding的方案, 并且支持连接池. /** * @author luyanan * @since 2020/4/1 * &lt;p>分片处理&lt;/p> **/ public class ShardingTest &amp;#123; public static void main(String[] args) &amp;#123; JedisPoolConfig poolConfig = new JedisPoolConfig(); //redis服务器 JedisShardInfo shardInfo1 = new JedisShardInfo(\"127.0.0.1\", 6379); JedisShardInfo shardInfo2 = new JedisShardInfo(\"192.168.8.205\", 6379); // 连接池 List&lt;JedisShardInfo> infos = new ArrayList&lt;>(); infos.add(shardInfo1); infos.add(shardInfo2); ShardedJedisPool shardedJedisPool = new ShardedJedisPool(poolConfig, infos); ShardedJedis jedis = null; try &amp;#123; jedis = shardedJedisPool.getResource(); for (int i = 0; i &lt; 100; i++) &amp;#123; jedis.set(\"key-\" + i, \"\" + i); &amp;#125; for (int i = 0; i &lt; 100; i++) &amp;#123; Client client = jedis.getShard(\"key-\" + i).getClient(); System.out.println(\"取到值:\" + jedis.get(\"key-\" + i) + \",当前key处于:\" + client.getHost() + \":\" + client.getPort()); &amp;#125; &amp;#125; finally &amp;#123; if (jedis != null) &amp;#123; jedis.close(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 使用shardedJedis 之类的客户端分片代码的优势是配置简单, 不依赖其他中间件, 分片的逻辑可以自己定义, 比较灵活.但是基于客户端的方案, 不能实现动态的服务递减,每个客户端需要自行维护分片策略, 存在重复代码. 第二种思路就是把分片的代码抽取出来, 做成一个公共的服务,所有的客户端都连接到这个代码层, 由代理层来实现请求和转发. 4.2 代理Proxy 典型的代理分区方案有Twitter开源的Twemproxy 和国内的豌豆荚开源的Codis 4.2.1 Twemproxytwo-em-proxy git地址 Twemproxy的优点: 比较稳定, 可用性高. 不足： 出现故障不能自动转移,架构复杂，需要借助其他组件(LVS/HAProxy + Keepalived) 实现HA 扩缩容需要修改配置, 不能实现平滑的扩缩容(需要重新分布数据). 4.2.2 CodisCodis 官网地址 Codis是一个代理中间层,用GO语言开发 功能: 客户端连接Codis 跟连接redis 没有区别. 分片原理 Codis 把所有的key 分成了N个槽(例如1024), 每个槽对应一个分组，一个分组对应一个或者一组redis实例. Codis 对key 进行CBC32 运算，得到一个32位的数字, 然后摸以N(槽的个数),得到余数, 这个就是key对应的槽, 槽后面就是redis 的实例, 比如4个槽： Codis 的槽位映射关系是保存在proxy中的, 如果要解决单点的问题，Codis 也要做集群部署, 多个Codis 节点怎么同步槽和实例的关系呢? 需要运行一个zookeeper（或者etcd/本地文件）. 在新增节点的时候, 可以为节点指定特定的槽位. Codis 也提供了自动均衡策略. Codis 不支持事务, 其他的一些命令也不支持. 不支持的命令. https://github.com/CodisLabs/codis/blob/release3.2/doc/unsupported_cmds.md 获取数据原理(mget): 在redis 中的各个实例里获取到符合的key, 然后再汇总到Codis. Codis是第三方提供了分布式解决方案, 在官方的集群功能稳定之前, Codis 也得到了大量的应用. 4.3 Redis Clusterhttps://redis.io/topics/cluster-tutorial/ redis cluster 是在redis 3.0 的版本正式推出的, 用来解决分布式的需求, 同时也可以实现高可用. 跟Codis不一样, 它是去中心化的, 客户端可以连接到任意一个可用的节点. 数据分片有几个关键的问题需要解决： 数据怎么相对均匀的分片 客户端怎么访问到相应的节点和数据 重新分片的过程,怎么保证正常服务. 4.3.1 架构Redis Cluster 可以看成是由多个redis实例组成的数据集合, 客户端不需要关注数据的子集到底存储在哪个节点,只需要关注这个集合整体. 以3主3从为例，节点之间两两交互,共享数据分片, 节点状态等信息. 4.3.2 集群命令 集群命令 cluster info 打印集群的信息 cluster nodes 列出集群当前已知的所有节点(node), 以及这些节点的相关信息 节点命令： cluster meet &lt;ip&gt; &lt;port&gt; 将ip和port 所指定的节点加入集群当中,让他成为集群的一份子。 cluster forget &lt;node_id&gt; 从集群中移除 指定的节点的从节点. cluster replicate &lt;node_id&gt; 将当前节点设置为 指定的节点的从节点 cluster saveconfig 将节点的配置文件保存到硬盘中 槽(slot）命令 cluster addsolts &lt;solt&gt; [solt...] 将一个或者多个槽(slot) 指派(assign) 给当前节点 cluster delsolts &lt;solt&gt;[solt...] 移除一个或者多个槽对当前节点的指派 cluster flushsolts 移除指派给当前节点的所有槽, 让当前节点变成一个没有指派任何槽的节点 cluster setsolt &lt;solt&gt; node &lt;node_id&gt; 将槽solt 指派给指定的节点, 如果槽已经指派给了另一个节点, 那么先让另一个节点删除该槽, 然后在进行指派. cluster setsolt &lt;slot&gt; migrating &lt;node_id&gt; 将本节点的槽solt迁移到 指定的节点中 cluster setsolt &lt;slot&gt; importing &lt;node_id&gt; 从 指定的节点中导出槽slot 到本节点 cluster setslot &lt;slot&gt; stable 取消对槽slot 的导入(import) 或者迁移migrate 键命令 cluster keysolt &lt;key&gt; 计算键key 应该被放置到哪个槽上 cluster countkeysinslot &lt;slot&gt; 返回槽slot 目前包含的键值对数量 cluster getkeysinslot &lt;slot&gt; &lt;count&gt; 返回count个slot槽中的键 4.3.3 数据分布如果是希望数据分布相对均匀的话，我们首先可以考虑哈希后取模. 哈希后取模例如hash(key) %N , 根据余数, 决定映射到那一个节点, 这种方式比较简单, 属于静态的分片规则, 但是一旦节点数量发生变化, 新增或者减少, 由于取模的N 发生了变化, 数据就需要重新分布. 为了解决这个问题, 我们就有了一致性哈希算法 一致性哈希算法一致性哈希的原理 把所有的哈希值空间组织称一个虚拟的圆环(哈希环). 整个空间按照顺时针方向组织. 因为是环形空间, 0和2^32-1 是重叠的. 假设我们有四台机器要哈希环来实现映射(分布数据), 我们先根据机器的名称或者ip计算哈希值, 然后分布到哈希环中(红色圆圈) 现在有4条数据或者4个访问请求，对key计算后， 得到哈希环中的位置, 沿着哈希环顺时针找到第一个Node, 就是数据存储的节点. 在这种情况下， 新增了一个Node5节点, 不影响数据的分布 删除了一个节点Node4.只影响到相邻的一个节点. 谷歌的MurmurHash 就是一致性哈希算法, 在分布式系统中, 负载均衡、分库分表等场景中都有应用. 一致性哈希算法解决了动态增减节点时候,所有的数据都需要重新分布的问题, 它只会影响到下一个相邻的节点, 对其他节点没有影响. 但是这样的一致性哈希算法还有一个缺点, 因为节点不一定是均匀的分布的, 特别是在节点数量少的情况下,所以数据并不能得到均匀的分布. 解决这个问题的办法就是引入虚拟节点 (Virtual Node). 比如2个节点，5条数据,只有1条分布到Node2, 4条分布到Node1, 不均匀. Node1 设置了两个虚拟节点, Node2 也设置了两个虚拟节点(虚拟圆圈) 这个时候有3条数据分布到了Node1, 1条数据分布到了Node2 redis 虚拟槽分区 redis 既没有使用哈希取模, 也没有用一致性哈希,而是使用虚拟槽来实现的。 redis 创建了16384个槽(slot)， 每个节点负责一定区间的slot, 比如Node1负责0-5460, Node2 负责5461-10922, Node3 负责10923-16383. redis节点的每个master节点维护一个16384位(2048bytes=2KB)的位序列, 比如: 序列的第0位是1 , 就代表第一个slot 是他负责, 序列的第1位是0 ,代表第二个slot 不归他负责. 对象分布到redis节点, 对key 用CRC16 算法计算再%16384,得到一个slot 的值 ， 数据落到负责这个的slot的redis节点上. 查看key属于哪个slot redis> cluster keyslot test 注意: key与solt的关系是永远不会变得, 会变的只有slot与redis节点的关系. **问题：怎么让相同的数据落在同一个节点上? ** 有些比如multi key 操作是不能跨节点的, 如果要让某些数据分布到一个节点上, 例如用户2673的基本信息和金融信息,怎么办? 在key中加入&#123;has_tag&#125; 即可, redis在计算槽位编号的时候, 只会获取{}之间的字符串进行槽编号, 这样由于上面,两个不同的键, {} 里面的字符串是相同的, 因为他们可以计算出相同的槽. 127.0.0.1:7293> set a&amp;#123;qs&amp;#125;a 1 OK 127.0.0.1:7293> set a&amp;#123;qs&amp;#125;b 1 OK 127.0.0.1:7293> set a&amp;#123;qs&amp;#125;c 1 OK 127.0.0.1:7293> set a&amp;#123;qs&amp;#125;d 1 OK 127.0.0.1:7293> set a&amp;#123;qs&amp;#125;e 1 OK 问题: 客户端连接到哪一台服务器? 访问的数据不在当前节点上, 怎么办? 4.3.4 客户端重定向比如在7291端的redis的redis-cli 客户端操作. 127.0.0.1:7291> set qs 1 (error) MOVED 13724 127.0.0.1:7293 服务端返回MOVED , 也就是根据key计算出来的slot不归7291端口管, 而是归7293端口管理,服务端返回MOVED 告诉客户端去7293端口操作. 这个时候更换端口, 用redis-cli -p 7293 操作, 才会返回OK.或者用./redis-cli -c -p port的命令(c 代表cluster). 这样客户端需要连接两次. jedis等客户端会在本地维护一份slot-node的映射关系, 大部分的时候不需要重定向, 所以叫做smart jedis（需要客户端支持） 问题:新增或下线了``Master 节点, 数据怎么迁移(重新分配)* 4.3.5 数据迁移因为key与slot 的关系是永远不会变的, 当新增了节点的时候, 需要把原有的slot 分配给了新的节点负责, 并且把相关的数据迁移过来. 新增加一个节点(新增一个7297) redis-cli --cluster add-node 127.0.0.1:7291 127.0.0.1:7297 新增的节点也是没有哈希槽, 不能分布数据, 在原来的任意一个节点上运行. redis-cli --cluster reshard 127.0.0.1:7291 输入需要分配的哈希槽的数量(比如500), 和哈希槽的来源节点(可以输入all 或者id) **问题:只有主节点可以写, 一个主节点挂了, 从节点怎么变成主节点? ** 4.3.6 高可用和主从切换原理当slave 发现自己的master变为fail 状态时, 便尝试进行Failover, 以期成为新的master. 由于挂掉的master 可能会有多个slave,从而存在多个slave 竞争成为master节点的过程, 其过程如下： slave 发现自己的master变为fail 将自己记录的集群currentEpoch 加1, 并广播FAILOVER_AUTH_REQUEST 信息 其他节点收到该节点, 只有master响应, 判断请求者的合法性, 并发送FAILOVER_AUTH_ACK,对每一个epoch只发送一次ack 尝试failover 的slave收集FAILOVER_AUTH_ACK 超过半数后变成新Master 广播ping 通知其他集群节点 redis cluster 既能够实现主从的角色分配, 又能够实现主从切换, 相当于继承了Replication 和sentinel的功能. 4.3.7 总结优势 无中心架构 数据按照slot 存储分布在多个节点, 节点间数据共享, 可动态调整数据分布 可扩展性, 可线性扩展到1000个节点(官当推荐不超过1000个), 节点可动态添加或者删除. 高可用性, 部分节点不可用的时候, 集群扔可用. 通过增加slave做standby 数据副本, 能够实现故障自动failover, 节点之间通过gossip协议交换状态信息, 用投票机制完成slave 到master的角色提升. 降低运维成本, 提高系统的扩展性和可用性. 不足 client实现复杂, 驱动要求实现smart client, 缓存slots mapping 信息并及时更新, 提高了开发难度, 客户端的不成熟影响业务的稳定性. 节点会因为某些原因发生阻塞(阻塞时间大于clutser-node-timeout), 被判断下线, 这种failover是没有必要的. 数据通过异步复制, 不保证数据的强一致性. 多个业务系统使用同一套集群时, 无法根据统计区区分冷热数据, 资源隔离性较差, 容易出现互相影响的情况.","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis基本类型之List(4)","slug":"redis/redis基本类型之List(4)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-ji-ben-lei-xing-zhi-list-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-ji-ben-lei-xing-zhi-list-4/","excerpt":"","text":"Redis基本类型之List1存储类型存储有效的字符串(从左到右),元素可以重复, 可以充当队列和栈的角色。 2基本命令 命令 作用 返回 lpush key value [value„] 将一个或者多个value值插入到表头,从左往右插入 返回新列表长度 rpush key value [value„] 将一个或者多个值插入到表尾(最右边), 从左往右插入 新列表长度 lrange key start stop 获取执行key的指定区间的元素 返回指定的列表 lindex key index 获取列表key的下标为index的元素 返回下表的元素，不存在则返回nil llen key 获取列表 key的长度 返回长度,key不存在, 则返回0 lrem key count value 根据参数count的值，移除列表中与参数value相等的元素，count&gt;0 ，从列表的左侧向右开始移 除； count&lt;0从列表的尾部开始移除；count=0 移除表中所有与value相等的值。 数值，移除的元素个数 lset key index value 将列表key 下标为Index的值设置为value 成功返回ok, key不存在或者idnex不存在返回异常 linsert keyAFTER(后) pivot value BEFORE(前) 将值value插入到列表key当中位于值pivot之前或之后的位置。key不存在，pivot不在列表中， 不执行任何操作 命令执行成功，返回新列表的长度。没有找到 pivot 返回 -1， key 不存在返回 0。 RPOP key 移除列表的最后一个元素 返回值为移除的元素 RPOPLPUSH source destination 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 LPOP key 移除列表的第一个元素 返回移除的元素 3存储(实现)原理 在早期的版本中, 数据量较小的用ziplist存储, 达到临界值时转换为linklist 进行存储, 分别对应OBJ_ENCODING_ZIPLIST 和OBJ_ENCODING_LINKLIST 3.2版本之后, 统一用quicklist 来存储, quicklist 存储了一个双向链表, 每个节点都是一个ziplist 127.0.0.1:6379> object encoding queue \"quicklist\" quicklistquicklist(快速列表) 是ziplist 和linklist的结合体 quicklist.h的head 和tail 指向双向列表的表头和表尾 /* quicklist is a 40 byte struct (on 64-bit systems) describing a quicklist. * 'count' is the number of total entries. * 'len' is the number of quicklist nodes. * 'compress' is: -1 if compression disabled, otherwise it's the number * of quicklistNodes to leave uncompressed at ends of quicklist. * 'fill' is the user-requested (or default) fill factor. */ typedef struct quicklist &amp;#123; quicklistNode *head; // 指向双向链表的表头 quicklistNode *tail;// 指向双向链表的表尾 unsigned long count; // 所有的ziplist 中一共存储了多少元素 /* total count of all entries in all ziplists */ unsigned long len; // 双向链表的长度, node的数量 /* number of quicklistNodes */ int fill : 16; /* fill factor for individual nodes */ unsigned int compress : 16; // 压缩深度, 0 表示不压缩. /* depth of end nodes not to compress;0=off */ &amp;#125; quicklist; redis.conf 相关参数 参数 含义 list-max-ziplist-size（fill） 正数表示单个 ziplist 最多所包含的 entry 个数。 负数代表单个 ziplist 的大小，默认 8k。 -1：4KB；-2：8KB；-3：16KB；-4：32KB；-5：64KB list-compress-depth（compress） 压缩深度，默认是 0。 1：首尾的 ziplist 不压缩；2：首尾第一第二个 ziplist 不压缩，以此类推 quicklistNode 中的*zl 指向一个ziplist, 一个ziplist 可以存放多个元素 typedef struct quicklistNode &amp;#123; struct quicklistNode *prev; // 前一个节点 struct quicklistNode *next; // 后一个节点 unsigned char *zl; // 指向实际的 ziplist unsigned int sz; // 当前ziplist 占用多少字节 /* ziplist size in bytes */ unsigned int count : 16; // 当前 ziplist 中存储了多少元素, 占 16bit（下同），最大 65536 个 /* count of items in ziplist */ unsigned int encoding : 2; // 当前采用了LZF压缩算法压缩节点, 1:RAW,2:LZF /* RAW==1 or LZF==2 */ unsigned int container : 2;// 2: ziplist, 未来可能支持其他数据结构 /* NONE==1 or ZIPLIST==2 */ unsigned int recompress : 1;// 当前ziplist是不是已经被解压出来临时使用 /* was this node previous compressed? */ unsigned int attempted_compress : 1;// 测试使用 /* node can't compress; too small */ unsigned int extra : 10;// 预留给未来使用 /* more bits to steal for future usage */ &amp;#125; quicklistNode; 4应用场景用户消息时间线 timeline 消息队列List提供了两个阻塞的弹出操作, BLPOP /BRPOP, 可以设置超时时间 BLOPO: ：BLPOP key1 timeout, 移除并获取列表的第一个元素, 如果列表没有元素会阻塞列表到等待超时时间或者发现可弹出的元素为止. BRPOP: BRPOP key timeout: 移除并获取列表的最后一个元素, 如果列表中没有元素会阻塞列表等待超时或者发现可弹出的元素为止.","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis使用lua脚本(10)","slug":"redis/redis使用lua脚本(10)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-shi-yong-lua-jiao-ben-10/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-shi-yong-lua-jiao-ben-10/","excerpt":"","text":"redis使用lua脚本lua(ˈluə) 是一种轻量级脚本语言, 他是用C语言编写的, 跟数据库的存储过程有点类型, 使用lua 脚本来执行redis命令的好处: 一次发送多条命令, 较少网络开销 redis会将整个脚本来作为一个整体执行, 不会被其他请求打断, 保持原子性. 对于复杂的组合命令, 我们可以放到文件中, 可以实现程序之间的命令复用. 1 在Redis 中调用lua 脚本使用eval(ɪ&#39;væl) 方法, 语法格式为: redis> eval lua-script key-num [key1 key2 key3 ....] [value1 value2 value3 ....] eval 代表执行 Lua 语言的命令。 lua-script 代表 Lua 语言脚本内容。 key-num 表示参数中有多少个 key，需要注意的是 Redis 中 key 是从 1 开始的，如果没有 key 的参数，那么写 0。 [key1 key2 key3…]是 key 作为参数传递给 Lua 语言，也可以不填，但是需要和 key-num 的个数对应起来。 [value1 value2 value3 ….]这些参数传递给 Lua 语言，它们是可填可不填的 示例: 返回一个字符串, 0个参数 redis> eval \"return 'Hello World'\" 0 2. 在lua 脚本中调用redis 的命令使用redis.call(command, key [param1, param2…]) 进行操作。语法格式: redis> eval \"redis.call('set',KEYS[1],ARGV[1])\" 1 lua-key lua-value command 是命令，包括 set、get、del 等。 key 是被操作的键 param1,param2… 代表给key的参数 注意跟java 不一样, 定义只有形参, 调用只有实参 lua 是在调用时用key表示形参, argv 表示参数值(实参) 2.1 设置键值对在redis中调用lua 脚本执行redis命令 redis> eval \"return redis.call('set',KEYS[1],ARGV[1])\" 1 test 2673 redis> get test 以上命令相当于set test 2673 在redis-cli 中直接写lua 脚本不够方便, 也不能实现编辑和复用, 通常我们会把脚本放在文件里, 然后执行这个文件. 2.2 在redis中调用lua 脚本中的命令, 操作redis创建lua 脚本文件: cd /usr/local/soft/redis5.0.5/src vim test.lua lua 脚本内容： 先设置, 再取值 redis.call('set','test','lua666') return redis.call('get','test') 在redis 客户端中调用lua 脚本 cd /usr/local/soft/redis5.0.5/src redis-cli --eval test.lua 0 得到返回值: [root@localhost src]# redis-cli --eval test.lua 0 \"lua666\" 3 案例： 对IP 进行限流需求: 在X 秒中只能访问Y次. 设计思路: 用key 记录ip, 用value记录访问数 拿到ip后，对ip+1. 如果是第一次访问, 对key设置过期时间(参数1). 否则判断次数, 超过限定的次数(参数2), 返回0. 如果没有超过次数则返回1. 超过时间, key过期, 可以再次访问. KEY[1]是ip,ARGV[1]是过期时间X, ARGV[2] 是限制访问次数Y -- ip_limit.lua -- IP 限流，对某个 IP 频率进行限制 ，6 秒钟访问 10 次 local num=redis.call('incr',KEYS[1]) if tonumber(num)==1 then redis.call('expire',KEYS[1],ARGV[1]) return 1 elseif tonumber(num)>tonumber(ARGV[2]) then return 0 else return 1 end 6 秒钟内限制访问10次, 调用次数(连续调用10次) ./redis-cli --eval \"ip_limit.lua\" app:ip:limit:192.168.8.111 , 6 10 app:ip:limit:192.168.8.111 是key值, 后面是参数值, 中间要加上一个空格和一个逗号, 再加上一个空格 即: ./redis-cli –eval [lua 脚本] [key…]空格,空格[args…] 多个参数之间用一个空格分割 public class LuaLimitTest &amp;#123; public static void main(String[] args) &amp;#123; Jedis jedis = getJedisUtil(); jedis.eval(\"return redis.call('set',KEYS[1],ARGV[1])\", 1, \"test:lua:key\", \"2673lua\"); System.out.println(jedis.get(\"test:lua:key\")); for (int i = 0; i &lt; 10; i++) &amp;#123; limit(); &amp;#125; &amp;#125; /** * 10秒内限制访问5次 */ public static void limit() &amp;#123; Jedis jedis = getJedisUtil(); // 只在第一次对key设置过期时间 String lua = \"local num = redis.call('incr', KEYS[1])\\n\" + \"if tonumber(num) == 1 then\\n\" + \"\\tredis.call('expire', KEYS[1], ARGV[1])\\n\" + \"\\treturn 1\\n\" + \"elseif tonumber(num) > tonumber(ARGV[2]) then\\n\" + \"\\treturn 0\\n\" + \"else \\n\" + \"\\treturn 1\\n\" + \"end\\n\"; Object result = jedis.evalsha(jedis.scriptLoad(lua), Arrays.asList(\"localhost\"), Arrays.asList(\"10\", \"5\")); System.out.println(result); &amp;#125; private static Jedis getJedisUtil() &amp;#123; String ip = ResourceUtil.getKey(\"redis.host\"); int port = Integer.valueOf(ResourceUtil.getKey(\"redis.port\")); String password = ResourceUtil.getKey(\"redis.password\"); JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); JedisPool pool = new JedisPool(jedisPoolConfig, ip, port, 10000, password); return pool.getResource(); &amp;#125; &amp;#125; 4. 缓存lua 脚本4.1 为什么要缓存在脚本比较长的情况下, 如果每次调用脚本都需要将整个脚本传给redis服务端, 会产生比较大的网络开销. 为了解决这个问题, redis 提供了EVALSHA命令, 允许开发者通过脚本内容的SHA1 摘要来执行脚本. 4.2 如何缓存redis在执行script load 命令时会计算脚本的SHA1 摘要并记录在脚本缓存中, 执行EVALSHA命令时redis 会根据提供的摘要从脚本中查找对应的脚本内容, 如果找到了则执行脚本, 否则会返回错误: &quot;NOSCRIPT No matching script. Please use EVAL.&quot;. 127.0.0.1:6379> script load \"return 'Hello World'\" \"470877a599ac74fbfda41caa908de682c5fc7d4b\" 127.0.0.1:6379> evalsha \"470877a599ac74fbfda41caa908de682c5fc7d4b\" 0 \"Hello World\" 自乘案例: redis有incrby 这样的自增命令, 但是没有自乘, 比如乘以3, 乘以5 我们可以写一个自乘的运算,让他乘以后面的参数 local curVal = redis.call(\"get\", KEYS[1]) if curVal == false then curVal = 0 else curVal = tonumber(curVal) end curVal = curVal * tonumber(ARGV[1]) redis.call(\"set\", KEYS[1], curVal) return curVal 把这个脚本换成单行, 语句之间使用分号隔开 local curVal = redis.call(\"get\", KEYS[1]); if curVal == false then curVal = 0 else curVal = tonumber(curVal) end; curVal = curVal * tonumber(ARGV[1]); redis.call(\"set\", KEYS[1], curVal); return curVal 使用script load 命令 127.0.0.1:6379> script load 'local curVal = redis.call(\"get\", KEYS[1]); if curVal == false then curVal = 0 else curVal = tonumber(curVal) end; curVal = curVal * tonumber(ARGV[1]); redis.call(\"set\", KEYS[1], curVal); return curVal' \"be4f93d8a5379e5e5b768a74e77c8a4eb0434441\" 调用 127.0.0.1:6379> set num 2 OK 127.0.0.1:6379> evalsha be4f93d8a5379e5e5b768a74e77c8a4eb0434441 1 num 6 (integer) 12 5. 脚本超时redis的指令执行本身是单线程的, 这个线程还要执行客户端的lua 脚本, 如果lua 脚本执行超时或者陷入了死循环, 是不是就没办法为客户端提供服务了呢? eval 'while(true) do end' 0 为了防止某个脚本执行时间过长导致redis无法提供服务,redis提供了lua-time-limit 参数限制脚本的最长运行时间,默认为5秒钟 lua-time-limit 5000（redis.conf 配置文件中） 当脚本运行时间超时这一限制后, redis将开始接收命名但不会执行(以确保脚本的原子性, 因为此时脚本并没有被终止), 而是会返回BUSY 错误. redis 提供了一个script kill 命令来终止脚本的运行。 新开一个客户端: script kill 如果当前执行的lua脚本对redis的数据进行了修改(set,del等), 那么通过script kill 命令是不能终止脚本运行的. 127.0.0.1:6379> eval \"redis.call('set','gupao','666') while true do end\" 0 因为要保证脚本运行的原子性, 如果脚本执行了一部分终止, 那就违背了脚本原子性的要求, 最终要保证脚本要么全部执行, 要么都不执行. 127.0.0.1:6379> script kill (error) UNKILLABLE Sorry the script already executed write commands against the dataset. You can either wait the script termination or kill the server in a hard way using the SHUTDOWN NOSAVE command. 遇到这种情况, 只能通过shutdown nosave 命名来强制终止redis shutdown nosave 和shutdown 的区别在于shutdown nosave 不会进行持久化操作,意味着发生在上一次快照后的数据库修改都会丢失. 总结: 如果我们有一些特殊的需求, 可以用lua 来实现, 但是要注意那些耗时的操作.","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis之发布订阅模式(8)","slug":"redis/redis之发布订阅模式(8)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-zhi-fa-bu-ding-yue-mo-shi-8/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-zhi-fa-bu-ding-yue-mo-shi-8/","excerpt":"","text":"redis之发布订阅1 列表的局限我们知道, redis的队列可以通过rpush和lpop 来实现消息队列(队尾进,队头出),但是消费者需要不断的调用lpop查看list中是否有等待处理的任务(比如写一个while循环).为了减少通信的消耗, 可以sleep一段时间后再进行消费, 但是这样会有两个问题: 如果生产者生产消息的速度远大于消费者消费消息的速度, List会占用大量的内存. 消息的实时性降低. list 还提供了一个阻塞的命令, blpop, 没有任何元素可以弹出的时候 , 连接会被阻塞. blpop queue 5 基于list 实现的消息队列, 不支持一对多的消息分发. 2发布订阅模式除了通过list实现消息队列之外, redis 还提供了一组命令来实现发布/订阅模式 这种方式, 发送者和接收者没有任何关联(实现了解耦), 接受着也不需要尝试持续接收消息. 2.1 订阅频道首先, 我们有很多的频道(channel), 我们也可以把这个频道理解成queue. 订阅者可以订阅一个或者多个频道. 消费的发布者(生产者) 可以给指定的频道发送消息. 只要有消息达到了频道, 所有订阅了这个频道的订阅者都会收到这条消息. 需要注意的是, 发出去的消息不会被持久化, 因为他们已经被从队列中删除了,所以消费者只能收到他开始订阅了这个频道之后发布的消息了. 下面我们来看看发布订阅命令的使用. 订阅者订阅消息, 可以一次订阅多个 subscribe channel-1 channel-2 channel-3 发布者可以向指定的频道发布消息(并不支持一次向多个频道发布消息) publish channel-1 2673 取消订阅(不能在订阅状态下使用) unsubscribe channel-1 2.2 按规则(pattern ) 订阅频道支持? 和* 占位符. ? 代表一个字符,* 代表0 或者多个字符 消费端 1，关注运动信息: psubscribe *sport 消费端 2，关注所有新闻： psubscribe news* 消费端 3，关注天气新闻： psubscribe news-weather 生产者，发布 3 条信息 publish news-sport yaoming publish news-music jaychou publish news-weather rain java 基于jedis实现 发布者 public class PublishTest &amp;#123; public static void main(String[] args) &amp;#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); jedis.publish(\"test-123\", \"666\"); jedis.publish(\"test-abc\", \"pengyuyan\"); &amp;#125; &amp;#125; 订阅者 MyListener public class MyListener extends JedisPubSub &amp;#123; // 取得订阅的消息后的处理 public void onMessage(String channel, String message) &amp;#123; System.out.println(channel + \"=\" + message); &amp;#125; // 初始化订阅时候的处理 public void onSubscribe(String channel, int subscribedChannels) &amp;#123; // System.out.println(channel + \"=\" + subscribedChannels); &amp;#125; // 取消订阅时候的处理 public void onUnsubscribe(String channel, int subscribedChannels) &amp;#123; // System.out.println(channel + \"=\" + subscribedChannels); &amp;#125; // 初始化按表达式的方式订阅时候的处理 public void onPSubscribe(String pattern, int subscribedChannels) &amp;#123; // System.out.println(pattern + \"=\" + subscribedChannels); &amp;#125; // 取消按表达式的方式订阅时候的处理 public void onPUnsubscribe(String pattern, int subscribedChannels) &amp;#123; // System.out.println(pattern + \"=\" + subscribedChannels); &amp;#125; // 取得按表达式的方式订阅的消息后的处理 public void onPMessage(String pattern, String channel, String message) &amp;#123; System.out.println(pattern + \"=\" + channel + \"=\" + message); &amp;#125; &amp;#125; ListenTest public class ListenTest &amp;#123; public static void main(String[] args) &amp;#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); final MyListener listener = new MyListener(); // 使用模式匹配的方式设置频道 // 会阻塞 jedis.psubscribe(listener, new String[]&amp;#123;\"test-*\"&amp;#125;); &amp;#125; &amp;#125;","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis之内存回收(12)","slug":"redis/redis之内存回收(12)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-zhi-nei-cun-hui-shou-12/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-zhi-nei-cun-hui-shou-12/","excerpt":"","text":"redis之内存回收redis的所有数据都是存储在内存中, 在某些情况下需要对占用的内存进行内存回收. 内存回收主要分为两类: 一类是key 过期, 一类是使用内存达到上限(max_memory), 触发内存淘汰. 1. 过期策略要实现key过期, 我们有几种思路 1.1 定时过期(主动淘汰)每个设置过期时间的key都需要创建一个定时器, 到过期时间就会立即清除. 该策略可以立即清除过期的数据, 对内存很友好; 但是会占用大量的CPU资源去处理过期的数据, 从而影响缓存的响应时间和吞吐量. 1.2 惰性过期(被动淘汰)只有当访问一个key 到时候, 才会判断这个key是不是过期, 过期则删除。 该策略可以最大化的节省CPU资源, 却对内存非常不友好 . 极端情况下可能会出现大量的过期的key没有被访问,从而不会被删除, 占用大量的内存. 例如,String, 在 getCommand 里面会调用到expireIfNeeded. server.c expireIfNeeded(redisDb *db, robj *key) 第二种情况, 每次写入key的时候, 发现内存不够, 调用activeExpireCycle 释放一部分内存. expire.c activeExpireCycle(int type) 1.3 定时过期源码: server.h /* Redis database representation. There are multiple databases identified * by integers from 0 (the default database) up to the max configured * database. The database number is the 'id' field in the structure. */ typedef struct redisDb &amp;#123; dict *dict; //所有的键值对 /* The keyspace for this DB */ dict *expires; // 设置了过期时间的键值对 /* Timeout of keys with a timeout set */ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* Average TTL, just for stats */ list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */ &amp;#125; redisDb; 每隔一定的时间, 会扫描一定数量的数据库的expires 字典中一定数量的key, 并清除其中已过期的key. 该策略是前两者的一个折中方案, 通过调整定时扫描的时间间隔和每次扫描的限定耗时, 可以在不同情况下使得CPU和内存资源达到最优的平衡效果. redis 中同时使用了惰性过期和定时过期这两种过期策略. **如果都不过期, redis内存满了怎么办? ** 2. 淘汰策略redis的内存淘汰策略, 是指当内存使用达到最大内存极限时, 需要使用淘汰算法来决定清理掉哪些数据, 以保证新数据的存入. 2.1 最大内存设置redis.conf 参数配置： # maxmemory &lt;bytes> 如果不设置maxmemory 或者设置为0, 64位系统不限制内存， 32位系统最多使用3GB内存. 动态修改: redis> config set maxmemory 2GB 达到最大内存怎么办? 2.2 淘汰策略https://redis.io/topics/lru-cache redis.conf # maxmemory-policy # volatile-lru -> Evict using approximated LRU among the keys with an expire set. # allkeys-lru -> Evict any key using approximated LRU. # volatile-lfu -> Evict using approximated LFU among the keys with an expire set. # allkeys-lfu -> Evict any key using approximated LFU. # volatile-random -> Remove a random key among the ones with an expire set. # allkeys-random -> Remove a random key, any key. # volatile-ttl -> Remove the key with the nearest expire time (minor TTL) # noeviction -> Don't evict anything, just return an error on write operations. 先从算法上看: LRU: Least Recently Used, 最近最少使用, 判断最近被使用的时间， 目前最远的数据优先被淘汰. LFU: Least Frequently Used , 最不常用, 4.0 版本新增 random: 随机删除 策略 含义 volatile-lru 根据 LRU 算法删除设置了超时属性（expire）的键，直到腾出足够内存为止。如果没有 可删除的键对象，回退到 noeviction 策略。 allkeys-lru 根据 LRU 算法删除键，不管数据有没有设置超时属性，直到腾出足够内存为止。 volatile-lfu 在带有过期时间的键中选择最不常用的。 allkeys-lfu 在所有的键中选择最不常用的，不管数据有没有设置超时属性。 volatile-random 在带有过期时间的键中随机选择。 allkeys-random 随机删除所有键，直到腾出足够内存为止。 volatile-ttl 根据键值对象的 ttl 属性，删除最近将要过期数据。如果没有，回退到 noeviction 策略。 noeviction 默 默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时 Redis 只响应读操作。 如果没有符合前提条件的key被淘汰, 那么volatile-lru、volatile-random 、 volatile-ttl 相当于noeviction（不做内存回收） 动态修改淘汰策略: redis> config set maxmemory-policy volatile-lru 建议使用volatile-lru, 在保证正常服务的情况下, 优先删除最近最少使用的key 2.3 LRU 淘汰原理如果基于传统的LRU 算法实现redis LRU 会有什么问题? 需要额外的数据结构存储, 消耗内存. redis LRU 对传统的LRU 算法进行了改良, 通过随机采样来调整算法的精度. 如果淘汰策略是LRU,则根据配置的采样值maxmemory_samples（默认是5个）, 随机从数据库中选择m个key, 淘汰其中热度最低的key对应的缓存数据, 所以采样参数m 配置的数值越大, 就越能精确的查找到待淘汰的缓存数据, 但是也消耗更多的CPU计算, 执行效率降低. 问题: 如何找出热度最低的数据? redis中所有对象结构都有一个lru字段, 且使用了unsigned的低24位, 这个字段用来记录对象的热度. 对象被创建时会记录lru值, 在被访问的时候会更新lru 的值,但是不是获取系统当前的时间戳, 而是设置为全局变量的server.lruclock的值. 源码：server.h #define OBJ_SHARED_REFCOUNT INT_MAX typedef struct redisObject &amp;#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr; &amp;#125; robj; server.lruclock的值是怎么来的呢？ redis中有个定时处理的函数serverCron, 默认每100毫秒调用函数updateCachedTime 更新一次全局变量server.lruclock的值, 他记录的是当前unix的时间戳 源码：server.c /* We take a cached value of the unix time in the global state because with * virtual memory and aging there is to store the current time in objects at * every object access, and accuracy is not needed. To access a global var is * a lot faster than calling time(NULL). * * This function should be fast because it is called at every command execution * in call(), so it is possible to decide if to update the daylight saving * info or not using the 'update_daylight_info' argument. Normally we update * such info only when calling this function from serverCron() but not when * calling it from call(). */ void updateCachedTime(int update_daylight_info) &amp;#123; server.ustime = ustime(); server.mstime = server.ustime / 1000; time_t unixtime = server.mstime / 1000; atomicSet(server.unixtime,unixtime); /* To get information about daylight saving time, we need to call * localtime_r and cache the result. However calling localtime_r in this * context is safe since we will never fork() while here, in the main * thread. The logging function will call a thread safe version of * localtime that has no locks. */ if (update_daylight_info) &amp;#123; struct tm tm; time_t ut = server.unixtime; localtime_r(&amp;ut,&amp;tm); server.daylight_active = tm.tm_isdst; &amp;#125; &amp;#125; 问题: 为什么不获取精准的时间戳而是获取全局的变量呢? 不会有延迟的问题吗 ? 这样函数lookupKey 中更新数据的lru 热度值时, 就不会每次调用系统的函数time, 可以提高执行效率. OK,当对象里面已经有了LRU 字段的值， 就可以评估对象的热度了. 函数estimateObjectIdleTime 评估执行对象的lru 热度,思想就是对象的lru值和全局的server.lruclock的差值越大(越久没有得到更新), 该对象热度就越低. 源码： evict.c /* Given an object returns the min number of milliseconds the object was never * requested, using an approximated LRU algorithm. */ unsigned long long estimateObjectIdleTime(robj *o) &amp;#123; unsigned long long lruclock = LRU_CLOCK(); if (lruclock >= o->lru) &amp;#123; return (lruclock - o->lru) * LRU_CLOCK_RESOLUTION; &amp;#125; else &amp;#123; return (lruclock + (LRU_CLOCK_MAX - o->lru)) * LRU_CLOCK_RESOLUTION; &amp;#125; &amp;#125; server.lruclock 只有24位, 按秒位单位才能存储194天, 当超过24bit能表示最大时间的时候, 他会从头开始计算. server.h #define LRU_CLOCK_MAX ((1&lt;&lt;LRU_BITS)-1) /* Max value of obj->lru */ 在这种情况下, 可能会出现对象的lru的值大于server.lruclock 的情况,如果遇到这种情况, 那么就两个相加而不是相减来求最久的值, 为什么不适用常规的哈希呢 + 双向链表的方式实现呢? 需要额外的数据结构, 消耗资源. 而redis lru 算法在sample 为10 的情况下,已经能接近传统LRU算法了., **问题：除了消耗资源, 传统LRU 还有什么问题呢? ** 如图, 假设A 在10秒中被访问了5次, 而B在10秒中被访问了3次。因为B 最后一次被访问的时间比A要晚, 在同等的情况下, A 反而先被回收. **问题:要实现基于访问频率的淘汰机制, 该怎么做呢? ** 2.4 LFUserver.h #define OBJ_SHARED_REFCOUNT INT_MAX typedef struct redisObject &amp;#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr; &amp;#125; robj; 当这24bits 用做LFU 时, 被分作两个部分. 高16位用来记录访问时间(单位位分钟, ldt,last decrement time ) 低8位来记录访问频率,简称counter(logc,ogistic counter ) counter 是用基于概率的对数计数器实现的, 8位可以表示百万次的访问频率. 对象被读写的时候,lfu的值会被更新. db.c–lookupKey /* Update LFU when an object is accessed. * Firstly, decrement the counter if the decrement time is reached. * Then logarithmically increment the counter, and update the access time. */ void updateLFU(robj *val) &amp;#123; unsigned long counter = LFUDecrAndReturn(val); counter = LFULogIncr(counter); val->lru = (LFUGetTimeInMinutes()&lt;&lt;8) | counter; &amp;#125; 增长的速率由lfu-log-factor 越大, counter 增长就越慢. redis.conf 配置文件 # lfu-log-factor 10 如果计数器只会递增不会递减, 也不能体现对象的热度. 没有被访问的时候, 计算器怎么递减呢? 减少的值由衰减因子lfu-decay-time（分钟）来控制, 如果值是1的话, N 分钟没有访问就要减少N redis.conf 配置文件 # lfu-decay-time 1","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis之事务(9)","slug":"redis/redis之事务(9)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-zhi-shi-wu-9/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-zhi-shi-wu-9/","excerpt":"","text":"redis之事务1. 官网介绍https://redis.io/topics/transactions/http://redisdoc.com/topic/transaction.html 2. 为什么要使用事务我们知道Redis的单个命令是原子性的(比如get,set,mget,mset),如果涉及到多个命令的时候, 需要把多个命令作为一个不可分割的处理序列, 就需要用到事务. 例如当使用sentx 实现分布式锁的时候，我们先set, 然后对key 设置expire, 防止del 发生异常的时候锁不会被释放, 业务处理完了之后再del, 这三个动作我们希望他们作为一组命令执行. redis的事务涉及到四个命令: multi: 开启事务 exec: 执行事务 discard: 取消事务 watch:监视事务 3. 事务的用法案例场景: tom 和 mic 各有 1000 元，tom 需要向 mic 转账 100 元。tom 的账户余额减少 100 元，mic 的账户余额增加 100 元。 127.0.0.1:6379> set tom 1000 OK 127.0.0.1:6379> set mic 1000 OK 127.0.0.1:6379> multi OK 127.0.0.1:6379> decrby tom 100 QUEUED 127.0.0.1:6379> incrby mic 100 QUEUED 127.0.0.1:6379> exec 1) (integer) 900 2) (integer) 1100 127.0.0.1:6379> get tom \"900\" 127.0.0.1:6379> get mic \"1100\" 通过multi 的命令开启事务. 事务不能嵌套, 多个multi 命令的效果一样. multi 执行后, 客户端可以继续向服务器发送任意多条命令,这些命令不会立即被执行, 而是被放到一个队列中, 当exec 命名被调用时, 所有队列中的这些命令才会被执行. 通过exec 命令执行事务, 如果没有执行exec, 所有的命令都不会被执行. 如果中途不想执行事务了, 怎么办? 可以调用discard 清空事务队列, 放弃执行. multi set k1 1 set k2 2 set k3 3 discard 4 watch 命令在redis 中还提供了一个watch 命令. 他可以为redis 事务提供CAS 乐观锁行为(Check and Set / Compare and Swap) , 也就是多个线程更新变量的时候, 会跟原值做比较， 只有他没有被其他线程做修改的情况下, 才更新成新的值. 我们可以用watch监视一个或者多个key, 如果开启事务后, 至少有一个被监视 key 键在exec 执行之前被修改了, 那么整个事务都会被取消(key提前过期除外). 可以使用unwatch 取消. 5. 事务中可能遇到的问题?我们把事务中可能遇到的问题分成两种: 在执行exec 之前发生的错误 在执行exec 之后发生的错误. 5.1 在执行exec 之前发生的错误比如, 入队的命令存在语法错误, 包括参数变量, 参数名等等(编译器错误) 127.0.0.1:6379> multi OK 127.0.0.1:6379> set test 666 QUEUED 127.0.0.1:6379> hset test1 2673 (error) ERR wrong number of arguments for 'hset' command 127.0.0.1:6379> exec (error) EXECABORT Transaction discarded because of previous errors. 在这种情况下, 事务会被拒绝执行, 也就是队列中的所有的命令都不会被执行 5.2 在执行exec 之后发生错误比如: 类型错误, 比如对String执行了Hset 的命令, 这是一种运行时错误 127.0.0.1:6379> flushall OK 127.0.0.1:6379> multi OK 127.0.0.1:6379> set k1 1 QUEUED 127.0.0.1:6379> hset k1 a b QUEUED 127.0.0.1:6379> exec 1) OK 2) (error) WRONGTYPE Operation against a key holding the wrong kind of value 127.0.0.1:6379> get k1 \"1\" 最后我们发现set k1 1的命令是成功的, 也就是在这种发生了运行时异常的情况下, 只有错误的命令不会被执行, 但是其他命令没有收到影响. 这个显然不符合我们对原子性的定义, 也就是我们没办法用redis的这种事务机制来实现原子性, 保证事务的一致.","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"redis之redis为什么那么快(11)","slug":"redis/redis之redis为什么那么快(11)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-zhi-redis-wei-shi-me-na-me-kuai-11/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-zhi-redis-wei-shi-me-na-me-kuai-11/","excerpt":"","text":"redis为什么那么快1. redis到底有多快?https://redis.io/topics/benchmarks cd /usr/local/soft/redis-5.0.5/src redis-benchmark -t set,lpush -n 100000 -q 结果(本地虚拟机) SET: 51813.47 requests per second —— 每秒钟处理 5 万多次 set 请求 LPUSH: 51706.31 requests per second —— 每秒钟处理 5 万多次 lpush 请求 redis-benchmark -n 100000 -q script load \"redis.call('set','foo','bar')\" 结果（本地虚拟机）： script load redis.call('set','foo','bar'): 46816.48 requests per second —— 每秒钟 46000 次 lua 脚本调用 根据官方的数据, redis的QPS 可以达到10万左右(每秒请求数). 2.redis为什么这么快?总结来说有三点: 纯内存结构 单线程 多路复用 2.1 纯内存结构KV结构的内存数据库, 时间复杂度为O(1). 第二个, 要实现这么高的并发性能, 是不是要创建非常多的线程? 恰恰相反, redis是单线程的. 2.2 单线程单线程有什么好处呢? 没有创建线程、销毁线程带来的消耗. 避免了上下文切换带来的cpu消耗 避免了线程之间带来的竞争问题, 例如加锁, 释放锁, 死锁等等. 2.3 异步非阻塞I/O, 多路复用处理并发连接.3. redis为什么是单线程的?不是白白浪费了CPU的资源呢? https://redis.io/topics/faq#redis-is-single-threaded-how-can-i-exploit-multiple-cpu--cores 因为单线程已经够用了, CPU不是redis的瓶颈. redis 的瓶颈最有可能是机器内存或者网络带宽. 既然单线程容易实现, 而且CPU 不会成为瓶颈, 那就顺理成章的采用单线程的方案了. 4. 单线程为什么这么快?因为redis 是基于内存的操作, 我们先从内存开始说起. 4.1 虚拟存储器(虚拟内存Vitual Memory)名词解释： 主存: 内存; 辅存:磁盘(硬盘) 计算机内存(主存) 可看作一个由M个连续的字节大小的单元组成的数组, 每个字节都有一个唯一的地址, 这个地址叫做物理地址(PA). 早期的计算机中, 如果CPU 需要内存, 使用物理寻址, 直接访问主存储器. 这种方式有几个弊端: 在多用户多任务的操作系统中, 所有的进程共享内存, 如果每个进程都独占一块物理地址空间, 主存很快就会被用完. 我们希望在不同的时刻, 不同的进程都可以共用同一个物理地址空间. 如果所有的进程都是直接访问物理地址, 那么一个进程就可以修改其他物理内存的内存数据, 导致物理地址空间被破坏, 程序运行就会出现异常. 为了解决这个问题, 我们就想到了一个办法, 在CPU和主存之间增加一个中间层. CPU不再使用物理内存, 而是访问一个虚拟地址, 由这个中间层将地址转换为物理地址, 最终获得数据. 这个中间层就叫做虚拟存储器(Virtual Memory) 具体的操作如下所示： 在每一个进程开始创建的时候, 都会分配一段虚拟地址, 然后通过虚拟地址和物理地址的映射来获取真实的数据, 这样进程就不会直接接触到物理地址, 甚至不知道自己调用的哪块物理地址的数据, 目前, 大多数操作系统都是用了虚拟内存, 如window系统的虚拟内存、linux 系统的交换空间等等. windows的虚拟内存(pagefile.sys) 是磁盘空间的一部分. 在32位的系统上, 虚拟地址空间大小是2^32bit=4G. 在64位的系统上, 最大虚拟地址空间大小是多少? 是不是2^64bit=1024*1014TB=1024PB=16EB? 实际上并没有用到64位, 因为用不到这么大的空间，而且会造成很大的系统开销。 Linux 一般用低48位来表示虚拟地址, 也就是2^48bit=256T. cat /proc/cpuinfo address sizes : 40 bits physical, 48 bits virtual 实际的物理内存可能远远小于虚拟 内存的大小. 总结: 引入虚拟内存, 可以提供更大的地址空间, 并且地址空间是连续的, 使得程序编写、连接更加简单. 并且可以对物理内存进行隔离, 不同的进程操作互不影响. 还可以通过把同一快物理内存映射到不同的虚拟地址空间实现内存共享. 4.2 用户空间和内核空间为了避免用户进程直接操作内核, 保证内核安全, 操作系统将虚拟内存划分为两个部分, 一部分是内核空间(间（Kernel-space）/ˈkɜːnl /),一部分是用户空间(User-space). 内核是操作系统的核心, 独立于普通的应用程序, 可以访问受保护的内存空间, 也有访问底层硬件设备的权限. 内核空间中存放的是内核代码和数据, 而进程的用户控件中存放的是用户程序的代码和数据. 不管是内核空间还是用户空间, 他们都处于虚拟空间中, 都是对物理的映射 . 在linux系统中, 内核进程和用户进程所占的虚拟内存比例是 1:3 当进程运行在内核空间的时候就处于内核态, 而进程运行在用户空间则处于用户态. 进程在内核空间可以执行任意命令, 调用系统的一切资源: 在用户空间只能执行简单的运算, 不能直接调用系统资源, 必须通过调用系统接口(又称system call), 才能向内核空间发出指令. top命令: us: 代表CPU 消耗在User space 的时间百分比 sy: 代表CPU消耗在Kernel space的时间百分比. 4.3 进程切换(上下文切换)多任务操作系统是怎么实现运行远大于CPU数量的任务个数的? 当然， 这样任务实际上并不是真的在同时运行, 而是因为系统通过时间片分片算法, 在很短的时间内, 将CPU轮流分配给他们, 造成多任务同时运行的假象. 为了控制进程的执行, 内核必须有能力挂起正在CPU上运行的进程, 并恢复以前挂起的某个进程的执行, 这种行为被称为进程切换. 什么叫上下文? 在每个任务运行前, CPU都需要知道任务从哪里加载, 又从哪里开始运行, 也就说, 需要系统事先帮他设置好CPU 寄存器和程序计数器(Program Counter),这个叫做CPU的上下文. 而这些保存下来的上下文, 会存储在系统内核中, 并在任务重新调度执行时再次加入加载进来. 这样就能保证任务原来的状态不受影响, 让任务看起来还是连续运行的. 在切换上下文到时候, 需要完成一系列的动作, 这是一个很消耗资源的操作. 4.4 进程的阻塞正在运行的进程由于提出系统服务i请求(如I/O操作),但因为某种原因未得到操作系统的立即响应, 该进程只能将自己编程阻塞状态, 等待响应的事件出现后才被唤醒, 进程在阻塞状态不占CPU. 4.5 文件描述符(FD)linux 系统将所有设备都当作文件处理, 而linux 用文件描述符来标识每个文件对象. 文件描述符(File Descriptor) 是内核为了高效管理已经被打开的文件所创建的索引, 用于指向被打开的文件, 所有执行i/O 操作的系统调用都是通过文件描述符, 文件描述符是一个简单的非负整数, 用来表明每个被进程打开的文件 linux系统里面有三个标准的文件描述符 0: 表示输入(键盘) 1: 标准输出(显示器) 2: 标准错误输出(显示器) 4.6 传统I/O 数据拷贝以读操作为例： 当应用程序执行read系统调用读取文件描述符(FD) 的时候, 如果这块数据已经存在于用户进程的页内存中, 就直接从内存中读取数据. 如果数据不存在, 则先将数据从磁盘加载数据到内核缓冲区中, 再从内核缓存区拷贝到用户进程的页内存中(两次拷贝,两次user和kernel的上下文切换) I/O 的阻塞到底阻塞在哪里呢? 4.7 Blocking I/O当使用read 或者write对某个文件描述符进行读写时, 如果当前FD 不可读,系统就不会对其他的操作做出响应. 从设备复制数据到内核缓冲区是阻塞,从内核缓存区拷贝到用户空间也是阻塞的. 直到copy complete,内核返回结果, 用户进程才解除block的状态. 为了解决阻塞的问题, 我们有几个思路： 在服务端创建多个线程或者使用线程池, 但是在高并发的情况下需要的线程会很多, 系统无法承受, 而且创建和释放线程都需要消耗资源. 由请求方定期轮询, 在数据准备完毕后, 再从内核缓冲区复制数据到用户空间(非阻塞式I/O), 这种方式会存在一定的延迟. 能不能用一个线程处理多个客户端请求呢? 4.8 I/O多路复用(I/O Multiplexing)I/O 指的是网络I/O 多路: 指的是多个TCP连接(Socket 或者Channel) 复用: 指的是复用一个或者多个线程 他的基本原理就是不再由应用程序自己监视连接, 而是由内核替应用程序监视文件描述符. 客户端在操作的时候, 会产生具有不同事件的socket. 在服务端, I/O 多路复用程序(I/O Multiplexing Module) 会把消息放入到队列中, 然后通过文件事件分派器(File event Dispatcher), 转发到不同的事件处理器中. 多路复用有很多的实现, 以select为例, 当用户进程调用了多路复用器, 进程会被阻塞. 内核会监视多路复用器负责的所有socket, 当任何一个socket的数据准备好了, 多路复用器就会返回. 这个时候用户再调用read操作, 把数据从内核缓冲区拷贝到了用户空间. 所以, I/O多路复用的特点就是通过一种机制一个进程能够同时等待多个文件描述符,而这些文件描述符(套接字描述符)其中的任意一个进入读就绪(readable) 状态, select() 函数就可以返回. redis 的多路复用,提供了select.epoll,evport,kqueue几种选择, 在编译的时候来选择一种, 源码ae.c /* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */ #ifdef HAVE_EVPORT #include \"ae_evport.c\" #else #ifdef HAVE_EPOLL #include \"ae_epoll.c\" #else #ifdef HAVE_KQUEUE #include \"ae_kqueue.c\" #else #include \"ae_select.c\" #endif #endif #endif evport 是 Solaris 系统内核提供支持的； epoll 是 LINUX 系统内核提供支持的； kqueue 是 Mac 系统提供支持的； select 是 POSIX 提供的，一般的操作系统都有支撑（保底方案）； 源码 ae_epoll.c、ae_select.c、ae_kqueue.c、ae_evport.c","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"nginx 安装","slug":"nginx/nginx 安装","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/nginx/nginx-an-zhuang/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/nginx/nginx-an-zhuang/","excerpt":"","text":"1. 环境安装1.1 安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc yum install gcc-c++ 1.2 PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库yum install -y pcre pcre-devel 1.3 zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。yum install -y zlib zlib-devel 1.4 OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库yum install -y openssl openssl-devel 2. 编译安装2.1 将nginx-1.8.0.tar.gz拷贝至linux服务器。2.2 解压 tar -zxvf nginx-1.8.0.tar.gzcd nginx-1.8.0 2.3 编译 ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module make make install 3. 启动重启3.1 启动cd /usr/local/nginx/sbin/ ./nginx // 执行./nginx启动nginx，这里可以-c指定加载的nginx配置文件，如下：./nginx -c /usr/local/nginx/conf/nginx.conf.如果不指定-c，nginx在启动时默认加载conf/nginx.conf文件，此文件的地址也可以在编译安装nginx时指定./configure的参数（--conf-path= 指向配置文件（nginx.conf）） 3.2 停止nginx3.2.1 快速停止cd /usr/local/nginx/sbin ./nginx -s stop //此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。 3.2.2 完整停止cd /usr/local/nginx/sbin ./nginx -s quit // 此方式停止步骤是待nginx进程处理任务完毕进行停止。 3.3 重启3.3.1 先停止再启动// 对nginx进行重启相当于先停止nginx再启动nginx，即先执行停止命令再执行启动命令。 如下： ./nginx -s quit ./nginx 3.3.2 重新加载配置文件：// 当nginx的配置文件nginx.conf修改后，要想让配置生效需要重启nginx，使用-s reload不用先停止nginx再启动nginx即可将配置信息在nginx中生效，如下： ./nginx -s reload","categories":[{"name":"nginx","slug":"nginx","permalink":"https://rainsoil.github.io/categories/nginx/"},{"name":"nginx","slug":"nginx/nginx","permalink":"https://rainsoil.github.io/categories/nginx/nginx/"}],"tags":[]},{"title":"Nginx 配置文件 nginx","slug":"nginx/Nginx 配置文件 nginx.conf 详解","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/nginx/nginx-pei-zhi-wen-jian-nginx.conf-xiang-jie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/nginx/nginx-pei-zhi-wen-jian-nginx.conf-xiang-jie/","excerpt":"","text":"定义Nginx 运行的用户和用户组 user www www ; nginx 进程数,建议设置为等于CPU 总核心数 worker_processes 8; 全局错误日志定义类型 [ debug | info | notice | warn | error | crit ]error_log /var/log/nginx/error.log info; 进程文件 pid /var/run/nginx.pid; 一个nginx 进程打开的最多文件描述符数目,理论值应该是自多打开文件数(系统的值 ulimit -n)与nginx进程数相除,但是nginx 分配请求并不均匀,所以建议与ulimit -n 的值保持一致worker_rlimit_nofile 65535; 工作模式与连接数上限 events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） worker_connections 65535; &#125; 设定http 服务器http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型 #charset utf-8; #默认编码 server_names_hash_bucket_size 128; #服务器名字的hash表大小 client_header_buffer_size 32k; #上传文件大小限制 large_client_header_buffers 4 64k; #设定请求缓 client_max_body_size 8m; #设定请求缓 sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。 tcp_nopush on; #防止网络阻塞 tcp_nodelay on; #防止网络阻塞 keepalive_timeout 120; #长连接超时时间，单位是秒 #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用 upstream blog.ha97.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; &#125; 虚拟主机配置server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.ha97.com ha97.com; index index.html index.htm index.php; root /data/www/ha97; location ~ .*\\.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*\\.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 log_format access &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; $http_x_forwarded_for&#39;; #定义本虚拟主机的访问日志 access_log /var/log/nginx/ha97access.log access; #对 &quot;/&quot; 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数， proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic &quot;NginxStatus&quot;; auth_basic_user_file conf/htpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125; &#125; &#125;","categories":[{"name":"nginx","slug":"nginx","permalink":"https://rainsoil.github.io/categories/nginx/"},{"name":"nginx","slug":"nginx/nginx","permalink":"https://rainsoil.github.io/categories/nginx/nginx/"}],"tags":[]},{"title":"redis的其他数据结构和总结(7)","slug":"redis/redis的其他数据结构和总结(7)","date":"2022-01-04T02:42:07.253Z","updated":"2022-01-04T02:42:07.253Z","comments":true,"path":"2022/01/04/redis/redis-de-qi-ta-shu-ju-jie-gou-he-zong-jie-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/redis/redis-de-qi-ta-shu-ju-jie-gou-he-zong-jie-7/","excerpt":"","text":"其他数据结构1. BitMapsBitMaps 是在字符串类型上面定义的操作. 一个字节由8个二进制组成 set k1 a 获取 value 在 offset 处的值（a 对应的 ASCII 码是 97，转换为二进制数据是 01100001） 修改二进制数据（b 对应的 ASCII 码是 98，转换为二进制数据是 01100010） setbit k1 6 1 setbit k1 7 0 get k1 统计二进制位中 1 的个数 bitcount k1 获取第一个 1 或者 0 的位置 bitpos k1 1 bitpos k1 0 BITOP 命令支持 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种参数： BITOP AND destkey srckey1 … srckeyN ，对一个或多个 key 求逻辑与，并将结果保存到 destkey BITOP OR destkey srckey1 … srckeyN，对一个或多个 key 求逻辑或，并将结果保存到 destkey BITOP XOR destkey srckey1 … srckeyN，对一个或多个 key 求逻辑异或，并将结果保存到 destkey BITOP NOT destkey srckey，对给定 key 求逻辑非，并将结果保存到 destkey 应用场景用户访问统计 在线用户统计 2.HyperloglogsHyperloglogs 提供了一种不太准确的基数统计方法, 比如统计网站的UV,存在一定的误差, 3. Streams5.0 推出的数据类型。支持多播的可持久化的消息队列，用于实现发布订阅功能，借 鉴了 kafka 的设计。 总结1.数据结构总结 对象 对象type属性值 type命令输出 底层可能的数据结构 object_encoding 字符串对象 OBJ_STRING string OBJ_ENCODING_INTOBJ_ENCODING_EMBSTROBJ_ENCODING_RAW intembstrraw 列表对象 OBJECT_LIST list OBJ_ENCODING_QUICKLIST quicklist 哈希对象 OBJ_HASH hash OBJ_ENCODING_ZIPLISTOBJ_ENCODING_HT zuplisthashtable 集合对象 OBJ_SET set OBJ_ENCODING_INTSETOBJ_ENCODING_HT intsethashtable 有序集合对象 OBJ_ZSET zset OBJ_ENCODING_ZIPLISTOBJ_ENCODING_SKIPLIST ziplistskiplist（包含 ht） 2.编码转换特点 对象 原始编码 升级编码 字符串对象 INT embstr raw 字符串对象 整数并且小于long 2^63-1 超过44个字节被修改 哈希对象 ziplist hashtable 哈希对象 键和值的长度不超过64字节,键值对个数不超过512, 同时满足 列表对象 quicklist set对象 intset hashtable set对象 元素都是整数类型, 元素个数小于512个, 同时满足 zset对象 ziplist spiklist zset对象 元素个数不超过128个, 任何一个member 的长度不超过64, 同时满足","categories":[{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"}],"tags":[]},{"title":"MySQL性能优化总结(5)","slug":"mysql/MySQL性能优化总结(5)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mysql/mysql-xing-neng-you-hua-zong-jie-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mysql/mysql-xing-neng-you-hua-zong-jie-5/","excerpt":"","text":"MySQL性能优化总结1. 优化思路作为开发人员,说到数据库性能优化,你的思路是怎么样的呢? 或者具体一点, 如果在面试中遇到这个问题: 你会从哪些维度来优化数据库,你会怎么回答呢? 我们说到性能优化,其实大部分的时候想要实现的目标就是让我们的查询更快. 一个查询动作又是由很多个环节组成的,每个环接都会消耗时间。 我们要减少查询所消耗的时间,就要从每一个环节入手. 2. 连接–配置优化第一个环节是客户端连接到服务端,连接这一块有可能会出现什么样的性能问题? 有可能是服务端连接数不够导致应用程序获取不到连接,比如报了一个Mysql: error 1040: Too many connections的错误. 我们可以从这两个方面来解决连接数不够的问题: 从服务端来说，我们可以增加服务端的可用连接数. 如果有多个应用或者很多请求同时访问数据库,连接数不够的时候,我们可以： 修改配置参数增加可用连接数,修改max_connections的大小 show variables like 'max_connections'; -- 修改最大连接数，当有多个应用连接的时候 或者, 及时释放不活动的连接. 交互式和非交互式的客户端的默认超时时间都是28800秒, 8个小时,我们呢可以把这个值调小. show global variables like 'wait_timeout'; --及时释放不活动的连接，注意不要释放连接池还在使用的连接 从客户端来说,可以减少从服务端获取的连接数,如果我们想要不是每一次执行SQL都创建一个新的连接,应该怎么做呢? 这个时候我们可以引入连接池,实现连接的重用. 我们可以在哪些层面使用连接池呢? ORM层面(Mybatis 自带了一个连接池), 或者使用专门的连接池工具(阿里的Durid、SpringBoot2.x版本默认的连接池HiKari、老牌的DBCP和C3P0). 当客户端改成从连接池获取连接后,连接池的大小应该怎么设置呢? 大家可能有一个误解,觉得连接池的最大连接数大小越大越好,这样在高并发的情况下客户端可以获取到的连接数最多,不需要排队. 实际情况并不是这样的,连接池并不是越大越好,只要维护一定数量大小的连接池,其他的客户端排队等待获取连接就行了,有的时候连接池越大, 效率反而越低. Durid 的默认最大连接池大小是8, Hikari 的默认最大连接池大小是10. 为什么默认值都是这么小呢? 在Hikari 的github 文档中,给出了一个PostgreSQL 数据库建议的设置连接池大小的公式: https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing 它的建议是 [机器核数乘以2加1]. 也就是说, 4核的机器,连接池维护9个就够了. 这个公式从一定程度上来说对其他数据库也是适用的. 这里面还有一个减少连接池大小实现提升并发度和吞吐量的案例. 为什么有的情况下，减少连接数反而会提升吞吐量呢？ 为什么建议设置的连接池大小要跟CPU 的核数相关呢? 每个连接, 服务端都需要创建一个线程去处理它,连接数越多,服务端创建的线程就越多. 问题： CPU是怎么同时执行远远超过它的核数大小的任务? 时间片,上下文切换. 而CPU的核数是有限的,频繁的上下文切换会造成比较大的性能开销. 我们这里说到了从数据库配置的层面去优化数据库,不管是数据库本身的配置还是安装这个数据库服务的操作系统的配置,对于配置进行优化,最终的目的都是为了更好的发挥硬件的本身,包括CPU、内存、磁盘、网络等. 在不同的硬件环境下,操作系统和MySQL 的参数的配置是不同的, 没有标准的配置. 我们知道, 在MySQL和InnoDB 的配置参数,包括各种开关和数值的配置,大多数参数都提供了一个默认值, 比如默认的buffer_pool_size ,默认的页大小, InnoDB 并发线程数等. 这些默认配置可以满足大部分情况的需求, 除非有特殊的情况, 在清楚参数的含义的情况下再去修改它. 至于硬件本身的选择, 比如使用固态硬盘，搭建磁盘阵列,选择特定的CPU型号这些. 如果想要了解一下特定的参数的含义,官网有一份系统的参数列表可以参考: https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html 除了合理设置服务端的连接数和客户端的连接池大小之外,我们还有哪些减少客户端跟服务端的连接数的办法呢? 我们可以引入缓存 3. 缓存–架构优化3.1 缓存在应用系统的并发数非常大的情况下, 如果没有缓存,会造成两个问题: 一方面会给数据库带来很大的压力,另一方面,从应用的层面来说,操作数据的速度也会收到影响. 我们可以用第三方的缓存服务来解决这个问题, 比如Redis 运行独立的缓存服务, 属于架构层面的优化. 为了减少单台数据库服务器的读写压力,在架构层面我们还可以做哪些其他的优化呢? 3.2 主从复制如果单台服务器服务满足不了访问需求, 那我们可以做数据库的集群方案. 集群的话必然会面临一个问题,就是不同的节点之间的数据一致性的问题. 如果同时读写多台数据库节点,怎么让所有的节点数据保持一致呢? 这个时候我们就需要用到复制技术(replication),被复制的节点称为master, 复制的节点称为slave. slave 本身也可以作为i其他节点的数据来源,这个叫做联机复制. 主从复制是怎么实现的呢? 更新语句会记录binlog, 它是一种逻辑日志. 有了这个binlog, 从服务器会获取主服务器的binlog文件,然后解析里面的SQL语句,在从服务器上执行一遍, 保持主从服务器数据一致. 这里面涉及到三个线程,连接到master 获取binlog,并且解析binlog 写入中继日志,这个线程叫做IO线程. Master节点上有一个log dump 线程,是用来发送binlog 给slave的. 从库的SQL 线程,是用来读取relay log, 把数据写入到数据库的. 做了主从复制的方案之后,我们只把数据写入到master节点,而读的请求可以分担到slave节点,我们把这种方案叫做 读写分离. 读写分离可以一定程序上减轻数据库服务器的访问压力,但是需要特别注意的是数据一致性的问题.如果我们在master节点上写入了,但是到slave查询,而这个时候slave 的数据还没有同步过来, 怎么办? 所以, 基于主从复制的原理,我们需要明白,主从复制到底慢在哪里? 3.2.1 单线程在早期的MySQL中,slave的SQL线程是单线程,master 可以支持SQL语句的并行执行,配置了多少的最大连接数就是最多同时多少个SQL并行执行. 而slave的SQL却智能单线程排队执行, 在主库并发量很大的情况下,同步数据肯定会出现延迟. 为什么从库上的SQL Thread 不能并行执行呢? 举个例子,主库删除了多条SQL语句,首先用户发表了一条评论,然后修改了内容,最后把这条评论删除了,这三条语句在从库上的执行顺序肯定是不能颠倒的. insert into user_comments (10000009,'nice'); update user_comments set content ='very good' where id =10000009; delete from user_comments where id =10000009; 那怎么解决这个问题呢? 怎么减少主从复制的延迟? 3.2.2 异步与全同步首先我们知道,在主从复制的过程中, MySQL 默认是异步复制。也就是说,对于主节点来说,写入binlog, 事务结束,就返回给客户端的, 对于slave 来说,接收到binlog就完事了,master 不关心slave 的数据有没有写入成功. 如果要减少延迟,是不是可以等待全部从库的事务执行完毕,才返回给客户端呢? 这种的方式叫做 全同步复制. 从库写完数据,主库才会返回给客户端. 这种方式虽然可以保证在读之前,数据已经同步成功了,但是带来的副作用大家应该能想到,事务执行的时间会变长,它会导致master节点性能下降. 有没有更好的办法呢? 即减少slave 写入的延迟,又不会明显增加master返回给客户端的时间? 3.2.3 半同步复制介于异步复制和全同步复制之间的, 还有一种半同步复制的方式. 半同步复制是怎么样的呢? 主从在执行完客户端提交的事务后, 不是立即返回给客户端,而是等待至少一个从库接收到binlog 并写入到relay log中才返回给客户端. master 不会等待很长的时间, 但是返回给客户端的时候,数据就即将写入成功了, 因为它只剩最后一步了, 就是读取relay log ,写入到从库. 如果我们要在数据库中使用半同步复制,必须安装一个插件,这个是谷歌的一位工程师贡献的, 这个插件在MySQL 的插件目录下已经提供. cd /usr/lib64/mysql/plugin/ 主库和从库的插件是不一样的, 安装之后需要启动. -- 主库执行 INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so'; set global rpl_semi_sync_master_enabled=1; show variables like '%semi_sync%'; -- 从库执行 INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so'; set global rpl_semi_sync_slave_enabled=1; show global variables like '%semi%'; 相对于异步复制,半同步复制提高了数据的安全性, 同时它也造成了一定程序上的延迟,它需要等待一个salve写入中继日志, 这里多了一个网络交互的过程,所以, 半同步复制最好在低延迟的网络中使用. 这个是从主库和从库连接的角度,来保证slave数据的写入. 另一个思路,如果要减少主从同步的延迟,减少SQL执行造成的等待的时间,那有没有办法在从库上, 让多个SQL 语句可以并行执行呢? 而不是排队执行呢? 3.2.4 多库并行复制怎么实现并行复制呢? 设想一下,如果有3条语句是在三个数据库执行,执行各自的数据库,是不是肯定不会产生并发的问题,执行的顺序也没有要求. 当然是,所以如果是操作三个数据库,这三个数据库的从库的SQL线程可以并发执行. 这是MySQL5.6 版本里面支持的多库并行执行. 但是在大部分的情况下,我们都是单库多表操作的情况,在一个数据库里面怎么实现并行复制呢? 或者说,我们知道， 数据库本身就是支持多个事务同时操作的,为什么这些事务可以在主库上并行执行, 却不会出现问题呢? 因为他们本身就是互不干扰的,比如这些事务是在操作不同的表,或者操作不同的行,不存在资源竞争和数据的干扰. 那在主库上并行执行的事务,在从库上肯定也可以并行执行,是不是?比如在master 上有三个事务同时分别操作三张表,这三个事务分别操作三张表,这三个事务是不是在slave 上面也可以并行执行呢? 3.2.5 异步复制值GTID复制https://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html 所以,我们可以把这些在主库上并行执行的事务,分为一个组,并且给他们编号,这一个组的事务在从库上并行执行,这个编号,我们把它叫做GTID（Global Transaction Identifiers）,这种主从复制的方式, 我们 把它叫做基于GTID的复制. 如果我们要基于GTID 复制, 我们可以通过修改配置参数打开它,默认是关闭的. show global variables like 'gtid_mode'; 无论是优化master 和slave的连接参数,还是让从库可以并行执行SQL,都是从数据库的层面解决主从延迟的问题. 除了数据库本身的层面之外,在应用层面,我们也有一些减少主从延迟的方法. 我们在做了主从复制之后,如果单个master 节点或者单张表存储的数据过大的时候, 比如有一张表有上亿的数据, 单表的查询性能还是会下降的, 我们要进一步对单台数据库节点的数据分型拆分,这个就是分库分表. 3.3 分库分表垂直分库, 减少并发压力. 水平分表, 解决存储瓶颈. 垂直分库的做法 把一个数据库按照业务拆分成不同的数据库. 水平分库分表的做法,把单张表的数据按照一定的规则分布到多个数据库. 通过主从或者分库分表可以减少单个数据库节点的访问压力和存储压力,达到提升数据库性能的目的,但是如果master节点挂了怎么办? 所以,高可用High Available 也是高性能的基础. 3.4 高可用的方案https://dev.mysql.com/doc/mysql-ha-scalability/en/ha-overview.html 3.4.1 主从复制传统的HAProxy + keepalived 的方案,基于主从复制 3.4.2 NDB Clusterhttps://dev.mysql.com/doc/mysql-cluster-excerpt/5.7/en/mysql-cluster-overview.html 基于NDB 集群存储引擎的MySQL Cluster 3.4.3 Galerahttps://galeracluster.com/ 一种多主同步复制的集群方案. 3.4.4 MHA/MMMhttps://tech.meituan.com/2017/06/29/database-availability-architecture.html MMM（Master-Master replication manager for MySQL）,一种多主的高可用架构, 是一个日本人开发的,像美团这样的公司早期也有大量使用MMM MHA（MySQL Master High Available） MMM和MHA都是对外提供一个虚拟IP, 并且监控主节点和从节点,当主节点发生故障的时候,需要把一个从节点提升为主节点, 并且把从节点里面比主节点少的数据补上,把VIP指向新的主节点. 3.4.5 MGRhttps://dev.mysql.com/doc/refman/5.7/en/group-replication.html https://dev.mysql.com/doc/refman/5.7/en/mysql-cluster.html MySQL5.7.17 版本推出的 InnoDB Cluster，也叫 MySQL Group Replicatioin （MGR），这个套件里面包括了 mysql shell 和 mysql-route。 总结一下: 高可用HA方案需要解决的问题都是当一个master 节点宕机的时候,如何提升一个数据最新的salve为master.如果同时运行多个master,又必须要解决多个master之间的数据复制,以及对客户端来说连接路由的问题. 不同的方案,实施难度不一样,运行管理的成本也不一样. 以上是架构层面的优化,可以用缓存、主从、分库分表. 第三个环节,词法和语法分析,主要保证语句的正确性,语句不出错就没事,由Server自己处理, 跳过 第四步,优化器. 4. 优化器–SQL语句分析和优化优化器就是对我们的SQL语句进行分析,生成执行计划. 问题：在我们做项目的时候,有时会收到DBA的邮件,里面列出了我们项目里面的几个耗时比较长的查询语句,让我们去优化,这些语句是哪里来的呢? 我们的服务层每天执行了这么多SQL语句,他哪里知道哪些SQL语句比较慢呢? 第一步, 我们要把SQL执行情况记录下来. 4.1 慢查询日志slow query loghttps://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html 4.1.1 打开慢日志开关因为开启慢查询日志是有代价的(跟bin log、optimizer-trace 一样), 所以他默认是关闭的. show variables like 'slow_query%'; 除了这个开关,还有一个参数, 控制执行超过多长时间的SQL 才记录到慢日志,默认是10秒. show variables like '%slow_query%'; 可以直接动态修改参数(重启后失效) set @@global.slow_query_log=1; -- 1 开启，0 关闭，重启后失效 set @@global.long_query_time=3; -- mysql 默认的慢查询时间是 10 秒，另开一个窗口后才会查到最新值 show variables like '%long_query%'; show variables like '%slow_query%'; 或者直接修改配置文件my.cnf 以上配置定义了慢查询日志的开关、慢查询的时间、日志文件的存放路径. slow_query_log = ON long_query_time=2 slow_query_log_file =/var/lib/mysql/029a337d9174-slow.log 模拟慢查询 select sleep(10); 查询user_innodb 表的500W的数据(在没有索引的情况下查询) SELECT * FROM `user_innodb` where phone = '136'; 4.1.2 慢日志分析 日志内容 mysqld, Version: 5.7.29 (MySQL Community Server (GPL)). started with: Tcp port: 3306 Unix socket: /var/run/mysqld/mysqld.sock Time Id Command Argument # Time: 2020-05-18T12:48:25.026857Z # User@Host: root[root] @ [114.245.95.23] Id: 74958 # Query_time: 6.341634 Lock_time: 0.000200 Rows_sent: 0 Rows_examined: 5000000 use exercise; SET timestamp=1589806105; SELECT * FROM `user_innodb` where phone = '136'; 有了慢查询日志,怎么去分析呢? 比如SQL 语句的出现慢查询次数最多,平均每次执行了多久? mysqldumpslow MySQL提供了mysqldumpslow 的工具,在MySQL的bin 目录下. mysqldumpslow --help 例如:查询用时最多的20条慢SQL: mysqldumpslow -s t -t 20 -g 'select' /var/lib/mysql/localhost-slow.log Count: 代表这个SQL执行了多长时间 Time: 代表执行的时间,括号里面的累加时间. Lock: 表示锁定的时间, 括号是累计. Rows: 表示返回的记录数,括号是累计. 除了慢查询日志之外, 还有一个SHOW PROFILE 工具可以使用. 4.2 SHOW PROFILEhttps://dev.mysql.com/doc/refman/5.7/en/show-profile.html SHOW PROFILE 是谷歌高级架构师Jeremy Cole 共享给MySQL社区的,可以查看SQL语句执行的时候使用的资源,比如CPU、IO的消耗情况. 在SQL中输入help profile 可以得到详细的帮助信息. 4.2.1 查看是否开启select @@profiling; set @@profiling=1; 4.2.2 查看profile 统计show profiles; 查看最后一个SQL的执行详细信息,从中找出耗时较多的环节 show profile; 6.2E-5,小数点左移5位,代表0.000062 秒. 也可以根据ID查看执行详细信息, 在后面加上for query + ID show profile for query 1; 除了慢日志和show profile,如果要分析出当前数据库中执行的慢的SQL, 还可以通过查询运行线程状态和服务器运行信息、存储引擎信息来分析. 4.2.3 其他系统命令https://dev.mysql.com/doc/refman/5.7/en/show-processlist.html show processlist; 这是一个很重要的命令,用于显示用户运行线程, 可以根据ID号kill 线程. 也可以查表,效果一样. select * from information_schema.processlist; 列 含义 Id 线程的唯一标志,可以根据他kill 线程 User 启动这个线程的用户,普通用户只能看到自己的线程 Host 哪个IP端口发起的链接 db 操作的数据库 Command 线程的命令, https://dev.mysql.com/doc/refman/5.7/en/thread-commands.html Time 操作持续时间,单位秒. State 线程状态,比如查询可能有copying to tmp table，Sorting result，Sending data https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html Info SQL语句的前100个字符, 如果要查看完整的SQL 语句,用SHOW FULL PROCESSLIST show status 服务器运行状态 SHOW STATUS 用于查看MySQL 服务器运行状态(重启后会清空),有session和global 两种作用域,格式： 参数-值 可以用like 带通配符过滤. SHOW GLOBAL STATUS LIKE 'com_select'; -- 查看 select 次数 show engine 存储引擎运行信息 https://dev.mysql.com/doc/refman/5.7/en/show-engine.html show engine 用来显示存储引擎的当前运行信息,包括事务持有的表锁,行锁信息,事务的锁等待情况,线程信号量等待,文件IO请求,buffer pool 统计信息. 例如: show engine innodb status; 如果要将监控信息输入到错误信息error log中(15秒一次), 可以开启输出 show variables like 'innodb_status_output%'; -- 开启输出： SET GLOBAL innodb_status_output=ON; SET GLOBAL innodb_status_output_locks=ON; 我们现在已经知道了那么多分析服务器状态、存储引擎状态、线程运行信息的信息, 如果让你去写一个数据库监控系统 , 你会怎么做? 其实很多开源的慢查询日志监控,他们的原理其实i都是读取的系统的变量和状态. 现在我们已经知道了哪些SQL慢了,为什么慢? 慢在哪里? MySQL 提供了一个执行计划的工具,其他数据库, 例如Oracle 也有类似的功能. 通过EXPLAIN 我们可以模拟优化器执行SQL查询语句的过程,来知道SQL 是怎么处理一条SQL 语句的, 通过这种方式我们可以分析语句或者表的性能瓶颈. explain 可以分析update、delete、insert吗? MySQL 5.6.3 以前只能分析SELECT;MySQL 5.6.3 以后就可以分析update、delete、insert了. 4.3 EXPLAIN执行计划官方链接: https://dev.mysql.com/doc/refman/5.7/en/explain-output.html 我们先来创建三张表, 一张课程表，一张老师表,一张老师联系方式表(没有任何索引). DROP TABLE IF EXISTS course; CREATE TABLE `course` ( `cid` INT ( 3 ) DEFAULT NULL, `cname` VARCHAR ( 20 ) DEFAULT NULL, `tid` INT ( 3 ) DEFAULT NULL ) ENGINE = INNODB DEFAULT CHARSET = utf8mb4; DROP TABLE IF EXISTS teacher; CREATE TABLE `teacher` ( `tid` INT ( 3 ) DEFAULT NULL, `tname` VARCHAR ( 20 ) DEFAULT NULL, `tcid` INT ( 3 ) DEFAULT NULL ) ENGINE = INNODB DEFAULT CHARSET = utf8mb4; DROP TABLE IF EXISTS teacher_contact; CREATE TABLE `teacher_contact` ( `tcid` INT ( 3 ) DEFAULT NULL, `phone` VARCHAR ( 200 ) DEFAULT NULL ) ENGINE = INNODB DEFAULT CHARSET = utf8mb4; INSERT INTO `course` VALUES ( '1', 'mysql', '1' ); INSERT INTO `course` VALUES ( '2', 'jvm', '1' ); INSERT INTO `course` VALUES ( '3', 'juc', '2' ); INSERT INTO `course` VALUES ( '4', 'spring', '3' ); INSERT INTO `teacher` VALUES ( '1', 'qingshan', '1' ); INSERT INTO `teacher` VALUES ( '2', 'jack', '2' ); INSERT INTO `teacher` VALUES ( '3', 'mic', '3' ); INSERT INTO `teacher_contact` VALUES ( '1', '13688888888' ); INSERT INTO `teacher_contact` VALUES ( '2', '18166669999' ); INSERT INTO `teacher_contact` VALUES ( '3', '17722225555' ); explain 的结果有很多的字段,我们详细的分析一下: 4.3.1 Idid是查询序列编号 id值不同 id值不同的时候, 先查询id值大的(先大后小) -- 查询 mysql 课程的老师手机号 EXPLAIN SELECT tc.phone FROM teacher_contact tc WHERE tcid = ( SELECT tcid FROM teacher t WHERE t.tid = ( SELECT c.tid FROM course c WHERE c.cname = 'mysql' ) ) 查询顺序: course c——teacher t——teacher_contact tc 先查课程表,在查老师表,最后查老师联系方式表,子查询只能以这种方式进行, 只有拿到内层的结果之后才能进行外层的查询. id值相同· -- 查询课程 ID 为 2，或者联系表 ID 为 3 的老师 EXPLAIN SELECT t.tname, c.cname, tc.phone FROM teacher t, course c, teacher_contact tc WHERE t.tid = c.tid AND t.tcid = tc.tcid AND ( c.cid = 2 OR tc.tcid = 3 ); id值相同的时候,表的查询顺序是从上往下顺序执行的,例如这次查询的id 是1,查询的顺序是teacher t（3 条）——course c（4 条）——teacher_contact tc（3 条）。 teacher 表插入3条数据 INSERT INTO `teacher` VALUES (4, 'james', 4); INSERT INTO `teacher` VALUES (5, 'tom', 5); INSERT INTO `teacher` VALUES (6, 'seven', 6); COMMIT; -- （备份）恢复语句 DELETE FROM teacher where tid in (4,5,6); COMMIT; 再次执行语句,可以看到 id也都是1,但是从上往下的顺序就变成了 teacher_contact tc（3 条）——teacher t（6 条）——course c（4 条）。` 为什么数据量不同的时候顺序会发生变化呢？ 这个是由笛卡尔积决定的. 举例:假如有a,b,c 三张表,分别有2,3,4条数据,如果做三张表的联合查询,当查询的顺序为a-&gt;b-&gt;c的时候,它的笛卡尔积为: 2*3*4=6*4=24, 如果查询顺序为c-&gt;b-&gt;a的时候,它的笛卡尔积为4*3*2=12*2=24 因为MySQL 要把查询的结果, 包括中间结果和最终结果都保存到内存中,所以MySQL 会优先选择中间结果数量比较小的顺序进行查询,所以最终联表查询的顺序是a-&gt;B-&gt;C,这个就是为什么teacher 表插入数据后查询顺序会发生变化. 既有相同也有不同 如果ID 有相同也有不同,就是ID 不同的先大后小,ID相同的从上往下. 4.3.2 select type 查询类型这里并没有列举全部(其他:DEPENDENT UNION、DEPENDENT SUBQUERY、 MATERIALIZED、UNCACHEABLE SUBQUERY、UNCACHEABLE UNION ) 下面列举了一些常见的查询类型: SIMPLE简单查询, 不包含子查询,不包含关联查询union EXPLAIN SELECT * FROM teacher; 再看一个包含子查询的案例: -- 查询 mysql 课程的老师手机号 EXPLAIN SELECT tc.phone FROM teacher_contact tc WHERE tcid = ( SELECT tcid FROM teacher t WHERE t.tid = ( SELECT c.tid FROM course c WHERE c.cname = 'mysql' ) ); PRIMARY子查询SQL语句中的主查询,也就是最外面的那一层 SUBQUERY子查询中所有的内层查询都是SUBQUERY类型 DERIVED衍生查询,表示在得到最终的结果之前会用到临时表.例如: -- 查询 ID 为 1 或 2 的老师教授的课程 EXPLAIN SELECT cr.cname FROM ( SELECT * FROM course WHERE tid = 1 UNION SELECT * FROM course WHERE tid = 2 ) cr; 对于关联查询, 先执行右边的table（UNION）, 再执行左边的table, 类型是DERIVED UNION用到了UNION 查询,同上例 UNION RESULT主要是显示在那些表之间存在UNION查询,&lt;union2,3&gt; 代表id=2和id=3的查询存在UNION.同上例. 4.3.3 type 连接类型https://dev.mysql.com/doc/refman/5.7/en/explain-output.html 所有的连接类型中,上面的最好,下面的最差. 在常见的连接类型中:system&gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all 这里并没有列举全部,(其他fulltext 、 ref_or_null 、 index_merger 、 unique_subquery、index_subquery) 以上访问类型, 除了all, 都能用到索引. const主键索引或者唯一索引,只能查到一条数据 DROP TABLE IF EXISTS single_data; CREATE TABLE single_data ( id INT ( 3 ) PRIMARY KEY, content VARCHAR ( 20 ) ); INSERT INTO single_data VALUES ( 1, 'a' ); EXPLAIN SELECT * FROM single_data a WHERE id = 1; systemsystem是const的一种特例,只有一行满足条件,假如: 只有一条数据的系统表 EXPLAIN SELECT * FROM mysql.proxies_priv; eq_ref通常出现在多表的join 查询,表示对前表的每一个结果,都只能匹配到后表的一行结果. 一般是唯一性索引的查询(UNIQUE 或 PRIMARY KEY) eq_ref是除const 之外的最好的访问类型 先删除tracher 表的多余的数据,teacher_contact 有三条数据,teacher表有3条数据. DELETE FROM teacher where tid in (4,5,6); commit; -- 备份 INSERT INTO `teacher` VALUES (4, 'james', 4); INSERT INTO `teacher` VALUES (5, 'tom', 5); INSERT INTO `teacher` VALUES (6, 'seven', 6); commit; 为teacher_contact 表的tcid（第一个字段）创建主键索引. -- ALTER TABLE teacher_contact DROP PRIMARY KEY; ALTER TABLE teacher_contact ADD PRIMARY KEY(tcid); 为teacher 表的tcid(第三个字段)创建普通索引. -- ALTER TABLE teacher DROP INDEX idx_tcid; ALTER TABLE teacher ADD INDEX idx_tcid (tcid); 执行以下SQL语句 此时的执行计划(teacher_contact 表是eq_ref) 小结： 以上三种system、const、er_ref,都是可遇不可求的, 基本上很难优化到这个状态. ref查询用到了唯一索引,或者关联操作只是用了索引的最左前缀. 例如: 使用tcid上的普通索引查询 explain SELECT * FROM teacher where tcid = 3; renge索引范围扫描 如果where 后面的是betweenh and 或&lt; 或&gt; 或&gt;= 或&lt;= 或in这些, type 类型就为range 不走索引一定是全表查询(ALL), 所以先加上普通索引. -- ALTER TABLE teacher DROP INDEX idx_tid; ALTER TABLE teacher ADD INDEX idx_tid (tid); 执行范围查询(字段上有普通索引): EXPLAIN SELECT * FROM teacher t WHERE t.tid = 900000 LIMIT 10; 对于具体的SQL语句的优化,MySQL官网也给出了很多建议,这个是在分析具体的SQL语句的时候需要注意的. https://dev.mysql.com/doc/refman/5.7/en/optimization.html 5. 存储引擎5.1 存储引擎的选择为不同的业务选择不同的存储引擎,例如:查询插入操作多的业务表, 用MyISAM. 临时数据用Memeroy, 常规的并发大更新多的表用InnoDB. 5.2 分区或者分表分区一般是不推荐使用的. 可以对数据库的数据库量大的数据进行分表操作. 5.3 字段定义原则: 使用可以正确存储数据的最小数据类型 为每一列选择合适的字段类型. 5.3.1 整型类型 INT有8种类型,不同的类型的最大存储范围是不一样的. 5.3.2 字符类型变长的情况下, varchar 更节省空间,但是对于varchar 字段,需要一个字节来记录长度. 固定长度用char, 不要用varchar. 5.3.3 非空非空字段尽量定义为NOT NULL, 提供默认值,或者使用特殊值、空串代替null 5.3.4 不要使用外键、触发器、视图降低了可读性. 影像数据库性能,应该把计算的事情交给程序, 数据库专心做存储. 数据的完整性应该要在程序中检查. 5.3.5 大文件存储不要用数据库存储图片(比如base64编码)或者大文件 把文件放在NAS上,数据库只需要存储URI（相对路径）, 在应用中配置NAS 服务器地址. 5.3.6 表拆分将不常用的字段拆分出去,避免列出过多和数据量过大. 6. 总结: 优化体系 除了代码、SQL语句、表定义、架构、配置优化之外,业务层面的优化也不能忽略. 举几个例子： 在某年的双11, 为什么会做一个充值到余额宝和余额有奖金的活动(充300送50)? 因为使用余额宝或余额付款是记录本地或者内部数据库,而使用银行卡付款, 需要调用接口,操作内部数据肯定更快. 在去年的双11, 为什么在凌晨禁止查询今天之外的订单? 这是一种降级措施,用来保证当前最核心的业务. 最近几年的双11, 为什么提前一个多星期就已经有双11当前的价格？ 预售分流. 在应用层面同样有很多其他的方案来优化,达到尽量减轻数据库的压力的目的,比如限流、或者引入MQ削峰等等 为什么同样用MySQL的公司,有的公司可以抗住百分千万级别的并发,而有的公司几百个并发都扛不住,关键在于怎么用? 所以,用数据库慢,不代表数据库本身慢,有的时候还要往上层优化. 当然,如果关系型数据库解决不了的问题,我们可能需要用到搜索引擎或者大数据的方案了,并不是所有的数据都需要放到关系型数据库存储的.","categories":[{"name":"mysql","slug":"mysql","permalink":"https://rainsoil.github.io/categories/mysql/"},{"name":"mysql","slug":"mysql/mysql","permalink":"https://rainsoil.github.io/categories/mysql/mysql/"}],"tags":[]},{"title":"Mybatis 编程式开发(1)","slug":"mybatis/Mybatis 编程式开发(1)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mybatis/mybatis-bian-cheng-shi-kai-fa-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mybatis/mybatis-bian-cheng-shi-kai-fa-1/","excerpt":"","text":"1. Mybatis 编程式开发 编程式使用&nbsp;&nbsp;&nbsp;大部分时候，我们都是在 Spring 里面去集成 MyBatis。因为 Spring 对 MyBatis 的一些操作进行的封装，我们不能直接看到它的本质，所以先看下不使用容器的时候，也就是编程的方式，MyBatis 怎么使用。 &nbsp;&nbsp;先引入 mybatis jar 包。&nbsp;&nbsp;&nbsp;&nbsp;首先我们要创建一个全局配置文件，这里面是对 MyBatis 的核心行为的控制，比如mybatis-config.xml。 &nbsp;&nbsp;&nbsp;&nbsp;第二个就是我们的映射器文件，Mapper.xml，通常来说一张表对应一个，我们会在这个里面配置我们增删改查的 SQL 语句，以及参数和返回的结果集的映射关系。 &nbsp;&nbsp;&nbsp;&nbsp;跟 JDBC 的代码一样，我们要执行对数据库的操作，必须创建一个会话，这个在MyBatis 里面就是 SqlSession。SqlSession 又是工厂类根据全局配置文件创建的。所以整个的流程就是这样的（如下代码）。最后我们通过 SqlSession 接口上的方法，传入我们的 Statement ID 来执行 SQL。这是第一种方式。 &nbsp;&nbsp;&nbsp;&nbsp;这种方式有一个明显的缺点，就是会对 Statement ID 硬编码，而且不能在编译时进行类型检查，所以通常我们会使用第二种方式，就是定义一个 Mapper 接口的方式。这个接口全路径必须跟 Mapper.xml 里面的 namespace 对应起来，方法也要跟 StatementID 一一对应。 public void testMapper() throws IOException &amp;#123; String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); try &amp;#123; BlogMapper mapper = session.getMapper(BlogMapper.class); Blog blog = mapper.selectBlogById(1); System.out.println(blog); &amp;#125; finally &amp;#123; session.close(); &amp;#125; &amp;#125; 这个就是我们单独使用 MyBatis 的全部流程。 这个案例非常重要，后面我们讲源码还是基于它。 核心对象的生命周期&nbsp;&nbsp;在编程式使用的这个 demo 里面，我们看到了 MyBatis 里面的几个核心对象：SqlSessionFactoryBuiler、SqlSessionFactory、SqlSession 和 Mapper 对象。这几个核心对象在 MyBatis 的整个工作流程里面的不同环节发挥作用。如果说我们不用容器，自己去管理这些对象的话，我们必须思考一个问题：什么时候创建和销毁这些对象？ 在一些分布式的应用里面，多线程高并发的场景中，如果要写出高效的代码，必须了解这四个对象的生命周期。这四个对象的声明周期的描述在官网上面也可以找到。 http://www.mybatis.org/mybatis-3/zh/getting-started.html 我们从每个对象的作用的角度来理解一下，只有理解了它们是干什么的，才知道什么时候应该创建，什么时候应该销毁。 1）SqlSessionFactoryBuiler首 先 是 SqlSessionFactoryBuiler 。 它 是 用 来 构 建 SqlSessionFactory 的 ， 而SqlSessionFactory 只需要一个，所以只要构建了这一个 SqlSessionFactory，它的使命就完成了，也就没有存在的意义了。所以它的生命周期只存在于==方法的局部==。 2）SqlSessionFactorySqlSessionFactory 是用来创建 SqlSession 的，每次应用程序访问数据库，都需要创建一个会话。因为我们一直有创建会话的需要，所以 SqlSessionFactory 应该存在于应用的整个生命周期中（==作用域是应用作用域==）。创建 SqlSession 只需要一个实例来做这件事就行了，否则会产生很多的混乱，和浪费资源。所以我们要采用单例模式 3）SqlSessionSqlSession 是一个会话，因为它不是线程安全的，不能在线程间共享。所以我们在请求开始的时候创建一个 SqlSession 对象，在请求结束或者说方法执行完毕的时候要及时关闭它（==一次请求或者操作中==）。 4）MapperMapper（实际上是一个代理对象）是从 SqlSession 中获取的。 BlogMapper mapper = session.getMapper(BlogMapper.class); 它的作用是发送 SQL 来操作数据库的数据。它应该在一个 SqlSession 事务方法之内。 最后总结如下： 对象 生命周期 SqlSessionFactoryBuiler 方法局部（method） SqlSessionFactory（单例） 应用级别（application） SqlSession 请求和操作（request/method） Mapper 方法（method） 这个就是我们在编程式的使用里面看到的四个对象的生命周期的总结。 核心配置解读第一个是 config 文件。大部分时候我们只需要很少的配置就可以让 MyBatis 运行起来。其实 MyBatis 里面提供的配置项非常多，我们没有配置的时候使用的是系统的默认值。mybatis-3 的 源 码 托 管 在 github 上 。 源 码 地 址https://github.com/mybatis/mybatis-3/releases 目前最新的版本是 3.5.1，大家可以从官方上下载到最新的源码。 第一个是 jar 包和文档。第二个第三个是源码。 在这个压缩包里面，解压出来有一个 mybatis-3.5.1.pdf，是英文版本的。如果阅读英文困难，可以基于 3.5.1 的中文版本学习http://www.mybatis.org/mybatis-3/zh/index.html 一级标签configurationconfiguration 是整个配置文件的根标签，实际上也对应着 MyBatis 里面最重要的配置类 Configuration。它贯穿 MyBatis 执行流程的每一个环节。我们打开这个类看一下，这里面有很多的属性，跟其他的子标签也能对应上。 注意：MyBatis 全局配置文件顺序是固定的，否则启动的时候会报错。 properties第一个是 properties 标签，用来配置参数信息，比如最常见的数据库连接信息。 为了避免直接把参数写死在 xml 配置文件中，我们可以把这些参数单独放在properties 文件中，用 properties 标签引入进来，然后在 xml 配置文件中用${}引用就可以了。 可以用 resource 引用应用里面的相对路径，也可以用 url 指定本地服务器或者网络的绝对路径。 我们为什么要把这些配置独立出来？有什么好处？或者说，公司的项目在打包的时候，有没有把 properties 文件打包进去？ 提取，利于多处引用，维护简单； 把配置文件放在外部，避免修改后重新编译打包，只需要重启应用； 程序和配置分离，提升数据的安全性，比如生产环境的密码只有运维人员掌握。settingssetttings 里面是 MyBatis 的一些核心配置，我们最后再看，先看下其他的以及标签。typeAliasesTypeAlias 是类型的别名，跟 Linux 系统里面的 alias 一样，主要用来简化全路径类名的拼写。比如我们的参数类型和返回值类型都可能会用到我们的 Bean，如果每个地方都配置全路径的话，那么内容就比较多，还可能会写错。 我们可以为自己的 Bean 创建别名，既可以指定单个类，也可以指定一个 package，自动转换。配置了别名以后，只需要写别名就可以了，比如 com.domain.Blog都只要写 blog 就可以了。 MyBatis 里面有系统预先定义好的类型别名，在 TypeAliasRegistry 中。 typeHandlers【重点】由于 Java 类型和数据库的 JDBC 类型不是一一对应的（比如 String 与 varchar），所以我们把 Java 对象转换为数据库的值，和把数据库的值转换成 Java 对象，需要经过一定的转换，这两个方向的转换就要用到 TypeHandler。 有的同学可能会有疑问，我没有做任何的配置，为什么实体类对象里面的一个 String属性，可以保存成数据库里面的 varchar 字段，或者保存成 char 字段？ 这是因为 MyBatis 已经内置了很多 TypeHandler（在 type 包下），它们全部全部注册在 TypeHandlerRegistry 中，他们都继承了抽象类 BaseTypeHandler，泛型就是要处理的 Java 数据类型。 当我们做数据类型转换的时候，就会自动调用对应的 TypeHandler 的方法。 如果我们需要自定义一些类型转换规则，或者要在处理类型的时候做一些特殊的动作，就可以编写自己的 TypeHandler，跟系统自定义的 TypeHandler 一样，继承抽象类BaseTypeHandler。有 4 个抽象方法必须实现，我们把它分成两类： set 方法从 Java 类型转换成 JDBC 类型的，get 方法是从 JDBC 类型转换成 Java 类型的。| 从java类型到JDBC类型 | 从JDBC类型到JAVA类型 || ——————————– | ———————————————————— || setNonNullParameter:设置非空参数 | getNullableResult：获取空结果集（根据列名），一般都是调用这个getNullableResult：获取空结果集（根据下标值）getNullableResult：存储过程用的 | 比如我们想要在获取或者设置 String 类型的时候做一些特殊处理，我们可以写一个String 类型的 TypeHandler public class MyTypeHandler extends BaseTypeHandler&lt;String> &amp;#123; public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException &amp;#123; // 设置 String 类型的参数的时候调用，Java 类型到 JDBC 类型 System.out.println(\"---------------setNonNullParameter1：\"+parameter); ps.setString(i, parameter); &amp;#125; public String getNullableResult(ResultSet rs, String columnName) throws SQLException &amp;#123; // 根据列名获取 String 类型的参数的时候调用，JDBC 类型到 java 类型 System.out.println(\"---------------getNullableResult1：\"+columnName); return rs.getString(columnName); &amp;#125; // 后面两个方法省略………… &amp;#125; 第二步，在 mybatis-config.xml 文件中注册： &lt;typeHandlers> &lt;typeHandler handler=\"com.type.MyTypeHandler\">&lt;/typeHandler> &lt;/typeHandlers> 第三步，在我们需要使用的字段上指定，比如：插入值的时候，从 Java 类型到 JDBC 类型，在字段属性中指定 typehandler： &lt;insert id=\"insertBlog\" parameterType=\"com.domain.Blog\"> insert into blog (bid, name, author_id) values (#&amp;#123;bid,jdbcType=INTEGER&amp;#125;, #&amp;#123;name,jdbcType=VARCHAR,typeHandler=com.type.MyTypeHandler&amp;#125;, #&amp;#123;authorId,jdbcType=INTEGER&amp;#125;) &lt;/insert> 返回值的时候，从 JDBC 类型到 Java 类型，在 resultMap 的列上指定 typehandler： &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\" typeHandler=\"com.type.MyTypeHandler\"/> objectFactory【重点】当我们把数据库返回的结果集转换为实体类的时候，需要创建对象的实例，由于我们不知道需要处理的类型是什么，有哪些属性，所以不能用 new 的方式去创建。在MyBatis 里面，它提供了一个工厂类的接口，叫做 ObjectFactory，专门用来创建对象的实例，里面定义了 4 个方法。| 方法 | 作用 || ———————————————————— | —————————— || void setProperties(Properties properties); | 设置参数时调用 || T create(Class type); | 创建对象（调用无参构造函数） || T create(Class type, List&lt;Class&lt;?&gt;&gt; constructorArgTypes, ListconstructorArgs); | 创建对象（调用带参数构造函数） || boolean isCollection(Class type) | 判断是否集合 | ObjectFactory 有一个默认的实现类 DefaultObjectFactory，创建对象的方法最终都调用了 instantiateClass()，是通过反射来实现的。 如果想要修改对象工厂在初始化实体类的时候的行为，就可以通过创建自己的对象工厂，继承 DefaultObjectFactory 来实现（不需要再实现 ObjectFactory 接口）。 例如： public class MyObjectFactory extends DefaultObjectFactory &amp;#123; @Override public Object create(Class type) &amp;#123; if (type.equals(Blog.class)) &amp;#123; Blog blog = (Blog) super.create(type); blog.setName(\"by object factory\"); blog.setBid(1111); blog.setAuthorId(2222); return blog; &amp;#125; Object result = super.create(type); return result; &amp;#125; &amp;#125; 我们可以直接用自定义的工厂类来创建对象 public class ObjectFactoryTest &amp;#123; public static void main(String[] args) &amp;#123; MyObjectFactory factory = new MyObjectFactory(); Blog myBlog = (Blog) factory.create(Blog.class); System.out.println(myBlog); &amp;#125; &amp;#125; 这样我们就直接拿到了一个对象如果在 config 文件里面注册，在创建对象的时候会被自动调用：如果在 config 文件里面注册，在创建对象的时候会被自动调用： &lt;objectFactory type=\"org.mybatis.example.MyObjectFactory\"> &lt;!-- 对象工厂注入的参数 --> &lt;property name=\"name\" value=\"666\"/> &lt;/objectFactory> 这样，就可以让 MyBatis 的创建实体类的时候使用我们自己的对象工厂。 plugins插件是 MyBatis 的一个很强大的机制，跟很多其他的框架一样，MyBatis 预留了插件的接口，让 MyBatis 更容易扩展。 根据官方的定义，插件可以拦截这四个对象的这些方法，我们把这四个对象称作MyBatis 的四大对象。我们会在带大家阅读源码，知道了这 4 大对象的作用之后，再来分析自定义插件的开发和插件运行的原理。http://www.mybatis.org/mybatis-3/zh/configuration.html#plugins 类（或接口） 方法 Executor update, query, flushStatements, commit, rollback, getTransaction, close, isClosed ParameterHandler getParameterObject, setParameters ResultSetHandler| handleResultSets, handleOutputParametersStatementHandler |prepare, parameterize, batch, update, query environments、environmentenvironments 标签用来管理数据库的环境，比如我们可以有开发环境、测试环境、生产环境的数据库。可以在不同的环境中使用不同的数据库地址或者类型。 &lt;environments default=\"development\"> &lt;environment id=\"development\"> &lt;transactionManager type=\"JDBC\"/> &lt;dataSource type=\"POOLED\"> &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/> &lt;property name=\"url\" value=\"jdbc:mysql://127.0.0.1:3306/-mybatis?useUnicode=true\"/> &lt;property name=\"username\" value=\"root\"/> &lt;property name=\"password\" value=\"123456\"/> &lt;/dataSource> &lt;/environment> &lt;/environments> 一个 environment 标签就是一个数据源，代表一个数据库。这里面有两个关键的标签，一个是事务管理器，一个是数据源。 transactionManager如果配置的是 JDBC，则会使用 Connection 对象的 commit()、rollback()、close()管理事务 如果配置成 MANAGED，会把事务交给容器来管理，比如 JBOSS，Weblogic。因为我们跑的是本地程序，如果配置成 MANAGE 不会有任何事务。 如 果 是 Spring + MyBatis ， 则 没 有 必 要 配 置 ， 因 为 我 们 会 直 接 在applicationContext.xml 里面配置数据源，覆盖 MyBatis 的配置。 dataSource将在下一节（settings）详细分析。在跟 Spring 集成的时候，事务和数据源都会交给 Spring 来管理。 mappers标签配置的是我们的映射器，也就是 Mapper.xml 的路径。这里配置的目的是让 MyBatis 在启动的时候去扫描这些映射器，创建映射关系。 我们有四种指定 Mapper 文件的方式： http://www.mybatis.org/mybatis-3/zh/configuration.html#mappers 使用相对于类路径的资源引用（resource） 使用完全限定资源定位符（绝对路径）（URL） 使用映射器接口实现类的完全限定类名 将包内的映射器接口实现全部注册为映射器（最常用） settings最后 settings 我们来单独说一下，因为 MyBatis 的一些最关键的配置都在这个标签里面（只讲解一些主要的）。 属性名 含义 简介 有效值 默认值 cacheEnabled 是否使用缓存 是整个工程中所有映射器配置缓存的开关，即是一个全局缓存开关 true/false true lazyLoadingEnabled 是否开启延迟加载 控制全局是否使用延迟加载（association、collection）。当有特殊关联关系需要单独配置时，可以使用 fetchType 属性来覆盖此配置 true/false false aggressiveLazyLoading 是否需要侵入式延迟加载 开启时，无论调用什么方法加载某个对象，都会加载该对象的所有属性，关闭之后只会按需加载 true/false false defaultExecutorType 设置默认的执行器 有三种执行器：SIMPLE 为普通执行器；REUSE 执行器会重用与处理语句；BATCH 执行器将重用语句并执行批量更新 SIMPLE/REUSE/BATCH SIMPLE lazyLoadTriggerMethods 指定哪个对象的方法触发一次延迟加载 配置需要触发延迟加载的方法的名字，该方法就会触发一次延迟加载 一个逗号分隔的方法名称列表 equals，clone，hashCode，toString localCacheScope MyBatis 利用本地缓存机制（LocalCache）防止循环引用（circularreferences）和加速重复嵌套查询 默认值为 SESSION，这种情况下会缓存一个会话中执行的所有查询。若设置值为STATEMENT，本地会话仅用在语句执行上，对相同 SqlSession 的不同调用将不会共享数据 SESSION/STATEMEN T SESSION logImpl 日志实现 指定 MyBatis 所用日志的具体实现，未指定时将自动查找 SLF4J、LOG4J、LOG4J2、JDK_LOGGING、COMMONS_LOGGING、STDOUT_LOGGING、NO_LOGGING 无 multipleResultSetsEnabled 是否允许单一语句返回多结果集 即 Mapper 配置中一个单一的 SQL 配置是否能返回多个结果集 true/false true useColumnLabel 使用列标签代替列名 设置是否使用列标签代替列名 true/false true useGeneratedKeys 是否支持 JDBC 自动生成主键 设置之后，将会强制使用自动生成主键 的策略 true/false false autoMappingBehavior 指定 MyBatis 自动 映射字段或属性的方式 有三种方式，NONE时将取消自动映射；PARTIAL时只会自动映射没有定义结果集的结果映射；FULL 时会映射任意复杂的结果集 NONE/PARTIAL/FULL PARTIAL autoMappingUnknownColumnBehavior 设置当自动映射时发现未知列的动作 有三种动作：NONE 时不做任何操作；WARNING 时会输出提醒日志；FAILING时会抛出 SqlSessionException 异常表示映射失败 NONE/WARNING/FAILING NONE defaultStatementTimeout 设置超时时间 该超时时间即数据库驱动连接数据库时，等待数据库回应的最大秒数 任意正整数 无 defaultFetchSize 设置驱动的结果集获取数量（fetchSize）的提示值 为了防止从数据库查询出来的结果过多，而导致内存溢出，可以通过设置fetchSize 参数来控制结果集的数量 任意正整数 无 safeRowBoundsEnabled 允许在嵌套语句中使用分页（RowBound，即行内嵌套语句） 如果允许在 SQL 的行内嵌套语句中使用分页，就设置该值为 false true/false false safeResultHandlerEnabled 允许在嵌套语句中使用分页（ResultHandler，即结果集处理） 如果允许在 SQL 的结果集使用分页，就设置该值为 false true/false true mapUnderscoreToCamelCase 是否开启驼峰命名规则（camel case）映射 表明数据库中的字段名称与工程中Java 实体类的映射是否采用驼峰命名规则校验 true/false false jdbcTypeForNull JDBC类型的默认设置 当没有为参数提供特定的 JDBC 类型时，为空值指定 JDBC 类型。某些驱动需要指定列的 JDBC 类型，多数情况直接用一般类型即可，比如 NULL、VARCHAR 或 OTHER 常用 NULL、VARCHAR、OTHER OTHER defaultScriptingLanguage 动态 SQL 默认语言 指定动态 SQL 生成的默认语言 一个类型别名或者一个类的全路径名 org.apache.ibatis.scripting.xmltags.XMLLanguageDriver callSettersOnNulls 是否在控制情况下调用 Set 方法 指定当结果集中值为 null 时是否调用映射对象的 sette（r map 对象时为 put）方法，这对于有 Map.keySet()依赖或null 值初始化时是有用的。注意基本类型是不能设置成 null 的 true/false false returnInstanceForEmptyRow 返回空实体集对象 当返回行的所有列都是空时，MyBatis默认返回 null。当开启这个设置时，MyBatis 会返回一个空实例。请注意，它也适用于嵌套的结果集（从MyBatis3.4.2 版本开始） true/false false logPrefix 日志前缀 指定 MyBatis 所用日志的具体实现，未指定时将自动查找 任意字符串 无 vfsImpl vfs 实现 指定 vfs 的实现 自定义 VFS 的实现的类的全限定名，以逗号分隔 无 useActualParamName 使用方法签名 允许使用方法签名中的名称作为语句参数名称。要使用该特性，工程必须采用 Java8 编译，并且加上-parameters选项（从 MyBatis3.4.1 版本开始） 自定义 VFS 的实现的类的全限定名，以逗号分隔 无 configurationFactory 配置工厂 指定提供配置示例的类。返回的配置实例用于加载反序列化的懒加载参数。这个类必须有一个签名的静态配置getconfiguration()方法（从MyBatis3.2.3 版本开始） 一个类型别名或者一个类型的全路径名 无 Mapper.xml 映射配置文件http://www.mybatis.org/mybatis-3/zh/sqlmap-xml.html &nbsp;&nbsp;映射器里面最主要的是配置了 SQL语句，也解决了我们的参数映射和结果集映射的问题。一共有 8 个标签: cache- 给定命名空间的缓存配置(是否开启二级缓存) cache-ref-其他命名空间缓存配置的引用. resultMap- 是最复杂也是最强大的元素,用来描述如何从数据库结果集中加载对象&lt;resultMap id=\"BaseResultMap\" type=\"Employee\"> &lt;id column=\"emp_id\" jdbcType=\"INTEGER\" property=\"empId\"/> &lt;result column=\"emp_name\" jdbcType=\"VARCHAR\" property=\"empName\"/> &lt;result column=\"gender\" jdbcType=\"CHAR\" property=\"gender\"/> &lt;result column=\"email\" jdbcType=\"VARCHAR\" property=\"email\"/> &lt;result column=\"d_id\" jdbcType=\"INTEGER\" property=\"dId\"/> &lt;/resultMap> sql- 可被其他语句引用的可重用语句块&lt;sql id=\"Base_Column_List\"> emp_id, emp_name, gender, email, d_id &lt;/sql> 增删改查标签: insert: 映射插入语句 update: 映射修改语句 delete: 映射删除语句 select: 映射查询语句总结 配置名称 配置含义 配置简介 configuration 包裹所有的配置标签 整个配置文件的顶级标签 properties 属性 该标签可以引入外部配置的属性,也可以自己配置.该配置标签所在的同一个配置的其他配置均可以引用此配置的属性 setting 全局配置参数 用来配置一些改变运行时行为的信息,例如 是否使用缓存机制,是否使用延迟加载,是否使用错误处理机制等. typeAliases 类型别名 用来设置一些别名来代码java的长类型声明(如java.lang.int变为int),减少配置编码的冗余 typeHandlers 类型处理器 将数据库获取的值以合适的方法转换为java类型,或者将java类型的参数转换为数据库对应的类型 objectFactory 对象工厂 实例化目标类的工厂类配置 plugins 插件 可以通过插件修改Mybatis的核心行为,例如对语句执行的某一点进行拦截调用. environments 环境集合属性对象 数据库环境信息的集合,在同一个配置文件中,可以有多个数据库环境即可,这样可以使Mybatis将sql同时映射到多个数据库 environment 环境子属性对象 数据库环境配置的详细配置 transactionManager 事务管理 指定Mybatis的事务管理器 dataSource 数据源 使用其中的type指定数据源的链接类型,在标签对中可以使用property属性指定数据库连接池的其他信息 mappers 映射器 配置SQL映射文件的位置,告知Mybatis去哪里加载SQL映射文件 Mybatis最佳实践为什么需要动态sql？由于前台传入的查询参数不同,所以写了很多的if else,还需要非常注意SQL里面的and,空格,逗号和转义的单引号这些,拼接和调试SQL就是一件非常耗时的工作. Mybatis的动态SQL就帮助我们解决了这个问题,他是基于OGNL表达式的 动态标签有哪些?按照官网的分类,Mybatis的动态标签主要有四类:if,choose(when,otherwise),trim(where,set),foreaach. if 需要判断的时候,条件写在test中以下语句可以用 改写 &lt;select id=\"selectDept\" parameterType=\"int\" resultType=\"com.crud.bean.Department\"> select * from tbl_dept where 1=1 &lt;if test=\"deptId != null\"> and dept_id = #&amp;#123;deptId,jdbcType=INTEGER&amp;#125; &lt;/if> &lt;/select> choose(when,otherwise) –需要选择一个条件的时候&lt;select id=\"getEmpList_choose\" resultMap=\"empResultMap\" parameterType=\"com.crud.bean.Employee\"> SELECT * FROM tbl_emp e &lt;where> &lt;choose> &lt;when test=\"empId !=null\"> e.emp_id = #&amp;#123;emp_id, jdbcType=INTEGER&amp;#125; &lt;/when> &lt;when test=\"empName != null and empName != ''\"> AND e.emp_name LIKE CONCAT(CONCAT('%', #&amp;#123;emp_name, jdbcType=VARCHAR&amp;#125;),'%') &lt;/when> &lt;when test=\"email != null \"> AND e.email = #&amp;#123;email, jdbcType=VARCHAR&amp;#125; &lt;/when> &lt;otherwise> &lt;/otherwise> &lt;/choose> &lt;/where> &lt;/select> trim(where,set)–需要去掉where,and,逗号之类的符号的时候主要最后一个条件 did多个一个逗号,就是用trim去掉的 &lt;update id=\"updateByPrimaryKeySelective\" parameterType=\"com.crud.bean.Employee\"> update tbl_emp &lt;set> &lt;if test=\"empName != null\"> emp_name = #&amp;#123;empName,jdbcType=VARCHAR&amp;#125;, &lt;/if> &lt;if test=\"gender != null\"> gender = #&amp;#123;gender,jdbcType=CHAR&amp;#125;, &lt;/if> &lt;if test=\"email != null\"> email = #&amp;#123;email,jdbcType=VARCHAR&amp;#125;, &lt;/if> &lt;if test=\"dId != null\"> d_id = #&amp;#123;dId,jdbcType=INTEGER&amp;#125;, &lt;/if> &lt;/set> where emp_id = #&amp;#123;empId,jdbcType=INTEGER&amp;#125; &lt;/update> trim用来指定或者去掉前缀或者后缀&lt;insert id=\"insertSelective\" parameterType=\"com.crud.bean.Employee\"> insert into tbl_emp &lt;trim prefix=\"(\" suffix=\")\" suffixOverrides=\",\"> &lt;if test=\"empId != null\"> emp_id, &lt;/if> &lt;if test=\"empName != null\"> emp_name, &lt;/if> &lt;if test=\"dId != null\"> d_id, &lt;/if> &lt;/trim> &lt;trim prefix=\"values (\" suffix=\")\" suffixOverrides=\",\"> &lt;if test=\"empId != null\"> #&amp;#123;empId,jdbcType=INTEGER&amp;#125;, &lt;/if> &lt;if test=\"empName != null\"> #&amp;#123;empName,jdbcType=VARCHAR&amp;#125;, &lt;/if> &lt;if test=\"dId != null\"> #&amp;#123;dId,jdbcType=INTEGER&amp;#125;, &lt;/if> &lt;/trim> &lt;/insert> foreach—需要遍历集合的时候&lt;delete id=\"deleteByList\" parameterType=\"java.util.List\"> delete from tbl_emp where emp_id in &lt;foreach collection=\"list\" item=\"item\" open=\"(\" separator=\",\" close=\")\"> #&amp;#123;item.empId,jdbcType=VARCHAR&amp;#125; &lt;/forea 动态SQL主要是用来解决SQL语句生成的问题 批量操作 我们在生产的项目中会有一个批量操作的场景,比如导入文件批量处理数据的情况(批量新增商户,批量修改商户信息),当数据量非常大,比如超过几万条的时候,在java代码中循环发送SQL到数据库执行肯定是不现实的,因为这意味着要跟数据库创建几万次绘画,即使我们使用了数据库连接池技术,对于数据库服务器来说也是不堪重负的 在Mybatis里面支持批量操作的,包括批量的插入,更新,删除.我们可以直接传入一个List,Set,Map或者数组,配置动态SQL的标签,Mybatis会自动帮我们生成语法正确的SQL语句 批量插入批量插入的语法是这样的,只要在value后面增加插入的值就可以了 insert into tbl_emp (emp_id, emp_name, gender,email, d_id) values ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , ( ?,?,?,?,? ) , 在Mapper文件里面,我们可以使用foreach标签拼接values部分的语句 &lt;!-- 批量插入 --> &lt;insert id=\"batchInsert\" parameterType=\"java.util.List\" useGeneratedKeys=\"true\"> &lt;selectKey resultType=\"long\" keyProperty=\"id\" order=\"AFTER\"> SELECT LAST_INSERT_ID() &lt;/selectKey> insert into tbl_emp (emp_id, emp_name, gender,email, d_id) values &lt;foreach collection=\"list\" item=\"emps\" index=\"index\" separator=\",\"> ( #&amp;#123;emps.empId&amp;#125;,#&amp;#123;emps.empName&amp;#125;,#&amp;#123;emps.gender&amp;#125;,#&amp;#123;emps.email&amp;#125;,#&amp;#123;emps.dId&amp;#125; ) &lt;/foreach> &lt;/insert> java代码里面,直接传入一个List类型的参数 我们来测试一下.效率要比循环发送SQL执行的要高的多,最关键的地方就在于减少了跟数据库交互的次数,并且避免了开启和结束事务的时间消耗。 批量更新批量更新的语法是这样的,通过case when,来匹配id相关的字段值 update tbl_emp set emp_name = case emp_id when ? then ? when ? then ? when ? then ? end , gender = case emp_id when ? then ? when ? then ? when ? then ? end , email = case emp_id when ? then ? when ? then ? when ? then ? end where emp_id in ( ? , ? , ? ) 所以在Mapper文件里面最关键的就是case when和where的配置 需要注意一下open属性和separator属性 &lt;update id=\"updateBatch\"> update tbl_emp set emp_name = &lt;foreach collection=\"list\" item=\"emps\" index=\"index\" separator=\" \" open=\"case emp_id\" close=\"end\"> when #&amp;#123;emps.empId&amp;#125; then #&amp;#123;emps.empName&amp;#125; &lt;/foreach> ,gender = &lt;foreach collection=\"list\" item=\"emps\" index=\"index\" separator=\" \" open=\"case emp_id\" close=\"end\"> when #&amp;#123;emps.empId&amp;#125; then #&amp;#123;emps.gender&amp;#125; &lt;/foreach> ,email = &lt;foreach collection=\"list\" item=\"emps\" index=\"index\" separator=\" \" open=\"case emp_id\" close=\"end\"> when #&amp;#123;emps.empId&amp;#125; then #&amp;#123;emps.email&amp;#125; &lt;/foreach> where emp_id in &lt;foreach collection=\"list\" item=\"emps\" index=\"index\" separator=\",\" open=\"(\" close=\")\"> #&amp;#123;emps.empId&amp;#125; &lt;/foreach> &lt;/update> 批量删除也是类似的 Batch Executor当然Mybatis的动态标签的批量操作也是存在一定的缺点的,比如数据量比较大的时候,拼接出来的SQL语句过大. MySql的服务端对于接受的数据包有大小限制,max_allowed_packet 默认是4M，需要修改默认配置才可以解决这个问题 Caused by: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (7188967 &gt; 4194304). You can change this value on the server by setting the max_allowed_packet&#39; variable. 在我们的全局配置文件中,可以配置默认的Executor的类型,其中有一种BatchExecutor 也可以在创建会话的时候指定执行器的类型 SqlSession session = sqlSessionFactory.openSession(ExecutorType.BATCH); BatchExecutor 底层的对JDBC ps.addBatch()的封装,原理是攒一批SQL以后再发送 嵌套(关联)查询/N+1/延迟加载我们在查询业务数据的时候，经常会遇到跨表关联的情况,比如查询员工就会关联部门,查询成绩就会关联课程,查询订单就会关联商品等等 我们映射结果有两个标签,一个是resultType,一个是resultMap. resultType是select标签的一个属性,适用于返回JDK类型(如Integer,String等等)和实体类.这种情况下结果集的列和实体类的属性可以直接映射,如果返回的字段无法直接映射,就要欧阳那个resultMap来建立映射关系. 对于关联查询的这种情况,通常不能用resultType来映射,要么就是修改dto,在里面增加字段,这个会导致增加很多无关的字段,要么就是引用关联的对象,比如Blog里面包含一个Author对象，这种情况下就要用到关联查询(assocation,或者嵌套查询),Mybatis可以帮我们自动做结果的映射. 一对一的关联查询有两种配置方式: 嵌套结果&lt;!-- 根据文章查询作者，一对一查询的结果，嵌套查询 --> &lt;resultMap id=\"BlogWithAuthorResultMap\" type=\"com.domain.associate.BlogAndAuthor\"> &lt;id column=\"bid\" property=\"bid\" jdbcType=\"INTEGER\"/> &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\"/> &lt;!-- 联合查询，将 author 的属性映射到 ResultMap --> &lt;association property=\"author\" javaType=\"com.gupaoedu.domain.Author\"> &lt;id column=\"author_id\" property=\"authorId\"/> &lt;result column=\"author_name\" property=\"authorName\"/> &lt;/association> &lt;/resultMap> 嵌套查询:&lt;!-- 另一种联合查询 (一对一)的实现，但是这种方式有“N+1”的问题 --> &lt;resultMap id=\"BlogWithAuthorQueryMap\" type=\"com.domain.associate.BlogAndAuthor\"> &lt;id column=\"bid\" property=\"bid\" jdbcType=\"INTEGER\"/> &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\"/> &lt;association property=\"author\" javaType=\"com.gupaoedu.domain.Author\" column=\"author_id\" select=\"selectAuthor\"/> &lt;!-- selectAuthor 定义在下面--> &lt;/resultMap> &lt;!-- 嵌套查询 --> &lt;select id=\"selectAuthor\" parameterType=\"int\" resultType=\"com.domain.Author\"> select author_id authorId, author_name authorName from author where author_id = #&amp;#123;authorId&amp;#125; &lt;/select> 其中第二种查询方式:嵌套查询,由于是分两次查询,当我们查询了员工信息之后,会再发送一条SQL到数据库查询部门信息 我们只执行了一次查询员工信息的SQL(所谓的1),如果返回了N条记录,就会再发送N条到数据库查询部门信息(所谓的N),这个就是我们所说的N+1的问题,这样就会白白的浪费我们的应用和数据库的性能. 如果我们用了嵌套查询的方式,怎么解决这个问题呢?能不能等到使用部门信息的时候再去查询呢?这个就是我们所说的延迟加载,或者叫懒加载. 在Mybatis里面可以通过开启延迟加载的开关来解决这个问题. 在settings标签里面可以配置 &lt;!--延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。默认 false --> &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/> &lt;!--当开启时，任何方法的调用都会加载该对象的所有属性。默认 false，可通过 select 标签的 fetchType 来覆盖--> &lt;setting name=\"aggressiveLazyLoading\" value=\"false\"/> &lt;!-- Mybatis 创建具有延迟加载能力的对象所用到的代理工具，默认 JAVASSIST --> &lt;setting name=\"proxyFactory\" value=\"CGLIB\" /> lazyLoadingEnabled 决定了是否延迟加载.aggressiveLazyLoading 决定了是不是对象的所有方法都会触发查询 先来测试一下(也可以修改成查询列表) 没有开启延迟加载的开关,会连续发送两次查询 开启了延迟加载的开关,调用 blog.getAuthor()以及默认的(equals,clone,hshCode,toString)时才会发送第二次查询,其他方法并不会触发查询.比图blog.getName(). 如果开启了 aggressiveLazyLoading=true ,其他方法也会触发查询,比如 blog.getName() 问题:为什么可以做到延迟加载呢?blog.getAuthor(),只是一个获取属性的方法,里面并没有链接数据库的代码,为什么会触发对数据库的查询 将 blog对象打印出来 System.out.println(blog.getClass()); class com.domain.associate.BlogAndAuthor_$$_jvst70_0 这个类的名字的后面有个jvst,是JAVASSIST的缩写,原来到这里带延迟加载的功能的对象blog已经变成了一个代理对象.","categories":[{"name":"mybatis","slug":"mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/"},{"name":"mybatis","slug":"mybatis/mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/mybatis/"}],"tags":[]},{"title":"Mybatis 体系结构和工作原理(2)","slug":"mybatis/Mybatis 体系结构和工作原理(2)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mybatis/mybatis-ti-xi-jie-gou-he-gong-zuo-yuan-li-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mybatis/mybatis-ti-xi-jie-gou-he-gong-zuo-yuan-li-2/","excerpt":"","text":"2. Mybatis 体系结构和工作原理 Mybatis的工作流程分析 首先,在Mybatis启动的时候解析配置文件,包括全局配置文件和映射器文件,这里面包含了我们怎么去控制Mybatis的行为,和我们要对数据库下达的命令,也就是我们的SQL信息,我们会把他们解析为一个configuration对象 接下来就是我们操作数据库的接口,他在应用程序和数据库的中间,代表我们和数据库之间的一次连接,这个就是sqlSession对象. 我们要获得一个会话,必须有个会话工厂sqlSessionFactory.SqiSessionFactory 里面又必须包含我们的所有的配置信息,所以我们会通过一个Builder来创建工厂类. 我们知道,Mybatis是对JDBC的封装,也就是意味着底层一定会出现JDBC的一些核心对象,比如执行SQL的Statement,结果集ResultSet.在Mybatis中SqlSession 只是提供了应用一个接口,还不是SQL的真正执行对象. 在SqlSession中有一个Executor对象,用来封装对数据库的操作.在执行器Executor执行query或者update操作的时候,我们创建了一系列的对象来处理参数,执行SQL，处理结果集.Mybatis的执行流程如下: Mybatis架构分层和模块划分 接口层首先接口层是我们打交道最多的.核心对象是SqlSession,它是上层应用和Mybatis打交道的桥梁,SqlSession 上定义了非常多的对数据库的操作方法,接口层在接收到调用请求的时候M回调用核心处理层的相应模块来完成具体的数据库操作. 核心处理层 接下来是核心处理层.既然叫核心处理层,也就是跟数据库操作相关的动作都是在这一层完成 核心处理层主要做了这几件事情: 把接口中传入的参数解析并且映射成JDBC类型 解析XML文件中的SQL语句,包括插入参数,和动态SQL的生成 执行SQL语句 处理结果集,并且映射成java对象 插件层也是属于核心层,这是由他的工作方式和拦截的对象决定的 基础支持层 最后一个就是基础支持层.基础支持层主要是一些抽取出来的通用的功能(实现复用),用来支持核心处理层的功能.比如数据源,缓存,日志,XML解析,反射,IO,事务等这些功能. Mybatis 缓存详解cache 缓存 缓存是一般的ORM框架都是提供的功能,目的就是为为了提升查询的效率和减少数据库的压力.跟Hibernate一样,Mybatis 也有一级缓存和二级缓存,并且预留了继承第三方缓存的接口. 缓存体系结构 Mybatis跟缓存相关的类都在cache包里面,其中有一个Cache接口,只有一个默认的实现 PerpetualCache,它是用HashMap实现的. 除此之外,还有很多的装饰器,通过这些装饰器可以额外实现很多的功能:回收策略,日志记录,定时刷新等. 但是无论怎么装饰,经过多少装饰,最后使用的还是基础的实现类(默认的实现类PerpetualCache) 所有的缓存实现类总体上可分为三类:基础缓存,淘汰算法缓存,装饰器缓存| 缓存实现类 | 描述 | 作用 | 装饰条件 || ——————- | —————- | ———————————————————— | ————————————— || 基本缓存 | 缓存基本实现类 | 默认是PerpetualCche,也可以自定义比如RedisCache,EhCache等,据类基础功能的缓存类 | 无 || LruCache | LRU策略的缓存 | 当缓存到达上限的时候,删除最近使用最少的缓存(Least Recently Use) | eviction=”LRU”(默认) || FifoCache | FIFO策略的缓存 | 当缓存达到上限的时候,删除最先入队的缓存 | eviction=”FIFO” || SoftCache WeakCache | 带清理策略的缓存 | 通过JVM的软引用和弱引用来实现缓存,当JVM内存不足的时候,会自动清理到这些缓存,基于SoftReference和WeakReference | eviction=”SOFT” eviction=”WEAK” || LoggingCache | 带日志功能的缓存 | 比如输出缓存命中率 | 基本 || SynchronizedCache | 同步缓存 | 基于Synchronized关键字实现,解决并发问题 | 基本 || BlockingCache | 阻塞缓存 | 通过在get/put方式中加锁,保证只有一个线程操作缓存,基于java重入锁实现 | blocking=true || SerializedCache | 支持序列化的缓存 | 将对象序列化后放入缓存中,取出是反序列化 | readOnly=faise(默认) || ScheduledCache | 定时调度的缓存 | 在进行get/put/remove/getSize等操作前,判断缓存时间是否超过了设置的最长缓存时间(默认是一个小时),如果是则清空缓存–即每隔一段时间清空一次缓存 | flushInterval不为空 || TransactionalCache | 事务缓存 | 在二级缓存中使用,可一次存入多个缓存,移除多个缓存 | 在TransactionalCache中用Map维护对应关系 | 一级缓存一级缓存(本地缓存)介绍 一级缓存也叫本地缓存,Mybatis的一级缓存默认的在会话(SqlSession)层面进行缓存的,Mybatis的一级缓存默认是开启的,不需要任何的配置. 首先我们必须去弄清楚一个问题,在Mybatis的执行流程里面,设计到那么多的对象,那么缓存PerpetualCache应该放到哪个对象里面去维护?如果要在同一个会话中共享一级缓存,那么对象肯定是在SqlSession里面创建的,作为SqlSession的一个属性. DefaultSqlSession 里面只有两个属性,Configuration 是全局的,所有缓存只可能放到Executor 里面维护– SimpleExecutor/ReuseExecutor/BatchExecutor 的父类BaseExecutor 的构造函数里面持有了PerpetualCache 在同一个会话中,多次执行相同的SQL语句,会直接从内存中取到缓存的结果,不会再发送SQL到数据库.但是不同的会话里面,即使执行的SQL是一模一样的(通过一个Mapper的同一个方法的相同参数调用) ,也不能使用到一级缓存 接下来我们验证一下,Mybatis 的一级缓存到底是不是只能在一个会话中共享,以及跨会话(不同的session)操作相同的数据会产生什么问题. 一级缓存验证 判断是否命中缓存: 如果再次发送SQL到数据执行,说明没有命中缓存;如果直接打印对象,则说明是从内存缓存中获取到数据 在同一个session中共享```javaBlogMapper mapper = session.getMapper(BlogMapper.class);System.out.println(mapper.selectBlog(1));System.out.println(mapper.selectBlog(1)); 2. 不同session 不能共享 ```java SqlSession session1 = sqlSessionFactory.openSession(); BlogMapper mapper1 = session1.getMapper(BlogMapper.class); System.out.println(mapper.selectBlog(1)); PS:一级缓存在BaseExecutor 的query()—queryFromDatabase()中存入,在queryFromDatabase()之前会get() 3.在 同一个会话中,update(包括delete) 会导致一级缓存被清空 mapper.updateByPrimaryKey(blog); session.commit(); System.out.println(mapper.selectBlogById(1)); 一级缓存是在BaseExecutor 中的update()方法调用 clearLocalCache()清空的(无条件),query中会判断 如果出现了跨会话,会出现什么问题呢?4. 其他会话更新了数据,导致读取到脏数据(一级缓存不能跨会话共享) // 会话 2 更新了数据，会话 2 的一级缓存更新 BlogMapper mapper2 = session2.getMapper(BlogMapper.class); mapper2.updateByPrimaryKey(blog); session2.commit(); // 会话 1 读取到脏数据，因为一级缓存不能跨会话共享 System.out.println(mapper1.selectBlog(1)); 一级缓存的不足使用一级缓存的时候,因为缓存不能跨会话共享,不同的会话之间对于相同的数据可能会有不一样的缓存.再有多个会话或者分布式的缓存下,会存在脏数据的问题,如果要解决这个问题,就要使用二级缓存. 二级缓存介绍二级缓存是用来解决一级缓存不能跨会话共享的问题的,范围是namespace 级别的,可以被多个SqlSession共享(只要是同一个接口里里面的相同的方法,都可以共享),生命周期和应用同步. 思考一个问题:如果开启了二级缓存,二级缓存应该是工作在一级缓存之前还是一级缓存之后呢?二级缓存是在哪里维护的? 作为一个作用范围更广的缓存,他肯定是在SqlSession 的外层,否则不可能被多个SqlSession 共享.而一级缓存是在SqlSession的内部,所以第一个问题,肯定是工作在一级缓存之前,也就是只有取不到二级缓存的情况下才会到一个会话中取一级缓存. 第二个问题,二级缓存存放到哪个对象中维护呢?要跨会话共享的话,SqlSession 本身和它里面的BaseExecutor 已经满足不了需求了,那我们应该在BaseExecutor 外创建一个对象. 实际上,Mybatis是用了一个装饰类来维护,就是CachingExecutor.如果启动了二级缓存,Mybatis 就会在创建Executor 对象的时候就会对Executor 进行装饰. CacheExecutor 对于查询请求,会判断二级缓存是否有缓存结果,如果有就直接返回,如果没有委派交给真正的查询器Executor 实现类,比如SimpleExecutor来执行查询,再走到一级缓存的流程,最后会把结果缓存起来,并且返回给用户. 一级缓存是默认开启的,那么二级缓存呢？ 开启二级缓存的方法第一步:在 mybatis-config.xml 中配置了(可以不配置,默认为true) 只要没有显示的设置 cacheEnable=false, 都会用CachingExecutor 装饰基本的执行器. 第二步: 在Mapper.xml文件中配置 标签： &lt;!-- 声明这个 namespace 使用二级缓存 --> &lt;cache type=\"org.apache.ibatis.cache.impl.PerpetualCache\" size=\"1024\" &lt;!—最多缓存对象个数，默认 1024--> eviction=\"LRU\" &lt;!—回收策略--> flushInterval=\"120000\" &lt;!—自动刷新时间 ms，未配置时只有调用时刷新--> readOnly=\"false\"/> &lt;!—默认是 false（安全），改为 true 可读写时，对象必须支持序列 化 --> cache属性讲解| 属性 | 含义 | 取值 || ————- | ———————————- | ———————————————————— || type | 缓存实现类 | 需要实现Cache接口,默认是PerpetualCache || size | 最多缓存对象个数 | 默认1024 || eviction | 回收策略(缓存淘汰算法) | LRU - 最近最少使用的;移除最长时间不被使用的对象(默认) FIFO - 先进先出,按照对象进入缓存的顺序来移除他们; SOFT - 软引用;移除基于垃圾回收器状态和软引用规则的对象; WEAK - 弱引用;更积极的移除基于垃圾回收器状态和弱引用规则的对象 || flushInterval | 定时自动清理缓存间隔 | 自动刷新时间,时间 ms,未配置时只有调用时刷新 || readOnly | 是否只读 | true:只读缓存,会给所有调用者返回缓存对象的相同实例.因此这些实例不能被修改,这提供了很重要的性能优势.false:读写缓存,会返回对象的拷贝(通过序列化),不会共享,这会慢一些,但是安全,因为默认为false.改为false读写的时候,对象必须支持序列化. || blocking | 是否使用可重入锁实现缓存的并发控制 | true,会使用BlockingCache对Cache进行装饰,默认为false | Mapper.xml 配置了之后,select()会被缓存.update(),delete()和insert()会刷新缓存. 思考:如果cacheEnable=true,Mapper.xml没有配置标签,还有二级缓存吗?还会出现CacheExecutor包装对象吗? 只要 cacheEnable=true 基本执行器就会被装饰.有没有配置,决定了在启动的时候会不会创建这个mapper对象的Cache对象,最终会影响到CachingExecutor query 方法的判断. if (cache != null) &amp;#123; 如果某些查询方法对数据的实时性要求很高,不需要二级缓存,怎么办? 我们可以在单个statement ID 上 显式关闭二级缓存(默认为true) &lt;select id=\"selectBlog\" resultMap=\"BaseResultMap\" useCache=\"false\"> 了解了二级缓存的工作位置和开启关闭的方式之后,我们来验证一下二级缓存. 二级缓存验证 验证二级缓存需要先开启二级缓存 事务不提交,二级缓存不存在BlogMapper mapper1 = session1.getMapper(BlogMapper.class); System.out.println(mapper1.selectBlogById(1)); // 事务不提交的情况下，二级缓存不会写入 // session1.commit(); BlogMapper mapper2 = session2.getMapper(BlogMapper.class); System.out.println(mapper2.selectBlogById(1)); 思考:为什么事务不提交,二级缓存不生效? 因为二级缓存使用transactionCacheManage(TCM) 来管理,最后又调用了TransactionCache的getObject(),putObject(),和commit()方法,TransactionCache里面又持有了真正的Cache对象,比如是经过层层包装的PerpetualCache对象 在putObject的时候,只是添加到了entriesToAddOnCommit里面,只有它的commit()方法被调用的时候才会调用flushPendingEntries()真正写入缓存,.它就是在DefaultSqlSession调用 commit()的时候被调用. 使用不同的session 和mapper,验证二级缓存可以跨session存在,取消以上 commit()注释 在其他的session中执行增删改查操作,验证缓存会被刷新Blog blog = new Blog(); blog.setBid(1); blog.setName(\"357\"); mapper3.updateByPrimaryKey(blog); session3.commit(); // 执行了更新操作，二级缓存失效，再次发送 SQL 查询 System.out.println(mapper2.selectBlogById(1)); 思考:为什么增删改操作会清空缓存? 在 CacheingExecutor的 update()方法里面调用 flushCacheIfRequired(ms),isFlushCacheRequired 就是从标签里面取到的 flushCache的值。而增删改操作的flushCache 属性默认为true 什么时候开启二级缓存 一级缓存默认是打开的,二级缓存需要配置才可以开启.那么我们必须思考一个问题,在什么情况下才有必要去开启二级缓存? 因为所有的增删改 都会刷新二级缓存,导致二级缓存失效,所有适合在查询喂猪的应用中使用,比如历史交易,历史订单等查询.否则缓存就失去了意义. 如果多个 namespace中有针对于同一个表的操作,比如Blog 表,如果在一个namespace 中刷新了缓存,另一个namespace 中没有刷新,就会出现脏数据的情况.所以,推荐在一个Mapper里面只操作单表的情况下使用. 思考:如果要让多个namespace 共享一个二级缓存,应该怎么做跨namespace 的缓存共享问题,可以使用来解决 &lt;cache-ref namespace=\"com.crud.dao.DepartmentMapper\" /> cache-ref 代表引用别的命名空间的Cache配置,两个命令空间的操作使用的是同一个Cache.在关联表比较少,或者按照业务可以对表进行分组的时候可以使用. 注意:在这种情况下,多个Mappper的操作都会引用缓存刷新,缓存的意思已经不大了. 第三方缓存做二级缓存除了Mybatis 自带的二级缓存之外,我们也可以通过实现Cache 接口来自定义二级缓存. Mybatis官方提供了一些第三方缓存集成方式,比如 ehcache和redis： https://github.com/mybatis/redis-cache pom文件中引入依赖 &lt;dependency> &lt;groupId>org.mybatis.caches&lt;/groupId> &lt;artifactId>mybatis-redis&lt;/artifactId> &lt;version>1.0.0-beta2&lt;/version> &lt;/dependency> Mapper.xml配置,type 使用RedisCache &lt;cache type=\"org.mybatis.caches.redis.RedisCache\" eviction=\"FIFO\" flushInterval=\"60000\" size=\"512\" readOnly=\"true\"/> redis.properties 配置 host=localhost port=6379 connectionTimeout=5000 soTimeout=5000 database=0 Mybatis 源码解读分析源码,我们从编程式的demo 入手 InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); BlogMapper mapper = session.getMapper(BlogMapper.class); Blog blog = mapper.selectBlogById(1); 把文件读取成流的这一步我们就省略了,接下来我们分成四步解析. 第一步,我们通过建造者模式创建一个工厂类,配置文件的解析就是在这一步完成的,包括mybatis-config.xml和Mapper 适配器文件 第二步,通过sqlSessionFactory创建SqlSession 第三步,获取一个Mapper对象 第四步,调用接口方法. 配置解析过程首先我们要清楚的是配置解析的过程全部直接洗了两种文件,一个是mybatis-config.xml全部配置文件,另外就是可能有很多个的Mapper.xml文件,也包括在Mapper接口类上定义的注解. 我们从mybatis-config.xml 开始,这里我们具体看一下这里面的标签都是怎么解析的,解析的时候都做了什么？ SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 首先 我们new了一个SqlSessionFactoryBuilder,非常明显的建造者模式,它里面定义了很多个build 方法的重载,最终返回的是一个SqlSessionFactory 对象(单例模式).我们点进去build 方法. 这里面创建了一个XMLConfigBuilder 对象(Configuration对象也是这个时候创建的). XMLConfigBuilderXMLConfigBuilder 是抽象类BaseBuilder 的一个子类,专门用来解析全局配置文件,针对不同的构建目标还有其他的一些子类,比如: XMLMapperBuider: 解析Mapper映射器 XMLStateementBuilder: 解析增删改查标签 根据我们解析的文件流,这里后面两个参数都是空的,创建了一个parser. 这里有两部,第一步是调用parser的parser()方法,它会返回一个Configuration 类. 之前我们说过,也就是配置文件里面所有的信息都会放在Configuration里面,Configuration 类里面有很多的属性,有很多是跟config里面的标签直接对应的. 我们先看一下parser()犯法: 首先会检查是不是已经解析过,也就是说在应用的生命周期里面, config配置文件只需要解析一次,生成的Configuration 对象也会存在应用的整个生命周期中,接下来就是parserConfiguration()方法: parseConfiguration(parser.evalNode(\"/configuration\")); 这下面有十几个方法,对应着config文件里面的所有一级标签. propertiesElement()第一个解析的是 标签,读取我们引入的外部配置文件.这里面又有两种类型,一种是放在resource目录下的,是相对路径,一种是写得绝对路径.解析的最终结果就是我们会把所有的配置信息方法名为defaults的Properties 对象里面,最后把XPathParser和Configuration 的Properties属性都设置为我们填充后的Properties对象. settingsAsProperties()第二个,我们把 标签也解析成了一个Properties 对象,对于标签的子标签处理在后面. 在早期的版本里面解析和设置都是在后面一起的,这里先解析成Properties 对象是因为后面的两个方法要用到. loadCustomVfs(settings)loadCustomVfs是 获取Vitual File System 的自定义实现类,比如我们要读取本地文件或者FTP远程文件 时候,就可以用到自定义的VFS类,我们根据 标签里面的 标签,生成了一个抽象类VFS的子类,并且赋值到Configuration 中. loadCustomLogImpl(settings)loadCustomLogImpl 是根据 标签获取日志的实现类,我们可以用到很多的日志的方案,包括LOG4J,Log4J2,slf4j等,这里生成了一个Log接口的实现类,并且赋值到Configuration中. typeAliasesElement()接下来,我们解析 标签,它有两种定义方法,一种是直接定义一个类的别名,一种就是指定一个包,那么这个package下的所有的类的名字都会成为这个类全路径的别名. 类的别名和类的关系,我们都放在一个TypeAliasRegistry 对象里面. pluginElement()接下来解析 标签,比如 PageHelper 的翻页插件,或者我们自定义的插件. 标签里面只有 标签,标签里面只有 标签. 标签解析完之后,会生成一个Interceptor 对象,并且添加到Configuration 的InterceptorChin属性里面,这是一个List objectFactoryElement()、objectWrapperFactoryElement()接下来的两个标签是用来实例化对象用的.和 这两个标签,分别生成 ObjectFactory和ObjectWrapperFactory 对象,同样设置到Configuration 的属性里面. reflectorFactoryElement()解析 reflectorFactory 标签,生成 ReflectorFactory对象 settingsElement(settings)这里就是对 标签里面所有子标签的处理了,前面我们已经把子标签全部转换成了Properties 对象，所以我们这里只处理Properties 对象就可以了. 二级标签里面有很多的配置,比如二级缓存,延迟加载,自动生成主键这些.需要注意的是,我们之前提到的所有的默认值,都是在这里赋值的. 所有的值,都会赋值到Configuration 的属性里面去. environmentsElement() 这一步是解析 标签. 我们之前讲过,一个environments 就是对应一个数据源,所以在这里会根据配置的 的创建一个事务工厂,根据 标签创建一个数据源,最后把这两个对象设置成 Environment 对象的属性,放到Configuration 里面. databaseIdProviderElement()解析 databaseIdProvider 标签,生成 DatabaseIdProvider对象(用来支持不同厂商的数据库) typeHandlerElement()跟TypeAlias 一样, typeHandler 有两种配置方式, 一种是单独配置一个类,一种是指定一个 package.我们最后得到的是 javaType和jdbcType,以及用来做相互映射的 TypeHandler之间的映射关系. 最后存放到TypeHandlerRegistry 对象里面. mapperElement()http://www.mybatis.org/mybatis-3/zh/configuration.html#mappers 1. 判断最后就是标签的解析| 扫描类型 | 含义 || ——– | ——– || resource | 相对路径 || url | 绝对路径 || package | 包 || class | 单个接口 | 首先会判断是不是接口,只有接口才会解析,然后判断是不是注册了,单个Mapper 重复注册就会抛出异常. 2. 注册XMLMapperBuilder.parser() 方法,是对Mapper 映射器的解析.里面有两个方法: configurationElement() – 解析所有的子标签,其中 buildStatementFromContext() 最终获得 MappedStatement 对象. bindMapperForNameSpace() – 把namespace(接口类型)和工厂类绑定起来 无论是按照 package 扫描还是按照接口扫描,租后都会调用到MapperRegistry 的addMapper() 方法. MapperRegistry 里面维护的其实是一个Map 容器,存储接口和代理工厂的映射关系. 3. 处理注解.除了映射文件,这里也会去解析Mapper接口方法的注解.在addMapper() 方法里面创建了一个MapperAnnotationBuilder ,我们点进去看一下parser()方法. parserCach()和parserCacgeRef()方法其实是对 @CacheNamespace和@CacheNamespaceRef 这两个注解的处理. parserStatement()方法里面的各种getAnnotation() 都是对注解的解析,比如@Options,@SelectKey,@ResultMap等等. 最后同样会解析成MappedStatement对象,也就是是说在XML中配置,和使用注解配置,最后起到一样的效果., 4. 收尾如果注解没有完成,还要从Map中remove掉 // MapperRegistry.java finally &amp;#123; if (!loadCompleted) &amp;#123; knownMappers.remove(type); &amp;#125; 最后,MapperRegistry 也会放到Configuration 中 第二步是调用另一个build() 方法,返回DefaultSqlSesionFactory. 总结在这一步,我们主要完成了 config 配置文件,Mapper文件,Mapper接口上的注解的解析. 我们得到了一个最重要的对象Configuration,这里面存放了全部的配置信息,它在属性里面还有各种各样的容器. 最后,返回了一个DefaultSqlSessionFactory ,里面持有了Configuratrion 的实例. 会话创建过程这是第二步,我们跟数据库的每一次链接,都需要创建一个会话,我们用openSession()方法来创建. DefaultSqlSessionFactory – openSessionFromDataSource() 这个会话里面，需要包含一个Executor 用来执行SQL.Executor 又要指定事务类型和执行器的类型。 所以我们会先从 Configuration 里面拿到Enviroment,Enviroment 里面就有事务工厂. 1. 创建Transaction 属性 产生工厂类 产生事务 JDBC JdbcTransactionFactory JdbcTransaction MANAGED ManagedTransactionFactory ManagedTransaction 如果配置的是JDBC，则会使用Connection对象的 commit().rollback(),close()管理事务. 如果配置成MANAGED,就会把事务交给容器来管理,比如JBOSS,Weblogic.以为我们跑的是本地程序,如果配置成MANAGED,不会有任务事务. 如果是Spring+Mybatis,则没有必要配置,因为我们会直接在applicationContext.xml 里面配置数据源和事务管理器,覆盖Mybatis的配置。 2. 创建Executor我们知道,Executor 的基本类型有三种,SIMPLE,BATCH,REUSE,默认是SIMPLE(settingsElement()读取默认值),他们都继承了抽象类BaseExecutor 为什么要让抽象类实现接口,然后让具体实现类继承抽象类(模板方法模式) “定义一个算法的骨架，并允许子类为一个或者多个步骤提供实现。 模板方法使得子类可以在不改变算法结构的情况下，重新定义算法的某些步骤。” 问题:三种类型的区别?(通过update 方法对比) SimpleExecutor：每执行一次 update或者 select,就开启一个Statement对象,用完立即关闭Statement ReuseExecutor: 执行update或者select,以sql作为key查找Statement对象,存在就使用,不存在就创建,用完之后,不关闭Statement对象,而是放置于Map中,供下一次使用.简言之,就是重复使用Statement BatchExecutor:执行update(没有select,批处理不支持select),将所有sql都添加到批处理中(addBatch(),等待统一执行(executeBatch()),它缓存了多个Statement对象,每个Statement对象都是addBatch()完毕后,等待逐一执行executeBatch()批处理,与JDBC批处理相同. 获得Mapper对象现在我们已经有了 DefaultSqlSession了,必须找到Mapper.xml里面定义的Statement ID,才能执行对应的SQL。 找到Statement ID 有两种方式:一种是直接调用session的方法,在参数中传入Statement ID,这种方式属于硬编码,我们没办法知道有多少地方调用,修改起来很麻烦. 另一个问题是如果参数传入错误,在编译阶段是不会报错的,不利于预先发现问题. Blog blog = (Blog) session.selectOne(\"com.gupaoedu.mapper.BlogMapper.selectBlogById \", 1); 所以在Mybatis后期的版本中提供了第二种方式,就是定义一个接口,然后再调用Mapper接口的方法. 由于我们的接口名称跟Mapper.xml的namespace是对应的,接口的方法跟statement ID 也是对应的,所以根据方法就能找到对应的SQL BlogMapper mapper = session.getMapper(BlogMapper.class); 在这里,我们主要研究一下Mapper 对象是怎么获得的,它的本质是什么? DefaultSqlSession的 getMapper()方法,调用Configuration 的getMapper()方法 configuration.&lt;T>getMapper() Configuration 的getMapper(),又调用了MapperRegistry的getMapper() 方法 mapperRegistry.getMapper() 我们知道,在解析mapper 标签和Mapper.xml 标签的时候已经把接口类型和类型对应的MapperProxyFactory 放到了Map中.获取Mapper代理对象,实际上是从Map中获取了对应的工厂类,调用以下方法创建对象 MapperProxyFactory.newInstance() 最后通过代理模式返回代理对象 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &amp;#123; mapperInterface &amp;#125;, mapperProxy); JDK动态代理和Mybatis使用的JDBC动态代理有什么区别? JDK动态代理 JDK动态代理在实现了 InvocationHandler的代理类里面,需要传入一个被代理对象的实现类. Mybatis 的动态代理 不需要实现类的原因:我们只需要根据接口类型+方法的名字,就可以找到Staement ID了,而唯一要做的一件事情也是这样的,所以不需要实现类,在MapperProxy 里面直接执行逻辑(也就是执行sql) 就可以了. 总结 获取Mapper对象的过程,实质上是获取了一个MapperProxy 对象,MapperProxy中有sqlSession,MapperInterface,methodCache. 4.执行SQLBlog blog = mapper.selectBlog(1); 由于所有的Mapper 都是MapperProxy 代理对象,所以任意的方法都是执行MapperProxy 的invoke()方法 我们看一下 invoke()方法 1. MapperProxy.invoke()方法 首先判断是否需要去执行SQL,还是直接执行方法Object 本身的方法和JAVA8 中接口的默认的方法是不需要去执行SQL的 获取缓存这里加入缓存是为了提升MapperMethod的获取速度 // 获取缓存，保存了方法签名和接口方法的关系 final MapperMethod mapperMethod = cachedMapperMethod(method); Map的 computeIfAbsent()方法:只有key不存在或者value为null的时候才调用 mapperFunction(). 2. MapperMethod.execute()接下来有调用了mapperMethod的execute方法 mapperMethod.execute(sqlSession, args); MapperMethod 里面主要有两个属性,一个是sqlCommand,一个是 MethodSignature, 这两个都是MapperMethod的内部类. 另外定义了多个execute()方法. 在这一步,根据不同的type 和返回类型: 调用 conbvertArgsToSqlCommandParam() 将参数换换为SQL的参数 调用sqlSession 的insert(),update(),delete(),selectOne() 方法,我们以查询为例,会走到selectOne() 方法. 3. DefaultSqlSession.selectOne()selectOne()方法最终也是调用了selectList() 方法. 在 sleectList() 中,我们根据 command name(Statement ID) 从Configuration 中拿到 MappedStatement ,这个 ms 上面有我们在xml 中配置的所有属性,包括id,statementType,sqlSource,usCache,入参,出参等等. 然后执行 Execute.query()方法. 前面我们说到了Executor 有三种基本类型, SIMPLE/REUSE/BATCH,还有一种包装类型CacheExecute,那么在这里会选择哪一种执行器呢? 我们要回过头看看DefaultSqlSession 在初始化的时候是怎么赋值的,这个就是我们的会话创建过程. 如果我们启动了二级缓存,就会先调用CacheExecute的query()方法,里面有缓存相关的操作,然后才是调用基本类型的执行器,比如默认的SimpleExecutor. 在没有开启二级缓存的情况下,先回走到BaseExecutor 的query()方法,(否则就会先走到CachingExecutor) 4. BaseExecutor.query() 创建CacheKey从Configuration 中获取MappedStatemet,然后从BoundSql 中获取SQL信息,创建CacheKey.这个CacheKey 就是缓存的key 然后在调用另一个query() 方法. 清空本地缓存 queryStack 用于记录查询栈,防止递归查询重复处理缓存。 flushCache=true 的时候,会先清理本地缓存(一级缓存):clearLocalCache(); 如果没有清理缓存,会从数据库查询:queryFromDatabase() 如果 LocalCacheScope== STATEMENT,会清理本地缓存。 从数据库查询。 缓存 先在缓存用占位符占位.执行查询后，移出占位符,放入数据 查询 执行Execitor的 doQuery();默认是 SimpleExecutor 5. SimpleExecutor.doQuery() 创建 StatementHandler在configuration.newStatementHandler() 中,new 一个StatementHandler ,先得到RoutingStatementHandler. RoutingStatementHandler 里面没有任何的实现,是用来创建基本的StatementHandler 的.这里会根据MappedStatement 里面的 statementType 决定了StatementHanlder 的类型,默认是 PREPARED(STATEMENT,PREPARD,CALLABLE) switch (ms.getStatementType()) &amp;#123; case STATEMENT: delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case PREPARED: delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case CALLABLE: delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; default: throw new ExecutorException(\"Unknown statement type: \" + ms.getStatementType()); &amp;#125; StatementHandler 里面包含了处理参数的 ParameterHandler 和处理结果集的 ResultSetHandler 这两个对象都是上面new的时候创建的 this.parameterHandler = configuration.newParameterHandler(mappedStatement, parameterObject, boundSql); this.resultSetHandler = configuration.newResultSetHandler(executor, mappedStatement, rowBounds, parameterHandler, resultHandler, boundSql); 这三个对象都是可以被插件拦截的四大对象之一,所以在创建之后都要用拦截器进行包装的方法. statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); 创建Statement用new 出来的StatementHandler 创建Statement 对象 –prepareStatement() 方法对语句进行预编译,处理参数 handler.para,terize(stmt) 执行的 StatementHandler的 query()方法 RoutingStatementHandler 的query() 方法. delegate委派,最终执行PreparedStatementHandler的query() 方法. 执行 PreparedStatement的execute() 方法后面的JDBC 包中的PreparedStatement的执行了 ResultSetHandler 处理结果集 return resultSetHandler.handleResultSets(ps); 附时序图01-SQLSessionFactory.02-DefaultSqlSession.03-getMapper04-MapperProxy Mybatis 核心对象 对象 相关对象 作用 Configuration MapperRegistry TypeAliasRegistry TypeHandlerRegistry 包含了Mybatis的所有的配置信息 SqlSession SqlSessionFactory DefaultSqlSession 对数据库的增删改查的操作进行了封装,提供给应用层使用. Executor BaseExecutorSimpleExecutorBatchExecutorReuseExecutor Mybatis 执行器,是Mybatis调度的核心,负责SQL语句的生成和查询缓存的维护. StatementHandler BaseStatementHandlerSimpleStatementHandlerPrepardStatementHandler CallableStatementHandler PreameterHandler DefaultParmeterHandler 把用户传递的参数转换给JDBC Statement 所需的参数 ResultSetHandler DefaultResultHandler 把JDBC 返回的ResultSet 结果集对象转换为List 类型的集合 MapperProxy MapperProxyFactory 代理对象,用于代理Mapper 接口方法. MappedStatement sqlSource BoundSql MappedStatement 维护了 一条&lt;select","categories":[{"name":"mybatis","slug":"mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/"},{"name":"mybatis","slug":"mybatis/mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/mybatis/"}],"tags":[]},{"title":"maven 配置参数详解","slug":"maven/maven 配置参数详解","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/maven/maven-pei-zhi-can-shu-xiang-jie/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/maven/maven-pei-zhi-can-shu-xiang-jie/","excerpt":"","text":"&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd \"> &lt;!-- 父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。 --> &lt;parent> &lt;!-- 被继承的父项目的构件标识符 --> &lt;artifactId /> &lt;!-- 被继承的父项目的全球唯一标识符 --> &lt;groupId /> &lt;!-- 被继承的父项目的版本 --> &lt;version /> &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 --> &lt;relativePath /> &lt;/parent> &lt;!-- 声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。 --> &lt;modelVersion> 4.0.0 &lt;/modelVersion> &lt;!-- 项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app --> &lt;groupId> asia.banseon &lt;/groupId> &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源码，二进制发布和WARs等。 --> &lt;artifactId> banseon-maven2 &lt;/artifactId> &lt;!-- 项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型 --> &lt;packaging> jar &lt;/packaging> &lt;!-- 项目当前版本，格式为:主版本.次版本.增量版本-限定版本号 --> &lt;version> 1.0-SNAPSHOT &lt;/version> &lt;!-- 项目的名称, Maven产生的文档用 --> &lt;name> banseon-maven &lt;/name> &lt;!-- 项目主页的URL, Maven产生的文档用 --> &lt;url> http://www.baidu.com/banseon &lt;/url> &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。 --> &lt;description> A maven project to study maven. &lt;/description> &lt;!-- 描述了这个项目构建环境中的前提条件。 --> &lt;prerequisites> &lt;!-- 构建该项目或使用该插件所需要的Maven的最低版本 --> &lt;maven /> &lt;/prerequisites> &lt;!-- 项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira --> &lt;issueManagement> &lt;!-- 问题管理系统（例如jira）的名字， --> &lt;system> jira &lt;/system> &lt;!-- 该项目使用的问题管理系统的URL --> &lt;url> http://jira.baidu.com/banseon &lt;/url> &lt;/issueManagement> &lt;!-- 项目持续集成信息 --> &lt;ciManagement> &lt;!-- 持续集成系统的名字，例如continuum --> &lt;system /> &lt;!-- 该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。 --> &lt;url /> &lt;!-- 构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） --> &lt;notifiers> &lt;!-- 配置一种方式，当构建中断时，以该方式通知用户/开发者 --> &lt;notifier> &lt;!-- 传送通知的途径 --> &lt;type /> &lt;!-- 发生错误时是否通知 --> &lt;sendOnError /> &lt;!-- 构建失败时是否通知 --> &lt;sendOnFailure /> &lt;!-- 构建成功时是否通知 --> &lt;sendOnSuccess /> &lt;!-- 发生警告时是否通知 --> &lt;sendOnWarning /> &lt;!-- 不赞成使用。通知发送到哪里 --> &lt;address /> &lt;!-- 扩展配置项 --> &lt;configuration /> &lt;/notifier> &lt;/notifiers> &lt;/ciManagement> &lt;!-- 项目创建年份，4位数字。当产生版权信息时需要使用这个值。 --> &lt;inceptionYear /> &lt;!-- 项目相关邮件列表信息 --> &lt;mailingLists> &lt;!-- 该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。 --> &lt;mailingList> &lt;!-- 邮件的名称 --> &lt;name> Demo &lt;/name> &lt;!-- 发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --> &lt;post> banseon@126.com &lt;/post> &lt;!-- 订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --> &lt;subscribe> banseon@126.com &lt;/subscribe> &lt;!-- 取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --> &lt;unsubscribe> banseon@126.com &lt;/unsubscribe> &lt;!-- 你可以浏览邮件信息的URL --> &lt;archive> http:/hi.baidu.com/banseon/demo/dev/ &lt;/archive> &lt;/mailingList> &lt;/mailingLists> &lt;!-- 项目开发者列表 --> &lt;developers> &lt;!-- 某个项目开发者的信息 --> &lt;developer> &lt;!-- SCM里项目开发者的唯一标识符 --> &lt;id> HELLO WORLD &lt;/id> &lt;!-- 项目开发者的全名 --> &lt;name> banseon &lt;/name> &lt;!-- 项目开发者的email --> &lt;email> banseon@126.com &lt;/email> &lt;!-- 项目开发者的主页的URL --> &lt;url /> &lt;!-- 项目开发者在项目中扮演的角色，角色元素描述了各种角色 --> &lt;roles> &lt;role> Project Manager &lt;/role> &lt;role> Architect &lt;/role> &lt;/roles> &lt;!-- 项目开发者所属组织 --> &lt;organization> demo &lt;/organization> &lt;!-- 项目开发者所属组织的URL --> &lt;organizationUrl> http://hi.baidu.com/banseon &lt;/organizationUrl> &lt;!-- 项目开发者属性，如即时消息如何处理等 --> &lt;properties> &lt;dept> No &lt;/dept> &lt;/properties> &lt;!-- 项目开发者所在时区， -11到12范围内的整数。 --> &lt;timezone> -5 &lt;/timezone> &lt;/developer> &lt;/developers> &lt;!-- 项目的其他贡献者列表 --> &lt;contributors> &lt;!-- 项目的其他贡献者。参见developers/developer元素 --> &lt;contributor> &lt;name /> &lt;email /> &lt;url /> &lt;organization /> &lt;organizationUrl /> &lt;roles /> &lt;timezone /> &lt;properties /> &lt;/contributor> &lt;/contributors> &lt;!-- 该元素描述了项目所有License列表。 应该只列出该项目的license列表 ，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。 --> &lt;licenses> &lt;!-- 描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。 --> &lt;license> &lt;!-- license用于法律上的名称 --> &lt;name> Apache 2 &lt;/name> &lt;!-- 官方的license正文页面的URL --> &lt;url> http://www.baidu.com/banseon/LICENSE-2.0.txt &lt;/url> &lt;!-- 项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖 --> &lt;distribution> repo &lt;/distribution> &lt;!-- 关于license的补充信息 --> &lt;comments> A business-friendly OSS license &lt;/comments> &lt;/license> &lt;/licenses> &lt;!-- SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。 --> &lt;scm> &lt;!-- SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。 --> &lt;connection> scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection> &lt;!-- 给开发者使用的，类似connection元素。即该连接不仅仅只读 --> &lt;developerConnection> scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection> &lt;!-- 当前代码的标签，在开发阶段默认为HEAD --> &lt;tag /> &lt;!-- 指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。 --> &lt;url> http://svn.baidu.com/banseon &lt;/url> &lt;/scm> &lt;!-- 描述项目所属组织的各种属性。Maven产生的文档用 --> &lt;organization> &lt;!-- 组织的全名 --> &lt;name> demo &lt;/name> &lt;!-- 组织主页的URL --> &lt;url> http://www.baidu.com/banseon &lt;/url> &lt;/organization> &lt;!-- 构建项目需要的信息 --> &lt;build> &lt;!-- 该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --> &lt;sourceDirectory /> &lt;!-- 该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。 --> &lt;scriptSourceDirectory /> &lt;!-- 该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --> &lt;testSourceDirectory /> &lt;!-- 被编译过的应用程序class文件存放的目录。 --> &lt;outputDirectory /> &lt;!-- 被编译过的测试class文件存放的目录。 --> &lt;testOutputDirectory /> &lt;!-- 使用来自该项目的一系列构建扩展 --> &lt;extensions> &lt;!-- 描述使用到的构建扩展。 --> &lt;extension> &lt;!-- 构建扩展的groupId --> &lt;groupId /> &lt;!-- 构建扩展的artifactId --> &lt;artifactId /> &lt;!-- 构建扩展的版本 --> &lt;version /> &lt;/extension> &lt;/extensions> &lt;!-- 当项目没有规定目标（Maven2 叫做阶段）时的默认值 --> &lt;defaultGoal /> &lt;!-- 这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。 --> &lt;resources> &lt;!-- 这个元素描述了项目相关或测试相关的所有资源路径 --> &lt;resource> &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&amp;#123;project.build.outputDirectory&amp;#125;）。举个例子，如果你想资源在特定的包里(org.apache.maven.messages)， 你就必须该元素设置为org/apache/maven/messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。 --> &lt;targetPath /> &lt;!-- 是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。 --> &lt;filtering /> &lt;!-- 描述存放资源的目录，该路径相对POM路径 --> &lt;directory /> &lt;!-- 包含的模式列表，例如**/*.xml. --> &lt;includes /> &lt;!-- 排除的模式列表，例如**/*.xml --> &lt;excludes /> &lt;/resource> &lt;/resources> &lt;!-- 这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。 --> &lt;testResources> &lt;!-- 这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明 --> &lt;testResource> &lt;targetPath /> &lt;filtering /> &lt;directory /> &lt;includes /> &lt;excludes /> &lt;/testResource> &lt;/testResources> &lt;!-- 构建产生的所有文件存放的目录 --> &lt;directory /> &lt;!-- 产生的构件的文件名，默认值是$&amp;#123;artifactId&amp;#125;-$&amp;#123;version&amp;#125;。 --> &lt;finalName /> &lt;!-- 当filtering开关打开时，使用到的过滤器属性文件列表 --> &lt;filters /> &lt;!-- 子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置 --> &lt;pluginManagement> &lt;!-- 使用的插件列表 。 --> &lt;plugins> &lt;!-- plugin元素包含描述插件所需要的信息。 --> &lt;plugin> &lt;!-- 插件在仓库里的group ID --> &lt;groupId /> &lt;!-- 插件在仓库里的artifact ID --> &lt;artifactId /> &lt;!-- 被使用的插件的版本（或版本范围） --> &lt;version /> &lt;!-- 是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。 --> &lt;extensions /> &lt;!-- 在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。 --> &lt;executions> &lt;!-- execution元素包含了插件执行需要的信息 --> &lt;execution> &lt;!-- 执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标 --> &lt;id /> &lt;!-- 绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段 --> &lt;phase /> &lt;!-- 配置的执行目标 --> &lt;goals /> &lt;!-- 配置是否被传播到子POM --> &lt;inherited /> &lt;!-- 作为DOM对象的配置 --> &lt;configuration /> &lt;/execution> &lt;/executions> &lt;!-- 项目引入插件所需要的额外依赖 --> &lt;dependencies> &lt;!-- 参见dependencies/dependency元素 --> &lt;dependency> &lt;/dependency> &lt;/dependencies> &lt;!-- 任何配置是否被传播到子项目 --> &lt;inherited /> &lt;!-- 作为DOM对象的配置 --> &lt;configuration /> &lt;/plugin> &lt;/plugins> &lt;/pluginManagement> &lt;!-- 使用的插件列表 --> &lt;plugins> &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --> &lt;plugin> &lt;groupId /> &lt;artifactId /> &lt;version /> &lt;extensions /> &lt;executions> &lt;execution> &lt;id /> &lt;phase /> &lt;goals /> &lt;inherited /> &lt;configuration /> &lt;/execution> &lt;/executions> &lt;dependencies> &lt;!-- 参见dependencies/dependency元素 --> &lt;dependency> &lt;/dependency> &lt;/dependencies> &lt;goals /> &lt;inherited /> &lt;configuration /> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;!-- 在列的项目构建profile，如果被激活，会修改构建处理 --> &lt;profiles> &lt;!-- 根据环境参数或命令行参数激活某个构建处理 --> &lt;profile> &lt;!-- 构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。 --> &lt;id /> &lt;!-- 自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。 --> &lt;activation> &lt;!-- profile默认是否激活的标志 --> &lt;activeByDefault /> &lt;!-- 当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --> &lt;jdk /> &lt;!-- 当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --> &lt;os> &lt;!-- 激活profile的操作系统的名字 --> &lt;name> Windows XP &lt;/name> &lt;!-- 激活profile的操作系统所属家族(如 'windows') --> &lt;family> Windows &lt;/family> &lt;!-- 激活profile的操作系统体系结构 --> &lt;arch> x86 &lt;/arch> &lt;!-- 激活profile的操作系统版本 --> &lt;version> 5.1.2600 &lt;/version> &lt;/os> &lt;!-- 如果Maven检测到某一个属性（其值可以在POM中通过$&amp;#123;名称&amp;#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --> &lt;property> &lt;!-- 激活profile的属性的名称 --> &lt;name> mavenVersion &lt;/name> &lt;!-- 激活profile的属性的值 --> &lt;value> 2.0.3 &lt;/value> &lt;/property> &lt;!-- 提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --> &lt;file> &lt;!-- 如果指定的文件存在，则激活profile。 --> &lt;exists> /usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ &lt;/exists> &lt;!-- 如果指定的文件不存在，则激活profile。 --> &lt;missing> /usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ &lt;/missing> &lt;/file> &lt;/activation> &lt;!-- 构建项目所需要的信息。参见build元素 --> &lt;build> &lt;defaultGoal /> &lt;resources> &lt;resource> &lt;targetPath /> &lt;filtering /> &lt;directory /> &lt;includes /> &lt;excludes /> &lt;/resource> &lt;/resources> &lt;testResources> &lt;testResource> &lt;targetPath /> &lt;filtering /> &lt;directory /> &lt;includes /> &lt;excludes /> &lt;/testResource> &lt;/testResources> &lt;directory /> &lt;finalName /> &lt;filters /> &lt;pluginManagement> &lt;plugins> &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --> &lt;plugin> &lt;groupId /> &lt;artifactId /> &lt;version /> &lt;extensions /> &lt;executions> &lt;execution> &lt;id /> &lt;phase /> &lt;goals /> &lt;inherited /> &lt;configuration /> &lt;/execution> &lt;/executions> &lt;dependencies> &lt;!-- 参见dependencies/dependency元素 --> &lt;dependency> &lt;/dependency> &lt;/dependencies> &lt;goals /> &lt;inherited /> &lt;configuration /> &lt;/plugin> &lt;/plugins> &lt;/pluginManagement> &lt;plugins> &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --> &lt;plugin> &lt;groupId /> &lt;artifactId /> &lt;version /> &lt;extensions /> &lt;executions> &lt;execution> &lt;id /> &lt;phase /> &lt;goals /> &lt;inherited /> &lt;configuration /> &lt;/execution> &lt;/executions> &lt;dependencies> &lt;!-- 参见dependencies/dependency元素 --> &lt;dependency> &lt;/dependency> &lt;/dependencies> &lt;goals /> &lt;inherited /> &lt;configuration /> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --> &lt;modules /> &lt;!-- 发现依赖和扩展的远程仓库列表。 --> &lt;repositories> &lt;!-- 参见repositories/repository元素 --> &lt;repository> &lt;releases> &lt;enabled /> &lt;updatePolicy /> &lt;checksumPolicy /> &lt;/releases> &lt;snapshots> &lt;enabled /> &lt;updatePolicy /> &lt;checksumPolicy /> &lt;/snapshots> &lt;id /> &lt;name /> &lt;url /> &lt;layout /> &lt;/repository> &lt;/repositories> &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --> &lt;pluginRepositories> &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --> &lt;pluginRepository> &lt;releases> &lt;enabled /> &lt;updatePolicy /> &lt;checksumPolicy /> &lt;/releases> &lt;snapshots> &lt;enabled /> &lt;updatePolicy /> &lt;checksumPolicy /> &lt;/snapshots> &lt;id /> &lt;name /> &lt;url /> &lt;layout /> &lt;/pluginRepository> &lt;/pluginRepositories> &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --> &lt;dependencies> &lt;!-- 参见dependencies/dependency元素 --> &lt;dependency> &lt;/dependency> &lt;/dependencies> &lt;!-- 不赞成使用. 现在Maven忽略该元素. --> &lt;reports /> &lt;!-- 该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素 --> &lt;reporting> &lt;/reporting> &lt;!-- 参见dependencyManagement元素 --> &lt;dependencyManagement> &lt;dependencies> &lt;!-- 参见dependencies/dependency元素 --> &lt;dependency> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;!-- 参见distributionManagement元素 --> &lt;distributionManagement> &lt;/distributionManagement> &lt;!-- 参见properties元素 --> &lt;properties /> &lt;/profile> &lt;/profiles> &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --> &lt;modules /> &lt;!-- 发现依赖和扩展的远程仓库列表。 --> &lt;repositories> &lt;!-- 包含需要连接到远程仓库的信息 --> &lt;repository> &lt;!-- 如何处理远程仓库里发布版本的下载 --> &lt;releases> &lt;!-- true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --> &lt;enabled /> &lt;!-- 该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。 这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --> &lt;updatePolicy /> &lt;!-- 当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。 --> &lt;checksumPolicy /> &lt;/releases> &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置， POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如， 可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --> &lt;snapshots> &lt;enabled /> &lt;updatePolicy /> &lt;checksumPolicy /> &lt;/snapshots> &lt;!-- 远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库 --> &lt;id> banseon-repository-proxy &lt;/id> &lt;!-- 远程仓库名称 --> &lt;name> banseon-repository-proxy &lt;/name> &lt;!-- 远程仓库URL，按protocol://hostname/path形式 --> &lt;url> http://192.168.1.169:9999/repository/ &lt;/url> &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局； 然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --> &lt;layout> default &lt;/layout> &lt;/repository> &lt;/repositories> &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --> &lt;pluginRepositories> &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --> &lt;pluginRepository> &lt;/pluginRepository> &lt;/pluginRepositories> &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --> &lt;dependencies> &lt;dependency> &lt;!-- 依赖的group ID --> &lt;groupId> org.apache.maven &lt;/groupId> &lt;!-- 依赖的artifact ID --> &lt;artifactId> maven-artifact &lt;/artifactId> &lt;!-- 依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。 --> &lt;version> 3.8.1 &lt;/version> &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应，尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true， 就可以在plugin里定义新的类型。所以前面的类型的例子不完整。 --> &lt;type> jar &lt;/type> &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成JAR， 一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。 --> &lt;classifier>&lt;/classifier> &lt;!-- 依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用 --> &lt;scope> test &lt;/scope> &lt;!-- 仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。 需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&amp;#123;java.home&amp;#125;。 --> &lt;systemPath>&lt;/systemPath> &lt;!-- 当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题 --> &lt;exclusions> &lt;exclusion> &lt;artifactId> spring-core &lt;/artifactId> &lt;groupId> org.springframework &lt;/groupId> &lt;/exclusion> &lt;/exclusions> &lt;!-- 可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。 --> &lt;optional> true &lt;/optional> &lt;/dependency> &lt;/dependencies> &lt;!-- 不赞成使用. 现在Maven忽略该元素. --> &lt;reports>&lt;/reports> &lt;!-- 该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 --> &lt;reporting> &lt;!-- true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。 --> &lt;excludeDefaults /> &lt;!-- 所有产生的报表存放到哪里。默认值是$&amp;#123;project.build.directory&amp;#125;/site。 --> &lt;outputDirectory /> &lt;!-- 使用的报表插件和他们的配置。 --> &lt;plugins> &lt;!-- plugin元素包含描述报表插件需要的信息 --> &lt;plugin> &lt;!-- 报表插件在仓库里的group ID --> &lt;groupId /> &lt;!-- 报表插件在仓库里的artifact ID --> &lt;artifactId /> &lt;!-- 被使用的报表插件的版本（或版本范围） --> &lt;version /> &lt;!-- 任何配置是否被传播到子项目 --> &lt;inherited /> &lt;!-- 报表插件的配置 --> &lt;configuration /> &lt;!-- 一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标 --> &lt;reportSets> &lt;!-- 表示报表的一个集合，以及产生该集合的配置 --> &lt;reportSet> &lt;!-- 报表集合的唯一标识符，POM继承时用到 --> &lt;id /> &lt;!-- 产生报表集合时，被使用的报表的配置 --> &lt;configuration /> &lt;!-- 配置是否被继承到子POMs --> &lt;inherited /> &lt;!-- 这个集合里使用到哪些报表 --> &lt;reports /> &lt;/reportSet> &lt;/reportSets> &lt;/plugin> &lt;/plugins> &lt;/reporting> &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID匹配到这里的依赖，并使用这里的依赖信息。 --> &lt;dependencyManagement> &lt;dependencies> &lt;!-- 参见dependencies/dependency元素 --> &lt;dependency> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;!-- 项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。 --> &lt;distributionManagement> &lt;!-- 部署项目产生的构件到远程仓库需要的信息 --> &lt;repository> &lt;!-- 是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素 --> &lt;uniqueVersion /> &lt;id> banseon-maven2 &lt;/id> &lt;name> banseon maven2 &lt;/name> &lt;url> file://$&amp;#123;basedir&amp;#125;/target/deploy &lt;/url> &lt;layout /> &lt;/repository> &lt;!-- 构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --> &lt;snapshotRepository> &lt;uniqueVersion /> &lt;id> banseon-maven2 &lt;/id> &lt;name> Banseon-maven2 Snapshot Repository &lt;/name> &lt;url> scp://svn.baidu.com/banseon:/usr/local/maven-snapshot &lt;/url> &lt;layout /> &lt;/snapshotRepository> &lt;!-- 部署项目的网站需要的信息 --> &lt;site> &lt;!-- 部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置 --> &lt;id> banseon-site &lt;/id> &lt;!-- 部署位置的名称 --> &lt;name> business api website &lt;/name> &lt;!-- 部署位置的URL，按protocol://hostname/path形式 --> &lt;url> scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url> &lt;/site> &lt;!-- 项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。 --> &lt;downloadUrl /> &lt;!-- 如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。 --> &lt;relocation> &lt;!-- 构件新的group ID --> &lt;groupId /> &lt;!-- 构件新的artifact ID --> &lt;artifactId /> &lt;!-- 构件新的版本号 --> &lt;version /> &lt;!-- 显示给用户的，关于移动的额外信息，例如原因。 --> &lt;message /> &lt;/relocation> &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部署），verified（被核实时正确的和最终的）。 --> &lt;status /> &lt;/distributionManagement> &lt;!-- 以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明） 。格式是&lt;name>value&lt;/name>。 --> &lt;properties /> &lt;/project>","categories":[{"name":"maven","slug":"maven","permalink":"https://rainsoil.github.io/categories/maven/"},{"name":"maven","slug":"maven/maven","permalink":"https://rainsoil.github.io/categories/maven/maven/"}],"tags":[]},{"title":"linux 命令大全","slug":"linux/linux 命令大全","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/linux/linux-ming-ling-da-quan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/linux/linux-ming-ling-da-quan/","excerpt":"","text":"[TOC] 1. 查看 HTTP 链接情况netstat -n | awk &#39;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#39; 2. 查看当前IP个数和每IP连接数netstat -an | grep 80 | awk &#39;&#123;print $5&#125;&#39; | awk &#39;BEGIN &#123;FS=&quot;:&quot;&#125; NF==2 &#123;print $1&#125; NF==5 &#123;print $4&#125;&#39; | sort | uniq -c | sort -n 3. iptables 开放端口3.1. 关闭firewall： systemctl stop firewalld.service 3.2. 停止firewall systemctl disable firewalld.service 3.3. 安装安装iptables防火墙 yum install iptables-services 3.4.升级 yum update iptables --允许关联的状态包通过 iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 3.5. 开放特定的端口，以80为例 iptables -A INPUT -p tcp –dport 80 -j ACCEP 3.6. 重启 systemctl restart iptables.service 3.7. 保存配置 service iptables save 3.8. 设置开机自启动 systemctl enable iptables.service 4. 列出相关目录下的所有目录和文件 ls [选项名] [目录名] -a 列出包括.a开头的隐藏文件的所有文件 -A 通 -a,但是不列出 &quot;.&quot;和&quot;..&quot; -l 列出文件的详细信息 -c 根据ctime 排序显示 -t 根据文件修改时间排序 -r 反序排列 -S 以文件大小排序 -h 以异度大小显示 ---color[=WHEN] 用色彩辨别文件类型, WHEN 可以是&#39;never&#39;,&#39;always&#39;或&#39;auto&#39; 其中之一 白色:表示普通文件 蓝色:表示目录 绿色:表示可执行文件 红色:表示压缩文件 浅蓝色:链接文件 红色闪烁:表示链接的文件有问题 黄色:表示设备文件 灰色:表示其他文件 例子 # 按易读的方式按时间排序,并显示文件详细信息 ls -lhrt # 按照大小 反序显示文件的详细信息 ls -lrS # 列出文件绝对路径（不包含隐藏文件） ls | sed &quot;s:^:`pwd`/:&quot; # 列出文件绝对路径（包含隐藏文件） find $pwd -maxdepth 1 | xargs ls -ld 5. 移动或重命名文件 mv [选项] 源文件或目录 目录或多个源文件 -b 覆盖前做备份 -f 如存在不询问而强制覆盖 -i 如存在则询问是否覆盖 -u 较新才覆盖 -t 将多个源文件移动到统一目录下,目录参数在前,文件参数在后 eg: mv a /tmp/ 将文件a 移动到 /tmp 目录下 mv a b 将a 命令为b mv /home/zenghao test1.txt test2.txt test3.txt 6. 将源文件复制至目标文件,或将多个源文件复制至目标目录 cp [选项] 源文件或目录 目录或多个源文件 -r -R 递归复制该目录以及子目录内容 -p 连同档案属性一起复制过去 -f 不询问而强制复制 -s 生成快捷方式 -a 将档案的所有特性都一起复制 7. 在linux 服务器之间复制文件和目录 scp [参数] [原路径] [目标路径] -v 详细显示输入的具体情况 -r 递归复制整个目录 (1) 复制文件： 命令格式： scp local_file remote_username@remote_ip:remote_folder 或者 scp local_file remote_username@remote_ip:remote_file 或者 scp local_file remote_ip:remote_folder 或者 scp local_file remote_ip:remote_file 第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名 第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名 (2) 复制目录： 命令格式： scp -r local_folder remote_username@remote_ip:remote_folder 或者 scp -r local_folder remote_ip:remote_folder 第1个指定了用户名，命令执行后需要输入用户密码； 第2个没有指定用户名，命令执行后需要输入用户名和密码； eg: 从 本地 复制到 远程 scp /home/daisy/full.tar.gz root@172.19.2.75:/home/root 从 远程 复制到 本地 scp root@/172.19.2.75:/home/root/full.tar.gz /home/daisy/full.tar.gz 8. 删除文件 rm [选项] 文件 -r 删除文件夹 -f 删除不提示 -i 删除提示 -v 详细显示进行步骤 9. 创建空的文件或更新文件时间 touch [选项] 文件 -a 只修改存取时间 -m 只修改变动时间 -r eg:touch -r a b ,使b的时间和a相同 -t 指定特定的时间 eg:touch -t 201211142234.50 log.log -t time [[CC]YY]MMDDhhmm[.SS],C:年前两位 10.查看当前所在的路径 pwd 例子 # 查看软链接的实际路径 pwd -p 11. 改变当前目录 cd - ：返回上次目录 .. :返回上层目录 回车 ：返回主目录 / :根目录 12. 创建新目录 mkdir [选项] 目录 -p 递归创建目录,若父目录不存在则以此创建 -m 自定义创建目录的权限 eg: mkdir -m 777 hehe -v 显示创建目录的详细信息 13. 删除空的目录 rmdir -v 显示执行过程 -p 自父目录删除,若父目录为空,则一并删除 14. 删除一个或多个文件或目录 rm [选项] 文件 -f 忽略不存在的文件,不给出提示 -i 交互式删除 -r 将列出的目录以及子目录递归删除 -v 列出详细的信息 15 . 显示内容 echo -n 输出后不换行 -e 遇到转义字符特殊处理 16. 一次显示整个文件或从键盘创建一个文件或将几个文件合并成一个文件 cat [选项 文件 -n 编号文件内容再输出 -E 在结束行提示$ cat &gt; fileanme #创建一个文件 cat file1 file2 &gt; file # 将几个文件合并为一个文件 17. 反向显示 tac 18. 按页查看文章内容,从前向后读取文件,因此在启动的时候就加载整个文件 more +n 从第n行开始显示 -n 每次查看n行数据 +/string 搜寻string字符串位置,从其前两行开始查看 -c 清屏再显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 常用操作命令 Enter 向下 n 行，需要定义。默认为 1 行 Ctrl+F 向下滚动一屏 空格键 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 :f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调用Shell，并执行命令 q 退出more 19. 可前后移动的逐屏查看文章内容,在查看钱不会加载整个文件 less -m 显示类似于more命令的百分比 -N 显示行号 / 字符串:向下搜索&quot;字符串&quot;的功能 ? 字符串:向上搜索&quot;字符串&quot;的功能 n 重复前一个搜索(与/或?有关) b 向后翻一页 d 向后翻半夜 常用命令 -i 忽略搜索时的大小写 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -s 显示连续空行为一行 /字符串：向下搜索“字符串”的功能 ?字符串：向上搜索“字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） -x &lt;数字&gt; 将“tab”键显示为规定的数字空格 b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 20. 将输出内容自动加上行号 nl [选项] …[文件]… -b -b a 不论是否有空格,都列出行号 (类似 cat -n) -b t 空格则不列行号(默认) -n 有ln,rn,rz 三个参数,分别为在最左方显示,最右方显示不加0,最右方显示加0 21. 显示档案开头,默认显示10行 head [参数]…[文件]… -v 显示文件名 -c number 显示前number个字符,若number 为负数,则显示除最后number个字符的所有内容 -number/n (+)number 显示前number 行内容 -n number 若number为负数,则显示除最后number行数据的所有内容 22. 显示文件结尾内容 tail [必要参数] [选择参数] -v 显示详细的处理信息 -q 不显示处理信息 -num/-n (-)num 显示最后num 行内容 -c 显示最后c个字符 -f 循环读取 23. 编辑文件 vi :w filename 将文章以指定的文件名保存起来 :wq 保存并退出 :q! 不保存而强制退出 :set number 或者 :set nu 显示行号 :set nonumber 或者 :set nonu 隐藏行号 命令行模式功能键 1）插入模式 按「i」切换进入插入模式「insert mode」，按&quot;i&quot;进入插入模式后是从光标当前位置开始输入文件； 按「a」进入插入模式后，是从目前光标所在位置的下一个位置开始输入文字； 按「o」进入插入模式后，是插入新的一行，从行首开始输入文字。 2）从插入模式切换为命令行模式 按「ESC」键。 3）移动光标 vi可以直接用键盘上的光标来上下左右移动，但正规的vi是用小写英文字母「h」、「j」、「k」、「l」，分别控制光标左、下、上、右移一格。 按「ctrl」+「b」：屏幕往&quot;后&quot;移动一页。 按「ctrl」+「f」：屏幕往&quot;前&quot;移动一页。 按「ctrl」+「u」：屏幕往&quot;后&quot;移动半页。 按「ctrl」+「d」：屏幕往&quot;前&quot;移动半页。 按数字「0」：移到文章的开头。 按「G」：移动到文章的最后。 按「$」：移动到光标所在行的&quot;行尾&quot;。 按「^」：移动到光标所在行的&quot;行首&quot; 按「w」：光标跳到下个字的开头 按「e」：光标跳到下个字的字尾 按「b」：光标回到上个字的开头 按「#l」：光标移到该行的第#个位置，如：5l,56l。 4）删除文字 「x」：每按一次，删除光标所在位置的&quot;后面&quot;一个字符。 「#x」：例如，「6x」表示删除光标所在位置的&quot;后面&quot;6个字符。 「X」：大写的X，每按一次，删除光标所在位置的&quot;前面&quot;一个字符。 「#X」：例如，「20X」表示删除光标所在位置的&quot;前面&quot;20个字符。 「dd」：删除光标所在行。 「#dd」：从光标所在行开始删除#行 5）复制 「yw」：将光标所在之处到字尾的字符复制到缓冲区中。 「#yw」：复制#个字到缓冲区 「yy」：复制光标所在行到缓冲区。 「#yy」：例如，「6yy」表示拷贝从光标所在的该行&quot;往下数&quot;6行文字。 「p」：将缓冲区内的字符贴到光标所在位置。注意：所有与&quot;y&quot;有关的复制命令都必须与&quot;p&quot;配合才能完成复制与粘贴功能。 6）替换 「r」：替换光标所在处的字符。 「R」：替换光标所到之处的字符，直到按下「ESC」键为止。 7）回复上一次操作 「u」：如果您误执行一个命令，可以马上按下「u」，回到上一个操作。按多次&quot;u&quot;可以执行多次回复。 8）更改 「cw」：更改光标所在处的字到字尾处 「c#w」：例如，「c3w」表示更改3个字 9）跳至指定的行 「ctrl」+「g」列出光标所在行的行号。 「#G」：例如，「15G」，表示移动光标至文章的第15行行首。 24. 查看可执行文件的位置,在PATH变量指定的路径中查看系统命令是否存在及其位置 which 25. 定位可执行文件,源代码文件,帮助文件在文件系统中的位置 whereis [-bmsu] [BMS 目录名 -f] 文件名 -b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件,源代码文件,帮助文件以外的其他文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件文件的路径 -S 指定搜索源文件的路径 26. 通过搜寻数据库快速搜寻档案 locate -r 使用正则运算式做寻找的条件 27. 在文件树中查找文件,并作出相应的处理 find [PATH] [option] [action] 选项与参数： 1. 与时间有关的选项：共有 -atime, -ctime 与 -mtime 和-amin,-cmin与-mmin，以 -mtime 说明 -mtime n ：n 为数字，意义为在 n 天之前的『一天之内』被更动过内容的档案； -mtime +n ：列出在 n 天之前(不含 n 天本身)被更动过内容的档案档名； -mtime -n ：列出在 n 天之内(含 n 天本身)被更动过内容的档案档名。 -newer file ：file 为一个存在的档案，列出比 file 还要新的档案档名 2. 与使用者或组名有关的参数： -uid n ：n 为数字，这个数字是用户的账号 ID，亦即 UID -gid n ：n 为数字，这个数字是组名的 ID，亦即 GID -user name ：name 为使用者账号名称！例如 dmtsai -group name：name 为组名，例如 users ； -nouser ：寻找档案的拥有者不存在 /etc/passwd 的人！ -nogroup ：寻找档案的拥有群组不存在于 /etc/group 的档案！ 3. 与档案权限及名称有关的参数： -name filename：搜寻文件名为 filename 的档案（可使用通配符） -size [+-]SIZE：搜寻比 SIZE 还要大(+)或小(-)的档案。这个 SIZE 的规格有： c: 代表 byte k: 代表 1024bytes。所以，要找比 50KB还要大的档案，就是『 -size +50k 』 -type TYPE ：搜寻档案的类型为 TYPE 的，类型主要有： 一般正规档案 (f) 装置档案 (b, c) 目录 (d) 连结档 (l) socket (s) FIFO (p) -perm mode ：搜寻档案权限『刚好等于』 mode的档案，这个mode为类似chmod的属性值，举例来说，-rwsr-xr-x 的属性为4755！ -perm -mode ：搜寻档案权限『必须要全部囊括 mode 的权限』的档案，举例来说， 我们要搜寻-rwxr--r-- 亦即 0744 的档案，使用-perm -0744，当一个档案的权限为 -rwsr-xr-x ，亦即 4755 时，也会被列出来，因为 -rwsr-xr-x 的属性已经囊括了 -rwxr--r-- 的属性了。 -perm +mode ：搜寻档案权限『包含任一 mode 的权限』的档案，举例来 说，我们搜寻-rwxr-xr-x ，亦即 -perm +755 时，但一个文件属性为 -rw-------也会被列出来，因为他有 -rw.... 的属性存在！ 4. 额外可进行的动作： -exec command ：command 为其他指令，-exec 后面可再接额外的指令来处理搜寻到的结果。 -print ：将结果打印到屏幕上，这个动作是预设动作！ eg: find / -perm +7000 -exec ls -l &#123;&#125; ; ,额外指令以-exec开头，以;结尾&#123;&#125;代替前面找到的内容 | xargs -i 默认的前面输出用&#123;&#125;代替 eg: find . -name &quot;*.log&quot; | xargs -i mv &#123;&#125; test4 28.用正则表达式搜索文本,并把匹配的行打印出来 grep “正则表达式” 文件名 -c 只输出匹配行的计数 -I 不区分大小写 -l 只显示文件名 -v 显示不包含匹配文本的所有行 -n 显示匹配数据以及行数 29.判断文件类型 file 30. 压缩,解压缩 gzip [选项] 文件/文件夹 -a：使用ASCII文字模式； -d：解开压缩文件； -f：强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接； -h：在线帮助； -l：列出压缩文件的相关信息； -L：显示版本与版权信息； -n：压缩文件时，不保存原来的文件名称及时间戳记； -N：压缩文件时，保存原来的文件名称及时间戳记； -q：不显示警告信息； -r：递归处理，将指定目录下的所有文件及子目录一并处理； -S或&lt;压缩字尾字符串&gt;或----suffix&lt;压缩字尾字符串&gt;：更改压缩字尾字符串； -t：测试压缩文件是否正确无误； -v：显示指令执行过程； -V：显示版本信息； -&lt;压缩效率&gt;：压缩效率是一个介于1~9的数值，预设值为“6”，指定愈大的数值，压缩效率就会愈高； --best：此参数的效果和指定“-9”参数相同； --fast：此参数的效果和指定“-1”参数相同 31. 多个目录或文件打包,压缩成一个大文件 tar [主选项+辅选项] 文件或目录 主选项： -c 建立打包档案，可搭配 -v 来察看过程中被打包的档名(filename) -t 察看打包档案的内容含有哪些档名，重点在察看『档名』就是了； -x 解打包或解压缩的功能，可以搭配 -C (大写) 在特定目录解开 辅选项： -j 透过 bzip2 的支持进行压缩/解压缩：此时档名最好为 *.tar.bz2 -z 透过 gzip 的支持进行压缩/解压缩：此时档名最好为 *.tar.gz -v 在压缩/解压缩的过程中，将正在处理的文件名显示出来！ -f filename -f 后面要立刻接要被处理的档名！ -C 目录 这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 --exclude FILE：在压缩打包过程中忽略某文件 eg: tar --exclude /home/zenghao -zcvf myfile.tar.gz /home/* /etc -p 保留备份数据的原本权限与属性，常用于备份(-c)重要的配置文件 -P(大写） 保留绝对路径，亦即允许备份数据中含有根目录存在之意； eg: 压 缩：tar -jcvf filename.tar.bz2 要被压缩的档案或目录名称 查 询：tar -jtvf filename.tar.bz2 解压缩：tar -jxvf filename.tar.bz2 -C 欲解压缩的目录 32. 关机 shutdown -n now 33. 显示当前登录的用户 users 34. 登录在本机的用户与来源 who -H 或 --heading 显示和栏位的标题信息列 35.给当前联机的用户发消息 wirite 36. 查看用户的登陆日志 last 37. 查看每个用户的最后登录时间lastlog 38.查看用户信息 finger [选项][使用者] [用户@主机] -a 显示用户的注册名,实际姓名,终端名称,写状态,停滞时间,登录时间等信息 -l 除了用-s 选项显示的信息外,还显示用户主目录,登录shell,邮件状态等信息,以及用户主目录下的.plan,.project和.forward 文件的内容 -p 除了不显示.plan文件和.project 文件之外,与-l 选项相同 39. 查看主机名 hostname 40. 别名 alias ii = “ls -l” 添加别名 unalias ii 清除别名 41. 新增用户.useradd [-u UID] [-g 初始群组] [-G 次要群组] [-c 说明栏] [-d 家目录绝对路径] [-s shell] 使用者账号名 -M 不建立用户目录, -m 建立用户目录 -r 建立一个系统的账号,这个账号的UID会有限制 -e 账号失效日期,格式为[YYYY-MM=DD] -D 查看useradd 的各项默认值 42. 密码 passwd -l 密码失效 -u 与-l 相对,用户解锁 -S 列出登录用户passwd文件的相关参数 -n 后面接天数，shadow 的第 4 字段，多久不可修改密码天数 -x 后面接天数，shadow 的第 5 字段，多久内必须要更动密码 -w 后面接天数，shadow 的第 6 字段，密码过期前的警告天数 -i 后面接『日期』，shadow 的第 7 字段，密码失效日期 使用管道刘设置密码：echo &quot;zeng&quot; | passwd --stdin zenghao 43. 删除用户 userde -r 用户文件一并删除 44. 修改用户密码的相关属性 chage [-ldEImMW] 账号名 -l 列出该账号的详细密码参数； -d 后面接日期，修改 shadow 第三字段(最近一次更改密码的日期)，格式YYYY-MM-DD -E 后面接日期，修改 shadow 第八字段(账号失效日)，格式 YYYY-MM-DD -I 后面接天数，修改 shadow 第七字段(密码失效日期) -m 后面接天数，修改 shadow 第四字段(密码最短保留天数) -M 后面接天数，修改 shadow 第五字段(密码多久需要进行变更) -W 后面接天数，修改 shadow 第六字段(密码过期前警告日期) 45. 修改用户的相关属性 usermod [-cdegGlsuLU] username -c 后面接账号的说明，即 /etc/passwd 第五栏的说明栏，可以加入一些账号的说明。 -d 后面接账号的家目录，即修改 /etc/passwd 的第六栏； -e 后面接日期，格式是 YYYY-MM-DD 也就是在 /etc/shadow 内的第八个字段数据啦！ -f 后面接天数为 shadow 的第七字段。 -g 后面接初始群组，修改 /etc/passwd 的第四个字段，亦即是GID的字段！ -G 后面接次要群组，修改这个使用者能够支持的群组 -l 后面接账号名称。亦即是修改账号名称， /etc/passwd 的第一栏！ -s 后面接 Shell 的实际档案，例如 /bin/bash 或 /bin/csh 等等。 -u 后面接 UID 数字啦！即 /etc/passwd 第三栏的资料； -L 冻结密码 -U 解冻密码 46. 查看用户相关的id信息，还可以用来判断用户是否存在 id [username] 47. 查看登陆用户支持的群组， 第一个输出的群组为有效群组 groups 48. 切换有效群组 newgrp 49. 添加组 groupadd [-g gid] 组名 -g 设定添加组的特定组的id 50. 修改组信息 groupmod [-g gid] [-n group_name] 群组名 -g 修改既有的 GID 数字 -n 修改既有的组名 51. 删除群组 groupdel [groupname] 52.群组管理员 gpasswd root管理员动作： -gpasswd groupname 设定密码 -gpasswd [-A user1,...] [-M user3,...] groupname -A 将 groupname 的主控权交由后面的使用者管理(该群组的管理员) -M 将某些账号加入这个群组当中 -gpasswd [-r] groupname -r 将 groupname 的密码移除 群组管理员动作： - gpasswd [-ad] user groupname -a 将某位使用者加入到 groupname 这个群组当中 -d 将某位使用者移除出 groupname 这个群组当中 53. 修改个人信息 chfn 54.分割 cut -b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域。 55.排序 sort -n 依照数值的大小排序。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k 选择以哪个区间进行排序。 56. 统计指定文件中的字节数、字数、行数, 并将统计结果显示输出 wc -l filename 报告行数 -c filename 报告字节数 -m filename 报告字符数 -w filename 报告单词数 57. 去除文件中相邻的重复行 uniq -c或——count：在每列旁边显示该行重复出现的次数； -d或--repeated：仅显示重复出现的行列； -f&lt;栏位&gt;或--skip-fields=&lt;栏位&gt;：忽略比较指定的栏位； -s&lt;字符位置&gt;或--skip-chars=&lt;字符位置&gt;：忽略比较指定的字符； -u或——unique：仅显示出一次的行列； -w&lt;字符位置&gt;或--check-chars=&lt;字符位置&gt;：指定要比较的字符。 58. 显示指定磁盘文件的可用空间,如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示功能是为文件在另外一个位置建立一个同步的链接，当在不同目录需要该问题时，就不需要为每一个目录创建同样的文件，通过 ln 创建的链接（link）减少磁盘占用量。 链接分类：软件链接及硬链接 软链接 硬链接 硬链接，以文件副本的形式存在。但不占用实际空间。 不允许给目录创建硬链接 硬链接只有在同一个文件系统中才能创建 软链接 软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式 软链接可以 跨文件系统 ，硬链接不可以 软链接可以对一个不存在的文件名进行链接 软链接可以对目录进行链接 du -a 显示全部文件系统 -h 文件大小友好显示 -l 只显示本地文件系统 -i 显示inode信息 -T 显示文件系统类型 例子 # 给文件创建软链接,并显示操作信息 ln -sv source.log link.log # 给文件创建硬链接,并显示操作信息 ln -v source.log link1.log # 给目录创建软链接 ln -sv /opt/soft/test/test3 /opt/soft/test/test5 59.显示每个文件和目录的磁盘使用空间 du [选项][文件] -h 方便阅读的方式 -s 只显示总和的大小 60. 某一个文件在另外一个位置建立一个同步的链接 ln [参数] [源文件或目录] [目标文件或目录] -s 建立软连接 -v 显示详细的处理过程 61. 比较单个文件或者目录内容 diff [参数] [文件1或目录1] [文件2或目录2] -b 不检查空格字符的不同。 -B 不检查空白行。 -i 不检查大小写 -q 仅显示差异而不显示详细信息 eg: diff a b &gt; parch.log 比较两个文件的不同并产生补丁 62. 显示或设定系统的日期与时间 date [参数]… [+格式] %H 小时(以00-23来表示)。 %M 分钟(以00-59来表示)。 %P AM或PM。 %D 日期(含年月日) %U 该年中的周数。 date -s “2015-10-17 01:01:01″ //时间设定 date +%Y%m%d //显示前天年月日 date +%Y%m%d --date=&quot;+1 day/month/year&quot; //显示前一天/月/年的日期 date +%Y%m%d --date=&quot;-1 day/month/year&quot; //显示后一天/月/年的日期 date -d &#39;2 weeks&#39; 2周后的日期 63. 查看日历 cal [参数] 月份] [年份] -1 显示当月的月历 -3 显示前、当、后一个月的日历 -m 显示星期一为一个星期的第一天 -s （默认）星期天为第一天 -j 显示当月是一年中的第几天的日历 -y 显示当前年份的日历 64. 列出当前进程的快照 ps a 显示所有的进程 -a 显示同一终端下的所有程序 e 显示环境变量 f 显示进程间的关系 -H 显示树状结构 r 显示当前终端的程序 T 显示当前终端的所有程序 -au 显示更详细的信息 -aux 显示所有包含其他使用者的行程 -u 指定用户的所有进程 65. 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 top 66. 杀死进程kill [参数] [进程号] 67. 显示linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的bufferfree [参数] 68. 对操作系统的虚拟内存、进程、CPU活动进行监控 vmstat 69. 对系统的磁盘操作活动进行监视,汇报磁盘活动统计情况，同时也会汇报出CPU使用情况 iostat [参数] [时间t] [次数n](每隔t时间刷新一次，最多刷新n次） -p[磁盘] 显示磁盘和分区的情况 70. 重复执行某一命令以观察变化 watch [参数] [命令] -n 时隔多少秒刷新 -d 高亮显示动态变化 71. 在一个指定的时间执行一个指定任务，只能执行一次 at [参数] [时间] HH:MM[am|pm] + number [minutes|hours|days|weeks] 强制在某年某月某日的某时刻进行该项任务 atq 查看系统未执行的任务 atrm n 删除编号为n的任务 at -c n 显示编号为n的任务的内容 72. 定时任务调度 crontab file 载入crontab -e 编辑某个用户的crontab文件内容 -l 显示某个用户的crontab文件内容 -r 删除某个用户的crontab文件 73. 查看和配置网络设备 ifconfig [网络设备] [参数] 74. 显示和操作IP路由表 route 75. 测试与目标主机的连通性 ping [参数] [主机名或IP地址] -q 只显示最后的结果 76. 显示与IP、TCP、UDP和ICMP协议相关的统计数据 netstat 77. 用于远程登录，采用明文传送报文，安全性不好telnet [参数] [主机] 78. 远程文件拷贝 rcp [参数] [源文件] [目标文件] -r 递归复制 -p 保留源文件的属性 usage: rcp –r remote_hostname:remote_dir local_dir 79. 直接从网络上下载文件 wget [参数] [URL地址] -o FILE 把记录写到FILE文件中 eg : wget -O a.txt URL wget --limit-rate=300k URL 限速下载 80. 对数据行进行替换、删除、新增、选取等操作 sed a 新增，在新的下一行出现 c 取代，取代 n1,n2 之间的行 eg: sed &#39;1,2c Hi&#39; ab d 删除 i 插入，在新的上一行出现 81. 合并文件，需确保合并的两文件行数相同 paste -d 指定不同于空格或tab键的域分隔符 -s 按行合并，单独一个文件为一行 82 授予用户文件夹权 chown chown -R 用户名 文件夹 83 df 命令 显示磁盘空间的使用情况 ``` -a 全部文件系统列表 -h 以方便阅读的方式显示信息 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地磁盘 -T 列出文件系统类型 ``` #### 84. 用命令行运行deb安装包 ``` 如果ubuntu要安装新软件，已有deb安装包（例如：iptux.deb），但是无法登录到桌面环境。那该怎么安装？答案是：使用dpkg命令。 dpkg命令常用格式如下： sudo dpkg -I iptux.deb #查看iptux.deb软件包的详细信息，包括软件名称、版本以及大小等（其中-I等价于--info） sudo dpkg -c iptux.deb #查看iptux.deb软件包中包含的文件结构（其中-c等价于--contents） sudo dpkg -i iptux.deb #安装iptux.deb软件包（其中-i等价于--install） sudo dpkg -l iptux #查看iptux软件包的信息（软件名称可通过dpkg -I命令查看，其中-l等价于--list） sudo dpkg -L iptux #查看iptux软件包安装的所有文件（软件名称可通过dpkg -I命令查看，其中-L等价于--listfiles） sudo dpkg -s iptux #查看iptux软件包的详细信息（软件名称可通过dpkg -I命令查看，其中-s等价于--status） sudo dpkg -r iptux #卸载iptux软件包（软件名称可通过dpkg -I命令查看，其中-r等价于--remove） 注：dpkg命令无法自动解决依赖关系。如果安装的deb包存在依赖包，则应避免使用此命令，或者按照依赖关系顺序安装依赖包。 ``` ##### 85. Ubuntu 18.04修改默认源为国内源 修改阿里源为Ubuntu 18.04默认的源 备份/etc/apt/sources.list #备份 cp /etc/apt/sources.list /etc/apt/sources.list.bak 在/etc/apt/sources.list文件前面添加如下条目 #添加阿里源 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 最后执行如下命令更新源 ##更新 sudo apt-get update sudo apt-get upgrade 另外其他几个国内源如下： 中科大源 ##中科大源 deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse 163源 ##163源 deb http://mirrors.163.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ bionic-backports main restricted universe multiverse 清华源 ##清华源 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse 86 修改用户为sudo 免密码1. 编辑 sudo vi /etc/sudoers 2. 找到%sudo ALL=(ALL:ALL) ALL ，在下边添加类似的一行 luyanan ALL = NOPASSWD: ALL 87 查看进程ps -ef|grep java、tomcat、maven、nginx 88. 查看运行端口号netstat -tunlp|grep java、nginx 89. 全局搜索find / -name &#39;文件名&#39; 90 防火墙 iptable修改防火墙开放端口vim /etc/sysconfig/iptables 重启防火墙systemctl restart iptables.service","categories":[{"name":"linux","slug":"linux","permalink":"https://rainsoil.github.io/categories/linux/"},{"name":"linux","slug":"linux/linux","permalink":"https://rainsoil.github.io/categories/linux/linux/"}],"tags":[]},{"title":"Mybatis与Spring整合分析(4)","slug":"mybatis/Mybatis与Spring整合分析(4)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mybatis/mybatis-yu-spring-zheng-he-fen-xi-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mybatis/mybatis-yu-spring-zheng-he-fen-xi-4/","excerpt":"","text":"4. Mybatis于Spring 整合分析 与 Spring 整合分析http://www.mybatis.org/spring/zh/index.html这里我们以传统的Spring为例,因为配置更加直观,在Spring中使用配置注册是一样的. 在前面,我们基于编程式的工程已经弄清楚了Mybatis的工作流程,核心模块和底层原理。编程式的工作,也就是Mybatis的原声API 里面有三个核心对象: SqlSessionFacyory,SqlSession,MapperProxy. 大部分我们不会在项目中单独使用Mybatis的工程,而是继承到Spring、中使用,但是却没有看到这三个对象在代理中出现.我们都是直接注入了一个Mapper接口,调用它的方法. 所以有几个关键的对象,我们要弄清楚: SqlSessionFactory 是什么时候创建的? SqlSession 去哪里了?为什么不用他来getMapper ？ 为什么@Autowired 注入一个接口,在使用的时候却变成了代理对象?在IOC 的容器中我们注入的是什么?注入的时候发生了什么事情?关键配置 我们先看一下把Mybatis集成到Spring 要做的几件事情。 为了让大家看起来更加直观,我们使用传统的XML 配置给大家做讲解,当然使用配置类@Configuration 效果是一样的,对于Spring来说只是解析的方式的差异. 除了Mybatis的依赖之外,我们还需要在pom.xml 里面加入Mybatis和Spring整合的jar(注意版本:mybatis 的版本和 mybatis-spring 的版本有兼容关系) &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis-spring&lt;/artifactId> &lt;version>2.0.0&lt;/version> &lt;/dependency> 然后在Spring的ApplicationContext.xml里面配置SqlSessionFactoryBean,它是用来帮助我们创建会话的,其中还要指定全局配置文件和Mapper映射器文件的路径. &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"> &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\">&lt;/property> &lt;property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\">&lt;/property> &lt;property name=\"dataSource\" ref=\"dataSource\"/> &lt;/bean> 然后在appcalitionContext.xml 配置需要扫描Mapper接口的路径 在Mybatis中有几种配置方式.一种是配置一个MapperScannerConfigurer &lt;bean id=\"mapperScanner\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"> &lt;property name=\"basePackage\" value=\"com.crud.dao\"/> &lt;/bean> 另一种是配置一个标签 &lt;mybatis-spring:scan base-package=\"com.crud.dao\"/> 还有一种是直接用@MapperScan 注解,比如我们在Spring Boot的主启动类上 添加上一个注解 @SpringBootApplication @MapperScan(\"com.crud.dao\") public class MybaitsApp &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(MybaitsApp.class, args); &amp;#125; &amp;#125; 这三种方式的实现效果是一样的. 1. 创建会话工厂Spring对Mybatis的对象进行了管理,但是并不会直接替换Mybatis的核心对象,也就是意味着: Mybatis包里的 SqlSessionFactory,SqlSession,MapperProxy 这些都会用到,而mybatis-spring.jar 里面的类只是做了一些包装和桥梁的工作. 所以 第一步,我们看一下在Spring中,工厂类是怎么创建的? 我们在Spring的配置文件里面配置了一个SqlSessionFactoryBean,我们来看一下这个类 它实现了InitialzingBean接口,所以要实现afterPropertiesSet() 方法,这个方法会在Bean属性值设置完成 的时候调用. 另外它实现了FactoryBean 接口,所以它初始化的时候,实际上是调用getObject() 方法,它里面调用的也是afterPropertiesSet() 方法. 在afterPropertiesSet() 方法里面 第一步是一些标签属性的检查,接下来是调用 buildSqlSessionFactory() 方法. 然后定义了一个Configuration, 叫做targetConfiguration 426行,判断Configuration 对象是否存在,也就是是否已经解析过,如果已经有对象,那就覆盖一下属性. 433行,如果Configuration 不存在,但是配置了 configLocation属性,就会根据mybatis-config.xml 的文件路径,构建一个xmlConfiuration对象. 436行,否则,Configuration 对象不存在,configLocation 路径也没有,只能使用默认的属性去构建给configurationProperties 赋值. 后面就是基于当前factory 对象里面的已有的属性,对targetConfiguration 对象里面的属性赋值. Optional.ofNullable(this.objectFactory).ifPresent(targetConfiguration::setObjectFactory); 这个方法是JAVA8里面判空的方法,如果不为空的话,就会调用对象里面的对象的方法,做赋值的处理。 在498行,如果xmlConfigurationBuilder 不为空,也就是上面的第二种情况了,调用了xmlConfigurationBuilder.parse()去解析配置文件,最终会返回解析好的Configuration 对象. 在第507行,如果没有明确的指定事务工厂,默认使用SpringManagedTransactionFactory,它创建的SpringManagedTransaction 也有getConnection 和close 方法. &lt;property name=\"transactionFactory\" value=\"\" /> 在502行,调用 xmlMapperBuilder.parse(),这个步骤我们之前了解过,它的作用的把接口和对用的MapperProxyFactory 注册到MapperRegistry 中. 最后调用的是sqlSessionFactoryBuilder.build() 返回了一个 DefaultSqlSessionFactory. OK.我们在这里完成了编程式的案例中的第一步,根据配置文件获取工厂类,它是单例的,会在后来用来创建SqlSession 用到的Spring 扩展点总结 接口 方法 作用 FactoryBean getObject() 返回由FactoryBean创建的Bean实例 InitializingBean afterPropertiesSet() bean 属性初始化完成后添加操作 BeanDefinitionRegistryPostProicessor postProcessBeanDefinitionRegistry() 注入BeanFinition时添加操作. 2. 创建SqlSessionQ1: 可以直接使用DefaultSqlSession吗？ 我们现在已经有了一个DefaultSqpSessionFactory,按照编程式的开发过程,我们接下来就会创建一个SqlSession的实现类,但是在Spring中,我们不是直接使用DefaultSqlSession的,而是对她进行了一个封装,这个SqlSession的实现类就是SqlSessionTemplate.这个跟spring封装其他的组件也是一样的.比如jdbcTemplate,RedisTemplate等等,也是Spring跟Mybatis最关键的类. 为什么不用DefaultSqlSession? 它是线程不安全的,注意查看类的注解? Note that this class is not Thread-Safe. 而 SqlSessionTemplate 而SqlSessionTemplate 是线程安全的. * Thread safe, Spring managed, &#123;@code SqlSession&#125; that works with Spring 回顾一下SqlSession的生命周期 对象 生命周期 SqlSessionFactoryBuilder 方法局部(method) SqlSessionFactory(单例) 应用级别(application) SqlSession 请求和操作(request/method) Mapper 方法(method) 在编程式开发中,SqlSession在每次请求的时候创建一个,但是Spring里面只有一个SqlSessionTenplate(默认是单例),多个线程同时调用的时候是怎么保证线程安全的？ 思考: 为什么SqlSessionTemplate 是线程安全的? 思考:在编程式开发中,有什么方式可以保证SqlSession的线程安全? SqlSessionTemplate 里面有DefaultSqlSession的所有方法: selectOne(),selectList(),insert(),update(),delete(),不过它都是通过一个代理对象实现的,这个代理对象在构造方法里面通过一个代理类创建. this.sqlSessionProxy = (SqlSession) newProxyInstance( SqlSessionFactory.class.getClassLoader(), new Class[] &amp;#123; SqlSession.class &amp;#125;, new SqlSessionInterceptor()); 所有的方法都会先走到内部类SqlSessionTenplate 的invoke() 方法. public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; SqlSession sqlSession = getSqlSession( SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &amp;#123; Object result = method.invoke(sqlSession, args); 首先会使用工厂类,执行器类型,异常解析器创建一个SqlSession,然后调用SqlSession的实现类,实际上就是在这里调用了DefaultSqlSession的方法. Q2:怎么拿到一个SqlSessionTenplate? 我们直到在Spring中会使用SqlSessionTemplate 替换DefaultSqlSession.那么接下来看一下怎么在DAO层拿到一个SqlSessionTemplate 不知道用过Hibernate 的同学还记不记得?如果不使用注入的方式,我们在DAO层注入一个HibernateTemplate的一种方法是什么? – 让我们DAO的实现类去继承HibernateDaoSupport Mybatis 也一样,它提供了一个SqlSessionSupport,里面持有了一个SqlSessionSupport,里面持有了一个SqlSessionTemplate 对象,并且提供了一个getSqlSession() 方法,让我们获取一个SqlSessionTemplate public abstract class SqlSessionDaoSupport extends DaoSupport &amp;#123; private SqlSessionTemplate sqlSessionTemplate; public SqlSession getSqlSession() &amp;#123; return this.sqlSessionTemplate; &amp;#125; 前面和后面省略………… 也就是说让我们的DAO 层的实现去继承SqlSessionDaoSupport, 就可以获得SqlSessionTemplate,然后在里面封装SqlSessionTemplate 方法. 当然,为了减少重复的代码,我们通常不会让我们的实现类去直接继承SqlSessionDaoSupport, 而是先创建一个BaseDao 去继承SqlSessionDaoSupport, 在BaseDao 里面封装对数据库的操作,包括 selectOne(),selectList(),insert(),update(),delete()等这些方法,子类就可以直接调用. public class BaseDao extends SqlSessionDaoSupport &amp;#123; //使用 sqlSessionFactory @Autowired private SqlSessionFactory sqlSessionFactory; @Autowired public void setSqlSessionFactory(SqlSessionFactory sqlSessionFactory) &amp;#123; super.setSqlSessionFactory(sqlSessionFactory); &amp;#125; public Object selectOne(String statement, Object parameter) &amp;#123; return getSqlSession().selectOne(statement, parameter); &amp;#125; 后面省略………… 然后让我们的实现类去继承BaseDao,并且实现我们的Dao接口,这里就是我们 Mapper接口，实现类上需要加上@Repositor注解 在实现类的方法里面,我们可以直接调用父类(BaseDao)封装的selectOne() 方法,那么它最终会调用 sqlSessionTemplate的 selectOne() 方法. @Repository public class EmployeeDaoImpl extends BaseDao implements EmployeeMapper &amp;#123; @Override public Employee selectByPrimaryKey(Integer empId) &amp;#123; Employee emp = (Employee) this.selectOne(\"com.crud.dao.EmployeeMapper.selectByPrimaryKey\",empId); return emp; &amp;#125; 后面省略………… 然后在需要的地方,比如service层,注入我们的实现类,调用实现类的方法就行了, @Autowired EmployeeDaoImpl employeeDao; @Test public void EmployeeDaoSupportTest() &amp;#123; System.out.println(employeeDao.selectByPrimaryKey(1)); &amp;#125; 最终会调用到DefaultSqlSession 的方法 Q3: 有没有更好的拿到SqlSessionTemplate 的方法?这么做有一个问题,我们的每一个DAO 层的接口,如果要拿到一个SqlSesionTemplate 去操作数据库,都要创建实现一个实现类,加上@Repository 注解,j继承BaseDao 这个工作量也不小. 另外一个,我们去直接调用selectOne 方法,还是出现了Statement ID的硬编码,MapperProxy 我们这里根本没用上. 我们可以通过什么方式,不创建任何的实现类,就可以Mapper注入到别的地方使用,并且可以拿到SqlSessionTemplate 操作数据库. 这样也确实我们在Spring中的用法. 那么我们就需要弄清楚,我们只是注入了一个接口,在对象实例化的时候,是怎么拿到SqlSessionTemplate的? 当我们调用方法的时候,还是不是用的MapperProxy ？ 3. 接口扫描注册在Service层可以使用@Autowired 自动注入的Mapper接口,需要保存到BeanFactory (比如XmlWebApplicationContext) 中,也就是说接口肯定在Spring启动的时候被扫描注册过了. 什么时候扫描的? 注册的时候,注册的是什么?这个决定了我们拿到的是什么实际对象?回顾一下,我们在 applicationContext.xml 里面配置了一个MapperScannerConfigurer. MapperScannerConfigurer 实现了BeanDefinitionRegistryPostProcesser 接口,BeanDefinitionRegistryProcessor是BeanFactoryPostProcessor的子类,可以通过编码的方式修改,新增或者删除某些bean的定义。 我们只需要重写postProcessBeanDefinitionRegistry 方法,在这里面操作Bean就可以了. 在这个方法中,scanner.scan() 方法是ClassPathBeanDefinitionScanner中的,而它的子类ClassPathMapperScanner 覆盖了doScan() 方法,而在doScan() 方法中调用了 processBeanDefinitions: public Set&lt;BeanDefinitionHolder> doScan(String... basePackages) &amp;#123; Set&lt;BeanDefinitionHolder> beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) &amp;#123; LOGGER.warn(() -> \"No MyBatis mapper was found in '\" + Arrays.toString(basePackages) + \"' package. Please check your configuration.\"); &amp;#125; else &amp;#123; processBeanDefinitions(beanDefinitions); &amp;#125; return beanDefinitions; &amp;#125; 它先调用父类的soScan() 扫描所有的接口。 processBeanDefinitions 方法里面,在注册beanDefinitions 的时候,BeanClass被改为MapperFactoryBean private void processBeanDefinitions(Set&lt;BeanDefinitionHolder> beanDefinitions) &amp;#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &amp;#123; definition = (GenericBeanDefinition) holder.getBeanDefinition(); String beanClassName = definition.getBeanClassName(); LOGGER.debug(() -> \"Creating MapperFactoryBean with name '\" + holder.getBeanName() + \"' and '\" + beanClassName + \"' mapperInterface\"); // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); // issue #59 definition.setBeanClass(this.mapperFactoryBean.getClass()); 问题: 为什么要把BeanClass 修改成MapperFactoryBean,这个类有什么用？ MapperFactoryBean 继承了SqlSessionDaoSupport,可以拿到sqlSessionTemplate 4. 接口注入使用我们使用Mapper 的时候,只需要在加了service 注解的类里面使用@Autowired 注入Mapper接口就可以了. @Service public class EmployeeService &amp;#123; @Autowired EmployeeMapper employeeMapper; public List&lt;Employee> getAll() &amp;#123; return employeeMapper.selectByMap(null); &amp;#125; &amp;#125; Spring在启动的时候需要取实例化EmployeeService EmployeeService 依赖了EmployeeMapper 接口(是EmployeeService 的一个属性) Spring会根据Mapper的名字从BeanFactory 中获取它的BeanDefinition ,再从BeanDefinition 中获取BeanClass,EmployeeMapper 对应的BeanClass 是MapperFactoryBean. 接下来就是创建MapperFactoryBean,因为实现了FactoryBean 接口,同样是调用getObject() 方法 // MapperFactoryBean.java public T getObject() throws Exception &amp;#123; return getSqlSession().getMapper(this.mapperInterface); &amp;#125; 因为MapperFactoryBean 继承了SqlSessionDaoSupport,所以这个 getSqlSession() 方法是调用父类的方法,返回SqlSessionTemplate // SqlSessionDaoSupport.java public SqlSession getSqlSession() &amp;#123; return this.sqlSessionTemplate; &amp;#125; 第二步, SqlSessionTemplate 的getMapper() 方法,里面又有两个方法。 // SqlSessionTemplate.java public &lt;T> T getMapper(Class&lt;T> type) &amp;#123; return getConfiguration().getMapper(type, this); &amp;#125; 第一步: SqlSessionoTemplate的 getConfiguration() 方法 // SqlSessionTemplate.java public Configuration getConfiguration() &amp;#123; return this.sqlSessionFactory.getConfiguration(); &amp;#125; 进入方法,通过 DefaultSqlSessionFactory ,返回全部配置Configuration // DefaultSqlSessionFactory.java public Configuration getConfiguration() &amp;#123; return configuration; &amp;#125; 第二步: Configuration的 getMapper() 方法 // Configuration.java public &lt;T> T getMapper(Class&lt;T> type, SqlSession sqlSession) &amp;#123; return mapperRegistry.getMapper(type, sqlSession); &amp;#125; 这一步我们很熟悉,跟编程式里面的 getMapper() 一样,通过工厂类MapperProxyFactory 获取一个MapperProxy 代理对象 也就是说我们注入Service 里面的接口,实际上还是一个MapperProxy 对象,所以最后调用Mapper 的接口的方法,也就是执行了 MapperProxy.invoke() 方法,后面的流程就跟编程式里面一模一样了. 总结: 对象 生命周期 SqlSessionTemplate spring中SqlSession的替代品,是线程安全的,通过代理模式调用DefaultSqlSession的方法, SqlSessionInterceptor(内部类) 代理对象,用来代理DefaultSqlSession,在SqlSessioonTemplate 中使用 SqlSessionDapSupport 用于获取SqlSessionTemplate,只要继承它就可以了 MapperFactoryBean 注册到IOC容器中替换接口类,继承了SqlSessionDaoSupport 用来获取SqlSessionTemplate,因为注入接口的时候,就会调用它的getObject 方法 SqlSessionHolder 控制SqlSession和事务","categories":[{"name":"mybatis","slug":"mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/"},{"name":"mybatis","slug":"mybatis/mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/mybatis/"}],"tags":[]},{"title":"MySQL架构(2)","slug":"mysql/MySQL架构(2)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mysql/mysql-jia-gou-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mysql/mysql-jia-gou-2/","excerpt":"","text":"MySQL架构1. 模块详解 Connector: 用来支持各种语言和SQL的交互, 比如php、Python、Java的JDBC., Management Serveices &amp; Utilities: 系统管理和控制工具,包括备份恢复、MySQL复制、集群等等. Connection Pool: 连接池,管理需要缓冲的资源,包括用户密码权限线程等. SQL Interface: 用来接收用户的SQL命令,返回用户需要的查询结果. Parser: 用来解析SQL语句 Optimizer:查询优化器 Cache and Buffer: 查询缓存,除了行记录的缓存之外，还有表缓存、key缓存、权限缓存等等. Pluggable Storage Engines:插件式引擎,它提供API给服务层使用,跟具体的文件打交道. 2. 架构分层总体上,我们可以把MySQL 分成三层,跟客户端对接的连接层,真正执行操作的服务层,和跟硬件打交道的存储引擎层 2.1 连接层我们的客户端要连接到MySQL服务器的3306端口, 必须要与服务端建立连接,那么管理所有的连接,验证客户端的身份和权限,这些功能就在连接层完成. 2.2 服务层连接层会把SQL交给服务层,这里面又包含一系列的流程： 比如查询缓存的依据,根据SQL 调用相应的接口,对我们的SQL 语句进行词法和语法的解析(比如关键词怎么识别, 别名怎么识别,语法有没有错误等等). 然后就是优化器,MySQL底层会根据一定的规则对我们的SQL进行优化,最后再交给执行器去执行. 2.3 存储引擎存储引擎就是我们的数据真正存放的地方,在MySQL里面支持不同的存储引擎,再往下就是内存或者磁盘. 3. 一条更新SQL是如何执行的?讲完了查询流程,我们是不是再讲讲更新流程、插入流程和删除流程呢? 在数据库中,我们说的update 操作其实包含了更新、插入、删除, 如果大家看过Mybatis 源码, 应该知道Executor 里面也只有doQuery()和doUpdate() 方法,没有doDelete()和 doInsert()。 更新流程和查询流程有什么不同呢? 基本流程也是一致的,也就是说,它也要经过解析器、优化器的处理,最后交给执行器. 区别就在于拿到符合条件的数据之后的操作. 3.1 缓冲池(Buffer Pool)首先,InnoDB 的数据都是放在磁盘的,InnoDB 操作数据有一个最小的逻辑单位,叫做页(索引页和数据页). 我们对于数的操作,不是每次都直接操作磁盘,因为磁盘的速度太慢了.InnoDB 使用了一种缓冲池的技术,也就是把磁盘读到的页放到一块内存区域里,这个内存区域就叫做Buffer Pool. 下一个读取相同的页,先判断是不是在缓冲池里, 如果是, 则直接读取,不用再访问磁盘. 修改数据的时候, 先修改缓冲池里面的页. 内存的数据页和磁盘数据不一致的时候,我们把它叫做 脏页.InnoDB 里面有专门的后台线程把Buffer Pool 的数据写入到磁盘, 每隔一段时间就一次性把多个修改写入磁盘, 这个动作就叫做 刷脏. Buffer Pool是InnoDB 里面一个非常重要的结构,它的内部又分为几块区域. 这里我们趁机来到官网来认识一下InnoDB的内存结构和磁盘结构. 3.2 InnoDB 内存结构和磁盘结构 3.2.1 内存结构Buffer Pool 主要分为3部分,Buffer Pool、Change Buffer、Adaptive Hash Index，另外还有一个（redo）log buffer。 1. Buffer PoolBuffer Pool 缓存的是页面信息,包括数据页、索引页. 查看服务器状态,里面有很多跟Buffer Pool相关的信息. SHOW STATUS LIKE '%innodb_buffer_pool%'; 这些状态都可以在官网中查到详细的含义. https://dev.mysql.com/doc/refman/5.7/en/server-status-variables.html Buffer Pool 默认大小为128M(134217728字节), 可以调整. 查看参数(系统变量) SHOW VARIABLES like '%innodb_buffer_pool%'; 这些参数都可以在官网中查到详细的含义. https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html 内存的缓冲池写满了怎么办? InnoDB 用LRU 算法来管理缓冲池(链表实现,不是传统的LRU, 分成了young和old),经过淘汰的数据就是热点数据. 内存缓冲区对于提升读写性能有很多的作用, 思考一个问题: 当需要更新一个数据页的时候,如果数据页在Buffer Pool中存在,那么就直接更新好了. 否则的话，就需要从磁盘加载到内存, 再对内存的数据页进行操作. 也就是说, 如果没有命中缓冲池,至少要产生一个磁盘IO, 有没有优化的方式呢? 2. Change Buffer 写缓冲如果这个数据页不是唯一索引,不存在数据重复的情况, 也就不需要从磁盘中加载索引页判断数据是不是重复(唯一性检查)。 这种情况下可以先把修改记录咋i内存的缓冲池中,从而提升更新语句(Insert、Delete、Update)的执行速度. 这一块区域就是Change Buffer, 5.5之前叫Insert Buffer插入缓冲, 现在也支持delete和update. 最后把change Buffer 记录到数据页的操作叫做merge, 什么时候发生merge呢? 有几种情况: 在访问这个数据页的时候, 或者通过后台线程、或者数据库shutdown、redo log 写满时触发. 如果数据库大部分索引都是非唯一索引, 并且业务是写多读少的,不会在写数据后立即读取,就可以使用Change Buffer(写缓冲).写多读少的业务, 调大这个值: SHOW VARIABLES LIKE 'innodb_change_buffer_max_size'; 代表Change Buffer占Buffer Pool的比例, 默认是25%. 3. Adaptive Hash Index索引应该放在磁盘的, 为什么还要专门把一种哈希的的东西放到内存? 下面再说. 4. （redo）Log Buffer思考一个问题: 如果Buffer Pool 里面的脏页还没有刷入磁盘时, 数据库宕或者重启,这些数据丢失. 如果写操作写道一半,甚至可能会破坏数据文件导致数据库不可用. 为了避免这个问题,InnoDB 把所有对页面的修改操作专门写入一个日志文件,并且在数据库启动时从这个文件中进行恢复操作(实现crash-safe)–用它来实现事务的持久性. 这个文件就是磁盘的redo log(叫做重做日志),对应于/var/lib/mysql/目录下的 ib_logfile0 和 ib_logfile1，每个48M. 这种日志和磁盘配合的整个过程,其实就是MySQL里的WAL技术（Write-Ahead Logging）, 它的关键点就是先写日志, 再写磁盘. show variables like 'innodb_log%'; 值 含义 innodb_log_file_size 指定每个文件的大小, 默认是48M innodb_log_files_in_group 指定文件的数量,默认为2 innodb_log_group_home_dir 指定文件所在路径,相对或者绝对,如果不指定,则为datadir 路径. 问题: 同样是写磁盘,为什么不直接写到db file 里面去呢? 为什么先写到日志再写磁盘呢? 我们先来了解一下随机IO和顺序IO的概念. 磁盘的最小组成单位是扇区,通常是512个字节. 操作系统和内存打交道,最小的单位是页Page 操作系统和磁盘打交道, 读写磁盘, 最小的单位是块Block 如果我们所需要的数据是随机分散在不同页的不同扇区中,那么找到相应的数据需要等待磁臂旋转到指定的页,然后盘片寻找到对应的扇区,才能找到我们所需要的一块数据, 依次进行此过程直到找到所有的数据,这个就是随机IO, 读取数据速度较慢. 假设我们已经找到了第一块数据,并且其他所需的数据就在这一块数据后面,那么就不需要重新寻址,可以依次拿到我们所需的数据, 这个就叫做顺序IO. 刷盘是随机IO, 而记录日志是顺序IO,顺序IO 效率更高, 因此先把修改写入日志,可以延迟刷盘时机,进而提升系统吞吐. 当然,redo log 也不是每一次都直接写入磁盘,而Buffer Pool里面有一块内存区域(Log Buffer)专门用来保存即将要写入日志文件的数据,默认16M, 它一样可以节省磁盘IO. SHOW VARIABLES LIKE 'innodb_log_buffer_size'; 需要注意的是,redo log 的内容主要是用于崩溃恢复, 磁盘的数据文件, 数据来自Buffer Pool.redo log 写入磁盘,不是写入数据文件。 那么Log Buffer 什么时候写入log file? 在我们写入数据到磁盘的时候,操作系统本身是有缓存的,flush 就是把操作系统缓冲区写入到磁盘. log buffer写入到磁盘的时机, 由一个参数控制, 默认是1. SHOW VARIABLES LIKE 'innodb_flush_log_at_trx_commit'; https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html 值 含义 0(延迟写) log buffer 将每秒一次的写入log buffer, 并且log file 的flush 操作同时进行,该模式下,在事务提交的时候,不会主动触发写入磁盘的操作. 1(默认, 实时写, 实时刷) 每次事务提交时MySQL都会把log buffer的数据写入到log file,并且刷到磁盘中去. 2(实时写, 延迟刷) 每次事务提交时MySQL都会把log buffer 的数据写入到log file.但是flush 操作并不会同时进行,该模式下,MySQL 会每秒执行一次flush 这是内存结构的第4块内容,redo log, 它又分为内存和磁盘两部分,redo log 有什么特点呢? redo log 是innoDB存储引擎实现的, 并不是所有存储引擎都有, 不是记录数据页更新之后的状态,而是记录这个页做了什么改动,属于物理日志 redo log 的大小是固定的, 前面的内容会被覆盖. check point 的当前要覆盖的位置. 如果write pos跟check point重叠,说明redo log 已经写满,这时候需要同步redo log到磁盘中 . 这是MySQL的内存结构,总结一下, 分为: Buffer pool、change buffer、Adaptive Hash Index、 log buffer。 3.2.2 磁盘结构表空间可以看作是InnoDB存储引擎逻辑结构的最高层,所有的数据都是存放在表空间中,InnoDB 的表空间分为5大类. 系统表空间 system tablespace在默认情况下InnoDB存储引擎有一个共享表空间(对应文件/var/lib/mysql/ ibdata1 ),也叫系统表空间. InnoDB系统表空间包含InoDB 数据字典和双写缓冲区,Change Buffer和Undo Logs,如果没有指定file-per-tables,也包含用户创建的表和索引数据. undo 在后面介绍, 因为有独立的表空间 数据字典: 由内部系统表组成,存储表和索引的元数据(定义信息) 双写缓冲(InnoDB的一大特性): InnoDB的页和操作系统的页大小不一致, InnoDB页大小一般分为16K, 操作系统页大小为4K, InnoDB的页写入到磁盘中,一个页需要分4次写. 如果存储引擎正在写入页的数据到了磁盘的时候发生了宕机,可能出现页只写了一部分的情况,比如只写了4K,就宕机了. 这种情况叫做部分写失效(partial page write), 可以会导致数据丢失. show variables like 'innodb_doublewrite'; 我们不同有redo log吗? 但是有个问题, 如果这个页本身已经损坏了,用它来做崩溃恢复是没有意义的. 所以 在对于应用redo log之前, 需要一个页的副本. 如果出现了写入失效,就用页的副本来还原这个页, 然后再应用到redo log.这个页的副本就是double write. InnoDB的双写技术. 通过它来实现了数据页的可靠性. 跟redo log 一样,double write 由两部分组成, 一部分是内存的double write,一部分是磁盘上的double write, 因为double write 是顺序写入的,不会带来很多的开销. 在默认情况下, 所有的表共享一个系统表空间,这个文件会越来越大,而且它的空间不会收缩. 独占表空间 file-per-table tablespaces我们可以让每张表独立一个表空间, 这个开关通过innodb_file_per_table 设置,默认开启. SHOW VARIABLES LIKE 'innodb_file_per_table'; 开启后,则每张表会开辟一个表空间,这个文件就是数据目录下的ibd 文件, 存放表的索引和数据. 但是其他类的数据, 如回滚(undo)信息、插入缓冲索引页、系统事务信息、二次写缓冲(Double write buffer) 等还是存放在原来的共享表空间内. 通用表空间 general tablespaces通用表空间也是一种共享的表空间, 跟ibdata1 类似. 可以创建一个通用的表空间,用来存储不同数据的表,数据路径和文件可以自定义. 语法: create tablespace ts2673 add datafile '/var/lib/mysql/ts2673.ibd' file_block_size=16K engine=innodb; 在创建表的时候,可以指定表空间,用 ALTER 修改表空间可以转移表空间. create table t2673(id integer) tablespace ts2673; 不同表空间的数据是可以移动的. 删除表空间需要先删除里面的所有的表. drop table t2673; drop tablespace ts2673; 临时表空间 temporary tablespaces存储临时表的数据, 包括用户创建的临时表, 和磁盘的内部临时表,对应数据目录下的ibtmp1文件。当数据服务器正常关闭时, 该表空间被删除,下次重新产生. Redo log磁盘结构里面的redi log undo log tablespacehttps://dev.mysql.com/doc/refman/5.7/en/innodb-undo-tablespaces.html https://dev.mysql.com/doc/refman/5.7/en/innodb-undo-logs.html undo log (撤销日志或回滚日志)记录了事务发生之前的数据状态(不包括select).如果修改了数据时出现异常,可以用undo log 来实现回滚操作(保证原子性). 在执行undo 的时候,仅仅是将数据从逻辑上恢复至事务之前的状态,而不是从物理页面上操作实现的,属于逻辑格式的日志. redo log 和undo log 与事务密切相关,统称为事务日志. undo Log的数据默认在系统表空间ibdata1文件中,因为共享表空间不会自动收缩,也可以单独创建一个undo 表空间。 show global variables like '%undo%'; 有了这些日志之后,我们来总结一下一个更新操作的流程,这是一个简化的过程. name的原值是张三 update user set name = '李四' where id=1; 事务开始,从内存或者磁盘取到这条数据,返回给Server 的执行器. 执行器修改这一行的数据的值为李四 记录name=张三到undo log 记录name=李四到redo log 调用存储引擎接口,在内存(Buffer Pool)中修改name=李四 事务提交 内存和磁盘之间工作着很多后台线程. 3.3 后台线程后台线程的主要作用是负责刷新内存池中的数据和把修改的数据页刷新到磁盘. 后台线程分为 master thread，IO thread，purge thread，page cleaner thread master thread:负责刷新缓存数据到磁盘并协调调度其他后台线程. IO thread：分为insert buffer、log、read、write 进程,分别用来处理insert buffer,重做日志,读写请求的IO回调. purge thread: 用来回收undo 页 . page cleaner thread: 用来刷新脏页. 除了InnoDB 架构中的日志文件,MySQL的Server 层也有一个日志文件,叫做binlog,它可以被所有的存储引擎使用. 3.4 BinLoghttps://dev.mysql.com/doc/refman/5.7/en/binary-log.html binlog 以事件的形式记录了所有的DDL和DML语句(因为它记录的是操作而不是数据值,属于逻辑日志), 可以用来做主从复制和数据恢复. 跟redo log 不一样,它的文件内容是可以追加的,没有固定大小限制. 在开启了binlog 功能的情况下, 我们可以把binlog导入成SQL语句,把所有的操作重放一遍，来实现数据的恢复. binlog的另一个功能就是用来实现主从复制,它的原理就是从服务器读取住服务器的binlog, 然后执行一遍. 有了这两个日志后, 我们来看一下一条更新语句是怎么执行的? 例如一条语句: update teacher set name=&#39;盆鱼宴&#39; where id=1; 先查询到这条数据,如果有缓存,也会用到缓存. 把name改成盆鱼宴，然后调用引擎的 API 接口，写入这一行数据到内存，同时 记录 redo log。这时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，可 以随时提交。 执行器收到通知后记录binlog, 然后调用存储引擎接口,设置 redo log为 commit 状态. 更新完成. 这张图的重点: 先记录到内存,再写日志文件 记录redo log 分为两个阶段 存储引擎和Server 记录不同的日志 先记录redo, 再记录binlog","categories":[{"name":"mysql","slug":"mysql","permalink":"https://rainsoil.github.io/categories/mysql/"},{"name":"mysql","slug":"mysql/mysql","permalink":"https://rainsoil.github.io/categories/mysql/mysql/"}],"tags":[]},{"title":"window10下子系统ubuntu安装Docker","slug":"linux/window10下子系统ubuntu安装Docker","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/linux/window10-xia-zi-xi-tong-ubuntu-an-zhuang-docker/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/linux/window10-xia-zi-xi-tong-ubuntu-an-zhuang-docker/","excerpt":"","text":"window10下子系统ubuntu安装Docker准备工作开启window子系统网上有很多教程，这里不做过多的记录，可使用以下教程:Win10安装Ubuntu子系统教程（附安装图形化界面） 下载Docker for Window安装包进入docker官网下载页面 有4 5百兆的样子，这里下着就好了，不用等他下完，我们先去做别的，后面再说这个怎么用。 ubuntu下安装Docker汇总的指令列表 sudo apt-get remove docker docker-engine docker-ce docker.io sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" apt-cache madison docker-ce sudo apt-get install docker-ce sudo service docker start 以下是具体的指令说明及执行情况 由于apt官方库里的docker版本可能比较旧，所以先卸载可能存在的旧版本： sudo apt-get remove docker docker-engine docker-ce docker.io 更新apt包索引： sudo apt-get update 安装以下包以使apt可以通过HTTPS使用存储库（repository）： sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common 添加Docker官方的GPG密钥： curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 安装stable存储库 sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; 查看Docker-ce的版本 apt-cache madison docker-ce 安装docker-ce sudo apt-get install docker-ce 或者指定以上查出来的版本，如 sudo apt-get install docker-ce=18.06.3~ce~3-0~ubuntu 启动服务 sudo service docker start 完了？可以用了？然而并没有！！！查看版本及状态下图看见没”Docker is not runing“ 这里只有client，没有发现server，之前习惯使用的Centos，比较少使用ubuntu，因此一度让我怀疑是我安装的时候出现了问题，因此测试了各种安装方式，均得到了同样的结果；反复找原因之后，这篇文章windows10 linux子系统 ubuntu 18.0运行docker让我明白了，windows10子系统有其特殊性，需要安装docker for windows，用来作为Docker的守护进程，作为Docker的服务端，ubuntu下作为客户端去访问这个守护进程，这也就是文章一开头为什么要下载docker for window的原因 安装 Docker for Windows 安装安装很简单，选择下载好的exe，下一步到结束即可，桌面会出现以下图标即可； 问题一,Typer-V的错误Typer-V如果没有开启，启动软件的时候会报错，这里开启，重启电脑即可 问题二,Cpu虚拟化在任务管理器中查看 开启虚拟化如果这里是已禁用，需要在BOIS开启CPU的虚拟化即可每个电脑的进入BOIS的方式不太一样，可以百度一下自己的电脑对应型号是如何开启CPU虚拟化的，我的电脑是使用F1进入BOIS 保存重启电脑，在任务管理器中确认虚拟化已启动即可 启动成功成功启动之后，会引导你登录官方Docker的账号(不登录也可以)，同时电脑的右下方会有个小鲸鱼，右键小鲸鱼，可以看到以下效果 开启2375端口对外提供服务右键小鲸鱼 &gt; settings &gt; General，勾选上以下选项 子进程链接宿主机Docker守护进程 配置及刷新环境变量 echo &quot;export DOCKER_HOST=&#39;tcp://0.0.0.0:2375&#39;&quot; &gt;&gt; ~/.bashrc source ~/.bashrc 再次查看版本 哦豁！！！ 好了。。。。","categories":[{"name":"linux","slug":"linux","permalink":"https://rainsoil.github.io/categories/linux/"},{"name":"linux","slug":"linux/linux","permalink":"https://rainsoil.github.io/categories/linux/linux/"}],"tags":[]},{"title":"Mybatis源码调试(6)","slug":"mybatis/Mybatis源码调试(6)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mybatis/mybatis-yuan-ma-diao-shi-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mybatis/mybatis-yuan-ma-diao-shi-6/","excerpt":"","text":"6. Mybatis源码调试 1. 版本与源码在引入jar之后，点开代码，首先是反编译的代码，没有相关的注释，在IDEA里面右上角会出现Download Sources和Choose Sources。IDEA里面直接下载官方的源代码包。 如果我们有自己下载的源码目录，包括一些我们自己加了注解的源代码，也可以用Choose Sources的方法选择源代码目录。切换源码版本，只要切换pom.xml里面的jar包版本就行了。 如果下载了其他版本的源码，例如带中文注释版，可以install，产生jar包以后，在pom.xml中修改依赖。https://github.com/tuguangquan/mybatis（3.3.0，snapshot，非最新版本） jar包里面的源代码是不可以修改的，想要自己给下载的源码加注释怎么办？可以添加source到下载的源码目录。","categories":[{"name":"mybatis","slug":"mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/"},{"name":"mybatis","slug":"mybatis/mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/mybatis/"}],"tags":[]},{"title":"Mybatis 设计模式总结(5)","slug":"mybatis/Mybatis 设计模式总结(5)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mybatis/mybatis-she-ji-mo-shi-zong-jie-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mybatis/mybatis-she-ji-mo-shi-zong-jie-5/","excerpt":"","text":"5. Mybatis 设计模式总结 设计模式 类 工厂 SqlSessionFactory,ObjectFactory,MapperProxyFactory 建造者 XMLConfigBuilder,XMLMapperBuilder,XMLStatementBuilder 单例模式 SqlSessionFactory,Configuration 代理模式 绑定:MappeProxy 延迟加载:ProxyFactory(CGLIB,javassit) 插件:Plugin Spring继承Mybatis:SqlSessionTemplate 的内部类SqlSessionIntercepor Mybatis 自带连接池:PoolDataSource管理的 PooledConnection 日志打印: ConnectionLogger,StatementLogger 适配器模式 logger 模块,对于Log4j,JDK logger,这些没有直接实现 slg4j接口的日志组件,需要适配器 模板方法 BaseExecutor与子类SimpleExecutor,BatchExecutor,ReuseExecutor 装饰器模式 LoggerCache,LruCache等对PrepetualCache的装饰,CachingExecutor对其他Executor的装饰 责任链模式 InterceptorChain","categories":[{"name":"mybatis","slug":"mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/"},{"name":"mybatis","slug":"mybatis/mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/mybatis/"}],"tags":[]},{"title":"MyBatis插件原理(3)","slug":"mybatis/MyBatis插件原理(3)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mybatis/mybatis-cha-jian-yuan-li-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mybatis/mybatis-cha-jian-yuan-li-3/","excerpt":"","text":"3. MyBatis插件原理 Mybatis 通过提供插件机制,让我们可以根据自己的需要去增强Mybatis 的功能 需要注意的是,如果没有完全理解Mybatis的运行原理和插件的工作方式,最好不要使用插件,因为他会改变底层的工作逻辑,给系统带来很大的影响. 1. 猜想Mybatis 的插件可以在不修改原来代码的情况下，通过拦截方式改变四大核心对象的行为,比如处理参数,处理SQL,处理结果. 第一个问题:不修改对象的代码,怎么对对象的行为进行修改,比如说在原来的方法前面做一点事情,在原来的方法后面做一点事情. 答案: 大家很容易想到使用代理模式,这个也确实是Mybatis 插件的原理。 第二个问题:我们可以定义很多的插件,那么这种所有的插件都会行成一个链路,比如我们提交一个休假申请,先是项目经理审批,然后是部门经理审批,再是HR审批,再到总经理审批,怎么实现层层的拦截., 答案: 插件是层层拦截的,我们又需要用到另一种设计模式–责任链模式 如果是用代理模式,我们就要解决几个问题？ 有哪些对象允许被代理？有哪些方法可以被拦截? 我们应该了解Mybatis 允许哪些对象的哪些方法允许被拦截,并不是每一个运行的节点的都是可以被修改的,只有清楚了这些对象的方法的作用,当我们自己编写插件拦截的时候才知道从哪里去拦截. 在Mybatis的官网上有答案,我们来看一下http://www.mybatis.org/mybatis-3/zh/configuration.html#plugins Executor 会拦截CachingExecutor或者BaseExecutor 因为创建Executor时先创建Executor,再拦截 2. 怎么创建代理?如果我们用JDK代理,要有一个实现InvocationHandler的代理类,用来包装被代理对象,这个类是自己创建还是谁创建? 3. 什么时候创建代理对象?是在Mybatis启动的时候创建,还是调用的时候创建?4. 被代理后,调用的是什么方法?怎么调用到原代理对象的方法(比如Executor的query 方法)要解决后面三个问题,我们先看一下别人的插件是如何工作的? 2. 插件编写与注册我们以PageHelper 为例: 1. 编写自己的插件类 实现Interceptor 接口 这个是所有插件必须实现的接口 添加@Intercepts({@Signarure()}) ,指定拦截的对象和方法,方法参数,方法名称+参数类型,构成了方法的签名,决定了能拦截到哪个方法. 问题:拦截参数跟参数的顺序有关系吗? 实现接口的三个方法 // 用于覆盖被拦截对象的原有方法（在调用代理对象 Plugin 的 invoke()方法时被调用） Object intercept(Invocation invocation) throws Throwable; // target 是被拦截对象，这个方法的作用是给被拦截对象生成一个代理对象，并返回它 Object plugin(Object target); // 设置参数 void setProperties(Properties properties); 2. 插件注册,在mybatis-config.xml中注册插件&lt;plugins> &lt;plugin interceptor=\"com.github.pagehelper.PageInterceptor\"> &lt;property name=\"offsetAsPageNum\" value=\"true\"/> ……后面全部省略…… &lt;/plugin> &lt;/plugins> 3. 插件登记Mybatis 启动时扫描 标签,注册到Configuration 对象的InterceptorChin 中,Property 里面的参数,会调用setProperty() 处理 以上就是编写和使用自定义插件的全部步骤 3.代理和拦截是怎么实现的? 问题1 : 四大对象是什么时候代理的,也就是:代理对象是什么时候创建的? 问题2: 多个插件的情况下,代理能不能被代理?代理顺序和调用顺序的关系? 问题3: 谁来创建代理对象? 问题4: 被代理后,调用的是什么方法?怎么调用到原被代理对象的方法? 问题1: Executor 是openSession()的时候创建的;StatementHandler 是SimpleExecutor.doQuery()的时候创建的;里面包含了处理参数的ParameterHandler和处理结果集ResultSetHandler的创建,创建之后立即调用InterceptorChin.pluginAll(),返回层层代理之后的对象. 问题2: 可以被代理,debug看一下. 问题3:Plugin 类,在我们重写的 plugin() 方法里面可以直接调用 return Plugin.wrap(target,this) 返回调用对象. 问题4:因为代理类是Plugin,所以最后调用的是 Plugin的 invoke() 方法,它先调用了定义的拦截器intercept() 方法.可以通过 invocation.proceed() 调用到被代理对象被拦截的方法. 总结流程如下: 总结:| 对象 | 作用 || ————– | ——————————————————– || Interceptor | 自定义插件需要实现接口,实现三个方法 || InterceptChain | 配置的插件解析后会保存到Configuration的InterceptChain中 || Plugin | 用来创建代理对象,包装四大对象 || Invocation | 对被代理类进行包装,可以调用proceed() 调用到被拦截的方法. | 4. PageHelper 原理用法（EmployeeController.getEmpsWithJson()） PageHelper.startPage(pn, 10); List&lt;Employee> emps = employeeService.getAll(); PageInfo page = new PageInfo(emps, 10); 先看PageHelper jar 中PageInterceptor 的源码,拦截的是Executor的两个query()方法,在这里对SQL 进行了改写 //调用方言获取分页 sql String pageSql = dialect.getPageSql(ms, boundSql, parameter, rowBounds, pageKey); 跟踪到最后,是在MySqlDialect.getPageSql() 对SQL 进行改写,翻页参数是从一个Page对象里面拿到的,那么Page对象是怎么传到这里的呢? 上一步,AbstractHelperDialect.getPageSql()中: Page page = getLocalPage(); return getPageSql(sql, page, pageKey); Page 对象是从一个ThreadLocal 变量中拿到的,那么他是什么时候赋值的呢? 回到EmployeeController. getEmpsWithJson()中，PageHelper.startPage() 方法,把分页参数放到了ThreadLocal 变量中 protected static void setLocalPage(Page page) &amp;#123; LOCAL_PAGE.set(page); &amp;#125; 关键类总结:| 对象 | 作用 || ————— | ———— || PageInterceptor | 自定义拦截器 || Page | 包装分页参数 || PageInfo | 包装结果 || PageHelper | 工具类 | 5. 应用场景分析 作用 实现方式 水平分表 对query,update 方法进行拦截,在接口上添加注解,通过反射获取接口注解,根据注解上配置的参数进行分表,修改原SQL 。 数据加解密 update– 加密,query–解密,获得入参和返回值 菜单权限控制 对query 方法进行拦截,在方法上添加注解,根据权限配置,以及用户登陆信息,在SQL上加上权限过滤条件.","categories":[{"name":"mybatis","slug":"mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/"},{"name":"mybatis","slug":"mybatis/mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/mybatis/"}],"tags":[]},{"title":"maven的命令大全","slug":"maven/maven的命令大全","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/maven/maven-de-ming-ling-da-quan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/maven/maven-de-ming-ling-da-quan/","excerpt":"","text":"[TOC] 1. 修改父项目和子项目的versionmvn versions:set -DnewVersion=1.4-RELEASE &gt; 有的说需要versions-maven-plugin 插件,经过证实,不需要 &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;versions-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;configuration&gt; &lt;generateBackupPoms&gt;false&lt;/generateBackupPoms&gt; &lt;/configuration&gt; &lt;/plugin&gt; 2. 打包mvn clean isntall -Dmaven.test.skip=true bat脚本 @echo off echo git pull .. &amp;&amp; git pull &amp;&amp; mvn clean install -U -Dmaven.test.skip=true 3. 上传私服 mvn deploy -X -Dmaven.test.skip=true bat 脚本 @echo off echo git pull .. &amp;&amp; git pull &amp;&amp; mvn clean install -U -Dmaven.test.skip=true &amp;&amp; mvn deploy -X -Dmaven.test.skip=true 4. 创建Maven的普通Java项目： mvn archetype:create -DgroupId=packageName -DartifactId=projectName 5. 创建Maven的Web项目： mvn archetype:create -DgroupId=packageName -DartifactId=webappName-DarchetypeArtifactId=maven-archetype-webapp 6. 编译源代码 mvn compile 7. 编译测试代码 mvn test-compile 8. 运行测试 mvn test 9. 产生site mvn site 10 打包 mvn package 11. 在本地Repository 中安装jar mvn install 12. 清除产生的项目 mvn clean 13. 生成eclipse 项目 mvn eclipse:eclipse 14. 生成idea 项目 mvn idea:idea 15. 发布第三方包到本地库 mvn install:install-file -DgroupId=com -DartifactId=client -Dversion=0.1.0 -Dpackaging=jar -Dfile=d:\\client-0.1.0.jar 16.maven archetype 模版化16.1 生成步骤1. 新建项目 2. 执行 mvn archetype:create-from-project 命令 3. cd target/generated-sources/archetype 4. mvn install -U -Dmaven.test.skip=true 16.2 使用步骤 1. 在需要创建项目的目录执行 mvn archetype:generate -DarchetypeCatalog=local 2. 输入要使用的archtype的序号 3. 输入groupId 4. 输入 artifactId 和version和package 5. 确定生成","categories":[{"name":"maven","slug":"maven","permalink":"https://rainsoil.github.io/categories/maven/"},{"name":"maven","slug":"maven/maven","permalink":"https://rainsoil.github.io/categories/maven/maven/"}],"tags":[]},{"title":"linux   maven 安装","slug":"maven/linux   maven 安装","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/maven/linux-maven-an-zhuang/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/maven/linux-maven-an-zhuang/","excerpt":"","text":"1. 安装jdk2. 下载maven 去http://maven.apache.org/download.cgi 下载maven 包 2.1 下载到服务器 wget http://mirrors.shu.edu.cn/apache/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gz 2.2 解压 tar -zxvf apache-maven-3.5.4-bin.tar.gz 2.3 配置环境变量 vim /etc/profile // 在最底层加入 export M2_HOME=你的maven安装路径 export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;M2_HOME&#125;/bin:$PATH 2.4 刷新系统配置 source /etc/profile 2.5 验证执行 mvn -v","categories":[{"name":"maven","slug":"maven","permalink":"https://rainsoil.github.io/categories/maven/"},{"name":"maven","slug":"maven/maven","permalink":"https://rainsoil.github.io/categories/maven/maven/"}],"tags":[]},{"title":"阿里云Centos6","slug":"linux/阿里云Centos6.5  更换源","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/linux/a-li-yun-centos6.5-geng-huan-yuan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/linux/a-li-yun-centos6.5-geng-huan-yuan/","excerpt":"","text":"阿里云Centos6.5 更换源背景信息2020年11月30日CentOS 6 EOL。按照社区规则，CentOS 6的源地址http://mirror.centos.org/centos-6/内容已移除，目前第三方的镜像站中均已移除CentOS 6的源。阿里云的源http://mirrors.cloud.aliyuncs.com和http://mirrors.aliyun.com也无法同步到CentOS 6的源。当您在阿里云上继续使用默认配置的CentOS 6的源会发生报错。报错示例如下图所示： 您可以通过下文的操作步骤，在CentOS 6操作系统的ECS实例中将源配置按照网络环境不同进行切换。 yum源 专有网络VPC类型实例需切换为http://mirrors.cloud.aliyuncs.com/centos-vault/6.10/源。 经典网络类型实例需切换为http://mirrors.aliyuncs.com/centos-vault/6.10/源。 epel源 专有网络VPC类型实例需切换为http://mirrors.cloud.aliyuncs.com/epel-archive/6/源。 经典网络类型实例需切换为http://mirrors.aliyuncs.com/epel-archive/6/源。 说明 本文主要说明ECS实例中的相关操作与配置。如果您的服务器不是ECS实例，需保证服务器具有公网访问能力，并且源地址http://mirrors.cloud.aliyuncs.com需要替换为http://mirrors.aliyun.com。例如，切换yum源为http://mirrors.aliyun.com/centos-vault/6.10/；切换epel源为http://mirrors.aliyun.com/epel-archive/6/。 操作步骤 登录CentOS 6系统的ECS实例。 具体操作，请参见连接方式概述。 运行以下命令编辑CentOS-Base.repo 文件。 vim /etc/yum.repos.d/CentOS-Base.repo 按i进入编辑模式，修改以下内容切换源。 请根据实例不同的网络类型进行修改，具体内容如下： 专有网络VPC类型实例 [base] name=CentOS-6.10 enabled=1 failovermethod=priority baseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/6.10/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.cloud.aliyuncs.com/centos-vault/RPM-GPG-KEY-CentOS-6 [updates] name=CentOS-6.10 enabled=1 failovermethod=priority baseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/6.10/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.cloud.aliyuncs.com/centos-vault/RPM-GPG-KEY-CentOS-6 [extras] name=CentOS-6.10 enabled=1 failovermethod=priority baseurl=http://mirrors.cloud.aliyuncs.com/centos-vault/6.10/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.cloud.aliyuncs.com/centos-vault/RPM-GPG-KEY-CentOS-6 经典网络类型实例 [base] name=CentOS-6.10 enabled=1 failovermethod=priority baseurl=http://mirrors.aliyuncs.com/centos-vault/6.10/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyuncs.com/centos-vault/RPM-GPG-KEY-CentOS-6 [updates] name=CentOS-6.10 enabled=1 failovermethod=priority baseurl=http://mirrors.aliyuncs.com/centos-vault/6.10/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyuncs.comm/centos-vault/RPM-GPG-KEY-CentOS-6 [extras] name=CentOS-6.10 enabled=1 failovermethod=priority baseurl=http://mirrors.aliyuncs.com/centos-vault/6.10/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyuncs.com/centos-vault/RPM-GPG-KEY-CentOS-6 编辑完成后，按Esc键，并输入:wq保存退出文件。 运行以下命令编辑epel.repo 文件。 vim /etc/yum.repos.d/epel.repo 按i进入编辑模式，修改以下内容切换源。 请根据实例不同的网络类型进行修改，具体内容如下： 专有网络VPC类型实例 [epel] name=Extra Packages for Enterprise Linux 6 - $basearch enabled=1 failovermethod=priority baseurl=http://mirrors.cloud.aliyuncs.com/epel-archive/6/$basearch gpgcheck=0 gpgkey=http://mirrors.cloud.aliyuncs.com/epel-archive/RPM-GPG-KEY-EPEL-6 经典网络类型实例 [epel] name=Extra Packages for Enterprise Linux 6 - $basearch enabled=1 failovermethod=priority baseurl=http://mirrors.aliyuncs.com/epel-archive/6/$basearch gpgcheck=0 gpgkey=http://mirrors.aliyuncs.com/epel-archive/RPM-GPG-KEY-EPEL-6 编辑完成后，按Esc键，并输入:wq保存退出文件。 后续步骤yum源和epel源切换完成后，即可使用yum install命令在实例上安装您所需要的软件包。 使用自定义镜像创建新的ECS实例，在启动实例时cloud-init会自动初始化系统的源配置。如果您后续需要通过已切换源的ECS实例创建自定义镜像，并且需要保留已切换的源配置，需要您在创建自定义镜像前，按照以下操作在已切换源的ECS实例中修改cloud-init的配置文件/etc/cloud/cloud.cfg。 运行以下命令编辑 /etc/cloud/cloud.cfg 文件。 vim /etc/cloud/cloud.cfg 按 i 进入编辑模式，使用 # 注释掉 cloud_init_modules: 下的 - source-address 模块。 注释后，文件内的配置信息如下所示： 编辑完成后，按Esc键，并输入:wq保存退出文件。 如果显示 需要配置dns vim /etc/resolv.conf nameserver 100.100.2.136 nameserver 100.100.2.138","categories":[{"name":"linux","slug":"linux","permalink":"https://rainsoil.github.io/categories/linux/"},{"name":"linux","slug":"linux/linux","permalink":"https://rainsoil.github.io/categories/linux/linux/"}],"tags":[]},{"title":"window10安装Linux子系统（WSL）及迁移到非系统盘","slug":"linux/window10安装Linux子系统（WSL）及迁移到非系统盘","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/linux/window10-an-zhuang-linux-zi-xi-tong-wsl-ji-qian-yi-dao-fei-xi-tong-pan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/linux/window10-an-zhuang-linux-zi-xi-tong-wsl-ji-qian-yi-dao-fei-xi-tong-pan/","excerpt":"","text":"window10安装Linux子系统（WSL）及迁移到非系统盘痛点：在电脑上想要使用linux又想使用windows系统只能安装双系统，因为虚拟机的性能差且使用麻烦，双系统使用起来倒是也还行，ubuntu的桌面系统现在用起来也可以，但是来回切换比较麻烦，故想尝试一下windows自带的这个WSL功能使用起来如何。记录一下安装过程。 Linux子系统WSL（Windows Subsystem for Linux）详细介绍见官网：https://docs.microsoft.com/en-au/windows/wsl/about 安装安装过程很简单，也不占什么空间： 1.打开控制面板中的程序和功能，打开启用或关闭Windows功能 2 向下拉 勾选适用于Linux的Windows子系统，确定 3 打开win10带的Microsoft Store 搜索 LINUX 4 选择在Windos上运行Linux,推荐安装ubuntu或debian，其他的都没见过，根据需求自行选择就行 5 点击获取安装 6 启动即可，初次启动会要求键入用户名和密码，根据需求输入即可，这样就算是安装完成 使用1 右键开始图标打开power shell 2 输了bash即可启动, 可以使用 wsl -l查询子系统安装列表 3 子系统默认安装在系统系统盘，其他盘在子系统中的mnt文件夹中 4 tips:你也可以在指定路径的文件夹中shift+右键打开Linux shell 5 字体大小啥的，右键窗口上端进入 默认值进行更改 迁移到非系统盘一般大家在安装系统的时候都喜欢把系统盘能的比较小，如果子系统要安装很多东西，比如我要安装docker，会有很多镜像，很占空间在系统盘不是很合适，于是有了迁出系统盘的需求，可以使用LxRunOffline进行迁移 1 下载 LxRunOffline ，https://github.com/DDoSolitary/LxRunOffline/releases，选择最新版下载即可 2 解压后，在软件目录打开power shell ，上面交的方法shift + 右键 3 使用LxRunOffline.exe list命令查看你可以使用子系统名称 4 使用 lxrunoffline move 进行迁移 ， -n 指定你要迁移的系统名 ，-d 指定你新系统的迁移路径 5 迁移过程会出现WARNING 不用管， 等待一段时间结束就算迁移完成了 6 使用LxRunOffline.exe get-dir 查询系统目录，可见已经更改成功 备注：还有个下载系统包的安装方法，由于下载速度感人没有尝试，方法官网有，链接如下：https://docs.microsoft.com/en-au/windows/wsl/install-on-server————————————————","categories":[{"name":"linux","slug":"linux","permalink":"https://rainsoil.github.io/categories/linux/"},{"name":"linux","slug":"linux/linux","permalink":"https://rainsoil.github.io/categories/linux/linux/"}],"tags":[]},{"title":"MySQL事务与锁详解(4)","slug":"mysql/MySQL事务与锁详解(4)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mysql/mysql-shi-wu-yu-suo-xiang-jie-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mysql/mysql-shi-wu-yu-suo-xiang-jie-4/","excerpt":"","text":"MySQL事务和锁详解1. 什么是数据库的事务1.1 事务的典型场景在项目中,什么地方会用到事务,或者配置了事务? 无论是在方法上加注解, 还是配置切面. &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"> &lt;tx:attributes> &lt;tx:method name=\"save*\" rollback-for=\"Throwable\" /> &lt;tx:method name=\"add*\" rollback-for=\"Throwable\" /> &lt;tx:method name=\"send*\" rollback-for=\"Throwable\" /> &lt;tx:method name=\"insert*\" rollback-for=\"Throwable\" /> &lt;/tx:attributes> &lt;/tx:advice> 比如下单,会操作订单表、资金表、物流表等等, 这个时候我们需要让这些操作都在一个事务中完成. 当一个业务中涉及到多个表的操作的时候,我们希望他们要么是全部成功,要么都不成功,这个时候我们会启用事务. 在金融的系统里面事务的配置是很常见的,比如行内转账的这种操作, 如果我们把他简单的理解为一个账户的余额增加,另一个账户的余额减少的情况(当然实际上要比这个复杂), 那么这两个动作一定是同时成功或者同时失败的,否则就会造成银行的会计科目不平衡. 1.2 事务的定义什么是事务? 维基百科的定义:事务是数据库管理系统(DBMS)执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成. 这里面有两个关键点,第一个是他是数据库最小的工作单元,是不可以再分的, 第二个, 他可能包含了一个或者一系列的DML语句, 包括(insert、delete、update) 单条DDL(create drop)和DCL(grant revoke) 也会有事务. 1.3 哪些存储引擎支持事务https://dev.mysql.com/doc/refman/5.7/en/storage-engines.html 查看官网我们直到,InnoDB和NDB 是支持事务的. 1.4 事务的四大特性事务的四大特性:ACID 1.4.1 原子性(Atomicity)原子性, 也就是我们说的不可再分,也就意味着我们对数据库的一系列操作, 要么都是成功,要么都是失败,不可能出现部分成功或者部分失败的情况. 以转账的场景为例,一个账户的余额较少,对应一个账户的余额增加,这两个一定是同时成功或者同时失败的. 全部成功比较简单,问题是如果前面一个操作已经成功了,后面的操作失败了, 怎么让他全部失败呢? 这个时候我们必须要回滚. 原子性, 在InnoDB 里面通过undo log 来实现的, 它记录了数据修修改之前的值(逻辑日志), 一般发生了异常,就可以使用undo log 来实现回滚操作. 1.4.2 一致性(consistent)一致性指的是数据库的完整性约束没有被破坏的,事务执行的前后都是合法的数据状态,比如主键必须是唯一,字段长度符合要求. 除了数据库自身的完整性约束,还有一个是用户自定义的完整性. 比如说转账这个场景,A账户余额减少了1000,B账户余额只是增加了500, 这个时候因为两个操作都成功了,按照我们对原子性的定义, 它满足原子性,但是它并没有满足一致性,以为它会导致会计科目不平衡. 还有一种情况,A账户余额为0, 如果这个时候转账成功了,A账户的余额就会变成-1000,虽然它满足了原子性,但是我们知道，借记卡的余额是不能小于0的,所以也违反了一致性。 用户自定义的完整性通常要在代码中控制. 1.4.3 隔离性(Isolation)我们有了事务的定义以后,在数据库里面会有很多事务同时去操作我们的同一张表或者同一行数据,必然会产生一些并发或者干扰的操作,那么我们对隔离的定义, 就是这些很多个事务, 对表或者行的并发操作,.应该是透明的, 互不干扰的. 通过这种方式,我们最终也是保证业务数据的一致性 1.4.4 持久性(Durable)事务的持久性是什么意思呢? 我们对数据库的任意操作, 增删拆, 只要事务提交成功,那么结果就是永久性的,不可能因为我们系统宕机或者重启了数据库的服务器,它又恢复到原来的状态,这个就是事务的持久性 . 持久性是怎么实现的呢? 数据库崩溃恢复(crash-safe)是通过什么实现的? 持久性是通过redo log和double write 双写缓存来实现的,我们操作数据的时候,会先写到内存的bufer Pool里面,同时记录redo log, 如果在刷盘之前出现异常,在重启后就可以读取redo log 的内容,写入到磁盘,保证数据的持久性. 当然, 恢复成功的前提是数据页本身没有损坏,是完整的,这个通过双写缓冲(double wrote) 保证. 原子性、隔离性、持久性, 最后都是为了实现一致性. 1.5 数据库什么时候会出现事务?无论你是在Navicat的这种工具里面去操作, 还是在我们的java代码里面通过API去操作,还是加上@Transactional的注解或者AOP的配置， 其实最终都是发送一个指令到数据库去执行,java的JDBC 只不过是把这些命令封装了起来而已. 我们先来看一下我们的操作环境,版本(5.7),存储引擎(InnoDB),事务隔离级别(RR) select version(); show variables like '%engine%'; show global variables like \"tx_isolation\"; 我们先准备一张表 CREATE TABLE `student` ( `id` INT ( 16 ) NOT NULL AUTO_INCREMENT COMMENT '自增ID', `sno` VARCHAR ( 16 ) DEFAULT NULL COMMENT '学号', `sname` VARCHAR ( 64 ) DEFAULT NULL COMMENT '姓名', `company` VARCHAR ( 128 ) DEFAULT NULL COMMENT '公司', PRIMARY KEY ( `id` ) ) ENGINE = INNODB AUTO_INCREMENT = 4 DEFAULT CHARSET = utf8; INSERT INTO `student` ( `id`, `sno`, `sname`, `company` ) VALUES ( 1, 'GP16666', '猫老公', 'Tencent' ); INSERT INTO `student` ( `id`, `sno`, `sname`, `company` ) VALUES ( 2, 'GP17777', '一个人的精彩', 'Baidu' ); INSERT INTO `student` ( `id`, `sno`, `sname`, `company` ) VALUES ( 3, 'GP18888', '菜鸟', 'Alibaba' ); 执行这样的一条更新语句,它有事务吗? update student set sname = '猫老公 111' where id=1; 实际上, 它自动开启了一个事务,并且提交了,所以最终写入了磁盘. 这个是开启事务的一种方式,自动开启和自动提交. InnoDB 里面有一个autocommit的参数(分为两个级别,session级别和global级别). show variables like 'autocommit'; 它的默认值是ON, autocommit 这个参数是什么意思呢? 是否自动提交. 如果它的值是true/on的话, 我们在操作数据的时候,会自动开启一个事务,和自动提交事务. 否则, 如果我们把autocommit 设置成false/off, 那么数据库的事务就需要我们手动的去开启和手动的去关闭. 手动开启事务也有几种方式,一种是用begin，一种是用start transaction. 那怎么结束一个事务呢? 我们结束事务的话也有两种方式: 一种就是提交一个事务,commit. 还有一种就是rollback,回滚的时候, 事务也会结束. 还有一种情况就是客户端连接断开的时候, 事务也会结束. 后面我们会讲到,当我们结束一个事务的是好， 事务持有的锁就会被释放,无论是提交还是回滚. 我们用begin 手动开启一个事务,指定第二个update. 但是数据并没有写入磁盘,因为事务还没有提交,这个时候commit 一下，再刷新一下，ok就写入了. 这个就是开启和结束事务的两种方式. 1.6 事务并发会带来什么问题?当很多事务并发的去操作数据库的表或者行的时候,如果没有我们刚才讲的事务的Isolation 隔离性的时候, 会带来哪些问题呢? 我们有两个事务,一个是Transaction A,一个是Transaction B, 在第一个事务里面,它首先会通过一个wgere id = 1 的条件查询一条数据, 返回name=Ada,age=16 的这条数据,然后第二个事务,它同样是去操作id=1的这行数据，它通过update的语句,把这行id=1的数据的age改成了18, 但是注意, 它并没有提交. 这个时候, 在第一个事务里面,它再次去执行相同的查询操作, 发生数据发生了变化， 获取到的数据age=18, 那么这种在一个事务里面 , 由于其他的事务修改了数据并且没有提交,而导致了前后两次读取到的数据不一致的情况,这种事务并发的问题,我们把它定义成什么? 这个就叫做脏读. 如果在转账的案例中,我们的第一个事务基于读取到的 第二个事务未提交的金额进行了操作,但是第二个事务进行了回滚,这个时候就会导致数据不一致. 这种读取到其他事务未提交的数据的情况,我们把它叫做脏读. 我们再来看第二个. 同样是两个事务,第一个事务通过id=1 查询到了一条数据,然后在第二个事务中, 执行了一个update操作, 这里大家注意一下, 执行了update 之后,通过commit 提交了修改,然后第一个事务读取到了其他事务已经提交的数据,导致前后两次读取到的数据不一致的情况，就像这里,age到底是等于16还是18,那么这种事务并发带来的问题,我们把它叫做什么? 这种一个事务读取到了其他事务已经提交的数据导致前后两次读取到的数据不一致的情况, 我们把它叫做不可重复读. 在第一个事务中执行了一个范围查询,这个时候满足条件的数据只有一条,在第二个事务里面,它插入了一条数据并且提交了,. 重点: 插入了一条数据. 在第一个事务中去查询的时候,它发现多了一条数据,这种情况,我们把它叫做什么? 一个事务前后两次读取数据不一致,是由于其他事务插入数据造成的, 这种情况我们把它叫做幻读 不可重复读和幻读的区别在哪里呢? 不可重复读是修改或者删除,幻读是插入. 小结: 我们刚才讲了事务并发的三大问题,现在来给大家总结一下,无论是脏读还是不可重复读, 还是幻读, 他们都是数据的读一致性的问题,都是在一个事务里面前后两次读取出现了不一致的情况. 读一致性的问题,必须要由数据库提供一定的事务隔离机制来解决,就像我们去饭店吃饭, 基本的设施和卫生保证都是由饭店提供的, 那么我们使用数据库,隔离性的问题也必须由数据库帮助我们解决. 1.7 SQL92标准.所以, 就有很多的数据库专家联合制定了一个标准,也就是说建议数据库厂商都按照这个标准, 提供一定的事务隔离级别, 来解决事务并发的问题,这个就是SQL92 标准. 我们来看一下SQL92标准的官网 http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt __Table_9-SQL-transaction_isolation_levels_and_the_three_phenomena_ _Level__________________P1______P2_______P3________________________ | READ UNCOMMITTED | Possib|e Possib|e Possible | | | | | | | READ COMMITTED | Not | Possibl| Possible | Possible | REPEATABLE READ | Not | Not | Possible | | | Possib|e Possib|e | | | | | | | SERIALIZABLE | Not | Not | Not Possible | |______________________|_Possib|e_Possib|e_________________________| | | | | | |Note: The exclusion of|these p|enomena |or SQL-transactions ex- | ecuting at isolation level SERIALIZABLE is a consequence of the requirement that such transactions be serializable. Changes made to SQL-data or schemas by an SQL-transaction in an SQL-session may be perceived by that SQL-transaction in that same SQL-session, and by other SQL-transactions, or by that same SQL-transaction in other SQL-sessions, at isolation level READ UNCOMMITTED, but cannot be perceived by other SQL-transactions at isolation level READ COMMITTED, REPEATABLE READ, or SERIALIZABLE until the former SQL-transaction terminates with a . Regardless of the isolation level of the SQL-transaction, phenomena P1, P2, and P3 shall not occur during the implied reading of schema definitions performed on behalf of executing an SQL-statement, the checking of integrity constraints, and the execution of referen- tial actions associated with referential constraints. The schema definitions that are implicitly read are implementation-dependent. This does not affect the explicit reading of rows from tables in the Information Schema, which is done at the isolation level of the SQL-transaction. The execution of a may be initiated implicitly by an implementation when it detects the inability to guarantee the serializability of two or more concurrent SQL-transactions. When this error occurs, an exception condition is raised: transaction rollback-serialization failure. The execution of a may be initiated implicitly by an implementation when it detects unrecoverable errors. When such an error occurs, an exception condition is raised: transaction rollback with an implementation-defined subclass code. The execution of an SQL-statement within an SQL-transaction has no effect on SQL-data or schemas other than the effect stated in the General Rules for that SQL-statement, in the General Rules for Subclause 11.8, \"\", and in the General Rules for Subclause 12.3, \"\". Together with serializable execution, this implies that all read opera- tions are repeatable within an SQL-transaction at isolation level SERIALIZABLE, except for: Concepts 69 这里面有一张表格(搜索_iso).里面定义了四个隔离级别, 右边的P1,P2,P3 就是代表事务并发的3个问题,脏读、不可重复度、幻读. Possible 代表在这个隔离级别下, 这个问题有可能发生, 换句话说, 没有解决这个问题,Not Possible 就是解决了这个问题. 我们详细的分析一下这4个隔离级别是怎么定义的. 第一个隔离级别叫做 Read Uncommitted(未提交读): 一个事务可以读取到其他事务未提交的数据, 会出现脏读,所以叫做RU, 它没有解决任何问题. 第二个隔离级别叫做**read Commited(已提交读)**: 也就是一个事务只能读取到其他事务已经提交的数据,不能读取到其他事务未提交的数据,它解决了脏读, 但是还是会出现不可重复读的情况. 第三各隔离级别叫做**Repeatable Read(可重复读)**: 它解决了不可重复读的问题, 也就是在同一个事务里面多次读取到的同样的数据结果是一样的,但是在这个级别下, 没有定义解决幻读的问题. 最后一个就是**Serliablizable(串行化读)**,在这个隔离级别里面,所有的事务都是串行执行的,也就是对数据的操作需要排队,已经不存在事务的并发操作了,所以它解决了所有的问题. 这个是SQL92的标准，但是不同的数据库厂商或者存储引擎的实现有一定的差异,比如Oracle 里面就只有两种RC(以提交读)和Serializable（串行化读）, 那么InnoDB 的实现又是咋么样呢? 1.8 MySQL InnoDB 对隔离级别的支持在MySQL InnoDB 里面，不需要使用串行化的隔离级别去解决所有的问题,那我们来看一下MySQL InnoDB 里面对数据库事务隔离级别的支持程序是什么样的呢? 事务隔离级别 脏读 不可重复读 幻读 未提交读(Read Uncommitted) 可能 可能 可能 已提交读(read Committed) 不可能 可能 可能 可重复读(Repeatable Read) 不可能 不可能 对InnoDB 不可能 串行化(Serializable) 不可能 不可能 不可能 InnoDB 支持的四个隔离级别和SQL92定义的基本一致,隔离级别越高,事务的并发度就越低. 唯一的区别在于,InnoDB 在RR 的级别就解决了幻读的问题,这个也是InnoDB默认使用RR作为事务隔离级别的原因,既保证了数据的一致性, 1.9 两大实现方案那么大家想一下,如果要解决读一致性的问题,保证一个事务中前后两次读取数据结果一致, 实现事务隔离,应该怎么做? 我们有哪一些方法呢? 你的思路是什么样的呢? 总体上说, 我们有两大类的方案： 1.9.1 LBCC第一种,我既然要保证前后读取数据一致,那么我读数据的时候,锁定我要操作的数据,不允许其他的事务修改就行了. 这种方案我们叫做基于锁的并发控制(Lock Based Concurrency Control（LBCC）). 如果仅仅是基于锁来实现事务隔离,一个事务读取的时候不允许其他事务去修改,那就意味着不支持并发的读写操作,而我们的大多数应用都是读多写少的场景,这样会极大的影响操作数据的效率. 1.9.2 MVCC所以我们还有另一种解决方案,如果要让一个事务前后两次读取的数据保持一致,那么我们可以在修改数据的时候给他建立一个备份或者叫快照,后面来读取这个快照就行了,这种方案我们叫做多版本的并发控制 Multi Version Concurrency Control （MVCC）。 MVCC的核心思想是: 我可以查到在我这个事务之前已经存在的数据,及时它在后面已经被修改或者删除了, 在我这个事务之后新增的数据,我查不到. 问题: 这个快照什么时候创建? 读取数据的时候,怎么保证能读取到这个快照而不是最新的数据,这个怎么实现呢? InnoDB 为每行记录记录都实现了两个隐藏字段. DB_TRX_ID: 6个字节, 插入或者更新行的最后一个事务ID,事务编号是自动递增的(我们把它理解为创建版本号， 在数据新增或者修改为新数据的时候,记录当前的事务ID). DB_ROLL_PTR: 7个字节,回滚指针(我们可以把它理解为删除版本号, 数据被删除或记录为旧数据的时候,记录当前事务ID) 我们把这两个事务ID理解为版本号. 第一个事务,初始化数据(检查初始化数据) Transaction 1 begin; insert into mvcctest values(NULL,'qingshan') ; insert into mvcctest values(NULL,'jack') ; commit; 此时的数据, 创建版本是当前事务ID, 删除版本为空 id name 创建版本 删除班恩 1 qingshan 1 undefined 2 jack 1 undefined 第二个事务,执行第1次查询,读取到2条原始数据,这个时候事务ID是2 Transaction 2 begin; select * from mvcctest ; -- (1) 第一次查询 第三个事务, 插入数据 Transaction 3 begin; insert into mvcctest values(NULL,'tom') ; commit; 此时的数据, 多了一条tom,它的创建版本号是当前事务编号 3 id name 创建版本 删除班恩 1 qingshan 1 undefined 2 jack 1 undefined 3 tom 3 undefined 第二个事务, 执行第2次查询 Transaction 2 select * from mvcctest ; (2) 第二次查询 MVCC的查询规则: 只能查找创建时间比小于等于当前事务ID的数据,和删除时间大于当前事务ID的行(或未删除) 也就是不能查找在我的事务开始之后插入的数据,tom的创建ID大于2, 所以换是只能查到2条数据. 第四个事务, 删除数据,删除了id=2 jack的数据 Transaction 4 begin; delete from mvcctest where id=2; commit; 此时的数据,jack的删除版本被记录为当前事务ID:4, 其他数据不变 id name 创建版本 删除班恩 1 qingshan 1 undefined 2 jack 1 4 3 tom 3 undefined 在第二个事务中,执行第3次查询 Transaction 2 select * from mvcctest ; (3) 第三次查询 查找规则: 只能查找创建时间小于当前事务ID的数据, 和删除时间大于当前事务ID的行(或未删除). 也就是说, 在我的事务之后删除的数据,所以jack 仍然可以查出来,所以还是这两条数据. 第五个事务,执行更新操作,这个事务ID是5. Transaction 5 update mvcctest set name ='盆鱼宴' where id=1; commit; 此时的数据,更新数据的时候,旧数据的删除版本被记录为当前事务ID5, 此时产生了一条新数据,创建ID为当前事务ID: 5 id name 创建版本 删除班恩 1 qingshan 1 5 2 jack 1 4 3 tom 3 undefined 1 盆鱼宴 5 undefined 第二个事务, 执行第4次查询 Transaction 2 select * from mvcctest ; (4) 第四次查询 查找规则: 只能查找创建时间小于等于当前事务ID的数据, 和删除时间大于当前事务ID的行(或未删除) 因为更新后的数据盆鱼宴 创建版本大于2, 代表是在事务之后增加的,差不出来. 而旧数据 qingshan 的删除版本大于2, 代表是在事务之后删除的, 可以查出来. 通过以上演示我们能看到,通过版本号的控制,无论其他事务是插入、修改、删除, 第一个事务查询到的数据都没有变化. 在InnoDB中, MVVC 是通过undo log 实现的. Oracle 、Postgrs 等等其他数据库都有MVCC的实现. 需要注意的是, 在InnoDB 中,MVCC和锁是协同使用的,这两种方案并不是互斥的. 第一大类解决的是锁,锁又是怎么实现读一致性的呢? 2. MySQL InnoDB 锁的基本类型https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html This section describes lock types used by InnoDB. Shared and Exclusive Locks Intention Locks Record Locks Gap Locks Next-Key Locks Insert Intention Locks AUTO-INC Locks Predicate Locks for Spatial Indexes 官网把锁分成了8类,所以我们把前面的两个行级别的锁(Shared and Exclusive Locks)和两个表级别的锁(Intention Locks) 称为锁的基本模式. 后面三个是Record Locks、Gap Locks、Next-Key Locks ,我们把它叫做锁的算法,也就是分别在什么情况下锁定什么范围. 2.1 锁的粒度我们讲到InnoDB 里面既有行级别的锁,也有表级别的锁,我们先来分析一下这两种锁定粒度的一些差异. 表锁, 顾名思义, 就是锁住一张表;行锁就是锁住表里面的一行数据, 锁定粒度,表锁肯定是要大于行锁的. 那么加锁效率呢? 表锁应该是大于行锁还是小于行锁呢? 大于, 为什么呢 ? 表锁只需要直接锁住这张表就行了,而行锁,还需要在表里面去检索这一行数据,所以表锁的加锁效率更高. 第二个冲突的概率呢? 表锁的冲突概率比行锁大? 还是小? 大于, 因为当我们锁住一张表的时候,其他任何一个事务都不能操作这张表。但是我们锁住了表里面的一行数据的时候, 其他事务还可以来操作其他没有被锁定的行,所以表锁的冲突概率更大. 表锁的冲突概率更大,所以并发性能更低, InnoDB 里面我们知道它既支持表锁, 也支持行锁,另一个常用的存储引擎MyIASM支持什么粒度的锁呢? 这是第一个问题,第二个就是InnoDB已经支持行锁了,那么它也可以通过把表里面的每一行数据都锁住实现表锁, 为什么还要提供表锁呢? 要搞清楚这个问题,我们就要来了解一下InnoDB 里面的基本的锁的模式(Lock mode), 这里面有两个行锁和两个表锁. 2.2 共享锁第一个行级别的锁就是我们在官网看的Shared Locks(共享锁), 我们获取了这一行数据的读锁之后,可以用来读取数据,所以它也叫做读锁,注意不要在加了读锁以后去写数据,不然的话可能会出现死锁的情况。 而且多个事务可以共享一把锁,那么怎么给一行数据加上读锁呢? 我们可以用select …… lock in share mode; 的方式手动加上一把读锁. 释放锁有两种方式, 只要事务结束，锁就会自动释放, 包括提交事务和结束事务. 我们也来验证一下,看看共享锁是不是可以重复获取. Transaction 1 Transaction2 begin; SELECT * FROM student WHERE id=1 LOCK IN SHARE MODE; begin; SELECT * FROM student WHERE id=1 LOCK IN SHARE MODE; // OK 2.3 排它锁第二个行级别是锁叫做Exclusive Locks(排它锁), 它是用来操作数据段, 所以又叫写锁,只要一个事务获取了一行数据的排它锁,其他的事务就不能获取这一行数据的共享和排它锁. 排它锁的加锁方式有两种: 第一种是自动加排它锁,我们在操作数据的时候, 包括增删改,都会默认加上一个排它锁, 还有一种是手工加锁,我们用一个FOR UPDATE 给一行数据加上一个排它锁,这个无论是在我们的代码里面还是操作数据库的工具里面, 都是比较常见的. 释放锁的方式跟前面是一样的。 排它锁的验证： Transaction 1 Transaction 2 begin; UPDATE student SET sname = &#39;猫老公 555&#39; WHERE id=1; begin; SELECT * FROM student WHERE id=1 LOCK IN SHARE MODE; // BLOCKED SELECT * FROM student where id=1 FOR UPDATE; // BLOCKED DELETE FROM student where id=1 ; 这两个是行锁,接下来就是两个表锁. 2.4 意向锁意向锁是什么呢? 我们好像从来没有听说过, 也没有使用过, 其实他们是由数据库自己维护的. 也就是说,当我们给一行数据进行加上共享锁之前,数据库会自动在这张表上面加一个意向共享锁. 当我们给一行数据加上排它锁之前, 数据库会自动在这张表上加上一个意向排它锁. 反过来说, 如果一张表上至少有一个意向共享锁,说明有其他事务给其中的某些数据行加上了共享锁. 如果一张表上至少有一个意向排它锁,说明有其他的事务给其中的某些数据行加上了排它锁. 那么这两个表级别的锁存在的意思是什么呢? 第一个, 当我们有了表级别的锁,在InnoDB 里面就可以支持更多粒度的锁,它的第二个作用, 我们想一下， 如果说没有意思的话,当我们准备给一张表加上表锁的时候,我们首先要做什么呢？ 是不是必须先去判断有没有别的事务锁定了其中的某些行? 如果有的话,肯定不能加上表锁. 那么这个时候我们就要去扫描整张表才能确定能不能成功加上一个表锁,如果数据量特别大, 比如有上千万的数据的时候, 加表锁的效率是不是很低. 但是我们引入了意向锁之后就不一样了,我只需要判断这种表上有没有意向锁,如果有, 就直接返回失败,如果没有,就可以加锁成功。 所以InnoDB 里面的表锁,我们可以把它理解为一个标志, 就像火车上厕所有没有人使用的灯,是用来提高加锁的效率的. Transaction 1 Transaction 2 begin; SELECT * FROM student where id=1 FOR UPDATE; BEGIN; LOCK TABLES student WRITE; // BLOCKED UNLOCK TABLES; // 释放表锁的方式 以上就是MySQL 里面的4种基本的锁模式,或者叫做锁的类型. 到这里我们要思考两个问题, 首先, 锁的作用是什么?它跟java里面的锁是一样的,是为了解决资源竞争的问题,JAVA里面的资源是对象,数据库的资源就是数据表或者数据行. 所以锁是用来解决事务对数据的并发访问问题的. 那么锁到底锁住了什么呢? 当一个事务锁住了一行数据的时候, 其他事务不能操作这一行数据,那他到底是锁住了这一行数据, 还是锁住了一个字段, 还是锁住了别的什么东西呢? 3. 行锁的原理3.1 没有索引的表(假设锁住记录)首先我们有3张表,一张没有索引的表t1,一张有主键索引的表t2,一张有唯一索引的表t3. CREATE TABLE `t1` ( `id` int(11) DEFAULT NULL, `name` varchar(255) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `t1` (`id`, `name`) VALUES (1, '1'); INSERT INTO `t1` (`id`, `name`) VALUES (2, '2'); INSERT INTO `t1` (`id`, `name`) VALUES (3, '3'); INSERT INTO `t1` (`id`, `name`) VALUES (4, '4'); DROP TABLE IF EXISTS `t2`; CREATE TABLE `t2` ( `id` int(11) NOT NULL, `name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `t2` (`id`, `name`) VALUES (1, '1'); INSERT INTO `t2` (`id`, `name`) VALUES (4, '4'); INSERT INTO `t2` (`id`, `name`) VALUES (7, '7'); INSERT INTO `t2` (`id`, `name`) VALUES (10, '10'); DROP TABLE IF EXISTS `t3`; CREATE TABLE `t3` ( `id` int(11) , `name` varchar(255) , PRIMARY KEY (`id`), UNIQUE KEY `uk_name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `t3` (`id`, `name`) VALUES (1, '1'); INSERT INTO `t3` (`id`, `name`) VALUES (4, '4'); INSERT INTO `t3` (`id`, `name`) VALUES (7, '7'); INSERT INTO `t3` (`id`, `name`) VALUES (10, '10'); 我们先假设InnoDB 的锁锁住了一行记录或者数据 我们先来看一下t1的表结构,int类型的id和varchar类型的name,里面有4条数据.1,2,3,4 Transaction 1 Transaction 2 begin; SELECT * FROM t1 WHERE id =1 FOR UPDATE; select * from t1 where id=3 for update; //blocked INSERT INTO t1 (id, name) VALUES (5, &#39;5&#39;); //blocked 现在我们在两个会话中手动开启两个事务. 在第一个事务里面,我们通过where id = 1 锁住第一行数据 在第二个事务里面, 我们尝试给id=3 这一行数据加锁, 大家觉得能成功吗? 很遗憾,我们能看到这个加锁的操作被阻塞了,这就有点奇怪了,第一个事务锁住了id=1的这行数据, 为什么我不能操作id=3的数据呢? 我们再来操作一条不存在的数据,插入id=5, 它也被阻塞了,实际上这里的整张表都被锁住了所以我们的第一个猜想就被推翻了,InnoDB 的锁锁住了应该不是Record. 那为什么在没有索引或者没有用到索引的情况下,会锁住整张表呢? 这个问题我们先留在这里. 我们继续第二个演示： 3.2 有主键索引的表我们看一下t2的表结构,字段是一样的,不同的地方是id上创建了一个主键索引,里面的数据是1,4,7,10. Transaction 1 Transaction 2 begin; select * from t2 where id=1 for update; select * from t2 where id=1 for update; //blocked select * from t2 where id=4 for update; // OK 第一种情况,使用相同的id值去加锁,冲突. 使用不同的id加锁, 可以加锁成功,那么, 既然不是锁定了一行数据,有没有可能是锁住了id的这个字段呢? 3.1 唯一索引(假设锁住字段)我们看一下t3的表结构,字段还是一样的,id上创建了一个主键索引, name上创建了一个唯一索引,里面的数据为1,4,7,10. Transaction 1 Transaction 2 begin; select * from t3 where name= &#39;4&#39; for update; select * from t3 where name = &#39;4&#39; for update; // blocked select * from t3 where id = 4 for update; // blocked 在第一个事务里面, 我们通过name字段去锁定值是4的这行数据 在第二个事务里面,尝试获取一样的排他锁,肯定是失败的,这个不用怀疑. 在这里我们怀疑InnoDB 锁住的是字段,所以这次我换一个字段, 用id=4去给这行数据加锁, 大家觉得能成功吗？ 很遗憾, 又被阻塞了,说明锁住的是字段的这个推测也是错的,否则就不会出现第一个事务锁住了name,第二个字段锁住id失败的情况. 既然锁住了不是record,也不是column,InnoDB 里面锁住的到底是什么呢? 在这三个案例里面,我们要去分析一下他们的差异在哪里呢? 也就是这三张表的结构,是什么区别导致了加锁行为的差异? 答案其实就是索引,InnoDB 的行锁,就是通过锁住索引来实现的. 那索引又是什么东西呢? 为什么它可以被锁住? 那么我们还有两个问题没有解决? 为什么表里面没有索引的时候,锁住一行数据会导致锁表. 或者说,如果锁住的是索引,一张表没有索引怎么办? 所以, 一张表有没有可能没有索引? 如果我们定义了主键(PRIMARY KEY),那InnoDB 会选择主键作为聚集索引. 如果没有显式定义主键,则InnoDB 会选额第一个不包含有NULL 值的唯一索引作为主键索引. 如果也没有这样的唯一索引, 则InnoDB 会选择内置6字节的ROWID 作为隐藏的聚集索引,他会随着行记录的写入而主键递增. 所以, 为什么锁表,是因为查询没有使用索引,会进行全表扫描,然后把每一个有隐藏的 聚集索引都锁住了. 为什么通过唯一索引给数据行加锁,主键索引也会被锁住. 大家还记得在InnoDB 里面, 当我们使用辅助索引的时候, 他是怎么检索数据的吗? 辅助索引的叶子节点存储的是什么内容呢? 在辅助索引里面,索引存储的是二级索引和主键的值,比如name=4,存储的是name的索引和主键id的值4 而主键索引里面除了索引之外,还存储了完整的数据,所以我们通过辅助索引锁定一行数据的时候, 他跟我们检索数据的步骤是一样的,会通过主键值找到主键索引,然后也锁定. 现在我们已经搞清楚了4个锁的基本类型和锁的原理了,在官网上, 还有3种锁,我们把它理解为锁的算法,我们也来看一下 InnoDB 什么时候分别锁住什么范围呢？ 4. 锁的算法我们先来看一下我们测试的表,t2，这张表有一个主键索引. 我们插入了4行数据, 主键值分别为1，4，7，10 为了让大家真正理解这三种行锁算法的区别,我们需要了解一下三种范围的概念. 因为我们用主键索引加锁,我们这里的划分标准就是主键索引的值. 这些数据库里面存在的主键值,我们把它叫做Record, 记录,那么这里我们就有4个Record 根据主键,这些存在的Record隔开的数据不存在的区间,我们把它叫做Gap,间隙,他是一个左开右开的区间. 最后一个,间隙Gap 连同他左边的记录(Record),我们把他叫做临建的区间, 他是一个左开右闭的区间, t2的主键索引,他是整型的,可以排序,所以才有这种区间,如果我的主键索引不是整型的, 是字符怎么办? 字符可以排序吗? 用ASCII码来排序. 我们已经弄清楚了三个范围的概念,下面我们来看一下在不同的范围下,行锁是怎么表现的. 4.1 记录锁第一种情况,但我们对于唯一性的索引(包含唯一索引和主键索引)使用等值查询, 精准匹配到一条记录的时候， 这个时候使用的就是记录锁. 比如where id = 1 4 7 10. 这个演示我们在前面已经看过了,我们使用不同的key去加锁,不会冲突,他只锁住了这个Record. 4.2 间隙锁第二种情况,当我们查询的记录不存在,没有命中任何一个Record,无论是用等值查询还是范围查询的时候, 他使用的都是间隙锁. 举个例子: where id &gt;4 and id &lt;7，where id = 6。 Transaction 1 Transaction 2 begin; INSERT INTO t2 (id, name) VALUES (5, &#39;5&#39;); // BLOCKEDINSERT INTOt2 (id, name) VALUES (6, &#39;6&#39;); // BLOCKED select * from t2 where id =6 for update; // OK select * from t2 where id &gt;20 for update; INSERT INTO t2 (id, name) VALUES (11, &#39;11&#39;); // BLOCKED 重复一遍,当查询的记录不存在的时候, 使用间隙锁. 注意:间隙锁主要是阻塞插入insert, 相同的间隙锁之间不冲突. Gap Lock 只在RR 中存在,如果要关闭间隙锁,就是把事务隔离级别设置成RC, 并且把innodb_locks_unsafe_for_binlog设置成ON, 这种情况下除了外键约束和唯一性检查会加间隙锁,其他情况都不会用间隙锁. 4.3 临键锁第三种情况,当我们使用了范围查询,不仅仅命中了Record 记录, 还包含了Gap间隙,在这种情况下我们使用的就是临键锁, 他是MySQL 里面默认的行锁算法,相当于记录锁加上间隙锁. 其他两种退化的情况： 唯一性索引, 等值匹配到一条记录的时候，退化成记录锁. 没有匹配到任何记录的时候,退化为间隙锁. 比如我们使用 \\&gt;5 &lt;9, 他包含了记录不存在的区间,也包含了一个Record7. Transaction 1 Transaction 2 begin; select * from t2 where id &gt;5 and id &lt; 9 for update; begin; select * from t2 where id =4 for update; // OK INSERT INTO t2 (id, name) VALUES (6, &#39;6&#39;); // BLOCKED INSERT INTO t2 (id, name) VALUES (8, &#39;8&#39;); // BLOCKED select * from t2 where id =10 for update; // **BLOCKED**` 临键锁, 锁住最后一个key的下一个左开右闭的区间, select * from t2 where id >5 and id 8 and id","categories":[{"name":"mysql","slug":"mysql","permalink":"https://rainsoil.github.io/categories/mysql/"},{"name":"mysql","slug":"mysql/mysql","permalink":"https://rainsoil.github.io/categories/mysql/mysql/"}],"tags":[]},{"title":"MySQL的SQL执行流程(1)","slug":"mysql/MySQL的SQL执行流程(1)","date":"2022-01-04T02:42:07.249Z","updated":"2022-01-04T02:42:07.249Z","comments":true,"path":"2022/01/04/mysql/mysql-de-sql-zhi-xing-liu-cheng-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/mysql/mysql-de-sql-zhi-xing-liu-cheng-1/","excerpt":"","text":"MySQL的执行流程MySQL的发展历史和版本分支 时间 里程碑 1996年 MySQL 1.0发布,它的历史可以追溯到1979年,作者Monty用BASIC设计的一个报表工具 1996年10月 3.11.1 发布, MySQL没有2.0版本 2000年 ISAM升级为MyISAM引擎,MySQL开源 2003年 MySQL4.0 发布,集成了InnoDB存储引擎 2005年 MySQL5.0版本发布,提供了视图、存储过程等功能 2008年 MySQL AB公司被Sun公司收购,进入Sun MySQL时代 2009年 Oracle公司收购Sun公司, 进入Oracle MySQL时代 2010年 MySQL5.5发布,InnoDB 成为默认的存储引擎 2016年 MySQL发布8.0.0版本.为什么没有6、7呢?5.6可以当成6.x, 5.7 可以当成7.x 因为Mysql 是开源的(也有收费版本)，所以在MySQL 稳定版本的基础上也发展出来了很多的分支,就想Linux 一样, 有Ubuntu、RedHat、ContOS、Fedora [fɪ&#39;dɔrə]、 Debian[Deb&#39;-ee-en]等等. 大家最熟悉的应该是MariaDB,因为Contos7 里面自带了一个MariaDB,它是怎么来的呢? Oracle 收购MySQL了之后, MySQL创始人之一Monty担心MySQL数据库的发展的未来(开发缓慢,封闭,可能会被闭源),就创建了一个分支MariaDB,默认使用全新的Maria存储引擎,它是原MyISAM 存储引擎的升级版本. 其他流行分支: Percona Server是MySQL最重要的分支之一,它基于InnoDB存储引擎的基础上,提高了性能和易管理性,最后形成了增强版的XtraDB 引擎, 可以用来更好的发挥服务器硬件上的性能. 国内有一些MySQL的分支或者自研的存储引擎,比如网易的InnoSQL、极数云舟的ArkDB. 我们操作数据库有各种各样的方式,比如Linux 系统中的命令行,比如数据库工具Navicat、比如程序,例如Java语言中的JDBC API 或者ORM框架. 大家有没有思考过,当我们的工具或者程序连接上数据库之后,实际上发生了什么事情呢? 它的内部是怎么工作的呢? 以一条查询语句为例,我们来看下MySQL的工作流程是怎么样的? 一条查询SQL语句是怎么执行的? 我们的程序或者工具要操作数据库,第一步要做什么事情呢? 跟数据库建立连接 1 通讯协议首先,MySQL 必须运行一个服务,监听默认的3306端口. 在我们开发系统跟第三方对接的时候, 必须要弄清楚的有两件事情. 第一个就是通讯协议, 比如我们使用的是HTTP 还是WebService还是TCP. 第二个是消息格式,比如我们用XML 格式还是JSON格式, 还是定长格式? 报文头长度多少,包含什么内容,每个字段的详细含义 . 1.1 通讯协议MySQL 是支持多种通信协议的,可以使用同步/异步的方式, 支持长连接/短连接,这里我们拆分来看,第一个是通讯类型. 通讯类型:同步或者异步同步通信的特点: 同步通信依赖于被调用方,受限于被调用方的性能,也就是说,应用操作数据库,线程会阻塞,等待数据库的返回. 一般只能做到一对一的, 很难做到一对多的通信. 异步跟同步相反: 异步可以避免应用阻塞,但是不能节省SQL执行的时间 如果异步存在并发,每一个SQL的执行都要单独建立一个连接,避免数据混乱.但是这样会给服务器带来巨大的压力(一个连接就会创建一个线程,线程间切换会占用大量的CPU资源).另外异步通信还带来的编码的复杂度,所以一般不建议使用. 如果要使用异步, 必须使用连接池,排队从连接池获取连接而不是创建新连接. 一般来说, 我们连接数据库都是同步连接. 连接方式:长连接或者短连接MySQL既支持短连接,也支持长连接. 短连接就是操作完毕以后, 马上close掉. 长连接可以保持打开,减少服务器创建和释放连接的消耗 ,后面的程序访问的时候还可以使用这个连接. 一般我们会在线程池中使用长连接. 保持长连接会消耗内存,长时间不活动的连接,MySQL服务器会断开. show global variables like 'wait_timeout'; -- 非交互式超时时间，如 JDBC 程序 show global variables like 'interactive_timeout'; -- 交互式超时时间，如数据库工具 默认都是28800秒,8个小时. 那我们怎么看MySQL当前有多少个连接呢? 可以使用show status 命令查看 show global status like 'Thread%'; Threads_cached: 缓存中线程连接数 Threads_connected： 当前打开的连接数 Threads_created:为处理连接创建的线程数 Threads_running: 非睡眠状态的连接数,通常指并发连接数. 每产生一个连接或者一个会话,在服务端会创建一个线程来处理. 反过来,如果要杀死会话, 那就Kill 线程. 有了连接数,怎么知道当前连接的状态? 可以使用SHOW PROCESSLIST;(root用户), 查看SQL的执行状态. https://dev.mysql.com/doc/refman/5.7/en/show-processlist.html 一些常见的状态: https://dev.mysql.com/doc/refman/5.7/en/thread-commands.html 状态 含义 Sleep 线程正在等待客户端,以向他发送一个新语句 Query 线程正在执行查询或者往客户端发送数据 Locked 该查询被其它查询锁住 Copying to tmp table on disk 临时结果集合大于tmp_table_size, 线程把临时表从存储器内部格式改为磁盘模式,以节省存储器 Sending data 线程正在为select 语句处理行,同时正在向客户端发送数据 Sorting for group 线程正在分类,以满足GROUP BY要求 Sorting for order 线程正在分类,以满足ORDER BY 要求 MySQL服务允许的最大连接数是多少 呢? 在5.7版本中， 默认是151个,最大可以设置为16384（2^14） show variables like 'max_connections'; show的参数说明： 级别: 会话session级别(默认),全局global 级别 动态修改: set 重启后失败; 永久生效需要修改配置文件/etc/my.cnf set global max_connections = 1000; 通讯协议 MySQL支持哪些通信协议呢? 第一种是Unix Socket 比如我们在linxu服务器上,如果没有指定-h参数,它就用socket方式登录(省略了-S /var/lib/mysql/mysql.sock) 它不用通过网络协议,也可以连接到MySQL服务器,它需要用到服务器上的一个物理文件(/var/lib/mysql/mysql.sock). select @@socket; 如果指定了-h参数,就会用第二种方式,TCP/IP协议. mysql -h 192.168.56.20 -uroot -pluyanan 我们的编程一眼的连接模块都是通过TCP协议连接到MySQL服务器的,比如mysql-connector-java-x.x.xx.jar 另外还有命名管道(Named Pipes)和内存共享(Share Memory) 的方式,这两种通讯方式只能在Window 上使用,一般用到较少. 1.2 通讯方式第二个是通讯方式 单工: 在两台计算机通信的时候,数据的传输是单向的,生活中的类比: 遥控器. 半双工: 在两台计算机之间, 数据传输是双向的,你可以给我发送,我也可以给你发送,但是在这个通讯连接中,同一个时间只能有一台服务器在发送数据,也就是你要给我发送的话, 也必须等我发给你完了之后你才能给我发。 生活中的类比: 对讲机. 全双工: 数据的传输是双向的, 而且可以同时传输. 生活中的类比: 打电话. MySQL使用了半双工的通信方式? 要么是客户端向服务端发送数据,要么是服务端向客户端发送数据,这两个动作不能同时发生,所以客户端发送SQL给服务端的时候(在一次连接中), 数据是不能分成小块发送的,不管你的SQL语句多大, 都不能一次性发送. 比如我们用Mybatis 动态SQL生成一个批量插入的语句,插入100W条数据,values 后面跟了一长串的内容, 或者where条件in 里面的值太多了,会出现问题. 这个时候我们必须调整MySQL服务器配置的max_allowed_packet参数的值(默认是4M)，把它调大, 否则就会报错. 另一方面,对于服务端来说,也是一次性发送所有的数据,不能因为你已经取到想要的数据就中断操作,这个时候会对网络和内存产生大量的消耗. 所以, 我们一定要再程序里面避免不带limit 的这种操作,比如一次性把满足条件的数据全部查出来,一定要先count一下,如果数据量大的话, 可以分批查询. 执行一条查询语句, 客户端跟服务端建立连接后,下一步要做什么呢? 2 查询缓存MySQL 内部自带了一个缓存模块. 缓存的作用我们知道，把数据以KV的形式放到内存中,可以加快数据的读取速度,也可以减少服务器处理的时间.但是MySQL的缓存我们好像比较陌生,从来没有去配置过,也不知道它什么时候生效? 比如user_innodb 有500W条数据, 没有索引,我们在没有索引的字段上执行同样的查询,大家觉得第二次会快吗? select * from user_innodb where name='张三'; 发现第二次速度并没有快, 缓存没有生效,为什么呢? MySQL 的缓存默认是关闭的, show variables like 'query_cache%'; 默认关闭的意思就是不推荐使用,为什么MySQL不推荐使用它自带的缓存呢? 主要是因为MySQL自带的缓存的应用场景有限,第一个是他要求SQL语句必须一模一样,中间多一个空格,字母大小写不同都被认为是不同的SQL. 第二个就是表里面的任意一条数据发生变化的时候,这种表的所有的缓存都会失效,所以对于有大量数据更新的场景,也不适合. 所以缓存这块,我们还是交给ORM框架(比如Mybatis 默认开启了一级缓存), 或者独立的缓存服务,比如Redis来处理更合适. 在MySQL8.0 中，查询缓存已经被移除了. 3 语法解析和预处理(Parser &amp; Preprocessor)我们没有使用缓存的话, 就会跳过缓存的模块,那下一步我们要做什么呢? 这里有一个疑问, 为什么我的一条SQL语句能够被识别呢? 假设我随便执行一个字符串aaa, 服务端就会报出一个1064的错. 它是怎么知道我输入的内容是错误的呢? 这个就是MySQL的Parser 解析器和PreProcessor 预处理模块. 这一步主要做的事情就是对语句基于SQL的语法进行词法和语法分析和语义的解析. 3.1 词法解析词法分析就是把一个完整的SQL 语句打碎成一个个的单词. 比如一个简单的SQL语句 select name from user where id = 1; 它会被打碎成8个符号, 每个符号是什么类型? 从哪里开始到哪里结束. 3.2 语法解析第二步就是语法分析, 语法分析就会SQL做一些语法检查,比如单引号有没有闭合,然后根据MySQL定义的语法规则,根据SQL生成一个数据结构,这个数据结构我们把它叫做解析数(select_lex). 任何数据库的中间件,比如Mycat、Sharding-JDBC(用到了Druid Parser),都必须要有词法和语法分析功能,在市面上也有很多的开源的词法解析的工具(比如LEX、Yacc). 3.3 预处理器问题:如果我写了一个语法和词法都正确的SQL,但是表名或者字段都不存在,会在哪里报错呢? 是在数据库的执行层还是解析器? 比如: select * from user2; 解析器可以分析语法, 但是它怎么知道数据库里面有什么表? 表里面有什么字段呢? 实际上还是在解析的时候报错, 解析SQL的环节里面有个预处理器. 它会检查生成的解析树, 解决解析器无法解析的语义. 比如他会检查表和列表是否存在, 检查名称和别名,保证没有歧义. 预处理之后得到一个新的解析数. 4 查询优化(Query Optimizer)和查询执行计划4.1 什么是优化器?得到解析树之后,是不是执行SQL语句了呢? 这里我们有一个问题, 一条SQL语句是不是只有一种执行方式? 或者说数据库最终执行的SQL是不是就是我们发送的SQL呢? 这个答案是否定的, 一条SQL 语句是可以有很多种执行方式的,最终返回相同的结果, 他们是等价的,但是如果有那么多的执行方式,这些执行方式最终是怎么得到呢? 最终选择哪一种方式去执行? 根据什么判断标准去选择&gt; 这个就是MySQL的查询优化器的模块Query Optimizer 查询优化器的目的就是根据解析数生成不同的执行计划(Execution Plan),然后选出一种最优的执行计划,MySQL里面使用的是基于开销(cost)的优化器,那种执行计划开销最小, 就用哪种? 可以使用这个命令查看查询的开销 show status like 'Last_query_cost'; https://dev.mysql.com/doc/refman/5.7/en/server-status-variables.html 4.2 优化器可以做什么? MySQL的优化器能处理那些优化类型呢? 举两个简单的例子: 当我们对多张表进行关联查询的时候,以哪个表的数据作为基准表. 有多个索引可以使用的时候,选择哪个索引. 实际上,对于每一种数据库来说,优化器的模块都是必不可少的,他们通过复杂的算法尽可能优化查询效率的目标. 如果对于优化器的细节感兴趣,可以看看《数据库查询优化器的艺术-原理解析与SQL 性能优化》。 但是优化器也不是万能的,并不是再垃圾的SQL语句都能自动优化,也不是每次都能选择到最优的执行计划,大家在编写SQL的时候还是要注意的. 如果我们想知道优化器是怎么工作的,它生成了几种执行计划,每种执行计划是cost是多少? 应该怎么做? 4.3 优化器是怎么得到执行计划的?https://dev.mysql.com/doc/internals/en/optimizer-tracing.html 首先我们要启动优化器的追踪(默认是关闭的) SHOW VARIABLES LIKE 'optimizer_trace'; set optimizer_trace='enabled=on'; 注意开启这开关是会消耗性能的,因为他要把优化分析的结果写到表里面,所以不要轻易开启,或者查看完之后关闭它(搞改成off). 注意:参数分为session和global级别. 接着我们执行一个SQL语句,优化器就会生成执行计划 . select t.tcid from teacher t,teacher_contact tc where t.tcid = tc.tcid; 这个时候优化器分析的过程已经记录到系统表里面了, 我们可以查询 select * from information_schema.optimizer_trace\\G 它是一个JSON类型的数据，主要分为三部分, 准备阶段、优化阶段、执行阶段. expanded_query是 优化后的SQL语句. considered_execution_plans 里面列出了所有的执行计划. 分析玩了之后记得关闭它. set optimizer_trace=\"enabled=off\"; SHOW VARIABLES LIKE 'optimizer_trace'; 4.4 优化器得到的结果优化完之后,得到一个什么东西呢? 优化器最终会把解析树变成一个查询执行计划,查询执行计划是一个数据结构. 当然, 这个执行计划是不是一定是最优的执行计划呢? 不一定, 因为MySQL也有可能覆盖不到所有的执行计划. 我们怎么查看MySQL的执行计划呢? 比如多张表关联查询,先查询哪张表? 在执行查询的时候可能用到哪些索引? 实际上用到了哪些索引? MySQL 提供了一个执行计划的工具,我们在SQL语句前加上EXPLAIN, 就可以看到执行计划的信息. EXPLAIN select name from user where id=1; 注意: Explain的结果也不一定是最终执行的方式. 5 存储引擎得到执行计划后,SQL语句是不是就可以执行了呢? 问题又来了: 从逻辑的角度来说, 我们的数据是放到哪里? 或者说放到一个什么样的结构里面呢? 执行计划在哪里执行? 是谁去执行? 5.1 存储引擎基本介绍我们先回答第一个问题: 在关系型数据库里面,数据是放到什么结构里? 放到表Table里面的. 我们可以把表理解为Excel 电子表格的形式,所以我们的表在存储数据的同时,还要组织数据的存储结构,这个存储结构就是由我们的存储引擎决定的,所以我们也可以把存储引擎叫做表类型. 在MySQL里面,支持多种存储引擎,他们是可以相互替换的,所以叫做插件式的存储引擎,为什么要搞这么多的存储引擎呢? 一种还不够用吗? 5.2 查看存储引擎比如我们数据库里面已经存在的表,我们怎么查看他们的存储引擎呢? show table status from `库名`; 或者通过DDL 建表语句查看 在MySQL里面, 我们创建的每一张表都可以指定它的存储引擎,而不是一个数据库只能使用一个存储引擎. 存储引擎的使用是以表为单位的,而且,创建表之后还可以修改存储引擎. 我们说一张表使用存储引擎决定我们存储数据的结构,那在服务器上他们是怎么储存的呢? 我们先要找到数据库存放数据的路径. show variables like 'datadir'; 默认情况下，每个数据库都有自己的一个文件夹, 任何一个存储引擎都有一个frm 文件, 这个是表结构定义文件., 不同的存储引擎存储数据的方式是不一样的,产生的文件也是不一样的,innodb是一个,memory没有,myisam是两个. 这些存储引擎是差别在哪里呢? 5.3 存储引擎比较常见的存储引擎: MyISAM 和Innodb是我们用的最多的两个存储引擎,在MySQL5.5 版本之前,默认的存储引擎是MyISAM,它是MySQL自带的,我们创建表的时候不指定存储引擎,它就会使用MyISAM作为存储引擎. MyISAM的前身是 ISAM（Indexed Sequential Access Method: 利用索引, 顺序读取数据的方法). 5.5 版本之后默认的存储引擎就改成了InnoDB,它是第三方公司为MySQL开发的,为什么要改呢? 最主要的原因是InnoDB 支持事务, 支持行级别的锁,对于业务一致性要求高的场景来说更适合. 这个里面又有 Oracle 和 MySQL 公司的一段恩怨情仇。 InnoDB 本来是 InnobaseOy 公司开发的，它和 MySQL AB 公司合作开源了 InnoDB 的代码。但是没想到 MySQL 的竞争对手 Oracle 把 InnobaseOy 收购了。 后来 08 年 Sun 公司（开发 Java 语言的 Sun）收购了 MySQL AB，09 年 Sun 公司 又被 Oracle 收购了，所以 MySQL，InnoDB 又是一家了。有人觉得 MySQL 越来越像 Oracle，其实也是这个原因。 那么除了这两个我们最熟悉的存储引擎,数据库还支持其他哪些常用的存储引擎呢? 数据库支持的存储引擎? 我们可以用这个命令查看数据库对存储引擎的支持情况. show engines ; 其中有存储引擎的描述和对事物、XA协议和Savepoints的支持. XA 协议用来实现分布式事务(分为本地资源管理器、事务管理器) Savepoints 用来实现子事务(嵌套事务), 创建了一个Savepoints之后,事务就可以回滚到这个点, 不会影响到创建Savepoints之前的操作. 这些数据库支持的存储引擎,分别有哪些特性? https://dev.mysql.com/doc/refman/5.7/en/storage-engines.html MyISAM（3 个文件） These tables have a small footprint. Table-level locking limits the performance in read/write workloads, so it is often used in read-only or read-mostly workloads in Web and data warehousing configurations 应用范围比较小,表级别锁定限制了读/写的性能, 因此在web和数据仓库配置中,它通常只用于只读或者以读为主的工作. 特点: 支持表级别的锁(插入/更新会锁表), 不支持事务. 拥有较高的插入(insert)和查询(select)的速度. 存储了表的行数(count的速度更快) (怎么向数据库快速插入100W条数据呢? 我们可以先用MyISAM插入数据, 然后修改存储引擎为InnoDB的操作) 适合: 只读之类的数据分析项目. InnoDB（2 个文件）https://dev.mysql.com/doc/refman/5.7/en/innodb-storage-engine.html The default storage engine in MySQL 5.7. InnoDB is a transaction-safe (ACID compliant) storage engine for MySQL that has commit, rollback, and crash-recovery capabilities to protect user data. InnoDB row-level locking (without escalation to coarser granularity locks) and Oracle-style consistent nonlocking reads increase multi-user concurrency and performance. InnoDB stores user data in clustered indexes to reduce I/O for common queries based on primary keys. To maintain data integrity, InnoDB also supports FOREIGN KEY referential-integrity constraints. mysql5.7 中默认的存储引擎, InnoDB是一个事务安全(与ACID兼容)的MySQL存储引擎,它具有提交、回滚和崩溃恢复的功能来保护用户数据.InnoDB 行级锁(不升级为更粗粒度的锁)和Oracle风格的一致非锁读提高了多用户并发性和性能. innoDB 将用户数据存储在聚集索引中,以减少基于主键的常见查询的I/O, 为了保持数据完整性, InnoDB还支持外键引用完整性约束. 特点: 支持事务,支持外键,因此数据的完整性、一致性更高, 支持行界别的锁和表级别的锁. 支持读写并发,写不阻塞读(MVCC)， 特殊的索引存放方式,可以减少IO,提升查询效率. 适合: 经常更新的表,存在并发读写或者有事务处理的业务系统. Memory（1 个文件） Stores all data in RAM, for fast access in environments that require quick lookups of non-critical data. This engine was formerly known as the HEAP engine. Its use cases are decreasing; InnoDB with its buffer pool memory area provides a general-purpose and durable way to keep most or all data in memory, and NDBCLUSTER provides fast key-value lookups for huge distributed data sets 将所有数据都存储在RAM中,以便在需要快速查找非关键数据的环境中快速访问. 这个引擎以前被称为堆引擎. 其使用案例正在减少,InnoDB 及其缓冲池内存区域提供了一种通用、持久的方法来将大部分或所有的数据都保存在内存中,而ndbcluster 为大型分布式数据集提供了快速的键值查找. 特点： 把数据放在内存中,读写速度很快,但是数据库重启或者崩溃, 数据会全部消失, 只适合做临时表. 将表中的数据存储到内存中. CSV（3 个文件） Its tables are really text files with comma-separated values. CSV tables let you import or dump data in CSV format, to exchange data with scripts and applications that read and write that same format. Because CSV tables are not indexed, you typically keep the data in InnoDB tables during normal operation, and only use CSV tables during the import or export stage. 它的表实际上是带有逗号分隔的文本文件,csv表允许以csv 格式导入或者转储数据, 以便以读写相同格式的脚本和应用程序交换数据. 因为csv表没有索引,所以通常在正常操作期间将数据保存在innoDB表中,并且只在导入或者导出阶段使用csv., 特点: 不允许空行,不支持索引 格式通用,可以直接编辑,适合在不同数据库之间导入导出. Archive（2 个文件） These compact, unindexed tables are intended for storing and retrieving large amounts of seldom-referenced historical, archived, or security audit information. 这些紧凑的未索引的表用于存储和检索大量很少引用的历史、存档和安全审计信息, 特点： 不支持索引, 不支持update delete 这是MySQL里面常见的一些存储引擎,我们看到了, 不同的存储疫情提供的特性不一样,他们有不同的存储机制、索引方式、锁定水平等功能. 我们在不同的业务场景中对数据操作的要求不同,就可以选择不同的存储引擎来满足我们的需求, 这个就是MySQL支持那么多存储引擎的原因. 5.4 如何选择存储引擎?如果对数据一致性要求比较高,需要事务支持,可以选择InnoDB. 如果数据查询多更新少,对查询性能要求比较高,可以选择MyIASM 如果需要一个用于查询的临时表,可以选择Memory. 如果所有的存储引擎都不能满足你的要求,并且技术能力足够,可以根据官网内部手册用C语言开发一个存储引擎. https://dev.mysql.com/doc/internals/en/custom-engine.html 6 执行引擎(Query Execution Engine),返回结果.OK,存储引擎分析完了,它是我们存储数据的形式,继续第二个问题,是谁使用执行计划去操作执行引擎呢? 这就是我们的执行引擎, 它利用存储引擎提供的相应的API 来完成操作. 为什么我们修改了表的存储引擎,操作方式不需要做任何改变? 因为不同功能的存储引擎实现的API是相同的。 最后将数据返回给客户端,即使没有结果也是要返回的.","categories":[{"name":"mysql","slug":"mysql","permalink":"https://rainsoil.github.io/categories/mysql/"},{"name":"mysql","slug":"mysql/mysql","permalink":"https://rainsoil.github.io/categories/mysql/mysql/"}],"tags":[]},{"title":"JVM之运行时数据区(2)","slug":"jvm/JVM之运行时数据区(2)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/jvm/jvm-zhi-yun-xing-shi-shu-ju-qu-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/jvm/jvm-zhi-yun-xing-shi-shu-ju-qu-2/","excerpt":"","text":"JVM之运行时数据区1. 结合字节码指令理解java虚拟机栈和栈帧 官网: https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.6 栈帧: 每个栈帧对应一个被调用的方法, 可以理解为一个方法的运行空间. 每个栈帧包括局部变量表(Local Variables)、操作数栈(Operated Stack)、指向运行时常量池的引用((A reference to the run-time constant pool)、方法返回地址(Return Address) 和附加信息 局部变量表: 方法中定义的局部变量以及方法的参数都存放在这张表中 局部变量表中的变量不可以直接使用,如需要使用的话,必须通过相关指令将其加载至操作数栈中作为操作数使用. 操作数栈: 以压栈和出栈的方式存储操作数 动态链接 : 每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法的引用,持有这个引用是为了支持方法调用过程中的动态连接(Dynamic Linking) 方法返回地址: 当一个方法开始执行后,只有两种方式可以退出,一种是遇到方法返回的字节码指令,一种是遇见异常,并且这个异常没有在方法体中得到处理. 准备一个Person.java 类 public class Person &amp;#123; private String name = \"Jack\"; private int age; private final double salary = 100; private static String address; private final static String hobby = \"Programming\"; public void say() &amp;#123; System.out.println(\"person say...\"); &amp;#125; public static int calc(int op1, int op2) &amp;#123; op1 = 3; int result = op1 + op2; return result; &amp;#125; public static void order() &amp;#123; &amp;#125; public static void main(String[] args) &amp;#123; calc(1, 2); order(); &amp;#125; &amp;#125; 生成字节码指令, 可以使用javap 我们到jdk的bin目录下 .\\javap.exe -c .\\Person > D://Person.txt Compiled from \"Person.java\" public class com.jvm.Person &amp;#123; public com.jvm.Person(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init>\":()V 4: aload_0 5: ldc #2 // String Jack 7: putfield #3 // Field name:Ljava/lang/String; 10: aload_0 11: ldc2_w #4 // double 100.0d 14: putfield #6 // Field salary:D 17: return public void say(); Code: 0: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #8 // String person say... 5: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return public static int calc(int, int); Code: 0: iconst_3 // 将int类型常量3 压入[操作数栈] 1: istore_0 // 将int 类型的值存入[局部变量0] 2: iload_0 // 从[局部变量0]中装载int 类型值入栈 3: iload_1 // 从[局部变量1] 中装载int类型入栈 4: iadd // 将栈顶元素弹出栈,执行int类型的加法,结果入栈 5: istore_2 // 将栈顶int 类型值保存到[局部变量2]中 6: iload_2 // 从[局部变量2] 中装载int类型值入栈 7: ireturn // 从方法中返回int类型的数值 public static void order(); Code: 0: return public static void main(java.lang.String[]); Code: 0: iconst_1 1: iconst_2 2: invokestatic #10 // Method calc:(II)I 5: pop 6: invokestatic #11 // Method order:()V 9: return &amp;#125; 此时, 你需要有一个能够看懂反编译指令的宝典, 比如官网的： https://docs.oracle.com/javase/specs/jvms/se8/html/index.html. 当然网上也有好多, 大家也可以自行查找. 2. 折腾一下2.1 栈指向堆如果在帧栈中有一个变量, 类型为引用类型,比如Object obj = new Object(); , 这个时候就是典型的栈中元素指向堆中的对象. 2.2 方法区指向堆方法区中会存放静态变量、常量等数据,如果是下面这种情况,就是典型的方法区中元素指向堆中的对象. private static Object obj=new Object(); 2.3 堆指向方法区方法区中会保存类的信息,堆中会有对象,那怎么直到对象是哪个类创建的呢? 思考: 一个对象怎么知道它是由哪个类创建出来的? 怎么记录? 这就需要了解一个java对象的具体信息了. 2.4 Java对象内存布局一个java对象在内存中包括3部分: 对象头、实例数据和对齐填充 3. 内存模型3.1 图解一块是非堆区, 一块是堆区, 堆区分为两大块, 一个是old 区, 一个是Young 区 Young区分为两大块,一个是Survivor区(s0+s1),一块是Eden区. Eden:s0:s1=8:1:1 S0 和S1 一样大, 也可以叫做From 和To 根据之前对Heap 的介绍可以知道,一般对象和数组的创建会在堆中分配内存空间,关键是堆中有那么多的区域, 那一个对象的创建到底在哪个区域呢? 3.2 对象创建所在区域一般情况下,新创建的对象都会被分配到Eden区, 一般特殊的大的对象会直接分配到Old 区 比如有对象A.B.C 等创建在Eden区,但是Eden区的内存空间肯定有限,比如有100M, 假如已经使用了100M 或者达到一个设定的临界值,这时候就需要对Eden 内存空间进行清理,即垃圾回收(Garbage Collect), 这样的GC 我们称之为Minor GC,Minor GC 指的是Young区的GC. 经过GC 之后, 有些对象就会被清理掉,有些对象可能还存活者,对于存活着的对象需要将其复制到Survivor区,然后再清理Eden 区中的对象. 3.3 Survivor 区详解由图解可以看出,Survivor 可以分为两块, S0 和s1, 也可以叫做From 和To 在同一个时间点,S0和s1 只能有一个区有数据,另外一个是空的, 接着上面的gc 来说,比如一开始只有Eden区和From 中有对象, To 中是空的, 此时进行一次gc操作,From 区中的对象年龄就是+1,我们知道Eden 区中所有存活的对象会被复制到To 区,From 区中还能存活的对象会有两个去处. 若对象年龄达到之前设置好的年龄阈值,此时对象会被移动到Old区, 此时Eden 区和From 区没有达到阈值的对象会被复制到To区,此时Eden区和From 区已经被清空(被gc 的对象肯定没了,没有被gc的对象都有了各自的去处). 这时候From 和To 交换角色,之前的From 变成了To, 之前的To 变成了From. 也就是说, 无论如何都要保证名为To的Survivor 区域是空的. Minor GC 会一直重复这样的过程,直到To区被填满,然后会将对象复制到老年代. 3.4 Old 区详解从上面的分析可以看出, 一般Old 区都是年龄比较大的对象,或者相对超过了某个阈值的对象, 在Old 区也会有GC的操作,Old 区的gc 我们称之为Major GC 3.5 对象的一辈子理解我是一个普通的java对象,我出生在Eden区,在Eden 区我还看到和我长的很像的小兄弟,我们在Eden 区中玩了挺长的时间,有一天Eden 区中的人实在太多了,我就被迫去了Survivor区的From 区, 自从去了Survivor 区,我就开始漂了,有时候在Survivor 的From区， 有时候在Survivor 的To区,居无定所,直到我18岁的时候,爸爸说我成人了,该去社会上去闯闯了, 于是我就去了老年代那里,老年代里, 人很多,并且年龄都很大,在这里我也认识了很多人,在老年代里， 我生活了20年(每次GC 加一岁), 然后被回收. 3.6 常见问题 如何理解Minor/Major/Full GC Minor GC: 新生代 Major GC: 老年代 Full GC: 新生代和老年代 为什么需要Survivor区? 只有Eden区不行吗? 如果没有Survivor , Eden 区每进行一次Minor GC, 并且没有年龄限制的话,存活的对象就会被送到老年代, 这样一来,老年代很快被填满,触发Major GC(因为Major GC 一般伴随着Minor GC, 也可以看作触发了Full GC) 老年代的内存空间远大于新生代,进行一次Full GC 消耗的时间比Minor GC长的多. 执行时间长有多少坏处呢? 频发的Full GC 消耗的时间很长,会影响大型程序的执行和响应速度. 可能你会说,那就对老年代的空间进行增加或者较少呢? 假如增加老年代空间,更多存活对象才能填满老年代，虽然降低Full GC频率,但是随着老年代的空间加大,一旦发生Full GC,执行所需要的时间更长. 假如减少老年代空间,虽然Full GC所需时间减少,但是老年代很快就被存活对象填满,Full GC 频率增加. 所以Survivor 的存在意义,就是减少被送到老年代的对象, 进而减少Full GC 的发生,Survivor 的预筛选保证, 只有经历16次Minor GC 还能在新生代中存活的对象,才会被送到老年代. 为什么会需要两个Survivor区? 最大的好处就是解决了碎片化,也就是说为什么一个Survivor区不行? 第一部分中, 我们知道了必须设置Survivor区,假设现在只有一个Survivor区,我们来模拟一下流程: 刚刚创建的对象在Eden 中, 一旦Eden 满了,触发一次Minor GC,Eden 中存活的对象就会被移动到Survivor 区, 这样继续循环下去, 下一个Eden 满了的时候,问题来了,此时进行Minor GC,Eden和Survivor 各有一些存活的对象,如果此时把Eden 区的存活对象硬放到Survivor区, 很明显这两部分对象所占用的内存是不连续的,也就导致了内存碎片化. 永远有一个Survivor space 是空的, 另一个是非空的Survivor space 无碎片化 新生代中Eden:s0:s1为什么是8:1:! 新生代中的可用内存: 复制算法用来担保的内存为9:1 可用内存中Eden:s1区为8:1 即新生代中Eden:s1:s2=8:1:1 4. 体验与验证4.1 使用jvisualvm查看jvisualvm 插件下载链接: https://visualvm.github.io/pluginscenters.html –&gt; 选择对应版本的链接-&gt; Tools –&gt; Visual GC 若上述链接找不到合适的,大家也可以自己在网上下载对应的版本。 4.2 堆内存溢出4.2.1 代码示例@RestController public class HeapController &amp;#123; List&lt;Person> peoples = new ArrayList&lt;>(); @GetMapping(\"heap\") public String heap() throws InterruptedException &amp;#123; while (true) &amp;#123; peoples.add(new Person()); Thread.sleep(1); &amp;#125; &amp;#125; &amp;#125; 4.2.2 访问测试为了设置参数比如: -Xmx20M -Xms20M 访问heap 接口发现 Exception in thread \"http-nio-8080-exec-2\" java.lang.OutOfMemoryError: GC overhead limit exceeded 4.3 方法区内存溢出4.3.1 需要依赖&lt;dependency> &lt;groupId>asm&lt;/groupId> &lt;artifactId>asm&lt;/artifactId> &lt;version>3.3.1&lt;/version> &lt;/dependency> 4.3.2 工具类,不断的生成类public class MetaspaceUtil extends ClassLoader &amp;#123; public static List&lt;Class&lt;?>> createClasses() &amp;#123; List&lt;Class&lt;?>> classes = new ArrayList&lt;Class&lt;?>>(); for (int i = 0; i &lt; 10000000; ++i) &amp;#123; ClassWriter cw = new ClassWriter(0); cw.visit(Opcodes.V1_1, Opcodes.ACC_PUBLIC, \"Class\" + i, null, \"java/lang/Object\", null); MethodVisitor mw = cw.visitMethod(Opcodes.ACC_PUBLIC, \"&lt;init>\", \"()V\", null, null); mw.visitVarInsn(Opcodes.ALOAD, 0); mw.visitMethodInsn(Opcodes.INVOKESPECIAL, \"java/lang/Object\", \"&lt;init>\", \"()V\"); mw.visitInsn(Opcodes.RETURN); mw.visitMaxs(1, 1); mw.visitEnd(); MetaspaceUtil test = new MetaspaceUtil(); byte[] code = cw.toByteArray(); Class&lt;?> exampleClass = test.defineClass(\"Class\" + i, code, 0, code.length); classes.add(exampleClass); &amp;#125; return classes; &amp;#125; &amp;#125; 4.2.3 代码@RestController public class NonHeapController &amp;#123; List&lt;Class&lt;?>> classes = new ArrayList&lt;>(); @GetMapping(\"nonheap\") public String nonHeap() throws InterruptedException &amp;#123; while (true) &amp;#123; classes.addAll(MetaspaceUtil.createClasses()); Thread.sleep(1); &amp;#125; &amp;#125; &amp;#125; 设置Metaspace的大小，比如-XX:MetaspaceSize=50M -XX:MaxMetaspaceSize=50M 4.2.4 验证访问nonheap 接口发现 java.lang.OutOfMemoryError: Metaspace at java.lang.ClassLoader.defineClass1(Native Method) ~[na:1.8.0_191] at java.lang.ClassLoader.defineClass(ClassLoader.java:763) ~[na:1.8.0_191] 4.3 虚拟机栈4.3.1 代码演示public class StackOverFlowDemo &amp;#123; public static long count = 0; public static void method(long count) &amp;#123; System.out.println(count++); method(count); &amp;#125; public static void main(String[] args) &amp;#123; method(1); &amp;#125; &amp;#125; 4.3.2 运行结果 4.3.3 理解和说明Stack Space 用来做方法的递归调用时压入Stack Frame(栈帧),所以当递归调用太深的时候, 就有可能耗尽Stack Space,报出 StackOverflow的错误. -Xss128k: 设置每个线程的堆栈大小,JDK5 之后每个线程堆栈大小为1M, 以前每个堆栈大小为256k, 根据应用的线程所需内存大小进行调整,在相同的物理内存下,减少这个值能够生成更多的线程. 但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值为3000-5000 左右. 线程栈的大小是个双刃剑,如果设置过小, 可能会出现栈溢出,特别是该线程内有递归、大的循环时出现溢出的可能性更大, 如果该值设置过大,就有可能影响到创建栈的数量,如果是多线程的应用,就会出现内存溢出的错误.","categories":[{"name":"jvm","slug":"jvm","permalink":"https://rainsoil.github.io/categories/jvm/"},{"name":"jvm","slug":"jvm/jvm","permalink":"https://rainsoil.github.io/categories/jvm/jvm/"}],"tags":[]},{"title":"JVM之调优(5)","slug":"jvm/JVM之调优(5)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/jvm/jvm-zhi-diao-you-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/jvm/jvm-zhi-diao-you-5/","excerpt":"","text":"JVM之调优1. 重新认识JVM我们画一张图来展示JVM的大体物理结构 2. GC优化内存被使用了以后, 难免会有不够用或者达到设定值的时候,就需要对内存空间进行垃圾回收. 2.1 垃圾收集发生的时机GC是由JVM 自动完成的,根据JVM系统环境而定,所以时机是不确定的. 当然, 我们也可以手动进行垃圾回收,比如调用system.gc() 方法通知JVM进行一次垃圾回收,但是具体什么时刻运行也无法控制. 也就是说,System.gc() 只是通知要回收,什么时候回收是由JVM控制的,但是不建议手动调用此方法,因为消耗的资源比较大. 一般以下几种情况会发生垃圾回收: 当Eden区或者S区不够用了 老年代空间不够用了. 方法区空间不够用了 System.gc() 2.2 实验环境准备我们这里准备一个springboot 项目,然后配置相应的参数 2.3 GC日志文件 要想分析日志文件,得先拿到日志文件才行, 所以要先配置一下 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:gc.log 然后启动项目,然后看到默认使用的是 ParallelGC 2.3.1 ParallelGC 日志 吞吐量优先 Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for windows-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:33:46 by \"java_re\" with MS VC++ 10.0 (VS2010) Memory: 4k page, physical 16636048k(7426340k free), swap 40753296k(25478464k free) CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=266176768 -XX:+ManagementServer -XX:MaxHeapSize=4258828288 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC 2020-05-11T09:04:45.331+0800: 3.376: [GC (Allocation Failure) [PSYoungGen: 65024K[Young区回收前]->8314K[Young区回收后](75776K[Young区总大小])] 65024K[整合堆回收前]->8330K[整个堆回收后](249344K[堆总大小]), 0.0110320 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 注意: 如果回收的差值中间有出入,则说明这部分空间是Old 空间释放出来的. 2.3.2 CMS 日志 停顿时间优先 参数设置：-XX:+UseConcMarkSweepGC -Xloggc:cms-gc.log 2.3.3 G1日志 停顿时间优先 参数设置 -XX:+UseG1GC -Xloggc:g1-gc.log Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for windows-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:33:46 by \"java_re\" with MS VC++ 10.0 (VS2010) Memory: 4k page, physical 16636048k(7679220k free), swap 40753296k(25282952k free) CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=266176768 -XX:+ManagementServer -XX:MaxHeapSize=4258828288 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC #使用了G1垃圾收集器 -XX:-UseLargePagesIndividualAllocation # 什么时候发生的GC,相对的时间刻,GC发生的区域young,总共花费的是时间0.0035105s 2020-05-11T09:21:41.242+0800: 1.976: [GC pause (G1 Evacuation Pause) (young), 0.0035105 secs] # 多少个垃圾回收线程,并行的时间 [Parallel Time: 2.8 ms, GC Workers: 4] # GC线程开始对于上面的 1.976 的时间刻 [GC Worker Start (ms): Min: 1975.7, Avg: 1975.7, Max: 1975.7, Diff: 0.0] [Ext Root Scanning (ms): Min: 0.3, Avg: 0.7, Max: 1.5, Diff: 1.2, Sum: 2.7] [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Processed Buffers: Min: 0, Avg: 0.0, Max: 0, Diff: 0, Sum: 0] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.3] [Object Copy (ms): Min: 1.2, Avg: 1.9, Max: 2.3, Diff: 1.1, Sum: 7.6] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Termination Attempts: Min: 1, Avg: 1.3, Max: 2, Diff: 1, Sum: 5] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.2] [GC Worker Total (ms): Min: 2.7, Avg: 2.7, Max: 2.7, Diff: 0.0, Sum: 10.8] [GC Worker End (ms): Min: 1978.4, Avg: 1978.4, Max: 1978.4, Diff: 0.0] [Code Root Fixup: 0.0 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.0 ms] [Other: 0.6 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.5 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.0 ms] [Humongous Register: 0.0 ms] [Humongous Reclaim: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 14.0M(14.0M)->0.0B(17.0M) Survivors: 0.0B->2048.0K Heap: 14.0M(254.0M)->2817.5K(254.0M)] [Times: user=0.00 sys=0.00, real=0.00 secs] 2020-05-11T09:21:41.489+0800: 2.222: [GC pause (G1 Evacuation Pause) (young), 0.0047721 secs] [Parallel Time: 3.5 ms, GC Workers: 4] [GC Worker Start (ms): Min: 2222.1, Avg: 2222.1, Max: 2222.1, Diff: 0.0] [Ext Root Scanning (ms): Min: 0.2, Avg: 0.4, Max: 0.8, Diff: 0.5, Sum: 1.5] [Update RS (ms): Min: 0.5, Avg: 0.9, Max: 1.8, Diff: 1.3, Sum: 3.5] [Processed Buffers: Min: 1, Avg: 1.3, Max: 2, Diff: 1, Sum: 5] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.3, Diff: 0.3, Sum: 0.3] [Object Copy (ms): Min: 1.4, Avg: 2.1, Max: 2.5, Diff: 1.1, Sum: 8.5] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Termination Attempts: Min: 1, Avg: 7.3, Max: 13, Diff: 12, Sum: 29] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [GC Worker Total (ms): Min: 3.5, Avg: 3.5, Max: 3.5, Diff: 0.0, Sum: 13.9] [GC Worker End (ms): Min: 2225.6, Avg: 2225.6, Max: 2225.6, Diff: 0.0] [Code Root Fixup: 0.1 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.0 ms] [Other: 1.1 ms] [Choose CSet: 0.0 ms] [Ref Proc: 1.0 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.0 ms] [Humongous Register: 0.0 ms] [Humongous Reclaim: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 17.0M(17.0M)->0.0B(149.0M) Survivors: 2048.0K->3072.0K Heap: 19.8M(254.0M)->6462.5K(254.0M)] [Times: user=0.00 sys=0.00, real=0.00 secs] 2020-05-11T09:21:42.162+0800: 2.895: [GC pause (Metadata GC Threshold) (young) (initial-mark), 0.0097849 secs] [Parallel Time: 4.7 ms, GC Workers: 4] [GC Worker Start (ms): Min: 2895.2, Avg: 2895.2, Max: 2895.2, Diff: 0.0] [Ext Root Scanning (ms): Min: 0.7, Avg: 1.0, Max: 1.4, Diff: 0.7, Sum: 4.0] [Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.4, Diff: 0.4, Sum: 1.0] [Processed Buffers: Min: 0, Avg: 2.8, Max: 6, Diff: 6, Sum: 11] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.2] [Code Root Scanning (ms): Min: 0.0, Avg: 0.2, Max: 0.4, Diff: 0.4, Sum: 0.6] [Object Copy (ms): Min: 2.8, Avg: 3.2, Max: 3.5, Diff: 0.7, Sum: 12.7] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Termination Attempts: Min: 1, Avg: 2.5, Max: 4, Diff: 3, Sum: 10] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [GC Worker Total (ms): Min: 4.6, Avg: 4.6, Max: 4.7, Diff: 0.0, Sum: 18.6] [GC Worker End (ms): Min: 2899.9, Avg: 2899.9, Max: 2899.9, Diff: 0.0] [Code Root Fixup: 0.1 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.0 ms] [Other: 5.0 ms] [Choose CSet: 0.0 ms] [Ref Proc: 4.7 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.0 ms] [Humongous Register: 0.0 ms] [Humongous Reclaim: 0.0 ms] [Free CSet: 0.1 ms] [Eden: 89.0M(149.0M)->0.0B(138.0M) Survivors: 3072.0K->14.0M Heap: 94.8M(254.0M)->16.8M(254.0M)] [Times: user=0.00 sys=0.00, real=0.01 secs] 2020-05-11T09:21:42.172+0800: 2.905: [GC concurrent-root-region-scan-start] 2020-05-11T09:21:42.178+0800: 2.912: [GC concurrent-root-region-scan-end, 0.0068436 secs] 2020-05-11T09:21:42.178+0800: 2.912: [GC concurrent-mark-start] 2020-05-11T09:21:42.183+0800: 2.916: [GC concurrent-mark-end, 0.0043306 secs] 2020-05-11T09:21:42.183+0800: 2.917: [GC remark 2020-05-11T09:21:42.183+0800: 2.917: [Finalize Marking, 0.0001185 secs] 2020-05-11T09:21:42.183+0800: 2.917: [GC ref-proc, 0.0002940 secs] 2020-05-11T09:21:42.184+0800: 2.917: [Unloading, 0.0019141 secs], 0.0024715 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 2020-05-11T09:21:42.186+0800: 2.919: [GC cleanup 17M->17M(254M), 0.0006070 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 2.4 GC日志分析工具2.4.1 gceasy 官网: https://gceasy.io 可以比较不同的垃圾回收器的吞吐量和停顿时间 比如打开前面生成的 cms-gc.log和g1-gc.log 2.4.2 GCViewer 2.5 G1 调优指南2.5.1 调优是否选用G1垃圾收集器的判断依据 https://docs.oracle.com/javase/8/docs/technotes/guides/vm/G1.html#use_cases 50% 以上的堆被存活对象占用 对象分配和晋升的速度变化比较大 垃圾回收时间比较长 思考: https://blogs.oracle.com/poonam/increased-heap-usage-with-g1-gc 使用G1GC垃圾收集器: -XX:+UseG1GC 修改配置参数,获取到gc日志,使用GCViewer分析吞吐量和响应时间 Throughput Min Pause Max Pause Avg Pause GC count 99.16% 0.00016s 0.0137s 0.00559s 12 调整内存大小再获取gc日志分析 -XX:MetaspaceSize=100M -Xms300M -Xmx300M 比如设置堆内存的大小,获取到gc日志,使用GCViewer 分析吞吐量和响应时间 Throughput Min Pause Max Pause Avg Pause GC count 98.89% 0.00021s 0.01531s 0.00538s 12 调整最大的停顿时间 -XX:MaxGCPauseMillis=20 设置最大GC停顿时间指标 比如设置最大的停顿时间, 获取到gc日志,然后分析吞吐量和停顿时间 Throughput Min Pause Max Pause Avg Pause GC count 98.96% 0.00015s 0.01737s 0.00574s 12 启动并发GC时堆内存占分比 -XX:InitiatingHeapOccupancyPercent=45 G1用它来触发并发GC周期,基于整个堆的使用率,而不只是某一代内存的 使用比例。值为 0 则表示“一直执行GC循环)'. 默认值为 45 (例如, 全部的 45% 或者使用了45%). 比如设置该百分比参数,获取到gc日志,分析吞吐量和响应时间 Throughput Min Pause Max Pause Avg Pause GC count 98.11% 0.00406s 0.00532s 0.00469s 12 2.5.2 最佳指南官网建议: https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/g1_gc_tuning.html#recommendations 不要手动设置新生代和老年代的大小,只要设置整个堆的大小 G1收集器在运行过程中,会自己调整新生代和老年代的大小 其实是通过adapt 代的大小来调整对象晋升的速度和年龄,从而达到为收集器设置的暂停时间目标. 如果手动设置了大小就意味着放弃了G1的自动调优 不断调优暂停时间目标 一般情况下这个值设置到100ms或者200ms 都是可以的(不同情况下会不一样), 但是如果设置成50ms 就不太合理, 暂停时间设置的太短的话，就会导致出现G1跟不上垃圾产生的速度,最终退化为Full GC, 所以对这个参数的调优是一个持续的过程, 逐步调整到最佳状态,暂停时间只是一个目标,总不能总是得到满足. 使用-XX:ConcGCThreads=n 来增加标记线程的数量 IHOP如果阈值设置过高, 可能就会遇到转移失败的风险,比如对象进行转移时空间不足. 如果阈值设置过低,就会时标记周期运行过于频繁,并且有可能混合收集期回收不到空间. MixedGC 调优 -XX:InitiatingHeapOccupancyPercent -XX:G1MixedGCLiveThresholdPercent -XX:G1MixedGCCountTarger -XX:G1OldCSetRegionThresholdPercent 适当增加堆内存大小 3. 高并发场景分析 以每秒3000笔订单为例 4. JVM 性能优化指南 发现问题 GC频繁 死锁 OOM 线程池不够用 CPU负载过高 排查问题 打印出gc日志, 查看minor gc/major gc,结合工具gcviewer jstack 查看线程堆栈信息 dump 出堆文件,使用MAT 或其他工具分析 合理使用jdk自带的jconsole，jvisualvm、阿里的arthas 等实时查看JVM状态 灵活应用jps 、jinfo、jstat、jmap 等常用命令 解决方案 适当增加内存大小/选择合适的垃圾收集器 使用ZK/redis 实现分布式锁 设置本地、nginx 等缓存减少对后端服务器的访问 后端代码优化及时释放资源/合理设置线程池中的参数 集群部署从而减少单节点的压力 利用一些消息中间件比如MQ 、Kafka 等实现异步消息 ….. 5. 常见问题思考5.1 内存泄漏和内存溢出的区别内存泄漏: 对象无法得到及时的回收持续占用内存的对象,从而造成内存空间的浪费 内存溢出: 内存泄漏到一定的程序就会造成内存溢出, 但是内存溢出也可能是大对象导致的. 5.2 young gc 会有stw 吗?不管什么GC, 都会有stop the world,只是发生时间的长短 5.3 major gc 和full gc的区别major gc 是指老年代的gc,而full gc 是指新生到+老年代+方法区的gc 5.4 G1和CMS的区别CMS 用于老年代的回收,而G1 用于新生代和老年代的回收 G1是用了Region 方法对堆内存进行了划分,且基于标记整理算法实现, 整体减少了垃圾碎片的产生 5.5 什么是直接内存直接内存是在java堆外，直接向系统申请的内存空间,通常访问直接内存的速度会优于java堆,因此处于性能的考虑, 读写频繁的场合可能会考虑到使用直接内存 5.6 不可达的对象一定要被回收吗?即使在可达性分析法中不可达的对象,也并非是”非死不可”的, 这时候他们暂时处于”缓刑阶段”, 要真正宣告一个对象死亡,至少要经历两次标记过程,可达性分析法中不可达的对象被第一次标记并且进行一次筛选,筛选的条件是此对象是否有必要执行ﬁnalize 方法,当对象没有覆盖ﬁnalize 方法, 或者ﬁnalize 方法已经被虚拟机调用过时, 虚拟机将这两种情况视为没有必要执行. 被判定为需要执行的对象将会被放在一个队列中进行第二次标记,除非这个对象与引用链上的任何一个对象建立关联, 否则就会被真的回收. 5.7 方法区中的无用类回收方法区主要回收的是无用的类,那么如何判断一个类是无用的类呢？ 判断一个常量是否是”废弃常量” 比较简单,而要判定一个类是否是”无用的类” 的条件则相对要苛刻的多,类需要同时满足下面3个条件才能算”无用的类” 该类所有的实例都已经被回收了,也就是java堆中不存在该类的任何实例 加载该类的ClassLoader 已经被回收 该类对应的java.lang.Class 对象没有在任何地方被引用,无法在任何地方通过反射该类的方法. 虚拟机可以对满足上述3个条件的无用类进行回收,这里说的仅仅是”可以”, 而并不是跟对象一样不使用了就必然会被回收. 5.7 不同的引用JDK12以后, Java对引用进行了扩充: 强引用、软引用、弱引用和虚引用","categories":[{"name":"jvm","slug":"jvm","permalink":"https://rainsoil.github.io/categories/jvm/"},{"name":"jvm","slug":"jvm/jvm","permalink":"https://rainsoil.github.io/categories/jvm/jvm/"}],"tags":[]},{"title":"kubernetes系统核心组件(10)","slug":"k8s/kubernetes系统核心组件(10)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/k8s/kubernetes-xi-tong-he-xin-zu-jian-10/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/k8s/kubernetes-xi-tong-he-xin-zu-jian-10/","excerpt":"","text":"kubernetes系统核心组件1. Master和Node 官网:https://kubernetes.io/zh/docs/concepts/architecture/master-node-communication/ k8s 集群中的控制节点,负责整个集群的管理和控制,可以做成高可用,防止一台master 宕机或者不可用,其中有一些关键的组件, 比如API Server、Controller Manage 、Scheduler等. Node Node 会被master 分配一些工作负载,当某个Node 不可用的时候, 会将工作负载转移到其他的Node 节点上,Node 上,Node 上有一些关键的进程,如kubelet、kube-proxy、docker 等等. 查看集群中的Node kubectl get nodes kubectl describe node node-name 2. kubeadm2.1 kubeadm init 进行一系列的健康检查[init 之前的检查], 以确定这台机器可以部署kubernetes kubeadm init pre-flight check: kubeadm 版本与要安装的kubernetes 版本检查 kuernetes 安装的系统检查(contos版本,cgroup、docker等) 用户、主机、端口、swap等 生成kubernetes 对外提供服务所需要的各种证书对应目录, 也就是生成私钥和数字证书 /etc/kubernetes/pki/* 自建ca,生成ca.key和ca.crt apiserver的私钥和公钥生成 apiserver访问kubeclt 使用的客户端私钥和证书 sa.key 和sa.pub etcd 相关私钥和数字证书 为其他组件生成访问kube-APIServer 所需要的配置文件xxx.conf ls /etc/kubernetes/ admin.conf controller-manager.conf kubelet.conf scheduler.conf 有了$HOME/.kube/config 就可以使用kubectl 和k8s集群打交道了,这个文件是来自于admin.config mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubeconfig 中包含了cluster、user 和context 信息, kubectl config view 允许kubectl 快速切换context, 管理多集群 为master 生成Pod 配置文件 ,这些组件会被master 节点上的kubectl 读取到,并且创建对应的资源 ls /etc/kubernetes/manifests/*.yaml kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml 这些pod 由kubectl 直接管理, 是静态pod, 直接使用主机网络 kubectl 读取manifests 目录并管理各控制平台组件pod 的启动与停止 要想修改这些pod,直接修改manifests 下的yaml 文件即可. 下载镜像,等待控制平面启动 一旦这些yaml 文件出现在被kubectl 监视的/etc/kubernetes/manifests/ 目录下, kubectl 就会自动创建这些yaml 文件定义的pod, 即master 组件的容器,master 容器启动后,kubeadm会通过检查localhost6443/healthz 这个master 组件的健康状态检查URL, 等到master组件完全 运行起来. 【 cat kube-apiserver.yaml里面有健康检查的配置】 为集群生成一个bootstrap token, 设置当前node 为master, master 节点将不承担工作负载. 将ca.crt 等master 节点的重要信息,通过COnfigMap 的方式保存在etcd 中, 供后续部署node 节点使用 安装默认插件,kubernetes 默认kube-proxy 和dns 两个插件是必须要安装的,dns 插件安装了会处于Pending状态, 要等网络插件安装完成, 比如calico kubectl get daemonset -n kube-system 可以看到kube-proxy和calico[或者其他网络插件] 2.2 kubeadm joinkubeadm join 192.168.0.51:6443 --token yu1ak0.2dcecvmpozsy8loh \\ --discovery-token-ca-cert-hash sha256:5c4a69b3bb05b81b675db5559b0e4d7972f1d0a61195f217161522f464c307b0 join 前检查 discovery-token-ca-cert-hash 用于验证master 的身份 #可以计算出来, 在w 节点上执行 openssl x509 -in /etc/kubernetes/pki/ca.crt -noout -pubkey | openssl rsa -pubin - outform DER 2>/dev/null | sha256sum | cut -d' ' -f1 # 最终的hash值 909adc03d6e4bd676cfc4e04b864530dd19927d8ed9d84e224101ef38ed0bb96 token 用于master 验证node # 在master 上节点上,可以查看对应的token kubectl get secret -n kube-system | grep bootstrap-token # 得到token的值 kubectl get secret/bootstrap-token-kggzhc -n kube-system -o yaml # 对token的值进行解码 echo NHRzZHp0Y2RidDRmd2U5dw==|base64 -d --->4tsdztcdbt4fwe9w # 最终token的值 kggzhc.4tsdztcdbt4fwe9w 3. 核心组件 3.1 kubectl操作集群的客户端,负责和集群进行打交道 3.2 kube-apiserver整个集群的中枢纽带,负责的事情很多 /etc/kubernetes/manifests/kube-apiserver.yaml # kubectl 管理的静态pod --insecure-port=0 #默认使用http 非安全协议访问 安全验证的一些文件 准入策略的拦截器 --authorization-mode=Node,RBAC --etcd # 配置apiserver 与etcd 通信 3.3 kube-scheduler单纯的调度pod, 按照特定的调度算法和策略，将待调度pod 绑定到集群中某个适合的Node, 并写入到绑定信息,由对应节点的kubectl 服务创建pod /etc/kubernetes/manifests/kube-scheduler.yaml # kubelet管理的静态pod --address表示只在master节点上提供服务，不对外 kubeconfig 表示 3.4 kube-controller-manage负责集群中Node、Pod 副本, 服务的endpoint、命令空间、Service Account、资源配置等管理. 会划分成不同类型的controller, 每个controller都是一个死循环, 在循环中controller 通过apiservice 监视自己控制资源的状态, 一旦状态发生变化就会努力改变状态,直到变成期望的状态. /etc/kubernetes/manifests/kube-controller-manager.yaml # kubelet管理的静态pod 参数设置ca-file 多个manage, 是否需要i进行leader 选举 3.5 kubectlkubectl 集群中的所有节点都运行,用于管理pod 和contailer, 每个kubectl 会向apiserver 注册本节点的信息,并向master 节点上报本节点资源使用的情况 kubectl 由操作系统init[systemd] 进行启动 ls /lib/systemd/system/kubelet.service systemctl daemon-reload &amp; systemctl restart kubelet 3.6 kube-proxy集群中的所有节点都运行,像service 的操作都是由kube-proxy 代理的,对于客户端是透明的. kube-proxy 由daemonset 控制器在各个节点上启动唯一实例 配置参数 ：/var/lib/kube-proxy/config.conf(pod内) # 不是静态pod kubectl get pods -n kube-system kubectl exec kube-proxy-jt9n4 -n kube-system -- cat /var/lib/kube-proxy/config.conf mode:&quot;&quot; ---&gt;# iptables 3.7 DNS域名解析的问题 3.8 dashboard需要有监控面板能够检测整个集群的状态 3.9 etcd整个集群的配置中心,所有集群的状态数据,对象数据都存储在etcd 中. kubeadm 引导启动的k8s 集群, 默认只启动一个etcd 节点 /etc/kubernetes/manifests/etcd.yaml # kubelet管理的静态pod etcd 所使用的相关密钥在/etc/kubernetes/pki/etcd 里面 etcd 挂载master 节点本地路径 /var/lib/etcd 用于运行时数据存储,tree 4. kubernetes 源码查看方式 源码地址: https://github.com/kubernetes/kubernetes https://github.com/kubernetes/kubernetes/tree/release-1.14 5. kubectl 语法: kubectl [command] [TYPE] [NAME] [flag] 官网: https://kubernetes.io/docs/reference/kubectl/overview/ command: 用于操作k8s 资源对象的命令,比如apply、delete、describe、get等 TYPE: 要操作资源对象的类型, 区分大小写,比如pod[pods/po]、deployment NAME: 要操作对象的具体名称,若不指定,则返回该资源类型的全部对象(是默认命名空间下的) flags: 可选 5.1 demo 查看集群的状态 # 查看集群的信息 kubectl config view # 查看cluster的信息 kubectl config get-clusters 创建资源 kubectl apply -f xxx.yaml kubectl apply -f &lt;directory> 查看资源对象 # 查看Pod kubectl get pods # 查看Service kubectl get svc 问题查看调试 kubectl describe pod pod-name kubectl exec -it pod-name kubectl logs -f pod-name kubectl attach 6. API Server 官网: https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/ API Server 提供了k8s 各类资源对象的操作,是集群内各个功能模块之间数据交互和通信的中心枢纽,是整个系统的数据总线和数据中心,通常我们通过kubectl 和apiservice 进行交互. APIService 通过kube-apiserver的进程提供服务,运行在master 节点上. kubectl与APIServer 之间是REST 调用 The Kubernetes API server validates and configures data for the api objects which include pods, services, replicationcontrollers, and others. The API Server services REST operations and provides the frontend to the cluster’s shared state through which all other components interact. 查看yaml 文件中的apiVersion grep -r \"apiVersion\" . ./pod_nginx.yaml:apiVersion: apps/v1 ./my-tomcat.yaml:apiVersion: apps/v1 ./my-tomcat.yaml:apiVersion: v1 ./mandatory.yaml:apiVersion: v1 ./mandatory.yaml:apiVersion: v1 ./mandatory.yaml:apiVersion: v1 ./mandatory.yaml:apiVersion: v1 ./mandatory.yaml:apiVersion: v1 ./mandatory.yaml:apiVersion: rbac.authorization.k8s.io/v1beta1 ./mandatory.yaml:apiVersion: rbac.authorization.k8s.io/v1beta1 ./mandatory.yaml:apiVersion: rbac.authorization.k8s.io/v1beta1 ... REST API 设计 API官网： https://kubernetes.io/docs/concepts/overview/kubernetes-api/ V1.14: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.14/ 想要写pod 的yaml 文件 https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.14/#pod-v1-core kube-apiserver lsof -i tcp:8080 vi /etc/kubernetes/manifests/kube-apiserver.yaml [kubeadm安装方式] # 查询insecure-port，并将修改端口为8080 insecure-port=8080 # kubect apply生效，需要等待一会 kubectl apply -f kube-apiserver.yaml 查看端口以及访问测试 可以发现结果和kubectl使用一样 lsof -i tcp:8080 curl localhost:8080 curl localhost:8080/api curl localhost:8080/api/v1 curl localhost:8080/api/v1/pods curl localhost:8080/api/v1/services 设计一个pod的url 请求 https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.14/#-strong-write-operations-pod-v1-core-strong 这种操作还是相对比较麻烦的,哪怕使用kubectl https://github.com/kubernetes-client Java ：https://github.com/kubernetes-client/java Go ：https://github.com/kubernetes/client-go 7. 集群安全机制之API Server 官网:https://v1-12.docs.kubernetes.io/docs/reference/access-authn-authz/controlling-access/ 对于k8s 集群的访问操作, 都是通过api server 的rest api 来实现的,难道所有的操作都允许吗? 当然是不行的, 这里就涉及到认证、授权和准入等操作. 7.1 API Server认证(Authentication) 官网: https://v1-12.docs.kubernetes.io/docs/reference/access-authn-authz/controlling-access/#authentication 说白了, 就是如何来识别客户端的身份,k8s 集群中提供了3种识别客户端的身份的方式 https 证书认证 基于CA 根证书签名的双向数字证书认证方式 HTTP Token 认证 通过Token 来识别合法用户 HTTP Base 认证 通过用户名+密码的方式来认证 7.2 API Server授权(Authorization) 官网: https://v1-12.docs.kubernetes.io/docs/reference/access-authn-authz/controlling-access/#authorization ABAC 授权模式 Webhook 授权模式 RBPC 授权模式 Role、ClusterRole、RoleBinding和ClusterRoleBinding 用户可以使用kubectl 或者API 调用等方式操作这些资源对象 7.3 Admission Contro(准入控制) 官网:https://v1-12.docs.kubernetes.io/docs/reference/access-authn-authz/controlling-access/#admission-control Always 允许所有请求 AlwaysPullImages 在启动容器之前总是尝试重新下载镜像 AlwaysDeny 禁止所有请求 8. Scheduler 官网: https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/ In Kubernetes, scheduling refers to making sure that Pods are matched to Nodes so that Kubelet can run them. 通过调度算法,为待调度Pod 列表的每个pod, 从Node 列表中选择一个最合适的Node 然后,目标节点上的kubelet 通过API Server 监听到Kubernetes Schduler 产生的Pod 绑定事件,获取对应的Pod 清单,下载image 镜像,并启动容器 8.1 架构图 8.2 流程描述 https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/#kube-scheduler-implementation Filtering Scoring 预选调度策略：遍历所有目标的Node,筛选出符合Pod 要求的候选节点 优选调度策略: 在1的基础上, 采用优选策略算法计算出每个候选节点的积分, 积分最高者胜出 8.3 预选策略和优选策略8.3.1 预选策略 https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/#filtering PodFitsHostPorts Checks if a Node has free ports (the network protocol kind) for the Pod ports the Pod is requesting. PodFitsHost Checks if a Pod specifies a specific Node by it hostname. PodFitsResources Checks if the Node has free resources (eg, CPU and Memory) to meet the requirement of the Pod. 8.3.2 优选策略 https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/#scoring SelectorSpreadPriority Spreads Pods across hosts, considering Pods that belonging to the same Service, StatefulSet or ReplicaSet InterPodAffinityPriority Computes a sum by iterating through the elements of weightedPodAffinityTerm and adding “weight” to the sum if the corresponding PodAffinityTerm is satisfied for that node; the node(s) with the highest sum are the most preferred. 8.4 实战8.4.1 Node 正常创建Node, 准备 scheduler-node-origin.yaml 资源文件 apiVersion: apps/v1 kind: Deployment metadata: name: scheduler-node spec: selector: matchLabels: app: scheduler-node replicas: 1 template: metadata: labels: app: scheduler-node spec: containers: - name: scheduler-node image: registry.cn-hangzhou.aliyuncs.com/luyanan/test-docker-image:v1.0 ports: - containerPort: 8080 启动并查看资源 kubectl apply -f scheduler-node-origin.yaml kubectl get pods kubectl describe pod pod-name 准备scheduler-node.yaml 资源文件 apiVersion: apps/v1 kind: Deployment metadata: name: scheduler-node spec: selector: matchLabels: app: scheduler-node replicas: 1 template: metadata: labels: app: scheduler-node spec: containers: - name: scheduler-node image: registry.cn-hangzhou.aliyuncs.com/luyanan/test-docker-image:v1.0 ports: - containerPort: 8080 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/arch operator: In values: - amd641 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: disktype operator: NotIn values: - ssd 主要是体现node 的调度 kubectl get nodes w1 -o yaml 找到labels [root@master-kubeadm-k8s ~]# kubectl get pods NAME READY STATUS RESTARTS AGE scheduler-node-84845c99d4-fvw9d 0/1 Pending 0 7s kubectl describe pod scheduler-node-84845c99d4-fvw9d Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 37s (x2 over 37s) default-scheduler 0/3 nodes are available: 3 node(s) didn't match node selector. 8.4.2 Podaffinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - k8s topologyKey: kubernetes.io/hostname 9. kubelet 官网:https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/ 在k8s集群中,每个Node 上都会启动一个kubelet 服务进程,用于处理master 节点上发到本节点的任务 管理pod 以及pod 中的容器,每个kubelet 进程会在API Server 上注册自身信息,定期向master 节点上汇报节点资源使用情况,并通过cAdvisor 监控容器和节点资源 10 .kube-proxy 官网:https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/ 在k8s 集群中, 每个Node 上都会运行一个kube-proxy 进行, 它是service 的透明代理兼负载均器,核心功能是将某个Service 的访问请求转发到后端的多个Pod 实例上.","categories":[{"name":"k8s","slug":"k8s","permalink":"https://rainsoil.github.io/categories/k8s/"},{"name":"k8s","slug":"k8s/k8s","permalink":"https://rainsoil.github.io/categories/k8s/k8s/"}],"tags":[]},{"title":"Centos7设置定时任务","slug":"linux/Centos7设置定时任务","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/linux/centos7-she-zhi-ding-shi-ren-wu/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/linux/centos7-she-zhi-ding-shi-ren-wu/","excerpt":"","text":"Centos7 设置定时任务1、安装 crontabs服务并设置开机自启： yum install crontabs systemctl enable crond systemctl start crond 2、配置定时规则 vim /etc/crontab 在配置文件中配置你的定时执行规则 59 23 * * * root /home/backup/showdoc/backup.sh backup.sh是你将要定时执行的脚本文件，如图所示： 规则很简单，看注释就能看懂了，从左到右分别是 分钟（059）、小时（023）、天（131）、月(112)、星期(0~6)、用户名、要执行的命令或者脚本。 脚本内容如下： #! /bin/bash t=$(date +%Y%m%d%H%M%S) cd /home/backup/showdoc/mount/ tar -zcvf ../data/data_$t.tar ./showdoc_data find /home/backup/showdoc/data -mtime 7 -type f|xargs rm -f t是当前日期，格式是年月日时分秒；tar -zcvf是将要备份的文件打成压缩包，后缀会带上日期；find … -mtime 7 …|xargs rm -f是只保留近七日的备份文件，之前的都会删掉。 3、保存生效 crontab /etc/crontab 4、查看任务 crontab -l 任务列表，如图所示： 到此定时任务配置完成。","categories":[{"name":"linux","slug":"linux","permalink":"https://rainsoil.github.io/categories/linux/"},{"name":"linux","slug":"linux/linux","permalink":"https://rainsoil.github.io/categories/linux/linux/"}],"tags":[]},{"title":"CentOS 6","slug":"linux/CentOS 6.x 内核升级（2.6.32 - 3.10.58）过程记录","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/linux/centos-6.x-nei-he-sheng-ji-2.6.32-3.10.58-guo-cheng-ji-lu/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/linux/centos-6.x-nei-he-sheng-ji-2.6.32-3.10.58-guo-cheng-ji-lu/","excerpt":"","text":"CentOS 6.x 内核升级（2.6.32 -&gt; 3.10.58）过程记录方法一yum update kernel 方法二1. 准备工作确认内核及版本信息[root@hostname ~]# uname -r 2.6.32-220.el6.x86_64 [root@hostname ~]# cat /etc/centos-release CentOS release 6.2 (Final) 安装软件编译安装新内核，依赖于开发环境和开发库 # yum grouplist //查看已经安装的和未安装的软件包组，来判断我们是否安装了相应的开发环境和开发库； # yum groupinstall &quot;Development Tools&quot; //一般是安装这两个软件包组，这样做会确定你拥有编译时所需的一切工具 # yum install ncurses-devel //你必须这样才能让 make *config 这个指令正确地执行 # yum install qt-devel //如果你没有 X 环境，这一条可以不用 # yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel //创建 CentOS-6 内核时需要它们 如果当初安装系统是选择了Software workstation，上面的安装包几乎都已包含。 2. 编译内核获取并解压内核源码，配置编译项去 http://www.kernel.org 首页，可以看到有stable, longterm等版本，longterm是比stable更稳定的版本，会长时间更新，因此我选择 3.10.58。 [root@sean ~]# tar -xf linux-3.10.58.tar.xz -C /usr/src/ [root@sean ~]# cd /usr/src/linux-3.10.58/ [root@sean linux-3.10.58]# cp /boot/config-2.6.32-220.el6.x86_64 .config 我们在系统原有的内核配置文件的基础上建立新的编译选项，所以复制一份到当前目录下，命名为.config。接下来继续配置： [root@sean linux-3.10.58]# sh -c &#39;yes &quot;&quot; | make oldconfig&#39; HOSTCC scripts/basic/fixdep HOSTCC scripts/kconfig/conf.o SHIPPED scripts/kconfig/zconf.tab.c SHIPPED scripts/kconfig/zconf.lex.c SHIPPED scripts/kconfig/zconf.hash.c HOSTCC scripts/kconfig/zconf.tab.o HOSTLD scripts/kconfig/conf scripts/kconfig/conf --oldconfig Kconfig .config:555:warning: symbol value &#39;m&#39; invalid for PCCARD_NONSTATIC .config:2567:warning: symbol value &#39;m&#39; invalid for MFD_WM8400 .config:2568:warning: symbol value &#39;m&#39; invalid for MFD_WM831X .config:2569:warning: symbol value &#39;m&#39; invalid for MFD_WM8350 .config:2582:warning: symbol value &#39;m&#39; invalid for MFD_WM8350_I2C .config:2584:warning: symbol value &#39;m&#39; invalid for AB3100_CORE .config:3502:warning: symbol value &#39;m&#39; invalid for MMC_RICOH_MMC * * Restart config... * * * General setup * ... ... XZ decompressor tester (XZ_DEC_TEST) [N/m/y/?] (NEW) Averaging functions (AVERAGE) [Y/?] (NEW) y CORDIC algorithm (CORDIC) [N/m/y/?] (NEW) JEDEC DDR data (DDR) [N/y/?] (NEW) # # configuration written to .config # make oldconfig会读取当前目录下的.config文件，在.config文件里没有找到的选项则提示用户填写。有的文档里介绍使用make memuconfig，它便是根据需要定制模块，类似界面如下：（我们不需要）make oldconfig会在生成新的.config之前备份为.config.old，并生成新的.config文件 开始编译[root@sean linux-3.10.58]# make -j4 bzImage //生成内核文件 [root@sean linux-3.10.58]# make -j4 modules //编译模块 [root@sean linux-3.10.58]# make -j4 modules_install //编译安装模块 -j后面的数字是线程数，用于加快编译速度，一般的经验是，逻辑CPU，就填写那个数字，例如有8核，则为-j8。（modules部分耗时30多分钟） 安装[root@sean linux-3.10.58]# make install实际运行到这一步时，出现ERROR: modinfo: could not find module vmware_balloon，但是不影响内核安装，是由于vsphere需要的模块没有编译，要避免这个问题，需要在make之前时修改.config文件，加入HYPERVISOR_GUEST=yCONFIG_VMWARE_BALLOON=m（这一部分比较容易出问题，参考下文异常部分） 修改grub引导，重启安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。编辑 grub.conf文件， vi /etc/grub.conf #boot=/dev/sda default=0 timeout=5 splashimage=(hd0,0)/grub/splash.xpm.gz hiddenmenu title CentOS (3.10.58) root (hd0,0) ... 数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置default=0。重启reboot： 确认当内核版本[root@sean ~]# uname -r 3.10.58 升级内核成功! 3. 异常编译失败（如缺少依赖包）可以先清除，再重新编译： # make mrproper #完成或者安装过程出错，可以清理上次编译的现场 # make clean 在vmware虚拟机上编译，出现类似下面的错误[root@sean linux-3.10.58]# make install sh /usr/src/linux-3.10.58/arch/x86/boot/install.sh 3.10.58 arch/x86/boot/bzImage \\ System.map &quot;/boot&quot; ERROR: modinfo: could not find module vmware_balloon 可以忽略，如果你有强迫症的话，尝试以下办法：要在vmware上需要安装VMWARE_BALLOON，可直接修改.config文件，但如果vi直接加入CONFIG_VMWARE_BALLOON=m依然是没有效果的，因为它依赖于HYPERVISOR_GUEST=y。如果你不知道这层依赖关系，通过make menuconfig后，Device Drivers -&gt; MISC devices 下是找不到VMware Balloon Driver的。（手动vi .config修改HYPERVISOR_GUEST后，便可以找到这一项），另外，无论是通过make menuconfig或直接vi .config，最后都要运行sh -c &#39;yes &quot;&quot; | make oldconfig&#39;一次得到最终的编译配置选项。然后，考虑到vmware_balloon可能在这个版本里已更名为vmw_balloon，通过下面的方法保险起见： # cd /lib/modules/3.10.58/kernel/drivers/misc/ # ln -s vmw_balloon.ko vmware_balloon.ko #建立软连接 其实，针对安装docker的内核编译环境，最明智的选择是使用sciurus帮我们配置好的.config文件。也建议在make bzImage之前，运行脚本check-config.sh检查当前内核运行docker所缺失的模块。当提示缺少其他module时如NF_NAT_IPV4时，也可以通过上面的方法解决，然后重新编译。 5. TO-DO 如何清除原内核 现有软件是否需要yum update升级","categories":[{"name":"linux","slug":"linux","permalink":"https://rainsoil.github.io/categories/linux/"},{"name":"linux","slug":"linux/linux","permalink":"https://rainsoil.github.io/categories/linux/linux/"}],"tags":[]},{"title":"基于kubernetes的CICD(7)","slug":"k8s/基于kubernetes的CICD(7)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/k8s/ji-yu-kubernetes-de-cicd-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/k8s/ji-yu-kubernetes-de-cicd-7/","excerpt":"","text":"基于kubernetes的CICD.md 思考: 当我们需要部署一个项目到k8s中的时候,需要编写Dockerfile-&gt; 打包-&gt; push 镜像-&gt; 编写k8s 配置文件-&gt; 在进行启动等等。 当我们需要对这个项目的某些代码进行修改的时候,还要重新打包-&gt;push镜像-&gt;k8s启动等等. 思考: 如果能够按照上述图解一样,在本地进行开发,然后git push 到guthub, 就能访问最终的应用多好. 1. 环境准备1.1 基础环境准备(在安装jenkins的机器上)1.1.1 安装java 下载jdk 资源并上传到指定的机器 resources/cicd/jdk-8u181-linux-x64.tar.gz 配置环境变量 vim /etc/profile export JAVA_HOME=/usr/local/java/jdk1.8.0_181 export CLASSPATH=.:$&amp;#123;JAVA_HOME&amp;#125;/jre/lib/rt.jar:$&amp;#123;JAVA_HOME&amp;#125;/lib/dt.jar:$&amp;#123;JAVA_HOME&amp;#125;/lib/tools .jar export PATH=$PATH:$&amp;#123;JAVA_HOME&amp;#125;/bin 重启环境变量 source /etc/profile java -version 1.1.2 maven 安装 上传maven 到指定的机器 resources/cicd/apache-maven-3.6.2-bin.tar.gz 配置环境变量 vim /etc/profile export MAVEN_HOME=/usr/local/maven/apache-maven-3.6.2 export PATH=$PATH:$JAVA_HOME/bin:$MAVEN_HOME/bin 刷新并验证 source /etc/profile mvn -version 在setting.xml 文件中配置阿里云镜像 &lt;mirror> &lt;id>alimaven&lt;/id> &lt;name>aliyun maven&lt;/name> &lt;url>http://maven.aliyun.com/nexus/content/groups/public/&lt;/url> &lt;mirrorOf>central&lt;/mirrorOf> &lt;/mirror> 1.1.3 git安装 下载安装 yum install git -y 配置git git config --global user.name \"luyanan0718\" git config --global user.email \"luyanan0718@163.com\" ssh-keygen -t rsa -C \"luyanan0718@163.com\" --->将公钥上传到github:/root/.ssh/id_rsa.pub 1.2 项目准备这里准备一个 springboot-demo 项目,git地址为: https://github.com/luyanan0718/springboot-demo.git 1.3 jenkens 必须在k8s集群中, 因为后面需要在jenkins的目录下创建文件执行,比如这里选用的是w2节点 操作前须知 jenkins官网:https://jenkins.io/ 入门指南:&lt;https://jenkins.io/zh/doc/pipeline/tour/getting-started/ 找到对应的资源 resources/cicd/jenkins.war wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war 启动 nohup java -jar jenkins.war --httpPort=8080 &amp; tail -f nohup.out 浏览器访问ip:port ,输入密码 密码: `cat /root/.jenkins/secrets/initialAdminPassword` 安装推荐的插件 创建用户或者直接使用root用户 [系统管理]-&gt;[全局工具配置] 中配置java、maven、git等 1.4 Docker Hub可以自己搭建Docker仓库, 也可以使用阿里云的 1.5 k8s 集群2. 必要的测试1.2.1 pipeline 任务 创建jenkins的task 拉取github代码, 在最下面编写pipeline,然后保存和立即构建,同时查看Console output node &amp;#123; def mvnHome stage('Preparation') &amp;#123; // for display purposes git 'https://github.com/luyanan0718/springboot-demo.git' &amp;#125; &amp;#125; 来到 jenkins 所在的服务器, ls /root/.jenkins/workspace/springboot-demo 配置springboot-demo 的task, 修改pipeline的内容, 增加maven构建,然后”保存和立即构建”, 同时可以查看Console Output node &amp;#123; def mvnHome stage('Preparation') &amp;#123; git 'https://github.com/itcrazy2016/springboot-demo.git' &amp;#125; stage('Maven Build') &amp;#123; sh \"mvn clean package\" &amp;#125; &amp;#125; 来到jenkins 所在的服务器 ls /root/.jenkins/workspace/springboot-demo 至此,我们已经可以通过在jenkins上手动构建的方式,拿到github 上的代码,并且使用maven 进行构建了. 1.2.2 git push触发jenkins 自动构建 最好的话,当用户 进行git commit/push 提交代码到github的时候,能够通知jenkins 自动构建. 在github 上 配置jenkins的webhook 地址 http://ip:8080/springboot-demo 这个地址一定是要`github` 能够访问到的地址 生成 Personal access tokens jenkins 访问github 需要授权,所以在github 上生成token 交给jenkins 使用 ，即Personal access tokens github的Settings[个人信息右上角]–&gt;Developer settings–&gt;Personal access tokens–&gt;Generate new token 最后保存好该token，比如:**72f048b514e95d6fe36f86d84374f2dcce402b43 jenkins 安装插件 安装github plugin插件:[系统管理]-&gt;[插件管理]-&gt;[可选插件] 安装gitlab插件和gitlab hook插件:[系统管理]-&gt;[插件管理]-&gt;[可选插件] 配置Github Server [系统管理]-&gt;[系统配置]-&gt;[找到github服务器]-&gt;[添加github服务器] 3. 核心实战走起3.1 build&amp;push 镜像来到jenkins 的workspace目录， cd /root/.jenkins/workspace 准备一个文件,名称为 springboot-demo-build-image.sh mkdir /root/.jenkins/workspace/scripts/ vi /root/.jenkins/workspace/scripts/springboot-demo-build-image.sh 编写 springboot-demo-build-image.sh 文件 # 进入到springboot-demo目录 cd ../springboot-demo # 编写Dockerfile文件 cat &lt;&lt;EOF > Dockerfile FROM openjdk:8-jre-alpine COPY target/springboot-demo-0.0.1-SNAPSHOT.jar /springboot-demo.jar ENTRYPOINT [\"java\",\"-jar\",\"/springboot-demo.jar\"] EOF echo \"Dockerfile created successfully!\" # 基于指定目录下的Dockerfile构建镜像 docker build -t registry.cn-hangzhou.aliyuncs.com/luyanan/springboot-demo:v1.0 . # push镜像，这边需要阿里云镜像仓库登录，在w2上登录 docker push registry.cn-hangzhou.aliyuncs.com/luyanan/springboot-demo:v1.0 增加pipeline node &amp;#123; def mvnHome stage('Preparation') &amp;#123; git 'https://github.com/itcrazy2016/springboot-demo.git' &amp;#125; stage('Maven Build') &amp;#123; sh \"mvn clean package\" &amp;#125; stage('Build Image') &amp;#123; sh \"/root/.jenkins/workspace/scripts/springboot-demo-build-image.sh\" &amp;#125; &amp;#125; 采坑 # 01 文件权限 /root/.jenkins/workspace/springboot-demo@tmp/durable-7dbf7e73/script.sh: line 1: /root/.jenkins/workspace/scripts/springboot-demo-build-image.sh: Permission denied # 解决 chmod +x /root/.jenkins/workspace/scripts/springboot-demo-build-image.sh # 02 docker没有运行 Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? # 解决 systemctl start docker systemctl enable docker # 03 push权限 docker login --username=luyanan0718@163.com registry.cn-hangzhou.aliyuncs.com 3.2 kubernetes 拉取镜像并运行 编写springboot-demo.yaml 文件 # 以Deployment部署Pod apiVersion: apps/v1 kind: Deployment metadata: name: springboot-demo spec: selector: matchLabels: app: springboot-demo replicas: 1 template: metadata: labels: app: springboot-demo spec: containers: - name: springboot-demo image: registry.cn-hangzhou.aliyuncs.com/luyanan/springboot-demo:v1.0 ports: - containerPort: 8080 --- # 创建Pod的Service apiVersion: v1 kind: Service metadata: name: springboot-demo spec: ports: - port: 80 protocol: TCP targetPort: 8080 selector: app: springboot-demo --- # 创建Ingress，定义访问规则 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: springboot-demo spec: rules: - host: springboot.jack.com http: paths: - path: / backend: serviceName: springboot-demo servicePort: 80 编写k8s-deploy-springboot-demo.sh 文件 vi /root/.jenkins/workspace/scripts/k8s-deploy-springboot-demo.sh kubectl delete -f springboot-demo.yaml kubectl apply -f /root/.jenkins/workspace/scripts/springboot-demo.yaml echo \"k8s deploy success!\" 编写pipeline node &amp;#123; def mvnHome stage('Preparation') &amp;#123; git 'https://github.com/itcrazy2016/springboot-demo.git' &amp;#125; stage('Maven Build') &amp;#123; sh \"mvn clean package\" &amp;#125; stage('Build Image') &amp;#123; sh \"/root/.jenkins/workspace/scripts/springboot-demo-build-image.sh\" &amp;#125; stage('K8S Deploy') &amp;#123; sh \"/root/.jenkins/workspace/scripts/k8s-deploy-springboot-demo.sh\" &amp;#125; &amp;#125; 采坑 # 01 权限 /root/.jenkins/workspace/springboot-demo@tmp/durable-8404142a/script.sh: line 1: /root/.jenkins/workspace/scripts/k8s-deploy-springboot-demo.sh: Permission denied # 解决 chmod +x /root/.jenkins/workspace/scripts/k8s-deploy-springboot-demo.sh # 02 worker02执行不了kubectl 切换到master上，cd ~ ---> cat .kube/config --->复制内容 切换到worker02上 cd ~ ---> vi .kube/config --->粘贴内容","categories":[{"name":"k8s","slug":"k8s","permalink":"https://rainsoil.github.io/categories/k8s/"},{"name":"k8s","slug":"k8s/k8s","permalink":"https://rainsoil.github.io/categories/k8s/k8s/"}],"tags":[]},{"title":"kubernetes组件之Storage(8)","slug":"k8s/kubernetes组件之Storage(8)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/k8s/kubernetes-zu-jian-zhi-storage-8/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/k8s/kubernetes-zu-jian-zhi-storage-8/","excerpt":"","text":"kubernetes组件之Storage1 VolumeOn-disk files in a Container are ephemeral, which presents some problems for non-trivial applications when running in Containers. First, when a Container crashes, kubelet will restart it, but the files will be lost - the Container starts with a clean state. Second, when running Containers together in a Pod it is often necessary to share files between those Containers. The Kubernetes Volume abstraction solves both of these problems. 2 Host 类型volume 实战 背景： 定义一个Pod, 其中包含两个contailer,都使用pod的vloume volume-pod.yaml apiVersion: v1 kind: Pod metadata: name: volume-pod spec: containers: - name: nginx-container image: nginx ports: - containerPort: 80 volumeMounts: - name: volume-pod mountPath: /nginx-volume - name: busybox-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] volumeMounts: - name: volume-pod mountPath: /busybox-volume volumes: - name: volume-pod hostPath: path: /tmp/volume-pod 创建资源 kubectl apply -f volume-pod.yaml 查看pod的运行情况 kubectl get pods -o wide 来到运行的worker 节点 docker ps | grep volume ls /tmp/volume-pod docker exec -it containerid sh ls /nginx-volume ls /busybox-volume # 看看是否同步 查看pod 中的容器里面的hosts 文件,是否一样. 发现是一样的,并且都是由pod 管理的. docker exec -it containerid cat /etc/hosts 所以一般contailer 中的存储或者网络中的内容, 不要在contailer 层面修改,而是在pod 中修改, 比如下面修改一下网络: spec: hostNetwork: true hostPID: true hostAliases: - ip: \"192.168.8.61\" hostnames: - \"test.jack.com\" containers: - name: nginx-container image: nginx 3 PersistentVolume 官网:https://kubernetes.io/docs/concepts/storage/persistent-volumes/ apiVersion: v1 kind: PersistentVolume metadata: name: my-pv spec: capacity: storage: 5Gi # 存储空间大小 volumeMode: Filesystem accessModes: - ReadWriteOnce # 只允许一个Pod进行独占式读写操作 persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp # 远端服务器的目录 server: 172.17.0.2 # 远端的服务器 说白了,PV是k8s中的资源,volume的plugin 实现,生命周期独立于pod, 封装了底层存储卷实现的字节. 注意: PV的维护通常是由运维人员、集群管理员进行维护的. 4 PersistentVolumeClaim 官网: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims 有了PV, 那Pod 如何使用呢? 为了方便使用, 我们可以设计出一个PVC 来绑定PV, 然后把PVC 交给Pod 来使用即可, apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim spec: accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 8Gi storageClassName: slow selector: matchLabels: release: \"stable\" matchExpressions: - &amp;#123;key: environment, operator: In, values: [dev]&amp;#125; 说白了, PVC 会匹配满足要求的PV[是根据size和访问模式进行匹配的],进行一一绑定,然后他们的状态都会变成Bound 也就是PVC 负责请求PV 的大小和访问方式,然后Pod 中就可以直接使用PVC了. 5 Pod 中如何使用PVC 官网: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#claims-as-volumes apiVersion: v1 kind: Pod metadata: name: mypod spec: containers: - name: myfrontend image: nginx volumeMounts: - mountPath: \"/var/www/html\" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim 6 Pod 中使用PVC 实战 背景: 使用nginx 持久化存储演示 共享存储使用nfs, 创建pv 和pvc nginx pod中使用pvc 6.1 master节点上搭建nfs nfs(network file system)网络文件系统,是FreeBSD支持的文件系统中的一种,允许网络中的计算机之间通过TCP/IP网络共享资源. 安装nfs yum install -y nfs-utils 创建nfs 目录 mkdir -p /nfs/data/ 授予权限 chmod -R 777 /nfs/data 编辑export 文件 vi /etc/exports /nfs/data *(rw,no_root_squash,sync) 使得配置生效 exportfs -r 查看生效 exportfs 启动rpcbind、nfs 服务 systemctl restart rpcbind &amp;&amp; systemctl enable rpcbind systemctl restart nfs &amp;&amp; systemctl enable nfs 查看rpc 注册的情况 rpcinfo -p localhost showmount测试 showmount -e master-ip 所有的节点上都安装客户端 yum -y install nfs-utils systemctl start nfs &amp;&amp; systemctl enable nfs 6.2 创建PV&amp;PVC&amp;Nginx 在nfs 服务器创建所需要的目录 mkdir -p /nfs/data/nginx 定义PV/PVC/Nginx的nginx-pv-demo.yaml 文件 # 定义PV apiVersion: v1 kind: PersistentVolume metadata: name: nginx-pv spec: accessModes: - ReadWriteMany capacity: storage: 2Gi nfs: path: /nfs/data/nginx server: 192.168.56.10 --- # 定义PVC，用于消费PV apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nginx-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 2Gi --- # 定义Pod，指定需要使用的PVC apiVersion: apps/v1beta1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - image: nginx name: mysql ports: - containerPort: 80 volumeMounts: - name: nginx-persistent-storage mountPath: /usr/share/nginx/html volumes: - name: nginx-persistent-storage persistentVolumeClaim: claimName: nginx-pvc 根据yaml 创建资源并且查看资源 kubectl apply -f nginx-pv-demo.yaml kubectl get pv,pvc kubectl get pods -o wide 测试持久化存储 在/nfs/data/nginx 上新建文件, 写上内容 kubectl get pods -o wide , 获取nginx 的ip地址 curl nginx-pod-ip/1.html kubectl exec -it nginx-pod bash,进入/usr/share/nginx/html 目录查看 kubectl delete pod nginx-pod 查看新的nginx-pod的ip 并且访问nginx-pod-ip/1.html 7 StorageClass上面手动管理Pv的方式还是有点low, 能不能更加灵活一点点呢? 官网：https://kubernetes.io/docs/concepts/storage/storage-classes/ nfs github：github：https://github.com/kubernetes-incubator/external-storage/tree/master/nfs A StorageClass provides a way for administrators to describe the “classes” of storage they offer. Different classes might map to quality-of-service levels, or to backup policies, or to arbitrary policies determined by the cluster administrators. Kubernetes itself is unopinionated about what classes represent. This concept is sometimes called “profiles” in other storage systems. Each StorageClass contains the fields provisioner, parameters, and reclaimPolicy, which are used when a PersistentVolume belonging to the class needs to be dynamically provisioned. The name of a StorageClass object is significant, and is how users can request a particular class. Administrators set the name and other parameters of a class when first creating StorageClass objects, and the objects cannot be updated once they are created. StorageClass 声明存储的插件,用于自动创建PV 说白了, 就是创建PV的模板,其中有两个最重要的部分: PV属性和创建此PV 所需要的插件 可以为PV 指定 storageClassName 属性, 标识PV 归属于哪一个Class apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: standard provisioner: kubernetes.io/aws-ebs parameters: type: gp2 reclaimPolicy: Retain allowVolumeExpansion: true mountOptions: - debug volumeBindingMode: Immediate 对于PV 或者StorageClass 只能对应一个后端存储 对于手动的情况,一般我们会创建很多的PV, 等有PVC 需要使用的事情就可以直接使用了. 对于自动的情况,那么就由storageClass 来自动管理创建 如果Pod想要使用共享存储,一般会在创建PVC、PV 中描述了想要什么类型的后端存储,空间等, k8s 从而会匹配对应的PV, 如果没有匹配成功,Pod就会处于Pending 状态.Pod 中使用只需要像使用volume 一样,指定名字就可以使用了, 一个Pod可以使用多个PVC,一个PVC 也可以使用多个Pod 使用. 一个PVC 可以绑定多个PV, 一个PV 只能对应一种后端存储. **** 有了StorageClass 之后的PVC 可以变成这样. kind: PersistentVolumeClaim apiVersion: v1 metadata: name: test-claim1 spec: accessModes: - ReadWriteMany resources: requests: storage: 1Mi storageClassName: nfs StorageClass 之所以能够动态供给PV, 是因为Provisioner，也就是Dynamic Provisioning 但是NFS 这种类型, k8s 中是默认没有Provisioner 插件的, 需要自己创建. 8 StorageClass 实战github：https://github.com/kubernetes-incubator/external-storage/tree/master/nfs 准备一个NFS 服务器.并且确保可以正常工作,创建持久化需要的目录 path: /nfs/data/jack server: 121.41.10.13 比如mkdir -p /nfs/data/jack 创建资源 rbac.yaml kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-provisioner-runner rules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-provisioner subjects: - kind: ServiceAccount name: nfs-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-provisioner rules: - apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-provisioner subjects: - kind: ServiceAccount name: nfs-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: Role name: leader-locking-nfs-provisioner apiGroup: rbac.authorization.k8s.io 然后启动 kubectl apply -f rbac.yaml deployment.yaml apiVersion: v1 kind: ServiceAccount metadata: name: nfs-provisioner --- kind: Deployment apiVersion: extensions/v1beta1 metadata: name: nfs-provisioner spec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: example.com/nfs - name: NFS_SERVER value: 192.168.56.10 - name: NFS_PATH value: /nfs/data/jack volumes: - name: nfs-client-root nfs: server: 192.168.56.10 path: /nfs/data/jack 启动kubectl apply -f deployment.yaml class.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: example-nfs provisioner: example.com/nfs 启动 kubectl apply -f class.yaml 创建pvc , my-pvc.yaml kind: PersistentVolumeClaim apiVersion: v1 metadata: name: my-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 1Mi # 这个名字要和上面创建的storageclass名称一致 storageClassName: example-nfs 创建nginx 资源 , nginx-pod.yaml kind: Pod apiVersion: v1 metadata: name: nginx spec: containers: - name: nginx image: nginx volumeMounts: - name: my-pvc mountPath: \"/usr/jack\" restartPolicy: \"Never\" volumes: - name: my-pvc persistentVolumeClaim: claimName: my-pvc kubectl apply -f nginx-pod.yaml kubectl exec -it nginx bash cd /usr/jack # 进行同步数据测试 9 PV的状态和回收策略9.1 PV的状态 Available: 表示当前的PV 没有被绑定 Bound: PVC 没有在使用PV,需要管理员手动释放PV Released: 资源回收失败 9.2 PV 回收策略 Retain: 表示删除PVC的时候,PV 不会一起删除,而是变成Released 状态等待管理员手动清理 Recycle: 在Kubernetes 新版本就不用了,采用动态PV 的方式来替代 Delete: 表示删除PVC的时候,PV 也会一起删除,同时也删除PV 所指向的实际存储地址. 注意: 目前只有NFS和HostPath支持Recycle策略。AWS EBS、GCE PD、Azure Disk和Cinder支持Delete策略","categories":[{"name":"k8s","slug":"k8s","permalink":"https://rainsoil.github.io/categories/k8s/"},{"name":"k8s","slug":"k8s/k8s","permalink":"https://rainsoil.github.io/categories/k8s/k8s/"}],"tags":[]},{"title":"kubectl常用命令(6)","slug":"k8s/kubectl常用命令(6)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/k8s/kubectl-chang-yong-ming-ling-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/k8s/kubectl-chang-yong-ming-ling-6/","excerpt":"","text":"1、查看集群状态kubectl version --short=true 查看客户端及服务端程序版本信息 kubectl cluster-info 查看集群信息 2、创建资源对象kubectl run name --image=(镜像名) --replicas=(备份数) --port=(容器要暴露的端口) --labels=(设定自定义标签) kubectl create -f **.yaml 陈述式对象配置管理方式 kubectl apply -f **.yaml 声明式对象配置管理方式（也适用于更新等） 3、查看资源对象kubectl get namespace 查看命名空间 kubectl get pods,services -o wide (-o 输出格式 wide表示plain-text) kubectl get pod -l \"key=value,key=value\" -n kube-system (-l 标签选择器(多个的话是与逻辑)，-n 指定命名空间，不指定默认default) kubectl get pod -l \"key1 in (val1,val2),!key2\" -L key (-l 基于集合的标签选择器, -L查询结果显示标签) 注意：为了避免和shell解释器解析!,必须要为此类表达式使用单引号 kubectl get pod -w(-w 监视资源变动信息) 4、打印容器中日志信息kubectl logs name -f -c container_name -n kube-system (-f 持续监控，-c如果pod中只有一个容器不用加) 5、在容器中执行命令kubectl exec name -c container_name -n kube-system -- 具体命令 kubectl exec -it pod_name /bin/sh 进入容器的交互式shell 6、删除资源对象kubectl delete [pods/services/deployments/...] name 删除指定资源对象 kubectl delete [pods/services/deployments/...] -l key=value -n kube-system 删除kube-system下指定标签的资源对象 kubectl delete [pods/services/deployments/...] --all -n kube-system 删除kube-system下所有资源对象 kubectl delete [pods/services/deployments/...] source_name --force --grace-period=0 -n kube-system 强制删除Terminating的资源对象 kubectl delete -f xx.yaml kubectl apply -f xx.yaml --prune -l (一般不用这种方式删除) kubectl delete rs rs_name --cascade=fale(默认删除控制器会同时删除其管控的所有Pod对象，加上cascade=false就只删除rs) 7、更新资源对象kubectl replace -f xx.yaml --force(--force 如果需要基于此前的配置文件进行替换，需要加上force) 8、将服务暴露出去(创建Service)kubectl expose deployments/deployment_name --type=\"NodePort\" --port=(要暴露的容器端口) --name=(Service对象名字) 9、扩容和缩容kubectl scale deployment/deployment_name --replicas=N kubectl scale deployment/deployment_name --replicas=N --current-replicas=M 只有当前副本数等于M时才会执行扩容或者缩容 10、查看API版本kubectl api-versions 11、在本地主机上为API Server启动一个代理网关kubectl proxy --port=8080 之后就可以通过curl来对此套字节发起访问请求 curl localhost:8080/api/v1/namespaces/ | jq .items[].metadata.name (jq可以对json进行过滤) 12、当定义资源配置文件时，不知道怎么定义的时候，可以查看某类型资源的配置字段解释kubectl explain pods/deployments/...(二级对象可用类似于pods.spec这种方式查看) 13、查看某资源对象的配置文件kubectl get source_type source_name -o yaml --export(--export表示省略由系统生成的信息) 后面加 > file.yaml就可以快速生成一个配置文件了 14、标签管理相关命令kubectl label pods/pod_name key=value 添加标签,如果是修改的话需要后面添加--overwrite kubectl label nodes node_name key=value 给工作节点添加标签，后续可以使用nodeSelector来指定pod被调度到指定的工作节点上运行 15、注解管理相关命令kubectl annotate pods pod_name key=value 16、patch修改Deployment控制器进行控制器升级kubectl patch deployment deployment-demo -p '&#123;\"spec\": &#123;\"minReadySeconds\": 5&#125;&#125;'(-p 以补丁形式更新补丁形式默认是json) kubectl set image deployments deployment-demo myapp=ikubernetes/myapp:v2 修改depolyment中的镜像文件 kubectl rollout status deployment deployment-demo 打印滚动更新过程中的状态信息 kubectl get deployments deployment-demo --watch 监控deployment的更新过程 kubectl kubectl rollout pause deployments deployment-demo 暂停更新 kubectl rollout resume deployments deployment-demo 继续更新 kubectl rollout history deployments deployment-demo 查看历史版本(能查到具体的历史需要在apply的时候加上--record参数) kubectl rollout undo deployments deployment-demo --to-revision=2 回滚到指定版本，不加--to-version则回滚到上一个版本","categories":[{"name":"k8s","slug":"k8s","permalink":"https://rainsoil.github.io/categories/k8s/"},{"name":"k8s","slug":"k8s/k8s","permalink":"https://rainsoil.github.io/categories/k8s/k8s/"}],"tags":[]},{"title":"Kubernetes之入门篇(1)","slug":"k8s/Kubernetes之入门篇(1)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/k8s/kubernetes-zhi-ru-men-pian-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/k8s/kubernetes-zhi-ru-men-pian-1/","excerpt":"","text":"Kubernetes之入门篇1. K8S核心组件和架构图K8S Docs Concepts 先从contailer 开始, K8S 既然是容器编排工具, 那么一定会有contailer 那k8s 如何操作这些contailer呢? k8s 不想直接操作这些contailer, 因为操作contailer 是docker 做的事情,k8s 中有自己的操作单位,称之为Prod 说白了, Prod 就是一个或者多个contailer的集合. 看看官网是怎么描述的? https://kubernetes.io/docs/concepts/workloads/pods/pod/ A Pod (as in a pod of whales or pea pod) is a group of one or more containers (such as Docker containers), with shared storage/network, and a specification for how to run the containers. A Pod’s contents are always co-located and co-scheduled, and run in a shared context. A Pod models an application-specific “logical host” - it contains one or more application containers which are relatively tightly coupled — in a pre-container world, being executed on the same physical or virtual machine would mean being executed on the same logical host 那Prod 的维护谁来做呢? 那就是ReplicaSet, 通过selector 来进行管理 ​ 看官网是怎么描述的. https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/ A ReplicaSet is defined with fields, including a selector that specifies how to identify Pods it can acquire, a number of replicas indicating how many Pods it should be maintaining, and a pod template specifying the data of new Pods it should create to meet the number of replicas criteria. A ReplicaSet then fulfills its purpose by creating and deleting Pods as needed to reach the desired number. When a ReplicaSet needs to create new Pods, it uses its Pod template. Prod 和ReplicaSet 的状态如何维护和检测呢? Deployment 看看官网是如何描述的, https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ A Deployment provides declarative updates for Pods and ReplicaSets. You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments. 不妨把相同的或者有关联的Prod 分门别类一下, 那怎么分类呢? Lable 官网是如何描述的： https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ Labels are key/value pairs that are attached to objects, such as pods 使得相同的lable 的service 要是能够有一个名称就好了,service 看官网上怎么说:https://kubernetes.io/docs/concepts/services-networking/service/ An abstract way to expose an application running on a set of Pods as a network service. With Kubernetes you don’t need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them. 上述说了那么多, Prod 运行在哪里呢? 当然是机器了,比如一台centos机器,我们把这个机器称之为Node 看看官网怎么说: https://kubernetes.io/docs/concepts/architecture/nodes/ A node is a worker machine in Kubernetes, previously known as a minion. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. See The Kubernetes Node section in the architecture design doc for more details. 难道只有一个Node, 显然不太合适, 多台Node共同组成集群. 此时我们把目光转移到由3个Node 节点组成的Matser-Node 集群. 这个集群要配合完成一些工作,总要有一些组件的支持把? 接下来我们想想有哪些组件, 然后画一个相对完整的架构图. 总要有一个操作集群的客户端, 也就是跟集群打交道 kubectl 请求肯定是到达Master Node, 然后再分配给Worker Node, 创建Prod 之类的, 关键是命令通过kubectl 过来之后, 是不是要认证授权一下? 请求过来之后,Master Node 中谁来接收? APIServer API 收到请求后,接下来是调用哪个Worker Node 创建Prod、Contailer 之类的，的要有调度策略 [Scheduler][https://kubernetes.io/docs/concepts/scheduling/kube-scheduler/] Scheduler 通过不同的策略,真正要分发请求到不同的worker Node 上创建内容,具体谁负责? Controlelr Manage workder Node 接收到创建请求后,具体谁来负责kebectl 服务,最终会调用kebectl 会调用Docker Engine,创建对应容器,这边是不是也反应出来一点, 在Node 上需要有Docker Engine,不然怎么创建维护容器呢? 会不会涉及到域名解析的问题? DNS 是否需要有监控面板能够检测到整个集群的状态? Dashboard 集群中这些数据如何保存? 分布式存储 ETCD 至于像容器的持久化存储,网络等 不妨把这个图翻转一下方便查看 k8s官网架构图 https://kubernetes.io/docs/concepts/architecture/cloud-controller/ 2. k8s的安装2.1 最艰难的方式Kelsey Hightower 2.2 在线play-with-k8s(只能用4个小时)网址: https://labs.play-with-k8s.com/ [node1 ~]$ WARNING!!!! This is a sandbox environment. Using personal credentials is HIGHLY! discouraged. Any consequences of doing so, are completely the user's responsibilites. You can bootstrap a cluster as follows: 1. Initializes cluster master node: kubeadm init --apiserver-advertise-address $(hostname -i) 2. Initialize cluster networking: kubectl apply -n kube-system -f \\ \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\" 3. (Optional) Create an nginx deployment: kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml 2.3 Cloud 上搭建 github:https://github.com/kubernetes/kops 2.4 企业级解决方法CoreOS coreos:https://coreos.com/tectonic/ 2.5 Minikube k8s 单节点, 适合本地学习使用 官网: https://kubernetes.io/docs/setup/learning-environment/minikube/ Github: https://github.com/kubernetes/minikube 2.6 Kubeadm本地多节点 Github: https://github.com/kubernetes/kubeadm 3. 使用Minikube 搭建单节点k8s3.1 windowkebectl官网 minikebe官网 选择任意一种虚拟化方式 Hyper-V VirtualBox 安装kebectl 根据官网步骤或直接下载 https://storage.googleapis.com/kubernetesrelease/release/v1.16.2/bin/windows/amd64/kubectl.exe 配置kubectl.exe 所在路径的的环境变量,使得cmd 窗口可以直接使用kebectl 命令 kebectl version 检查是否配置成功 安装minikebe 根据官网步骤或者直接下载 https://github.com/kubernetes/minikube/releases/download/v1.5.2/minikubewindows-amd64.exe 修改minikube-windows-amd64.exe 为 minikube.exe 配置minikube 所在路径的环境变量,使得cmd 创建可以直接使用minikube 命令 minikube version 检查是否配置 使用minikube 创建单节点的k8s minikube start --vm-driver=virtualbox --image-repository=gcr.azk8s.cn/googlecontainers 小结 其实就是通过minikube 创建一个虚拟机,这个虚拟机中安装好了单节点的k8s 环境然后通过kubectl 进行交互 ## 创建k8s minikube start ## 删除k8s minikube delete ## 进入到k8s的容器中 minikube ssh ## 查看状态 minikube status ## 进入到dashboard minikube dashboard 3.2 centoskebectl官网 minikube 安装docker 安装kubectl 下载 curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl 授权 chmod +x ./kubectl 添加到环境变量 sudo mv ./kubectl /usr/local/bin/kubectl 检查 kubectl version 安装minikube 下载 wget https://github.com/kubernetes/minikube/releases/download/v1.5.2/minikubelinux-amd64 配置环境变量 sudo mv minikube-linux-amd64 minikube &amp;&amp; chmod +x minikube &amp;&amp; mv minikube /usr/local/bin/ 检查 minikube version 使用minikebe 创建单节点的k8s minikube start --vm-driver=none --image-repository=gcr.azk8s.cn/googlecontainers 3.3 Mac OS也是下载安装kebectl 和minikebe,选择virtualbox,然后minikebe start, 就可以通过kebectl 操作. 4. 先感受一下K8s既然已经通过minikebe 搭建了单节点的k8s,不妨先来感受一下组件的存在和操作 4.1 查看连接信息kubectl config view kubectl config get-contexts kubectl cluster-info 4.2 体验Prod 创建prod_nginx.yaml apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 根据prod_nginx.yaml 文件创建prod kubectl apply -f pod_nginx.yaml 查看prod kubectl get pods kubectl get pods -o wide kubectl describe pod nginx 进入到nginx容器中 # kubectl进入 kubectl exec -it nginx bash # 通过docker进入 minikube ssh docker ps docker exec -it containerid bash 访问nginx, 端口转发 # 若在minikube中，直接访问 # 若在物理主机上，要做端口转发 kubectl port-forward nginx 8080:80 删除prod kubectl delete -f pod_nginx.yaml","categories":[{"name":"k8s","slug":"k8s","permalink":"https://rainsoil.github.io/categories/k8s/"},{"name":"k8s","slug":"k8s/k8s","permalink":"https://rainsoil.github.io/categories/k8s/k8s/"}],"tags":[]},{"title":"JVM入门之类加载器和运行时数据区(1)","slug":"jvm/JVM入门之类加载器和运行时数据区(1)","date":"2022-01-04T02:42:07.245Z","updated":"2022-01-04T02:42:07.245Z","comments":true,"path":"2022/01/04/jvm/jvm-ru-men-zhi-lei-jia-zai-qi-he-yun-xing-shi-shu-ju-qu-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/jvm/jvm-ru-men-zhi-lei-jia-zai-qi-he-yun-xing-shi-shu-ju-qu-1/","excerpt":"","text":"JVM入门之类加载器和运行时数据区1. 官网1.1 JDK8 官网: https://docs.oracle.com/javase/8/ 1.2 The relation of JDK/JRE/JVMReference -&gt; Developer Guides -&gt; 定位到:https://docs.oracle.com/javase/8/docs/index.html Oracle has two products that implement Java Platform Standard Edition (Java SE) 8: Java SE Development Kit (JDK) 8 and Java SE Runtime Environment (JRE) 8. JDK 8 is a superset of JRE 8, and contains everything that is in JRE 8, plus tools such as the compilers and debuggers necessary for developing applets and applications. JRE 8 provides the libraries, the Java Virtual Machine (JVM), and other components to run applets and applications written in the Java programming language. Note that the JRE includes components not required by the Java SE specification, including both standard and non-standard Java components. The following conceptual diagram illustrates the components of Oracle’s Java SE products: 2.源码到类文件2.1 源码准备一个Person 的类 public class Person &amp;#123; private String name; private int age; private static String address; private final static String hobby = \"Programming\"; public void say() &amp;#123; System.out.println(\"person say...\"); &amp;#125; public int calc(int op1, int op2) &amp;#123; return op1 + op2; &amp;#125; &amp;#125; 编译: javac Person.java -&gt;Person.class 2.2 编译过程Person.java -&gt; 语法分析器 -&gt; tokens流 -&gt; 语法分析器 -&gt; 语法树/抽象语法树 -&gt; 语法分析器 -&gt; 注解抽象语法树 -&gt;字节码生成器 -&gt; Person.class 文件 2.3 类文件(class 文件) 官网The class File Format : https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html cafe babe 0000 0033 002c 0a00 0600 1d09 001e 001f 0800 200a 0021 0022 0700 2307 0024 0100 046e 616d 6501 0012 4c6a 6176 612f 6c61 6e67 2f53 7472 696e 673b 0100 0361 6765 0100 0149 0100 0761 6464 7265 7373 0100 0568 6f62 6279 0100 0d43 6f6e 7374 616e 7456 616c 7565 0800 2501 0006 3c69 6e69 743e 0100 0328 2956 0100 0443 6f64 6501 000f 4c69 6e65 4e75 6d62 6572 5461 626c 6501 0012 4c6f 6361 6c56 6172 6961 626c 6554 6162 6c65 0100 0474 6869 7301 0010 4c63 6f6d 2f6a 766d 2f50 6572 736f 6e3b 0100 0373 6179 0100 0463 616c 6301 0005 2849 4929 4901 0003 6f70 3101 0003 6f70 3201 000a 536f 7572 6365 4669 6c65 0100 0b50 6572 736f 6e2e 6a61 7661 0c00 0f00 1007 0026 0c00 2700 2801 000d ...... magic(魔数): The magic item supplies the magic number identifying the class file format; it has the value 0xCAFEBABE. cafe babe minor_version, major_version 0000 0034 对应10进制的52，代表JDK 8中的一个版本 constant_pool_count 0027 对应十进制27，代表常量池中27个常量 ClassFile &#123; u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count]; &#125; .class 字节码文件 魔数与class 文件版本 常量池 访问标识 类索引、父类索引、接口索引 字段表集合 方法表集合 属性表集合 3. 类文件到虚拟机(类加载过程)3.1 装载(Load) 查找和导入class 文件 通过一个类的全限定名获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法去的运行时数据结构 在java 堆中生成一个代表这个类的java.lang.Class 对象, 作为对方法区中这些数据的访问入口 3.2 链接(Link)3.2.1 验证(Verify) 保证被加载类的正确性 文件格式验证 元数据验证 字节码验证 符号引用验证 3.2.2 准备(Prepare) 为类的静态变量分配内存,并将其初始化为默认值 3.2.3 初始化(Initialize) 对类的静态变量、静态代码块执行初始化操作 3.4 类加载机制图解 使用和卸载并不算是类加载过程,只是画完整了一下 4. 类装载器ClassLoader在装载(Load) 阶段,其中第(1) 步同故宫类的全限定名获取其定义的二进制字节流,需要借助类装载器完成, 顾名思义,就是用来装载Class 文件的. 通过一个类的全限定名获取定义此类的二进制字节流 4.1 分类 Bootstrap ClassLoader 负责加载$JAVA_HOME 中jre/lib/rt.jar 里面所有的class 或Xbootclassoath 选项指定的jar包,由C++ 实现,不是ClassLoader 子类 Extension ClassLoader 负责加载java 平台中扩展功能的一些jar包. 包括$JAVA_HOME 中jre/lib/*.jar 或-Djava.ext.dirs 指定目录下的jar包. App ClassLoader 负责加载classpath 中指定的jar 包以及-Djava.class.path 所指定目录下的类和jar 包 Custom ClassLoader 通过java.lang.ClassLoader 的子类自定义加载class,属于应用策划稿内需根据自身需要自定义的classLoader,如tomcat、jboss 都会根据j2ee 规范自动实现classLoader 4.2 图解 4.3 加载原理检查某个类是否已经加载,顺序是自底向上的,从Costom ClassLoader到Bootstrap ClassLoader逐层检查,只要某个ClassLoader 已经加载,就视为已经加载此类,保证此类所以的ClassLoader 只加载一次. 加载的顺序是自顶向下的,也就是由上层来逐层的尝试加载此类. 双亲委派模式 定义: 如果一个类加载器在接收到加载类的请求后, 它首先不会自己去尝试去加载这个类,而是把这个请求任务委托给父类加载器去完成,依次递归, 如果父类加载器可以完成类加载任务,就成功返回,只有父类加载器无法完成此加载任务的时候,才自己去加载. 优势:java类随着加载它的类加载器一起具备了一种带有优先级的层次关系,比如,Java 中的Object类, 它存放在rt.jar 之中, 无论哪一个类加载器要加载此类, 最终都是委派给处于模型最顶端的启动类加载器进行加载,因此Object 类在各种类加载环境中都是同一个类. 如果不采用双亲委派模型,那么由各个类加载器自己加载的话,那么系统中就会存在多种不同的Object 类. 破坏: 可以继承ClassLoader 类, 然后重写 其中的loadClass 方法,其他方式大家可以自己了解扩展一下. 5 运行时数据区(Run-Time Data Areas)在装载阶段的第2、3步, 可以发现有运行时数据、堆、方法区等名词 将这个字节流所代表的静态存储结构转化位方法区的运行时数据结构 在java堆中生成一个代表这个类的java.lang.Class 对象,作为对方法区中这些数据的访问入口 说白了,就是类文件被类装载器装载进来之后,类中的内容(比如常量、变量、方法、对象等这些数据总要有个去处,也就是要存储起来, 存储的位置肯定在JVM中有对应的空间) 5.1 官网概况https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5 The Java Virtual Machine defines various run-time data areas that are used during execution of a program. Some of these data areas are created on Java Virtual Machine start-up and are destroyed only when the Java Virtual Machine exits. Other data areas are per thread. Per-thread data areas are created when a thread is created and destroyed when the thread exits. 5.2 图解 5.3 常规理解5.3.1 Method Area(方法区)方法区是各个线程共享的内存区域,在虚拟机启动时候创建 用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 虽然java虚拟机规范把方法区描述为堆的一个逻辑部分, 但是它却又一个别名叫做Non-Heap(非堆), 目的是与Java 堆区分开来. 当方法区无法满足内存分配需求的时候,将抛出OutOfMemoryError 异常 The Java Virtual Machine has a method area that is shared among all Java Virtual Machine threads. The method area is analogous to the storage area for compiled code of a conventional language or analogous to the “text” segment in an operating system process. It stores per-class structures such as the run-time constant pool, field and method data, and the code for methods and constructors, including the special methods (§2.9) used in class and instance initialization and interface initialization. If memory in the method area cannot be made available to satisfy an allocation request, the Java Virtual Machine throws an OutOfMemoryError. 此时回看装载阶段的第二步: 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 如果这个时候把从Class 文件到装载的第1、2步合并起来理解的话, 可以画个图 值得说明的是 方法区在JDK1.8z 中就是Metaspace, jdk1.6或7 中就是Perm Space Run-Time Constant Pool Class 文件中除了有类的版本、字段、方法、接口描述信息外，还有一项信息就是常量池,用于存放编译时期生成的各种字面量和符号引用,这部分内容将在类加载后进入方法区的运行时常量池中存放. Each run-time constant pool is allocated from the Java Virtual Machine’s method area (§2.5.4).s 5.3.2 Heap(堆)java堆是java虚拟机所管理的内存中最大的一块,在虚拟机启动的时候创建, 被所有线程共享 java对象实例以及数组都在堆上进行分配. The Java Virtual Machine has a heap that is shared among all Java Virtual Machine threads. The heap is the run-time data area from which memory for all class instances and arrays is allocated. The heap is created on virtual machine start-up. 此时回看装载阶段的第三步: 在java 堆中生成一个代表这个类的java.lang.Class 对象,作为方法区中这些数据的入口 5.3.3 Java Virtual Machine Stacks(java虚拟机栈)经过上面的分析,类加载机制的装载过程已经完成,后续的链接、初始化也会相应的生效. 假如目前的阶段是初始化完成了,后续做啥呢? 肯定是User使用了, 不用的话这样折腾来折腾去有什么意义呢? 那怎样才能被使用到呢? 换句话说里面的内容怎么样才能被执行呢? 比如通过主函数main调用其他的方法,这种方法实际上是main线程执行之后调用的方法,即要想使用里面的内容,得要以线程为单位,执行相应的方法才行. 那一个线程执行的状态是如何维护的呢? 一个线程可以执行多少方法? 这样的关系是如何维护的呢? 虚拟机栈是一个线程执行的区域,保存着一个线程中方法的调用状态, 换句话说,一个java线程的运行状态,由一个虚拟机栈来保存,所以虚拟机栈肯定是线程私有的,独有的,随着线程的创建而创建. 每一个被线程执行的方法,为该栈的栈帧,即每一个方法对应一个栈帧. 调用一个方法, 就会向栈中压入一个栈帧,一个方法调用完成后,就会把该栈帧从栈中弹出. Each Java Virtual Machine thread has a private Java Virtual Machine stack, created at the same time as the thread. A Java Virtual Machine stack stores frames (§2.6). 画图理解栈和栈帧 5.3.4 The pc Register(程序计数器)我们都知道一个JVM 进程中有多个线程在执行,而线程中的内容是否能够拥有执行权, 是根据CPU调度来的. 假如线程A正在执行到某个地方,突然失去了CPU的执行权,切换到线程B了,然后当线程A 重新获取到CPU执行权的时候,怎么才能继续执行呢? 这就是需要在线程中维护一个变量,记录线程执行到的位置. 程序计数器占用的内存很小,由于java虚拟机的多线程是通过线程轮流切换, 并分配处理器执行时间的方法来实现的,在任意时刻,一个处理器只会执行一个线程中的指令. 因此,为了线程切换后能够恢复到正确的执行位置,每条线程需要有一个独立的程序计数器(线程私有). 如果线程正在执行java方法,则计数器记录的是正在执行的虚拟机字节码指令的地址, 如果执行的是Native 方法, 则这个计数器为空. The Java Virtual Machine can support many threads of execution at once (JLS §17). Each Java Virtual Machine thread has its own pc (program counter) register. At any point, each Java Virtual Machine thread is executing the code of a single method, namely the current method (§2.6) for that thread. If that method is not native, the pc register contains the address of the Java Virtual Machine instruction currently being executed. If the method currently being executed by the thread is native, the value of the Java Virtual Machine’s pc register is undefined. The Java Virtual Machine’s pc register is wide enough to hold a returnAddress or a native pointer on the specific platform. 5.3.5 Native Method Stacks(本地方法栈)如果当前线程执行的方法是Native类型的,这些方法就会在本地方法栈中执行.","categories":[{"name":"jvm","slug":"jvm","permalink":"https://rainsoil.github.io/categories/jvm/"},{"name":"jvm","slug":"jvm/jvm","permalink":"https://rainsoil.github.io/categories/jvm/jvm/"}],"tags":[]},{"title":"Logback日志模板","slug":"Spring Boot/Logback日志模板","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/spring-boot/logback-ri-zhi-mo-ban/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring-boot/logback-ri-zhi-mo-ban/","excerpt":"","text":"Logback 日志模板1. 配置首先需要在 springboot的 application.properties 配置文件中配置 生成日志的路径和项目名 日志路径 logging.path=/web/apps/ 项目名 spring.application.name 2. Logback.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"> &lt;springProperty scope=\"context\" name=\"LOG_HOME\" source=\"logging.path\"/> &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--> &lt;!--&lt;property name=\"LOG_HOME\" value=\"c:/crmlog\" />--> &lt;springProperty scope=\"context\" name=\"SERVICE_NAME\" source=\"spring.application.name\"/> &lt;property name=\"logback.logdir\" value=\"$&amp;#123;LOG_HOME&amp;#125;\"/> &lt;property name=\"logback.appname\" value=\"$&amp;#123;SERVICE_NAME&amp;#125;\"/> &lt;!--输出到控制台 ConsoleAppender--> &lt;appender name=\"consoleLog\" class=\"ch.qos.logback.core.ConsoleAppender\"> &lt;!--展示格式 layout--> &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"> &lt;pattern> &lt;pattern>%d [%thread] %-5level %logger&amp;#123;36&amp;#125; - %msg%n&lt;/pattern> &lt;/pattern> &lt;/layout> &lt;/appender> &lt;appender name=\"fileInfoLog\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"> &lt;!--如果只是想要 Info 级别的日志，只是过滤 info 还是会输出 Error 日志，因为 Error 的级别高， 所以我们使用下面的策略，可以避免输出 Error 的日志--> &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"> &lt;!--过滤 Error--> &lt;level>ERROR&lt;/level> &lt;!--匹配到就禁止--> &lt;onMatch>DENY&lt;/onMatch> &lt;!--没有匹配到就允许--> &lt;onMismatch>ACCEPT&lt;/onMismatch> &lt;/filter> &lt;!--日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则 如果同时有&lt;File>和&lt;FileNamePattern>，那么当天日志是&lt;File>，明天会自动把今天 的日志改名为今天的日期。即，&lt;File> 的日志都是当天的。 --> &lt;File>$&amp;#123;logback.logdir&amp;#125;/$&amp;#123;logback.appname&amp;#125;/info.log&lt;/File> &lt;!--滚动策略，按照时间滚动 TimeBasedRollingPolicy--> &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"> &lt;!--文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间--> &lt;FileNamePattern>$&amp;#123;logback.logdir&amp;#125;/$&amp;#123;logback.appname&amp;#125;/%d&amp;#123;yyyy-MM-dd&amp;#125;/info.log&lt;/FileNamePattern> &lt;!--只保留最近90天的日志--> &lt;maxHistory>90&lt;/maxHistory> &lt;!--用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志--> &lt;!--&lt;totalSizeCap>1GB&lt;/totalSizeCap>--> &lt;/rollingPolicy> &lt;!--日志输出编码格式化--> &lt;encoder> &lt;charset>UTF-8&lt;/charset> &lt;pattern>%d [%thread] %-5level %logger&amp;#123;36&amp;#125; %line - %msg%n&lt;/pattern> &lt;/encoder> &lt;/appender> &lt;appender name=\"fileErrorLog\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"> &lt;!--如果只是想要 Error 级别的日志，那么需要过滤一下，默认是 info 级别的，ThresholdFilter--> &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"> &lt;level>Error&lt;/level> &lt;/filter> &lt;!--日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则 如果同时有&lt;File>和&lt;FileNamePattern>，那么当天日志是&lt;File>，明天会自动把今天 的日志改名为今天的日期。即，&lt;File> 的日志都是当天的。 --> &lt;File>$&amp;#123;logback.logdir&amp;#125;/$&amp;#123;logback.appname&amp;#125;/error.log&lt;/File> &lt;!--滚动策略，按照时间滚动 TimeBasedRollingPolicy--> &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"> &lt;!--文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间--> &lt;FileNamePattern>$&amp;#123;logback.logdir&amp;#125;/$&amp;#123;logback.appname&amp;#125;/%d&amp;#123;yyyy-MM-dd&amp;#125;/error.log&lt;/FileNamePattern> &lt;!--只保留最近90天的日志--> &lt;maxHistory>90&lt;/maxHistory> &lt;!--用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志--> &lt;!--&lt;totalSizeCap>1GB&lt;/totalSizeCap>--> &lt;/rollingPolicy> &lt;!--日志输出编码格式化--> &lt;encoder> &lt;charset>UTF-8&lt;/charset> &lt;pattern>%d [%thread] %-5level %logger&amp;#123;36&amp;#125; %line - %msg%n&lt;/pattern> &lt;/encoder> &lt;/appender> &lt;!--指定最基础的日志输出级别--> &lt;root level=\"INFO\"> &lt;!--appender将会添加到这个loger--> &lt;appender-ref ref=\"fileInfoLog\"/> &lt;appender-ref ref=\"fileErrorLog\"/> &lt;appender-ref ref=\"consoleLog\"/> &lt;/root> &lt;/configuration>","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/"},{"name":"Spring Boot","slug":"Spring-Boot/Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/Spring-Boot/"}],"tags":[]},{"title":"Elasticsearch之Mapping","slug":"elasticsearch/Elasticsearch之Mapping","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/elasticsearch/elasticsearch-zhi-mapping/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/elasticsearch/elasticsearch-zhi-mapping/","excerpt":"","text":"Elasticsearch之Mapping1. 字段类型1. 核心类型 字符串String text keyword 数字类型Numeric long integer short byte double float half_float scaled_float 日期类型(Date) date 布尔类型(Boolean) boolean 二进制类型(binary) binary 2. 复合类型 数组类型(Array) Array 支持不针对特定的类型 对象类型(Object) object 用于单json 对象 嵌套类型 Nested nested 用于json 对象数组 3. 地理类型(Geo) 地理坐标(Geo-points) Geo-points 用于描述经纬度坐标 地理图形(Geo-Shape) Geo-Shape 用于描述复杂形状,如多边形 2. 映射Mapping 映射Mapping 用来定义一个文档(document),以及他所包含的属性(field)是如何存储和索引的,比如, 使用Mapping 来定义: 哪些字符串属性应该被看作全文属性(full text fields) 哪些属性包含数字,日期或者地理位置 文档中的所有属性是否都能被所索引(all配置) 日期的格式 自定义映射规则来执行动态添加属性 查看mapping 信息GET bank/_mapping &amp;#123; \"bank\" : &amp;#123; \"mappings\" : &amp;#123; \"properties\" : &amp;#123; \"account_number\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"address\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"age\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"balance\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"city\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"email\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"employer\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"firstname\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"gender\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"lastname\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"state\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 修改mapping 信息自动猜测的映射类型 JSON type 域 type 布尔型: true 或者false boolean 整数 123 long 浮点数 123.45 double 字符串,有效日期: 2020-01:11 date 字符串 foo bar string 3. 新版本改变Elasticsearch7 中去掉了type的概念 关系型数据库中两个数据表示独立,即使他们里面有相同名称的列也是不影响使用的,但是es中不是这样的, es 是基于lucene 开发的搜索引擎, es 中不同type 下名称相同的field 最终在lucene 中处理的方式是一样的. 两个不同type 下的两个user_name , 在es 同一个索引下其实被认为是同一个field, 你必须在两个不同的type 中定义相同的field 映射. 否则,不同type 中的相同字段名称就会在处理中出现冲突的情况,导致luence 处理效果低下. 去掉type 就是为了提高es 中处理数据的效率. Elasticsearch 7.X URL 中的type 参数是可选的,比如索引一个文档不再要求文档类型。 Elasticsearch 8.X 不再支持URL 中的type参数 解决: 将索引从多类型迁移到单类型,每种类型文档一个独立索引 将以存在的索引下的类型数据,全部迁移到指定位置即可,详见数据迁移 Elasticsearch 7.x Specifying types in requests is deprecated. For instance, indexing a document no longer requires a document type. The new index APIs are PUT &#123;index&#125;/_doc/&#123;id&#125; in case of explicit ids and POST &#123;index&#125;/_doc for auto-generated ids. Note that in 7.0, _doc is a permanent part of the path, and represents the endpoint name rather than the document type. The include_type_name parameter in the index creation, index template, and mapping APIs will default to false. Setting the parameter at all will result in a deprecation warning. The _default_ mapping type is removed. Elasticsearch 8.x Specifying types in requests is no longer supported. The include_type_name parameter is removed. 创建映射 创建索引并指定映射 PUT /my_index &amp;#123; \"mappings\": &amp;#123; \"properties\": &amp;#123; \"age\": &amp;#123; \"type\": \"integer\" &amp;#125;, \"email\": &amp;#123; \"type\": \"keyword\" &amp;#125;, \"name\": &amp;#123; \"type\": \"text\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; 添加成功返回结果: &amp;#123; \"acknowledged\" : true, \"shards_acknowledged\" : true, \"index\" : \"my_index\" &amp;#125; 查看映射GET /my_index/_mapping 返回结果: &amp;#123; \"my_index\" : &amp;#123; \"mappings\" : &amp;#123; \"properties\" : &amp;#123; \"age\" : &amp;#123; \"type\" : \"integer\" &amp;#125;, \"email\" : &amp;#123; \"type\" : \"keyword\" &amp;#125;, \"name\" : &amp;#123; \"type\" : \"text\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 添加新的字段映射PUT /my_index/_mapping &amp;#123; \"properties\": &amp;#123; \"employee-id\": &amp;#123; \"index\": false, \"type\": \"keyword\" &amp;#125; &amp;#125; &amp;#125; 这里的 &quot;index&quot;: false, 表示新增的字段不能被检索,只是一个冗余字段 更新映射对于已经存在的字段映射,我们不能更新,更新必须创建新的索引,进行数据迁移 数据迁移先创建new_my_index的正确映射,然后使用如下方式进行数据迁移 POST reindex [固定写法] &amp;#123; \"source\":&amp;#123; \"index\":\"twitter\" &amp;#125;, \"dest\":&amp;#123; \"index\":\"new_twitters\" &amp;#125; &amp;#125; 将旧索引下的type 下的数据进行迁移 POST reindex [固定写法] &amp;#123; \"source\":&amp;#123; \"index\":\"my_index\", \"twitter\":\"my_index\" &amp;#125;, \"dest\":&amp;#123; \"index\":\"new_my_index\" &amp;#125; &amp;#125; 更多详情见: https://www.elastic.co/guide/en/elasticsearch/reference/7.6/docs-reindex.html 实例:先执行 GET /bank/_search 获取到type &amp;#123; \"took\" : 102, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1000, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 1.0, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"1\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 1, \"balance\" : 39225, \"firstname\" : \"Amber\", \"lastname\" : \"Duke\", \"age\" : 32, \"gender\" : \"M\", \"address\" : \"880 Holmes Lane\", \"employer\" : \"Pyrami\", \"email\" : \"amberduke@pyrami.com\", \"city\" : \"Brogan\", \"state\" : \"IL\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"6\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 6, \"balance\" : 5686, \"firstname\" : \"Hattie\", \"lastname\" : \"Bond\", \"age\" : 36, \"gender\" : \"M\", \"address\" : \"671 Bristol Street\", \"employer\" : \"Netagy\", \"email\" : \"hattiebond@netagy.com\", \"city\" : \"Dante\", \"state\" : \"TN\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"13\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 13, \"balance\" : 32838, \"firstname\" : \"Nanette\", \"lastname\" : \"Bates\", \"age\" : 28, \"gender\" : \"F\", \"address\" : \"789 Madison Street\", \"employer\" : \"Quility\", \"email\" : \"nanettebates@quility.com\", \"city\" : \"Nogal\", \"state\" : \"VA\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"18\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 18, \"balance\" : 4180, \"firstname\" : \"Dale\", \"lastname\" : \"Adams\", \"age\" : 33, \"gender\" : \"M\", \"address\" : \"467 Hutchinson Court\", \"employer\" : \"Boink\", \"email\" : \"daleadams@boink.com\", \"city\" : \"Orick\", \"state\" : \"MD\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"20\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 20, \"balance\" : 16418, \"firstname\" : \"Elinor\", \"lastname\" : \"Ratliff\", \"age\" : 36, \"gender\" : \"M\", \"address\" : \"282 Kings Place\", \"employer\" : \"Scentric\", \"email\" : \"elinorratliff@scentric.com\", \"city\" : \"Ribera\", \"state\" : \"WA\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"25\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 25, \"balance\" : 40540, \"firstname\" : \"Virginia\", \"lastname\" : \"Ayala\", \"age\" : 39, \"gender\" : \"F\", \"address\" : \"171 Putnam Avenue\", \"employer\" : \"Filodyne\", \"email\" : \"virginiaayala@filodyne.com\", \"city\" : \"Nicholson\", \"state\" : \"PA\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"32\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 32, \"balance\" : 48086, \"firstname\" : \"Dillard\", \"lastname\" : \"Mcpherson\", \"age\" : 34, \"gender\" : \"F\", \"address\" : \"702 Quentin Street\", \"employer\" : \"Quailcom\", \"email\" : \"dillardmcpherson@quailcom.com\", \"city\" : \"Veguita\", \"state\" : \"IN\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"37\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 37, \"balance\" : 18612, \"firstname\" : \"Mcgee\", \"lastname\" : \"Mooney\", \"age\" : 39, \"gender\" : \"M\", \"address\" : \"826 Fillmore Place\", \"employer\" : \"Reversus\", \"email\" : \"mcgeemooney@reversus.com\", \"city\" : \"Tooleville\", \"state\" : \"OK\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"44\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 44, \"balance\" : 34487, \"firstname\" : \"Aurelia\", \"lastname\" : \"Harding\", \"age\" : 37, \"gender\" : \"M\", \"address\" : \"502 Baycliff Terrace\", \"employer\" : \"Orbalix\", \"email\" : \"aureliaharding@orbalix.com\", \"city\" : \"Yardville\", \"state\" : \"DE\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"49\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 49, \"balance\" : 29104, \"firstname\" : \"Fulton\", \"lastname\" : \"Holt\", \"age\" : 23, \"gender\" : \"F\", \"address\" : \"451 Humboldt Street\", \"employer\" : \"Anocha\", \"email\" : \"fultonholt@anocha.com\", \"city\" : \"Sunriver\", \"state\" : \"RI\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; 然后看到字段类型 GET /bank/_mapping 查看到 &amp;#123; \"bank\" : &amp;#123; \"mappings\" : &amp;#123; \"properties\" : &amp;#123; \"account_number\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"address\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"age\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"balance\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"city\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"email\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"employer\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"firstname\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"gender\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"lastname\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"state\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 我们看到age的类型是long, 我们想将age的类型更换为Integer 所以我们需要新建一个索引 newbank, 在新索引中更新为正确的索引 PUT /newbank &amp;#123; \"mappings\": &amp;#123; \"properties\": &amp;#123; \"account_number\": &amp;#123; \"type\": \"long\" &amp;#125;, \"address\": &amp;#123; \"type\": \"text\" &amp;#125;, \"age\": &amp;#123; \"type\": \"integer\" &amp;#125;, \"balance\": &amp;#123; \"type\": \"long\" &amp;#125;, \"city\": &amp;#123; \"type\": \"keyword\" &amp;#125;, \"email\": &amp;#123; \"type\": \"keyword\" &amp;#125;, \"employer\": &amp;#123; \"type\": \"keyword\" &amp;#125;, \"firstname\": &amp;#123; \"type\": \"text\" &amp;#125;, \"gender\": &amp;#123; \"type\": \"keyword\" &amp;#125;, \"lastname\": &amp;#123; \"type\": \"text\", \"fields\": &amp;#123; \"keyword\": &amp;#123; \"type\": \"keyword\", \"ignore_above\": 256 &amp;#125; &amp;#125; &amp;#125;, \"state\": &amp;#123; \"type\": \"keyword\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; 查看newbank的映射 GET newbank/_mapping &amp;#123; \"newbank\" : &amp;#123; \"mappings\" : &amp;#123; \"properties\" : &amp;#123; \"account_number\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"address\" : &amp;#123; \"type\" : \"text\" &amp;#125;, \"age\" : &amp;#123; \"type\" : \"integer\" &amp;#125;, \"balance\" : &amp;#123; \"type\" : \"long\" &amp;#125;, \"city\" : &amp;#123; \"type\" : \"keyword\" &amp;#125;, \"email\" : &amp;#123; \"type\" : \"keyword\" &amp;#125;, \"employer\" : &amp;#123; \"type\" : \"keyword\" &amp;#125;, \"firstname\" : &amp;#123; \"type\" : \"text\" &amp;#125;, \"gender\" : &amp;#123; \"type\" : \"keyword\" &amp;#125;, \"lastname\" : &amp;#123; \"type\" : \"text\", \"fields\" : &amp;#123; \"keyword\" : &amp;#123; \"type\" : \"keyword\", \"ignore_above\" : 256 &amp;#125; &amp;#125; &amp;#125;, \"state\" : &amp;#123; \"type\" : \"keyword\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 能够看到age的类型是integer, 将bank 中的数据迁移到newbank 中 POST _reindex &amp;#123; \"source\": &amp;#123; \"index\": \"bank\", \"type\": \"account\" &amp;#125;, \"dest\": &amp;#123; \"index\": \"newbank\" &amp;#125; &amp;#125; 返回结果: #! Deprecation: [types removal] Specifying types in reindex requests is deprecated. &amp;#123; \"took\" : 3924, \"timed_out\" : false, \"total\" : 1000, \"updated\" : 0, \"created\" : 1000, \"deleted\" : 0, \"batches\" : 1, \"version_conflicts\" : 0, \"noops\" : 0, \"retries\" : &amp;#123; \"bulk\" : 0, \"search\" : 0 &amp;#125;, \"throttled_millis\" : 0, \"requests_per_second\" : -1.0, \"throttled_until_millis\" : 0, \"failures\" : [ ] &amp;#125; 3.分词一个tokenizer（分词器）接收一个字符流，将之分割为独立的tokens（词元，通常是独立的单词），然后输出tokens流。例如：whitespace tokenizer遇到空白字符时分割文本。它会将文本“Quick brown fox!”分割为[Quick,brown,fox!]。该tokenizer（分词器）还负责记录各个terms(词条)的顺序或position位置（用于phrase短语和word proximity词近邻查询），以及term（词条）所代表的原始word（单词）的start（起始）和end（结束）的character offsets（字符串偏移量）（用于高亮显示搜索的内容）。elasticsearch提供了很多内置的分词器，可以用来构建custom analyzers（自定义分词器）。关于分词器： https://www.elastic.co/guide/en/elasticsearch/reference/7.6/analysis.html POST _analyze &amp;#123; \"analyzer\": \"standard\", \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\" &amp;#125; 返回结果: &amp;#123; \"tokens\" : [ &amp;#123; \"token\" : \"the\", \"start_offset\" : 0, \"end_offset\" : 3, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 0 &amp;#125;, &amp;#123; \"token\" : \"2\", \"start_offset\" : 4, \"end_offset\" : 5, \"type\" : \"&lt;NUM>\", \"position\" : 1 &amp;#125;, &amp;#123; \"token\" : \"quick\", \"start_offset\" : 6, \"end_offset\" : 11, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 2 &amp;#125;, &amp;#123; \"token\" : \"brown\", \"start_offset\" : 12, \"end_offset\" : 17, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 3 &amp;#125;, &amp;#123; \"token\" : \"foxes\", \"start_offset\" : 18, \"end_offset\" : 23, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 4 &amp;#125;, &amp;#123; \"token\" : \"jumped\", \"start_offset\" : 24, \"end_offset\" : 30, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 5 &amp;#125;, &amp;#123; \"token\" : \"over\", \"start_offset\" : 31, \"end_offset\" : 35, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 6 &amp;#125;, &amp;#123; \"token\" : \"the\", \"start_offset\" : 36, \"end_offset\" : 39, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 7 &amp;#125;, &amp;#123; \"token\" : \"lazy\", \"start_offset\" : 40, \"end_offset\" : 44, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 8 &amp;#125;, &amp;#123; \"token\" : \"dog's\", \"start_offset\" : 45, \"end_offset\" : 50, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 9 &amp;#125;, &amp;#123; \"token\" : \"bone\", \"start_offset\" : 51, \"end_offset\" : 55, \"type\" : \"&lt;ALPHANUM>\", \"position\" : 10 &amp;#125; ] &amp;#125; 3.1 安装ik 分词器所有的语言分词,默认都是使用的是 Standard Analyzer, 但是这个分词器对于中文的分词并不友好,为此需要安装中文的分词器,注意: 不能用默认的 elasticsearch-plugin install xxx.zip 进行自动安装 https://github.com/medcl/elasticsearch-analysis-ik/releases/download 去找见对应的es版本进行安装 我这里按爪给你es使用的docker,并且已经将elasticsearch 容器的 /usr/share/elasticsearch/plugins 目录映射到宿主机的plugins 目录下，所以比较方便的就是下载elasticsearch-analysis-ik-7.6.2.zip, 然后解压到该文件夹即可. 安装完毕后,需要重启elasticsearch` 容器. 如果不嫌麻烦的话也可以进入到容器内部然后安装 3.2 测试分词器使用默认的分词器 GET my_index/_analyze &amp;#123; \"text\":\"我是中国人\" &amp;#125; 返回结果: &amp;#123; \"tokens\" : [ &amp;#123; \"token\" : \"我\", \"start_offset\" : 0, \"end_offset\" : 1, \"type\" : \"&lt;IDEOGRAPHIC>\", \"position\" : 0 &amp;#125;, &amp;#123; \"token\" : \"是\", \"start_offset\" : 1, \"end_offset\" : 2, \"type\" : \"&lt;IDEOGRAPHIC>\", \"position\" : 1 &amp;#125;, &amp;#123; \"token\" : \"中\", \"start_offset\" : 2, \"end_offset\" : 3, \"type\" : \"&lt;IDEOGRAPHIC>\", \"position\" : 2 &amp;#125;, &amp;#123; \"token\" : \"国\", \"start_offset\" : 3, \"end_offset\" : 4, \"type\" : \"&lt;IDEOGRAPHIC>\", \"position\" : 3 &amp;#125;, &amp;#123; \"token\" : \"人\", \"start_offset\" : 4, \"end_offset\" : 5, \"type\" : \"&lt;IDEOGRAPHIC>\", \"position\" : 4 &amp;#125; ] &amp;#125; 使用ik 分词器 GET my_index/_analyze &amp;#123; \"analyzer\": \"ik_smart\", \"text\":\"我是中国人\" &amp;#125; 返回结果: &amp;#123; \"tokens\" : [ &amp;#123; \"token\" : \"我\", \"start_offset\" : 0, \"end_offset\" : 1, \"type\" : \"CN_CHAR\", \"position\" : 0 &amp;#125;, &amp;#123; \"token\" : \"是\", \"start_offset\" : 1, \"end_offset\" : 2, \"type\" : \"CN_CHAR\", \"position\" : 1 &amp;#125;, &amp;#123; \"token\" : \"中国人\", \"start_offset\" : 2, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 2 &amp;#125; ] &amp;#125; GET my_index/_analyze &amp;#123; \"analyzer\": \"ik_max_word\", \"text\":\"我是中国人\" &amp;#125; 返回结果: &amp;#123; \"tokens\" : [ &amp;#123; \"token\" : \"我\", \"start_offset\" : 0, \"end_offset\" : 1, \"type\" : \"CN_CHAR\", \"position\" : 0 &amp;#125;, &amp;#123; \"token\" : \"是\", \"start_offset\" : 1, \"end_offset\" : 2, \"type\" : \"CN_CHAR\", \"position\" : 1 &amp;#125;, &amp;#123; \"token\" : \"中国人\", \"start_offset\" : 2, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 2 &amp;#125;, &amp;#123; \"token\" : \"中国\", \"start_offset\" : 2, \"end_offset\" : 4, \"type\" : \"CN_WORD\", \"position\" : 3 &amp;#125;, &amp;#123; \"token\" : \"国人\", \"start_offset\" : 3, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 4 &amp;#125; ] &amp;#125; 3.3 自定义词库修改/usr/share/elasticsearch/plugins/ik/config中的IKAnalyzer.cfg.xml/usr/share/elasticsearch/plugins/ik/config &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"> &lt;properties> &lt;comment>IK Analyzer 扩展配置&lt;/comment> &lt;!--用户可以在这里配置自己的扩展字典 --> &lt;entry key=\"ext_dict\">&lt;/entry> &lt;!--用户可以在这里配置自己的扩展停止词字典--> &lt;entry key=\"ext_stopwords\">&lt;/entry> &lt;!--用户可以在这里配置远程扩展字典 --> &lt;entry key=\"remote_ext_dict\">http://192.168.137.14/es/fenci.txt&lt;/entry> &lt;!--用户可以在这里配置远程扩展停止词字典--> &lt;!-- &lt;entry key=\"remote_ext_stopwords\">words_location&lt;/entry> --> &lt;/properties> 原来的xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"> &lt;properties> &lt;comment>IK Analyzer 扩展配置&lt;/comment> &lt;!--用户可以在这里配置自己的扩展字典 --> &lt;entry key=\"ext_dict\">&lt;/entry> &lt;!--用户可以在这里配置自己的扩展停止词字典--> &lt;entry key=\"ext_stopwords\">&lt;/entry> &lt;!--用户可以在这里配置远程扩展字典 --> &lt;!-- &lt;entry key=\"remote_ext_dict\">words_location&lt;/entry> --> &lt;!--用户可以在这里配置远程扩展停止词字典--> &lt;!-- &lt;entry key=\"remote_ext_stopwords\">words_location&lt;/entry> --> &lt;/properties> 完成之后, 需要重启es容器,否则修改不生效. 更新完成后,es只会对新增的数据用更新分词,历史数据是不会重新分词的,如果想要历史数据重新分词,就需要执行 POST my_index/_update_by_query?conflicts=proceed http://192.168.137.14/es/fenci.txt 是一个可以访问的资源,可以放nginx下.","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/"},{"name":"elasticsearch","slug":"elasticsearch/elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/elasticsearch/"}],"tags":[]},{"title":"Elasticsearch之检索","slug":"elasticsearch/Elasticsearch之检索","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/elasticsearch/elasticsearch-zhi-jian-suo/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/elasticsearch/elasticsearch-zhi-jian-suo/","excerpt":"","text":"4. Elasticsearch之检索4. 检索4.1 样本测试数据准备一份顾客银行账户信息的虚构的JSON 文档样本,每个文档下面都用下列的schema(模式) &amp;#123; \"account_number\": 1, \"balance\": 39225, \"firstname\": \"Amber\", \"lastname\": \"Duke\", \"age\": 32, \"gender\": \"M\", \"address\": \"880 Holmes Lane\", \"employer\": \"Pyrami\", \"email\": \"amberduke@pyrami.com\", \"city\": \"Brogan\", \"state\": \"IL\" &amp;#125; 从 [https://github.com/elastic/elasticsearch/blob/master/docs/src/test/resources/accounts.json] 导入测试数据 POST bank/account/_bulk 4.2 检索4.2.1 search apiES 支持两种基本方式检索 通过REST request uri发送搜索参数(uri+搜索参数) 通过REST request body 来发送参数(uri+请求体) 信息检索 一切检索从_search开始 GET /bank/_search 检索bank 下所有信息,包括type和docs GET bank/_search?q=*&amp;sort=account_number:asc 请求参数方式检索 返回结果: &amp;#123; \"took\" : 887, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1000, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : null, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"0\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 0, \"balance\" : 16623, \"firstname\" : \"Bradshaw\", \"lastname\" : \"Mckenzie\", \"age\" : 29, \"gender\" : \"F\", \"address\" : \"244 Columbus Place\", \"employer\" : \"Euron\", \"email\" : \"bradshawmckenzie@euron.com\", \"city\" : \"Hobucken\", \"state\" : \"CO\" &amp;#125;, \"sort\" : [ 0 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"1\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 1, \"balance\" : 39225, \"firstname\" : \"Amber\", \"lastname\" : \"Duke\", \"age\" : 32, \"gender\" : \"M\", \"address\" : \"880 Holmes Lane\", \"employer\" : \"Pyrami\", \"email\" : \"amberduke@pyrami.com\", \"city\" : \"Brogan\", \"state\" : \"IL\" &amp;#125;, \"sort\" : [ 1 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"2\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 2, \"balance\" : 28838, \"firstname\" : \"Roberta\", \"lastname\" : \"Bender\", \"age\" : 22, \"gender\" : \"F\", \"address\" : \"560 Kingsway Place\", \"employer\" : \"Chillium\", \"email\" : \"robertabender@chillium.com\", \"city\" : \"Bennett\", \"state\" : \"LA\" &amp;#125;, \"sort\" : [ 2 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"3\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 3, \"balance\" : 44947, \"firstname\" : \"Levine\", \"lastname\" : \"Burks\", \"age\" : 26, \"gender\" : \"F\", \"address\" : \"328 Wilson Avenue\", \"employer\" : \"Amtap\", \"email\" : \"levineburks@amtap.com\", \"city\" : \"Cochranville\", \"state\" : \"HI\" &amp;#125;, \"sort\" : [ 3 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"4\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 4, \"balance\" : 27658, \"firstname\" : \"Rodriquez\", \"lastname\" : \"Flores\", \"age\" : 31, \"gender\" : \"F\", \"address\" : \"986 Wyckoff Avenue\", \"employer\" : \"Tourmania\", \"email\" : \"rodriquezflores@tourmania.com\", \"city\" : \"Eastvale\", \"state\" : \"HI\" &amp;#125;, \"sort\" : [ 4 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"5\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 5, \"balance\" : 29342, \"firstname\" : \"Leola\", \"lastname\" : \"Stewart\", \"age\" : 30, \"gender\" : \"F\", \"address\" : \"311 Elm Place\", \"employer\" : \"Diginetic\", \"email\" : \"leolastewart@diginetic.com\", \"city\" : \"Fairview\", \"state\" : \"NJ\" &amp;#125;, \"sort\" : [ 5 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"6\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 6, \"balance\" : 5686, \"firstname\" : \"Hattie\", \"lastname\" : \"Bond\", \"age\" : 36, \"gender\" : \"M\", \"address\" : \"671 Bristol Street\", \"employer\" : \"Netagy\", \"email\" : \"hattiebond@netagy.com\", \"city\" : \"Dante\", \"state\" : \"TN\" &amp;#125;, \"sort\" : [ 6 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"7\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 7, \"balance\" : 39121, \"firstname\" : \"Levy\", \"lastname\" : \"Richard\", \"age\" : 22, \"gender\" : \"M\", \"address\" : \"820 Logan Street\", \"employer\" : \"Teraprene\", \"email\" : \"levyrichard@teraprene.com\", \"city\" : \"Shrewsbury\", \"state\" : \"MO\" &amp;#125;, \"sort\" : [ 7 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"8\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 8, \"balance\" : 48868, \"firstname\" : \"Jan\", \"lastname\" : \"Burns\", \"age\" : 35, \"gender\" : \"M\", \"address\" : \"699 Visitation Place\", \"employer\" : \"Glasstep\", \"email\" : \"janburns@glasstep.com\", \"city\" : \"Wakulla\", \"state\" : \"AZ\" &amp;#125;, \"sort\" : [ 8 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"9\", \"_score\" : null, \"_source\" : &amp;#123; \"account_number\" : 9, \"balance\" : 24776, \"firstname\" : \"Opal\", \"lastname\" : \"Meadows\", \"age\" : 39, \"gender\" : \"M\", \"address\" : \"963 Neptune Avenue\", \"employer\" : \"Cedward\", \"email\" : \"opalmeadows@cedward.com\", \"city\" : \"Olney\", \"state\" : \"OH\" &amp;#125;, \"sort\" : [ 9 ] &amp;#125; ] &amp;#125; &amp;#125; 响应结果解释: took: es 执行搜索的时间(毫秒) time_out: 告诉我们搜索是否超时 _shards: 告诉我们多少个分片被搜索了,以及统计了成功/失败的搜索分片 hits: 搜索结果 hits.total: 搜索结果总条数 hits.hits: 实际的搜索结果(数组), 默认为前10 的文档 sort: 结果的排序key(键), 没有则按照 scort 排序 score 和max_score : 相关性得分和最高得分(全文检索用) 详细的字段信息，参照： https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started-search.html 4.3 Query DSL4.3.1 基本语法格式Elasticsearch 提供了一个可以执行查询的json 风格的DSL, 这个被称为Query DSL, 该查询语句非常全面,一个查询语句的典型结构: QUERY_NAME:&amp;#123; ARGUMENT:VALUE, ARGUMENT:VALUE,... &amp;#125; 如果针对某个字段,那么它的结构如下: &amp;#123; QUERY_NAME:&amp;#123; FIELD_NAME:&amp;#123; ARGUMENT:VALUE, ARGUMENT:VALUE,... &amp;#125; &amp;#125; &amp;#125; GET bank/_search &amp;#123; \"query\": &amp;#123; \"match_all\": &amp;#123;&amp;#125; &amp;#125;, \"from\": 0, \"size\": 5, \"sort\": [ &amp;#123; \"account_number\": &amp;#123; \"order\": \"desc\" &amp;#125; &amp;#125; ] &amp;#125; query 定义了如何查询 match_all : 查询类型(代表查询所有的数据), es中可以在query 中组合非常多的查询类型来完成复杂查询 除 了query 参数之后,我们也可以传递其他的参数以改变查询的结果,比如sort,size form+szie 限定, 完成分页功能 sort排序,多字段排序,会在前序字段相等时后续字段内部排序,否则以前序为准 4.3.2 返回部分字段GET bank/_search &amp;#123; \"query\": &amp;#123; \"match_all\": &amp;#123;&amp;#125; &amp;#125;, \"from\": 0, \"size\": 5, \"sort\": [ &amp;#123; \"account_number\": &amp;#123; \"order\": \"desc\" &amp;#125; &amp;#125; ], \"_source\": [\"balance\",\"firstname\"] &amp;#125; 返回结果: &amp;#123; \"took\" : 221, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1000, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : null, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"999\", \"_score\" : null, \"_source\" : &amp;#123; \"firstname\" : \"Dorothy\", \"balance\" : 6087 &amp;#125;, \"sort\" : [ 999 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"998\", \"_score\" : null, \"_source\" : &amp;#123; \"firstname\" : \"Letha\", \"balance\" : 16869 &amp;#125;, \"sort\" : [ 998 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"997\", \"_score\" : null, \"_source\" : &amp;#123; \"firstname\" : \"Combs\", \"balance\" : 25311 &amp;#125;, \"sort\" : [ 997 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"996\", \"_score\" : null, \"_source\" : &amp;#123; \"firstname\" : \"Andrews\", \"balance\" : 17541 &amp;#125;, \"sort\" : [ 996 ] &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"995\", \"_score\" : null, \"_source\" : &amp;#123; \"firstname\" : \"Phelps\", \"balance\" : 21153 &amp;#125;, \"sort\" : [ 995 ] &amp;#125; ] &amp;#125; &amp;#125; 4.3.3 match 匹配查询 基本类型(非字符串), 精切控制 GET bank/_search &amp;#123; \"query\": &amp;#123; \"match\": &amp;#123; \"account_number\": \"20\" &amp;#125; &amp;#125; &amp;#125; match 返回 account_number=20的数据 返回结果; &amp;#123; \"took\" : 774, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 1.0, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"20\", \"_score\" : 1.0, \"_source\" : &amp;#123; \"account_number\" : 20, \"balance\" : 16418, \"firstname\" : \"Elinor\", \"lastname\" : \"Ratliff\", \"age\" : 36, \"gender\" : \"M\", \"address\" : \"282 Kings Place\", \"employer\" : \"Scentric\", \"email\" : \"elinorratliff@scentric.com\", \"city\" : \"Ribera\", \"state\" : \"WA\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; 字符串: 全文检索 GET bank/_search &amp;#123; \"query\": &amp;#123; \"match\": &amp;#123; \"address\": \"kings\" &amp;#125; &amp;#125; &amp;#125; 全文检索,最后会按照评分进行排序,会对检索条件进行分词匹配 查询结果: &amp;#123; \"took\" : 790, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 2, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 6.095661, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"20\", \"_score\" : 6.095661, \"_source\" : &amp;#123; \"account_number\" : 20, \"balance\" : 16418, \"firstname\" : \"Elinor\", \"lastname\" : \"Ratliff\", \"age\" : 36, \"gender\" : \"M\", \"address\" : \"282 Kings Place\", \"employer\" : \"Scentric\", \"email\" : \"elinorratliff@scentric.com\", \"city\" : \"Ribera\", \"state\" : \"WA\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"722\", \"_score\" : 6.095661, \"_source\" : &amp;#123; \"account_number\" : 722, \"balance\" : 27256, \"firstname\" : \"Roberts\", \"lastname\" : \"Beasley\", \"age\" : 34, \"gender\" : \"F\", \"address\" : \"305 Kings Hwy\", \"employer\" : \"Quintity\", \"email\" : \"robertsbeasley@quintity.com\", \"city\" : \"Hayden\", \"state\" : \"PA\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; 4.3.4 match_phrase 短句匹配将需要匹配的值当成一整个单词(不分词) 进行检索 GET bank/_search &amp;#123; \"query\": &amp;#123; \"match_phrase\": &amp;#123; \"address\": \"mill road\" &amp;#125; &amp;#125; &amp;#125; 查看 address 中包含 mill road的所有记录, 并且给出相关性得分. 返回结果: &amp;#123; \"took\" : 6278, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 8.991257, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 8.991257, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; match 和match_phrase 的区别,观察如下例子: GET bank/_search &amp;#123; \"query\": &amp;#123; \"match_phrase\": &amp;#123; \"address\": \"990 Mill\" &amp;#125; &amp;#125; &amp;#125; 返回结果: &amp;#123; \"took\" : 48, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 10.919691, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 10.919691, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; 使用match 的keyword GET bank/_search &amp;#123; \"query\": &amp;#123; \"match\": &amp;#123; \"address.keyword\": \"990 Mill\" &amp;#125; &amp;#125; &amp;#125; 查看结果, 一条也没有匹配到 &amp;#123; \"took\" : 34, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 0, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : null, \"hits\" : [ ] &amp;#125; &amp;#125; 修改匹配条件为: 990 Mill Road GET bank/_search &amp;#123; \"query\": &amp;#123; \"match\": &amp;#123; \"address.keyword\": \"990 Mill Road\" &amp;#125; &amp;#125; &amp;#125; 查询出来一条数据 &amp;#123; \"took\" : 133, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 6.685111, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 6.685111, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; 文本字段的匹配,使用keyword, 匹配的条件就是要显示字段的全部值,要进行精确匹配,match_phrase 是做短语匹配的,只要是文本中包含匹配条件,就能匹配到. 4.3.5 multi_math 多字段匹配GET bank/_search &amp;#123; \"query\": &amp;#123; \"multi_match\": &amp;#123; \"query\": \"mill\", \"fields\": [ \"state\", \"address\" ] &amp;#125; &amp;#125; &amp;#125; state 或者address 中包含mill, 并且在查询的过程中 , 会对于查询条件进行分词. 查询结果: &amp;#123; \"took\" : 121, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 4, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 5.4598455, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 5.4598455, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"136\", \"_score\" : 5.4598455, \"_source\" : &amp;#123; \"account_number\" : 136, \"balance\" : 45801, \"firstname\" : \"Winnie\", \"lastname\" : \"Holland\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"198 Mill Lane\", \"employer\" : \"Neteria\", \"email\" : \"winnieholland@neteria.com\", \"city\" : \"Urie\", \"state\" : \"IL\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"345\", \"_score\" : 5.4598455, \"_source\" : &amp;#123; \"account_number\" : 345, \"balance\" : 9812, \"firstname\" : \"Parker\", \"lastname\" : \"Hines\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"715 Mill Avenue\", \"employer\" : \"Baluba\", \"email\" : \"parkerhines@baluba.com\", \"city\" : \"Blackgum\", \"state\" : \"KY\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"472\", \"_score\" : 5.4598455, \"_source\" : &amp;#123; \"account_number\" : 472, \"balance\" : 25571, \"firstname\" : \"Lee\", \"lastname\" : \"Long\", \"age\" : 32, \"gender\" : \"F\", \"address\" : \"288 Mill Street\", \"employer\" : \"Comverges\", \"email\" : \"leelong@comverges.com\", \"city\" : \"Movico\", \"state\" : \"MT\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; 4.3.6 bool 用来做复合查询复合语句可以合并,任何其他查询语句,包括复合语句,这也就是意味着复合语句之间可以互相嵌套,可以表达非常复杂的逻辑. must: 必须达到must 所列举的所有条件GET bank/_search &amp;#123; \"query\": &amp;#123; \"bool\": &amp;#123; \"must\": [ &amp;#123; \"match\": &amp;#123; \"address\": \"mill\" &amp;#125; &amp;#125;, &amp;#123; \"match\": &amp;#123; \"gender\": \"M\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; &amp;#125; 查看address=mill 和gender=M的数据 返回结果: &amp;#123; \"took\" : 21, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 3, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 6.1390967, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"136\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 136, \"balance\" : 45801, \"firstname\" : \"Winnie\", \"lastname\" : \"Holland\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"198 Mill Lane\", \"employer\" : \"Neteria\", \"email\" : \"winnieholland@neteria.com\", \"city\" : \"Urie\", \"state\" : \"IL\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"345\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 345, \"balance\" : 9812, \"firstname\" : \"Parker\", \"lastname\" : \"Hines\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"715 Mill Avenue\", \"employer\" : \"Baluba\", \"email\" : \"parkerhines@baluba.com\", \"city\" : \"Blackgum\", \"state\" : \"KY\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; must not 必须不匹配must not 所列举的所有条件查询gender=M 并且address =mill的,但是age!=38的数据 GET bank/_search &amp;#123; \"query\": &amp;#123; \"bool\": &amp;#123; \"must\": [ &amp;#123; \"match\": &amp;#123; \"address\": \"mill\" &amp;#125; &amp;#125;, &amp;#123; \"match\": &amp;#123; \"gender\": \"M\" &amp;#125; &amp;#125; ], \"must_not\": [ &amp;#123; \"match\": &amp;#123; \"age\": \"30\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; &amp;#125; 返回结果: &amp;#123; \"took\" : 90, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 3, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 6.1390967, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"136\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 136, \"balance\" : 45801, \"firstname\" : \"Winnie\", \"lastname\" : \"Holland\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"198 Mill Lane\", \"employer\" : \"Neteria\", \"email\" : \"winnieholland@neteria.com\", \"city\" : \"Urie\", \"state\" : \"IL\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"345\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 345, \"balance\" : 9812, \"firstname\" : \"Parker\", \"lastname\" : \"Hines\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"715 Mill Avenue\", \"employer\" : \"Baluba\", \"email\" : \"parkerhines@baluba.com\", \"city\" : \"Blackgum\", \"state\" : \"KY\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; should 应该达到should 列举的条件,如果达到就会增加相关文档的评分, 并不会改变查询的结果, 如果query 中只有should 且只有一种匹配规则,那么should 的条件就会被作为默认匹配条件去改变查询结果例子: 匹配lastName 应该等于Wallace的数据 GET bank/_search &amp;#123; \"query\": &amp;#123; \"bool\": &amp;#123; \"must\": [ &amp;#123; \"match\": &amp;#123; \"address\": \"mill\" &amp;#125; &amp;#125;, &amp;#123; \"match\": &amp;#123; \"gender\": \"M\" &amp;#125; &amp;#125; ], \"must_not\": [ &amp;#123; \"match\": &amp;#123; \"age\": \"30\" &amp;#125; &amp;#125; ], \"should\": [ &amp;#123; \"match\": &amp;#123; \"lastname\": \"Wallace\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; &amp;#125; 返回结果: &amp;#123; \"took\" : 18145, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 3, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 12.824207, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 12.824207, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"136\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 136, \"balance\" : 45801, \"firstname\" : \"Winnie\", \"lastname\" : \"Holland\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"198 Mill Lane\", \"employer\" : \"Neteria\", \"email\" : \"winnieholland@neteria.com\", \"city\" : \"Urie\", \"state\" : \"IL\" &amp;#125; &amp;#125;, &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"345\", \"_score\" : 6.1390967, \"_source\" : &amp;#123; \"account_number\" : 345, \"balance\" : 9812, \"firstname\" : \"Parker\", \"lastname\" : \"Hines\", \"age\" : 38, \"gender\" : \"M\", \"address\" : \"715 Mill Avenue\", \"employer\" : \"Baluba\", \"email\" : \"parkerhines@baluba.com\", \"city\" : \"Blackgum\", \"state\" : \"KY\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; 能够看到相关度越高,得分也就越高 4.3.7 Filter 结果过滤并不是所有的查询都需要产生分数,特别是哪些仅用于filter 过滤的文档 . 为了不计算分数,es 会自动检查场景并且优化查询的执行 GET bank/_search &amp;#123; \"query\": &amp;#123; \"bool\": &amp;#123; \"must\": [ &amp;#123; \"match\": &amp;#123; \"address\": \"mill\" &amp;#125; &amp;#125; ], \"filter\": [ &amp;#123; \"range\": &amp;#123; \"balance\": &amp;#123; \"gte\": 10000, \"lte\": 20000 &amp;#125; &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; &amp;#125; 这里先查询所有匹配address=mill的文档,然后再根据10000&lt;=balance&lt;=20000进行结果查询, 查询结果: &amp;#123; \"took\" : 66, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : 5.4598455, \"hits\" : [ &amp;#123; \"_index\" : \"bank\", \"_type\" : \"account\", \"_id\" : \"970\", \"_score\" : 5.4598455, \"_source\" : &amp;#123; \"account_number\" : 970, \"balance\" : 19648, \"firstname\" : \"Forbes\", \"lastname\" : \"Wallace\", \"age\" : 28, \"gender\" : \"M\", \"address\" : \"990 Mill Road\", \"employer\" : \"Pheast\", \"email\" : \"forbeswallace@pheast.com\", \"city\" : \"Lopezo\", \"state\" : \"AK\" &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; Each must, should, and must_not element in a Boolean query is referred to as a query clause. How well a document meets the criteria in each must or should clause contributes to the document’s relevance score. The higher the score, the better the document matches your search criteria. By default, Elasticsearch returns documents ranked by these relevance scores.在boolean查询中，must, should 和must_not 元素都被称为查询子句 。 文档是否符合每个“must”或“should”子句中的标准，决定了文档的“相关性得分”。 得分越高，文档越符合您的搜索条件。 默认情况下，Elasticsearch返回根据这些相关性得分排序的文档。The criteria in a must_not clause is treated as a filter. It affects whether or not the document is included in the results, but does not contribute to how documents are scored. You can also explicitly specify arbitrary filters to include or exclude documents based on structured data. “must_not”子句中的条件被视为“过滤器”。 它影响文档是否包含在结果中， 但不影响文档的评分方式。 还可以显式地指定任意过滤器来包含或排除基于结构化数据的文档。 filter 在使用过程中,并不会计算相关性得分 4.3.8 term和match 一样,匹配某个属性的值,全文检索字段用match, 其他非text字段匹配用term Avoid using the term query for text fields.避免对文本字段使用“term”查询By default, Elasticsearch changes the values of text fields as part of analysis. This can make finding exact matches for text field values difficult.默认情况下，Elasticsearch作为analysis的一部分更改’ text ‘字段的值。这使得为“text”字段值寻找精确匹配变得困难。To search text field values, use the match.要搜索“text”字段值，请使用匹配。[https://www.elastic.co/guide/en/elasticsearch/reference/7.6/query-dsl-term-query.html]( 使用term 匹配查询 GET bank/_search &amp;#123; \"query\": &amp;#123; \"term\": &amp;#123; \"address\": &amp;#123; \"value\": \"mill Road\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; 返回结果: &amp;#123; \"took\" : 26, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 0, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : null, \"hits\" : [ ] &amp;#125; &amp;#125; 一条也没有匹配到, 更换为match后, 就可以匹配到32个 也就是说, 全文检索字段用match, 其他非text 字段匹配用match 4.3.9 Aggregation 执行聚合聚合提供了从数据中分组和提取数据的能力,最简单的聚合方法大致等于SQL Group by和SQL的聚合函数, 在es中,执行搜索返回hits( 命中结果), 并且同时返回聚合结果,把响应中所有的hits(命中结果)分隔开的能力, 这是非常强大并且有效的, 你可以执行查询和多个聚合,并且在一次使用中得到各自的(任何一个)返回结果,使用一次简介和简化的API 就可以避免网络往返. size:0 不显示搜索数据 aggs 执行聚合,聚合语法如下: \"aggs\":&amp;#123; \"aggs_name这次聚合的名字，方便展示在结果集中\":&amp;#123; \"AGG_TYPE聚合的类型(avg,term,terms)\":&amp;#123;&amp;#125; &amp;#125; &amp;#125;， 例子: 搜索address 中包含mill 的所有人的年龄分布以及平均年龄,但是不显示这些人的详情GET bank/_search &amp;#123; \"query\": &amp;#123; \"match\": &amp;#123; \"address\": \"mill\" &amp;#125; &amp;#125;, \"aggs\": &amp;#123; \"ageAgg\": &amp;#123; \"terms\": &amp;#123; \"field\": \"age\", \"size\": 10 &amp;#125; &amp;#125;, \"ageAvg\": &amp;#123; \"avg\": &amp;#123; \"field\": \"age\" &amp;#125; &amp;#125;, \"balanceAvg\": &amp;#123; \"avg\": &amp;#123; \"field\": \"balance\" &amp;#125; &amp;#125; &amp;#125;,\"size\": 0 &amp;#125; 返回结果: &amp;#123; \"took\" : 1229, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 4, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : null, \"hits\" : [ ] &amp;#125;, \"aggregations\" : &amp;#123; \"ageAgg\" : &amp;#123; \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ &amp;#123; \"key\" : 38, \"doc_count\" : 2 &amp;#125;, &amp;#123; \"key\" : 28, \"doc_count\" : 1 &amp;#125;, &amp;#123; \"key\" : 32, \"doc_count\" : 1 &amp;#125; ] &amp;#125;, \"ageAvg\" : &amp;#123; \"value\" : 34.0 &amp;#125;, \"balanceAvg\" : &amp;#123; \"value\" : 25208.0 &amp;#125; &amp;#125; &amp;#125; 复杂的查询： 按照年龄聚合,并且求这些年龄段的人的平均薪资GET bank/_search &amp;#123; \"query\": &amp;#123; \"match_all\": &amp;#123;&amp;#125; &amp;#125;, \"aggs\": &amp;#123; \"ageAgg\": &amp;#123; \"terms\": &amp;#123; \"field\": \"age\", \"size\": 100 &amp;#125;, \"aggs\": &amp;#123; \"ageAvg\": &amp;#123; \"avg\": &amp;#123; \"field\": \"balance\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125;, \"size\": 0 &amp;#125; 返回结果: &amp;#123; \"took\" : 3307, \"timed_out\" : false, \"_shards\" : &amp;#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &amp;#125;, \"hits\" : &amp;#123; \"total\" : &amp;#123; \"value\" : 1000, \"relation\" : \"eq\" &amp;#125;, \"max_score\" : null, \"hits\" : [ ] &amp;#125;, \"aggregations\" : &amp;#123; \"ageAgg\" : &amp;#123; \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ &amp;#123; \"key\" : 31, \"doc_count\" : 61, \"ageAvg\" : &amp;#123; \"value\" : 28312.918032786885 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 39, \"doc_count\" : 60, \"ageAvg\" : &amp;#123; \"value\" : 25269.583333333332 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 26, \"doc_count\" : 59, \"ageAvg\" : &amp;#123; \"value\" : 23194.813559322032 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 32, \"doc_count\" : 52, \"ageAvg\" : &amp;#123; \"value\" : 23951.346153846152 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 35, \"doc_count\" : 52, \"ageAvg\" : &amp;#123; \"value\" : 22136.69230769231 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 36, \"doc_count\" : 52, \"ageAvg\" : &amp;#123; \"value\" : 22174.71153846154 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 22, \"doc_count\" : 51, \"ageAvg\" : &amp;#123; \"value\" : 24731.07843137255 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 28, \"doc_count\" : 51, \"ageAvg\" : &amp;#123; \"value\" : 28273.882352941175 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 33, \"doc_count\" : 50, \"ageAvg\" : &amp;#123; \"value\" : 25093.94 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 34, \"doc_count\" : 49, \"ageAvg\" : &amp;#123; \"value\" : 26809.95918367347 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 30, \"doc_count\" : 47, \"ageAvg\" : &amp;#123; \"value\" : 22841.106382978724 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 21, \"doc_count\" : 46, \"ageAvg\" : &amp;#123; \"value\" : 26981.434782608696 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 40, \"doc_count\" : 45, \"ageAvg\" : &amp;#123; \"value\" : 27183.17777777778 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 20, \"doc_count\" : 44, \"ageAvg\" : &amp;#123; \"value\" : 27741.227272727272 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 23, \"doc_count\" : 42, \"ageAvg\" : &amp;#123; \"value\" : 27314.214285714286 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 24, \"doc_count\" : 42, \"ageAvg\" : &amp;#123; \"value\" : 28519.04761904762 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 25, \"doc_count\" : 42, \"ageAvg\" : &amp;#123; \"value\" : 27445.214285714286 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 37, \"doc_count\" : 42, \"ageAvg\" : &amp;#123; \"value\" : 27022.261904761905 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 27, \"doc_count\" : 39, \"ageAvg\" : &amp;#123; \"value\" : 21471.871794871793 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 38, \"doc_count\" : 39, \"ageAvg\" : &amp;#123; \"value\" : 26187.17948717949 &amp;#125; &amp;#125;, &amp;#123; \"key\" : 29, \"doc_count\" : 35, \"ageAvg\" : &amp;#123; \"value\" : 29483.14285714286 &amp;#125; &amp;#125; ] &amp;#125; &amp;#125; &amp;#125; 查询所有年龄分布,并且这些年龄段中M的平均薪资和F的平均薪资以及这个年龄段的总体平均薪资GET bank/_search &amp;#123; \"query\": &amp;#123; \"match_all\": &amp;#123;&amp;#125; &amp;#125;, \"aggs\": &amp;#123; \"ageAgg\": &amp;#123; \"terms\": &amp;#123; \"field\": \"age\", \"size\": 100 &amp;#125;, \"aggs\": &amp;#123; \"genderAgg\": &amp;#123; \"terms\": &amp;#123; \"field\": \"gender.keyword\" &amp;#125;, \"aggs\": &amp;#123; \"balanceAvg\": &amp;#123; \"avg\": &amp;#123; \"field\": \"balance\" &amp;#125; &amp;#125; &amp;#125; &amp;#125;, \"ageBalanceAvg\": &amp;#123; \"avg\": &amp;#123; \"field\": \"balance\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125;, \"size\": 0 &amp;#125; 返回结果： &amp;#123; \"_shards\": &amp;#123; \"failed\": 0, \"skipped\": 0, \"successful\": 1, \"total\": 1 &amp;#125;, \"aggregations\": &amp;#123; \"ageAgg\": &amp;#123; \"buckets\": [ &amp;#123; \"ageBalanceAvg\": &amp;#123; \"value\": 28312.918032786885 &amp;#125;, \"doc_count\": 61, \"genderAgg\": &amp;#123; \"buckets\": [ &amp;#123; \"balanceAvg\": &amp;#123; \"value\": 29565.628571428573 &amp;#125;, \"doc_count\": 35, \"key\": \"M\" &amp;#125;, &amp;#123; \"balanceAvg\": &amp;#123; \"value\": 26626.576923076922 &amp;#125;, \"doc_count\": 26, \"key\": \"F\" &amp;#125; ], \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0 &amp;#125;, \"key\": 31 &amp;#125;, &amp;#123; \"ageBalanceAvg\": &amp;#123; \"value\": 25269.583333333332 &amp;#125;, \"doc_count\": 60, \"genderAgg\": &amp;#123; \"buckets\": [ &amp;#123; \"balanceAvg\": &amp;#123; \"value\": 26348.684210526317 &amp;#125;, \"doc_count\": 38, \"key\": \"F\" &amp;#125;, &amp;#123; \"balanceAvg\": &amp;#123; \"value\": 23405.68181818182 &amp;#125;, \"doc_count\": 22, \"key\": \"M\" &amp;#125; ], \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0 &amp;#125;, \"key\": 39 &amp;#125;, &amp;#123; \"ageBalanceAvg\": &amp;#123; \"value\": 23194.813559322032 &amp;#125;, \"doc_count\": 59, \"genderAgg\": &amp;#123; \"buckets\": [ &amp;#123; \"balanceAvg\": &amp;#123; \"value\": 25094.78125 &amp;#125;, \"doc_count\": 32, \"key\": \"M\" &amp;#125;, &amp;#123; \"balanceAvg\": &amp;#123; \"value\": 20943.0 &amp;#125;, \"doc_count\": 27, \"key\": \"F\" &amp;#125; ], \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0 &amp;#125;, \"key\": 26 &amp;#125; ], \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0 &amp;#125; &amp;#125;, \"hits\": &amp;#123; \"hits\": [], \"total\": &amp;#123; \"relation\": \"eq\", \"value\": 1000 &amp;#125; &amp;#125;, \"timed_out\": false, \"took\": 34 &amp;#125;","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/"},{"name":"elasticsearch","slug":"elasticsearch/elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/elasticsearch/"}],"tags":[]},{"title":"深入浅出SpringBoot核心原理","slug":"Spring Boot/深入浅出SpringBoot核心原理","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/spring-boot/shen-ru-qian-chu-springboot-he-xin-yuan-li/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring-boot/shen-ru-qian-chu-springboot-he-xin-yuan-li/","excerpt":"","text":"深入浅出SpringBoot核心原理1. SpringBoot 的基本认识不管是不是Spring Cloud Netflix 还是Spring Cloud Alibaba, 都是基于SpringBoot 这个框架来构建的. 1. 什么是SpringBoot对于Sping框架,我们接触的比较多的应该是Spring MVC和Spring. 而Spring 的核心在于IOC(控制反转)和ID(依赖注入). 而这些框架在使用的过程中需要配置大量的XML，或者需要做很多繁琐的配置. SpringBoot 框架是为了能够帮助使用Spring框架的开发者快速高效的构建一个基于Spring 框架以及Spring生态体系的应用解决方案. 它是对”约定优于配置” 这个理念下的一个最佳实践. 因为它是一个服务于框架的框架, 服务的范围是简化配置文件. 约定优于配置的体现约定优于配置的体现主要是: Maven 的目录结构 默认有resources 文件夹存放配置文件 默认打包方式为jar spring-boot-starter-web 中默认包含Spring MVC 相关的依赖以及内置的tomcat 容器,使得构建一个web应用更加简单 默认提供 application.properties/yml 配置文件 默认通过spring.profiles.active 属性来解决运行环境时读取的配置文件 EnableAutoConfiguration 默认对于依赖的starter 进行自动装载. 从 SpringBootApplication 注解入手为了解开SpringBoot 的奥秘,我们直接从Annotation 入手, 看看@SpringBootApplication 里面, 做了什么呢? 打开SpringBootApplication 这个注解, 可以看到它实际上是一个复合注解. @Target(&amp;#123;ElementType.TYPE&amp;#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan( excludeFilters = &amp;#123;@Filter( type = FilterType.CUSTOM, classes = &amp;#123;TypeExcludeFilter.class&amp;#125; ), @Filter( type = FilterType.CUSTOM, classes = &amp;#123;AutoConfigurationExcludeFilter.class&amp;#125; )&amp;#125; ) @ConfigurationPropertiesScan public @interface SpringBootApplication &amp;#123; @AliasFor( annotation = EnableAutoConfiguration.class ) Class&lt;?>[] exclude() default &amp;#123;&amp;#125;; @AliasFor( annotation = EnableAutoConfiguration.class ) String[] excludeName() default &amp;#123;&amp;#125;; @AliasFor( annotation = ComponentScan.class, attribute = \"basePackages\" ) String[] scanBasePackages() default &amp;#123;&amp;#125;; @AliasFor( annotation = ComponentScan.class, attribute = \"basePackageClasses\" ) Class&lt;?>[] scanBasePackageClasses() default &amp;#123;&amp;#125;; @AliasFor( annotation = Configuration.class ) boolean proxyBeanMethods() default true; &amp;#125; SpringBootApplication 本质上是由三个注解组成, 分别是: @Configuration @EnableAutoConfiguration @ComponentScan 我们可以直接使用这三个注解也可以启动SpringBoot 应用,只是每次配置这三个注解比较繁琐, 所以直接用一个复合注解更方便些. 然后仔细观察这三个注解, 除了 @EnableAutoConfiguration 可以稍微陌生些, 其他两个注解使用的都比较多. 简单分析@Configuration@Configuration 这个注解大家应该有用到过, 它是JavaConfig 形式的基于Spring IOC 容器的配置类使用的一种注解. 因为SpringBoot 本质上就是一个Spring 应用, 所以通过这个注解来加载IOC 容器的配置是很正常的. 所以在启动类里面标注了@Configuration,意味着它其实也是一个IOC容器里面的配置类. 传统意义上的Spring 应用 都是基于XML 形式来配置bean 的依赖关系, 然后通过Spring 应用在启动的时候, 把Bean 进行初始化并且如果bean 还存在依赖关系,则分析这些已经在IOC容器中的bean 根据依赖关系进行组装. 直到Java 5中, 引入了Annotation 这个特性, Spring 框架也进随大流并且推出了基于Java 代码和Annotation 元信息的依赖关系绑定描述的方式. 也就是JavaConfig. 从Spring3开始,Spring 就支持了两种Bean 的配置方式, 一种下基于XML的方式, 另一种就是JavaConfig. 任何一个标注了@Configuration 的Java 类定义都是一个JavaConfig 配置类. 而在这个配置类中, 任何标注了Bean 注解的方法, 他的返回值都会作为Bean 定义注册到Spring 的IOC容器中, 方法名默认为这个bean 的id 简单分析 ComponentScanComponentScan 这个注解是大家接触的最多的, 相当于xml配置中的 &lt;context:component-scan&gt;, 他的主要作用就是扫描指定路径下的标识了需要装配的类, 自动装配到Spring 的IOC容器中。 标识需要装配的类的主要形式是: @Component、@Repositiory、@Service、@Controller 这类的注解标识类. ComponentScan 默认会扫描当前 package 下的所有加了相关注解标识的类到IOC 容器中. 简单分析 EnableAutoConfigurationEnable 并不是新鲜玩意儿仍然是在Spring 3.1 版本中, 提供了一系列的@Enable 开头的注解，Enable 注解应该是在JavaConfig 框架上的更进一步的完善, 使得用户在使用Spring 相关的框架的时候, 避免配置大量的代码从而降低使用的难度. 比如常见的一些Enable 注解: EnableWebMvc 这个注解是引入MVC 框架在Spring 应用中需要用到的所有bean EnableScheduling 开启计划任务的支持 找到EnableAutoConfiguration , 我们可以看到每一个涉及到Enable 开头的注解,都会带有一个 @Import 的注解, @Target(&amp;#123;ElementType.TYPE&amp;#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import(&amp;#123;AutoConfigurationImportSelector.class&amp;#125;) public @interface EnableAutoConfiguration &amp;#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; Class&lt;?>[] exclude() default &amp;#123;&amp;#125;; String[] excludeName() default &amp;#123;&amp;#125;; &amp;#125; Import 注解Import 注解是什么意思呢? 联想到XML形式下有一个 形式的注解, 就明白它的作用了. Import 就是把多个分开的容器配置合并在一起，在JavaConfig 中所表达的意义是一样的. 深入分析EnableAutoConfigurationEnableAutoConfiguration 的主要作用其实是帮助SpringBoot 应用所有符合条件的@Configuration 配置都加载到当前SpringBoot 创建并使用的IOC容器中, 再回到EnableAutoConfiguration 这个注解中,我们发现它的Import 是这样 @Import(&amp;#123;AutoConfigurationImportSelector.class&amp;#125;) public @interface EnableAutoConfiguration &amp;#123; AutoConfigurationImportSelector 是什么呢?Enable 注解不仅仅可以实现多个Configuration 的整合, 还可以实现一些复杂的场景，比如可以根据上下文来激活不同类型的bean, @Import 注解可以配置三种不同的class 第一种 基于普通的bean 或者带有@Configuration 的bean 进行注入 实现ImportSelector 接口进行动态注入 实现ImportBeanDefinitionRegistrar 接口进行动态注入 @EnableAutoConfiguration 注解的实现原理了解 ImportSelector 和ImportBeanDefinitionRegistrar 之后, 对于EnableAutoConfiguration 的理解就容易一些了, 他会通过Import 导入第三方提供的Bean 的配置类. @Import(&amp;#123;AutoConfigurationImportSelector.class&amp;#125;) 从名字来看, 可以猜到它的基于 ImportSelector 来实现基于Bean 的动态加载功能, SpringBoot 的@Enable* 注解的工作原理. 实现ImportSelector 接口selectImports 返回的数组(类的全名) 都会被纳入到Spring 容器中. 那么可以猜想到这里的实现原理也是一样的, 定位到AutoConfigurationImportSelector 这个类中的selectImports 方法,本质上来说, 其实EnableAutoConfiguration 会帮助SpringBoot 应用把所有符合@Configuration 配置都加载到当前SpringBoot 创建的IOC 容器, 而这里面借助了Spring 框架提供了一个工具类SpringFactoriesLoader的支持，以及用到了Spring 提供了条件注解@Conditional,选择性的针对需要加载的bean 进行条件过滤. SpringFactoriesLoader这里简单分析一下SpringFactoriesLoader 这个工具类的使用, 他其实和Java 中的SPI 机制的原理是一样的. 不过它比SPI更好的点在于不会一次性的加载所有的类, 而是根据key 进行加载. 首先,SpringFactoriesLoader的作用是从classpath/META-INF/spring.factories 文件夹中根据key来加载对应的类到Spring IOC 容器中. 深入理解过滤条件在分析 AutoConfigurationImportSelector 的源码时, 会先扫描spring-autoconfiguration-metadata.properties 文件, 最后再扫描spring.factories 对应的类, 会结合前面的元数据进行过滤. 为什么要进行过滤? 原因是很多的@Configuration 其实是依托其他的框架来加载的, 如果当前的classpath 环境下没有相关联的依赖, 则意味着这些类没必要加载, 所以, 通过这种条件过滤可以有效的减少@configuration 类的数量从而减低SpringBoot 的启动时间 Conditional 中的其他注解 Conditions 描述 @ConditionalOnBean 在存在某个Bean 的时候 @ConditionalOnMissingBean 不存在某个Bean 的时候 @ConditionalOnClass 当前classpath 可以找到某个类型的类时 @ConditionalOnMissingClass 当前classpath 不可以找到某个类型的类的时候 @ConditionalOnResource 当前classpath 是否存在某个资源文件 @ConditionalOnProperty 当前jvm 是否包含某个系统属性为某个值 @ConditionalOnWebApplication 当前Spring context 是否是web 应用程序 代码演示使用ComponentScan 注解我们先准备一个需要托管的类 ComponentScanDemo,加上@Configuration 注解 @Configuration public class ComponentScanDemo &amp;#123; &amp;#125; DemoClass 类加上 @Service 注解 @Service public class DemoClass &amp;#123; &amp;#125; 测试类 @ComponentScan(basePackages = \"com.springboot.basic.configuration.componentscan\") public class ComponentScanMain &amp;#123; public static void main(String[] args) &amp;#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(ComponentScanMain.class); for (int i = 0; i &lt; applicationContext.getBeanDefinitionNames().length; i++) &amp;#123; System.out.println(applicationContext.getBeanDefinitionNames()[i]); &amp;#125; &amp;#125; &amp;#125; 运行结果: 17:32:50.342 [main] DEBUG org.springframework.context.annotation.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@2a33fae0 17:32:50.374 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor' 17:32:50.452 [main] DEBUG org.springframework.context.annotation.ClassPathBeanDefinitionScanner - Identified candidate component class: file [D:\\workspace\\lyn\\lyn-project\\javaNotes\\SpringBoot\\spring-boot-basic\\target\\classes\\com\\springboot\\basic\\configuration\\componentscan\\ComponentScanDemo.class] 17:32:50.455 [main] DEBUG org.springframework.context.annotation.ClassPathBeanDefinitionScanner - Identified candidate component class: file [D:\\workspace\\lyn\\lyn-project\\javaNotes\\SpringBoot\\spring-boot-basic\\target\\classes\\com\\springboot\\basic\\configuration\\componentscan\\DemoClass.class] 17:32:50.609 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor' 17:32:50.612 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory' 17:32:50.616 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor' 17:32:50.624 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor' 17:32:50.638 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'componentScanMain' 17:32:50.645 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'componentScanDemo' 17:32:50.647 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean 'demoClass' org.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory componentScanMain componentScanDemo demoClass 结果能看到我们想要托管的类 使用Import 注解和Bean注解进行注入先准备一个需要被托管的类 public class OtherBean &amp;#123; &amp;#125; 再准备一个配置类,使用bean 注解将这个类注入到IOC容器中 @Configuration public class OtherConfig &amp;#123; @Bean public OtherBean otherBean() &amp;#123; return new OtherBean(); &amp;#125; &amp;#125; 再准备一个想被托管的类 public class DefaultBean &amp;#123; &amp;#125; 准备一个总的配置文件 @Configuration @Import(OtherConfig.class) public class SpringConfig &amp;#123; @Bean public DefaultBean defaultBean() &amp;#123; return new DefaultBean(); &amp;#125; &amp;#125; 编写测试类 public class SecondMain &amp;#123; public static void main(String[] args) &amp;#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(SpringConfig.class); for (int i = 0; i &lt; applicationContext.getBeanDefinitionNames().length; i++) &amp;#123; System.out.println(applicationContext.getBeanDefinitionNames()[i]); &amp;#125; &amp;#125; &amp;#125; 运行结果就能看到我们想要托管的类 springConfig com.springboot.basic.configuration.imports.other.OtherConfig otherBean defaultBean 使用Import 注解中使用 ImportSelector接口和ImportBeanDefinitionRegistrar 接口进行动态注入先准备两个类 public class CacheService &amp;#123; &amp;#125; public class LoggerService &amp;#123; &amp;#125; 再创建两个类, 分别实现ImportSelector接口和ImportBeanDefinitionRegistrar 接口返回上面两个类 public class CacheImportSelector implements ImportSelector &amp;#123; @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &amp;#123; Map&lt;String, Object> annotationAttributes = annotationMetadata.getAnnotationAttributes(EnableDefineService.class.getName()); return new String[]&amp;#123;CacheService.class.getName()&amp;#125;; &amp;#125; &amp;#125; public class LoggerDefinitionRegistrar implements ImportBeanDefinitionRegistrar &amp;#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &amp;#123; Class beanClass = LoggerService.class; RootBeanDefinition beanDefinition = new RootBeanDefinition(beanClass); String beanName = StringUtils.uncapitalize(beanClass.getSimpleName()); registry.registerBeanDefinition(beanName, beanDefinition); &amp;#125; &amp;#125; 创建Enable 注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @Import(&amp;#123;LoggerDefinitionRegistrar.class, CacheImportSelector.class&amp;#125;) public @interface EnableDefineService &amp;#123; //配置一些方法 Class&lt;?>[] exclude() default &amp;#123;&amp;#125;; &amp;#125; 编写测试类 @SpringBootApplication @EnableDefineService public class EnableDemoMain &amp;#123; public static void main(String[] args) &amp;#123; ConfigurableApplicationContext ca= SpringApplication.run(EnableDemoMain.class,args); System.out.println(ca.getBean(CacheService.class)); System.out.println(ca.getBean(LoggerService.class)); &amp;#125; &amp;#125; 运行则能打印出来两个类的实例信息 EnableAutoConfiguration 注入新建一个项目springboot-core 创建HelloService public class HelloService &amp;#123; public String say() &amp;#123; return \"Hello World\"; &amp;#125; &amp;#125; 再创建配置类 HelloConfig @Configuration public class HelloConfig &amp;#123; @Bean public HelloService helloService() &amp;#123; return new HelloService(); &amp;#125; &amp;#125; 在 resources 下创建META-INF 目录 新建spring.factories 配置文件,EnableAutoConfiguration 会自动注入这配置文件里配置类 org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.springboot.core.HelloConfig 创建 spring-autoconfigure-metadata.properties 配置文件, 注入配置文件的时候 会按照这个配置文件中的配置进行条件筛选 com.springboot.core.GupaoConfig.ConditionalOnClass=com.springboot.core.TestClass 在另外一个项目里面加入 springboot-core 项目的依赖 &lt;dependency> &lt;groupId>com.springboot.core&lt;/groupId> &lt;artifactId>springboot-core&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/dependency> 修改主启动类 @SpringBootApplication public class SpringBootBasicApplication &amp;#123; public static void main(String[] args) &amp;#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(SpringBootBasicApplication.class, args); HelloService helloService = applicationContext.getBean(HelloService.class); System.out.println(helloService.say());; &amp;#125; &amp;#125; 运行成功后打印出Hello World 2. 什么是starterStarter 是SpringBoot 中的一个非常重要的概念, Starter相当于模块,它能将模块所需的依赖整个起来并对模块内的Bean 根据环境(条件) 进行自动装配.使用者还需要依赖相应功能的Statrer ,无需做过多的配置和依赖, SpringBoot 就能自动扫描并加载相应的模块. SpringBoot中存在很多开箱即用的Starter 依赖,使得我们在开发业务代码时能够非常方便、不需要过多关注框架的配置,只需要关注业务即可. spring-boot-starter-logger在实际应用中, 日志其实是最重要的一个组件. 他可以作为系统提供错误以及日常 的定位. 也可以对访问的记录进行追踪 当然,在很多大型的互联网应用中, 基于日志的手机以及分析可以了解用户的用户画像,比如兴趣爱好、点击行为. 常见的日志框架可能是太常见了,所以使得大家很少关注,只是要用的时候复制粘贴一份就可以了,甚至连配置文件中的配置都不清楚.另一方面,Java 中提供了日志组件太多了,一会儿log4j,一会儿logback,一会儿又是log4j4,不清楚其中的关联. Java 中常用的日志框架: Log4j、Log4j2、Commons Logging、Slf4j、Logback、JUL(Java Util Logging). 简单介绍日志的发展历史最早的日志组件是Apache 基金会提供的Log4j, Log4j 能够通过配置文件轻松的实现日志系统的管理和多样化配置, 所以很快被广泛运用. 也就我们接触的比较早和比较多的日志组件. 它几乎成了Java 社区的日志标准. 据说Apache 基金会还曾经建议SUN 引入Log4j 到Java 的标准库中, 但SUN 拒绝了. 所以SUN 公司 在Java 1.4 版本中,增加了日志库(Java Util Logger). 其实现基本模仿了Log4j的技术. 在JUL 出来之前, Log4j 就已经成为一项成熟的技术, 使得Log4j 在选择上占据了一定的优势. Apache 推出JUL 之后, 有一些项目使用JUL, 也有一些项目使用Log4j. 这样就造成了开发者的混乱, 因为这两个日志组件没有关联, 所以想实现统一管理或者替换就非常困难. 怎么办呢? 这个时候又轮到Apache 出手了, 他推出一个Apache Commons Logging 组件, 只是定义了一套日志接口(其内部也提供了一个Simple Log的简易实现),支持运行时动态加载日志组件的实现,也就是说, 在你的应用代码中, 只需要调用Common Logger 的接口, 底层实现可以是Log4j, 也可以是Java Util Logging. 由于它很出色的完成了主流日志的兼容, 所以基本上在后面的很长一段时间, 是无敌的存在. 连Spring 也都是依赖JCL 进行日志管理. 但是故事还没有结束. 原Log4j 的作者, 它觉得 Apache Commons Logging 不够优秀, 所以它也行搞一套更优雅的方案, 于是slf4j 日志体系诞生了, slf4j 实际上及就是一个日志门面接口,它的作用类似于Commons Logging. 并且它还为slf4j 提供了一个日志的实现 logback. 因为大家可以发现Java 的日志领域被划分为两个大营:Commons Logging 和slf4j 另外还有一个log4j2 是怎么回事? 因为 slf4j 以及它的实现 logback 出来以后,很快就超赶了原本的 apache 的 log4j 体系,所以 apache 在2012 年重写了 log4j, 成立了新的项目 log4j2. 总的来说,日志的整个体系分为日志框架和日志系统: 日志框架: JCL/ slf4j 日志系统: Log4j、Log4j2、Logback、JUL。 而我们现在的应用中,绝大部分都是使用 slf4j 作为门面, 然后搭配 logback 或者 log4j 日志系统的. 3.SpringBoot 的另一大神器 - Actuator微服务应用开发完成后, 最终目的是为了发布到生产环境上给用户使用,开发结束并不意味着研发的生命周期结束,很多的时候只是一个开始, 因为服务在本地测试完成以后, 并不一定能够非常完善的考虑到各种场景. 所以需要通过运维来保障服务的稳定. 在以前的传统应用中,我们可以靠人工来监控. 但是微服务中,几千上万个服务, 我们需要了解各个服务的健康状态, 就必须依赖监控平台来实现. 所以在SpringBoot 框架中提供了 spring-boot-starter-actuator 自动配置模块来支持对于SpringBoot 应用的监控. ActuatorSpringBoot Acyuator 的关键特性是在应用程序里提供众多WEB 端点, 通过他们了解应用程序运行时的内部状态. 有了Actuator ,你可以知道Bean 在Spring 应用程序上下文里是如何组装在一起的, 掌握应用程序可以获取的环境属性信息. 在SpringBoot 项目中, 添加 actuator 的一个starter &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> Actuator 提供的 endpoint 启动服务后, 可以通过下面这个地址看到 actuator 提供的所有endoint 地址 http://localhost:8080/actuator 可以看到非常多的endpoint. 有一些Endpiont 是不能访问的, 涉及到安全问题. 如果想开启访问的那些安全相关的url, 可以在 appliaction.propertie/yml 中配置, 开启所有的 endpoint management.endpoints.web.exposure.include=* health 针对当前SpringBoot 的健康检查, 默认情况下, 会通过 “up” 或者”down” , 可以基于下面这个配置, 来打印health 更加详细的信息 ## 打印health 更信息的监控信息 management.endpoint.health.show-details=always loggers显示当前SpringBoot 应用中的日志配置信心, 针对每个package 对应的日志级别 beans获取当前SpringBoot 应用中IOC 容器中的所有的bean Dump获取活动线程的快照. Mappings返回全部的url 路径, 以及和控制器的映射关系. conditions显示当前所有的条件注解, 提供一份自动配置生效的条件情况, 记录哪些自动配置条件通过了, 哪些没通过. shuwdown关闭应用程序,需要添加以下这个配置 ## 使用 shutdowm 关闭应用程序 management.endpoint.shutdown.enabled=true 这个Endpoint 是比较危险的, 如果没有一定的安全保证,不要开启. Env获取全部的环境信息 关于Health 的原理应用健康状态检查应该是监控系统中最基本的要求, 所以我们基于health 来分析一下它是如何实现的.SpringBoot 预先通过org.springframework.boot.actuate.autoconfigure.health.HealthIndicatorAutoConfiguration 这个就是基于Springboot 的自动装配来载入的. 所以可以在spring-boot-actuator-autoconfigure 这个包下找到spring.factories Actuator 中提供了非常多的扩展点, 默认情况下提供了一些常见的服务的监控检查和支持。 DataSourceHealthIndicator DiskSpaceHealthIndicator RedisHealthIndicator … 其中, 有一些服务的检查, 需要依赖于当前应用是否集成了对应的组件, 比如redis,如果没有集成, 那么 RedisHealthIndicatorAutoConfiguration 就不会被装载. 因为它有condition 的条件判断. Actuator 对于JMX 支持除了REST 方式发布的Endpoint,Actuator 还把它的端点以JMX MBean 的方式发布出来, 可以通过JMX 来查看和管理 操作步骤在CMD中输入 jconsole,连接到springboot 应用 就可以看到JBean 的信息以及相应的操作, 比如可以在操作菜单中访问shutdown 的endpiont 来关闭服务. 什么是JMXJMX 全称是 Java Management Extensions , Java 管理扩展,它提供了对java 应用程序和JVM 的监控和管理功能. 通过JMX，我们可以监控: 服务器中的各种资源的使用情况, 比如CPU、内存 JVM 的内存的使用情况 JVM线程的使用情况 比如前面讲的Actuator ,就是基于JMX技术来实现对endpoint 的访问的.","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/"},{"name":"Spring Boot","slug":"Spring-Boot/Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/Spring-Boot/"}],"tags":[]},{"title":"SpringApplication深入解析(1)","slug":"Spring Boot/SpringApplication深入解析(1)","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/spring-boot/springapplication-shen-ru-jie-xi-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring-boot/springapplication-shen-ru-jie-xi-1/","excerpt":"","text":"SpringApplication 深入解析我们知道,SpringBoot 程序中最重要的类就是SpringApplication,SpringApplication是SpringBoot驱动Spring应用上下文的引导类. 接下来我们看看SpringApplication有什么玄妙之处. 1. 自定义SpringApplication我们要启动一个SpringBoot程序, 我们需要使用@SpringBootApplication注解标注一个启动类, 并且执行SpringApplication.run()来启动. @SpringBootApplication public class SpringbootDemo1Application &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(SpringbootDemo1Application.class, args); &amp;#125; &amp;#125; 我们先看看@SpringBootApplication @Target(&amp;#123;ElementType.TYPE&amp;#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan( excludeFilters = &amp;#123;@Filter( type = FilterType.CUSTOM, classes = &amp;#123;TypeExcludeFilter.class&amp;#125; ), @Filter( type = FilterType.CUSTOM, classes = &amp;#123;AutoConfigurationExcludeFilter.class&amp;#125; )&amp;#125; ) public @interface SpringBootApplication &amp;#123; ... &amp;#125; 我们看到, @SpringBootApplication 注解是一个复合注解, 由三个注解组合而成. @ComponentScan @EnableAutoConfiguration @SpringBootConfiguration @ComponentScan这是Spring Framework3.1中引进来的一个注解, 主要是根据定义的扫描的包路径, 将符合扫描规则的类装配到Spring容器当中. @Repeatable(ComponentScans.class) public @interface ComponentScan &amp;#123; @AliasFor(\"basePackages\") String[] value() default &amp;#123;&amp;#125;; @AliasFor(\"value\") String[] basePackages() default &amp;#123;&amp;#125;; Class&lt;?>[] basePackageClasses() default &amp;#123;&amp;#125;; Class&lt;? extends BeanNameGenerator> nameGenerator() default BeanNameGenerator.class; Class&lt;? extends ScopeMetadataResolver> scopeResolver() default AnnotationScopeMetadataResolver.class; ScopedProxyMode scopedProxy() default ScopedProxyMode.DEFAULT; String resourcePattern() default \"**/*.class\"; boolean useDefaultFilters() default true; ComponentScan.Filter[] includeFilters() default &amp;#123;&amp;#125;; ComponentScan.Filter[] excludeFilters() default &amp;#123;&amp;#125;; boolean lazyInit() default false; @Retention(RetentionPolicy.RUNTIME) @Target(&amp;#123;&amp;#125;) public @interface Filter &amp;#123; FilterType type() default FilterType.ANNOTATION; @AliasFor(\"classes\") Class&lt;?>[] value() default &amp;#123;&amp;#125;; @AliasFor(\"value\") Class&lt;?>[] classes() default &amp;#123;&amp;#125;; String[] pattern() default &amp;#123;&amp;#125;; &amp;#125; &amp;#125; basePackages与value: 用于给定的包的路径, 进行扫描 basePackageClasses: 用于指定某个类的包的路径进行扫描 nameGenerator: bean的名称的生成器 useDefaultFilters: 是否开启对@Component，@Repository，@Service，@Controller的类进行检测 includeFilters: 包含的过滤条件 FilterType.ANNOTATION：按照注解过滤 FilterType.ASSIGNABLE_TYPE：按照给定的类型 FilterType.ASPECTJ：使用ASPECTJ表达式 FilterType.REGEX：正则 FilterType.CUSTOM：自定义规则 excludeFilters: 排除的规则, 用于跟includeFilters 一样. 那么@ComponentScan 注解是在哪里作用的呢? 我们看org.springframework.context.annotation.ConfigurationClassParser#doProcessConfigurationClass 这个方法中 @Nullable protected final SourceClass doProcessConfigurationClass( ConfigurationClass configClass, SourceClass sourceClass, Predicate&lt;String> filter) throws IOException &amp;#123; if (configClass.getMetadata().isAnnotated(Component.class.getName())) &amp;#123; // Recursively process any member (nested) classes first processMemberClasses(configClass, sourceClass, filter); &amp;#125; // Process any @PropertySource annotations for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), PropertySources.class, org.springframework.context.annotation.PropertySource.class)) &amp;#123; if (this.environment instanceof ConfigurableEnvironment) &amp;#123; processPropertySource(propertySource); &amp;#125; else &amp;#123; logger.info(\"Ignoring @PropertySource annotation on [\" + sourceClass.getMetadata().getClassName() + \"]. Reason: Environment must implement ConfigurableEnvironment\"); &amp;#125; &amp;#125; // Process any @ComponentScan annotations Set&lt;AnnotationAttributes> componentScans = AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &amp;#123; for (AnnotationAttributes componentScan : componentScans) &amp;#123; // The config class is annotated with @ComponentScan -> perform the scan immediately Set&lt;BeanDefinitionHolder> scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); // Check the set of scanned definitions for any further config classes and parse recursively if needed for (BeanDefinitionHolder holder : scannedBeanDefinitions) &amp;#123; BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) &amp;#123; bdCand = holder.getBeanDefinition(); &amp;#125; if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &amp;#123; parse(bdCand.getBeanClassName(), holder.getBeanName()); &amp;#125; &amp;#125; &amp;#125; &amp;#125; ... &amp;#125; 我们看 Set&lt;BeanDefinitionHolder> scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); 调用了解析器进行解析, 我们继续看 org.springframework.context.annotation.ComponentScanAnnotationParser#parse public Set&lt;BeanDefinitionHolder> parse(AnnotationAttributes componentScan, final String declaringClass) &amp;#123; ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean(\"useDefaultFilters\"), this.environment, this.resourceLoader); Class&lt;? extends BeanNameGenerator> generatorClass = componentScan.getClass(\"nameGenerator\"); boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass); scanner.setBeanNameGenerator(useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass)); ScopedProxyMode scopedProxyMode = componentScan.getEnum(\"scopedProxy\"); if (scopedProxyMode != ScopedProxyMode.DEFAULT) &amp;#123; scanner.setScopedProxyMode(scopedProxyMode); &amp;#125; else &amp;#123; Class&lt;? extends ScopeMetadataResolver> resolverClass = componentScan.getClass(\"scopeResolver\"); scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass)); &amp;#125; scanner.setResourcePattern(componentScan.getString(\"resourcePattern\")); for (AnnotationAttributes filter : componentScan.getAnnotationArray(\"includeFilters\")) &amp;#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &amp;#123; scanner.addIncludeFilter(typeFilter); &amp;#125; &amp;#125; for (AnnotationAttributes filter : componentScan.getAnnotationArray(\"excludeFilters\")) &amp;#123; for (TypeFilter typeFilter : typeFiltersFor(filter)) &amp;#123; scanner.addExcludeFilter(typeFilter); &amp;#125; &amp;#125; boolean lazyInit = componentScan.getBoolean(\"lazyInit\"); if (lazyInit) &amp;#123; scanner.getBeanDefinitionDefaults().setLazyInit(true); &amp;#125; Set&lt;String> basePackages = new LinkedHashSet&lt;>(); String[] basePackagesArray = componentScan.getStringArray(\"basePackages\"); for (String pkg : basePackagesArray) &amp;#123; String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized); &amp;#125; for (Class&lt;?> clazz : componentScan.getClassArray(\"basePackageClasses\")) &amp;#123; basePackages.add(ClassUtils.getPackageName(clazz)); &amp;#125; if (basePackages.isEmpty()) &amp;#123; basePackages.add(ClassUtils.getPackageName(declaringClass)); &amp;#125; scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) &amp;#123; @Override protected boolean matchClassName(String className) &amp;#123; return declaringClass.equals(className); &amp;#125; &amp;#125;); return scanner.doScan(StringUtils.toStringArray(basePackages)); &amp;#125; 这个方法中, 使用ClassPathBeanDefinitionScanner的doScan 方法进行解析 我们先看这一段 ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry, componentScan.getBoolean(\"useDefaultFilters\"), this.environment, this.resourceLoader); public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters, Environment environment, @Nullable ResourceLoader resourceLoader) &amp;#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); this.registry = registry; if (useDefaultFilters) &amp;#123; registerDefaultFilters(); &amp;#125; setEnvironment(environment); setResourceLoader(resourceLoader); &amp;#125; 我们看这个方法registerDefaultFilters() protected void registerDefaultFilters() &amp;#123; this.includeFilters.add(new AnnotationTypeFilter(Component.class)); ClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader(); try &amp;#123; this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation>) ClassUtils.forName(\"javax.annotation.ManagedBean\", cl)), false)); logger.trace(\"JSR-250 'javax.annotation.ManagedBean' found and supported for component scanning\"); &amp;#125; catch (ClassNotFoundException ex) &amp;#123; // JSR-250 1.1 API (as included in Java EE 6) not available - simply skip. &amp;#125; try &amp;#123; this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation>) ClassUtils.forName(\"javax.inject.Named\", cl)), false)); logger.trace(\"JSR-330 'javax.inject.Named' annotation found and supported for component scanning\"); &amp;#125; catch (ClassNotFoundException ex) &amp;#123; // JSR-330 API not available - simply skip. &amp;#125; &amp;#125; 我们看this.includeFilters.add(new AnnotationTypeFilter(Component.class)); 这段代码, @ComponentScan 扫描的时候, 会将包含 @Component注解的所有类和”派生类”都扫描. @EnableAutoConfiguration激活自动装配,也就是启动SpringBoot的自动加载配置, 我们平时会看到很多已@Enable 开头的, 比如: @EnableWebMvc @EnableTransactionManagement @EnableAspectJAutoProxy @EnableAsync … @SpringBootConfiguration@Configuration public @interface SpringBootConfiguration &amp;#123; @AliasFor( annotation = Configuration.class ) boolean proxyBeanMethods() default true; &amp;#125; 我们看到, 这也是一个复合注解,其实其真正意义上还是@Configuration 注解,我们再看看@Configuration注解, @Component public @interface Configuration &amp;#123; @AliasFor( annotation = Component.class ) String value() default \"\"; boolean proxyBeanMethods() default true; &amp;#125; 我们看到, 最后是@Component注解. 这里, 我们不得不说说 Spring 注解编程模型 我们可以看到, @Service @Component public @interface Service &amp;#123; ... &amp;#125; @Repository @Component public @interface Repository &amp;#123; ... &amp;#125; @Controller @Component public @interface Controller &amp;#123; ... &amp;#125; @Configuration @Component public @interface Configuration &amp;#123; ... &amp;#125; 在上面的这些我们常用的注解当中, 都”派生了”@Component注解. 2. 配置SpringBoot源SpringApplication Spring Boot 应用的引导, 那么我们启动一个Spring上下文, 有那些方式呢? 2.1. 基于 AnnotationConfigApplicationContext 注解进行启动上下文/** * @author luyanan * @since 2020/3/17 * &lt;p>注解启动Spring上下文&lt;/p> **/ @Configuration public class SpringBootAnnotationDemo &amp;#123; public static void main(String[] args) &amp;#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); // 注册一个Configuration class context.register(SpringBootAnnotationDemo.class); // 启动上下文 context.refresh(); System.out.println(context.getBean(SpringBootAnnotationDemo.class)); &amp;#125; &amp;#125; 输出结果: com.demo.annotation.SpringBootAnnotationDemo$$EnhancerBySpringCGLIB$$8a01a66@527e5409 2.2 基于SpringApplicationBuilder@SpringBootApplication public class SpringApplicationBuilderDemo &amp;#123; public static void main(String[] args) &amp;#123; new SpringApplicationBuilder(SpringApplicationBuilderDemo.class) .properties(\"server.port=0\") .run(args); &amp;#125; &amp;#125; 2.3 使用SpringApplication 启动上下文@SpringBootApplication public class SpringbootDemo1Application &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication application = new SpringApplication(SpringbootDemo1Application.class); Map&lt;String, Object> pro = new HashMap&lt;>(); pro.put(\"server.port\", \"0\"); application.setDefaultProperties(pro); application.run(args); &amp;#125; &amp;#125; 2.4 调整为非web程序// 非web程序 public static void main(String[] args) &amp;#123; SpringApplication application = new SpringApplication(SpringbootDemo1Application.class); Map&lt;String, Object> pro = new HashMap&lt;>(); pro.put(\"server.port\", \"0\"); //调整为非web程序 application.setWebApplicationType(WebApplicationType.NONE); application.setDefaultProperties(pro); ConfigurableApplicationContext context = application.run(args); System.out.println(\"当前Spring 应用上下文类:\" + context.getClass().getName()); &amp;#125; 我们看到, 我们通过application.setWebApplicationType(WebApplicationType.NONE); 设置为非web程序，当我们不调整的时候, Spring在启动的时候, 是如何推断出当前为非web程序还是Servlet程序还是webFlux 程序的呢? 3. SpringApplication类型推断 当我们不设置类型的时候, Spring 是如何给我们推断的呢? 我们看代码 public SpringApplication(ResourceLoader resourceLoader, Class&lt;?>... primarySources) &amp;#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;>(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &amp;#125; 我们看到this.webApplicationType是WebApplicationType.deduceFromClasspath() 方法判断出来的, 我们继续看 private static final String[] SERVLET_INDICATOR_CLASSES = &amp;#123; \"javax.servlet.Servlet\", \"org.springframework.web.context.ConfigurableWebApplicationContext\" &amp;#125;; private static final String WEBMVC_INDICATOR_CLASS = \"org.springframework.web.servlet.DispatcherServlet\"; private static final String WEBFLUX_INDICATOR_CLASS = \"org.springframework.web.reactive.DispatcherHandler\"; private static final String JERSEY_INDICATOR_CLASS = \"org.glassfish.jersey.servlet.ServletContainer\"; private static final String SERVLET_APPLICATION_CONTEXT_CLASS = \"org.springframework.web.context.WebApplicationContext\"; private static final String REACTIVE_APPLICATION_CONTEXT_CLASS = \"org.springframework.boot.web.reactive.context.ReactiveWebApplicationContext\"; static WebApplicationType deduceFromClasspath() &amp;#123; if (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) &amp;#123; return WebApplicationType.REACTIVE; &amp;#125; for (String className : SERVLET_INDICATOR_CLASSES) &amp;#123; if (!ClassUtils.isPresent(className, null)) &amp;#123; return WebApplicationType.NONE; &amp;#125; &amp;#125; return WebApplicationType.SERVLET; &amp;#125; WebApplicationType.NONE : 非 Web 类型 Servlet 不存在 Spring Web 应用上下文 ConfigurableWebApplicationContext 不存在 spring-boot-starter-web 不存在 spring-boot-starter-webflux 不存在 WebApplicationType.REACTIVE : Spring WebFlux DispatcherHandler spring-boot-starter-webflux 存在 Servlet 不存在 spring-boot-starter-web 不存在 WebApplicationType.SERVLET : Spring MVC spring-boot-starter-web 存在 当自己设置类型的时候, org.springframework.boot.SpringApplication#setWebApplicationType public void setWebApplicationType(WebApplicationType webApplicationType) &amp;#123; Assert.notNull(webApplicationType, \"WebApplicationType must not be null\"); this.webApplicationType = webApplicationType; &amp;#125; 会将webApplicationType 类型设置为自己想要的类型 4 SpringBoot事件Spring事件Spring内部发送的事件我们可以通过以下代码来看看Spring内部发送的事件 @Configuration public class SpringEventDemo &amp;#123; public static void main(String[] args) &amp;#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); // 注册一个Configuration class context.register(SpringEventDemo.class); context.addApplicationListener(new ApplicationListener&lt;ApplicationEvent>() &amp;#123; @Override public void onApplicationEvent(ApplicationEvent event) &amp;#123; System.err.println(event.getClass().getName()); &amp;#125; &amp;#125;); // 启动上下文 context.refresh(); context.close(); &amp;#125; &amp;#125; 运行后我们发现 , 发送了两个事件. ContextRefreshedEvent ContextClosedEvent 那么这两个事件是在哪里被发送的呢? ContextRefreshedEvent我们进去org.springframework.context.support.AbstractApplicationContext#refresh 方法 @Override public void refresh() throws BeansException, IllegalStateException &amp;#123; synchronized (this.startupShutdownMonitor) &amp;#123; ... // Last step: publish corresponding event. finishRefresh(); ... &amp;#125; 接下来看org.springframework.context.support.AbstractApplicationContext#finishRefresh protected void finishRefresh() &amp;#123; // Clear context-level resource caches (such as ASM metadata from scanning). clearResourceCaches(); // Initialize lifecycle processor for this context. initLifecycleProcessor(); // Propagate refresh to lifecycle processor first. getLifecycleProcessor().onRefresh(); // Publish the final event. publishEvent(new ContextRefreshedEvent(this)); // Participate in LiveBeansView MBean, if active. LiveBeansView.registerApplicationContext(this); &amp;#125; 我们看publishEvent(new ContextRefreshedEvent(this)); 这里发送了一个ContextRefreshedEvent 事件 ContextClosedEvent我们再看看这个事件在哪里发送的发送的呢? 我们进入到org.springframework.context.support.AbstractApplicationContext#close @Override public void close() &amp;#123; synchronized (this.startupShutdownMonitor) &amp;#123; doClose(); // If we registered a JVM shutdown hook, we don't need it anymore now: // We've already explicitly closed the context. if (this.shutdownHook != null) &amp;#123; try &amp;#123; Runtime.getRuntime().removeShutdownHook(this.shutdownHook); &amp;#125; catch (IllegalStateException ex) &amp;#123; // ignore - VM is already shutting down &amp;#125; &amp;#125; &amp;#125; &amp;#125; 看org.springframework.context.support.AbstractApplicationContext#doClose 方法 protected void doClose() &amp;#123; // Check whether an actual close attempt is necessary... if (this.active.get() &amp;&amp; this.closed.compareAndSet(false, true)) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Closing \" + this); &amp;#125; LiveBeansView.unregisterApplicationContext(this); try &amp;#123; // Publish shutdown event. publishEvent(new ContextClosedEvent(this)); &amp;#125; ... &amp;#125; 我们看publishEvent(new ContextClosedEvent(this)); 这里发送了ContextClosedEvent 事件 自定义事件当我们自定义一个事件的时候, 那么这个事件是在哪里发送的呢? //自定义事件 AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); // 注册一个Configuration class context.register(SpringEventDemo.class); context.addApplicationListener(new ApplicationListener&lt;ApplicationEvent>() &amp;#123; @Override public void onApplicationEvent(ApplicationEvent event) &amp;#123; System.err.println(event.getClass().getName()); &amp;#125; &amp;#125;); // 启动上下文 context.refresh(); context.publishEvent(new MyApplicationEvent(\"自定义事件\")); &amp;#125; public static class MyApplicationEvent extends ApplicationEvent &amp;#123; /** * Create a new &amp;#123;@code ApplicationEvent&amp;#125;. * * @param source the object on which the event initially occurred or with * which the event is associated (never &amp;#123;@code null&amp;#125;) */ public MyApplicationEvent(Object source) &amp;#123; super(source); &amp;#125; &amp;#125; 输出结果 org.springframework.context.event.ContextRefreshedEvent com.demo.event.SpringEventDemo$MyApplicationEvent 那么这个事件是在哪里被发送的呢? 我们从context.publishEvent(new MyApplicationEvent(&quot;自定义事件&quot;)) 这个方法进去 @Override public void publishEvent(ApplicationEvent event) &amp;#123; publishEvent(event, null); &amp;#125; 继续看org.springframework.context.support.AbstractApplicationContext#publishEvent(java.lang.Object, org.springframework.core.ResolvableType) protected void publishEvent(Object event, @Nullable ResolvableType eventType) &amp;#123; Assert.notNull(event, \"Event must not be null\"); // Decorate event as an ApplicationEvent if necessary ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) &amp;#123; applicationEvent = (ApplicationEvent) event; &amp;#125; else &amp;#123; applicationEvent = new PayloadApplicationEvent&lt;>(this, event); if (eventType == null) &amp;#123; eventType = ((PayloadApplicationEvent&lt;?>) applicationEvent).getResolvableType(); &amp;#125; &amp;#125; // Multicast right now if possible - or lazily once the multicaster is initialized if (this.earlyApplicationEvents != null) &amp;#123; this.earlyApplicationEvents.add(applicationEvent); &amp;#125; else &amp;#123; getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); &amp;#125; // Publish event via parent context as well... if (this.parent != null) &amp;#123; if (this.parent instanceof AbstractApplicationContext) &amp;#123; ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); &amp;#125; else &amp;#123; this.parent.publishEvent(event); &amp;#125; &amp;#125; &amp;#125; 我们看到, 事件是通过getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); 发送的. SpringBoot 的事件接下来我们看看SpringBoot的事件有那些呢? @SpringBootApplication public class SpringBootEvent &amp;#123; public static void main(String[] args) &amp;#123; new SpringApplicationBuilder(SpringBootEvent.class) .listeners(event -> System.err.println(event.getClass().getName())) .run(args).close(); &amp;#125; &amp;#125; 我们看输出结果得知, 事件有: org.springframework.boot.context.event.ApplicationStartingEvent org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent org.springframework.boot.context.event.ApplicationContextInitializedEvent org.springframework.boot.context.event.ApplicationPreparedEvent org.springframework.context.event.ContextRefreshedEvent org.springframework.boot.web.servlet.context.ServletWebServerInitializedEvent org.springframework.boot.context.event.ApplicationReadyEvent org.springframework.context.event.ContextClosedEvent org.springframework.boot.context.event.ApplicationFailedEvent（容器启动失败的时候才会发送到事件）","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/"},{"name":"Spring Boot","slug":"Spring-Boot/Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/Spring-Boot/"}],"tags":[]},{"title":"Service Mesh初入门(1)","slug":"Service Mesh/Service Mesh初入门(1)","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/service-mesh/service-mesh-chu-ru-men-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/service-mesh/service-mesh-chu-ru-men-1/","excerpt":"","text":"Service Mesh初入门1. 分布式架构发展史1.1 单机小型机时代 1969年,阿帕网诞生,最初是为了军事目的,后来演变成了Inernet 2000年左右,互联网在中国盛行起来,但是那时候网民数量较少,所以多数企业服务单一,采用集中式部署的方式就能满足需求 一旦小型机或者数据库出现问题,会导致整个系统的故障,而且功能修改发布也不方便,所以不妨把大系统拆分成多个子系统, 比如用户 、商品 、论坛等, 也就是“垂直拆分”, 并且每个子系统都有各自的硬件 1.2 集群化负载均衡时代 用户量越来越大,就意味着需要更多的小型机,价格昂贵、操作维护成本高, 不妨把小型机换成普通的PC机,采用多台PC机部署同一个应用的方案,但是此时就需要对这些应用做负载均衡, 因为客户端不知道请求哪一个. 2013年5月17 日, 阿里集团最后一台IBM 小型机在支付宝下线 这是自2009年”去IOE” 战略以来,“去IOE” 非常重要的一个节点。”去IOE” 指的是摆脱掉IT部署中原有的IBM小型机、Oracle 数据库以及EMC存储的过度依赖,告别最后一台小型机,意味着整个阿里集团尽管还有一些Oracle 数据库和EMC 存储,但是IBM 小型机已经全部消失了. 负载均衡可以分为硬件和软件,硬件比如F5,软件比如LVS(Linux Virtual Server) . 负载均衡的思路是对外暴露一个统一的接口,然后根据用户的请求进行对应规则的转发,同时负载均衡还可以做健康检查、限流等 有了负载均衡, 后端的应用就可以根据流量的大小进行动态的扩缩容了, 也就是“水平扩展” 1.3 服务化时代 此时发现在用户、订单、商品等有重复的功能,比如登陆、注册、邮件等,一旦项目大了之后, 集群部署多了, 这些重复的功能无疑是浪费资源, 不妨把重复的功能抽离出来, 起个名字叫做”服务Service” 其实对于”服务”现在已经比较广泛了, 比如”基础设施即服务laas“、”平台即服务PaaS“ 、”软件即服务Saas“等 这时候就急需解决的就是服务之间的调用问题,RPC(Remote Pricedure Call), 同时这种调用关系得维护起来,比如某个服务在哪里? 是不是得知道? 所以不仅仅要解决服务调用的问题,还要解决服务治理的问题,比如像Dubbo, 默认采用Zookeeper 作为注册中心,SpringCloud 使用Eureka 作为注册中心 当然,要关注的还有很多,比如限流、降级、负载均衡、容错等 1.4 分布式微服务时代 在分布式架构下,服务可能拆分的没有那么细, 可以进一步的拆分 Microservices https://martinfowler.com/articles/microservices.html Java 中微服务主流解决方案SpringCloud，SpringCloud 可以用过引入几个注解,写少量的代码完成微服务架构中的开发,相对Dubbo而言简单方便很多, 并且使用的是Http协议,所以对多语言也可以很好的支持 https://spring.io/projects/spring-cloud spring-cloud-bus spring-cloud-consul spring-cloud-config spring-cloud-netflix:eureka、 hystrix、 feign、 zuul、 ribbon等 ….. 1.5 服务网格时代然后微服务时代有了SpringCloud 就完美了吗? 不妨想一想会有哪些问题? 最初是为了业务而写代码,比如登陆功能,支付功能等,到后面会发现要解决网络通信的问题,虽然有SpringCloud 里面的组件帮我们解决了, 但是细想一下他是怎么解决的? 引入dependenct,加注解,写配置,最后将这些非业务功能的代码打包一起部署,和业务代码一起,称为”侵入式代码” 微服务中的服务支持不同语言开发,维护不同语言和非业务代码的成本 业务代码开发者应该把更多的精力投入到业务熟悉度上,而不应该是非业务上,SpringCloud 虽然能解决微服务领域的很多问题,但是学习成本还是较大的. 对于SpringCloud 而言, 并不是微服务领域的所有问题都有对应的解决方案., 也就是功能受限,比如Content Based Routing和Version Based Routing。 当然可以将SpringCloud和Service Mesh结合起来使用,也就是对SC 的补充、扩展和加强等. 互联网公司产品的版本升级是非常频繁的,为了维护各个版本的兼容性、权限、流量等, 因为SpringCloud 是”代码侵入式的框架”, 这时候版本的升级就注定要让非业务的代码一起,一旦出现问题, 再加上多语言之间的调用,工程师会非常痛苦的. 其实大家有没有发现,服务拆分的越细,只是感觉上轻量级解耦了, 但是维护成本越高了, 那怎么办呢? 网络的问题当然还是交给网络本身来解决。 1.5.1 问题解决思路 本质上要解决服务之间通信的问题,不应该将非业务的代码融合到业务代码中 也就是从客户端发出的请求, 要能够顺利到达对应的服务,这中间的网络通信的过程要和业务代码尽量无关. 通信的问题: 服务发现、负载均衡、版本控制、蓝绿部署 在很早之前的单体架构中,其实通信问题也是写在业务代码中的, 那时候怎么解决的呢? 把网络通信、流量转发等问题放到了计算机网络模型中的TCP/UDP 层,也就是非业务功能代码下沉 那就不妨把这些通信的问题都交给计算机网络模型组织去解决咯? 别人肯定不会答应的, 怎么办呢? 既然不答应,那我们就自己想办法去解决通信问题,撸一些产品岂不快哉? 没错,代理嘛. 不妨这样在帮每个服务配置一个代理,所有通信的问题都交给这个代理去解决 大家肯定接触过, 比如最初Nginx、HaPorxy 等,其实他们做反向代理把请求转发给其他服务器,也就为Service Mesh 的诞生和完成提供了一个解决思路. 1.5.2 一些公司对于代理的探索Sidecar很多公司借鉴了Proxy 模式, 推出了Sidecar的产品,比如像14年Netflix的Prana, 15年唯品会的local proxy. 其实Sidecar 模式和Proxy 很类似,但是Sidecar功能更全面,也就是Sidecar 功能和侵入式框架的功能对应 问题: 这种Sidecar 是为特定的基础设施而设计的,也就是跟公司原有的框架技术绑定在一起,不能成为通用性的产品, 所以还需要继续探索. 1.5.3 Service Mesh 之Linkerd 2016年1月, 离开Twitter的基础设施工程师William Morgan和Oliver Gould, 在github 上发布了linkerd 0.0.7 版本, 从而第一个Service Mesh 项目由此诞生,并且Linkerd 是基于Twitter的Finagle 开源项目, 实现了通用性。 后面又出现了Service Mesh 的第二个项目Envoy, 并且在17年的时候都加入了CNCF 项目 小结: linderd 解决了通用性问题, 在linkerd 思想要求所有的流量都走Sidecar , 而原来的Sidecar 方式可以走直接直连, 这样 一来Linkerd 就帮业务人员屏蔽了通信细节,也不需要侵入到业务代码中,让业务开发者更加专注业务本身, 问题: 但是Linkerd 的设计思想在传统运维方式中太难部署和维护了,所以到后来就没有得到广泛的关注, 其实主要的问题是Linkerd 只是实现了数据层面的问题,但没有对其进行很好的管理. 1.5.4 Service Mesh 之Istio由Google、IBM 和Lyft 共同发起的开源项目,17年5月份的时候发布0.1 release 版本,17年10月发布0.2 release版本,18年7月份发布1.0 release 版本 很明显Istio 不仅拥有”数据层面(Data Plane)”,还拥有”控制平面(Control Plane)”, 也就是拥有了数据的接管和几种控制能力。 官网: https://istio.io/docs/concepts/what-is-istio/#why-use-istio Istio makes it easy to create a network of deployed services with load balancing, service-to-service authentication, monitoring, and more, with few or no code changes in service code. You add Istio support to services by deploying a special sidecar proxy throughout your environment that intercepts all network communication between microservices, then configure and manage Istio using its control plane functionality, which includes: 2. Service Mesh2.1 What’s a service mesh[William] William Morgan :https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one A service mesh is a dedicated infrastructure layer for making service-to-service communication safe, fast, and reliable. If you’re building a cloud native application, you need a service mesh. 2.2 What is a service mesh?[Istio] istio官网 ：https://istio.io/docs/concepts/what-is-istio/#what-is-a-service-mesh The term service mesh is used to describe the network of microservices that make up such applications and the interactions between them. As a service mesh grows in size and complexity, it can become harder to understand and manage. Its requirements can include discovery, load balancing, failure recovery, metrics, and monitoring. A service mesh also often has more complex operational requirements, like A/B testing, canary rollouts, rate limiting, access control, and end-to-end authentication. 2.3 Linkerd 和Istio 发展历程 Mircroservices Martin Fowler 14年提出 https://martinfowler.com/articles/microservices.html Linkerd William Morgan[Buoyant] Scala语言编写，运行在JVM中， Service Mesh名词的创造者 16年01月15号，0.0.7发布 17年01月23号，加入CNCF 17年04月25号，1.0版本发布 Envoy C++语言编程[Lyft] 16年09月13号，1.0发布 17年09月14号，加入CNCF Istio Google、IBM、Lyft发布0.1版本 2.4 国内发展情况 蚂蚁金服的SOFA 全称Scalable Open Financial Architecture 前身是SOFA RPC 18年07月正式开源 腾讯的Tencent Service Mesh 华为的CSE Mesher 总结: 基本上都是借鉴了Sidecar、Envoy 和Istio的设计思想 最终目录: TCP/IP协议解决了计算机之间连接的问题, 其实我们很少感知到它的存在 而目前的服务治理也面临相似的问题, 也就是要让计算机中的服务更好的连接起来,而且要做到业务代码尽可能无感知. 2.5 为何Service Mesh 能够迅速走红?随着微服务和容器化技术的发展, 使得开发和运维的方式变得非常方便 从而让服务能够方便的迁移到不同的云平台上. 2.6 回顾一下Service Mesh 的发展历程 借鉴反向代理,对Proxy 模式进行探索,让非业务的代码下沉 使用Sidecar 弥补Proxy 模式功能的不足, 解决”侵入式框架” 中非业务代码的问题 Linkerd 解决了传统Sidecar 模式中通用性的问题 Istio 增加了控制平面,解决了整个系统中的流量完全控制的问题 3. Istio基于Sidecar 模式, 数据平面和控制平台,主流Service Mesh 解决方案 官网: https://istio.io/ github: https://github.com/istio 3.1 整体感受数据平面和控制平面 Sidecar 的方式解决了数据通信的问题,而在Istio 中加入了控制平面,所有的流量都能被有效的控制,也就是通过控制平面可以控制整个系统. 3.2 在Istio 中到底能解决哪些问题? 针对Http、gRPC、WebSocket 等协议的自动负载均衡 故障的排查、应用的容错、路由 流量控制、全链路安全访问控制和认证 请求监测、日志分析以及全链路跟踪 应用的升级发布、频率限制和配合等. 3.3 Architecture有了感性的认知和功能了解之后,接下来就要考虑落地的问题,也就是Istio的架构图该如何设计? 说白了, 就是根据数据平面和控制平面的理念,该怎么设计架构图呢? 这个官方已经帮我们考虑好了 Architecutre: https://istio.io/docs/ops/deployment/architecture/ An Istio service mesh is logically split into a data plane and a control plane. The data plane is composed of a set of intelligent proxies (Envoy) deployed as sidecars. These proxies mediate and control all network communication between microservices. They also collect and report telemetry on all mesh traffic. The control plane manages and configures the proxies to route traffic. 4. 安装Istio4.1 Getting Started 官网: https://istio.io/docs/setup/getting-started/ Set up your platform Download the release Install Istio 4.1.1 Set up your platform这里使用kubernetes 1.14 版本 4.1.2 Download the release Go to the Istio release page... 放到master节点 方式一: 到github 上下载 https://github.com/istio/istio/releases 方式二: macOs or Linux System直接下载，这个地址下载国内下载会很慢，不推荐 curl -L https://istio.io/downloadIstio | sh - 解压 tar -zxvf istio-1.x.y.tar.gz, 进入到Istio 文件目录下 The installation directory contains: Installation YAML files for Kubernetes in install/kubernetes Sample applications in samples/ The istioctl client binary in the bin/ directory. istioctl is used when manually injecting Envoy as a sidecar proxy. 将itsioctl 添加到环境变量中 export PATH=$PWD/bin:$PATH 4.1.3 Install Istio4.1.3.1 Kubernetes CRDkubernetes 平台对于分布式服务部署的很多重要的模块都有系统性的支持,借助如下一些平台资源可以满足大多数分布式系统部署和管理的需求 但是在不同应用业务环境下,对于平台可能有一些特殊的需求,这些需求可以抽象为kubernetes的扩展资源,而kubernetes 的CRD(CustomResourceDefinition) 为这样的需求提供了轻量级的机制,保证新的资源的快速注册和使用. 在更老的版本中, TPR(ThirdPartyResource) 是与CRD 类似的概念, 但是在1.9 以上的版本中被弃用,而CRD 则进入到beta的状态. Istio就是使用CRD在Kubernetes上建构出一层Service Mesh的实现 istio-1.0.6/install/kubernetes/helm/istio/templates/crds.yaml 4.1.3.2 准备镜像 istio-1.0.6/install/kubernetes/istio-demo.yaml 上述istio-demo.yaml 文件 中有很多镜像速度较慢,大家记得下载我的,然后tag, 最好保存到自己的镜像仓库中,以便日后使用 从阿里云镜像仓库下载 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/proxy_init:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/hyperkube:v1.7.6_coreos.0 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/galley:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/proxyv2:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/grafana:5.2.3 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/mixer:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/pilot:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/prometheus:v2.3.1 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/citadel:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/servicegraph:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/sidecar_injector:1.0.6 docker pull registry.cn-hangzhou.aliyuncs.com/l_third_party/all-in-one:1.5 将阿里云仓库的镜像打成原有的tag docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/proxy_init:1.0.6 docker.io/istio/proxy_init:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/hyperkube:v1.7.6_coreos.0 quay.io/coreos/hyperkube:v1.7.6_coreos.0 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/galley:1.0.6 docker.io/istio/galley:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/proxyv2:1.0.6 docker.io/istio/proxyv2:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/grafana:5.2.3 grafana/grafana:5.2.3 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/mixer:1.0.6 docker.io/istio/mixer:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/pilot:1.0.6 docker.io/istio/pilot:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/prometheus:v2.3.1 docker.io/prom/prometheus:v2.3.1 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/citadel:1.0.6 docker.io/istio/citadel:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/servicegraph:1.0.6 docker.io/istio/servicegraph:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/sidecar_injector:1.0.6 docker.io/istio/sidecar_injector:1.0.6 docker tag registry.cn-hangzhou.aliyuncs.com/l_third_party/all-in-one:1.5 docker.io/jaegertracing/all-in-one:1.5 删除阿里云仓库下载的镜像 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/proxy_init:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/hyperkube:v1.7.6_coreos.0 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/galley:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/proxyv2:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/grafana:5.2.3 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/mixer:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/pilot:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/prometheus:v2.3.1 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/citadel:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/servicegraph:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/sidecar_injector:1.0.6 docker rmi registry.cn-hangzhou.aliyuncs.com/l_third_party/all-in-one:1.5 4.1.3.4 安装Istio 核心组件 根据 istio-1.0.6/install/kubernetes/istio-demo.yaml 创建资源 kubectl apply -f istio-demo.yaml 查看核心组件资源 kubectl get pods -n istio-system kubectl get svc -n istio-system # 可以给某个service配置一个ingress规则，访问试试 这样一来,Istio的核心组件就安装完成了. 4.2 初步感受Istio4.2.1 手动注入Sidecar大家都知道,k8s 是通过pod 来部署业务的,流量的进出都是直接跟pod 打交道的 那在Istio 中如何体现Sidecar的作用呢？ 思路: 在pod 中除了业务的contailer,再增加一个contailer为Sidecar 岂不快哉 准备一个资源文件 first-istio.yaml apiVersion: apps/v1 kind: Deployment metadata: name: first-istio spec: selector: matchLabels: app: first-istio replicas: 1 template: metadata: labels: app: first-istio spec: containers: - name: first-istio image: registry.cn-hangzhou.aliyuncs.com/luyanan/test-docker-image:v1.0 ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: first-istio spec: ports: - port: 80 protocol: TCP targetPort: 8080 selector: app: first-istio type: ClusterIP kubectl apply -f first-istio.yaml kubectl get pods -> # 注意该pod中容器的数量 kubectl get svc curl 192.168.80.227:8080/dockerfile curl 10.105.179.205/dockerfile 删除上面的资源,重新创建, 使用手动注入Sidecar的方式 kubectl delete -f first-istio.yaml istioctl kube-inject -f first-istio.yaml | kubectl apply -f - 查看资源 kubectl get pods -> # 注意该pod中容器的数量 kubectl get svc kubectl describe pod first-istio-cc5d65fc-rzdxx -> # Containers:first-istio &amp; istio-proxy 删除资源 istioctl kube-inject -f first-istio.yaml | kubectl delete -f - 这样一来,就手动给pod 注入了sidecar的contailer, 也就是envoy sidecar 实际上,其实这块先是改变了yaml 文件的内容,然后再创建 pod, kubectl get pod pod-name -o yaml 4.2.2 自动注入Sidecar上述每次都进行手动创建肯定是不爽的，那能不能自动注入呢? 这块需要命名空间的支持,比如有一个命令空间为istio-demo, 可以让该命名空间下创建的pod 自动注入sidecar 创建命名空间 kubectl create namespace istio-demo 给命名空间添加label kubectl label namespace istio-demo istio-injection=enabled 创建资源 kubectl apply -f first-istio.yaml -n istio-demo 查看资源 kubectl get pods -n istio-demo kubectl describe pod pod-name -n istio-demo kubectl get svc -n istio-demo 删除资源 kubectl delete -f first-istio.yaml -n istio-demo 4.2.3 感受prometheus和grafana其实Istio 已经默认帮我们安装好了grafana和prometheus,只是对应的service 是ClusterIp, 我们按照k8s的方式配置一下ingress的访问规则,但是要前提会有Ingress Controller的支持, 访问prometheus 搜索istio-demo.yaml 文件 kind: Service name: http-prometheus # 主要是为了定位到prometheus的Service 配置prometheus的ingrss 规则 prometheus-ingress.yaml #ingress apiVersion: extensions/v1beta1 kind: Ingress metadata: name: prometheus-ingress namespace: istio-system spec: rules: - host: prometheus.istio.luyanan.com http: paths: - path: / backend: serviceName: prometheus servicePort: 9090 访问grafana istio-demo.yaml 文件 kind: Service targetPort: 3000 配置grafana 的ingress 规则 grafana-ingress.yaml #ingress apiVersion: extensions/v1beta1 kind: Ingress metadata: name: grafana-ingress namespace: istio-system spec: rules: - host: grafana.istio.luyanan.com http: paths: - path: / backend: serviceName: grafana servicePort: 3000 根据两个ingress 创建资源 并且访问测试 istio.luyanan.com/prometheus istio.luyanan.com/grafana kubectl apply -f prometheus-ingress.yaml kubectl apply -f grafana-ingress.yaml kubectl get ingress -n istio-system","categories":[{"name":"Service Mesh","slug":"Service-Mesh","permalink":"https://rainsoil.github.io/categories/Service-Mesh/"},{"name":"Service Mesh","slug":"Service-Mesh/Service-Mesh","permalink":"https://rainsoil.github.io/categories/Service-Mesh/Service-Mesh/"}],"tags":[]},{"title":"Istio架构原理和实战(2)","slug":"Service Mesh/Istio架构原理和实战(2)","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/service-mesh/istio-jia-gou-yuan-li-he-shi-zhan-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/service-mesh/istio-jia-gou-yuan-li-he-shi-zhan-2/","excerpt":"","text":"Istio 核心架构和实战1. 组件介绍Components 官网:https://istio.io/docs/ops/deployment/architecture/#components 1.1 Proxy[Envoy]proxy 在Istio 架构中必须存在. Envoy 是由Lyft开发并开源的,使用C++ 编写的高性能代理,负责在服务网格中服务的进出流量 Istio uses an extended version of the Envoy proxy. Envoy is a highperformance proxy developed in C++ to mediate all inbound and outbound traffic for all services in the service mesh. Envoy proxies are the only Istio components that interact with data plane traffic. 官网:https://www.envoyproxy.io/ ENVOY IS AN OPEN SOURCE EDGE AND SERVICE PROXY, DESIGNED FOR CLOUD-NATIVE APPLICATIONS github: https://github.com/envoyproxy/envoy Envoy is hosted by the Cloud Native Computing Foundation (CNCF). If you are a company that wants to help shape the evolution of technologies that are container-packaged, dynamically-scheduled and microservices-oriented, consider joining the CNCF. For details about who’s involved and how Envoy plays a role, read the CNCF announcement. 1.1.1 Features Dynamic service discovery Load balancing TLS termination HTTP/2 and gRPC proxies Circuit breakers Health checks Staged rollouts with %-based traffic split Fault injection Rich metrics 1.1.2 为什么选择Envoy对于Sidecar/Proxy 其实不仅仅可以选择Envoy, 还可以用Likerd、Nginx和NginMesh等. 像Nginx 作为分布式架构中比较广泛使用的网关,Istio 默认却没有选择,是因为Nginx 没有Envoy 优秀的配置扩展,Envoy 可以实时配置. 1.2 Mixer Mixer 在Istio 架构中不是必须的. 官网: https://istio.io/docs/ops/deployment/architecture/#mixer Mixer is a platform-independent component. Mixer enforces access control and usage policies across the service mesh, and collects telemetry data from the Envoy proxy and other services. The proxy extracts request level attributes, and sends them to Mixer for evaluation. You can find more information on this attribute extraction and policy evaluation in our Mixer Configuration documentation. Mixer includes a flexible plugin model. This model enables Istio to interface with a variety of host environments and infrastructure backends. Thus, Istio abstracts the Envoy proxy and Istio-managed services from these details. 为集群执行访问控制,哪些用户可以访问哪些服务? 包括白名单检查、ACL 检查等. 策略管理,比如某个服务最多只能接受多少流量请求 遥测报告上报,比如从Envoy中收集数据[请求数据、使用时间、使用的协议等], 通过Adpater 上报给Primethues、Heapster等. 1.3 PilotPilot在Istio架构中必须要有 官网: https://istio.io/docs/ops/deployment/architecture/#pilot Pilot provides service discovery for the Envoy sidecars, traffic management capabilities for intelligent routing (e.g., A/B tests, canary rollouts, etc.), and resiliency (timeouts, retries, circuit breakers, etc.). Pilot converts high level routing rules that control traffic behavior into Envoy-specific configurations, and propagates them to the sidecars at runtime. Pilot abstracts platform-specific service discovery mechanisms and synthesizes them into a standard format that any sidecar conforming with the Envoy API can consume. Pilot 为Envoy Sidecar 提供了服务发现功能, 为智能路由提供了流量管理能力(比如A/B测试,金丝雀发布等) Pilot 本身不做服务注册,它会提供一个接口,对接已有的服务注册系统,比如Eureka、Etcd等, Pilot 对配置的格式做了抽象,整理成能够符合Envoy 数据层的API Pilot 定义了一个抽象模型,从特定平台细节中解耦,用于对接外部的不同平台 Envoy API 负责和Envoy 的通讯,主要是发送服务发现信息和流量控制规则给Envoy Platform Adapter 是Pilot 抽象模型的实现版本,用于对接外部的不同平台 1.4 GalleyGalley 在Istio 架构中不是必须的 官网: https://istio.io/docs/ops/deployment/architecture/#galley Galley is Istio’s configuration validation, ingestion, processing and distribution component. It is responsible for insulating the rest of the Istio components from the details of obtaining user configuration from the underlying platform (e.g. Kubernetes). 主要负责Istio 配置的校验、各种配置之间的统筹,为Istio 提供配置管理服务, 通过Kubernetes 的webhook 机制对pilot 和mixer的配置进行验证. 1.5 CitadelCitadel在Istio 架构中不是必须的 官网: https://istio.io/docs/ops/deployment/architecture/#citadel Citadel enables strong service-to-service and end-user authentication with built-in identity and credential management. You can use Citadel to upgrade unencrypted traffic in the service mesh. Using Citadel, operators can enforce policies based on service identity rather than on relatively unstable layer 3 or layer 4 network identifiers. Starting from release 0.5, you can use Istio’s authorization feature to control who can access your services. 在有一些场景中,对于安全的要求是非常高的,比如支付,所以Citadel 就是用来保证安全的. 2. 实战之Bookinfo 官网: https://istio.io/docs/examples/bookinfo/ This example deploys a sample application composed of four separate microservices used to demonstrate various Istio features. The application displays information about a book, similar to a single catalog entry of an online book store. Displayed on the page is a description of the book, book details (ISBN, number of pages, and so on), and a few book reviews. The Bookinfo application is broken into four separate microservices: productpage. The productpage microservice calls the details and reviews microservices to populate the page. details. The details microservice contains book information. reviews. The reviews microservice contains book reviews. It also calls the ratings microservice. ratings. The ratings microservice contains book ranking information that accompanies a book review. There are 3 versions of the reviews microservice: Version v1 doesn’t call the ratings service. Version v2 calls the ratings service, and displays each rating as 1 to 5 black stars. Version v3 calls the ratings service, and displays each rating as 1 to 5 red stars. The end-to-end architecture of the application is shown below. This application is polyglot, i.e., the microservices are written in different languages. It’s worth noting that these services have no dependencies on Istio, but make an interesting service mesh example, particularly because of the multitude of services, languages and versions for the reviews service. 2.1 理解Bookinfo productpage 是python 语言编写的,用于前端页面展示,会调用 reviews微服务和details服务 details 是Ruby 语言编写的,是书籍的详情信息 reviews 是java编写的,是书籍的评论信息,会调用ratings 微服务, 有3个版本 ratings是node.js 语言编写的,是书籍的评分部分 2.2 Sidecar 自动注入到微服务官网: https://istio.io/docs/examples/bookinfo/#start-the-application-services To run the sample with Istio requires no changes to the application itself. Instead, you simply need to configure and run the services in an Istio-enabled environment, with Envoy sidecars injected along side each service. The resulting deployment will look like this All of the microservices will be packaged with an Envoy sidecar that intercepts incoming and outgoing calls for the services, providing the hooks needed to externally control, via the Istio control plane, routing, telemetry collection, and policy enforcement for the application as a whole. Change directory to the root of the Istio installation. cd istio-1.0.6 )The default Istio installation uses automatic sidecar injection. Label the namespace that will host the application with istio-injection=enabled: kubectl label namespace default istio-injection=enabled kubectl get namespaces --show-labels Deploy your application using the kubectl command: kubectl apply -f istio-1.0.6/samples/bookinfo/platform/kube/bookinfo.yaml 查看pod kubectl get pods NAME READY STATUS details-v1-d458c8599-l2rpr 2/2 Running productpage-v1-79d85ff9fc-jvlrn 2/2 Running ratings-v1-567bfb85cf-lrkpm 2/2 Running reviews-v1-fd6c96c74-ncl8k 2/2 Running reviews-v2-68d98477f6-s5f7l 2/2 Running reviews-v3-8495f5f6bb-mx8q2 2/2 Running 查看sv kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE details ClusterIP 10.103.89.119 &lt;none> 9080/TCP 5m48s kubernetes ClusterIP 10.96.0.1 &lt;none> 443/TCP 18d productpage ClusterIP 10.104.220.93 &lt;none> 9080/TCP 5m48s ratings ClusterIP 10.106.48.89 &lt;none> 9080/TCP 5m48s reviews ClusterIP 10.98.5.206 &lt;none> 9080/TCP 5m48s 测试一下是否成功 kubectl exec -it $(kubectl get pod -l app=ratings -o jsonpath='&amp;#123;.items[0].metadata.name&amp;#125;') -c ratings -- curl productpage:9080/productpage | grep -o \"&lt;title>.*&lt;/title>\" &lt;title>Simple Bookstore App&lt;/title> 2.3 通过Ingress 方式访问 创建ingress 规则 productpage-ingress.yaml 资源文件 #ingress apiVersion: extensions/v1beta1 kind: Ingress metadata: name: productpage-ingress spec: rules: - host: productpage.istio.luyanan.com http: paths: - path: / backend: serviceName: productpage servicePort: 9080 访问测试 productpage.istio.luyanan.com 2.4 通过Istio的Ingressgateway访问官网: https://istio.io/docs/examples/bookinfo/#determine-the-ingress-ip-and-port Define the ingress gateway for the application: istio-1.0.6/samples/bookinfo/networking/bookinfo-gateway.yaml 可以查看一下该yaml文件，一个是Gateway，一个是VirtualService kubectl apply -f bookinfo-gateway.yaml Confirm the gateway has been created: kubectl get gateway set the INGRESS_HOST and INGRESS_PORT variables for accessing the gateway export INGRESS_HOST=$(kubectl get po -l istio=ingressgateway -n istio-system -o jsonpath='&amp;#123;.items[0].status.hostIP&amp;#125;') export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway - o jsonpath='&amp;#123;.spec.ports[?(@.name==\"http2\")].nodePort&amp;#125;') Set GATEWAY_URL : export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT 查看INGRESS_PORT端口 # 比如结果为31380 env | grep INGRESS_PORT 测试 不断的访问测试,发现会访问review的不同版本 Apply default destination rules 官网: https://istio.io/docs/examples/bookinfo/#apply-default-destination-rules Before you can use Istio to control the Bookinfo version routing, you need to define the available versions, called subsets, in destination rules. istio-1.0.6/samples/bookinfo/networking/destination-rule-all.yaml kubectl apply -f destination-rule-all.yaml 2.5 体验Istio的流量管理流量这块就体现了Pilot和Envoy的功能 2.5.1 基于版本的路由 官网: https://istio.io/docs/tasks/traffic-management/request-routing/#apply-a-virtual-service 之前刷新productpage页面的时候,发现review的版本一直会变,能不能一直访问某个版本呢? istio-1.0.6/samples/bookinfo/networking/virtual-service-reviews-v3.yaml kubectl apply -f virtual-service-reviews-v3.yaml 再次访问测试http://121.41.10.13:31380/productpage 2.5.2 基于用户身份的路由 官网: https://istio.io/docs/tasks/traffic-management/request-routing/#route-based-on-user-identity Next, you will change the route configuration so that all traffic from a specific user is routed to a specific service version. In this case, all traffic from a user named Jason will be routed to the service reviews:v2. Note that Istio doesn’t have any special, built-in understanding of user identity. This example is enabled by the fact that the productpage service adds a custom end-user header to all outbound HTTP requests to the reviews service. Remember, reviews:v2 is the version that includes the star ratings feature. 根据对应文件创建资源 istio-1.0.6/samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml 测试 # 使用jason来登录[右上角有Sign in的功能或者url?u=jason]，一直会访问到v2版本 On the /productpage of the Bookinfo app, log in as user jason. Refresh the browser. What do you see? The star ratings appear next to each review. # 使用其他用户登陆,一直会访问到v1版本 Log in as another user (pick any name you wish). Refresh the browser. Now the stars are gone. This is because traffic is routed to reviews:v1 for all users except Jason. 2.5.3 基于权重的路由 根据对应文件创建资源 istio-1.0.6/samples/bookinfo/networking/virtual-service-reviews-50-v3.yaml 一般几率访问到v1,一般的几率访问到v3 这里就相当于之前的蓝绿部署,AB测试或者灰度发布 权重加起来必须是100 kubectl apply -f virtual-service-reviews-50-v3.yaml 测试 http://121.41.10.13:31380/productpage 2.5.4 故障注入 官网: https://istio.io/docs/tasks/traffic-management/fault-injection/ Apply application version routing by either performing the request routing task or by running the following commands: istio-1.0.6/samples/bookinfo/networking/ kubectl apply -f virtual-service-all-v1.yaml kubectl apply -f virtual-service-reviews-test-v2.yaml With the above configuration, this is how requests flow: productpage → reviews:v2 → ratings (only for user jason) productpage → reviews:v1 (for everyone else) To test the Bookinfo application microservices for resiliency, inject a 7s delay between the reviews:v2 and ratings microservices for user jason. This test will uncover a bug that was intentionally introduced into the Bookinfo app. Note that the reviews:v2 service has a 10s hard-coded connection timeout for calls to the ratings service. Even with the 7s delay that you introduced, you still expect the end-to-end flow to continue without any errors. 创建一个故障注入规则,使得jason 用户访问v2 到ratings 有7秒的延迟 kubectl apply -f virtual-service-ratings-test-delay.yaml 使得jason账户登陆,并且访问productpage页面,会得到这样一个返回信息 Error fetching product reviews! Sorry, product reviews are currently unavailable for this book. View the web page response times: Open the Developer Tools menu in you web browser. Open the Network tab Reload the /productpage web page. You will see that the page actually loads in about 6 seconds. 2.5.5 流量迁移 官网: https://istio.io/docs/tasks/traffic-management/traffic-shifting/ This task shows you how to gradually migrate traffic from one version of a microservice to another. For example, you might migrate traffic from an older version to a new version. A common use case is to migrate traffic gradually from one version of a microservice to another. In Istio, you accomplish this goal by configuring a sequence of rules that route a percentage of traffic to one service or another. In this task, you will send 50% of traffic to reviews:v1 and 50% to reviews:v3. Then, you will complete the migration by sending 100% of traffic to reviews:v3. 让所有的流量都到v1 kubectl apply -f virtual-service-all-v1.yaml 将v1的50% 流量转移到v3 kubectl apply -f virtual-service-reviews-50-v3.yaml 确保v3版本没问题后,可以将流量都转移到v3 kubectl apply -f virtual-service-reviews-v3.yaml 访问测试,看是否都访问到v3 版本 2.6 体验Istio的Obseerve这块就体现了Mixer和Envoy的功能 2.6.1 收集Metrics 官网: https://istio.io/docs/tasks/observability/metrics/collecting-metrics/ This task shows how to configure Istio to automatically gather telemetry for services in a mesh. At the end of this task, a new metric will be enabled for calls to services within your mesh. Apply a YAML file with configuration for the new metric that Istio will generate and collect automatically metrics-crd.yaml # Configuration for metric instances apiVersion: \"config.istio.io/v1alpha2\" kind: instance metadata: name: doublerequestcount namespace: istio-system spec: compiledTemplate: metric params: value: \"2\" # count each request twice dimensions: reporter: conditional((context.reporter.kind | \"inbound\") == \"outbound\", \"client\", \"server\") source: source.workload.name | \"unknown\" destination: destination.workload.name | \"unknown\" message: '\"twice the fun!\"' monitored_resource_type: '\"UNSPECIFIED\"' --- # Configuration for a Prometheus handler apiVersion: \"config.istio.io/v1alpha2\" kind: prometheus metadata: name: doublehandler namespace: istio-system spec: metrics: - name: double_request_count # Prometheus metric name instance_name: doublerequestcount.instance.istio-system # Mixer instance name (fully-qualified) kind: COUNTER label_names: - reporter - source - destination - message --- # Rule to send metric instances to a Prometheus handler apiVersion: \"config.istio.io/v1alpha2\" kind: rule metadata: name: doubleprom namespace: istio-system spec: actions: - handler: doublehandler.prometheus instances: - doublerequestcount Send traffic to the sample application http://121.41.10.13:31380/productpage 访问 prometheus http://prometheus.istio.luyanan.com/ 根据 istio_double_request_count 进行查询 Understanding the metrics configuration https://istio.io/docs/tasks/observability/metrics/collecting-metrics/#understanding-the-metrics-configuration 2.6.2 查询Istio的Metrics 官网: https://istio.io/docs/tasks/observability/metrics/querying-metrics/ This task shows you how to query for Istio Metrics using Prometheus. As part of this task, you will use the web-based interface for querying metric values. 访问 productpage http://121.41.10.13:31380/productpage 打开prometheus 界面 http://prometheus.istio.luyanan.com/ 输入查询指标 istio_requests_total About the Prometheus add-on https://istio.io/docs/tasks/observability/metrics/querying-metrics/#about-theprometheus-add-on 2.6.3 分布式追踪之Jaeger 官网: https://istio.io/docs/tasks/observability/distributed-tracing/overview/ Distributed tracing enables users to track a request through mesh that is distributed across multiple services. This allows a deeper understanding about request latency, serialization and parallelism via visualization jaeger官网:https://istio.io/docs/tasks/observability/distributed-tracing/jaeger/ After completing this task, you understand how to have your application participate in tracing with Jaeger, regardless of the language, framework, or platform you use to build your application. istio-tracing-c8b67b59c-8vgrl 1/1 Running —&gt; 即Jaeger，默认已经安装 查看jaeger 的svc kubectl get svc -n istio-system | grep jae kubectl get svc jaeger-query -n istio-system -o yaml 配置jaeage的ingress jaeger-ingress.yaml #ingress apiVersion: extensions/v1beta1 kind: Ingress metadata: name: jaeger-ingress namespace: istio-system spec: rules: - host: jaeger.istio.luyanan.com http: paths: - path: / backend: serviceName: jaeger-query servicePort: 16686 浏览器访问 jaeger.istio.luyanan.com 发送100个请求 for i in `seq 1 100`; do curl -s -o /dev/null http://121.41.10.13:31380/productpage; done 进入到jaeger 界面 选择productpage, 查询详情 2.6.4 Mesh 可视化之Kiali 官网: https://istio.io/docs/tasks/observability/kiali/ This task shows you how to visualize different aspects of your Istio mesh. As part of this task, you install the Kiali add-on and use the web-based graphical user interface to view service graphs of the mesh and your Istio configuration objects. Lastly, you use the Kiali Public API to generate graph data in the form of consumable JSON. 3. 安装Istio(Helm) 官网: https://istio.io/docs/setup/install/helm/ 3.1 下载安装Helm3.1.1 Helm 简介Helm 是kubernetes 的软件包管理工具,类似于Ubuntu 中的apt、Contos 中的yum等. 可以快速查找、下载和安装软件包,Helm 由客户端组件helm和服务端组件tiller 组成 3.1.2 解决的问题比如在k8s中部署一个wordpress , 需要创建deployment、service、secret、pv等,这些资源有时候不方便管理,过于分散,如果使用kubectl 进行操作,发现还是比较恶心的,所以简单来说,helm 就是为了解决上述问题的 . 3.1.3 各种名词概念 chart helm 的打包格式叫chart,chart即一系列文件,描述了一组相关的k8s集群资源 helm 客户端命令工具, 用于本地开发以及管理chart、chart仓库. tiller helm的服务端,tiller 接收helm的请求,与k8s 的apiserver打交道,根据chart 生成一个release 并且管理release release helm install 命令在k8s集群中部署的chart 称之为release repository helm chart helm 客户端通过http协议来访问存储库中chart的索引文件和压缩包 3.1.4 图解Helm 原理 3.1.5 release操作创建release helm 客户端从指定的目录或本地tar 文件或远程repo 仓库解析出chart 的结构信息 helm 客户端指定的chart 结构和values 信息通过gRPC 传递给Tiller Tiller 服务端根据chart 和values 生成一个release Tiller 将install release 请求直接传递给kube-apiserver 删除release helm 客户端从指定的目录或者本地tar 文件或者远程repo 仓库解析出chart 的结构信息 helm 客户端指定的chart结构和values 信息通过gRPC传递给Tiller Tiller服务器根据chart 和values 生成一个release Tiller 将delete release 请求直接传递给api-server 更新release helm 客户端将需要更新的chart 的release 名称、chart结构和values 信息传给Tiller Tiller 将收到信息生成新的release,并同时更新这个release 的historty Tiller 将新的release 传递给kube-apiserver 进行更新 3.1.6 安装Helm 官网: https://github.com/helm/helm/releases # 放到k8s 集群master节点 ## 解压 tar -zxvf helm-v2.13.1-linux-amd64.tar.gz # 复制helm 二进制到bin目录下, 并且配置环境变量 cp linux-amd64/helm /usr/local/bin/ export PATH=$PATH:/usr/local/bin # 查看是否安装成功 helm version [ Client: &amp;version.Version&amp;#123;SemVer:\"v2.13.1\", GitCommit:\"618447cbf203d147601b4b9bd7f8c37a5d39fbb4\", GitTreeState:\"clean\"&amp;#125; Error: could not find tiller ] 3.1.7 安装Tiller重新安装tiller: helm reset -f 安装tiller helm init --upgrade -i registry.cnhangzhou.aliyuncs.com/google_containers/tiller:v2.13.1 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts kubectl get pods -n kube-system -l app=helm kubectl get svc -n kube-system -l app=helm 配置rbac cat >helm-rbac-config.yaml&lt;&lt;EOF apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: tiller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller namespace: kube-system EOF kubectl create -f helm-rbac-config.yaml # 配置tiller使用创建的ServiceAccount kubectl patch deploy --namespace kube-system tiller-deploy -p '&amp;#123;\"spec\":&amp;#123;\"template\":&amp;#123;\"spec\":&amp;#123;\"serviceAccount\":\"tiller\"&amp;#125;&amp;#125;&amp;#125;&amp;#125;' 验证 # 查看pod启动情况 kubectl get pod -n kube-system -l app=helm # 再次查看版本，显示出server版本 helm version [ Client: &amp;version.Version&amp;#123;SemVer:\"v2.13.1\", GitCommit:\"618447cbf203d147601b4b9bd7f8c37a5d39fbb4\", GitTreeState:\"clean\"&amp;#125; Server: &amp;version.Version&amp;#123;SemVer:\"v2.13.1\", GitCommit:\"618447cbf203d147601b4b9bd7f8c37a5d39fbb4\", GitTreeState:\"clean\"&amp;#125; ] 3.1.8 使用Helm 操作`chart``helm create:创建一个chart模板，比如：helm create test --->ls test helm package:打包一个chart模板，比如：helm package test --->test-0.1.0.tgz heml search:查找可用的chart模板，比如：helm search nginx helm inspect:查看指定chart的基本信息，比如：helm inspect test helm install:根据指定的chart部署一个release到k8s集群，比如：helm install test --- >get pods 3.1.9 chart 模板 chart 文件结构 wordpress ├── charts # 存放chart的定义 ├── Chart.yaml # 包含chart信息的yaml文件，如chart的版本、名称等 ├── README.md # chart的介绍信息 ├── requirements.lock ├── requirements.yaml # chart需要的依赖 ├── templates # k8s需要的资源 │ ├── deployment.yaml │ ├── externaldb-secrets.yaml │ ├── _helpers.tpl # 存放可重用的模板片段 │ ├── ingress.yaml │ ├── NOTES.txt │ ├── pvc.yaml │ ├── secrets.yaml │ ├── svc.yaml │ └── tls-secrets.yaml └── values.yaml # 当前chart的默认配置的值 3.2 使用helm 安装Istio 官网: https://istio.io/docs/setup/install/helm/","categories":[{"name":"Service Mesh","slug":"Service-Mesh","permalink":"https://rainsoil.github.io/categories/Service-Mesh/"},{"name":"Service Mesh","slug":"Service-Mesh/Service-Mesh","permalink":"https://rainsoil.github.io/categories/Service-Mesh/Service-Mesh/"}],"tags":[]},{"title":"SpringBoot2","slug":"Spring Boot/SpringBoot2.X 中文配置参考指南","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/spring-boot/springboot2.x-zhong-wen-pei-zhi-can-kao-zhi-nan/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring-boot/springboot2.x-zhong-wen-pei-zhi-can-kao-zhi-nan/","excerpt":"","text":"SpringBoot2.X 中文配置参考指南.md＃================================================= ================== ＃COMMON SPRING BOOT PROPERTIES ＃============================================== ===================== ＃---------------------------------------- ＃核心属性 ＃----- ----------------------------------- debug = false ＃启用调试日志。 trace = false ＃启用跟踪日志。 ＃LOGGING logging.config = ＃日志配置文件的位置。例如，Logback的`classpath：logback.xml`。 logging.exception-conversion-word =％wEx ＃记录异常时使用的转换字。 logging.file = ＃日志文件名（例如`myapp.log`）。名称可以是确切的位置或相对于当前目录。 logging.file.max-history = 0 ＃要保留的归档日志文件的最大数量。仅支持默认的登录设置。 logging.file.max-size = 10MB ＃最大日志文件大小。仅支持默认的登录设置。 logging.level。* =＃日志级别严重性映射。例如`logging.level.org.springframework = DEBUG`。 logging.path = ＃日志文件的位置。例如，`/ var / log`。 logging.pattern.console = ＃输出到控制台的Appender模式。仅使用默认的Logback设置支持。 logging.pattern.dateformat = yyyy-MM-dd HH：mm：ss.SSS ＃日志格式的Appender模式。仅使用默认的Logback设置支持。 logging.pattern.file = ＃输出到文件的Appender模式。仅使用默认的Logback设置支持。 logging.pattern.level =％5p ＃日志级别的Appender模式。仅使用默认的Logback设置支持。 logging.register-shutdown-hook = false ＃为日志记录系统初始化时注册一个关闭钩子。 ＃AOP spring.aop.auto =真＃添加@EnableAspectJAutoProxy。 spring.aop.proxy-target-class = true ＃是否创建基于子类的（CGLIB）代理（true），而不是基于标准Java接口的代理（false）。 ＃IDENTITY （ContextIdApplicationContextInitializer） spring.application.name = ＃应用程序名称。 ＃ADMIN （SpringApplicationAdminJmxAutoConfiguration） spring.application.admin.enabled = false ＃是否为应用程序启用管理功能。 spring.application.admin.jmx-name = org.springframework.boot:type = Admin,name = SpringApplication ＃JMX应用程序的名称admin MBean。 ＃AUTO-CONFIGURATION spring.autoconfigure.exclude = ＃要排除的自动配置类。 ＃BANNER spring.banner.charset = UTF-8 ＃横幅文件编码。 spring.banner.location = classpath：banner.txt ＃横幅文本资源位置。 spring.banner.image.location = classpath：banner.gif ＃横幅图像文件位置（也可以使用jpg或png）。 spring.banner.image.width = 76 ＃字符图片的宽度。 spring.banner.image.height = ＃以字符形式显示横幅图像的高度（默认基于图像高度）。 spring.banner.image.margin = 2 ＃在字符中留下左手边缘图像。 spring.banner.image.invert = false ＃图像是否应该反转为黑暗的终端主题。 ＃弹簧芯 ＃SPRING spring.beaninfo.ignore = true ＃是否跳过对BeanInfo类的搜索。 ＃SPRING CACHE（CacheProperties） spring.cache.cache-names = ＃如果基础高速缓存管理器支持，将创建缓存名称的逗号分隔列表。 spring.cache.caffeine.spec = ＃用于创建缓存的规范。有关规格格式的更多详细信息，请参阅CaffeineSpec。 spring.cache.couchbase.expiration = 0ms ＃进入到期。默认情况下，这些条目永不过期。请注意，该值最终转换为秒。 spring.cache.ehcache.config = ＃用于初始化EhCache的配置文件的位置。 spring.cache.infinispan.config = ＃用于初始化Infinispan的配置文件的位置。 spring.cache.jcache.config = ＃用于初始化缓存管理器的配置文件的位置。 spring.cache.jcache.provider = ＃用于检索符合JSR-107的缓存管理器的CachingProvider实现的完全限定名称。只有在类路径中有多个JSR-107实现可用时才需要。 spring.cache.redis.cache-null-values = true ＃允许缓存空值。 spring.cache.redis.key-prefix = ＃键字前缀。 spring.cache.redis.time-to-live = 0ms ＃进入到期。默认情况下，这些条目永不过期。 spring.cache.redis.use-key-prefix = true＃写入Redis时是否使用密钥前缀。 spring.cache.type = ＃缓存类型。默认情况下，根据环境自动检测。 ＃SPRING CONFIG - 仅使用环境属性（ConfigFileApplicationListener） spring.config.additional-location = ＃除默认配置之外使用的配置文件位置。 spring.config.location = ＃配置替换默认值的文件位置。 spring.config.name = application ＃配置文件名。 ＃HAZELCAST（HazelcastProperties） spring.hazelcast.config = ＃用于初始化Hazelcast的配置文件的位置。 ＃项目信息（ProjectInfoProperties） spring.info.build.location = classpath：META-INF / build-info.properties ＃生成的build-info.properties文件的位置。 spring.info.git.location =类路径：git.properties 生成的git.properties文件＃所在。 ＃JMX spring.jmx.default域 = ＃JMX域名。 spring.jmx.enabled = true ＃将管理bean展示给JMX域。 spring.jmx.server = mbeanServer ＃MBeanServer bean名称。 ＃电子邮件（MailProperties） spring.mail.default-encoding = UTF-8 ＃默认MimeMessage编码。 spring.mail.host = ＃SMTP服务器主机。例如，`smtp.example.com`。 spring.mail.jndi-name = ＃会话JNDI名称。设置时，优先于其他邮件设置。 spring.mail.password = ＃登录SMTP服务器的密码。 spring.mail.port = ＃SMTP服务器端口。 spring.mail.properties。* = ＃其他JavaMail会话属性。 spring.mail.protocol = smtp ＃SMTP服务器使用的协议。 spring.mail.test-connection = false＃是否测试邮件服务器在启动时是否可用。 spring.mail.username = ＃登录SMTP服务器的用户。 ＃应用程序设置（SpringApplication） spring.main.banner-mode = console ＃用于在应用程序运行时显示横幅的模式。 spring.main.sources = ＃包含在ApplicationContext中的源（类名，包名或XML资源位置）。 spring.main.web-application-type = ＃显式请求特定类型的Web应用程序的标志。如果未设置，则根据类路径自动检测。 ＃FILE ENCODING（FileEncodingApplicationListener） spring.mandatory-file-encoding = ＃应用程序必须使用的期望字符编码。 ＃INTERNATIONALIZATION （MessageSourceProperties） spring.messages.always-use-message-format = false ＃是否始终应用MessageFormat规则，甚至可以解析不带参数的消息。 spring.messages.basename = messages ＃以逗号分隔的基本名称列表（本质上是一个完全限定的类路径位置），每个都遵循ResourceBundle约定，对基于斜杠的位置提供宽松的支持。 spring.messages.cache-duration = ＃加载的资源包文件缓存持续时间。未设置时，捆绑包将永久缓存。如果未指定持续时间后缀，则将使用秒。 spring.messages.encoding = UTF-8 ＃消息包编码。 spring.messages.fallback-to-system-locale = true＃是否使用消息代码作为默认消息，而不是抛出“NoSuchMessageException”。仅在开发期间推荐。＃如果没有找到特定语言环境的文件，是否回退到系统语言环境。 spring.messages.use-code-as-default-message = false ＃OUTPUT spring.output.ansi.enabled =检测＃配置的ANSI输出。 ＃PID FILE（ApplicationPidFileWriter） spring.pid.fail-on-write-error = ＃如果使用ApplicationPidFileWriter，将失败，但不能写入PID文件。 spring.pid.file =＃要写入的PID文件的位置（如果使用ApplicationPidFileWriter）。 ＃PROFILES spring.profiles.active = ＃逗号分隔的有源配置文件列表。可以被命令行开关覆盖。 spring.profiles.include =＃无条件激活指定的以逗号分隔的配置文件列表（或使用YAML配置文件列表）。 ＃Quartz调度（QuartzProperties） spring.quartz.jdbc.initialize-架构 =嵌入＃数据库模式初始化模式。 spring.quartz.jdbc.schema = classpath中：组织/石英/ IMPL / jdbcjobstore / tables_ @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。 spring.quartz.job-store-type =内存＃石英作业存储类型。 spring.quartz.properties。* = ＃额外的Quartz Scheduler属性。 ＃REACTOR （ReactorCoreProperties） spring.reactor.stacktrace -mode.enabled = false ＃Reactor是否应该在运行时收集堆栈跟踪信息。 ＃SENDGRID（SendGridAutoConfiguration） spring.sendgrid.api-key = ＃SendGrid API密钥。 spring.sendgrid.proxy.host = ＃SendGrid代理主机。 spring.sendgrid.proxy.port = ＃SendGrid代理端口。 ＃---------------------------------------- ＃WEB PROPERTIES ＃----- ----------------------------------- ＃嵌入式服务器配置（ServerProperties） server.address = ＃服务器应绑定到的网络地址。 server.compression.enabled = false ＃是否启用响应压缩。 server.compression.excluded-user-agents = ＃要从压缩中排除的用户代理列表。 server.compression.mime-types = text / html，text / xml，text / plain，text / css，text / javascript，application / javascript ＃应该压缩的逗号分隔的MIME类型列表。 server.compression.min-response-size = 2048 =＃压缩执行所需的最小“Content-Length”值。 server.connection超时＃连接器在关闭连接之前等待另一个HTTP请求的时间。未设置时，使用连接器的容器特定默认值。使用值-1来表示否（即无限）超时。 server.error.include-exception = false ＃包含“exception”属性。 server.error.include-stacktrace = never ＃何时包含“stacktrace”属性。 server.error.path = / error ＃错误控制器的路径。 server.error.whitelabel.enabled = true ＃是否在服务器出错时启用浏览器中显示的默认错误页面。 ＃如果当前环境支持，是否启用HTTP / 2支持。server.jetty.acceptors =server.http2.enabled = false ＃要使用的接受者线程的数量。 server.jetty.accesslog.append = false ＃附加到日志。 server.jetty.accesslog.date-format = dd / MMM / yyyy：HH：mm：ss Z ＃请求日志的时间戳格式。 server.jetty.accesslog.enabled = false ＃启用访问日志。 server.jetty.accesslog.extended-format = false ＃启用扩展的NCSA格式。 server.jetty.accesslog.file-date-format = ＃放置在日志文件名中的日期格式。 ＃日志文件名。如果未指定，日志重定向到“System.err”。server.jetty.accesslog.locale = ＃请求日志的语言环境。server.jetty.accesslog.log-cookies = falseserver.jetty.accesslog.filename = ＃启用记录请求cookie。 server.jetty.accesslog.log-latency = false ＃启用记录请求处理时间。 server.jetty.accesslog.log-server = false ＃启用对请求主机名的记录。 server.jetty.accesslog.retention-period = 31 ＃删除旋转的日志文件之前的天数。 server.jetty.accesslog.time-zone = GMT ＃请求日志的时区。 server.jetty.max-http-post-size = 0＃HTTP帖子或放置内容的最大大小（以字节为单位）。 server.jetty.selectors = ＃要使用的选择器线程数。 server.max-http-header-size = 0 ＃HTTP消息头的最大大小（以字节为单位）。 server.port = 8080 ＃服务器HTTP端口。 server.server-header = ＃用于服务器响应头的值（如果为空，则不会发送头）。 server.use-forward-headers = ＃是否应将X-Forwarded- *标头应用于HttpRequest。 server.servlet.context-parameters。* = ＃Servlet上下文初始化参数。 server.servlet.context-path = ＃应用程序的上下文路径。 server.servlet.application-display-name = application ＃显示应用程序的名称。 server.servlet.jsp.class-name = org.apache.jasper.servlet.JspServlet ＃JSP servlet的类名称。 server.servlet.jsp.init-parameters。* = = ＃会话cookie的域名。＃用于配置JSP servlet的Init参数。 server.servlet.jsp.registered = true ＃JSP servlet是否已注册。 server.servlet.path = / ＃主调度程序servlet的路径。 server.servlet.session.cookie.comment = ＃评论会话cookie。 server.servlet.session.cookie.domain = cookie域 server.servlet.session.cookie.http-only = ＃会话cookie的“HttpOnly”标志。 server.servlet.session.cookie.max-age = ＃会话cookie的最大年龄。如果未指定持续时间后缀，则将使用秒。 server.servlet.session.cookie.name = ＃会话cookie名称。 server.servlet.session.cookie.path = ＃会话cookie的路径。 server.servlet.session.cookie.secure = ＃会话cookie的“安全”标志。 server.servlet.session.persistent = false ＃是否在重新启动之间保留会话数据。 server.servlet.session.store-dir = ＃用于存储会话数据的目录。 server.servlet.session.timeout = ＃会话超时。如果未指定持续时间后缀，则将使用秒。 server.servlet.session.tracking-modes = ＃会话跟踪模式（以下一项或多项：“cookie”，“url”，“ssl”）。 server.ssl.ciphers = ＃支持的SSL密码。 server.ssl.client-auth =＃是否需要客户端身份验证（“需要”）或需要（“需要”）。需要信任商店。 server.ssl.enabled = ＃启用SSL支持。 server.ssl.enabled-protocols = ＃启用SSL协议。 server.ssl.key-alias = ＃标识密钥库中密钥的别名。 server.ssl.key-password = ＃用于访问密钥存储区中密钥的密码。 server.ssl.key-store = ＃保存SSL证书的密钥存储区的路径（通常是一个jks文件）。 server.ssl.key-store-password = ＃用于访问密钥存储区的密码。 server.ssl.key-store-provider = ＃密钥存储的提供者。 server.ssl.key-store-type = ＃密钥存储的类型。 server.ssl.protocol = ＃要使用的SL协议。 server.ssl.trust-store = ＃持有SSL证书的信任库。 server.ssl.trust-store-password = ＃用于访问信任存储的密码。 server.ssl.trust-store-provider = ＃信任存储的提供程序。 server.ssl.trust-store-type = ＃信任存储的类型。 server.tomcat.accept-count = 0 ＃所有可能的请求处理线程正在使用时传入连接请求的最大队列长度。 server.tomcat.accesslog.buffered = true ＃是否缓冲输出，使其仅定期刷新。 server.tomcat.accesslog.directory = logs ＃创建日志文件的目录。可以是绝对的或相对于Tomcat的基本目录。 server.tomcat.accesslog.enabled = false ＃启用访问日志。 server.tomcat.accesslog.file = .yyyy-MM-dd ＃放置在日志文件名中的日期格式。 server.tomcat.accesslog.pattern = common ＃访问日志的格式模式。 server.tomcat.accesslog.prefix = access_log ＃记录文件名前缀。 server.tomcat.accesslog.rename-on-rotate = false ＃是否推迟在文件名中包含日期标记，直到旋转时间。 server.tomcat.accesslog.request-attributes-enabled = false ＃为请求使用的IP地址，主机名，协议和端口设置请求属性。 server.tomcat.accesslog.rotate = true ＃是否启用访问日志循环。 server.tomcat.accesslog.suffix = .log ＃日志文件名后缀。 server.tomcat.additional-tld-skip-patterns = ＃与TLD扫描相匹配的要匹配的瓶子的逗号分隔列表。 server.tomcat.background-processor-delay = 30s ＃调用backgroundProcess方法之间的延迟。如果未指定持续时间后缀，则将使用秒。 server.tomcat.basedir = ＃Tomcat基本目录。如果未指定，则使用临时目录。 server.tomcat.internal-proxies = 10 \\\\。\\\\ d &amp;#123;1,3&amp;#125; \\\\。\\\\ d &amp;#123;1,3&amp;#125; \\\\。\\\\ d &amp;#123;1,3&amp;#125; | \\\\ 。192 \\\\ 168 \\\\ d &amp;#123;1,3&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; | \\\\ 。169 \\\\ 254 \\\\ d &amp;#123;1,3&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; | \\\\ 。127 \\\\ d &amp;#123;1,3&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; | \\\\ 172 \\\\ 1 [6-9] &amp;#123;1&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; |。。\\\\ 172 \\\\ 2 [0-9] &amp;#123;1&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; \\\\ d &amp;#123;1,3&amp;#125; |。。\\\\ 172 \\\\。3 [0-1] &amp;#123;1&amp;#125; \\\\。\\\\ d &amp;#123;1,3&amp;#125; \\\\。\\\\ d &amp;#123;1,3&amp;#125; ＃匹配可信IP地址的正则表达式。 server.tomcat.max-connections = 0 ＃服务器在任何给定时间接受和处理的最大连接数。 server.tomcat.max-http-header-size = 0 ＃HTTP消息头的最大大小（以字节为单位）。 server.tomcat.max-http-post-size = 0 ＃HTTP邮件内容的最大大小（以字节为单位）。 server.tomcat.max-threads = 0 ＃工作线程的最大数量。 server.tomcat.min-spare-threads = 0 ＃工作线程的最小数量。 server.tomcat.port-header = X-Forwarded-Port＃用于覆盖原始端口值的HTTP标头的名称。 server.tomcat.protocol-header = ＃保存传入协议的头部，通常名为“X-Forwarded-Proto”。 server.tomcat.protocol-header-https-value = https ＃协议头的值，指示传入请求是否使用SSL。 server.tomcat.redirect-context-root = ＃是否应通过将/附加到路径来重定向对上下文根的请求。 server.tomcat.remote-ip-header = ＃从中提取远程IP的HTTP头的名称。例如，“X-FORWARDED-FOR”。 server.tomcat.resource.cache-ttl = ＃静态资源缓存的生存时间。 server.tomcat.uri-encoding = UTF-8 ＃用于解码URI的字符编码。 server.tomcat.use-relative-redirects = ＃对于sendRedirect调用生成的HTTP 1.1和更高版本位置标头是否使用相对或绝对重定向。 server.undertow.accesslog.dir = ＃取消访问日志目录。 server.undertow.accesslog.enabled = false ＃是否启用访问日志。 server.undertow.accesslog.pattern = common ＃访问日志的格式模式。 server.undertow.accesslog.prefix = access_log。＃日志文件名称前缀。 server.undertow.accesslog.rotate = true＃是否启用访问日志。 server.undertow.accesslog.suffix = log＃日志文件名后缀。 server.undertow.buffer-size = ＃每个缓冲区的大小，以字节为单位。 server.undertow.direct-buffers = ＃是否在Java堆外分配缓冲区。 server.undertow.io-threads = ＃为worker创建的I / O线程数量。 server.undertow.eager-filter-init = true ＃是否应该在启动时初始化servlet过滤器。 server.undertow.max-http-post-size = 0 ＃HTTP邮件内容的最大大小（以字节为单位）。 server.undertow.worker-threads = ＃工作线程数。 #FREEMARKER（FreeMarkerProperties） spring.freemarker.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）具有相同名称的控制器生成的模型属性。 spring.freemarker.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）具有相同名称的控制器生成的模型属性。 spring.freemarker.cache = false ＃是否启用模板缓存。 spring.freemarker.charset = UTF-8 ＃模板编码。 spring.freemarker.check-template-location = true ＃是否检查模板位置是否存在。 spring.freemarker.content-type = text / html ＃Content-Type值。 spring.freemarker.enabled = true ＃是否为此技术启用MVC视图分辨率。 spring.freemarker.expose-request-attributes = false ＃在与模板合并之前是否应将所有请求属性添加到模型中。 spring.freemarker.expose-session-attributes = false ＃是否应该在与模板合并之前将所有HttpSession属性添加到模型中。 spring.freemarker.expose-spring-macro-helpers = true ＃是否公开名为“springMacroRequestContext”的Spring的宏库使用的RequestContext。 spring.freemarker.prefer-file-system-access = true ＃是否喜欢文件系统访问模板加载。文件系统访问使模板更改的热检测成为可能。 spring.freemarker.prefix = ＃构建URL时预先查看名称的前缀。 spring.freemarker.request-context-attribute = ＃所有视图的RequestContext属性的名称。 spring.freemarker.settings.* = ＃众所周知的传递给FreeMarker配置的FreeMarker密钥。 spring.freemarker.suffix = .ftl ＃在构建URL时附加到查看名称的后缀。 spring.freemarker.template-loader-path = classpath：/ templates /＃逗号分隔的模板路径列表。 spring.freemarker.view-names = ＃可以解析的视图名称的白名单。 ＃GROOVY TEMPLATES（GroovyTemplateProperties） spring.groovy.template.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）具有相同名称的控制器生成的模型属性。 spring.groovy.template.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）具有相同名称的控制器生成的模型属性。 spring.groovy.template.cache = false ＃是否启用模板缓存。 spring.groovy.template.charset = UTF-8 ＃模板编码。 spring.groovy.template.check-template-location = true＃是否检查模板位置是否存在。 spring.groovy.template.configuration。* = ＃请参阅GroovyMarkupConfigurer spring.groovy.template.content-type = text / html ＃Content-Type值。 spring.groovy.template.enabled = true ＃是否为此技术启用MVC视图分辨率。 spring.groovy.template.expose-request-attributes = false ＃在与模板合并之前是否应将所有请求属性添加到模型中。 spring.groovy.template.expose-session-attributes = false ＃是否应该在与模板合并之前将所有HttpSession属性添加到模型中。 spring.groovy.template.expose-spring-macro-helpers = true ＃是否公开名为“springMacroRequestContext”的Spring的宏库使用的RequestContext。 spring.groovy.template.prefix = ＃构建URL时预先查看名称的前缀。 spring.groovy.template.request-context-attribute = ＃所有视图的RequestContext属性的名称。 spring.groovy.template.resource-loader-path = classpath：/ templates / ＃模板路径。 spring.groovy.template.suffix = .tpl ＃在构建URL时被附加到视图名称后缀。 spring.groovy.template.view-names =＃可以解析的视图名称的白名单。 ＃SPRING HATEOAS（HateoasProperties） spring.hateoas.use-hal-as-default-json-media-type = true ＃应用程序/ hal + json响应是否应发送到接受application / json的请求。 ＃HTTP 消息转换spring.http.converters.preferred-json-mapper = ＃用于HTTP消息转换的首选JSON映射器。默认情况下，根据环境自动检测。 ＃HTTP 编码（HttpEncodingProperties） spring.http.encoding.charset = UTF-8 ＃HTTP请求和响应的字符集。如果未明确设置，则添加到“Content-Type”标题中。 spring.http.encoding.enabled = true ＃是否启用http编码支持。 spring.http.encoding.force = ＃是否强制编码到HTTP请求和响应的配置字符集。 spring.http.encoding.force-request = ＃是否强制编码到HTTP请求上配置的字符集。未指定“强制”时默认为true。 spring.http.encoding.force-response =＃是否强制编码到HTTP响应上配置的字符集。 spring.http.encoding.mapping = ＃映射的编码区域。 ＃MULTIPART （MultipartProperties） spring.servlet.multipart.enabled = true ＃是否启用对分段上传的支持。 spring.servlet.multipart.file-size-threshold = 0 ＃文件写入磁盘后的阈值。值可以使用后缀“MB”或“KB”分别表示兆字节或千字节。 spring.servlet.multipart.location = ＃上传文件的中间位置。 spring.servlet.multipart.max-file-size = 1MB ＃最大文件大小。值可以使用后缀“MB”或“KB”分别表示兆字节或千字节。 spring.servlet.multipart.max-request-size = 10MB＃最大请求大小。值可以使用后缀“MB”或“KB”分别表示兆字节或千字节。 spring.servlet.multipart.resolve-lazily = false ＃是否在文件或参数访问时懒惰地解析多部分请求。 ＃JACKSON （JacksonProperties） spring.jackson.date-format = ＃日期格式字符串或完全合格的日期格式类名称。例如，`yyyy-MM-dd HH：mm：ss`。 spring.jackson.default-property-inclusion = ＃在序列化过程中控制属性的包含。使用Jackson的JsonInclude.Include枚举中的一个值进行配置。 spring.jackson.deserialization.* = ＃杰克逊开/关功能，影响Java对象反序列化的方式。 spring.jackson.generator.* = ＃生成器的Jackson开/关功能。 spring.jackson.joda-date-time-format =＃乔达日期时间格式字符串。如果未配置，如果使用格式字符串配置“date-format”作为后备。 spring.jackson.locale = ＃用于格式化的区域设置。 spring.jackson.mapper。* = ＃杰克逊通用开/关功能。 spring.jackson.parser。* = ＃解析器的Jackson开/关功能。 spring.jackson.property-naming-strategy = ＃Jackson的PropertyNamingStrategy上的常量之一。也可以是PropertyNamingStrategy子类的完全限定类名。 spring.jackson.serialization.* = ＃杰克逊开/关功能，影响Java对象序列化的方式。 spring.jackson.time-zone =＃格式化日期时使用的时区。例如“America / Los_Angeles”或“GMT + 10”。 ＃GSON（GsonProperties） spring.gson.date-format = ＃在序列化Date对象时使用的格式。 spring.gson.disable-html-escaping = ＃是否禁用HTML字符的转义，例如'&lt;'，'>'等 spring.gson.disable-inner-class-serialization = ＃是否在排除内部类序列化。 spring.gson.enable-complex-map-key-serialization = ＃是否启用复杂映射键的序列化（即非基元化）。 spring.gson.exclude-fields-without-expose-annotation = ＃是否将所有字段排除在没有“Expose”注释的序列化或反序列化考虑之上。 spring.gson.field-naming-policy = ＃在序列化和反序列化过程中应该应用于对象字段的命名策略。 spring.gson.generate-non-executable-json = ＃是否通过在输出前添加一些特殊文本来生成不可执行的JSON。 spring.gson.lenient = ＃是否对分析不符合RFC 4627的JSON宽容 spring.gson.long-serialization-policy = ＃长和长类型的序列化策略。 spring.gson.pretty-printing = ＃是否输出适合漂亮打印的页面的序列化JSON。 spring.gson.serialize-nulls = ＃是否序列化空字段。 ＃JERSEY （JerseyProperties） spring.jersey.application-path = ＃作为应用程序的基本URI的路径。如果指定，则覆盖“@ApplicationPath”的值。 spring.jersey.filter.order = 0 ＃Jersey过滤器链顺序。 spring.jersey.init.* = ＃通过servlet或过滤器传递给Jersey的初始化参数。 spring.jersey.servlet.load-on-startup = -1 ＃加载泽西岛servlet的启动优先级。 spring.jersey.type = servlet ＃Jersey集成类型。 ＃SPRING LDAP（LdapProperties） spring.ldap.anonymous-read-only = false ＃只读操作是否应使用匿名环境。 spring.ldap.base = ＃所有操作应从其发起的基本后缀。 spring.ldap.base-environment.* = ＃LDAP规范设置。 spring.ldap.password = ＃登录服务器的密码。 spring.ldap.urls = ＃服务器的LDAP URL。 spring.ldap.username = ＃登录服务器的用户名。 ＃EMBEDDED LDAP（EmbeddedLdapProperties） spring.ldap.embedded.base-dn = ＃基本DN的列表。 spring.ldap.embedded.credential.username = ＃嵌入式LDAP用户名。 spring.ldap.embedded.credential.password = ＃嵌入式LDAP密码。 spring.ldap.embedded.ldif = classpath：schema.ldif ＃Schema（LDIF）脚本资源引用。 spring.ldap.embedded.port = 0 ＃嵌入式LDAP端口。 spring.ldap.embedded.validation.enabled = true ＃是否启用LDAP模式验证。 spring.ldap.embedded.validation.schema = ＃自定义模式的路径。 #MUSTACHE TEMPLATES（MustacheAutoConfiguration） spring.mustache.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）同名控制器生成的模型属性。 spring.mustache.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）控制器生成的具有相同名称的模型属性。 spring.mustache.cache = false ＃是否启用模板缓存。 spring.mustache.charset = UTF-8 ＃模板编码。 spring.mustache.check-template-location = true ＃是否检查模板位置是否存在。 spring.mustache.content-type = text / html ＃Content-Type值。 spring.mustache.enabled = true ＃是否为此技术启用MVC视图分辨率。 spring.mustache.expose-request-attributes = false ＃是否所有的请求属性都应该在与模板合并之前添加到模型中。 spring.mustache.expose-session-attributes = false ＃是否应该在与模板合并之前将所有HttpSession属性添加到模型中。 spring.mustache.expose-spring-macro-helpers = true ＃是否公开名为“springMacroRequestContext”的Spring的宏库使用的RequestContext。 spring.mustache.prefix= classpath：/ templates / ＃应用于模板名称的前缀。 spring.mustache.request-context-attribute = ＃所有视图的RequestContext属性的名称。 spring.mustache.suffix = .mustache ＃适用于模板名称的后缀。 spring.mustache.view-names = ＃可以解析的视图名称的白名单。 ＃SPRING MVC（WebMvcProperties） spring.mvc.async.request-timeout = ＃异步请求处理超时前的时间量。 spring.mvc.contentnegotiation.favor-parameter = false ＃是否应该使用请求参数（默认为“format”）来确定请求的媒体类型。 spring.mvc.contentnegotiation.favor-path-extension = false ＃是否应该使用URL路径中的路径扩展来确定所请求的媒体类型。 spring.mvc.contentnegotiation.media-types。* = ＃将文件扩展名映射到媒体类型以进行内容协商。例如，yml到text / yaml。 spring.mvc.contentnegotiation.parameter-name =＃查询“使用参数”时使用的参数名称。 spring.mvc.date-format = ＃要使用的日期格式。例如，`dd / MM / yyyy`。 spring.mvc.dispatch-trace-request = false ＃是否将TRACE请求分派给FrameworkServlet doService方法。 spring.mvc.dispatch-options-request = true ＃是否将OPTIONS请求分派给FrameworkServlet doService方法。 spring.mvc.favicon.enabled = true ＃是否启用favicon.ico的解析。 spring.mvc.formcontent.putfilter.enabled = true ＃是否启用Spring的HttpPutFormContentFilter。 spring.mvc.ignore-default-model-on-redirect = true＃重定向场景中是否应该忽略“默认”模型的内容。 spring.mvc.locale = ＃使用的语言环境。默认情况下，此语言环境由“Accept-Language”标题覆盖。 spring.mvc.locale-resolver = accept-header ＃定义应如何解析区域设置。 spring.mvc.log-resolved-exception = false ＃是否启用由“HandlerExceptionResolver”解决的异常的警告日志记录。 spring.mvc.message-codes-resolver-format = ＃消息代码的格式化策略。例如，`PREFIX_ERROR_CODE`。 spring.mvc.pathmatch.use-registered-suffix-pattern = false＃后缀模式匹配是否仅适用于使用“spring.mvc.contentnegotiation.media-types。*”注册的扩展名。 spring.mvc.pathmatch.use-suffix-pattern = false ＃匹配模式到请求时是否使用后缀模式匹配（“。*”）。 spring.mvc.servlet.load-on-startup = -1 ＃加载调度程序servlet的启动优先级。 spring.mvc.static-path-pattern = / ** ＃用于静态资源的路径模式。 spring.mvc.throw-exception-if-no-handler-found=false ＃是否如果没有处理程序被发现处理的请求的“NoHandlerFoundException”应该被抛出。 spring.mvc.view.prefix = ＃Spring MVC视图前缀。 spring.mvc.view.suffix = ＃Spring MVC视图后缀。 ＃SPRING RESOURCES HANDLING（ResourceProperties） spring.resources.add-mappings = true ＃是否启用默认资源处理。 spring.resources.cache.cachecontrol.cache-private = ＃指示响应消息是针对单个用户的，不能由共享缓存存储。 spring.resources.cache.cachecontrol.cache-public = ＃指示任何缓存都可以存储响应。 spring.resources.cache.cachecontrol.max-age = ＃如果没有指定持续时间后缀，则应该缓存响应的最长时间，以秒为单位。 spring.resources.cache.cachecontrol.must-revalidate =＃指示一旦它变得陈旧，缓存就不能使用该响应，而不必在服务器上重新验证它。 spring.resources.cache.cachecontrol.no-cache = ＃指示只有在服务器重新验证后才能重新使用缓存的响应。 spring.resources.cache.cachecontrol.no-store = ＃表示在任何情况下都不缓存响应。 spring.resources.cache.cachecontrol.no-transform = ＃指示不应该转换响应内容的中介（缓存和其他）。 spring.resources.cache.cachecontrol.proxy-revalidate = ＃与“must-revalidate”指令的含义相同，只是它不适用于私有缓存。 spring.resources.cache.cachecontrol.s-max-age = ＃共享缓存响应应该被缓存的最大时间，如果没有指定持续时间后缀，则以秒为单位。 spring.resources.cache.cachecontrol.stale-if-error = ＃遇到错误时可以使用响应的最长时间，如果没有指定持续时间后缀，则以秒为单位。 spring.resources.cache.cachecontrol.stale-while-revalidate = ＃如果未指定持续时间后缀，则可以在响应失效后的最长响应时间（以秒为单位）。 spring.resources.cache.period = ＃资源处理程序服务的资源的缓存期。如果未指定持续时间后缀，则将使用秒。 spring.resources.chain.cache= true ＃是否在资源链中启用缓存。 spring.resources.chain.enabled = ＃是否启用Spring资源处理链。默认情况下，除非至少有一个策略已启用，否则禁用。 spring.resources.chain.gzipped = false ＃是否启用已解压缩资源的解析。 spring.resources.chain.html-application-cache = false ＃是否启用HTML5应用程序缓存清单重写。 spring.resources.chain.strategy.content.enabled = false ＃是否启用内容版本策略。 spring.resources.chain.strategy.content.paths = / **＃应用于内容版本策略的逗号分隔模式列表。 spring.resources.chain.strategy.fixed.enabled = false ＃是否启用固定版本策略。 spring.resources.chain.strategy.fixed.paths = / ** ＃用逗号分隔的模式列表应用于固定版本策略。 spring.resources.chain.strategy.fixed.version = ＃用于固定版本策略的版本字符串。 spring.resources.static-locations = classpath：/ META-INF / resources /，classpath：/ resources /，classpath：/ static /，classpath：/ public / ＃静态资源的位置。 ＃SPRING SESSION（SessionProperties） spring.session.store-type = ＃会话存储类型。 spring.session.servlet.filter-order = -2147483598 ＃会话存储库过滤器顺序。 spring.session.servlet.filter-dispatcher-types = async，error，request ＃会话存储库过滤器调度程序类型。 ＃SPRING SESSION HAZELCAST（HazelcastSessionProperties） spring.session.hazelcast.flush-mode = on-save ＃会话刷新模式。 spring.session.hazelcast.map-name = spring：session：sessions ＃用于存储会话的地图名称。 ＃SPRING SESSION JDBC（JdbcSessionProperties） spring.session.jdbc.cleanup-cron = 0 * * * * * ＃过期会话清理作业的Cron表达式。 spring.session.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。 spring.session.jdbc.schema = classpath：org / springframework / session / jdbc / schema- @ @ platform @@ .sql ＃用于初始化数据库模式的SQL文件的路径。 spring.session.jdbc.table-name = SPRING_SESSION ＃用于存储会话的数据库表的名称。 ＃SPRING SESSION MONGODB（MongoSessionProperties） spring.session.mongodb.collection-name = sessions ＃用于存储会话的集合名称。 ＃SPRING SESSION REDIS（RedisSessionProperties） spring.session.redis.cleanup-cron = 0 * * * * * ＃过期会话清理作业的Cron表达式。 spring.session.redis.flush-mode = on-save ＃会话刷新模式。 spring.session.redis.namespace = spring：session ＃用于存储会话的密钥的命名空间。 ＃THYMELEAF（ThymeleafAutoConfiguration） spring.thymeleaf.cache = true ＃是否启用模板缓存。 spring.thymeleaf.check-template = true ＃是否在渲染之前检查模板是否存在。 spring.thymeleaf.check-template-location = true ＃是否检查模板位置是否存在。 spring.thymeleaf.enabled = true ＃是否为Web框架启用Thymeleaf视图分辨率。 spring.thymeleaf.enable-spring-el-compiler = false ＃在SpringEL表达式中启用SpringEL编译器。 spring.thymeleaf.encoding = UTF-8 ＃模板文件编码。 spring.thymeleaf.excluded-view-names = ＃应该从分辨率中排除的逗号分隔的视图名称列表（允许的模式）。 spring.thymeleaf.mode = HTML ＃应用于模板的模板模式。另请参阅Thymeleaf的TemplateMode枚举。 spring.thymeleaf.prefix = classpath：/ templates / ＃构建URL时预先查看名称的前缀。 spring.thymeleaf.reactive.chunked-mode-view-names = ＃逗号分隔的视图名称列表（允许的模式），当设置最大块大小时，应该是CHUNKED模式中唯一执行的视图名称列表。 spring.thymeleaf.reactive.full-mode-view-names =＃即使设置了最大块大小，也应该在FULL模式下执行逗号分隔的视图名称列表（允许的模式）。 spring.thymeleaf.reactive.max-chunk-size = 0 ＃用于写入响应的数据缓冲区的最大大小（以字节为单位）。 spring.thymeleaf.reactive.media-types = ＃视图技术支持的媒体类型。 spring.thymeleaf.servlet.content-type = text / html ＃写入HTTP响应的Content-Type值。 spring.thymeleaf.suffix = .html ＃在构建URL时附加到视图名称的后缀。 spring.thymeleaf.template-resolver-order = ＃链中模板解析器的顺序。 spring.thymeleaf.view-names= ＃可以解析的逗号分隔的视图名称列表（允许的模式）。 ＃SPRING WEBFLUX（WebFluxProperties） spring.webflux.date-format = ＃要使用的日期格式。例如，`dd / MM / yyyy`。 spring.webflux.static-path-pattern = / ** ＃用于静态资源的路径模式。 #SPRING WEB SERVICES（WebServicesProperties） spring.webservices.path = / services ＃作为服务基础URI的路径。 spring.webservices.servlet.init = ＃传递给Spring Web Services的Servlet初始化参数。 spring.webservices.servlet.load-on-startup = -1 ＃加载Spring Web Services servlet的启动优先级。 spring.webservices.wsdl-locations = ＃以逗号分隔的WSDL位置以及随附的XSD将作为bean公开的位置列表。 ＃---------------------------------------- ＃SECURITY PROPERTIES ＃----- ----------------------------------- ＃SECURITY（SecurityProperties） spring.security.filter.order = -100 ＃安全过滤器链顺序。 spring.security.filter.dispatcher-types = async，error，request ＃安全性筛选器链调度程序类型。 spring.security.user.name = user ＃默认用户名。 spring.security.user.password = ＃默认用户名的密码。 spring.security.user.roles = ＃授予默认用户名的角色。 ＃SECURITY OAUTH2客户端（OAuth2ClientProperties） spring.security.oauth2.client.provider。* = ＃OAuth提供程序详细信息。 spring.security.oauth2.client.registration。* = ＃OAuth客户端注册。 ＃---------------------------------------- ＃DATA PROPERTIES ＃----- ----------------------------------- ＃FLYWAY （FlywayProperties） spring.flyway.baseline-description = ＃ spring.flyway.baseline-on-migrate = ＃ spring.flyway.baseline-version = 1 ＃开始迁移的版本 spring.flyway.check-location = true ＃是否检查是否存在迁移脚本位置。 spring.flyway.clean禁用 = ＃ spring.flyway.clean上验证错误 = ＃ spring.flyway.dry -运行-输出 = ＃ spring.flyway.enabled =真＃是否启用迁徙路线。 spring.flyway.encoding = ＃ spring.flyway.error-handlers = ＃ spring.flyway.group = ＃ spring.flyway.ignore-future-migrations = ＃ spring.flyway.ignore-missing-migrations = ＃ spring.flyway.init-sqls = ＃SQL语句在获得它之后立即执行初始化连接。 spring.flyway.installed-by = ＃ spring.flyway.locations = classpath：db / migration ＃迁移脚本的位置。 spring.flyway.mixed = ＃ spring.flyway.out-of-order = ＃ spring.flyway.password =＃要使用Flyway创建自己的DataSource的JDBC密码。 spring.flyway.placeholder-prefix = ＃ spring.flyway.placeholder-replacement = ＃ spring.flyway.placeholder-suffix = ＃ spring.flyway.placeholders。* = ＃ spring.flyway.repeatable-sql-migration-prefix = ＃ spring .flyway.schemas = ＃要更新的模式 spring.flyway.skip-default-callbacks = ＃ spring.flyway.skip-default-resolvers = ＃ spring.flyway.sql-migration-prefix = V ＃ spring.flyway.sql-migration -separator =＃ spring.flyway.sql-migration-suffix = .sql ＃ spring.flyway.sql-migration-suffixes = ＃ spring.flyway.table = ＃ spring.flyway.target = ＃ spring.flyway.undo-sql-migration-prefix = ＃ spring.flyway.url = ＃要迁移的数据库的JDBC URL。如果未设置，则使用主要配置的数据源。 spring.flyway.user = ＃登录要迁移的数据库的用户。 spring.flyway.validate-on-migrate = ＃ ＃LIQUIBASE（LiquibaseProperties） spring.liquibase.change-log = classpath：/db/changelog/db.changelog-master.yaml＃更改日志配置路径。 spring.liquibase.check-change-log-location = true ＃是否检查更改日志位置是否存在。 spring.liquibase.contexts = ＃使用的运行时上下文的逗号分隔列表。 spring.liquibase.default-schema = ＃默认数据库模式。 spring.liquibase.drop-first = false ＃是否首先删除数据库模式。 spring.liquibase.enabled = true ＃是否启用Liquibase支持。 spring.liquibase.labels =＃使用的运行时标签的逗号分隔列表。 spring.liquibase.parameters。* = ＃更改日志参数。 spring.liquibase.password = ＃登录要迁移的数据库的密码。 spring.liquibase.rollback-file = ＃执行更新时写回滚SQL的文件。 spring.liquibase.url = ＃要迁移的数据库的JDBC URL。如果未设置，则使用主要配置的数据源。 spring.liquibase.user = ＃登录要迁移的数据库的用户。 ＃COUCHBASE（CouchbaseProperties） spring.couchbase.bootstrap-hosts = ＃从中引导的Couchbase节点（主机或IP地址）。 spring.couchbase.bucket.name = default ＃要连接的存储桶的名称。 spring.couchbase.bucket.password = ＃桶的密码。 spring.couchbase.env.endpoints.key-value = 1 ＃针对键/值服务的每个节点的套接字数量。 spring.couchbase.env.endpoints.queryservice.min-endpoints = 1 ＃每个节点的最小套接字数量。 spring.couchbase.env.endpoints.queryservice.max-endpoints = 1 ＃每个节点的最大套接字数量。 spring.couchbase.env.endpoints.viewservice.min-endpoints = 1 ＃每个节点的最小套接字数量。 spring.couchbase.env.endpoints.viewservice.max-endpoints = 1 ＃每个节点的最大套接字数量。 spring.couchbase.env.ssl.enabled = ＃是否启用SSL支持。除非另有规定，否则如果提供“keyStore”，则自动启用。 spring.couchbase.env.ssl.key-store = ＃持有证书的JVM密钥存储的路径。 spring.couchbase.env.ssl.key-store-password = ＃用于访问密钥存储区的密码。 spring.couchbase.env.timeouts.connect = 5000ms ＃桶连接超时。 spring.couchbase.env.timeouts.key-value = 2500ms ＃在特定的按键超时上执行阻塞操作。 spring.couchbase.env.timeouts.query = 7500ms ＃N1QL查询操作超时。 spring.couchbase.env.timeouts.socket-connect = 1000ms ＃套接字连接超时。 spring.couchbase.env.timeouts.view = 7500ms ＃定期和地理空间视图操作超时。 ＃DAO （PersistenceExceptionTranslationAutoConfiguration） spring.dao.exceptiontranslation.enabled = true ＃是否启用PersistenceExceptionTranslationPostProcessor。 ＃CASSANDRA （CassandraProperties） spring.data.cassandra.cluster-name = ＃Cassandra集群的名称。 spring.data.cassandra.compression = none ＃Cassandra二进制协议支持的压缩。 spring.data.cassandra.connect-timeout = ＃套接字选项：连接超时。 spring.data.cassandra.consistency-level = ＃查询一致性级别。 spring.data.cassandra.contact-points = localhost ＃集群节点地址。 spring.data.cassandra.fetch-size = ＃查询默认获取大小。 spring.data.cassandra.keyspace-name = ＃使用的Keyspace名称。 spring.data.cassandra.load-balancing-policy = ＃负载均衡策略的类名称。 spring.data.cassandra.port = ＃Cassandra服务器的端口。 spring.data.cassandra.password = ＃登录服务器的密码。 spring.data.cassandra.pool.heartbeat-interval = 30s ＃心跳间隔后，在空闲连接上发送消息以确保其仍处于活动状态。如果未指定持续时间后缀，则将使用秒。 spring.data.cassandra.pool.idle-timeout = 120s ＃空闲连接被移除前的空闲超时。如果未指定持续时间后缀，则将使用秒。 spring.data.cassandra.pool.max-queue-size = 256＃如果没有连接可用，请求排队的最大请求数。 spring.data.cassandra.pool.pool-timeout = 5000ms ＃尝试从主机池获取连接时的池超时。 spring.data.cassandra.read-timeout = ＃套接字选项：读取超时。 spring.data.cassandra.reconnection-policy = ＃重新连接策略类。 spring.data.cassandra.repositories.type = auto ＃启用Cassandra存储库的类型。 spring.data.cassandra.retry-policy = ＃重试策略的类名称。 spring.data.cassandra.serial-consistency-level = ＃查询串行一致性级别。 spring.data.cassandra.schema-action = none ＃在启动时采取的模式操作。 spring.data.cassandra.ssl = false ＃启用SSL支持。 spring.data.cassandra.username = ＃服务器的登录用户。 ＃DATA COUCHBASE（CouchbaseDataProperties） spring.data.couchbase.auto-index = false ＃自动创建视图和索引。 spring.data.couchbase.consistency = read-your-own-writes ＃在生成的查询中默认应用的一致性。 spring.data.couchbase.repositories.type = auto ＃启用的Couchbase存储库的类型。 ＃ELASTICSEARCH（ElasticsearchProperties） spring.data.elasticsearch.cluster-name = elasticsearch ＃Elasticsearch集群名称。 spring.data.elasticsearch.cluster-nodes = ＃以逗号分隔的集群节点地址列表。 spring.data.elasticsearch.properties。* = ＃用于配置客户端的其他属性。 spring.data.elasticsearch.repositories.enabled = true ＃是否启用Elasticsearch存储库。 ＃DATA LDAP spring.data.ldap.repositories.enabled = true ＃是否启用LDAP存储库。 ＃MONGODB（MongoProperties） spring.data.mongodb.authentication-database = ＃认证数据库名称。 spring.data.mongodb.database = ＃数据库名称。 spring.data.mongodb.field-naming-strategy = ＃要使用的FieldNamingStrategy的完全限定名称。 spring.data.mongodb.grid-fs-database = ＃GridFS数据库名称。 spring.data.mongodb.host = ＃Mongo服务器主机。不能使用URI进行设置。 spring.data.mongodb.password = ＃登录mongo服务器的密码。不能使用URI进行设置。 spring.data.mongodb.port = ＃Mongo服务器端口。不能使用URI进行设置。 spring.data.mongodb.repositories.type = auto ＃启用Mongo存储库的类型。 spring.data.mongodb.uri = mongodb：// localhost / test ＃Mongo数据库URI。无法使用主机，端口和凭证进行设置。 spring.data.mongodb.username = ＃mongo服务器的登录用户。不能使用URI进行设置。 ＃DATA REDIS spring.data.redis.repositories.enabled = true ＃是否启用Redis存储库。 ＃NEO4J（Neo4jProperties） spring.data.neo4j.auto-index = none ＃自动索引模式。 spring.data.neo4j.embedded.enabled = true ＃是否在嵌入式驱动程序可用时启用嵌入式模式。 spring.data.neo4j.open-in-view = true ＃注册OpenSessionInViewInterceptor。将Neo4j会话绑定到线程，以完成请求的整个处理。 spring.data.neo4j.password = ＃登录服务器的密码。 spring.data.neo4j.repositories.enabled = true ＃是否启用Neo4j存储库。 spring.data.neo4j.uri = 驱动程序使用的＃URI 。自动检测默认。 spring.data.neo4j.username = ＃服务器的登录用户。 ＃DATA REST（RepositoryRestProperties） spring.data.rest.base-path = ＃Spring Data REST用于公开资源库资源的基础路径。 spring.data.rest.default-media-type = ＃当没有指定任何内容时，默认使用的内容类型。 spring.data.rest.default-page-size = ＃页面的默认大小。 spring.data.rest.detection-strategy = default ＃用于确定哪些存储库暴露的策略。 spring.data.rest.enable-enum-translation = ＃是否通过Spring Data REST默认资源包启用枚举值转换。 spring.data.rest.limit-param-name =＃URL查询字符串参数的名称，指示一次返回多少个结果。 spring.data.rest.max-page-size = ＃页面的最大尺寸。 spring.data.rest.page-param-name = ＃指示要返回哪个页面的URL查询字符串参数的名称。 spring.data.rest.return-body-on-create = ＃是否在创建实体后返回响应主体。 spring.data.rest.return-body-on-update = ＃是否在更新实体后返回响应主体。 spring.data.rest.sort-param-name = ＃URL查询字符串参数的名称，指示对结果进行排序的方向。 ＃SOLR （SolrProperties） spring.data.solr.host = http：//127.0.0.1：8983 / solr ＃Solr主机。如果设置了“zk-host”，则忽略。 spring.data.solr.repositories.enabled = true ＃是否启用Solr存储库。 spring.data.solr.zk-host = ＃HOST：PORT形式的＃ZooKeeper 主机地址。 ＃DATA WEB（SpringDataWebProperties） spring.data.web.pageable.default页大小 = 20 ＃缺省页大小。 spring.data.web.pageable.max-page-size = 2000 ＃要接受的最大页面大小。 spring.data.web.pageable.one-indexed-parameters = false ＃是否公开并假设基于1的页码索引。 spring.data.web.pageable.page-parameter = page ＃页面索引参数名称。 spring.data.web.pageable.prefix = ＃页面编号和页面大小参数前面的一般前缀。 spring.data.web.pageable.qualifier-delimiter = _＃限定符与实际页码和大小属性之间使用的分隔符。 spring.data.web.pageable.size-parameter = size ＃页面大小参数名称。 spring.data.web.sort.sort-parameter = sort ＃排序参数名称。 ＃DATASOURCE （DataSourceAutoConfiguration＆DataSourceProperties） spring.datasource.continue-on-error = false ＃是否在初始化数据库时发生错误时停止。 spring.datasource.data = ＃数据（DML）脚本资源引用。 spring.datasource.data-username = ＃执行DML脚本的数据库的用户名（如果不同）。 spring.datasource.data-password = ＃执行DML脚本的数据库的密码（如果不同）。 spring.datasource.dbcp2.* = ＃Commons DBCP2特定设置 spring.datasource.driver-class-name =＃JDBC驱动程序的完全限定名称。默认情况下基于URL自动检测。 spring.datasource.generate-unique-name = false ＃是否生成随机数据源名称。 spring.datasource.hikari.* = ＃Hikari特定设置 spring.datasource.initialization-mode = embedded ＃使用可用的DDL和DML脚本初始化数据源。 spring.datasource.jmx-enabled = false ＃是否启用JMX支持（如果由底层池提供）。 spring.datasource.jndi-name = ＃数据源的JNDI位置。设置时会忽略类，网址，用户名和密码。 spring.datasource.name =＃数据源的名称。使用嵌入式数据库时，默认为“testdb”。 spring.datasource.password = ＃登录数据库的密码。 spring.datasource.platform = all ＃在DDL或DML脚本中使用的平台（例如schema - $ &amp;#123;platform&amp;#125; .sql或data - $ &amp;#123;platform&amp;#125; .sql）。 spring.datasource.schema = ＃架构（DDL）脚本资源引用。 spring.datasource.schema-username = ＃执行DDL脚本的数据库的用户名（如果不同）。 spring.datasource.schema-password = ＃执行DDL脚本的数据库的密码（如果不同）。 spring.datasource.separator =;＃SQL初始化脚本中的语句分隔符。 spring.datasource.sql-script-encoding = ＃SQL脚本编码。 spring.datasource.tomcat.* = ＃Tomcat数据源特定设置 spring.datasource.type = ＃要使用的连接池实现的完全限定名称。默认情况下，它是从类路径中自动检测的。 spring.datasource.url = ＃数据库的JDBC URL。 spring.datasource.username = ＃登录数据库的用户名。 spring.datasource.xa.data-source-class-name = ＃XA数据源完全限定名称。 spring.datasource.xa.properties =＃传递给XA数据源的属性。 ＃JEST （Elasticsearch HTTP客户端）（JestProperties） spring.elasticsearch.jest.connection-timeout = 3s ＃连接超时。 spring.elasticsearch.jest.multi-threaded = true ＃是否启用来自多个执行线程的连接请求。 spring.elasticsearch.jest.password = ＃登录密码。 spring.elasticsearch.jest.proxy.host = ＃HTTP客户端应该使用的代理主机。 spring.elasticsearch.jest.proxy.port = ＃HTTP客户端应该使用的代理端口。 spring.elasticsearch.jest.read-timeout = 3s ＃读取超时。 spring.elasticsearch.jest.uris = http：// localhost：9200＃要使用的Elasticsearch实例的逗号分隔列表。 spring.elasticsearch.jest.username = ＃登录用户名。 ＃H2 Web控制台（H2ConsoleProperties） spring.h2.console.enabled = false ＃是否启用控制台。 spring.h2.console.path = / h2-console ＃控制台可用的路径。 spring.h2.console.settings.trace = false ＃是否启用跟踪输出。 spring.h2.console.settings.web-allow-others = false ＃是否启用远程访问。 ＃InfluxDB（InfluxDbProperties） spring.influx.password = ＃登录密码。 spring.influx.url = ＃要连接的InfluxDB实例的URL。 spring.influx.user = ＃登录用户。 ＃JOOQ （JooqProperties） spring.jooq.sql-dialect = ＃使用SQL方言。自动检测默认。 ＃JDBC （JdbcProperties） spring.jdbc.template.fetch-size = -1 ＃当需要更多行时，应从数据库中获取的行数。 spring.jdbc.template.max-rows = -1 ＃最大行数。 spring.jdbc.template.query-timeout = ＃查询超时。默认是使用JDBC驱动程序的默认配置。如果未指定持续时间后缀，则将使用秒。 ＃JPA （JpaBaseConfiguration，HibernateJpaAutoConfiguration） spring.data.jpa.repositories.enabled = true ＃是否启用JPA存储库。 spring.jpa.database = ＃目标数据库进行操作，默认为自动检测。可以使用“databasePlatform”属性进行替代设置。 spring.jpa.database-platform = ＃要运行的目标数据库的名称，默认为自动检测。也可以使用“数据库”枚举进行设置。 spring.jpa.generate-ddl = false ＃是否在启动时初始化模式。 spring.jpa.hibernate.ddl-auto =＃DDL模式。这实际上是“hibernate.hbm2ddl.auto”属性的快捷方式。当使用嵌入式数据库并且没有检测到模式管理器时，默认为“创建 - 删除”。否则，默认为“无”。 spring.jpa.hibernate.naming.implicit-strategy = ＃隐式命名策略的完全限定名称。 spring.jpa.hibernate.naming.physical-strategy = ＃物理命名策略的完全限定名称。 spring.jpa.hibernate.use-new-id-generator-mappings = ＃是否将Hibernate的新的IdentifierGenerator用于AUTO，TABLE和SEQUENCE。 spring.jpa.mapping-resources = ＃映射资源（相当于persistence.xml中的“映射文件”条目）。 spring.jpa.properties = ＃在JPA提供程序上设置的其他本机属性。 spring.jpa.show-sql = false ＃是否启用SQL语句的日志记录。 ＃JTA （JtaAutoConfiguration） spring.jta.enabled = true ＃是否启用JTA支持。 spring.jta.log-dir = ＃事务日志目录。 spring.jta.transaction-manager-id = ＃事务管理器唯一标识符。 ＃ATOMIKOS（AtomikosProperties） spring.jta.atomikos.connectionfactory.borrow-connection-timeout = 30 ＃从池中借用连接超时，以秒为单位。 spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag = true ＃创建会话时是否忽略事务处理标志。 spring.jta.atomikos.connectionfactory.local-transaction-mode = false ＃是否需要本地事务。 spring.jta.atomikos.connectionfactory.maintenance-interval = 60 ＃池的维护线程运行之间的时间，以秒为单位。 spring.jta.atomikos.connectionfactory.max-idle-time = 60＃从池中清除连接之后的时间，以秒为单位。 spring.jta.atomikos.connectionfactory.max-lifetime = 0 ＃以秒为单位的连接可以在被销毁前汇集的时间。0表示没有限制。 spring.jta.atomikos.connectionfactory.max-pool-size = 1 ＃池的最大尺寸。 spring.jta.atomikos.connectionfactory.min-pool-size = 1 ＃池的最小大小。 spring.jta.atomikos.connectionfactory.reap-timeout = 0 ＃借用连接的收获超时（以秒为单位）。0表示没有限制。 spring.jta.atomikos.connectionfactory.unique-resource-name = jmsConnectionFactory＃恢复期间用于识别资源的唯一名称。 spring.jta.atomikos.connectionfactory.xa-connection-factory-class-name = ＃供应商特定的XAConnectionFactory实现。 spring.jta.atomikos.connectionfactory.xa-properties = ＃供应商特定的XA属性。 spring.jta.atomikos.datasource.borrow-connection-timeout = 30 ＃用于从池中借用连接的超时，以秒为单位。 spring.jta.atomikos.datasource.concurrent-connection-validation = ＃是否使用并发连接验证。 spring.jta.atomikos.datasource.default-isolation-level = ＃池提供的连接的默认隔离级别。 spring.jta.atomikos.datasource.login-timeout = ＃建立数据库连接 的超时时间，以秒为单位。 spring.jta.atomikos.datasource.maintenance-interval = 60 ＃池维护线程运行之间的时间（以秒为单位）。 spring.jta.atomikos.datasource.max-idle-time = 60 ＃从池中清除连接之后的时间，以秒为单位。 spring.jta.atomikos.datasource.max-lifetime = 0 ＃以秒为单位的连接可以在被销毁前汇集的时间。0表示没有限制。 spring.jta.atomikos.datasource.max-pool-size = 1 ＃池的最大尺寸。 spring.jta.atomikos.datasource.min-pool-size = 1＃池的最小尺寸。 spring.jta.atomikos.datasource.reap-timeout = 0 ＃借用连接的收获超时（以秒为单位）。0表示没有限制。 spring.jta.atomikos.datasource.test-query = ＃返回之前用于验证连接的SQL查询或语句。 spring.jta.atomikos.datasource.unique-resource-name = dataSource ＃在恢复期间用于标识资源的唯一名称。 spring.jta.atomikos.datasource.xa-data-source-class-name = ＃供应商特定的XAConnectionFactory实现。 spring.jta.atomikos.datasource.xa-properties = ＃供应商特定的XA属性。 spring.jta.atomikos.properties.allow-sub-transactions = true ＃指定是否允许子交易。 spring.jta.atomikos.properties.checkpoint-interval = 500 ＃检查点之间的时间间隔，表示为两个检查点之间的日志写入次数。 spring.jta.atomikos.properties.default-jta-timeout = 10000ms ＃JTA事务的默认超时。 spring.jta.atomikos.properties.default-max-wait-time-on-shutdown = 9223372036854775807 ＃正常关机（无强制）等待事务完成多长时间。 spring.jta.atomikos.properties.enable-logging = true ＃是否启用磁盘日志记录。 spring.jta.atomikos.properties.force-shutdown-on-vm-exit = false ＃VM关闭是否应触发事务核心的强制关闭。 spring.jta.atomikos.properties.log-base-dir = ＃应该存储日志文件的目录。 spring.jta.atomikos.properties.log -base -name = tmlog ＃事务日志文件的基本名称。 spring.jta.atomikos.properties.max-actives = 50 ＃活动事务的最大数量。 spring.jta.atomikos.properties.max-timeout = 300000ms ＃交易允许的最大超时时间。 spring.jta.atomikos.properties.recovery.delay = 10000ms ＃两次恢复扫描之间的延迟。 spring.jta.atomikos.properties.recovery.forget- orphaned -log-entries-delay = 86400000ms ＃延迟后恢复可以清除挂起（'孤立'）日志条目。 spring.jta.atomikos.properties.recovery.max-retries = 5 ＃抛出异常之前尝试提交事务的重试次数。 spring.jta.atomikos.properties.recovery.retry-interval = 10000ms ＃重试尝试之间的延迟。 spring.jta.atomikos.properties.serial-jta-transactions = true ＃是否应该在可能的情况下连接子事务。 spring.jta.atomikos.properties.service = ＃应该启动的事务管理器实现。 spring.jta.atomikos.properties.threaded-two-phase-commit = false ＃是否在参与资源上使用不同（并发）的线程进行两阶段提交。 spring.jta.atomikos.properties.transaction-manager-unique-name = ＃事务管理器的唯一名称。 ＃BITRONIX spring.jta.bitronix.connectionfactory.acquire-increment = 1 ＃增长池时创建的连接数。 spring.jta.bitronix.connectionfactory.acquisition-interval = 1 ＃在获取无效连接后尝试重新获取连接之前，需要等待的时间（以秒为单位）。 spring.jta.bitronix.connectionfactory.acquisition-timeout = 30 ＃以秒为单位的超时时间，用于从池中获取连接。 spring.jta.bitronix.connectionfactory.allow-local-transactions = true ＃事务管理器是否应允许混合XA和非XA事务。 spring.jta.bitronix.connectionfactory.apply-transaction-timeout = false＃在注册时是否应该在XAResource上设置事务超时。 spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled = true ＃资源是否应该自动注册和退出。 spring.jta.bitronix.connectionfactory.cache-producer-consumers = true ＃生产者和消费者是否应该被缓存。 spring.jta.bitronix.connectionfactory.class-name = ＃XA资源的基础实现类名称。 spring.jta.bitronix.connectionfactory.defer-connection-release = true ＃提供者是否可以在同一连接上运行多个事务并支持事务交叉。 spring.jta.bitronix.connectionfactory.disabled= ＃该资源是否被禁用，意味着暂时禁止从其池中获取连接。 spring.jta.bitronix.connectionfactory.driver-properties = ＃应该在底层实现上设置的属性。 spring.jta.bitronix.connectionfactory.failed = ＃标记此资源生产者失败。 spring.jta.bitronix.connectionfactory.ignore-recovery-failures = false ＃是否应该忽略恢复失败。 spring.jta.bitronix.connectionfactory.max-idle-time = 60 ＃连接从池中清理之后的时间，以秒为单位。 spring.jta.bitronix.connectionfactory.max-pool-size = 10＃池的最大尺寸。0表示没有限制。 spring.jta.bitronix.connectionfactory.min-pool-size = 0 ＃池的最小大小。 spring.jta.bitronix.connectionfactory.password = ＃用于连接到JMS提供程序的密码。 spring.jta.bitronix.connectionfactory.share-transaction-connections = false ＃ACCESSIBLE状态下的连接是否可以在事务上下文中共享。 spring.jta.bitronix.connectionfactory.test-connections = true ＃连接是否需要从池中获取时进行测试。 spring.jta.bitronix.connectionfactory.two-pc-ordering-position = 1＃这个资源在两阶段提交期间应该采取的位置（总是首先是Integer.MIN_VALUE，总是最后是Integer.MAX_VALUE）。 spring.jta.bitronix.connectionfactory.unique-name = jmsConnectionFactory ＃在恢复期间用于标识资源的唯一名称。 spring.jta.bitronix.connectionfactory.use-tm-join = true ＃启动XAResources时是否应使用TMJOIN。 spring.jta.bitronix.connectionfactory.user = ＃用于连接到JMS提供程序的用户。 spring.jta.bitronix.datasource.acquire-increment = 1 ＃增长池时创建的连接数。 spring.jta.bitronix.datasource.acquisition-interval = 1＃以秒为单位的时间在获取无效连接后再次尝试获取连接之前等待。 spring.jta.bitronix.datasource.acquisition-timeout = 30 ＃以秒为单位超时获取池中的连接。 spring.jta.bitronix.datasource.allow-local-transactions = true ＃事务管理器是否应允许混合XA和非XA事务。 spring.jta.bitronix.datasource.apply-transaction-timeout = false ＃在注册时是否应该在XAResource上设置事务超时。 spring.jta.bitronix.datasource.automatic-enlisting-enabled = true ＃资源是否应该自动注册和除名。 spring.jta.bitronix.datasource.class-name = ＃XA资源的基础实现类名称。 spring.jta.bitronix.datasource.cursor-holdability = ＃连接的默认光标可保存性。 spring.jta.bitronix.datasource.defer-connection-release = true ＃数据库是否可以在同一连接上运行多个事务并支持事务交叉。 spring.jta.bitronix.datasource.disabled = ＃该资源是否被禁用，意味着暂时禁止从其池中获取连接。 spring.jta.bitronix.datasource.driver-properties = ＃应该在底层实现中设置的属性。 spring.jta.bitronix.datasource.enable -jdbc4-connection-test = ＃是否在从池中获取连接时调用Connection.isValid（）。 spring.jta.bitronix.datasource.failed = ＃标记此资源生产者失败。 spring.jta.bitronix.datasource.ignore-recovery-failures = false ＃是否应该忽略恢复失败。 spring.jta.bitronix.datasource.isolation-level = ＃连接的默认隔离级别。 spring.jta.bitronix.datasource.local-auto-commit = ＃本地事务的默认自动提交模式。 spring.jta.bitronix.datasource.login-timeout =＃建立数据库连接的超时时间，以秒为单位。 spring.jta.bitronix.datasource.max-idle-time = 60 ＃从池中清除连接之后的时间，以秒为单位。 spring.jta.bitronix.datasource.max-pool-size = 10 ＃池的最大尺寸。0表示没有限制。 spring.jta.bitronix.datasource.min-pool-size = 0 ＃池的最小尺寸。 spring.jta.bitronix.datasource.prepared-statement-cache-size = 0 ＃准备好的语句缓存的目标大小。0禁用缓存。 spring.jta.bitronix.datasource.share-transaction-connections = false＃ACCESSIBLE状态下的连接是否可以在事务上下文中共享。 spring.jta.bitronix.datasource.test-query = ＃返回之前用于验证连接的SQL查询或语句。 spring.jta.bitronix.datasource.two-pc-ordering-position = 1 ＃这个资源在两阶段提交期间应该采取的位置（总是首先是Integer.MIN_VALUE，并且总是最后是Integer.MAX_VALUE）。 spring.jta.bitronix.datasource.unique-name = dataSource ＃在恢复期间用于标识资源的唯一名称。 spring.jta.bitronix.datasource.use-tm-join = true ＃启动XAResources时是否应使用TMJOIN。 spring.jta.bitronix.properties.allow-multiple-lrc = false ＃是否允许多个LRC资源被列入同一事务。 spring.jta.bitronix.properties.asynchronous2-pc = false ＃是否启用两阶段落实的异步执行。 spring.jta.bitronix.properties.background-recovery-interval-seconds = 60 ＃在后台运行恢复进程的间隔秒数。 spring.jta.bitronix.properties.current-node-only-recovery = true ＃是否仅恢复当前节点。 spring.jta.bitronix.properties.debug-zero-resource-transaction = false＃是否记录创建并提交未执行单个登记资源的事务的调用堆栈。 spring.jta.bitronix.properties.default-transaction-timeout = 60 ＃默认事务超时，以秒为单位。 spring.jta.bitronix.properties.disable-jmx = false ＃是否启用JMX支持。 spring.jta.bitronix.properties.exception-analyzer = ＃设置要使用的异常分析器实现的完全限定名称。 spring.jta.bitronix.properties.filter-log-status = false ＃是否启用对日志的过滤，以便仅写入强制日志。 spring.jta.bitronix.properties.force-batching-enabled = true＃磁盘力量是否成批。 spring.jta.bitronix.properties.forced-write-enabled = true ＃日志是否被强制为磁盘。 spring.jta.bitronix.properties.graceful-shutdown-interval = 60 ＃TM在等待事务在关闭时中止之前完成的最大秒数。 spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name = ＃TransactionSynchronizationRegistry的JNDI名称。 spring.jta.bitronix.properties.jndi-user-transaction-name = ＃UserTransaction的JNDI名称。 spring.jta.bitronix.properties.journal = disk ＃日志的名称。可以是'磁盘'，'空'或类名。 spring.jta.bitronix.properties.log-part1 -filename = btm1.tlog ＃日志的第一个片段的名称。 spring.jta.bitronix.properties.log-part2-filename = btm2.tlog ＃日志的第二个片段的名称。 spring.jta.bitronix.properties.max-log-size-in-mb = 2 ＃日志片段的最大大小（以兆字节为单位）。 spring.jta.bitronix.properties.resource-configuration-filename = ＃ResourceLoader配置文件名。 spring.jta.bitronix.properties.server-id = ＃必须唯一标识此TM实例的ASCII ID。默认为机器的IP地址。 spring.jta.bitronix.properties.skip-corrupted-logs = false＃跳过损坏的事务日志条目。 spring.jta.bitronix.properties.warn-about-zero-resource-transaction = true ＃是否为未执行单个登记资源而执行的事务记录警告。 ＃NARAYANA（NarayanaProperties） spring.jta.narayana.default-timeout = 60s ＃交易超时。如果未指定持续时间后缀，则将使用秒。 spring.jta.narayana.expiry-scanners = com.arjuna.ats.internal.arjuna.recovery.ExpiredTransactionStatusManagerScanner ＃过期扫描仪的逗号分隔列表。 spring.jta.narayana.log-dir = ＃交易对象存储目录。 spring.jta.narayana.one-phase-commit = true ＃是否启用一个阶段提交优化。 spring.jta.narayana.periodic-recovery-period = 120s＃执行周期性恢复扫描的时间间隔。如果未指定持续时间后缀，则将使用秒。 spring.jta.narayana.recovery-backoff-period = 10s ＃恢复扫描的第一阶段和第二阶段之间的退避阶段。如果未指定持续时间后缀，则将使用秒。 spring.jta.narayana.recovery-db-pass = ＃恢复管理器要使用的数据库密码。 spring.jta.narayana.recovery-db-user = ＃恢复管理器使用的数据库用户名。 spring.jta.narayana.recovery-jms-pass = ＃恢复管理器要使用的JMS密码。 spring.jta.narayana.recovery-jms-user =＃恢复管理器使用的JMS用户名。 spring.jta.narayana.recovery-modules = ＃以逗号分隔的恢复模块列表。 spring.jta.narayana.transaction-manager-id = 1 ＃唯一的事务管理器ID。 spring.jta.narayana.xa-resource-orphan-filters = ＃孤立过滤器的逗号分隔列表。 ＃EMBEDDED MONGODB（EmbeddedMongoProperties） spring.mongodb.embedded.features = sync_delay ＃要启用的功能的逗号分隔列表。 spring.mongodb.embedded.storage.database-dir = ＃用于数据存储的目录。 spring.mongodb.embedded.storage.oplog-size = ＃oplog的最大大小，以兆字节为单位。 spring.mongodb.embedded.storage.repl-set-name = ＃副本集的名称。 spring.mongodb.embedded.version = 3.2.2 ＃使用Mongo版本。 ＃REDIS（RedisProperties） spring.redis.cluster.max -redirects = ＃在群集中执行命令时遵循的最大重定向数。 spring.redis.cluster.nodes = ＃以逗号分隔的“主机：端口”对列表进行引导。 spring.redis.database = 0 ＃连接工厂使用的数据库索引。 spring.redis.url = ＃连接网址。覆盖主机，端口和密码。用户被忽略。示例：redis：// user：password@example.com ：6379 spring.redis.host = localhost ＃Redis服务器主机。 spring.redis.jedis.pool.max-active = 8＃给定时间内池可以分配的最大连接数。使用负值无限制。 spring.redis.jedis.pool.max-idle = 8 ＃池中“空闲”连接的最大数量。使用负值表示无限数量的空闲连接。 spring.redis.jedis.pool.max -wait = -1ms ＃当池被耗尽时抛出异常之前连接分配应该阻塞的最大时间量。使用负值可以无限期地阻止。 spring.redis.jedis.pool.min-idle = 0 ＃目标为保持在池中的最小空闲连接数。如果该设置是肯定的，则该设置仅起作用。 spring.redis.lettuce.pool.max-active = 8＃给定时间内池可以分配的最大连接数。使用负值无限制。 spring.redis.lettuce.pool.max-idle = 8 ＃池中“空闲”连接的最大数量。使用负值表示无限数量的空闲连接。 spring.redis.lettuce.pool.max -wait = -1ms ＃连接分配在池耗尽时抛出异常之前应阻塞的最长时间量。使用负值可以无限期地阻止。 spring.redis.lettuce.pool.min-idle = 0 ＃目标为要在池中维护的最小空闲连接数。如果该设置是肯定的，则该设置仅起作用。 spring.redis.lettuce.shutdown-timeout = 100ms＃关机超时。 spring.redis.password = ＃登录redis服务器的密码。 spring.redis.port = 6379 ＃Redis服务器端口。 spring.redis.sentinel.master = ＃Redis服务器的名称。 spring.redis.sentinel.nodes = ＃“主机：端口”对的逗号分隔列表。 spring.redis.ssl = false ＃是否启用SSL支持。 spring.redis.timeout = ＃连接超时。 ＃TRANSACTION （TransactionProperties） spring.transaction.default-timeout = ＃默认事务超时。如果未指定持续时间后缀，则将使用秒。 spring.transaction.rollback-on-commit-failure = ＃是否回滚提交失败。 ＃---------------------------------------- ＃INTEGRATION PROPERTIES ＃----- ----------------------------------- ＃ACTIVEMQ（ActiveMQProperties） spring.activemq.broker-url = ＃ActiveMQ代理的URL。自动生成默认。 spring.activemq.close-timeout = 15s ＃在考虑完成之前等待的时间。 spring.activemq.in-memory = true ＃默认代理URL是否应该在内存中。如果指定了明确的代理，则忽略。 spring.activemq.non-blocking-redelivery = false ＃是否在重新传递回退事务中的消息之前停止消息传递。这意味着启用此功能时不会保留消息顺序。 spring.activemq.password = ＃登录经纪人的密码。 spring.activemq.send-timeout = 0ms ＃等待响应消息发送的时间。将其设置为0以永久等待。 spring.activemq.user = ＃代理的登录用户。 spring.activemq.packages.trust-all = ＃是否信任所有包。 spring.activemq.packages.trusted = ＃以逗号分隔的特定软件包列表（不信任所有软件包）。 spring.activemq.pool.block-if-full = true ＃是否阻止请求连接并且池已满。将其设置为false以代替引发“JMSException”。 spring.activemq.pool.block-if-full-timeout = -1ms＃如果池仍然已满，则在抛出异常之前阻塞期。 spring.activemq.pool.create-connection-on-startup = true ＃是否在启动时创建连接。可用于在启动时预热池。 spring.activemq.pool.enabled = false ＃是否应该创建PooledConnectionFactory，而不是常规的ConnectionFactory。 spring.activemq.pool.expiry-timeout = 0ms ＃连接到期超时。 spring.activemq.pool.idle-timeout = 30s ＃连接空闲超时。 spring.activemq.pool.max-connections = 1 ＃共享连接的最大数量。 spring.activemq.pool.maximum-active-session-per-connection = 500＃每个连接的最大活动会话数。 spring.activemq.pool.reconnect-on-exception = true ＃发生“JMSException”时重置连接。 spring.activemq.pool.time-between-expiration-check = -1ms ＃空闲连接驱逐线程运行之间的休眠时间。否定时，不会有空闲连接逐出线程运行。 spring.activemq.pool.use-anonymous-producers = true ＃是否只使用一个匿名的“MessageProducer”实例。将其设置为false以在每次需要时创建一个“MessageProducer”。 ＃ARTEMIS （ArtemisProperties） spring.artemis.embedded.cluster-password = ＃集群密码。默认情况下在启动时随机生成。 spring.artemis.embedded.data-directory = ＃日记文件目录。如果关闭持久性，则不需要。 spring.artemis.embedded.enabled = true ＃是否在Artemis服务器API可用时启用嵌入模式。 spring.artemis.embedded.persistent = false ＃是否启用持久存储。 spring.artemis.embedded.queues = ＃在启动时创建的逗号分隔列表。 spring.artemis.embedded.server-id =＃服务器ID。默认情况下，使用自动递增的计数器。 spring.artemis.embedded.topics = ＃启动时要创建的主题的逗号分隔列表。 spring.artemis.host = localhost ＃阿蒂米斯经纪人主机。 spring.artemis.mode = ＃Artemis部署模式，默认为自动检测。 spring.artemis.password = ＃代理的登录密码。 spring.artemis.port = 61616 ＃阿蒂米斯经纪人港口。 spring.artemis.user = ＃代理的登录用户。 ＃SPRING BATCH（BatchProperties） spring.batch.initialize-schema = embedded ＃数据库模式初始化模式。 spring.batch.job.enabled = true ＃启动时执行上下文中的所有Spring批处理作业。 spring.batch.job.names = ＃逗号分隔的启动时要执行的作业名称列表（例如`job1，job2`）。默认情况下，执行在上下文中找到的所有作业。 spring.batch.schema = classpath：org / springframework / batch / core / schema- @ @ platform @@ .sql ＃用于初始化数据库模式的SQL文件的路径。 spring.batch.table-prefix =＃所有批量元数据表的表格前缀。 #SPRING INTEGRATION（IntegrationProperties） spring.integration.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。 spring.integration.jdbc.schema = classpath中：组织/ springframework的/集成/ JDBC / schema- @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。 ＃JMS （JmsProperties） spring.jms.jndi-name = ＃连接工厂的JNDI名称。设置时，优先于其他连接工厂自动配置。 spring.jms.listener.acknowledge-mode = ＃容器的确认模式。默认情况下，侦听器通过自动确认进行事务处理。 spring.jms.listener.auto-startup = true ＃启动时自动启动容器。 spring.jms.listener.concurrency = ＃最小并发消费者数量。 spring.jms.listener.max-concurrency = ＃最大并发消费者数量。 spring.jms.pub-sub-domain = false＃默认目标类型是否为主题。 spring.jms.template.default-destination = ＃在没有目标参数的发送和接收操作上使用的默认目标。 spring.jms.template.delivery-delay = ＃发送延迟用于发送呼叫。 spring.jms.template.delivery-mode = ＃传送模式。设置时启用QoS（服务质量）。 spring.jms.template.priority = ＃发送时的消息优先级。设置时启用QoS（服务质量）。 spring.jms.template.qos-enabled = ＃发送消息时是否启用显式QoS（服务质量）。 spring.jms.template.receive-timeout =＃超时使用接收电话。 spring.jms.template.time-to-live = ＃发送消息时的生存时间。设置时启用QoS（服务质量）。 ＃APACHE KAFKA（KafkaProperties） spring.kafka.admin.client-id = ＃发送请求时传递给服务器的ID。用于服务器端日志记录。 spring.kafka.admin.fail-fast = false ＃如果代理在启动时不可用，是否快速失败。 spring.kafka.admin.properties。* = ＃用于配置客户端的其他特定于管理员的属性。 spring.kafka.admin.ssl.key-password = ＃密钥存储文件中的私钥密码。 spring.kafka.admin.ssl.keystore-location = ＃密钥存储文件的位置。 spring.kafka.admin.ssl.keystore-password =＃存储密钥存储文件的密码。 spring.kafka.admin.ssl.truststore-location = ＃信任存储文件的位置。 spring.kafka.admin.ssl.truststore-password = ＃存储信任存储文件的密码。 spring.kafka.bootstrap-servers = ＃主机：端口对的逗号分隔列表，用于建立到Kafka集群的初始连接。 spring.kafka.client-id = ＃发送请求时传递给服务器的ID。用于服务器端日志记录。 spring.kafka.consumer.auto-commit-interval = ＃如果'enable.auto.commit'设置为true，则消费者偏移自动提交给Kafka的频率。 spring.kafka.consumer.auto-offset-reset = ＃在Kafka中没有初始偏移量或当前偏移量不再存在于服务器上时该做什么。 spring.kafka.consumer.bootstrap-servers = ＃主机：端口对的逗号分隔列表，用于建立与Kafka集群的初始连接。 spring.kafka.consumer.client-id = ＃在发出请求时传递给服务器的ID。用于服务器端日志记录。 spring.kafka.consumer.enable-auto-commit = ＃用户的偏移是否在后台定期提交。 spring.kafka.consumer.fetch-max-wait =＃如果没有足够的数据立即满足“fetch.min.bytes”给出的要求，服务器在应答提取请求之前阻塞的最大时间量。 spring.kafka.consumer.fetch-min-size = ＃服务器为获取请求返回的最小数据量（以字节为单位）。 spring.kafka.consumer.group-id = ＃标识此用户所属的用户组的唯一字符串。 spring.kafka.consumer.heartbeat-interval = ＃心跳到消费者协调员之间的预期时间。 spring.kafka.consumer.key-deserializer = ＃反序列化程序类。 spring.kafka.consumer.max-poll-records =＃在一次调用poll（）中返回的最大记录数。 spring.kafka.consumer.properties。* = ＃用于配置客户端的其他消费者特定属性。 spring.kafka.consumer.ssl.key-password = ＃密钥存储文件中的私钥密码。 spring.kafka.consumer.ssl.keystore-location = ＃密钥存储文件的位置。 spring.kafka.consumer.ssl.keystore-password = ＃存储密钥存储文件的密码。 spring.kafka.consumer.ssl.truststore-location = ＃信任存储文件的位置。 spring.kafka.consumer.ssl.truststore-password = ＃存储信任存储文件的密码。 spring.kafka.consumer.value-deserializer = ＃解码器类的值。 spring.kafka.jaas.control-flag = required ＃登录配置的控制标志。 spring.kafka.jaas.enabled = false ＃是否启用JAAS配置。 spring.kafka.jaas.login-module = com.sun.security.auth.module.Krb5LoginModule ＃登录模块。 spring.kafka.jaas.options = ＃其他JAAS选项。 spring.kafka.listener.ack-count = ＃当ackMode为“COUNT”或“COUNT_TIME”时，偏移量之间的记录数。 spring.kafka.listener.ack-mode = ＃Listener AckMode。请参阅spring-kafka文档。 spring.kafka.listener.ack-time = ＃当ackMode为“TIME”或“COUNT_TIME”时，偏移提交之间的时间。 spring.kafka.listener.client-id = ＃监听器的消费者client.id属性的前缀。 spring.kafka.listener.concurrency = ＃在侦听器容器中运行的线程数。 spring.kafka.listener.idle-event-interval = ＃发布空闲消费者事件（未收到数据）之间的时间。 spring.kafka.listener.log-container-config = ＃是否在初始化期间记录容器配置（INFO级别）。 spring.kafka.listener.monitor-interval =＃检查无响应客户的时间。如果未指定持续时间后缀，则将使用秒。 spring.kafka.listener.no-poll-threshold = ＃乘数应用于“pollTimeout”以确定消费者是否无响应。 spring.kafka.listener.poll-timeout = ＃轮询消费者时使用的超时。 spring.kafka.listener.type = single ＃监听器类型。 spring.kafka.producer.acks = ＃生产者在考虑请求完成之前要求领导者收到的确认数量。 spring.kafka.producer.batch-size = ＃发送前批量记录的数量。 spring.kafka.producer.bootstrap的服务器= ＃主机：端口对的逗号分隔列表，用于建立到Kafka集群的初始连接。 spring.kafka.producer.buffer-memory = ＃生产者可用于缓冲等待发送到服务器的记录的总内存字节数。 spring.kafka.producer.client-id = ＃在发出请求时传递给服务器的ID。用于服务器端日志记录。 spring.kafka.producer.compression-type = ＃生产者生成的所有数据的压缩类型。 spring.kafka.producer.key-serializer = ＃键的序列化类。 spring.kafka.producer.properties。* = ＃用于配置客户端的其他特定于生产者的属性。 spring.kafka.producer.retries = ＃当大于零时，允许重试失败的发送。 spring.kafka.producer.ssl.key-password = ＃密钥存储文件中的私钥密码。 spring.kafka.producer.ssl.keystore-location = ＃密钥存储文件的位置。 spring.kafka.producer.ssl.keystore-password = ＃存储密钥存储文件的密码。 spring.kafka.producer.ssl.truststore-location = ＃信任存储文件的位置。 spring.kafka.producer.ssl.truststore-password = ＃存储信任存储文件的密码。 spring.kafka.producer.transaction-id-prefix =＃非空时，为生产者启用事务支持。 spring.kafka.producer.value-serializer = ＃值的串行器类。 spring.kafka.properties。* = ＃用于配置客户端的其他属性，通常用于生产者和使用者。 spring.kafka.ssl.key-password = ＃密钥存储文件中的私钥密码。 spring.kafka.ssl.keystore-location = ＃密钥存储文件的位置。 spring.kafka.ssl.keystore-password = ＃存储密钥存储文件的密码。 spring.kafka.ssl.truststore-location = ＃信任存储文件的位置。 spring.kafka.ssl.truststore-password =＃存储信任存储文件的密码。 spring.kafka.template.default-topic = ＃发送消息的默认主题。 ＃RABBIT（RabbitProperties） spring.rabbitmq.addresses = ＃客户端应该连接的地址的逗号分隔列表。 spring.rabbitmq.cache.channel.checkout-timeout = ＃如果已达到缓存大小，则等待获取频道的持续时间。 spring.rabbitmq.cache.channel.size = ＃缓存中要保留的通道数。 spring.rabbitmq.cache.connection.mode = channel ＃连接工厂缓存模式。 spring.rabbitmq.cache.connection.size = ＃要缓存的连接数。 spring.rabbitmq.connection-timeout = ＃连接超时。将其设置为零以永久等待。 spring.rabbitmq.dynamic = true ＃是否创建一个AmqpAdmin bean。 spring.rabbitmq.host = localhost ＃RabbitMQ主机。 spring.rabbitmq.listener.direct.acknowledge-mode = ＃容器的确认模式。 spring.rabbitmq.listener.direct.auto-startup = true ＃是否在启动时自动启动容器。 spring.rabbitmq.listener.direct.consumers-per-queue = ＃每个队列的使用者数量。 spring.rabbitmq.listener.direct.default-requeue-rejected = ＃默认情况下，拒绝交付是否重新排队。 spring.rabbitmq.listener.direct.idle-event-interval =＃空闲容器事件应该多久发布一次。 spring.rabbitmq.listener.direct.prefetch = ＃单个请求中要处理的消息数。它应该大于或等于事务大小（如果使用）。 spring.rabbitmq.listener.direct.retry.enabled = false ＃是否启用发布重试。 spring.rabbitmq.listener.direct.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。 spring.rabbitmq.listener.direct.retry.max-attempts = 3 ＃传递消息的最大尝试次数。 spring.rabbitmq.listener.direct.retry.max -interval = 10000ms ＃尝试之间的最大持续时间。 spring.rabbitmq.listener.direct.retry.multiplier = 1 ＃乘数应用于以前的重试间隔。 spring.rabbitmq.listener.direct.retry.stateless = true ＃重试是无状态还是有状态。 spring.rabbitmq.listener.simple.acknowledge-mode = ＃容器的确认模式。 spring.rabbitmq.listener.simple.auto-startup = true ＃是否在启动时自动启动容器。 spring.rabbitmq.listener.simple.concurrency = ＃监听器调用者线程的最小数量。 spring.rabbitmq.listener.simple.default-requeue-rejected = ＃默认情况下是否拒绝交付重新排队。 spring.rabbitmq.listener.simple.idle-event-interval = ＃应该发布空闲容器事件的频率。 spring.rabbitmq.listener.simple.max-concurrency = ＃监听器调用者线程的最大数量。 spring.rabbitmq.listener.simple.prefetch = ＃在单个请求中要处理的消息数。它应该大于或等于事务大小（如果使用）。 spring.rabbitmq.listener.simple.retry.enabled = false ＃是否启用发布重试。 spring.rabbitmq.listener.simple.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。 spring.rabbitmq.listener.simple.retry.max-尝试= 3 ＃传递消息的最大尝试次数。 spring.rabbitmq.listener.simple.retry.max -interval = 10000ms ＃尝试之间的最大持续时间。 spring.rabbitmq.listener.simple.retry.multiplier = 1 ＃乘数应用于之前的重试间隔。 spring.rabbitmq.listener.simple.retry.stateless = true ＃重试是无状态还是有状态。 spring.rabbitmq.listener.simple.transaction-size = ＃事务中要处理的消息数。也就是说，ack之间的消息数量。为了获得最佳结果，它应该小于或等于预取计数。 spring.rabbitmq.listener.type = simple ＃监听器容器类型。 spring.rabbitmq.password = guest ＃登录以对经纪人进行身份验证。 spring.rabbitmq.port = 5672 ＃RabbitMQ端口。 spring.rabbitmq.publisher-confirms = false ＃是否启用发布者确认。 spring.rabbitmq.publisher-returns = false ＃是否启用发布商退货。 spring.rabbitmq.requested-heartbeat = ＃请求的心跳超时; 零为零。如果未指定持续时间后缀，则将使用秒。 spring.rabbitmq.ssl.enabled = false ＃是否启用SSL支持。 spring.rabbitmq.ssl.key-store = ＃保存SSL证书的密钥存储区的路径。 spring.rabbitmq.ssl.key-store-password = ＃用于访问密钥存储区的密码。 spring.rabbitmq.ssl.key-store-type = PKCS12 ＃密钥库类型。 spring.rabbitmq.ssl.trust-store = ＃持有SSL证书的信任库。 spring.rabbitmq.ssl.trust-store-password = ＃用于访问信任存储的密码。 spring.rabbitmq.ssl.trust-store-type = JKS ＃信任商店类型。 spring.rabbitmq.ssl.algorithm = ＃使用的SSL算法。默认情况下，由Rabbit客户端库配置。 spring.rabbitmq.template.exchange = ＃用于发送操作的默认交换的名称。 spring.rabbitmq.template.mandatory = ＃是否启用强制消息。 spring.rabbitmq.template.receive-timeout = ＃receive（）操作超时。 spring.rabbitmq.template.reply-timeout = ＃sendAndReceive（）操作超时。 spring.rabbitmq.template.retry.enabled = false ＃是否启用发布重试。 spring.rabbitmq.template.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。 spring.rabbitmq.template.retry.max-attempts = 3 ＃传递消息的最大尝试次数。 spring.rabbitmq.template.retry.max -interval = 10000ms＃尝试之间的最大持续时间 spring.rabbitmq.template.retry.multiplier = 1 ＃乘数应用于以前的重试间隔。 spring.rabbitmq.template.routing-key = ＃用于发送操作的默认路由密钥的值。 spring.rabbitmq.username = guest ＃登录用户向代理进行身份验证。 spring.rabbitmq.virtual-host = ＃连接到代理时使用的虚拟主机。 ＃---------------------------------------- ＃ACTUATOR PROPERTIES ＃----- ----------------------------------- ＃MANAGEMENT HTTP SERVER（ManagementServerProperties） management.server.add-application-context-header = false ＃在每个响应中添加“X-Application-Context”HTTP头。 management.server.address = ＃管理端点应该绑定的网络地址。需要一个自定义的management.server.port。 management.server.port = ＃管理端点HTTP端口（默认使用与应用程序相同的端口）。配置不同的端口以使用特定于管理的SSL。 management.server.servlet.context-path = ＃管理端点上下文路径（例如`/ management`）。需要一个自定义的management.server.port。 management.server.ssl.ciphers= ＃支持的SSL密码。需要一个自定义的management.port。 management.server.ssl.client-auth = ＃是否需要客户端身份验证（“需要”）或需要（“需要”）。需要信任商店。需要一个自定义的management.server.port。 management.server.ssl.enabled = ＃是否启用SSL支持。需要一个自定义的management.server.port。 management.server.ssl.enabled-protocols = ＃启用SSL协议。需要一个自定义的management.server.port。 management.server.ssl.key-alias = ＃标识密钥库中密钥的别名。需要一个自定义的management.server.port。 management.server.ssl.key-password =＃用于访问密钥存储区中密钥的密码。需要一个自定义的management.server.port。 management.server.ssl.key-store = ＃保存SSL证书的密钥存储区的路径（通常是一个jks文件）。需要一个自定义的management.server.port。 management.server.ssl.key-store-password = ＃用于访问密钥存储的密码。需要一个自定义的management.server.port。 management.server.ssl.key-store-provider = ＃密钥存储的提供者。需要一个自定义的management.server.port。 management.server.ssl.key-store-type = ＃密钥存储的类型。需要一个自定义的management.server.port。 management.server.ssl.protocol = TLS＃使用SSL协议。需要一个自定义的management.server.port。 management.server.ssl.trust-store = ＃持有SSL证书的信任库。需要一个自定义的management.server.port。 management.server.ssl.trust-store-password = ＃用于访问信任存储的密码。需要一个自定义的management.server.port。 management.server.ssl.trust-store-provider = ＃信任存储的提供者。需要一个自定义的management.server.port。 management.server.ssl.trust-store-type = ＃信任存储的类型。需要一个自定义的management.server.port。 ＃CLOUDFOUNDRY management.cloudfoundry.enabled = true ＃是否启用扩展Cloud Foundry执行器端点。 management.cloudfoundry.skip-ssl-validation = false ＃是否跳过针对Cloud Foundry执行器端点安全调用的SSL验证。 ＃ 终端常规配置management.endpoints.enabled-by-default = ＃是否默认启用或禁用所有终端。 ＃ENDPOINTS JMX配置（JmxEndpointProperties） management.endpoints.jmx.domain = org.springframework.boot ＃终结点JMX域名。如果设置，则回退到'spring.jmx.default-domain'。 management.endpoints.jmx.exposure.include = * ＃应包含的端点ID或全部包含的“*”。 management.endpoints.jmx.exposure.exclude = ＃应排除的端点ID。 management.endpoints.jmx.static-names = ＃追加到所有表示端点的MBean的ObjectName的静态属性。 management.endpoints.jmx.unique-names = false ＃是否确保ObjectNames在发生冲突时被修改。 ＃终端WEB配置（WebEndpointProperties） management.endpoints.web.exposure.include =健康，信息＃应包含的终端ID或全部为'*'。 management.endpoints.web.exposure.exclude = ＃应该排除的端点ID。 management.endpoints.web.base-path = / actuators ＃Web端点的基本路径。相对于server.servlet.context-path或management.server.servlet.context-path，如果配置了management.server.port。 management.endpoints.web.path-mapping = ＃端点ID和应该暴露它们的路径之间的映射。 ＃ENDPOINTS CORS CONFIGURATION（CorsEndpointProperties） management.endpoints.web.cors.allow-credentials = ＃是否支持凭证。未设置时，不支持凭证。 management.endpoints.web.cors.allowed-headers = ＃在请求中允许使用逗号分隔的标题列表。'*'允许所有标题。 management.endpoints.web.cors.allowed-methods = ＃允许使用逗号分隔的方法列表。'*'允许所有方法。未设置时，默认为GET。 management.endpoints.web.cors.allowed-origins = ＃逗号分隔的起源列表允许。'*'允许所有的来源。未设置时，CORS支持被禁用。 management.endpoints.web.cors.exposed-headers = ＃包含在响应中的逗号分隔的标题列表。 management.endpoints.web.cors.max-age = 1800s ＃客户端可以缓存飞行前请求的响应时间。如果未指定持续时间后缀，则将使用秒。 ＃审计事件ENDPOINT（AuditEventsEndpoint） management.endpoint.auditevents.cache.time-to-live = 0ms ＃响应可以被缓存的最长时间。 management.endpoint.auditevents.enabled = true ＃是否启用auditevents端点。 ＃BEANS ENDPOINT（BeansEndpoint） management.endpoint.beans.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.beans.enabled = true ＃是否启用bean端点。 ＃条件REPORT ENDPOINT（ConditionsReportEndpoint） management.endpoint.conditions.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.conditions.enabled = true ＃是否启用条件端点。 ＃配置属性报告ENDPOINT（ConfigurationPropertiesReportEndpoint，ConfigurationPropertiesReportEndpointProperties） management.endpoint.configprops.cache.time-to-live = 0ms ＃响应可以被缓存的最大时间。 management.endpoint.configprops.enabled = true ＃是否启用configprops端点。 management.endpoint.configprops.keys-to-sanitize =密码，密钥，密钥，令牌，*凭证。*，vcap_services ＃应该清理的密钥。键可以是属性以正则表达式结尾的简单字符串。 ＃ENVIRONMENT ENDPOINT（EnvironmentEndpoint，EnvironmentEndpointProperties） management.endpoint.env.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.env.enabled = true ＃是否启用env端点。 management.endpoint.env.keys-to-sanitize =密码，秘密，密钥，令牌，*凭证。*，vcap_services ＃应该清理的密钥。键可以是属性以正则表达式结尾的简单字符串。 ＃FLYWAY ENDPOINT（FlywayEndpoint） management.endpoint.flyway.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.flyway.enabled = true ＃是否启用飞桥端点。 ＃HEALTH ENDPOINT（HealthEndpoint，HealthEndpointProperties） management.endpoint.health.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.health.enabled = true ＃是否启用运行状况端点。 management.endpoint.health.roles = ＃用于确定用户是否有权显示详细信息的角色。当为空时，所有认证的用户都被授权。 management.endpoint.health.show-details = never ＃何时显示完整健康详情。 ＃HEAP DUMP ENDPOINT（HeapDumpWebEndpoint） management.endpoint.heapdump.cache.time-to-live = 0ms ＃响应可以被缓存的最长时间。 management.endpoint.heapdump.enabled = true ＃是否启用heapdump端点。 ＃HTTP TRACE ENDPOINT（HttpTraceEndpoint） management.endpoint.httptrace.cache.time-to-live = 0ms ＃响应可以被缓存的最大时间。 management.endpoint.httptrace.enabled = true ＃是否启用httptrace端点。 ＃INFO ENDPOINT（InfoEndpoint） info = ＃添加到信息端点的任意属性。 management.endpoint.info.cache.time-to-live = 0ms ＃响应可以被缓存的最大时间。 management.endpoint.info.enabled = true ＃是否启用信息端点。 ＃JOLOKIA ENDPOINT（JolokiaProperties） management.endpoint.jolokia.config。* = ＃Jolokia设置。有关更多详细信息，请参阅Jolokia的文档。 management.endpoint.jolokia.enabled = true ＃是否启用jolokia端点。 ＃LIQUIBASE ENDPOINT（LiquibaseEndpoint） management.endpoint.liquibase.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.liquibase.enabled = true ＃是否启用liquibase端点。 ＃LOG FILE ENDPOINT（LogFileWebEndpoint，LogFileWebEndpointProperties） management.endpoint.logfile.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.logfile.enabled = true ＃是否启用日志文件端点。 management.endpoint.logfile.external-file = ＃要访问的外部日志文件。如果日志文件是由输出重定向写入的，而不是日志记录系统本身，则可以使用。 ＃LOGGERS ENDPOINT（LoggersEndpoint） management.endpoint.loggers.cache.time-to-live = 0ms ＃响应可以被缓存的最大时间。 management.endpoint.loggers.enabled = true ＃是否启用记录器端点。 ＃请求MAPPING ENDPOINT（MappingsEndpoint） management.endpoint.mappings.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.mappings.enabled = true ＃是否启用映射端点。 ＃METRICS ENDPOINT（MetricsEndpoint） management.endpoint.metrics.cache.time-to-live = 0ms ＃响应可以被缓存的最大时间。 management.endpoint.metrics.enabled = true ＃是否启用度量标准端点。 ＃PROMETHEUS ENDPOINT（PrometheusScrapeEndpoint） management.endpoint.prometheus.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.prometheus.enabled = true ＃是否启用普罗米修斯端点。 ＃SCHEDULED TASKS ENDPOINT（ScheduledTasksEndpoint） management.endpoint.scheduledtasks.cache.time-to-live = 0ms ＃响应可以被缓存的最大时间。 management.endpoint.scheduledtasks.enabled = true ＃是否启用scheduledtasks端点。 ＃SESSIONS ENDPOINT（SessionsEndpoint） management.endpoint.sessions.enabled = true ＃是否启用会话端点。 ＃SHUTDOWN ENDPOINT（ShutdownEndpoint） management.endpoint.shutdown.enabled = false ＃是否启用关闭端点。 ＃THREAD DUMP ENDPOINT（ThreadDumpEndpoint） management.endpoint.threaddump.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。 management.endpoint.threaddump.enabled = true ＃是否启用线程转储端点。 ＃健康指标 management.health.db.enabled = true ＃是否启用数据库健康检查。 management.health.cassandra.enabled = true ＃是否启用Cassandra健康检查。 management.health.couchbase.enabled = true ＃是否启用Couchbase运行状况检查。 management.health.defaults.enabled = true ＃是否启用默认运行状况指示器。 management.health.diskspace.enabled = true ＃是否启用磁盘空间运行状况检查。 management.health.diskspace.path = ＃用于计算可用磁盘空间的路径。 management.health.diskspace.threshold = 0＃应该可用的最小磁盘空间（以字节为单位）。 management.health.elasticsearch.enabled = true ＃是否启用Elasticsearch运行状况检查。 management.health.elasticsearch.indices = ＃逗号分隔的索引名称。 management.health.elasticsearch.response-timeout = 100ms ＃等待集群响应的时间。 management.health.influxdb.enabled = true ＃是否启用InfluxDB运行状况检查。 management.health.jms.enabled = true ＃是否启用JMS运行状况检查。 management.health.ldap.enabled = true ＃是否启用LDAP运行状况检查。 management.health.mail.enabled = true＃是否启用邮件运行状况检查。 management.health.mongo.enabled = true ＃是否启用MongoDB运行状况检查。 management.health.neo4j.enabled = true ＃是否启用Neo4j运行状况检查。 management.health.rabbit.enabled = true ＃是否启用RabbitMQ运行状况检查。 management.health.redis.enabled = true ＃是否启用Redis运行状况检查。 management.health.solr.enabled = true ＃是否启用Solr运行状况检查。 management.health.status.http-mapping = ＃健康状态到HTTP状态代码的映射。默认情况下，注册的健康状态映射到合理的默认值（例如，UP映射为200）。 management.health.status.order = DOWN，OUT_OF_SERVICE，UP，UNKNOWN ＃以严重性顺序的逗号分隔的健康状态列表。 ＃HTTP TRACING（HttpTraceProperties） management.trace.http.enabled = true ＃是否启用HTTP请求 - 响应跟踪。 management.trace.http.include = request-headers，response-headers，cookies，errors ＃要包含在跟踪中的项目。 ＃信息贡献者（InfoContributorProperties） management.info.build.enabled = true ＃是否启用 management.info.defaults.enabled = true ＃是否启用默认信息撰稿人。 management.info.env.enabled = true ＃是否启用环境信息。 management.info.git.enabled = true ＃是否启用git信息。 management.info.git.mode = simple ＃用于公开git信息的模式。 ＃METRICS management.metrics.binders.files.enabled = true ＃是否启用文件度量标准。 management.metrics.binders.integration.enabled = true ＃是否启用Spring Integration指标。 management.metrics.binders.jvm.enabled = true ＃是否启用JVM度量标准。 management.metrics.binders.logback.enabled = true ＃是否启用Logback指标。 management.metrics.binders.processor.enabled = true ＃是否启用处理器指标。 management.metrics.binders.uptime.enabled = true ＃是否启用正常运行时间指标。 management.metrics.distribution.percentiles-histogram。* =＃以指定名称开头的电表ID是否应该公布百分比直方图。 management.metrics.distribution.percentiles。* = ＃从指定名称开始计算出的计量器ID从后端运送到特定计算的不可汇总百分点。 management.metrics.distribution.sla。* = ＃以特定名称开始的电表ID的特定SLA边界。最长的匹配胜出，关键'全部'也可用于配置所有仪表。 management.metrics.enable。* = ＃是否启用以指定名称开头的电表ID。最长的匹配胜出，关键'全部'也可用于配置所有仪表。 management.metrics.export.atlas.batch-size = 10000＃每个请求用于此后端的度量数。如果找到更多的测量结果，则会发出多个请求。 management.metrics.export.atlas.config-refresh-frequency = 10s ＃刷新LWC服务配置设置的频率。 management.metrics.export.atlas.config-time-to-live = 150s ＃为LWC服务的订阅生存的时间。 management.metrics.export.atlas.config-uri = http：// localhost：7101 / lwc / api / v1 / expressions / local-dev ＃Atlas LWC端点检索当前订阅的URI。 management.metrics.export.atlas.connect-timeout = 1s ＃对后端请求的连接超时。 management.metrics.export.atlas.enabled= true ＃是否启用指标到此后端的导出。 management.metrics.export.atlas.eval-uri = http：// localhost：7101 / lwc / api / v1 / evaluate ＃URI用于Atlas LWC端点评估订阅的数据。 management.metrics.export.atlas.lwc-enabled = false ＃是否启用流式传输到Atlas LWC。 management.metrics.export.atlas.meter-time-to-live = 15m ＃生活在没有任何活动的米的时间。经过这段时间后，电表将被视为过期，并不会被报告。 management.metrics.export.atlas.num-threads = 2 ＃用于度量标准发布计划程序的线程数。 management.metrics.export.atlas.read超时= 10s ＃读取该后端请求的超时时间。 management.metrics.export.atlas.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.atlas.uri = http：// localhost：7101 / api / v1 / publish ＃Atlas服务器的URI。 management.metrics.export.datadog.api-key = ＃Datadog API密钥。 management.metrics.export.datadog.application-key = ＃Datadog应用程序密钥。不是严格要求，而是通过向Datadog发送电表描述，类型和基本单位来改善Datadog体验。 management.metrics.export.datadog.batch-size = 10000＃每个请求用于此后端的度量数。如果找到更多的测量结果，则会发出多个请求。 management.metrics.export.datadog.connect-timeout = 1s ＃对后端请求的连接超时。 management.metrics.export.datadog.descriptions = true ＃是否将描述元数据发布到Datadog。关闭此功能可最大限度地减少发送的元数据量。 management.metrics.export.datadog.enabled = true ＃是否启用指标到此后端的导出。 management.metrics.export.datadog.host-tag = instance ＃将标准传送到Datadog时将被映射到“主机”的标签。 management.metrics.export.datadog.num线程= 2 ＃用于度量标准发布计划程序的线程数。 management.metrics.export.datadog.read-timeout = 10s ＃读取该后端请求的超时时间。 management.metrics.export.datadog.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.datadog.uri = https：//app.datadoghq.com＃将指标发送到的URI。如果您需要将指标发布到通往Datadog的内部代理，则可以使用此代理定义代理的位置。 management.metrics.export.ganglia.addressing-mode = multicast ＃UDP寻址模式，可以是单播或多播。 management.metrics.export.ganglia.duration-units =毫秒＃用于报告持续时间的基本时间单位。 management.metrics.export.ganglia.enabled = true ＃是否启用向Ganglia导出度量标准。 management.metrics.export.ganglia.host = localhost ＃Ganglia服务器的主机接收导出的度量标准。 management.metrics.export.ganglia.port = 8649 ＃Ganglia服务器的端口，用于接收导出的度量标准。 management.metrics.export.ganglia.protocol-version = 3.1 ＃Ganglia协议版本。必须是3.1或3.0。 management.metrics.export.ganglia.rate-units = seconds ＃用于报告费率的基本时间单位。 management.metrics.export.ganglia.step = 1m＃步长（即报告频率）使用。 management.metrics.export.ganglia.time-to-live = 1 ＃生活在Ganglia指标上的时间。将多播时间生存时间设置为比主机之间的跳数（路由器）数量多一个。 management.metrics.export.graphite.duration-units = milliseconds ＃用于报告持续时间的基本时间单位。 management.metrics.export.graphite.enabled = true ＃是否启用指标到Graphite的导出。 management.metrics.export.graphite.host = localhost ＃接收导出指标的Graphite服务器的主机。 management.metrics.export.graphite.port = 2004＃接收导出指标的Graphite服务器的端口。 management.metrics.export.graphite.protocol = pickled ＃将数据传输到Graphite时使用的协议。 management.metrics.export.graphite.rate-units = seconds ＃用于报告费率的基本时间单位。 management.metrics.export.graphite.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.graphite.tags-as-prefix = ＃对于默认的命名约定，将指定的标记键转换为度量标准前缀的一部分。 management.metrics.export.influx.auto-create-db = true ＃是否在尝试向其发布指标之前创建Influx数据库（如果它不存在）。 management.metrics.export.influx.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多的测量结果，则会发出多个请求。 management.metrics.export.influx.compressed = true ＃是否启用发布到Influx的指标批次的GZIP压缩。 management.metrics.export.influx.connect-timeout = 1s ＃对此后端请求的连接超时。 management.metrics.export.influx.consistency = 1 ＃为每个点编写一致性。 management.metrics.export.influx.db = mydb ＃将标准传送到Influx时将映射到“主机”的标签。 management.metrics.export.influx.enabled= true ＃是否启用指标到此后端的导出。 management.metrics.export.influx.num-threads = 2 ＃用于指标发布计划程序的线程数。 management.metrics.export.influx.password = ＃Influx服务器的登录密码。 management.metrics.export.influx.read-timeout = 10s ＃读取该后端请求的超时时间。 management.metrics.export.influx.retention-policy = ＃使用的保留策略（如果未指定DEFAULT保留策略，Influx写入DEFAULT保留策略）。 management.metrics.export.influx.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.influx.uri= http：// localhost：8086 ＃Influx服务器的URI。 management.metrics.export.influx.user-name = ＃Influx服务器的登录用户。 management.metrics.export.jmx.enabled = true ＃是否启用指标到JMX的导出。 management.metrics.export.jmx.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.newrelic.account-id = ＃新的遗物账户ID。 management.metrics.export.newrelic.api-key = ＃新的Relic API密钥。 management.metrics.export.newrelic.batch-size = 10000＃每个请求用于此后端的度量数。如果找到更多的测量结果，则会发出多个请求。 management.metrics.export.newrelic.connect-timeout = 1s ＃对此后端请求的连接超时。 management.metrics.export.newrelic.enabled = true ＃是否启用度量标准导出到此后端。 management.metrics.export.newrelic.num-threads = 2 ＃用于指标发布调度程序的线程数。 management.metrics.export.newrelic.read-timeout = 10s ＃读取该后端请求的超时时间。 management.metrics.export.newrelic.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.newrelic.uri = https：//insights-collector.newrelic.com＃将指标发送到的URI。 management.metrics.export.prometheus.descriptions = true ＃是否启用发布说明，作为Prometheus的有效载荷的一部分。关闭此功能可以最大限度地减少每次扫描发送的数据量。 management.metrics.export.prometheus.enabled = true ＃是否启用指标到Prometheus的导出。 management.metrics.export.prometheus.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.signalfx.access-token = ＃SignalFX访问令牌。 management.metrics.export.signalfx.batch-size = 10000＃每个请求用于此后端的度量数。如果找到更多的测量结果，则会发出多个请求。 management.metrics.export.signalfx.connect-timeout = 1s ＃对此后端请求的连接超时。 management.metrics.export.signalfx.enabled = true ＃是否启用度量标准导出到此后端。 management.metrics.export.signalfx.num-threads = 2 ＃用于指标发布计划程序的线程数。 management.metrics.export.signalfx.read-timeout = 10s ＃读取该后端请求的超时时间。 management.metrics.export.signalfx.source =＃唯一标识将度量标准发布到SignalFx的应用程序实例。默认为本地主机名称。 management.metrics.export.signalfx.step = 10s ＃使用步长（即报告频率）。 management.metrics.export.signalfx.uri = https：//ingest.signalfx.com＃将指标发送到的URI。 management.metrics.export.simple.enabled = true ＃是否在没有任何其他导出器的情况下启用度量标准导出到内存后端。 management.metrics.export.simple.mode =累计＃计数模式。 management.metrics.export.simple.step = 1m ＃使用步长（即报告频率）。 management.metrics.export.statsd.enabled= true ＃是否启用指标到StatsD的导出。 management.metrics.export.statsd.flavor = datadog ＃StatsD要使用的协议。 management.metrics.export.statsd.host = localhost ＃StatsD服务器的主机接收导出的度量标准。 management.metrics.export.statsd.max-packet-length = 1400 ＃单个有效负载的总长度应保留在网络的MTU内。 management.metrics.export.statsd.polling-frequency = 10s ＃调查仪表的频率。当轮询仪表时，其值将被重新计算，如果值已更改（或者publishUnchangedMeters为true），则会将其发送到StatsD服务器。 management.metrics.export.statsd.port= 8125 ＃StatsD服务器的端口，用于接收导出的指标。 management.metrics.export.statsd.publish-unchanged-meters = true ＃是否向StatsD服务器发送未更改的计量表。 management.metrics.export.statsd.queue-size = 2147483647 ＃等待发送到StatsD服务器的项目队列的最大大小。 management.metrics.export.wavefront.api-token = ＃将API度量标准直接发布到Wavefront API主机时使用。 management.metrics.export.wavefront.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多的测量结果，则会发出多个请求。 management.metrics.export.wavefront.connect-timeout = 1s ＃对后端请求的连接超时。 management.metrics.export.wavefront.enabled = true ＃是否启用度量标准导出到此后端。 management.metrics.export.wavefront.global-prefix = ＃在Wavefront用户界面中查看时，将源自此应用的白色盒子检测的度量与源自其他Wavefront集成的度量分开的全局前缀。 management.metrics.export.wavefront.num-threads = 2 ＃用于指标发布计划程序的线程数。 management.metrics.export.wavefront.read-timeout = 10s ＃读取该后端请求的超时时间。 management.metrics.export.wavefront.source = ＃作为发布到Wavefront的指标来源的应用实例的唯一标识符。默认为本地主机名称。 management.metrics.export.wavefront.step = 10s ＃步长（即报告频率）使用。 management.metrics.export.wavefront.uri = https：//longboard.wavefront.com＃将指标发送到的URI。 management.metrics.use-global-registry = true ＃自动配置的MeterRegistry实现是否应绑定到Metrics上的全局静态注册表。 management.metrics.web.client.max-uri-tags = 100＃允许的最大唯一URI标记值数量。达到标签值的最大数量后，具有附加标签值的度量标准将被过滤器拒绝。 management.metrics.web.client.requests-metric-name = http.client.requests ＃发送请求的度量标准名称。 management.metrics.web.server.auto-time-requests = true ＃是否应该自动计时由Spring MVC或WebFlux处理的请求。 management.metrics.web.server.requests-metric-name = http.server.requests ＃接收请求的度量标准名称。 ＃---------------------------------------- ＃DEVTOOLS PROPERTIES ＃----- ----------------------------------- ＃DEVTOOLS（DevToolsProperties） spring.devtools.livereload.enabled = true ＃是否启用livereload.com兼容服务器。 spring.devtools.livereload.port = 35729 ＃服务器端口。 spring.devtools.restart.additional-exclude = ＃应该从触发完全重新启动时排除的其他模式。 spring.devtools.restart.additional-paths = ＃观察更改的其他路径。 spring.devtools.restart.enabled = true ＃是否启用自动重启。 spring.devtools.restart.exclude= META-INF /行家/ **，META-INF /资源/ **，资源/ **，静态/ **，公共/ **，模板/ **，** / *的Test.class，** / * Tests.class，git.properties，META-INF / build-info.properties ＃应该排除触发完全重新启动的模式。 spring.devtools.restart.log-condition-evaluation-delta = true ＃是否在重新启动时记录条件评估增量。 spring.devtools.restart.poll-interval = 1s ＃轮询类路径更改之间等待的时间。 spring.devtools.restart.quiet-period = 400ms ＃触发重新启动之前所需的静默时间，不需要任何类路径更改。 spring.devtools.restart.trigger-file =＃特定文件的名称，如果更改，则会触发重新启动检查。如果未指定，则任何类路径文件更改都会触发重新启动。 ＃REMOTE DEVTOOLS（RemoteDevToolsProperties） spring.devtools.remote.context-path = /。~~ spring-boot！〜＃用于处理远程连接的上下文路径。 spring.devtools.remote.proxy.host = ＃用于连接远程应用程序的代理主机。 spring.devtools.remote.proxy.port = ＃用于连接远程应用程序的代理端口。 spring.devtools.remote.restart.enabled = true ＃是否启用远程重启。 spring.devtools.remote.secret = ＃建立连接所需的共享密钥（启用远程支持所必需的）。 spring.devtools.remote.secret头名= 用于传输共享密钥的 X-AUTH-TOKEN ＃HTTP标头。 ＃---------------------------------------- ＃测试属性 ＃----- ----------------------------------- spring.test.database.replace = any ＃要替换的现有DataSource的类型。 spring.test.mockmvc.print =默认＃MVC 打印选项。","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/"},{"name":"Spring Boot","slug":"Spring-Boot/Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/Spring-Boot/"}],"tags":[]},{"title":"JVM之垃圾回收机制(3)","slug":"jvm/JVM之垃圾回收机制(3)","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/jvm/jvm-zhi-la-ji-hui-shou-ji-zhi-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/jvm/jvm-zhi-la-ji-hui-shou-ji-zhi-3/","excerpt":"","text":"JVM之Garbage Collect(垃圾回收)1 如何确定一个对象是垃圾要想进行垃圾回收,得先知道什么样的对象是垃圾. 1.1 引用计数法对于某个对象而言,只要应用程序中持有该对象的引用,就说明该对象不是垃圾,如果一个对象没有任何指针对其引用, 就说明他是个垃圾. 弊端: 如果AB 互相持有引用,导致永远不能被回收. 1.2 可达性分析通过GC Root 对象,开始向下寻找, 看某个对象是否可达. 能作为GC Root: 类加载器、Thread、虚拟机栈的本地变量表、static 成员、常量引用、本地方法栈的变量等. 2 垃圾收集算法已经能够确定一个对象为垃圾后,接下来要考虑的就是回收, 怎么回收呢? 得要有对应的算法,下面聊聊常见的垃圾回收算法. 2.1 标记-清除算法(Mark-Sweep) 标记 找出内存中需要回收的对象,并且把他们标记出来. 此时堆中所有的对象都会被扫描一遍,从而才能确定需要回收的对象,比较耗时. 清除 清除掉被标记的需要回收的对象，释放出相应的内存空间. 缺点: 标记清除之后会产生大量不连续的内存碎片,空间碎片太多可能会导致以后的程序运行过程中需要分配较大的对象的时候, 无法找到足够的连续内存而不得不提前触发另一次垃圾收集的动作. 标记和清除两个过程都比较耗时,效率不高. 会产生大量的不连续的内存碎片,空间碎片太对会导致以后再程序运行过程中需要分配较大对象的时候,无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作. 2.2 复制(Copying)将内存划分为两块相等的区域, 每次只使用一块,如下图所示: 当其中一块内存使用完了后,就将还存活的对象复制到另外一块上面,然后把已经使用过的内存空间一次清除掉. 缺点: 空间利用率低 2.3 标记-整理(Mark-Compact)标记过程中仍然与”标记-清除”算法一样,但是后续步骤不是直接对可回收对象进行清理,而是让所有存活的对象都向一端移动,然后直接清理掉边界以外的内存. 让所有存活的对象都向一端移动,清理掉边界以外的内存. 3. 分代收集算法既然上面介绍了3种垃圾收集算法,那么在堆内存中到底用哪一个呢? Young区: 复制算法(对象在被分配后, 可能生命周期比较短,Young 区复制效率比较高) Old区: 标记清除或者标记整理(Old 区对象存活时间比较长, 复制来复制去没必要, 不如做个标记再清理) 4. 垃圾收集器如果收集算法是内存回收的方法论,那么垃圾收集器就是垃圾回收的具体实现,说白了就是落地. 4.1 Serial 收集器Serial 收集器是最基本、发展历史最悠久的收集器,曾经(JDK1.3.1之前)是虚拟机新生代收集的唯一选择. 它是一种单线程的收集器,不仅仅意味着它只会使用一个CPU 或者一条收集线程去完成垃圾收集工作,更重要的是其在进行垃圾收集的时候需要暂停其他线程. **优点:**简单高效, 拥有很高的单线程收集效率 缺点: 收集过程中需要暂停所有线程 算法: 复制算法 使用范围: 新生代 应用: Client 模式下的默认新生代收集器 4.2 ParNew 收集器可以把这个收集器理解为Serial 收集器的的多线程版本 优点: 在多CPU的时候,比Serial效率高 缺点: 收集过程中暂停所有应用程序线程,单CPU时比Servial 效率慢 算法: 复制算法 适用范围: 新生代 应用: 运行在Server 模式下的虚拟机中首选的新生代收集器 4.3 Paraller Scavenge 收集器Parallel Scavenge收集器是一个新生代我收集器, 它也是使用复制算法的收集器,又是并行的多线程收集器, 看上去和ParNew 一样,但是 Paraller Scavenge 更加关注系统吞吐量 吞吐量= 运行用户代码的时间/(运行用户代码的时间+垃圾收集时间) 比如虚拟机总共运行了100分钟, 垃圾收集时间用了1分钟, 吞吐量=(100-1)/100 = 99% 若吞吐量越大, 意味着垃圾收集的时间越短,则用户代码可以充分利用用CPU资源,尽快完成程序的运算任务. -XX:MaxGCPauseMillis控制最大的垃圾收集停顿时间， -XX:GCTimeRatio直接设置吞吐量的大小。 4.4 Serial Old 收集器Serial Old 收集器是Serial 收集器的老年代版本,也是一个单线程收集器, 不同的是采用”标记-整理” 算法,运行过程跟Serial是一样的. 4.5 Paraller Old 收集器Paraller Old 收集器是Paraller Scavenge 收集器的老年代版本,使用多线程和”标记-整理”算法进行垃圾收集. 使用场景: 吞吐量优先 4.6 CMS 收集器CMS(Concurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间 为目标的收集器. 采用的是”标记-清除”算法, 整个过程分为4步: 初始标记 CMS initial mark -&gt; 标记GC Roots能关联的对象 -&gt; Stop The World(速度很快) 并发标记 CMS concurrent mark -&gt; 进行GC Roots Tracing 重新标记 CMS remark 修改并发标记因用户程序变动的内容 Stop The World 并发清除 CMS concurrent sweep 整个过程中, 并发标记和并发清除,收集器线程可以与工作线程一起工作,所以总体上来说,CSM 收集器的内存回收过程是与用户线程一起并发的执行的. 优点: 并发收集、低停顿 缺点: 会产生大量空间碎片、并发阶段会降低吞吐量. 4.7 G1 收集器G1的特点: 并行与并发 分代收集(仍然保留了分代的概念) 空间整合(整体上属于”标记-整理”算法,不会导致空间碎片) 可预测的停顿(比CMS 更先进的地方在于能让使用者明确指定一个长度为M毫秒的时间片段内,消耗在垃圾收集器上的时间不得超过M毫秒) 使用G1 收集器时,java堆的内存布局就与其他收集器有很大的差别, 它将整个java堆划分为多个大小相等的独立区域(Region), 虽然还保留有新生代和老年代的概念,但新生代和老年代不再是物理隔离,他们都是一部分Region(不需要连续)的集合. 工作过程可以分为以下几步: 初始标记(Initial Marking): 标记一下GC Roots 能够关联的对象,并且修改TAMS的值,需要暂停用户线程 并发标记(Concurrent Marking): 从GC Roots 进行可达性分析,找出存活的对象,与用户线程并发执行. 最终标记(Final Marking): 修改正在并发标记节点因为用户程序的并发执行导致变动的数据,需要暂停用户线程 筛选回收(Live Data Counting and Evacuation): 对各个Region的回收价值和成本进行排序,根据用户所期望的GC 停顿时间制定回收计划. 4.8 垃圾收集器分类 串行收集器 -&gt; Serial 和Serial Old 只能有一个垃圾回收线程执行,用户线程暂停, 适用于内存比较小的嵌入式设备 并行收集器[吞吐量优先] -&gt; Paraller Scanvenge 、Paraller Old 多条垃圾收集线程并行工作,但是此时用户线程仍然处于等待状态 适用于科学计算、后台处理等弱交互场景 并行收集器[停顿时间优先]: -&gt;CMS、G1 用户线程和垃圾收集线程同时执行(但并不一定是并行,可能是交替执行). 垃圾收集线程在执行的时候不会停顿用户线程的运行. 适用于相对时间有要求的场景, 比如web` 4.9 理解吞吐量和停顿时间 停顿时间: 垃圾收集器进行垃圾回收终端应用执行响应的时间 吞吐量: 运行用户代码时间/(运行用户代码时间+垃圾收集时间) 停顿时间越短就越适合需要和用户交互的场景,良好的响应速度能提升用户体验. 高吞吐量则可以高效的利用CPU时间,尽快完成程序的运算任务,只要使用在后台运算并且不需要太多交互的任务. 小结: 这两个指标也是评价垃圾回收期好坏的标准,其实调优也是在观察这两个变量. 4.10 如何选择合适的垃圾收集器官网: https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/collectors.html#sthref28 优先调整堆的大小让服务器自己来选择 如果内存小于100M , 使用串行收集器 如果是单核,并且没有停顿时间要求,使用串行或者JVM 自己选 如果允许停顿时间超过1s, 选择并行或JVM 自己选 如果响应时间最重要, 并且不能超过1s,使用并发收集器 对于G1收集器 4.11 再次理解G1jdk7开始使用,JDK8 已经成熟, JDK9默认的垃圾收集器, 适用于新老年代 判断是否需要使用G1 收集器 50% 以上的堆被存活对象占用 对象分配和晋升的速度变化非常大 垃圾回收时间比较长 4.12 如何开启需要的垃圾收集器（1）串行 -XX：+UseSerialGC -XX：+UseSerialOldGC (2)并行(吞吐量优先)： -XX：+UseParallelGC -XX：+UseParallelOldGC (3)并发收集器(响应时间优先) -XX：+UseConcMarkSweepGC -XX：+UseG1GC","categories":[{"name":"jvm","slug":"jvm","permalink":"https://rainsoil.github.io/categories/jvm/"},{"name":"jvm","slug":"jvm/jvm","permalink":"https://rainsoil.github.io/categories/jvm/jvm/"}],"tags":[]},{"title":"待补充","slug":"Spring Boot/待补充","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/spring-boot/dai-bu-chong/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/spring-boot/dai-bu-chong/","excerpt":"","text":"这里是添加一些需要补充的知识@ComponentScan 详解 https://blog.csdn.net/u012326462/article/details/82765485","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/"},{"name":"Spring Boot","slug":"Spring-Boot/Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/Spring-Boot/"}],"tags":[]},{"title":"git常用命令","slug":"git/git常用命令","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/git/git-chang-yong-ming-ling/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/git/git-chang-yong-ming-ling/","excerpt":"","text":"常用命令1. 初始化仓库git init # 在当前目录新建一个git 仓库 git init [project-name] #新建一个目录,将其初始化为git仓库 2. 将文件添加到仓库中git add 文件名 # 将工作区的某个文件添加到暂存区 git add -u # 添加将所有被tracked文件中被修改或者删除的文件信息到暂存区,不处理untracked 文件 git add -A #添加所有被tracked文件中被修改或者删除的文件信息到暂存区 git add . # 将当前工作区的所有文件都加入到暂存区 git add -i # 进入交互界面模式,按需添加文件到暂停区 git add -p # 添加每个变化前,都会要求确认,对于同一个文件的多处变化,可以实现分次提交 git rm [file1] [file2] # 删除工作区文件,并且将这次删除放入暂存区 git rm --cached [file] # 停止追踪指定文件,但是该文件会保留在工作区 git mv [file-original] [file-renamed] # 改名文件,并且将这个改名放入暂存区 3. 将暂存区的文件提交到本地仓库git commit -m &quot;提交说明&quot; # 将暂存区内容提交到本地仓库 git commit -a -m &quot;提交说明&quot; # 跳过缓存区操作,直接把工作区的内容提交到本地仓库 git commit -v # 提交时显示所有diff信息 git commit --amend -m &quot;提交说明&quot; # 使用一次新的commit,替代上一次提交.如果代码没有新变化,则用来改写上一次的commit的提交信息 4. 查看仓库当前状态git status 5. 比较文件异同git diff #工作区与暂存区的差异 git diff 分支名 # 工作区与某分支的差异,远程分支这样写:remotes/origin/分支名 git diff HEAD # 工作区与HEAD指针指向的内容差异 git diff 提交id 文件路径 # 工作区某文件当前版本与历史版本的差异 git diff --stage # 工作区文件与上次提交的差异(1.6版本前用--cached) git diff 版本TAG # 查看从某个版本后的改动内容 git diff 分支A 分支B # 比较从分支A 和分支B的差异(也支持比较两个TAG) # git diff 分支A...分支B # 比较两分支在分开后的各自改动 # 另外：如果只想统计哪些文件被改动,多少行被改动,可以添加 --stat 参数 6. 查看历史记录git log # 查看所有的 commit 记录(SHA-A校验和,作者名称,邮箱,提交时间,提交说明) git log -p -次数 #查看最近的多少次的提交记录 git log --stat # 简略显示每次提交的内容更改 git log --name -only # 仅显示已修改的文件清单 git log --name-status # 显示新增,修改,删除的文件清单 git log --online # 让提交记录已精简的一行输出 git log -graph -all --online # 图形展示分支的合并历史 git log --author=作者 #查询作者的提交记录(和grep同时使用要加一个 --all --match参数) git log --grep=过滤信息 # 列出提交信息中包含过滤信息的提交记录 git log -S 查询内容 # 和--grep 类似，S和查询内容间没有空格 git log fileName #查看某文件的修改记录 7. 代码回滚git reset HEAD^ # 恢复成上次提交的版本 git reset HEAD^^ # 恢复上上次提交的版本,就是多个^，以此类推或用~次数 git reset --hard 版本号 ---soft :只是修改HEAD指针指向,暂存区和工作区不变 ---mixed：修改HEAD 指针指向,暂存区内容修饰,工作区不变 --hard ：修改HEAD指针指向,暂存区内容丢失,工作区恢复以前状态 8. 同步远程仓库git push -u origin master 9. 删除版本库文件git rm 文件名 10. 版本库里的版本替换工作区的版本git checkout --test.txt 11. 本地仓库内容推送到远程仓库git remote add origin git@github.com:账号名/仓库名.git //添加多个远程仓库 git remote add origin2 git@github.com:账号名/仓库名.git git remote add origin4 git@github.com:账号名/仓库名.git 12. 从远程仓库克隆项目到本地git clone git@github.com:git账号名/仓库名.git git clone -b 分支名仓库地址 下载指定分支的代码 13.创建分支git checkout -b dev -b 表示创建分支并切换分支 上面一条命令相当于两条 git breanch dev // 创建分支 git checkout dev // 切换分支 git branch --set-upstream [branch] [remote-branch] # 建立追踪关系，在现有分支与指定的远程分支之间 14. 查看分支git branch 15. 合并分支git merge dev # 用于合并指定分支到当前分支 git merge origin/serverfix # 合并远程分支 git merge --no-ff -m &quot;merge with no -ff&quot; dev # 加上 --no-ff 参数就可以使用普通的模式合并,合并后的历史有分支,能看出来曾经做过合并 16. 删除分支git branch -d dev # 删除远程分支 git push origin --delete [branch-name] # 删除远程分支 git branch -dr [remote/branch] #删除远程分支 17. 查看分支合并图git log --grap --pretty=oneline --abbrev -commit 18. 查看远程信息git remote // -v 显示更详细的信息 19. 相关信息# 安装完Git后的第一件做药的事情就是设置用户信息(global 可以秀海为local 在单独项目生效): git config --global user.name &quot;用户名&quot; # 设置用户名 git config --global user.email &quot;用户邮箱&quot; # 设置邮箱 git config --global user.name # 查看用户名是否配置成功 git config --global user.email # 查看邮箱是否配置 # 其他查看配置相关 git config --global --list # 查看全局设置相关参数列表 git config --local --list # 查看本地设置相关参数列表 git config --system --list # 查看系统配置参数列表 git config --list # 查看所有Git的配置(本地+全局+系统) git config --global color.ui true # 显示git相关颜色 20 . 撤销某次提交git revert HEAD # 撤销最近的一个提交 git revert 版本号 # 撤销某次commit git reset HEAD~n # 撤销本地的第n次提交 21. 拉取远程分支到本地仓库git checkout -b 本地分支 远程分支 # 会在本地新建分支,并自动切换到该分支 git fetch origin 远程分支:本地分支 #会再本地新建分支,单不会自动切换,还需要checkout git branch --set-upstream 本地分支 远程分支#建立本地分支与远程分支的链接 22. 标签命令git tag # 列出所有tag git tag [tag] # 新建一个tag在当前commit git tag [tag] [commit] # 新建一个tag在指定commit git tag -d [tag] # 删除本地tag git push origin :refs/tags/[tagName] # 删除远程tag git show [tag] # 查看tag信息 git push [remote] [tag] # 提交指定tag git push [remote] --tags # 提交所有tag git checkout -b [branch] [tag] # 新建一个分支，指向某个tag 23. 同步远程仓库更新git fetch origin master #从远程获取最新的到本地,首先从远程的origin的master 分支下载最新的版本到origin/master 分支上,然后比较本地的master 分支和origin/master 分支的差别,最后进行合并 git fetch 比git pull 更加安全 24. 查看git 的创建时间git for-each-ref --sort=-taggerdate --format &quot;%(tag) %(taggerdate)&quot; refs/tags 25 去除已经被git 托管的文件git rm -r --cached . 常见问题git add 提交到暂存区,出错怎么办?一般代码的提交流程： 工作区 &gt; git status 查看状态 -&gt; git add . 将所有修改加入暂存区-&gt; git commit -m &quot;提交描述&quot; 将代码提交到本地仓库 -&gt;git push 将本地仓库代码更新到远程仓库 场景1当你改乱了工作区某个文件的内容,还添加到了暂存区, 想直接丢弃工作区的修改时, 用命令 git checkout -- file // 丢弃工作区的修改 git checkout -- &lt;文件名> 场景2当你不但改乱了工作区的某个文件, 还添加到了暂存区,想丢弃修改, 分为两步, 第一步使用命令 git reset HEAD file, 就回到了场景1 , 第二步按照场景1操作. git commit 提交到本地仓库出错怎么办1. 提交信息出错更改commit 信息 git commit --amend -m \"新提交消息\" 2. 漏提交commit 时, 遗漏提交部分更新, 有两种解决方案 方案一: 再次 commit git commit -m“提交消息” 此时, git上会出现两次commit 方案二： 遗漏文件提交到之前的commit 上 git add missed-file // missed-file 为遗漏提交文件 git commit --amend --no-edit 提交错误文件,回退到上一个commit 版本, 再commitgit reset删除指定的 commit // 修改版本库，修改暂存区，修改工作区 git reset HEAD &lt;文件名> // 把暂存区的修改撤销掉（unstage），重新放回工作区。 // git版本回退，回退到特定的commit_id版本，可以通过git log查看提交历史，以便确定要回退到哪个版本(commit 之后的即为ID); git reset --hard commit_id //将版本库回退1个版本，不仅仅是将本地版本库的头指针全部重置到指定版本，也会重置暂存区，并且会将工作区代码也回退到这个版本 git reset --hard HEAD~1 // 修改版本库，保留暂存区，保留工作区 // 将版本库软回退1个版本，软回退表示将本地版本库的头指针全部重置到指定版本，且将这次提交之后的所有变更都移动到暂存区。 git reset --soft HEAD~1 git revert撤销某次操作, 此次操作之前和之后的commit 和 history 都会保留, 并且把这次撤销作为一次最近的提交。 // 撤销前一次 commit git revert HEAD // 撤销前前一次 commit git revert HEAD^ // (比如：fa042ce57ebbe5bb9c8db709f719cec2c58ee7ff）撤销指定的版本，撤销也会作为一次提交进行保存。 git revert commit git revert 和 git reset 的区别 git revert 是用一个新的commit 来回滚之前的commit,git reset是直接删除指定的 commit 在回滚这一操作上看, 效果差不多, 但是在日后继续merge 以前的老版本的时候有区别，因为 git ervert 是用一次你想的 commit 中和之前的提交, 因此日后合并老的branch时, 导致这部分改变不会再出现, 但是git reset 是之前把某些 commit 在某个branch 上删除, 因此和老的branch 再次 merge的时候, 这些被回滚的 commit 应该还会被引入. git reset是把HEAD 向后移动了一下, 而 git revert是HEAD 继续前进, 只是新的commit 内容 要和 revert 的内容正好相反, 能够抵消要被revert 的内容.","categories":[{"name":"git","slug":"git","permalink":"https://rainsoil.github.io/categories/git/"},{"name":"git","slug":"git/git","permalink":"https://rainsoil.github.io/categories/git/git/"}],"tags":[]},{"title":"centos  ftp 安装","slug":"ftp/centos  ftp 安装","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/ftp/centos-ftp-an-zhuang/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/ftp/centos-ftp-an-zhuang/","excerpt":"","text":"1. 安装VSFTPD 使用 yum 安装 yum install -y vsftpd 2. 启动 VSFTPDservice vsftpd start // 查看系统是否监听了21端口 netstat -nltp | grep 21 3. 修改配置 /etc/vsftpd/vsftpd.confanonymous_enable=NO chroot_local_user=YES chroot_local_user=YES listen_ipv6=YES userlist_enable=YES tcp_wrappers=YES pasv_min_port=30000 pasv_max_port=30999 allow_writeable_chroot=YES pam_service_name=vsftpd 4. 重启 service vsftpd restart 5. 配置登录的用户名和密码adduser -d /home/upload/ -g ftp -s /sbin/nologin beinan // 配置密码 passwd beinan 7. 开通端口 开通30000-39999 和21的端口号","categories":[{"name":"ftp","slug":"ftp","permalink":"https://rainsoil.github.io/categories/ftp/"},{"name":"ftp","slug":"ftp/ftp","permalink":"https://rainsoil.github.io/categories/ftp/ftp/"}],"tags":[]},{"title":"Springboot 整合Elasticsearch","slug":"elasticsearch/Springboot 整合Elasticsearch","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/elasticsearch/springboot-zheng-he-elasticsearch/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/elasticsearch/springboot-zheng-he-elasticsearch/","excerpt":"","text":"Springboot 整合Elasticsearch1. elasticsearch-Rest-Clientelasticserch 客户端详解 9300 tcp spring-data-elasticsearch:transport-api.jar springboot 版本不同,ransport-api.jar 不同,不能适配es 版本 7.x 已经不建议使用了,8以后就要废弃了 9200 HTTP jestClient:非官方,更新慢 RestTemplate: 模拟HTTP请求, ES 很多操作都需要自己封装 HttpClient: 同上 Elasticsearch-Rest-Client: 官方RestClient，封装了ES操作, API层次分明,上手简单 最终选择Elasticsearch-Rest-Client（elasticsearch-rest-high-level-client）；https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high.html 2. SpringBoot 整合ElasticSearch2.1 导入依赖这里的版本要和所安装的es的版本匹配 &lt;dependency> &lt;groupId>org.elasticsearch.client&lt;/groupId> &lt;artifactId>elasticsearch-rest-high-level-client&lt;/artifactId> &lt;version>7.6.2&lt;/version> &lt;/dependency> 修改 elasticsearch的版本, &lt;spring-boot-dependencies&gt; 中所依赖的版本为6.x,需要将版本改为安装的版本 2.2 编写测试类2.2.1 测试保存数据https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-document-index.html public static RestHighLevelClient restHighLevelClient() &amp;#123; return new RestHighLevelClient(RestClient.builder(new HttpHost(\"122.152.226.81\", 9200, \"http\"))); &amp;#125; @Test public void initData() throws IOException &amp;#123; IndexRequest request = new IndexRequest(\"user\"); User user = new User(); user.setName(\"张三\"); user.setAge(22); user.setCreateTime(new Date()); // 设置要保存的内容 request.source(JSON.toJSONString(user), XContentType.JSON); //执行创建索引和保存数据 IndexResponse index = restHighLevelClient().index(request, RequestOptions.DEFAULT); System.out.println(index); &amp;#125; 返回结果 IndexResponse[index=user,type=_doc,id=9kuBoHUBGfMAKZWDXKSG,version=1,result=created,seqNo=0,primaryTerm=1,shards=&amp;#123;\"total\":2,\"successful\":1,\"failed\":0&amp;#125;] 获取数据 /** * &lt;p>获取数据&lt;/p> * * @author luyanan * @since 2020/11/7 */ @Test public void getData() throws IOException &amp;#123; // 9kuBoHUBGfMAKZWDXKSG 是上步添加操作的时候返回的id GetRequest request = new GetRequest(\"user\", \"9kuBoHUBGfMAKZWDXKSG\"); GetResponse response = restHighLevelClient().get(request, RequestOptions.DEFAULT); System.out.println(response); String id = response.getId(); System.out.println(\"id:\" + id); if (response.isExists()) &amp;#123; System.out.println(\"version:\" + response.getVersion()); System.out.println(\"返回结果:\" + response.getSourceAsString()); &amp;#125; &amp;#125; 返回结果 &amp;#123;\"_index\":\"user\",\"_type\":\"_doc\",\"_id\":\"9kuBoHUBGfMAKZWDXKSG\",\"_version\":1,\"_seq_no\":0,\"_primary_term\":1,\"found\":true,\"_source\":&amp;#123;\"age\":22,\"createTime\":1604715631647,\"name\":\"张三\"&amp;#125;&amp;#125; id:9kuBoHUBGfMAKZWDXKSG version:1 返回结果:&amp;#123;\"age\":22,\"createTime\":1604715631647,\"name\":\"张三\"&amp;#125; 复杂查询 搜索address 中包含mill的所有人的年龄分布以及平均年龄, 平均薪资 GET bank/_search &amp;#123; \"query\": &amp;#123; \"match\": &amp;#123; \"address\": \"Mill\" &amp;#125; &amp;#125;, \"aggs\": &amp;#123; \"ageAgg\": &amp;#123; \"terms\": &amp;#123; \"field\": \"age\", \"size\": 10 &amp;#125; &amp;#125;, \"ageAvg\": &amp;#123; \"avg\": &amp;#123; \"field\": \"age\" &amp;#125; &amp;#125;, \"balanceAvg\": &amp;#123; \"avg\": &amp;#123; \"field\": \"balance\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; java的实现 /** * &lt;p>复杂检索:在bank中搜索address中包含mill的所有人的年龄分布以及平均年龄，平均薪资&lt;/p> * GET bank/_search * &amp;#123; * \"query\": &amp;#123; * \"match\": &amp;#123; * \"address\": \"Mill\" * &amp;#125; * &amp;#125;, * \"aggs\": &amp;#123; * \"ageAgg\": &amp;#123; * \"terms\": &amp;#123; * \"field\": \"age\", * \"size\": 10 * &amp;#125; * &amp;#125;, * \"ageAvg\": &amp;#123; * \"avg\": &amp;#123; * \"field\": \"age\" * &amp;#125; * &amp;#125;, * \"balanceAvg\": &amp;#123; * \"avg\": &amp;#123; * \"field\": \"balance\" * &amp;#125; * &amp;#125; * &amp;#125; * &amp;#125; * @author luyanan * @since 2020/11/7 */ @Test public void getData2() &amp;#123; //1. 创建检索请求 SearchRequest searchRequest = new SearchRequest(); //1.1）指定索引 searchRequest.indices(\"bank\"); //1.2）构造检索条件 SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); sourceBuilder.query(QueryBuilders.matchQuery(\"address\", \"Mill\")); //1.2.1)按照年龄分布进行聚合 TermsAggregationBuilder ageAgg = AggregationBuilders.terms(\"ageAgg\").field(\"age\").size(10); sourceBuilder.aggregation(ageAgg); //1.2.2)计算平均年龄 AvgAggregationBuilder ageAvg = AggregationBuilders.avg(\"ageAvg\").field(\"age\"); sourceBuilder.aggregation(ageAvg); //1.2.3)计算平均薪资 AvgAggregationBuilder balanceAvg = AggregationBuilders.avg(\"balanceAvg\").field(\"balance\"); sourceBuilder.aggregation(balanceAvg); System.out.println(\"检索条件：\" + sourceBuilder); searchRequest.source(sourceBuilder); //2. 执行检索 SearchResponse searchResponse = restHighLevelClient().search(searchRequest, RequestOptions.DEFAULT); System.out.println(\"检索结果：\" + searchResponse); //3. 将检索结果封装为Bean SearchHits hits = searchResponse.getHits(); SearchHit[] searchHits = hits.getHits(); for (SearchHit searchHit : searchHits) &amp;#123; String sourceAsString = searchHit.getSourceAsString(); Account account = JSON.parseObject(sourceAsString, Account.class); System.out.println(account); &amp;#125; //4. 获取聚合信息 Aggregations aggregations = searchResponse.getAggregations(); Terms ageAgg1 = aggregations.get(\"ageAgg\"); for (Terms.Bucket bucket : ageAgg1.getBuckets()) &amp;#123; String keyAsString = bucket.getKeyAsString(); System.out.println(\"年龄：\" + keyAsString + \" ==> \" + bucket.getDocCount()); &amp;#125; Avg ageAvg1 = aggregations.get(\"ageAvg\"); System.out.println(\"平均年龄：\" + ageAvg1.getValue()); Avg balanceAvg1 = aggregations.get(\"balanceAvg\"); System.out.println(\"平均薪资：\" + balanceAvg1.getValue()); &amp;#125;","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/"},{"name":"elasticsearch","slug":"elasticsearch/elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/elasticsearch/"}],"tags":[]},{"title":"Elasticserarch和kibana的安装","slug":"elasticsearch/Elasticserarch和kibana的安装","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/elasticsearch/elasticserarch-he-kibana-de-an-zhuang/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/elasticsearch/elasticserarch-he-kibana-de-an-zhuang/","excerpt":"","text":"Elasticsearch 和kibana的初体验 我们这里使用的是docker-compose 进行安装, 在安装之前, 首先需要服务器安装docker和docker-compose, 安装这些的过程这里就先不说了 1. 安装前的准备docker-compose.yml version: '3' services: elasticsearch: environment: discovery.type: \"single-node\" ES_JAVA_OPTS: '-Xms64m -Xmx512m' image: \"elasticsearch:7.6.2\" restart: always volumes: - \"./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \" - \"./data:/usr/share/elasticsearch/data\" - \"./plugins:/usr/share/elasticsearch/plugins\" ports: - \"9200:9200\" - \"9300:9300\" networks: - es7net kibana: image: kibana:7.6.2 container_name: kibana environment: - XPACK_GRAPH_ENABLED=true - TIMELION_ENABLED=true - XPACK_MONITORING_COLLECTION_ENABLED=\"true\" ports: - \"5601:5601\" networks: - es7net networks: es7net: driver: bridge 在执行docker-compose之前,先创建好docker 映射需要的一些目录,这里直接使用一个脚本代替 init.sh echo \"开始初始化es\" echo \"初始化config 目录\" mkdir ./config echo \"初始化数据目录\" mkdir ./data echo \"初始化插件目录\" mkdir ./plugins echo \"http.host: 0.0.0.0\" >./config/elasticsearch.yml echo \"添加访问权限\" chmod -R 777 ../es echo \"初始化结束,可以开始直接 docker-compose up 了\" 2. 安装先执行chmod +x init.sh 给予init.sh 脚本执行的权限, 然后执行 sh init.sh 然后启动docker-compose 进行安装即可, 在docker-compose的同级目录下执行 docker-compose up -d 然后我们使用docker ps 就可以看到 elasticsearch 和kibana 的容器启动成功了 验证 我们可以通过访问 http://ip:9200端口, 可以看到 &amp;#123; \"name\": \"0adeb7852e00\", \"cluster_name\": \"elasticsearch\", \"cluster_uuid\": \"9gglpP0HTfyOTRAaSe2rIg\", \"version\": &amp;#123; \"number\": \"7.6.2\", \"build_flavor\": \"default\", \"build_type\": \"docker\", \"build_hash\": \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\", \"build_date\": \"2020-03-26T06:34:37.794943Z\", \"build_snapshot\": false, \"lucene_version\": \"8.4.0\", \"minimum_wire_compatibility_version\": \"6.8.0\", \"minimum_index_compatibility_version\": \"6.0.0-beta1\" &amp;#125;, \"tagline\": \"You Know, for Search\" &amp;#125; 就说明 elasticsearch 已经安装成功了 访问http://ip:5601 出现页面,就说明kibana 安装成功了","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/"},{"name":"elasticsearch","slug":"elasticsearch/elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/elasticsearch/"}],"tags":[]},{"title":"Elasticsearch之基本API","slug":"elasticsearch/Elasticsearch之基本API","date":"2022-01-04T02:42:07.241Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/elasticsearch/elasticsearch-zhi-ji-ben-api/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/elasticsearch/elasticsearch-zhi-ji-ben-api/","excerpt":"","text":"Elasticsearch的基本API3. 基本API3.1 _cat3.1.1 GET _cat 查看所有的节点如: http://ip:9200/_cat/nodes, 可以看到: 172.29.0.3 21 86 55 8.33 8.23 9.08 dilm * 2162cacd6d03 注: * 表示集群中的主节点 3.1.2 GET _cat/health 查看es的健康状况访问: http://ip:9200/_cat/health,可以看到 1604546520 03:22:00 docker-cluster green 1 1 4 4 0 0 0 0 - 100.0% 注意: green 表示健康值正常 3.1.3 GET _cat/master 查看主节点访问: http://ip:9200/_cat/master , 可以看到 osm0iaKBT9qrxc5mOIsRDQ 172.29.0.3 172.29.0.3 2162cacd6d03 3.1.4 GET _cat/indices 查看所有的索引,等价于mysql 中的show databases访问: http://ip:9200/_cat/indices 可以看到 green open .kibana_task_manager_1 SXTHIO_4RsWZmTwMNshnsA 1 0 2 0 49.2kb 49.2kb green open kibana_sample_data_ecommerce caFiJ4VWSDmDkQFl6HXTRw 1 0 4675 0 5.1mb 5.1mb green open .apm-agent-configuration HPYrwMnOTB2s2vSeSMi_bQ 1 0 0 0 283b 283b green open .kibana_1 dIEll9o5TJWPNr95Bfv9pw 1 0 57 49 1.8mb 1.8mb 3.2 索引一个文档保存一个数据,保存到哪个索引下面,指定用哪个唯一标识, 如PUT customer/external/1, 表示 在customer 索引下的 external 类型下保存1号数据 &amp;#123; \"name\":\"卢亚楠\" &amp;#125; 这里可以使用POST 请求, 也可以使用PUT请求, POST 新增,如果不指定id, 会自动生成id, 指定id就会修改这个数据,并新增版本号 PUT 可以新增,也可以修改,但是PUT 必须指定id, 由于PUT必须指定id, 所以我们一般用来做更新操作,不指定id 就会报错 可以看到返回 &amp;#123; \"_index\": \"customer\", \"_type\": \"external\", \"_id\": \"1\", \"_version\": 1, \"result\": \"created\", \"_shards\": &amp;#123; \"total\": 2, \"successful\": 1, \"failed\": 0 &amp;#125;, \"_seq_no\": 0, \"_primary_term\": 1 &amp;#125; 这些返回的JSON串的含义: 这些带有下划线开头的, 称为元数据,反映了当前的基本信息. &quot;_index&quot;: &quot;customer&quot;: 表示该数据在哪个数据库下 &quot;_type&quot;: &quot;external&quot;, 表示该数据在哪个类型下 &quot;_id&quot;: &quot;1&quot;,: 说明被保存的数据的id &quot;_version&quot;: 1,:被保存的数据的版本 &quot;result&quot;: &quot;created&quot;,: 这里是创建了一条数据,如果 重新put 了一条数据, 该状态会变为updated, 并且版本号也会发生变化 3.3 查看文档GET customer/external/1 http://ip:9200/customer/external/1 返回结果: &amp;#123; \"_index\": \"customer\", // 在哪个索引中 \"_type\": \"external\", // 在那个类型下 \"_id\": \"1\", // 记录id \"_version\": 1, // 版本号 \"_seq_no\": 0, // 并发控制字段,每次更新都会加1,用来做乐观锁 \"_primary_term\": 1, // 同上,主分片重新分配,如重启,就会变化 \"found\": true, \"_source\": &amp;#123; \"name\": \"卢亚楠\" &amp;#125; &amp;#125; 通过if_seq_no=1&amp;if_primary_term=1 ,当序列号匹配的时候,才进行修改,否则不修改. 实例: 将id=1的数据, 修改为name=1,然后再次更新为name=2, 起始seq_no=0, primary_term=1 1. 将name 更新为1http://ip:9200/customer/external/1?if_seq_no=0&amp;if_primary_term=1 查看返回结果 &amp;#123; \"_index\": \"customer\", \"_type\": \"external\", \"_id\": \"1\", \"_version\": 2, \"result\": \"updated\", \"_shards\": &amp;#123; \"total\": 2, \"successful\": 1, \"failed\": 0 &amp;#125;, \"_seq_no\": 1, \"_primary_term\": 1 &amp;#125; 可以看到, _seq_no加1了 2. 将name 更新为2,更新过程中使用_seq_no=0再次调用 http://ip:9200/customer/external/1?if_seq_no=0&amp;if_primary_term=1 将参数更新为: &amp;#123; \"name\":\"2\" &amp;#125; 返回结果: &amp;#123; \"error\": &amp;#123; \"root_cause\": [ &amp;#123; \"type\": \"version_conflict_engine_exception\", \"reason\": \"[1]: version conflict, required seqNo [0], primary term [1]. current document has seqNo [1] and primary term [1]\", \"index_uuid\": \"wnn6v2lTQD23hl6ZTc2zpw\", \"shard\": \"0\", \"index\": \"customer\" &amp;#125; ], \"type\": \"version_conflict_engine_exception\", \"reason\": \"[1]: version conflict, required seqNo [0], primary term [1]. current document has seqNo [1] and primary term [1]\", \"index_uuid\": \"wnn6v2lTQD23hl6ZTc2zpw\", \"shard\": \"0\", \"index\": \"customer\" &amp;#125;, \"status\": 409 &amp;#125; 可以看到更新出现了错误 3. 查看新的数据调用 http://ip:9200/customer/external/1 &amp;#123; \"_index\": \"customer\", \"_type\": \"external\", \"_id\": \"1\", \"_version\": 2, \"_seq_no\": 1, \"_primary_term\": 1, \"found\": true, \"_source\": &amp;#123; \"name\": \"1\" &amp;#125; &amp;#125; 可以看到_seq_no 变成了1 4. 再次更新,更新成功将地址换为 http://ip:9200/customer/external/1?if_seq_no=1&amp;if_primary_term=1, 查看返回结果: &amp;#123; \"_index\": \"customer\", \"_type\": \"external\", \"_id\": \"1\", \"_version\": 3, \"result\": \"updated\", \"_shards\": &amp;#123; \"total\": 2, \"successful\": 1, \"failed\": 0 &amp;#125;, \"_seq_no\": 2, \"_primary_term\": 1 &amp;#125; 可以看到数据已经更新成功了 3.4 更新文档可以使用 POST customer/external/1/_update &amp;#123; \"doc\":&amp;#123; \"name\":\"1\" &amp;#125; &amp;#125; POST customer/external/1 &amp;#123; \"name\":\"1\" &amp;#125; PUT customer/external/1 &amp;#123; \"name\":\"1\" &amp;#125; 不同: POST操作会对比源文档数据,如果相同不会有什么操作,文档Version 不增加,PUT 操作总会将数据重新保存并且增加version` 版本 带_update 对比元数据, 如果一样,则不进行任何操作. 使用场景: 对于大并发更新,不带update 对于大并发查询偶尔更新,带update, 对比更新,重新计算分配规则 更新同时增加属性 POST /customer/external/1_update &amp;#123; \"doc\":&amp;#123; \"name\":\"2\", \"age\":\"22\" &amp;#125; &amp;#125; 3.5 删除文档或者索引DELETE customer/external/1 DELETE customer 注: elasticsearch 并没有提供删除类型的操作, 只提供了删除索引和文档的操作, 3.5.1 根据id删除 例: 删除id=1的数据,删除后继续查询` DELETE http://ip:9200/customer/external/1 返回结果: &amp;#123; \"_index\": \"customer\", \"_type\": \"external\", \"_id\": \"1\", \"_version\": 4, \"result\": \"deleted\", \"_shards\": &amp;#123; \"total\": 2, \"successful\": 1, \"failed\": 0 &amp;#125;, \"_seq_no\": 3, \"_primary_term\": 1 &amp;#125; 然后再查询, 可以看到返回 &#123; \"_index\": \"customer\", \"_type\": \"external\", \"_id\": \"1\", \"found\": false &#125; 3.5.2 删除整个索引DELETE http://ip:9200/customer 返回结果: &amp;#123; \"acknowledged\": true &amp;#125; 3.6 批量操作 bulk语法格式: &#123;action:&#123;metadata&#125;&#125;\\n &#123;request body &#125;\\n &#123;action:&#123;metadata&#125;&#125;\\n &#123;request body &#125;\\n 这里的批量操作,当发生某一条执行发生失败的时候,其他的数据仍然是可以继续执行,也就是说彼此之间是独立的, bulk api依次按顺序执行所有的action(动作), 如果一个单个的动作因为任何原因失败,它将继续处理后面剩余的动作,当bulk api 返回的时候,它将提供每个动作的状态(与发送的顺序相同) , 通过这个可以检查一个指定的动作是否失败了. 例子 执行多条数据 POST customer/external/_bulk &#123;\"index\":&#123;\"_id\":\"1\"&#125;&#125; &#123;\"name\":\"John Doe\"&#125; &#123;\"index\":&#123;\"_id\":\"2\"&#125;&#125; &#123;\"name\":\"John Doe\"&#125; 执行结果: #! Deprecation: [types removal] Specifying types in bulk requests is deprecated. &amp;#123; \"took\" : 491, \"errors\" : false, \"items\" : [ &amp;#123; \"index\" : &amp;#123; \"_index\" : \"customer\", \"_type\" : \"external\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : &amp;#123; \"total\" : 2, \"successful\" : 1, \"failed\" : 0 &amp;#125;, \"_seq_no\" : 0, \"_primary_term\" : 1, \"status\" : 201 &amp;#125; &amp;#125;, &amp;#123; \"index\" : &amp;#123; \"_index\" : \"customer\", \"_type\" : \"external\", \"_id\" : \"2\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : &amp;#123; \"total\" : 2, \"successful\" : 1, \"failed\" : 0 &amp;#125;, \"_seq_no\" : 1, \"_primary_term\" : 1, \"status\" : 201 &amp;#125; &amp;#125; ] &amp;#125; 对于整个索引执行批量操作 POST /_bulk &#123;\"delete\":&#123;\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"&#125;&#125; &#123;\"create\":&#123;\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"&#125;&#125; &#123;\"title\":\"my first blog post\"&#125; &#123;\"index\":&#123;\"_index\":\"website\",\"_type\":\"blog\"&#125;&#125; &#123;\"title\":\"my second blog post\"&#125; &#123;\"update\":&#123;\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"&#125;&#125; &#123;\"doc\":&#123;\"title\":\"my updated blog post\"&#125;&#125; 运行结果: #! Deprecation: [types removal] Specifying types in bulk requests is deprecated. &amp;#123; \"took\" : 608, \"errors\" : false, \"items\" : [ &amp;#123; \"delete\" : &amp;#123; \"_index\" : \"website\", \"_type\" : \"blog\", \"_id\" : \"123\", \"_version\" : 1, \"result\" : \"not_found\", \"_shards\" : &amp;#123; \"total\" : 2, \"successful\" : 1, \"failed\" : 0 &amp;#125;, \"_seq_no\" : 0, \"_primary_term\" : 1, \"status\" : 404 &amp;#125; &amp;#125;, &amp;#123; \"create\" : &amp;#123; \"_index\" : \"website\", \"_type\" : \"blog\", \"_id\" : \"123\", \"_version\" : 2, \"result\" : \"created\", \"_shards\" : &amp;#123; \"total\" : 2, \"successful\" : 1, \"failed\" : 0 &amp;#125;, \"_seq_no\" : 1, \"_primary_term\" : 1, \"status\" : 201 &amp;#125; &amp;#125;, &amp;#123; \"index\" : &amp;#123; \"_index\" : \"website\", \"_type\" : \"blog\", \"_id\" : \"MCOs0HEBHYK_MJXUyYIz\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : &amp;#123; \"total\" : 2, \"successful\" : 1, \"failed\" : 0 &amp;#125;, \"_seq_no\" : 2, \"_primary_term\" : 1, \"status\" : 201 &amp;#125; &amp;#125;, &amp;#123; \"update\" : &amp;#123; \"_index\" : \"website\", \"_type\" : \"blog\", \"_id\" : \"123\", \"_version\" : 3, \"result\" : \"updated\", \"_shards\" : &amp;#123; \"total\" : 2, \"successful\" : 1, \"failed\" : 0 &amp;#125;, \"_seq_no\" : 3, \"_primary_term\" : 1, \"status\" : 200 &amp;#125; &amp;#125; ] &amp;#125;","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/"},{"name":"elasticsearch","slug":"elasticsearch/elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/elasticsearch/"}],"tags":[]},{"title":"实战Spring Security Oauth2","slug":"Security/实战Spring Security Oauth2.0搭建分布式授权中心(8)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.241Z","comments":true,"path":"2022/01/04/security/shi-zhan-spring-security-oauth2.0-da-jian-fen-bu-shi-shou-quan-zhong-xin-8/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/shi-zhan-spring-security-oauth2.0-da-jian-fen-bu-shi-shou-quan-zhong-xin-8/","excerpt":"","text":"实战Spring Security Oauth2.0搭建分布式授权中心1. 需求分析技术方案如下: UAA 认证服务负责认证授权 所有的请求经过网关到达微服务 网关将负责鉴权客户端以及请求转发 网关将token 解析后传给微服务, 微服务进行授权. 2. 父工程 spring-security-oauth2-demo定义常用的一些jar的版本 pom.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;packaging>pom&lt;/packaging> &lt;properties> &lt;project.build.sourceEncoding>UTF‐8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF‐8&lt;/project.reporting.outputEncoding> &lt;java.version>1.8&lt;/java.version> &lt;/properties> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.security.oauth.boot&lt;/groupId> &lt;artifactId>spring-security-oauth2-autoconfigure&lt;/artifactId> &lt;version>2.1.3.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.security&lt;/groupId> &lt;artifactId>spring-security-jwt&lt;/artifactId> &lt;version>1.0.10.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>5.1.46&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;version>1.2.70&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>cn.hutool&lt;/groupId> &lt;artifactId>hutool-all&lt;/artifactId> &lt;version>5.3.8&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.18.12&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>Greenwich.RELEASE&lt;/version> &lt;scope>import&lt;/scope> &lt;type>pom&lt;/type> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-dependencies&lt;/artifactId> &lt;version>2.1.3.RELEASE&lt;/version> &lt;scope>import&lt;/scope> &lt;type>pom&lt;/type> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;!--子模块 --> &lt;modules> &lt;module>eureka&lt;/module> &lt;module>gateway&lt;/module> &lt;module>uaa&lt;/module> &lt;module>order&lt;/module> &lt;/modules> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>1.8&lt;/source> &lt;target>1.8&lt;/target> &lt;encoding>UTF-8&lt;/encoding> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;!--aliyun 私服配置 --> &lt;repositories> &lt;repository> &lt;id>public&lt;/id> &lt;name>aliyun nexus&lt;/name> &lt;url>http://maven.aliyun.com/nexus/content/groups/public/&lt;/url> &lt;releases> &lt;/releases> &lt;/repository> &lt;/repositories> &lt;pluginRepositories> &lt;pluginRepository> &lt;id>public&lt;/id> &lt;name>aliyun nexus&lt;/name> &lt;url>http://maven.aliyun.com/nexus/content/groups/public/&lt;/url> &lt;releases> &lt;/releases> &lt;snapshots> &lt;enabled>false&lt;/enabled> &lt;/snapshots> &lt;/pluginRepository> &lt;/pluginRepositories> &lt;/project> 3. eureka 注册中心所有的微服务的请求都经过网关,网关从注册中心读取微服务的地址,将请求转发到微服务. 本节完成注册中心的搭建,注册中心采用eureka 创建maven 工程 3.1 pom.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/parent> &lt;groupId>com.spring.security.eureka&lt;/groupId> &lt;artifactId>eureka&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>eureka&lt;/name> &lt;description>注册中心&lt;/description> &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-server&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>org.junit.vintage&lt;/groupId> &lt;artifactId>junit-vintage-engine&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>1.8&lt;/source> &lt;target>1.8&lt;/target> &lt;encoding>UTF-8&lt;/encoding> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 3.2 主启动类 EurekaApplication@EnableEurekaServer @SpringBootApplication public class EurekaApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(EurekaApplication.class, args); &amp;#125; &amp;#125; 3.3 application.yml 配置文件spring: application: name: eureka server: port: 8002 eureka: server: enable-self-preservation: false # 关闭服务器的自我保护,客户端心跳检测15分钟内错误达到80% 服务会保护,导致别人还以为是好的服务 eviction-interval-timer-in-ms: 10000 #清理间隔（单位毫秒，默认是60*1000）5秒将客户端剔除的服务在服务注册列表中剔除# use-read-only-response-cache: true #eureka是CAP理论种基于AP策略，为了保证强一致性关闭此切换CP默认不关闭 false关闭 client: register-with-eureka: false #false:不作为一个客户端注册到注册中心 fetch-registry: false #为true时，可以启动，但报异常：Cannot execute request on any known server instance-info-replication-interval-seconds: 10 service-url: defaultZone: http://localhost:$&amp;#123;server.port&amp;#125;/eureka/ instance: # hostname: $&amp;#123;spring.cloud.client.ip‐address&amp;#125; prefer-ip-address: true instance-id: $&amp;#123;spring.application.name&amp;#125;:$&amp;#123;server.port&amp;#125;&amp;#125; 3.4 测试启动成功后, 浏览器访问 http://localhost:8002/, 出现 即为搭建成功. 4. UAA 授权认证中心它承载了OAuth2.0接入方认证、登入用户的认证、授权以及生成令牌的职责，完成实际的用户认证、授权功能 4.1 pom.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/parent> &lt;groupId>com.spring.security.uaa&lt;/groupId> &lt;artifactId>uaa&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>uaa&lt;/name> &lt;description>授权认证服务&lt;/description> &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-ribbon&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;/dependency> &lt;!--认证授权相关 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-oauth2&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.security&lt;/groupId> &lt;artifactId>spring-security-jwt&lt;/artifactId> &lt;/dependency> &lt;!-- 认证授权end--> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-jdbc&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>org.junit.vintage&lt;/groupId> &lt;artifactId>junit-vintage-engine&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;/dependencies> &lt;/project> 4.2 UaaApplication 主启动类 @EnableHystrix @EnableFeignClients @EnableDiscoveryClient @SpringBootApplication public class UaaApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(UaaApplication.class, args); &amp;#125; &amp;#125; 4.3 application.yml 配置文件spring: application: name: uaa main: allow-bean-definition-overriding: true http: encoding: charset: UTF-8 enabled: true force: true datasource: url: jdbc:mysql://localhost:3306/spring-security-oauth2-demo username: root password: rootroot driver-class-name: com.mysql.jdbc.Driver mvc: throw-exception-if-no-handler-found: true resources: add-mappings: false server: port: 8000 tomcat: remote-ip-header: x‐forwarded‐for protocol-header: x‐forwarded‐proto use-forward-headers: true servlet: context-path: /uaa eureka: client: service-url: defaultZone: http://localhost:8002/eureka/ instance: prefer-ip-address: true logging: level: root: info feign: hystrix: enabled: true compression: request: enabled: true mime-types: - text/html - appliication/xml - application/json min-request-size: 2048 response: enabled: true 4.4 授权客户端和授权码sql导入 CREATE TABLE `oauth_client_details` ( `client_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '客户端标\\r\\n识', `resource_ids` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT '接入资源列表', `client_secret` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT '客户端秘钥', `scope` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `authorized_grant_types` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `web_server_redirect_uri` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `authorities` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `access_token_validity` int(11) DEFAULT NULL, `refresh_token_validity` int(11) DEFAULT NULL, `additional_information` longtext CHARACTER SET utf8 COLLATE utf8_general_ci, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `archived` tinyint(4) DEFAULT NULL, `trusted` tinyint(4) DEFAULT NULL, `autoapprove` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, PRIMARY KEY (`client_id`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC COMMENT='接入客户端信息'; INSERT INTO `oauth_client_details`(`client_id`, `resource_ids`, `client_secret`, `scope`, `authorized_grant_types`, `web_server_redirect_uri`, `authorities`, `access_token_validity`, `refresh_token_validity`, `additional_information`, `create_time`, `archived`, `trusted`, `autoapprove`) VALUES ('c1', 'res1', '$2a$10$H1wKlULSV5J9XsA9AACC9OsNtIYOaFEAH3gi5nYsIkWGkqiYLCwli', 'ROLE_ADMIN,ROLE_USER,ROLE_API', 'client_credentials,password,authorization_code,implicit,refresh_token', 'http://www.baidu.com', NULL, 7200, 259200, NULL, '2020-08-01 14:13:18', 0, 0, 'false'); CREATE TABLE `oauth_code` ( `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `authentication` blob, KEY `code_index` (`code`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT; 4.5 配置jwt的token 令牌方案@Configuration public class TokenConfig &amp;#123; private String SIGNING_KEY = \"uaa123\"; @Bean public TokenStore tokenStore() &amp;#123; // 使用内存存储令牌 return new JwtTokenStore(accessTokenConverter()); &amp;#125; @Bean public JwtAccessTokenConverter accessTokenConverter() &amp;#123; JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); //对称密钥,资源服务器使用改密钥进行验证 converter.setSigningKey(SIGNING_KEY); return converter; &amp;#125; &amp;#125; 4.6 授权服务器配置@Configuration @EnableAuthorizationServer public class AuthorizationServer extends AuthorizationServerConfigurerAdapter &amp;#123; @Autowired private TokenStore tokenStore; @Autowired private ClientDetailsService clientDetailsService; @Autowired private JwtAccessTokenConverter accessTokenConverter; public AuthorizationServerTokenServices authorizationServerTokenServices() &amp;#123; DefaultTokenServices tokenServices = new DefaultTokenServices(); tokenServices.setClientDetailsService(clientDetailsService); tokenServices.setSupportRefreshToken(true); tokenServices.setTokenStore(tokenStore); TokenEnhancerChain tokenEnhancerChain = new TokenEnhancerChain(); tokenEnhancerChain.setTokenEnhancers(Arrays.asList(accessTokenConverter)); tokenServices.setTokenEnhancer(tokenEnhancerChain); tokenServices.setAccessTokenValiditySeconds(7200);//令牌的默认有效时间 2小时 tokenServices.setRefreshTokenValiditySeconds(259200); //刷新令牌的默认有效时间3天 return tokenServices; &amp;#125; @Autowired private AuthenticationManager authenticationManager; @Autowired private AuthorizationCodeServices authorizationCodeServices; /** * &lt;p>令牌访问端点&lt;/p> * * @param endpoints * @author luyanan * @since 2020/7/30 */ @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &amp;#123; endpoints.authenticationManager(authenticationManager) .authorizationCodeServices(authorizationCodeServices) .tokenServices(authorizationServerTokenServices()) .allowedTokenEndpointRequestMethods(HttpMethod.POST); &amp;#125; @Bean public PasswordEncoder passwordEncoder() &amp;#123; return new BCryptPasswordEncoder(); &amp;#125; @Bean public ClientDetailsService clientDetailsService(DataSource dataSource) &amp;#123; ClientDetailsService clientDetailsService = new JdbcClientDetailsService(dataSource); ((JdbcClientDetailsService) clientDetailsService).setPasswordEncoder(passwordEncoder()); return clientDetailsService; &amp;#125; @Bean public AuthorizationCodeServices authorizationCodeServices(DataSource dataSource) &amp;#123; // 设置授权码模式的授权码如何存储, 暂时采用内存存储的方式 // return new InMemoryAuthorizationCodeServices(); return new JdbcAuthorizationCodeServices(dataSource); &amp;#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &amp;#123; clients.withClientDetails(clientDetailsService); // clients.inMemory()// 使用in‐memory存储 // .withClient(\"c1\")// client_id // .secret(new BCryptPasswordEncoder().encode(\"secret\")) // .resourceIds(\"res1\") // .authorizedGrantTypes(\"authorization_code\", // \"password\", \"client_credentials\", \"implicit\", \"refresh_token\")// 该client允许的授权类型 authorization_code,password,refresh_token,implicit,client_credentials // .scopes(\"all\")// 允许的授权范围 // .autoApprove(false) ////加上验证回调地址 // .redirectUris(\"http://www.baidu.com\"); &amp;#125; //令牌端点安全约束 @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &amp;#123; security.tokenKeyAccess(\"permitAll()\") //(1) .checkTokenAccess(\"permitAll()\") //(2) .allowFormAuthenticationForClients();//(3) &amp;#125; &amp;#125; 4.7 安全配置@Configuration @EnableGlobalMethodSecurity(securedEnabled = true, prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; @Bean public UserDetailsService userDetailsService() &amp;#123; UserDetails zhangsan = User.withUsername(\"zhangsan\").password(passwordEncoder().encode(\"123\")).authorities(\"p1\").build(); UserDetails lisi = User.withUsername(\"lisi\").password(passwordEncoder().encode(\"123\")).authorities(\"p2\").build(); UserDetailsManager userDetailsManager = new InMemoryUserDetailsManager(); userDetailsManager.createUser(zhangsan); userDetailsManager.createUser(lisi); return userDetailsManager; &amp;#125; @Bean public PasswordEncoder passwordEncoder() &amp;#123; return new BCryptPasswordEncoder(); &amp;#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &amp;#123; return super.authenticationManagerBean(); &amp;#125; // 安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.csrf().disable() .authorizeRequests() .antMatchers(\"/login\").permitAll() .anyRequest().authenticated() .and().formLogin(); &amp;#125; &amp;#125; 5 . 网关网关整个Oauth2.0 有两种思路, 一种是认证服务器生成jwt 令牌, 所有请求统一在网络层验证,判断权限等操作,另一种是由各资源服务处理,网关只做请求转发. 我们选用第一种,我们把API 网关作为Oauth2.0的资源服务器角色,实现接入客户端权限拦截,令牌解析并转发当前登陆用户信息(jsonToken ) 给微服务,这样下游微服务就不需要关心令牌格式解析以及Oauth2.0 的相关机制. API网关在认证授权体系里面主要负责两件事情: 作为Oauth2.0的资源服务角色,实现接入方权限拦截 令牌解析并转发当前登陆用户信息(明文token) 给微服务 微服务拿到明文token(明文token中包含登陆用户的身份和权限信息) 后也需要做两件事情: 用户授权拦截(看当前用户是否有权限访问该资源) 将用户信息存储进当前线程上下文(有利于后续业务逻辑随时获取当前用户信息) 5.1 pom.xml 依赖&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/parent> &lt;groupId>com.spring.security.gateway&lt;/groupId> &lt;artifactId>gateway&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>gateway&lt;/name> &lt;description>服务网关&lt;/description> &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>cn.hutool&lt;/groupId> &lt;artifactId>hutool-all&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-oauth2&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.security&lt;/groupId> &lt;artifactId>spring-security-jwt&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-ribbon&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-zuul&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>org.junit.vintage&lt;/groupId> &lt;artifactId>junit-vintage-engine&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>1.8&lt;/source> &lt;target>1.8&lt;/target> &lt;encoding>UTF-8&lt;/encoding> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 5.2 主启动类@EnableZuulProxy @EnableDiscoveryClient @SpringBootApplication public class GatewayApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(GatewayApplication.class, args); &amp;#125; &amp;#125; 5.3 application.yml 配置文件spring: application: name: gateway main: allow-bean-definition-overriding: true server: port: 8004 zuul: retryable: true ignored-services: \"*\" add-host-header: true sensitive-headers: \"*\" routes: uaa: stripPrefix: false path: /uaa/** order: stripPrefix: false path: /order/** eureka: client: service-url: defaultZone: http://localhost:8002/eureka/ instance: prefer-ip-address: true management: endpoints: web: exposure: include: refresh,health,info,env feign: hystrix: enabled: true compression: request: enabled: true mime-types: - text/html - appliication/xml - application/json min-request-size: 2048 response: enabled: true 5.4 资源服务配置@Configuration public class ResourceServerConfig &amp;#123; public static final String RESOURCE_ID = \"res1\"; /** * uaa的资源拦截 */ @Configuration @EnableResourceServer public class UaaServerConfig extends ResourceServerConfigurerAdapter &amp;#123; @Autowired private TokenStore tokenStore; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &amp;#123; resources.tokenStore(tokenStore) .resourceId(RESOURCE_ID).stateless(true); &amp;#125; @Override public void configure(HttpSecurity http) throws Exception &amp;#123; http.authorizeRequests().antMatchers(\"/uaa/**\").permitAll(); &amp;#125; &amp;#125; /** * 订单服务资源拦截 */ @Configuration @EnableResourceServer public class OrderServerConfig extends ResourceServerConfigurerAdapter &amp;#123; @Autowired private TokenStore tokenStore; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &amp;#123; resources.resourceId(RESOURCE_ID).tokenStore(tokenStore).stateless(true); &amp;#125; @Override public void configure(HttpSecurity http) throws Exception &amp;#123; http.authorizeRequests().antMatchers(\"/order/**\").access(\"#oauth2.hasScope('ROLE_API')\"); &amp;#125; &amp;#125; &amp;#125; 5.5 令牌配置@Configuration public class TokenConfig &amp;#123; private String SIGNING_KEY = \"uaa123\"; @Bean public TokenStore tokenStore() &amp;#123; // 使用内存存储令牌 return new JwtTokenStore(accessTokenConverter()); &amp;#125; @Bean public JwtAccessTokenConverter accessTokenConverter() &amp;#123; JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); //对称密钥,资源服务器使用改密钥进行验证 converter.setSigningKey(SIGNING_KEY); return converter; &amp;#125; &amp;#125; 5.6 安全配置@Configuration @EnableGlobalMethodSecurity(prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; //安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http .authorizeRequests() .antMatchers(\"/**\") .permitAll() .and() .csrf() .disable(); &amp;#125; &amp;#125; 5.7 过滤器配置编写过滤器, 将解析后的明文token 放入header 中转发至内部服务 public class AuthFilter extends ZuulFilter &amp;#123; @Override public String filterType() &amp;#123; return \"pre\"; &amp;#125; @Override public int filterOrder() &amp;#123; return 0; &amp;#125; @Override public boolean shouldFilter() &amp;#123; return true; &amp;#125; @Override public Object run() throws ZuulException &amp;#123; //1. 获取令牌内容 RequestContext ctx = RequestContext.getCurrentContext(); Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (!(authentication instanceof OAuth2Authentication)) &amp;#123; // 无token 访问资源的情况,目前只有`uaa` 服务直接暴露 return null; &amp;#125; OAuth2Authentication oAuth2Authentication = (OAuth2Authentication) authentication; Authentication userAuthentication = oAuth2Authentication.getUserAuthentication(); Object principal = userAuthentication.getPrincipal(); // 2. 组装明文token,转发给内部服务,放入header中,名称为 json-token List&lt;String> authorities = new ArrayList&lt;>(); userAuthentication.getAuthorities().stream().forEach(a -> &amp;#123; authorities.add(((GrantedAuthority) a).getAuthority()); &amp;#125;); OAuth2Request oAuth2Request = oAuth2Authentication.getOAuth2Request(); Map&lt;String, String> requestParameters = oAuth2Request.getRequestParameters(); Map&lt;String, Object> jsonToken = new HashMap&lt;>(requestParameters); if (null != userAuthentication) &amp;#123; jsonToken.put(\"principal\", userAuthentication.getName()); jsonToken.put(\"authorities\", authorities); &amp;#125; ctx.addZuulRequestHeader(\"json-token\", URLUtil.encode(JSON.toJSONString(jsonToken), \"utf-8\")); return null; &amp;#125; &amp;#125; 5.8 配置类将编写的过滤器注册成Bean和配置CORS @Configuration public class ZuulConfig &amp;#123; @Bean public AuthFilter authFilter() &amp;#123; return new AuthFilter(); &amp;#125; @Bean public FilterRegistrationBean corsFilter() &amp;#123; final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); final CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.addAllowedOrigin(\"*\"); config.addAllowedHeader(\"*\"); config.addAllowedMethod(\"*\"); config.setMaxAge(18000L); source.registerCorsConfiguration(\"/**\", config); CorsFilter corsFilter = new CorsFilter(source); FilterRegistrationBean bean = new FilterRegistrationBean(corsFilter); bean.setOrder(Ordered.HIGHEST_PRECEDENCE); return bean; &amp;#125; &amp;#125; 6. Order 资源服务本工程为Order订单服务工程，访问本工程的资源需要认证通过。 本工程的目的主要是测试认证授权的功能，所以不涉及订单管理相关业务 6.1 pom.xml 依赖&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/parent> &lt;groupId>com.spring.security.order&lt;/groupId> &lt;artifactId>order&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>order&lt;/name> &lt;description>订单模块&lt;/description> &lt;dependencies> &lt;dependency> &lt;groupId>cn.hutool&lt;/groupId> &lt;artifactId>hutool-all&lt;/artifactId> &lt;/dependency> &lt;!-- 认证授权相关--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-oauth2&lt;/artifactId> &lt;/dependency> &lt;!-- &lt;dependency>--> &lt;!-- &lt;groupId>org.springframework.boot&lt;/groupId>--> &lt;!-- &lt;artifactId>spring-boot-starter-jdbc&lt;/artifactId>--> &lt;!-- &lt;/dependency>--> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-ribbon&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>org.junit.vintage&lt;/groupId> &lt;artifactId>junit-vintage-engine&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>1.8&lt;/source> &lt;target>1.8&lt;/target> &lt;encoding>UTF-8&lt;/encoding> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 6.2 主启动类@EnableHystrix @EnableFeignClients @EnableDiscoveryClient @SpringBootApplication public class OrderApplication &amp;#123; public static void main(String[] args) &amp;#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(OrderApplication.class, args); &amp;#125; &amp;#125; 6.3 application.yml 配置文件server: port: 8001 tomcat: remote-ip-header: x‐forwarded‐for protocol-header: x‐forwarded‐proto use-forward-headers: true servlet: context-path: /order spring: application: name: order main: allow-bean-definition-overriding: true http: encoding: charset: UTF-8 enabled: true force: true datasource: url: jdbc:mysql://localhost:3306/spring-security-oauth2-demo username: root password: rootroot driver-class-name: com.mysql.jdbc.Driver mvc: throw-exception-if-no-handler-found: true resources: add-mappings: false eureka: client: service-url: defaultZone: http://localhost:8002/eureka/ instance: prefer-ip-address: true management: endpoints: web: exposure: include: refresh,health,info,env feign: hystrix: enabled: true compression: request: enabled: true mime-types: - text/html - appliication/xml - application/json min-request-size: 2048 response: enabled: true 6.4 令牌配置@Configuration public class TokenConfig &amp;#123; private String SIGNING_KEY = \"uaa123\"; @Bean public TokenStore tokenStore() &amp;#123; // 使用内存存储令牌 return new JwtTokenStore(accessTokenConverter()); &amp;#125; @Bean public JwtAccessTokenConverter accessTokenConverter() &amp;#123; JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); //对称密钥,资源服务器使用改密钥进行验证 converter.setSigningKey(SIGNING_KEY); return converter; &amp;#125; &amp;#125; 6.5 资源服务配置@Configuration @EnableResourceServer @EnableGlobalMethodSecurity(prePostEnabled = true) public class ResourceServerConfig extends ResourceServerConfigurerAdapter &amp;#123; @Autowired private TokenStore tokenStore; public static final String RESOURCE_ID = \"res1\"; /** * 资源服务令牌解析服务 * * @return */ // @Bean // public ResourceServerTokenServices tokenServices() &amp;#123; // // //使用远程服务请求授权服务器校验token , 必须指定校验token 的url,client_id,client_secret // RemoteTokenServices services = new RemoteTokenServices(); // services.setCheckTokenEndpointUrl(\"http://localhost:8000/uaa/oauth/check_token\"); // // services.setClientId(\"c1\"); // services.setClientSecret(\"secret\"); // return services; // &amp;#125; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &amp;#123; resources.resourceId(RESOURCE_ID) .tokenStore(tokenStore) .stateless(true); &amp;#125; @Override public void configure(HttpSecurity http) throws Exception &amp;#123; http.authorizeRequests() .antMatchers(\"/**\") .access(\"#oauth2.hasScope('ROLE_ADMIN')\") .and() .csrf() .disable() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS); &amp;#125; &amp;#125; 6.6 web安全配置@Configuration @EnableGlobalMethodSecurity(prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; //安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.csrf().disable() .authorizeRequests() .antMatchers(\"/**\").authenticated()// 所有r/**的请求都必须通过认证 .anyRequest().permitAll(); // 除了r/r** 之外的请求都放行 &amp;#125; &amp;#125; 6.7 token拦截器定义filter拦截token，并形成Spring Security的Authentication对象 @Component public class TokenAuthenticationFilter extends OncePerRequestFilter &amp;#123; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &amp;#123; String token = request.getHeader(\"json-token\"); if (null != token) &amp;#123; // 1. 解析token String decode = URLUtil.decode(token, \"utf-8\"); JSONObject userJson = JSON.parseObject(decode); UserEntity userEntity = new UserEntity(); userEntity.setUsername(userJson.getString(\"principal\")); JSONArray authoritiesArray = userJson.getJSONArray(\"authorities\"); String[] authorities = authoritiesArray.toArray(new String[authoritiesArray.size()]); // 2. 新建并填充 authentication UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(userEntity, null, AuthorityUtils.createAuthorityList(authorities)); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 3.将authentication 保存到上下文中 SecurityContextHolder.getContext().setAuthentication(authenticationToken); &amp;#125; filterChain.doFilter(request, response); &amp;#125; &amp;#125; 6.8 编写资源UserEntity @Data @Builder @AllArgsConstructor @NoArgsConstructor public class UserEntity &amp;#123; private String username; private String password; &amp;#125; OrderController @RestController public class OrderController &amp;#123; @GetMapping(\"r1\") @PreAuthorize(\"hasAnyAuthority('p1')\") public String r1() &amp;#123; UserEntity userEntity = (UserEntity) SecurityContextHolder.getContext().getAuthentication().getPrincipal(); return userEntity.getUsername() + \":访问r1资源\"; &amp;#125; @GetMapping(\"r2\") @PreAuthorize(\"hasAnyAuthority('p2')\") public String r2() &amp;#123; UserEntity userEntity = (UserEntity) SecurityContextHolder.getContext().getAuthentication().getPrincipal(); return userEntity.getUsername() + \":访问r2资源\"; &amp;#125; &amp;#125; 7 集成测试本案例测试过程的描述 采用Oauth2.0 的密码模式从UAA 获取到token 使用该token 通过网关访问订单服务中的测试资源 7.1 token 获取访问http://localhost:8004/uaa/oauth/token, 注意:此处的端口为网关的端口 返回内容: &amp;#123; \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbIlJPTEVfQURNSU4iLCJST0xFX1VTRVIiLCJST0xFX0FQSSJdLCJleHAiOjE1OTYyNzA1NTAsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6ImE1ODFkN2JiLWQ3ZmQtNDc3Yi1hNWM0LTgxN2UwOGQ4N2QzYiIsImNsaWVudF9pZCI6ImMxIn0.AkD2rd8AnAst2gv0KdwkNta6d0Hy1tz-qNO-euMmHkw\", \"token_type\": \"bearer\", \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbIlJPTEVfQURNSU4iLCJST0xFX1VTRVIiLCJST0xFX0FQSSJdLCJhdGkiOiJhNTgxZDdiYi1kN2ZkLTQ3N2ItYTVjNC04MTdlMDhkODdkM2IiLCJleHAiOjE1OTY1MjI1NTAsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6Ijg5NTIyMjA0LWUwYTgtNDNiNy1hYWM4LTUzMWUyNWEyZTYzMSIsImNsaWVudF9pZCI6ImMxIn0.tbtuWBgYZfBiAZLdwZq27CqFwW5PyytEcbQfSpjxHXo\", \"expires_in\": 7199, \"scope\": \"ROLE_ADMIN ROLE_USER ROLE_API\", \"jti\": \"a581d7bb-d7fd-477b-a5c4-817e08d87d3b\" &amp;#125; 携带token 访问Order 资源访问路径为:http://localhost:8004/order/r1 发现可以访问成功. 使用token 访问r2 资源, 由于r2 资源需要p2的权限 所以: 破坏测试无token 访问测试返回内容 &amp;#123; \"error\": \"unauthorized\", \"error_description\": \"Full authentication is required to access this resource\" &amp;#125; 破坏token访问测试返回内容 &amp;#123; \"error\": \"invalid_token\", \"error_description\": \"Cannot convert access token to JSON\" &amp;#125; 8. 扩展用户信息8.1 需求分析目前jwt 用户中存储了用户的身份信息,权限信息,网关将token 明文转发给微服务使用, 目前用户身份信息仅包含了用户的账号,微服务还需要用户的id, 手机号等其他的信息 所以,本案例将提供扩展用户的思路和方法,满足为服务使用用户信息的需求. 下面分析JWT 令牌中扩展用户信息的方案: 在认证阶段DaoAuthenticationProvider 会调用UserDetailService 查询用户信息,这里是可以获取到齐全的用户信息的, 由于JWT 令牌中的用户身份信息来源子UserDetails,UserDetails 中仅仅定义了username 为用户的身份信息,这里有两个思路: 第一是可以扩展UserDetails,使之可以包含更多的自定义属性 第二种是扩展username的内容, 比如存入json 作为username 的内容 相比较而言,第二种方案比较简单还不用破坏UserDetails 的结构,我们采用方案二. 8.2 修改 UserDetailService从数据库查询到user, 将整体user存入到UserDetails对象中., // 这里还是模拟使用虚拟用户, 不从数据库中查询 修改用户的实体, 增加 @Data @Builder @AllArgsConstructor @NoArgsConstructor public class UserEntity &amp;#123; private String id; private String username; private String password; private String mobile; &amp;#125; 增加自定义的ConsumerUserDetailsService @Service public class ConsumerUserDetailsService implements UserDetailsService &amp;#123; @Autowired private PasswordEncoder passwordEncoder; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException &amp;#123; UserEntity zhangsan = UserEntity.builder().id(\"1\").username(\"zhangsan\").password(passwordEncoder.encode(\"123\")).mobile(\"18111111111\").build(); return User.withUsername(JSON.toJSONString(zhangsan)).password(zhangsan.getPassword()).authorities(\"p1\").build(); &amp;#125; &amp;#125; 修改 WebSecurityConfig @Configuration @EnableGlobalMethodSecurity(securedEnabled = true, prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; @Bean public PasswordEncoder passwordEncoder() &amp;#123; return new BCryptPasswordEncoder(); &amp;#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &amp;#123; return super.authenticationManagerBean(); &amp;#125; // 安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.csrf().disable() .authorizeRequests() .antMatchers(\"/login\").permitAll() .anyRequest().authenticated() .and().formLogin(); &amp;#125; &amp;#125; 8.3 修改资源服务过滤器TokenAuthenticationFilter @Component public class TokenAuthenticationFilter extends OncePerRequestFilter &amp;#123; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &amp;#123; String token = request.getHeader(\"json-token\"); if (null != token) &amp;#123; // 1. 解析token String decode = URLUtil.decode(token, \"utf-8\"); JSONObject userJson = JSON.parseObject(decode); String principal = userJson.getString(\"principal\"); UserEntity userEntity = JSON.parseObject(principal, UserEntity.class); JSONArray authoritiesArray = userJson.getJSONArray(\"authorities\"); String[] authorities = authoritiesArray.toArray(new String[authoritiesArray.size()]); // 2. 新建并填充 authentication UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(userEntity, null, AuthorityUtils.createAuthorityList(authorities)); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); // 3.将authentication 保存到上下文中 SecurityContextHolder.getContext().setAuthentication(authenticationToken); &amp;#125; filterChain.doFilter(request, response); &amp;#125; &amp;#125; 以上过程就完成自定义用户信息的方案","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"基于Spring Security认证授权(3)","slug":"Security/基于Spring Security认证授权(3)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.237Z","comments":true,"path":"2022/01/04/security/ji-yu-spring-security-ren-zheng-shou-quan-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/ji-yu-spring-security-ren-zheng-shou-quan-3/","excerpt":"","text":"基于Spring Security 认证授权1. 介绍Spring Security 是一个能够为基于Spring的企业应用系统提升声明式的安全访问控制解决方案的安全框架.由于他是Spring 生态系统中的一员,因为他伴随着整个Spring 生态系统的不断修正、升级,在Spring Boot 项目中加入Spring Security 更是十分简单,使用Spring Security 减少了为企业系统安全控制编写了大量重复代码的工作. 2. 实战2.1 pom依赖 &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.2.1.RELEASE&lt;/version> &lt;/parent> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-thymeleaf&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.18.12&lt;/version> &lt;/dependency> &lt;/dependencies> 2.2 安全配置Spring Security 提供了用户名密码登陆、退出、会话管理等认证功能,只需要简单配置就可以使用. 在config 包下定义WebSecurityConfig， 安全配置的内容包括: 用户信息、密码编码器、安全拦截机制. @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; // 配置用户信息 @Bean public UserDetailsService userDetailsService() &amp;#123; InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(\"zhangsan\").password(\"123456\").authorities(\"p1\").build()); manager.createUser(User.withUsername(\"lisi\").password(\"123456\").authorities(\"p2\").build()); return manager; &amp;#125; // 密码编码器 @Bean public PasswordEncoder passwordEncoder() &amp;#123; return NoOpPasswordEncoder.getInstance(); &amp;#125; // 配置安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.authorizeRequests() .antMatchers(\"/r/**\").authenticated() .anyRequest().permitAll() .and() .formLogin().successForwardUrl(\"/login-success\"); &amp;#125; &amp;#125; 在userDetailsService() 方法中,我们返回了一个UserDetailsService 给Spring 容器, Spring Security 会使得他来获取用户信息,我们暂时使用InMemoryUserDetailsManager 实现类,基于内存实现,并在启动创建了zhangsan、lisi 两个用户, 并设置密码和权限. 而在com.spring.security.config.WebSecurityConfig#configure 中,我们通过HttpSecurity 设置了安全拦截规则,其中包含了以下内容： url 匹配/r/** 的资源,经过认证后才能访问. 其他url 完全开放 支持form 表单认证, 认证成功后跳转到/login-success 页面 2.3 编写LoginController@Controller public class LoginController &amp;#123; @ResponseBody @GetMapping(\"login-success\") public String loginSuccess() &amp;#123; return \"登陆成功\"; &amp;#125; &amp;#125; 2.4 测试 启动项目, 访问 http://localhost:8080/login, 可以看到Spring Security 为我们提供的登陆页面 登陆测试 当我们输入错误的账号密码的时候, 输入正确的账号密码则会登陆成功 退出 请求/logout 接口退出 3. 授权实现授权只需要对用户的访问进行拦截校验,校验用户的权限是否可以操作指定的资源,Spring Security 默认提供了授权实现方法. 在LoginController中添加r/r1 和r/r2 接口 @ResponseBody @GetMapping(\"/r/r1\") public String r1() &amp;#123; return \"访问r1的资源\"; &amp;#125; @ResponseBody @GetMapping(\"/r/r2\") public String r2() &amp;#123; return \"访问r2的资源\"; &amp;#125; 在安全配置类WebSecurityConfig 中添加授权规则 // 配置安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.authorizeRequests() //访问/r/r1资源的 url需要拥有p1权限。 .antMatchers(\"/r/r1\").hasAuthority(\"p1\") //访问/r/r2资源的 url需要拥有p2权限。 .antMatchers(\"/r/r2\").hasAuthority(\"p2\") .antMatchers(\"/r/**\").authenticated() .anyRequest().permitAll() .and() .formLogin().successForwardUrl(\"/login‐success\"); &amp;#125; 测试: 当账号密码输入成功的时候, 则登陆成功. 访问r/r1和/r/r2, 有权限的时候则正常访问, 否则则返回403(拒绝访问)","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"基于Session进行认证(2)","slug":"Security/基于Session进行认证(2)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.237Z","comments":true,"path":"2022/01/04/security/ji-yu-session-jin-xing-ren-zheng-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/ji-yu-session-jin-xing-ren-zheng-2/","excerpt":"","text":"基于Session进行认证1. 认证流程用户认证成功后,在服务端生成用户相关的数据, 并保存在session 会话中,而发给客户端的session_id 保存在浏览器的cookie中, 当客户端请求的时候带上session_id ,服务端就可以通过验证session_id是否存在和session 数据来完成用户的合法性校验了. 当用户退出系统或者session 销毁的时候, 只需要清空会话的session 即可. 这样客户端的session_id也就无效了. 基于session的认证机制是由Servlet 规范定制的,servlet已经实现,用户可以通过HttpSession 的操作方法就可以实现,如下是HttpSession 相关的操作API 方法 含义 HttpSession getSession(Boolean create) 获取当前的session对象 void setAttribute(String name,Object value) 往session 中存放数据 object getAttribute(String name) 从session中获取数据 void removeAttribute(String name); 移除session对象 void invalidate() 使得HttpSession失效 2. 案例演示本案例使用Maven 和SpringBoot 进行实现 pom.xml依赖 &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.2.1.RELEASE&lt;/version> &lt;/parent> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-thymeleaf&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 启动类SecurityApplication /** * @author luyanan * @since 2020/7/22 * &lt;p>启动类&lt;/p> **/ @SpringBootApplication public class SecurityApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(SecurityApplication.class, args); &amp;#125; &amp;#125; 控制层UserController,这里使用的是假数据做的登录 /** * @author luyanan * @since 2020/7/22 * &lt;p>用户的控制层和&lt;/p> **/ @Controller public class UserController &amp;#123; static Map&lt;String, String> users = new HashMap&lt;>(); static &amp;#123; users.put(\"zhangsan\", \"123456\"); users.put(\"lisi\", \"234567\"); &amp;#125; @Autowired private HttpSession httpSession; /** * &lt;p>登陆页面&lt;/p> * * @return &amp;#123;@link String&amp;#125; * @author luyanan * @since 2020/7/22 */ @GetMapping(\"login\") public String index() &amp;#123; return \"login\"; &amp;#125; /** * &lt;p>登陆接口&lt;/p> * * @param userName * @param passWord * @return &amp;#123;@link String&amp;#125; * @author luyanan * @since 2020/7/22 */ @ResponseBody @PostMapping(\"login\") public String login(String userName, String passWord) &amp;#123; Assert.hasText(userName, \"用户名为空\"); Assert.hasText(passWord, \"密码为空\"); String s = users.get(userName); if (null == s) &amp;#123; throw new RuntimeException(\"用户不存在\"); &amp;#125; if (!passWord.equals(s)) &amp;#123; throw new RuntimeException(\"密码不正确\"); &amp;#125; httpSession.setAttribute(\"name\", userName); return userName + \":登陆成功\"; &amp;#125; /** * &lt;p>个人详情&lt;/p> * * @return &amp;#123;@link String&amp;#125; * @author luyanan * @since 2020/7/22 */ @ResponseBody @GetMapping(\"info\") public String info() &amp;#123; Object name = httpSession.getAttribute(\"name\"); return Optional.ofNullable(name).orElse(\"匿名\") + \":访问info\"; &amp;#125; /** * &lt;p>注销&lt;/p> * * @return &amp;#123;@link String&amp;#125; * @author luyanan * @since 2020/7/22 */ @ResponseBody @GetMapping(\"logout\") public void logout() &amp;#123; httpSession.invalidate(); &amp;#125; &amp;#125; 里面编写了四个接口,分别为跳转登陆页面、登陆、用户信息(当用户登陆的时候,则会返回用户名称+访问,否则为匿名访问)、注销接口 application.yml spring: application: name: session thymeleaf: mode: HTML 登陆页面 login.html &lt;!DOCTYPE html> &lt;html lang=\"en\"> &lt;head> &lt;meta charset=\"UTF-8\"> &lt;title>登陆&lt;/title> &lt;/head> &lt;body> &lt;div> &lt;form action=\"/login\" method=\"post\"> &lt;input type=\"text\" name=\"userName\" placeholder=\"用户名\"> &lt;input type=\"password\" name=\"passWord\" placeholder=\"密码\"> &lt;button type=\"submit\">登陆&lt;/button> &lt;/form> &lt;/div> &lt;/body> &lt;/html> 最后的目录结构为 : 启动项目, 访问路径进行测试 不登陆的情况 当我们直接访问/info接口的时候 发现为匿名用户访问,说明用户没有登陆 登陆测试 我们访问/login 页面 输入账号密码之后,发现 显示张三登陆成功,再次访问/info 发现我们已经获取到登陆用户的名称, 然后调用注销的接口/logout 再次访问/info 发现又变成了匿名用户登陆了,这就完成了基于session的认证","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"分布式系统认证(6)","slug":"Security/分布式系统认证(6)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.237Z","comments":true,"path":"2022/01/04/security/fen-bu-shi-xi-tong-ren-zheng-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/fen-bu-shi-xi-tong-ren-zheng-6/","excerpt":"","text":"分布式系统认证方案1. 什么是分布式系统随着软件环境和需求的变化,软件的架构由单体结构演变为分布式架构,具有分布式架构的系统叫做分布式系统, 分布式系统的运行通常依靠网络, 他将单体结构的系统分为若干服务, 服务之间通过网络交互来完成用户的业务处理, 当前流行的微服务架构就是分布式系统的结构,如下图: 分布式系统具体如下基本特点: 分布式: 每个部分都可以独立部署,服务之间交互通过网络进行通信,比如:订单服务、商品服务 伸缩性: 每个部分都可以集群方式部署,并可针对部分节点进行硬件和软件扩容,具有一定的伸缩能力, 共享性: 每个部分都可以作为共享资源并对外提供服务,多个部分可能有操作共享资源的情况 开放性: 每个部分根据需求都可以对外发布共享资源的访问接口, 并可允许第三方系统访问. 2 分布式纷争需求分布式系统的每个服务的都会有认证,授权的需求，如果每个服务都实现一套认证授权逻辑会非常冗余,考虑到分布式系统共享性的特点,需要由独立的认证服务处理系统认证授权的请求,考虑分布式系统开放性的特点,不仅对系统内部服务提供认证,对第三放系统也要提供认证. 分布式认证的需求如下: 2.1 统一认证授权提供独立的认证服务,统一处理认证授权 无论是不同类型的用户,还是不同种类的客户端(web端,H5、APP),均采用一致的认证,权限、会话机制,实现统一认证授权. 要实现统一则认证方式必须可扩展,支持各种认证需求,比如:用户名密码认证、短信验证码、二维码、人脸识别等认证方式,并可以非常灵活的却换, 2.2 应用接入认证应提供扩展和开放能力,提供安全的系统对接机制,并可开放部分API给接入第三方使用,一方应用(内部系统服务)和三方应用(第三方应用) 均采用统一机制接入. 3. 分布式认证方案3.1 选型分析3.1.1 基于session 的认证方式在分布式环境下,基于session 的认证会出现一个问题,每个应用服务都需要在session 中存储用户身份信息,通过负载均衡将本地的请求分配到另外一个应用服务需要将session 信息带过去,否则会重新认证 这个时候,通常的做法有下面几种: session复制: 多台应用服务器之间同步session, 使session 保持一致,对外透明 session 黏贴: 当用户访问集群中某台服务器后,强制指定后续所有请求均落到此机器上. session 集中存储: 将session 存入分布式缓存中, 所有服务器应用实例统一从分布式缓存中存取session 总体来说,基于session 认证的认证方式, 可以更好的在服务端对会话进行控制, 且安全性较高。但是,session 机制方式基于cookie, 在复杂多样的移动客户端上不能有效的使用,并且无法跨域,另外随着系统的扩展需提高session的复制、黏贴、存储的容错性. 3.1.2 基于token的认证方式基于token的认证方式,服务端不用存储认证数据,易维护扩展性强, 客户端可以把token 存在任意地方,并且可以实现web 和app 统一认证机制. 其缺点也很明显,token由于自包含信息,因此一般数据量较大, 并且每次请求都需要传递,因此比较占带宽. 另外，token 的签名验签操作也会给cpu 带来额外的处理负担. 3.2 技术方案根据选型的分析,一般采用基于token的认证方式,它的优点是: 适合统一认证的机制, 客户端、一方应用、三方应用都遵循一致的认证方案 token认证方式对第三方应用接入更适合,因为它更开放, 可使用当前有流行的开放协议Oauth2.0、JWT等. 一般情况服务端无需存储会话信息,减轻了服务端的压力. 分布式系统认证技术方案见下图: 流程描述: 用户通过接入方(应用)登陆, 接入方采用Oauth2.0方式 在统一认证服务(UAA) 中认证 认证服务(UAA) 调用验证该用户的身份是否合法, 并获取用户权限信息 认证服务(UAA) 获取接入方权限信息,并验证接入方是否合法. 若登陆用户以及接入方都合法,认证服务生成jwt 令牌返回给接入方,其中jwt 中包含了用户权限以及接入方权限. 后续, 接入方携带jwt 令牌对API 网关内的微服务资源进行访问. API 网关对令牌解析,并验证接入方的权限是否能够访问本次请求的微服务 如果接入方的权限没有问题,API网关将原请求header 中附加解析后的明文token,并将请求转发至微服务 微服务收到请求,明文token 中包含登录用户的身份信息和权限信息,因此后续微服务自己可以干两件事情: 用户授权拦截(看当前用户是否有权限访问该资源) 将用户信息存储到当前线程上下文中(有利于后续业务逻辑随时获取当前用户信息) 流程所涉及到UAA服务、API 网关服务、这些组件的职责如下: **统一认证服务UAA ** 它承载了Oauth2.0 接入方认证、登入用户的认证、授权以及生成令牌的职责, 完成实际的用户认证、授权哦功能 API 网关 作为系统唯一的入口, API 网关为接入方提供定制的API 集合,它可能还具体有其他职责,如验证、监控、负载均衡、缓存等. API 网关方式的核心要点是所有的接入方和消费端都通过统一的网关接入服务，在网关层处理所有的非业务处理. 4. Oauth2.0Oauth（开放授权）是一个开放标准,允许用户授权第三方应用访问他们存储在另外的服务提供者上的信息,而不需要将用户名和密码提供给第三方应用或者分享他们数据的所有内容.Oauth2.0 是Oauth协议的延续版本,但不向后兼容Oauth1.0,即完全废止了Oauth1.0. 很多大公司比如Google、Yahoo等都提供了Oauth 认证服务,这些都足以说明Oauth 标准逐渐成为开放资源授权的标准. 参考: https://baike.baidu.com/item/oAuth/7153134?fr=aladdin Oauth协议: https://tools.ietf.org/html/rfc6749 下面分析一个Oauth2.0 认证的例子,通过例子去理解Oauth2.0协议的认证流程,本例子是gitee 网站使用微信去认证的过程, 这个过程简单的描述如下： 用户借助微信认证登录码云网站,用户就不需要单独在码云网站上注册用户,怎么样才算认证成功呢? 码云网站需要成功从微信获取用户的身份信息则视为用户认证成功,那如何获取微信的用户信息呢? 用户信息的拥有者是用户本人,微信需要经过用户的同意方可为码云网站生成令牌,码云网站拿到此令牌方可从微信获取用户信息. 客户端请求第三方授权 用户进入码云的登录页面, 点击微信的图标进入微信账号登陆系统,用户是自己微信信息的资源拥有者 点击微信, 出现一个二维码,此时用户扫描二维码就开始给码云授权 资源拥有者同意给客户端授权 资源拥有者扫描二维码表示资源拥有者同意给客户端授权,微信会对资源拥有者的身份进行验证,验证通过后,微信会询问用户是否给授权码云访问自己的微信数据,用户点击”确认登录” 表示同意授权,微信认证服务器会颁发一个授权码,并重定向到码云的网站. 客户端获取到授权码, 请求认证服务器申请令牌 此过程用户看不到,客户端从应用程序请求认证服务器,请求携带授权码 认证服务器向客户端响应令牌 微信认证服务器验证了客户端请求的授权码,如果合法则给客户端颁发令牌, 令牌是客户端访问资源的通行证,此交互过程用户看不到,当客户端拿到令牌后,用户在码云网站看已经登录成功了. 客户端请求资源服务器的资源 客户端携带令牌访问资源服务器的资源 码云网站写到令牌请求访问微信服务器获取用户的基本用户信息 资源服务器返回受保护的资源 资源服务器校验令牌的合法性,如果合法则向用户响应资源信息内容 通过上面的例子,我们已经大致了解了Oauth2.0 的认证过程,下面我们看Oauth2.0的认证过程 引自Oauth2.0协议rfc6749 https://tools.ietf.org/html/rfc6749 Oauth2.0 包括以下角色: 客户端 本身不存储资源,需要通过资源拥有者的授权去请求资源服务器的资源,比如Android 客户端,web 客户端,微信客户端 资源拥有者 通常为用户,也可以是应用程序,即该资源的拥有者 授权服务器(也成为认证服务器) 用于服务提供商对资源拥有者的身份进行认证,对访问资源进行授权,认证成功后会给客户端发放令牌(access_token),作为客户端访问资源服务器的凭据,本例中微信为认证服务器. 资源服务器 存储资源的服务器,本例子为微信存储的用户信息 现在还有一个问题,服务提供商能允许随便一个客户端就接入到它的授权服务商吗? 答案是否定的,服务提供商会给准入的接入方一个身份,用户接入的凭据 client_id 客户端标识 client_secret: 客户端秘钥 因此,准确的来说,授权服务器对两种Oauth2.0 中的两个角色进行认证授权,分别是资源拥有者和客户端.","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"Spring Security Oauth2的基本概念(1)","slug":"Security/Spring Security Oauth2的基本概念(1)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.237Z","comments":true,"path":"2022/01/04/security/spring-security-oauth2-de-ji-ben-gai-nian-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/spring-security-oauth2-de-ji-ben-gai-nian-1/","excerpt":"","text":"Spring Security Oauth2的基本概念1. 什么是认证在移动互联网时代,我们经常要登陆各种各样的软件, 比如微信、支付宝、淘宝等,我们拿登陆淘宝来举例子来说明一下认证的基本概念, 当我们在初次使用淘宝的时候, 需要注册为淘宝的会员,然后输入账号密码登录淘宝,这个使用账号密码登陆淘宝的过程就是认证. 系统 为什么要认证呢? 认证是为了保护系统的隐私数据与资源, 用户的身份合法才可以访问该系统的资源. 认证: 用户认证就是判断一个用户的身份是否合法的过程,用户去访问系统资源时系统要求验证用户的身份信息, 身份合法之后才可以继续访问,不合法则会拒绝. 常见的用户身份认证的方式有: 用户名密码认证、二维码登陆、手机短信登陆、指纹认证等. 2. 什么是会话当用户认证通过后,为了避免用户的每次操作都需要认证, 于是将用户的信息保存到会话中，会话就是系统为了保持当前用户的登陆状态所提供的机制,常见的有基于session的和基于token的. 基于session的认证方式他的交互流程是,用户认证成功后,在服务端生成用户相关的数据保存在session(当前会话中), 发给客户端的session_id 存放到cookie 中, 这样用户客户端请求时带上session_id 就可以验证服务器是否存在session数据 ,以此完成用户的合法校验,当用户退出系统或者session 过期销毁时,客户端的session_id 也就无效了. 基于token方式如下图他的交互流程是, 用户认证成功后,服务端生成一个token 发给客户端,客户端可以放到cookie 或者localStorage 等存储中,每次请求带上token, 服务端收到token后即可以确认用户的身份. 1.3. 什么是授权还拿淘宝来举例子,淘宝登陆成功后就可以使用购物车,订单之类的功能,但是没有绑定支付宝的用户是无法进行购买的,订单、购物车这些都属于功能资源,用户有购物车、下订单的功能的权限,这种根据用户的权限来控制用户使用资源的过程就是授权. 为什么要授权呢? 认证是为了保证用户身份的合法性, 授权则是为了更细粒度的对隐私数据进行划分,授权是在用户认证之后发生的, 为了控制不同的用户能够访问不同的资源. 授权: 授权是用户认证通过根据用户的权限来控制用户访问资源的过程,拥有资源的访问权限则正常访问,没有权限则拒绝访问. 1.3.1 授权的数据模式如何进行授权即如何对用户的访问资源进行控制,首先需要学习一下授权相关的数据模型. 主体(Subject) 一般是指用户,也可以说程序,需要访问系统中的资源 资源(Resource) 如系统资源、页面、按钮、代码方法、系统商品信息、系统订单信息等, 系统菜单、页面、按钮等属于系统功能资源, 对于web系统的每个功能资源通常对应一个URL; 系统商品信息、系统订单信息属于实体资源(数据资源), 实体资源由资源类型和资源实例组成, 权限/许可(Permission) 规定了用户对资源的操作许可,权限离开资源没有意义. 1.3.2 授权的方式 RBAC1.3.2.1 基于角色的访问控制RBAC 基于角色的访问控制(Role-Based Access Control)是按照角色进行授权,比如: 主体的角色为总经理,可以直接查询企业运营报表,查询员工工资信心等.判断逻辑授权代码表示为: if(主体.hasRole(\"总经理角色id\"))&amp;#123; 查询工资 &amp;#125; 如果查询工作所需要的角色变化为总经理和部门经理,此时就需要修改判断逻辑为”判断用户的角色是否为总经理或者部门经理”, 修改代码如下: if(主体.hasRole(\"总经理角色id\") || 主体.hasRole(\"部门经理角色id\"))&amp;#123; 查询工资 &amp;#125; 根据上面的例子发现,当需要修改角色的权限时就需要修改代码授权的相关代码,系统可扩展性差. 1.3.2.2 基于资源的访问控制RBAC 基于资源的访问控制(Resource-Based Access Control) 是按资源(或权限)进行授权,比如: 用户必须具有查询工资的权限才可以查询员工工资信息等,授权代码可以表示为： if(主体.hasPermission(\"查询工资权限标识\"))&amp;#123; 查询工资 &amp;#125; 优点: 系统设计时定义好查询工资的权限标识,即使查询工资所需要的角色变化为总经理或者部门经理,也不需要修改授权代码, 系统可扩展性强.","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"Spring Security 认证授权高级篇(5)","slug":"Security/Spring Security 认证授权高级篇(5)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.237Z","comments":true,"path":"2022/01/04/security/spring-security-ren-zheng-shou-quan-gao-ji-pian-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/spring-security-ren-zheng-shou-quan-gao-ji-pian-5/","excerpt":"","text":"Spring Security 认证授权高级篇1. 自定义认证Spring Security 提供了非常好的认证方法, 比如: 快速上手将用户信息保存到内存中,实际开发中用户信息通常是放到数据库中,Spring Security 可以实现从数据库中读取用户信息,Spring Security 还支持多种授权方法. 1.1 自定义登陆页面Spring Security 会根据启用的功能自动生成一个登录页面URL, 并使用默认URL 处理登陆的提交内容,登录i后跳转到默认的URL等,尽管自动生成的登陆页面很方便快速启动和运行,但大多数应用程序都希望定义自己的登录页面. 1.1.1 添加pom 依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-thymeleaf&lt;/artifactId> &lt;/dependency> 1.2 添加页面, 在项目的resource/templates下放入login.html页面&lt;!DOCTYPE html> &lt;html lang=\"en\"> &lt;head> &lt;meta charset=\"UTF-8\"> &lt;title>登陆&lt;/title> &lt;/head> &lt;body> &lt;div> &lt;form action=\"/login\" method=\"post\"> &lt;input type=\"text\" name=\"username\" placeholder=\"用户名\"> &lt;input type=\"password\" name=\"password\" placeholder=\"密码\"> &lt;button type=\"submit\">登陆&lt;/button> &lt;/form> &lt;/div> &lt;/body> &lt;/html> 目录结构为: 1.1.4 编写跳转逻辑 LoginController@GetMapping(\"/login-html\") public String login() &amp;#123; return \"login\"; &amp;#125; 1.1.4 配置安全配置我们在WebSecurityConfig 中修改 // 配置安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.authorizeRequests() // //访问/r/r1资源的 url需要拥有p1权限。 // .antMatchers(\"/r/r1\").hasAuthority(\"p1\") // //访问/r/r2资源的 url需要拥有p2权限。 // .antMatchers(\"/r/r2\").hasAuthority(\"p2\") .antMatchers(\"/r/**\").authenticated() .anyRequest().permitAll() .and() .formLogin() // (1) .loginPage(\"/\") // (2) .loginProcessingUrl(\"/login-html\") // (3) .successForwardUrl(\"/login‐success\") // (4) .permitAll(); // (5) &amp;#125; 步骤介绍 允许表单登陆 指定我们自己的登陆页面, Spring Security 以重定向的方式跳转到/ 指定登陆处理的URL, 也就是用户名、密码表单提交的目的路径 指定登陆成功后的跳转URL 我们必须允许所有用户访问我们的登录页面(例如为验证的用户), 这个formLogin().permitAll() 方法允许任务用户访问基于表单登陆的所有URL 1.1.5 测试当用户没有认证的时候,访问系统的资源就会重定向到/login-html 页面 当输入账号和密码, 点击登陆的时候，发现报错 解决: Spring Security 为防止CSRF``（Cross-site request forgery跨站请求伪造） 的发生, 限制了除了get 以外的大多数方法. 解决方法1: 屏蔽CSRF的控制, 即Spring Security 不再限制CSRF 配置 WebSecurityConfig // 配置安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http .csrf().disable() // //屏蔽CSRF控制，即spring security不再限制CSRF .... 解决方法2: 在login的页面,添加一个token,Spring Security 会验证token, 如果token 通过则可以继续请求. login.html &lt;form action=\"/login\" method=\"post\"> &lt;input type=\"hidden\" name=\"$&amp;#123;_csrf.parameterName&amp;#125;\" value=\"$&amp;#123;_csrf.token&amp;#125;\"/> ..... 1.2 连接数据库认证前面的例子中我们将用户信息存储在内存中,但是在实际项目中 用户信息是存储在数据库中,本节实现从数据库中读取用户信息,我们只需要重新定义 UserDetailService 即可实现根据用户账号查询数据库 1.2.1 数据库准备 新建数据库 我们这里新建一个名称为spring-security-oauth2-demo的数据库, 新建t_user 表 CREATE TABLE `t_user` ( `id` bigint(20) NOT NULL COMMENT '用户id', `username` varchar(64) NOT NULL, `password` varchar(64) NOT NULL, `fullname` varchar(255) NOT NULL COMMENT '用户姓名', `mobile` varchar(11) DEFAULT NULL COMMENT '手机号', PRIMARY KEY (`id`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC 1.2.2 代码实现 pom 依赖添加 &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-jdbc&lt;/artifactId> &lt;/dependency> 配置文件 application.yml 添加数据库相关配置 spring: datasource: url: jdbc:mysql://localhost:3306/spring-security-oauth2-demo username: root password: rootroot 定义实体类 @Builder @AllArgsConstructor @NoArgsConstructor @Data public class UserEntity &amp;#123; private String id; private String username; private String password; private String fullname; private String mobile; &amp;#125; 定义UserDao @Repository public class UserDao &amp;#123; @Autowired private JdbcTemplate jdbcTemplate; /** * &lt;p>根据用户名查询用户信息&lt;/p> * * @param userName 用户名 * @return &amp;#123;@link UserEntity&amp;#125; * @author luyanan * @since 2020/7/27 */ public UserEntity findByUserName(String userName) &amp;#123; String sql = \"select id,username,password,fullname,mobile from t_user where username = ?\"; List&lt;UserEntity> query = jdbcTemplate.query(sql, new Object[]&amp;#123;userName&amp;#125;, new BeanPropertyRowMapper(UserEntity.class)); return CollectionUtils.isEmpty(query) ? null : query.get(0); &amp;#125; &amp;#125; 定义UserDetailService /** * @author luyanan * @since 2020/7/24 * &lt;p>自定义UserDetailsService&lt;/p> **/ @Service public class ConsumerUserDetailsService implements UserDetailsService &amp;#123; @Autowired private UserDao userDao; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException &amp;#123; // 这里使用静态数据 // return User.withUsername(\"zhangsan\").password(\"$2a$10$Z0lpyLYr3DYWdpRQPr3i5eVx3Q1LolIz7QUDCcq5aFePUh5IahaEa\").authorities(\"p1\").build(); UserEntity userEntity = userDao.findByUserName(s); if (null == userEntity) &amp;#123; return null; &amp;#125; UserDetails userDetails = User.withUsername(userEntity.getFullname()).password(userEntity.getPassword()).authorities(\"p1\").build(); return userDetails; &amp;#125; &amp;#125; 测试数据添加 因为我们使用的是 BCryptPasswordEncoder 密码编码器,所以我们要生成 BCryptPasswordEncoder 格式的密码 INSERT INTO `spring-security-oauth2-demo`.`t_user`(`id`, `username`, `password`, `fullname`, `mobile`) VALUES (1, 'zhangsan', '$2a$10$Z0lpyLYr3DYWdpRQPr3i5eVx3Q1LolIz7QUDCcq5aFePUh5IahaEa', '张三', '18111111111'); 结果测试 当我们访问登录页面,输入账号密码的时候, 发现跳转到了 2. 会话用户认证通过后,为了避免用户的每次操作都进行认证可以将用户的信息保存在会话中,Spring Security 提供会话管理,认证通过后将身份信息放入到SecurityContextHolder 上下文中, SecurityContextHolder 与当前线程进行绑定,方便获取用户身份. 2.1 获取用户身份修改LoginController.实现 r/r1 和r/r2 和/login-success 接口 返回用户名信息,Spring Security 获取当前登录用户信息的方法为: SecurityContextHolder.getContext().getAuthentication(); @Controller public class LoginController &amp;#123; @GetMapping(\"/login-html\") public String login() &amp;#123; return \"login\"; &amp;#125; @ResponseBody @GetMapping(\"/r/r1\") public String r1() &amp;#123; return getUserName() + \":访问r1的资源\"; &amp;#125; @ResponseBody @GetMapping(\"/r/r2\") public String r2() &amp;#123; return getUserName() + \":访问r2的资源\"; &amp;#125; @ResponseBody @RequestMapping(value = \"login‐success\") public String loginSuccess() &amp;#123; return getUserName() + \":登陆成功\"; &amp;#125; /** * &lt;p>获取用户名&lt;/p> * * @return &amp;#123;@link String&amp;#125; * @author luyanan * @since 2020/7/27 */ public String getUserName() &amp;#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (!authentication.isAuthenticated()) &amp;#123; return null; &amp;#125; Object principal = authentication.getPrincipal(); String userName = null; if (principal instanceof UserDetails) &amp;#123; userName = ((UserDetails) principal).getUsername(); &amp;#125; else &amp;#123; userName = principal.toString(); &amp;#125; return userName; &amp;#125; &amp;#125; 结果测试 2.2 会话控制我们可以通过以下选项准确控制会话合适创建以及Spring Security 如何与之交互. 机制 描述 always 如果没有session就创建一个 ifRequired 如果需要就创建一个session(默认)登录时 never Spring Security 将不会创建session, 但是如果应用中其他地方创建了session, 那么Spring Security 将会使用它. stateless Spring Security 将绝对不会创建session, 也不适用session 通过以下配置方式对该选项进行配置 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED); &amp;#125; 默认情况下,Spring Security 会为每个登录的用户会新建一个session, 就是 ifRequired 若选用 never, 则指示Spring Security 对登录成功的用户不创建session了, 但若你的应用程序在某地方新建了session, 那么Spring Security 还是会用它的. 若使用stateless, 则说明Spring Security 对登录的用户不会创建session, 你的应用程序也不允许创建session,并且他会暗示不使用cookie, 所以每个请求都需要重新进行身份验证,这种无状态的架构适用于REST API 以及无状态认证机制 会话超时 可以在servlet 容器中设置session的超时时间,如下设置session的超时时间为 3600s spring boot的配置文件 server: servlet: session: timeout: 3600s session 超时之后, 可以通过Spring Security 设置跳转的路径 http.sessionManagement() .expiredUrl(\"/login‐success?error=EXPIRED_SESSION\") .invalidSessionUrl(\"/login‐success?error=INVALID_SESSION\"); expiredUrl 是指session 过期, invalidSessionUrl 是指传入的session 无效. 安全会话cookie 我们可以使用httpOnly 和secure 标签来保护我们的会话cookie httpOnly: 如果为true, 那么浏览器脚本将无法访问cookie secure: 如果为true, 则cookie 仅通过HTTPS 来连接发送 spring boot 配置文件 server: servlet: session: cookie: http-only: true secure: true 3. 退出Spring Security 默认实现了logout 退出,访问/logout, 退出功能Spring 也帮我们做好了. 我们可以自定义退出成功的页面 .and() .logout() .logoutSuccessUrl(\"/login-html?logout\") .logoutUrl(\"/logout\"); // (5) 当退出操作发生时,将发生 使得Http Session 无效 清除SecurityContextHolder 跳转到/login-html?logout 页面 但是, 类似于配置登陆功能,我们可以进一步自定义退出的功能 .and() .logout() // (1) .logoutSuccessUrl(\"/login-html?logout\") // (2) .addLogoutHandler(new LogoutHandler() &amp;#123;// (3) @Override public void logout(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Authentication authentication) &amp;#123; &amp;#125; &amp;#125;) .logoutUrl(\"/logout\") // (4) .addLogoutHandler(new LogoutHandler() &amp;#123; // (5) @Override public void logout(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Authentication authentication) &amp;#123; &amp;#125; &amp;#125;).invalidateHttpSession(true); // (6) 提供系统退出的支持,使用 WebSecurityConfigurerAdapter 会自动被应用 设置触发退出操作的URL,默认是/logout 退出之后跳转到URL,默认是/login?logout 定制的LogoutSuccessHandler 用于实现用户退出成功的时候的处理,如果指定了这个选项, 那么logoutSuccessUrl() 的设置会被忽略. 添加一个LogoutHandler , 用于实现用户退出的时候的清理工作,默认 SecurityContextLogoutHandler 会被添加为最后一个LogoutHandler 指定是否在退出的时候让HttpSession 无效,默认设置为true 注意: 如果让logout 在GET 请求下生效,必须关闭防止CSRF 攻击csrf().disable(),如果开启了CSRF, 必须使用post 方法请求/logout logoutHandler： 一般来说,logoutHandler 的实现类被用来执行必要的清理,因而他们不应该抛出异常 下面是Spring Security 提供的一些实现 PersistentTokenBasedRememberMeServices: 基于持久化token的RememberMe 功能的相关清理 TokenBasedRememberMeService: 基于token 的RememberMe 功能的清理 CookieClearingLogoutHandler: 退出时Cookie的相关清理 CsrfLogoutHandler: 负责在退出时移除csrfToken SecurityContextLogoutHandler: 退出时SecurityContext的相关清理 链式API提供了调用相应的logoutHandler 实现的快捷方式, 比如deleteCookies() 4. 授权4.1 概述授权的方式包括web 授权和方法授权,web 授权是通过 url 拦截进行授权,方法授权是通过方法拦截进行授权, 他们都会调用accessDecisionManage 进行授权决策,若为web 授权则拦截器为FilterSecurityInterceptor; 若为方法授权则拦截器为MethodSecurityInterceptor. 如果同时通过web 授权和方法授权则先执行web 授权, 在执行方法授权, 最后决策通过, 则允许访问资源, 否则将禁止访问. 类关系如下： 4.2 环境准备4.2.1 数据库环境准备角色表CREATE TABLE `t_role` ( `id` varchar(32) NOT NULL, `role_name` varchar(255) DEFAULT NULL, `description` varchar(255) DEFAULT NULL, `create_time` datetime DEFAULT NULL, `update_time` datetime DEFAULT NULL, `status` char(1) NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `unique_role_name` (`role_name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 insert into `t_role`(`id`,`role_name`,`description`,`create_time`,`update_time`,`status`) values ('1','管理员',NULL,NULL,NULL,''); 角色用户关系表CREATE TABLE `t_user_role` ( `user_id` varchar(32) NOT NULL, `role_id` varchar(32) NOT NULL, `create_time` datetime DEFAULT NULL, `creator` varchar(255) DEFAULT NULL, PRIMARY KEY (`user_id`,`role_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 insert into `t_user_role`(`user_id`,`role_id`,`create_time`,`creator`) values ('1','1',NULL,NULL); 权限表CREATE TABLE `t_permission` ( `id` varchar(32) NOT NULL, `code` varchar(32) NOT NULL COMMENT '权限标识符', `description` varchar(64) DEFAULT NULL COMMENT '描述', `url` varchar(128) DEFAULT NULL COMMENT '请求地址', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 insert into `t_permission`(`id`,`code`,`description`,`url`) values ('1','p1','测试资源 1','/r/r1'),('2','p3','测试资源2','/r/r2'); 角色权限表CREATE TABLE `t_role_permission` ( `role_id` varchar(32) NOT NULL, `permission_id` varchar(32) NOT NULL, PRIMARY KEY (`role_id`,`permission_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 insert into `t_role_permission`(`role_id`,`permission_id`) values ('1','1'),('1','2'); 4.2.2 修改UserDetailsService修改Dao 接口 修改dao 接口 在UserDao 中添加: /** * &lt;p>根据用户id查询权限列表&lt;/p> * * @param userId * @return &amp;#123;@link List&lt; String>&amp;#125; * @author luyanan * @since 2020/7/27 */ public List&lt;String> findPermissionByUserId(String userId) &amp;#123; String sql = \"SELECT * FROM t_permission WHERE id IN(\\n\" + \"SELECT permission_id FROM t_role_permission WHERE role_id IN(\\n\" + \"\\tSELECT role_id FROM t_user_role WHERE user_id = ? \\n\" + \")\\n\" + \")\"; List&lt;PermissionEntity> query = jdbcTemplate.query(sql, new Object[]&amp;#123;userId&amp;#125;, new BeanPropertyRowMapper&lt;>(PermissionEntity.class)); return query.stream().map(PermissionEntity::getCode).collect(Collectors.toList()); &amp;#125; 修改UserDetailsService 实现从数据库中读取权限 @Service public class ConsumerUserDetailsService implements UserDetailsService &amp;#123; @Autowired private UserDao userDao; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException &amp;#123; // 这里使用静态数据 // return User.withUsername(\"zhangsan\").password(\"$2a$10$Z0lpyLYr3DYWdpRQPr3i5eVx3Q1LolIz7QUDCcq5aFePUh5IahaEa\").authorities(\"p1\").build(); UserEntity userEntity = userDao.findByUserName(s); if (null == userEntity) &amp;#123; return null; &amp;#125; List&lt;String> permission = userDao.findPermissionByUserId(userEntity.getId()); UserDetails userDetails = User .withUsername(userEntity.getFullname()) .password(userEntity.getPassword()) .authorities(permission.toArray(new String[permission.size()])) .build(); return userDetails; &amp;#125; &amp;#125; 4.3 web 授权在上面的例子中, 我们完成了认证拦截,并对r/** 下的资源进行了简单的授权保护,但是我们想要灵活的授权控制该怎么做呢? 通过给http.authorizeRequests() 添加多个子节点来定制需求到我们的URL, 如下所示： protected void configure(HttpSecurity http) throws Exception &amp;#123; http .csrf().disable() // //屏蔽CSRF控制，即spring security不再限制CSRF .authorizeRequests() //（1） //访问/r/r1资源的 url需要拥有p1权限。 .antMatchers(\"/r/r1\").hasAuthority(\"p1\")//（2） //访问/r/r2资源的 url需要拥有p2权限。 .antMatchers(\"/r/r2\").hasAuthority(\"p2\")//（3） .antMatchers(\"/r/r3\").access(\"hasAuthority('p1') and hasAuthority('p2')\")//（4） .antMatchers(\"/r/**\").authenticated()//（5） .anyRequest().permitAll()//（6） .and() http.authorizeRequests() 方法有多个子节点, 每个mathcer 按照他们声明的顺序进行 指定r/r1 拥有p1的权限才可以访问 指定r/r2 拥有p2 的权限才可以访问 指定r/r3 同时拥有p1和p2的权限才可以访问 指定了处r/r1、r/r2、r/r3 之外的r/r** 资源, 同时通过身份认证就能过够访问 剩余的尚不匹配的资源,不做保护。 注意: 规则的顺序是最重要的,更具体的规则应该先写,现在以/admin 开始是所有内容都需要具体也有ADMIN角色的身份验证用户,即使是admin/login 路径,(因为/admin/login 已经被/admin/** 规则匹配, 所以第二个规则被忽略) .antMatchers(\"/admin/**\").hasRole(\"ADMIN\") .antMatchers(\"/admin/login\").permitAll() 因此登陆页面的规则应该是在/admin/** 规则之前,例如: .antMatchers(\"/admin/login\").permitAll() .antMatchers(\"/admin/**\").hasRole(\"ADMIN\") 保护URL 常用的方法有: authenticated(): 保护URL, 需要用户登陆 permitAll(): 指定URL 无需保护,一般应用与静态资源文件 hasRole(String role) 限制单个角色访问,角色将会被增加ROLE, 所以ADMIN 将和ROLE_ADMIN 进行比较. hasAuthority(String authority) 限制单个权限访问 hasAnyRole(String… roles): 允许多个角色访问 hasAnyAuthority(String… authorities) 允许多个权限访问 access(String attribute): 该方法使用SPEL表达式 ,所以可以创建复杂的限制 hasIpAddress(String ipaddressExpression): 限制地址或者子网 4.3 方法授权现在我们已经掌握了如何使用 http.authorizeRequests()对web 资源进行授权保护,从Spring Security2.0 版本开始,它支持服务层方法的安全性支持,本节学习@PreAuthorize,@PostAuthorize, @Secured 三类注解 我们可以在任何@Configuration实例上使用@EnableGlobalMethodSecurity 注释来启动基于注册的安全性. 以下内容将启动Spring Security 的@Secured 注释 @EnableGlobalMethodSecurity(securedEnabled = true) 然后向方法(类或者接口) 上添加注解就hi限制对方法的访问,Spring Security 的原生注释支持为该方法定义了一组属性,这些将被传递给AccessDecisionManage 以供它做出实际的决定. public interface IUserService &amp;#123; @Secured(\"IS_AUTHENTICATED_ANONYMOUSLY\") UserEntity findById(String id); @Secured(\"IS_AUTHENTICATED_ANONYMOUSLY\") List&lt;UserEntity> findByPage(int page); @Secured(\"ROLE_TELLER\") void save(UserEntity userEntity); &amp;#125; 以上配置表明findById、findByPage 方法可匿名访问,底层使用WebExpressionVote 投票器,可从AffirmativeBased 第23 行代码进行跟踪 save 方法需要TELLER 角色才访问,底层使用RoleVoter 投票器 使用如下代码可启用prePost 注解的支持 @EnableGlobalMethodSecurity(prePostEnabled = true) 相应的代码如下: @PreAuthorize(\"isAnonymous()\") UserEntity findById(String id); @PreAuthorize(\"isAnonymous()\") List&lt;UserEntity> findByPage(int page); @PreAuthorize(\"hasAuthority('findById') and hasAuthority('findByPage')\") void save(UserEntity userEntity); 以上配置表明 findById 和findByPage 方法可以匿名访问,save 方法需要同时拥有findById 和findByPage的权限才可以访问,底层使用WebExpressionVote 投票器,可从**AffirmativeBased** 第23行代码","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"Spring Cloud Security Oauth2","slug":"Security/Spring Cloud Security Oauth2.0实现分布式系统认证(7)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.237Z","comments":true,"path":"2022/01/04/security/spring-cloud-security-oauth2.0-shi-xian-fen-bu-shi-xi-tong-ren-zheng-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/spring-cloud-security-oauth2.0-shi-xian-fen-bu-shi-xi-tong-ren-zheng-7/","excerpt":"","text":"Spring Cloud Security Oauth2.0实现分布式系统认证1. 环境介绍Spring-Security-Oauth2.0 是对Oauth2.0 的一种实现,并且跟Spring Security相辅相成,与Spring Cloud 体系的集成也非常便利,接下来,我们需要对它进行学习,最终使用它来实现我们设计的分布式认证授权解决方案 Oauth2.0 的服务提供方涵盖两个服务,即授权服务(Authorization Server,也叫认证服务)和资源服务(resource Server),使用 Spring Security Oauth2.0的时候, 你可以选择把他们放在同一个应用程序中去实现,也可以选择建立使用同一个授权服务的多个资源服务. 授权服务(Authorization Server) 应包含对接入端以及登录用户的合法性进行验证并颁发token 等功能,对令牌的请求端点由Spring MVC控制器进行实现,下面是一个配置一个认证服务必须实现的endpoints: AuthorizationEndpoint:’ 服务于认证请求, 默认URL:/oauth/authorize TokenEndpoint 服务于访问令牌的请求,默认URL: /oauth/token 资源服务(Resource Server),应包含对资源的保护功能,对非法请求进行拦截,对请求token 进行解析鉴权等,下面的过滤器用于实现Oauth2.0 资源服务 OAuth2AuthenticationProcessingFilter:用来对请求给出的身份令牌解析鉴权. 本教程分别创建UAA认证中心和order 订单资源服务 认证流程如下: 客户端请求UAA 授权服务进行认证 认证通过后由UAA 颁发令牌 客户端携带令牌Token请求资源服务 资源服务校验令牌的合法性,合法则返回资源信息 2. 代码演示2.1 创建父工程创建maven 父工程,依赖如下 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;packaging>pom&lt;/packaging> &lt;properties> &lt;project.build.sourceEncoding>UTF‐8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF‐8&lt;/project.reporting.outputEncoding> &lt;java.version>1.8&lt;/java.version> &lt;/properties> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.security.oauth.boot&lt;/groupId> &lt;artifactId>spring-security-oauth2-autoconfigure&lt;/artifactId> &lt;version>2.1.3.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.security&lt;/groupId> &lt;artifactId>spring-security-jwt&lt;/artifactId> &lt;version>1.0.10.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>5.1.46&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;version>1.2.70&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>cn.hutool&lt;/groupId> &lt;artifactId>hutool-all&lt;/artifactId> &lt;version>5.3.8&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.18.12&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>Greenwich.RELEASE&lt;/version> &lt;scope>import&lt;/scope> &lt;type>pom&lt;/type> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-dependencies&lt;/artifactId> &lt;version>2.1.3.RELEASE&lt;/version> &lt;scope>import&lt;/scope> &lt;type>pom&lt;/type> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;!--子模块 --> &lt;modules> &lt;module>uaa&lt;/module> &lt;module>order&lt;/module> &lt;/modules> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>1.8&lt;/source> &lt;target>1.8&lt;/target> &lt;encoding>UTF-8&lt;/encoding> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;!--aliyun 私服配置 --> &lt;repositories> &lt;repository> &lt;id>public&lt;/id> &lt;name>aliyun nexus&lt;/name> &lt;url>http://maven.aliyun.com/nexus/content/groups/public/&lt;/url> &lt;releases> &lt;/releases> &lt;/repository> &lt;/repositories> &lt;pluginRepositories> &lt;pluginRepository> &lt;id>public&lt;/id> &lt;name>aliyun nexus&lt;/name> &lt;url>http://maven.aliyun.com/nexus/content/groups/public/&lt;/url> &lt;releases> &lt;/releases> &lt;snapshots> &lt;enabled>false&lt;/enabled> &lt;/snapshots> &lt;/pluginRepository> &lt;/pluginRepositories> &lt;/project> 里面主要定义了Spring Boot的版本和Spring Cloud的版本 2.2 创建UAA 授权服务工程 pom 依赖 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/parent> &lt;groupId>com.spring.security.uaa&lt;/groupId> &lt;artifactId>uaa&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>uaa&lt;/name> &lt;description>授权认证服务&lt;/description> &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;/properties> &lt;dependencies> &lt;!--wen组件 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;!--端点监控 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;!--服务调用 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;!--负载均衡 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-ribbon&lt;/artifactId> &lt;/dependency> &lt;!-- 熔断--> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;!--注册中心 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;!--认证授权相关 --> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-oauth2&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.security&lt;/groupId> &lt;artifactId>spring-security-jwt&lt;/artifactId> &lt;/dependency> &lt;!-- 认证授权end--> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-jdbc&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>org.junit.vintage&lt;/groupId> &lt;artifactId>junit-vintage-engine&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;/dependencies> &lt;/project> 编写启动类UaaApplication @EnableHystrix @EnableFeignClients @EnableDiscoveryClient @SpringBootApplication public class UaaApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(UaaApplication.class, args); &amp;#125; &amp;#125; 编写配置文件application.yml spring: application: name: uaa main: allow-bean-definition-overriding: true http: encoding: charset: UTF-8 enabled: true force: true datasource: url: jdbc:mysql://localhost:3306/spring-security-oauth2-demo username: root password: rootroot driver-class-name: com.mysql.jdbc.Driver mvc: throw-exception-if-no-handler-found: true resources: add-mappings: false server: port: 8000 tomcat: remote-ip-header: x‐forwarded‐for protocol-header: x‐forwarded‐proto use-forward-headers: true servlet: context-path: /uaa logging: level: root: info feign: hystrix: enabled: true compression: request: enabled: true mime-types: - text/html - appliication/xml - application/json min-request-size: 2048 response: enabled: true 结构预览 2.3 编写Order 资源服务项目本工程为Order 订单服务工程,访问本工程的资源需要认证通过 本工程的目的主要是为了测试认证授权功能,所以不会涉及订单的相关业务逻辑. pom.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.spring.security&lt;/groupId> &lt;artifactId>spring-security-oauth2-demo&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/parent> &lt;groupId>com.spring.security.order&lt;/groupId> &lt;artifactId>order&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>order&lt;/name> &lt;description>订单模块&lt;/description> &lt;dependencies> &lt;!-- 认证授权相关--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-oauth2&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-jdbc&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-ribbon&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>org.junit.vintage&lt;/groupId> &lt;artifactId>junit-vintage-engine&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-compiler-plugin&lt;/artifactId> &lt;configuration> &lt;source>1.8&lt;/source> &lt;target>1.8&lt;/target> &lt;encoding>UTF-8&lt;/encoding> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> Order的启动类 @EnableHystrix @EnableFeignClients @EnableDiscoveryClient @SpringBootApplication public class OrderApplication &amp;#123; public static void main(String[] args) &amp;#123; SpringApplication.run(OrderApplication.class, args); &amp;#125; &amp;#125; 配置文件application.yml server: port: 8081 tomcat: remote-ip-header: x‐forwarded‐for protocol-header: x‐forwarded‐proto use-forward-headers: true servlet: context-path: /order spring: application: name: order main: allow-bean-definition-overriding: true http: encoding: charset: UTF-8 enabled: true force: true datasource: url: jdbc:mysql://localhost:3306/spring-security-oauth2-demo username: root password: rootroot driver-class-name: com.mysql.jdbc.Driver mvc: throw-exception-if-no-handler-found: true resources: add-mappings: false feign: hystrix: enabled: true compression: request: enabled: true mime-types: - text/html - appliication/xml - application/json min-request-size: 2048 response: enabled: true 项目的基本框架现在已经搭建了 2.4 授权服务器设置(uaa)2.4.1 EnableAuthorizationServer可以用 EnableAuthorizationServer注解并继承AuthorizationServerConfigurerAdapter 来配置Oauth2.0 授权服务器. 在config 包下创建 AuthorizationServer AuthorizationServerConfigurerAdapter 要求配置以下几个类,这几个类是由Spring 创建的独立的配置对象,他们会被Spring传入AuthorizationServerConfigurerAdapter 中进行配置. public class AuthorizationServerConfigurerAdapter implements AuthorizationServerConfigurer &amp;#123; public AuthorizationServerConfigurerAdapter() &amp;#123; &amp;#125; public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &amp;#123; &amp;#125; public void configure(ClientDetailsServiceConfigurer clients) throws Exception &amp;#123; &amp;#125; public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &amp;#123; &amp;#125; &amp;#125; ClientDetailsServiceConfigurer:用来配置客户端详情服务(ClientDetailsService),客户端详情信息在这里进行初始化,可以通过客户端详细写死在这里或者通过数据库来存储调取详情信息. AuthorizationServerEndpointsConfigurer: 用来配置令牌token 的访问端点和令牌服务(token service) AuthorizationServerSecurityConfigurer: 用来配置令牌端点的安全约束 2.4.2 配置客户端相信信息ClientDetailsServiceConfigurer 可以使用内存或者JDBC来实现客户端详细信息服务(ClientDetailsService) ClientDetailsService 负责查找ClientDetails, 而ClientDetails 有几个重要的属性如下列表: clientId(必须): 用来标识客户的id secret: (需要值得信任的客户端)客户端安全码,如果有的话, scope :用来限制客户端的访问范围, 如果为空(默认的话), 那么客户端将拥有全部的访问范围. authorizedGrantTypes:此客户端可以使用的授权类型,默认为空 authorities 此客户端可以使用的权限(基于Spring Security authorities) 客户端详情(client details) 能够在应用程序运行的时候进行更新,可以通过访问底层的存储服务(例如将客户端详情存储在一个关系型数据库的表中,就可以使用jdbcClientDetailsService) 或者通过自己实现ClientRegistrationService 接口(同时实现ClientDetailsServcice 接口) 来进行管理. @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &amp;#123; clients.inMemory()// 使用in‐memory存储 .withClient(\"c1\")// client_id .secret(new BCryptPasswordEncoder().encode(\"secret\")) .resourceIds(\"res1\") .authorizedGrantTypes(\"authorization_code\", \"password\", \"client_credentials\", \"implicit\", \"refresh_token\")// 该client允许的授权类型 authorization_code,password,refresh_token,implicit,client_credentials .scopes(\"all\")// 允许的授权范围 .autoApprove(false) //加上验证回调地址 .redirectUris(\"http://www.baidu.com\"); &amp;#125; 2.4.3 管理令牌AuthorizationServerTokenService接口定义了一些操作使得你可以对令牌进行一些必要的管理,令牌可以被用来加载身份信息,里面包含了这个令牌的相关权限. 自己可以创建AuthorizationServerTokenService 这个接口的实现,则需要继承DefaultTokenServices 这个类, 里面包含了一些有用的实现,可以使用它来修改令牌的格式和令牌的存储. 默认的,当它尝试创建一个令牌的时候,是使用随机值来进行填充的,除了持久化令牌是委托一个tokenStore 接口来实现以外,这个类几乎帮你做了所有的事情,并且TokenStore 这个接口有一个默认的实现InMemoryTokenStore, 基于内存的令牌保存实现. 除了使用这个类之外, 你还可以使用一些其他的预定义的实现,下面有几个版本,他们都实现了TokenStore 接口. InMemoryTokenStore:这个版本都实现是被默认采用的,它可以完美的工作在单机服务器上(即访问并发量不大的情况下, 并且它在失败的时候不会进行备份), 大多数的项目都可以使用这个版本的实现来进行尝试, 一般可以在开发的时候使用它进行管理, 因为不会被保存在磁盘中, 所以更易于调试. JdbcTokenStore: 这是一个基于JDBC的实现版本, 令牌会被保存在关系型数据库中,使用这个版本的实现的时候,你可以在不同的服务器之间共享信息,使用这个版本的时候注意把spring-jdbc这个依赖加入到项目中. JwtTokenStore: 这个版本的全称是JSON Web Token（JWT）,它可以把令牌相关的数据进行编码(因此相对于后端服务来说, 它不需要进行存储,这是一个重大的优势),但是它有一个缺点,就是撤销一个已经授权的令牌将会非常困难,所以它通常用来处理一个生命周期很短的令牌以及撤销刷新令牌(refresh token), 另一个缺点就是这个令牌会占用的空间会比较大 , 如果你加入了比较多的用户凭证信息,JwtTokenStore 不会保存任何数据,它是它在转换令牌以及授权信息等方法跟 DefaultTokenServices 所扮演的角色是一样的. 定义TokenConfig 在config包下定义TokenConfig, 我们暂时使用InMemoryTokenStore, 生成一个普通的令牌. @Configuration public class TokenConfig &amp;#123; @Bean public TokenStore tokenStore() &amp;#123; // 使用内存存储令牌 return new InMemoryTokenStore(); &amp;#125; &amp;#125; 定义 AuthorizationServerTokenServices 在AuthorizationServer 中定义AuthorizationServerTokenServices @Autowired private TokenStore tokenStore; @Autowired private ClientDetailsService clientDetailsService; @Bean public AuthorizationServerTokenServices authorizationServerTokenServices() &amp;#123; DefaultTokenServices services = new DefaultTokenServices(); services.setClientDetailsService(clientDetailsService); services.setSupportRefreshToken(true); services.setTokenStore(tokenStore); services.setAccessTokenValiditySeconds(7200);//令牌默认的有效时间为2小时 services.setRefreshTokenValiditySeconds(259200);//刷新令牌默认有效期为3天 return services; &amp;#125; 2.4.4 令牌访问端点配置AuthorizationServerEndpointsConfigurer 这个对象的实例可以完成令牌服务以及令牌endpoint 的配置 配置授权类型(Grant Types)AuthorizationServerEndpointsConfigurer 通过设定以下属性来决定支持的授权类型(Grant Types) authenticationManager: 认证管理器 ,当你选择了资源所有者的密码(password)授权类型的时候,请设置这个属性注入一个AuthenticationManager 对象 userDetailsService:如果你设置了这个属性,那说明你有一个自己定义的UserDetailsService 接口的实现,或者你可以把这个东西设置到全局域上面去(例如GlobalAuthenticationManagerConfigurer 这个配置对象), 当你设置了这个后, 那么refresh_token即刷新令牌授权类型模式的流程中就会包含一个检查,用来确保这个账号是否仍然有效,假如说你禁用了这个账号了的话. authorizationCodeServices: 这个属性是用来设置授权码服务(即 AuthorizationCodeServices 的实例对象),主要用于authorization_code 授权码类型模式. implicitGrantService: 这个属性用于设置隐形授权模式,用来管理隐式授权模式的状态. tokenGranter: 当你设置了这个东西(即tokenGranter接口实现), 那么授权就会交给你完全掌握,并且会忽略掉上面的几个属性, 这个属性一般是用作扩展用途的,即标准的四种授权模式已经满足不了你的需求的时候, 才会用到这个. 配置授权端点的URL(Endpoint URLs)AuthorizationServerEndpointsConfigurer 这个配置对象有一个叫做pathMapping() 方法来配置端点URL连接, 它有两个参数: 第一个参数: String 类型的,这个端点URL 的默认链接. 第二个参数: String 类型的, 你要进行替代的URL 链接. 以上的参数都将以/ 字符为开始的字符串,框架默认的URL链接如下列表,可以作为这个pathMapping() 方法的第一个参数 /oauth/authorize: 授权端点 /oauth/token: 令牌端点 /oauth/confirm_access:用户确认授权提交端点 /oauth/error: 授权服务错误信息端点 /oauth/check_token: 用于资源服务访问的令牌解析端点 /oauth/token_key:提供公有密钥的端点,如果你使用JWT令牌的话. 需要注意的是授权端点这个URL应该被Spring Security保护起来只供授权用户访问. 在AuthorizationServer 中配置令牌访问端点 @Autowired private AuthenticationManager authenticationManager; @Autowired private AuthorizationCodeServices authorizationCodeServices; /** * &lt;p>令牌访问端点&lt;/p> * * @param endpoints * @author luyanan * @since 2020/7/30 */ @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &amp;#123; endpoints.authenticationManager(authenticationManager) .authorizationCodeServices(authorizationCodeServices) .tokenServices(authorizationServerTokenServices()) .allowedTokenEndpointRequestMethods(HttpMethod.POST); &amp;#125; @Bean public AuthorizationCodeServices authorizationCodeServices() &amp;#123; // 设置授权码模式的授权码如何存储, 暂时采用内存存储的方式 return new InMemoryAuthorizationCodeServices(); &amp;#125; 2.4.5 令牌端点的安全约束AuthorizationServerSecurityConfigurer 用来配置令牌端点(Token Endpoint) 的安全约束,在AuthorizationServer 中配置如下 //令牌端点安全约束 @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &amp;#123; security.tokenKeyAccess(\"permitAll()\") //(1) .checkTokenAccess(\"permitAll()\") //(2) .allowFormAuthenticationForClients();//(3) &amp;#125; tokenkey 这个endpoint 当使用jwtToken 且使用非对称加密的时候, 资源服务用于获取公钥而开放,这里指这个endpoint 完全开放. checkToken 在个endpoint 完全公开 允许表单认证 授权服务器总结: 授权服务配置分为三大块,可以关联记忆既然要完成认证,它首先要知道客户端信息从哪里读取,因此要进行客户端详情配置. 既然要颁发token, 那必须要定义token 的相关endpoint , 以及token 如何存取,以及客户端支持哪些类型的token. 既然暴露了一些endpoint, 那对这些endpoint 可以定义一些安全上的约束等. 2.4.5 web 安全配置在config包路径下添加WebSecurityConfig文件 package com.spring.security.uaa.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import org.springframework.security.provisioning.UserDetailsManager; import javax.jws.Oneway; /** * @author luyanan * @since 2020/7/30 * &lt;p>web安全配置&lt;/p> **/ @Configuration @EnableGlobalMethodSecurity(securedEnabled = true, prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; @Bean public UserDetailsService userDetailsService() &amp;#123; UserDetails zhangsan = User.withUsername(\"zhangsan\").password(passwordEncoder().encode(\"123\")).authorities(\"p1\").build(); UserDetailsManager userDetailsManager = new InMemoryUserDetailsManager(); userDetailsManager.createUser(zhangsan); return userDetailsManager; &amp;#125; @Bean public PasswordEncoder passwordEncoder() &amp;#123; return new BCryptPasswordEncoder(); &amp;#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &amp;#123; return super.authenticationManagerBean(); &amp;#125; // 安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.csrf().disable() .authorizeRequests() .antMatchers(\"/r/r1\").hasAnyAuthority(\"p1\") .antMatchers(\"/r/r2\").hasAnyAuthority(\"p2\") .antMatchers(\"/login\").permitAll() .anyRequest().authenticated() .and().formLogin(); &amp;#125; &amp;#125; 3. 授权模式3.1 授权码模式3.1.1 授权码模式介绍下面是授权码模式的交互流程 资源拥有者打开客户端,客户端要求资源拥有者给予授权,它将浏览器被重定向到授权服务器,重定向时会附加客户端的身份信息,如: /uaa/oauth/authorize?client_id=c1&response_type=code&scope=all&redirect_uri=http://www.baidu.com 参数列表如下: client_id: 客户端准入标识 response_type：授权码模式固定为code scope: 客户端权限 redirect_uri:跳转url, 当授权码申请成功后将跳转到此地址,并在后面带上code参数(授权码) 浏览器出现向授权服务器授权页面后, 之后将用户同意授权. 授权服务器将授权码(AuthorizationCode) 转经浏览器发送给client（通过redirect_uri） 客户端拿着授权码向授权服务器索要访问access_token, 请求如下: /uaa/oauth/token? client_id=c1&client_secret=secret&grant_type=authorization_code&code=5PgfcD&redirect_uri=http://www.baidu.com 参数列表如下: cleint_id 客户端准入标识 client_secret: 客户端密钥 grant_type:授权类型, 添加 authorization_code 表示授权码模式 code: 授权码,就是刚刚获取的授权码.注意: 授权码使用一次就无效了, 需要重新申请. redirect_uri: 申请授权码时跳转的url,一定要和申请授权码时使用的 redirect_uri一致 授权服务器返回令牌access_token 这种模式是四种模式中最安全的一种模式,一般用于client 是web应用服务器端或者第三方的原生APP 调用资源服务的时候 , 因为这种模式中access_token 不会经过浏览器或者移动端的APP, 而是直接从服务端去交换,这样就最大限度的减少了令牌泄漏的危险. 3.1.2 测试浏览器访问认证页面: http://localhost:8000/uaa/oauth/authorize?client_id=c1&response_type=code&scope=all&redirect_uri=http://www.baidu.com 然后输入模拟的账号密码后点击登陆后进入授权页面 确认授权后,浏览器会重定向到指定路径(redirect_uri 中携带的路径),并附加验证码 ?code=0rlqUV(每次都不一样), 最后使用该验证码获取token. POST: http://localhost:8000/uaa/oauth/token 3.2 简化模式3.2.1 简化模式介绍下图是简化模式交互图 资源拥有者打开客户端, 客户端要求资源拥有者给与授权,它将浏览器重定向到授权服务器,重定向时会附加客户端的身份信息,如: /uaa/oauth/authorize?client_id=c1&response_type=token&scope=all&redirect_uri=http://www.baidu.com 参数描述同授权模式, 注意response_type=token, 说明是简化模式 浏览器出现向授权服务器授权后,之后将用户同意授权 授权服务器将授权码令牌(access_token) 以hash的形式存放在重定向url 的fargment 中发送给浏览器 注: fargment 主要用来 标识URL所标识资源里的某个资源，在URL的末尾通过# 作为fargment的开头,其中# 不属于fargment的值, 比如 https://domain/index#L18 中L18 就是fargment 的值,大家只需要通过js响应浏览器地址变化栏的方式就能获取到fargment 的值 一般来说, 简化模式用于没有服务端的第三方单页应用,因为没有服务端就无法接受授权码. 3.2.2 代码测试浏览器访问认证页面 http://localhost:8000/uaa/oauth/authorize?client_id=c1&response_type=token&scope=all&redirect_uri=http://www.baidu.com 然后输入账号密码点击登陆后进入授权页面 确认授权后,浏览器会重定向到指定路径(redirect_uri 中携带的路径),并以Hash的形式存放在重定向uri的fargment 中. 如: https://www.baidu.com/#access_token=c68eeda7-abbc-4e38-90b1-93c64f61e8b9&token_type=bearer&expires_in=5777 3.3 密码模式3.3.1 授权码模式介绍下图是密码模式交互图 资源拥有者将用户名、密码发送给客户端 客户端拿着资源拥有者的用户名、密码向授权服务器请求令牌(access_token), 请求如下: /uaa/oauth/token? client_id=c1&client_secret=secret&grant_type=password&username=shangsan&password=123 参数列表如下： client_id： 客户端准入标识 client_secret: 客户端密钥 grant_type: 授权类型,填写password 表示密码模式 username: 资源拥有者的用户名 password: 资源拥有者的密码 授权服务器将令牌access_token 发送给client 这种模式十分简单,但是却意味着直接将用户敏感信息泄露给了client, 因此这就说明了这种模式只能用于client 是我们呢自己开发的模式下,因此密码模式一般用于我们自己开发的, 第一方原生APP 或者第一方单页面应用 3.3.2 代码测试POST http://localhost:8000/uaa/oauth/token 请求参数: 3.4 客户端模式3.4.1 客户端模式介绍 客户端向授权服务器发送自己的身份信息,并请求令牌(access_token) 确认客户端身份无误后, 将令牌(access_token) 发送给client, 请求如下: /uaa/oauth/token?client_id=c1&client_secret=secret&grant_type=client_credentials 参数列表如下: client_id: 客户端准入标识 client_secret: 客户端密钥 grant_type: 授权类型,添加client_credentials 表示客户端模式 这种模式是最方便但是最不安全的模式,因此这就要求我们对client 完全信任,而client本身也是安全的. 因此这种模式一般用来提供给我们完全信任的服务器端服务, 比如:合作方系统对接,拉取一组用户信息. 3.4.2 客户端模式代码演示POST http://localhost:53020/uaa/oauth/token 4. 资源服务测试4.1 资源服务器配置@EnableResourceServer 注解到一个@Configuration 配置类上,并且必须使用ResourceServerConfigurer 这个配置对象来进行配置(可以选择继承ResourceServerConfigurerAdapter 然后覆盖里面的方法, 参数就是这个对象的实例), 下面是一些可以配置的属性: ResourceServerSecurityConfigure 中主要包括 tokenServices: ResourceServerTokenServices 类的实例,用来实现令牌服务 tokenStore:TokenStore类的实例,指定令牌如何访问, 与tokenServices 配置可选 resourceId: 这个资源服务的ID, 这个属性是可选的,但是推荐设置并在授权服务中进行验证. 其他的扩展属性例如tokenExtractor 令牌提取器用来提取请求中的令牌. HttpSecurity 配置这个与Spring Security 的配置类似 请求匹配器, 用来设置需要进行保护的资源,默认的情况下是保护资源服务的全部路径 通过http.authorizeRequests() 来设置受保护资源的访问规则 其他的自定义权限保护规则通过HttpSecurity 来进行配置. @EnableResourceServer 注解自动增加了一个类型为OAuth2AuthenticationProcessingFilter 的过滤器链, 编写 ResouceServerConfig: @Configuration @EnableResourceServer @EnableGlobalMethodSecurity(prePostEnabled = true) public class ResourceServerConfig extends ResourceServerConfigurerAdapter &amp;#123; public static final String RESOURCE_ID = \"res1\"; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &amp;#123; resources.resourceId(RESOURCE_ID) .tokenServices(tokenServices()) .stateless(true); &amp;#125; @Override public void configure(HttpSecurity http) throws Exception &amp;#123; http.authorizeRequests() .antMatchers(\"/**\") .access(\"#oauth2.hasScope('all')\") .and() .csrf() .disable() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS); &amp;#125; &amp;#125; 4.2 验证tokenResourceServerTokenServices 是组成授权服务的另一半,如果你的授权服务和资源服务在同一个应用程序上的话, 你可以使用DefaultTokenServices, 这样的话, 就不需要考虑关于实现所有必要接口的一致性问题,如果你的资源服务是分开开的,那么你就必须要确保能够有匹配服务提供的 ResourceServerTokenServices, 它知道如何对令牌进行解码. 令牌解析方法: 使用DefaultTokenServices 在资源服务器本地配置令牌存储、解码、解析方式,使用RemoteTokenServices 资源服务器通过HTTP 请求来解码令牌,每次都请求授权服务器端点/oauth/check_token 使用授权服务的/oauth/check_token 端点你需要在授权服务将这个端点暴露出去,以便资源服务可以进行访问,这在咱们的授权服务i的配置中已经提到了,下面是一个例子,在这个例子中, 我们在授权服务中配置了/oauth/check_token 和 /oauth/token_key 这两个端点. //令牌端点安全约束 @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &amp;#123; security.tokenKeyAccess(\"permitAll()\") //(1) .checkTokenAccess(\"permitAll()\") //(2) .allowFormAuthenticationForClients();//(3) &amp;#125; 在资源服务配置RemoteTokenServices, 在ResourceServerConfig 中配置: public static final String RESOURCE_ID = \"res1\"; /** * 资源服务令牌解析服务 * * @return */ @Bean public ResourceServerTokenServices tokenServices() &amp;#123; //使用远程服务请求授权服务器校验token , 必须指定校验token 的url,client_id,client_secret RemoteTokenServices services = new RemoteTokenServices(); services.setCheckTokenEndpointUrl(\"http://localhost:8000/uaa/oauth/check_token\"); services.setClientId(\"c1\"); services.setClientSecret(\"secret\"); return services; &amp;#125; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &amp;#123; resources.resourceId(RESOURCE_ID) .tokenServices(tokenServices()) .stateless(true); &amp;#125; 4.3 编写资源在controller 包下编写OrderController, 此controller 表示订单资源的访问类 @RestController @RequestMapping(\"r\") public class OrderController &amp;#123; @GetMapping(\"r1\") @PreAuthorize(\"hasAnyAuthority('p1')\") public String r1() &amp;#123; return \"访问r1资源\"; &amp;#125; &amp;#125; 4.4 添加安全访问控制@Configuration @EnableGlobalMethodSecurity(prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; //安全拦截机制 @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http.csrf().disable() .authorizeRequests() .antMatchers(\"/r/**\").authenticated()// 所有r/**的请求都必须通过认证 .anyRequest().permitAll(); // 除了r/r** 之外的请求都放行 &amp;#125; &amp;#125; 4.5 代码测试4.5.1 申请令牌我们这里使用的是密码模式 返回结果: &amp;#123; \"access_token\": \"915fe34e-72e6-4b1f-b1ee-74c4b91d483a\", \"token_type\": \"bearer\", \"refresh_token\": \"08190be7-0b32-4576-a1e7-170211aefe5e\", \"expires_in\": 7199, \"scope\": \"all\" &amp;#125; 4.5.2 请求资源按照oauth2.0的协议要求,请求资源需要携带token,如下： token的参数名为:Authorization, 值为: Bearer token值 当我们输入一个错误的token的话可以看到 提示token 无效 具体代码见 https://github.com/lyn-workspace/spring-security-oauth2-demo的 spring-security-oauth-memory 分支 5. JWT 令牌5.1 JWT 介绍通过上面的测试我们发现,当资源服务和授权服务不在一起的时候, 资源服务使用RemoteTokenServices 远程请求授权服务验证token, 如果访问量大的话会影响系统的性能. 解决上面的问题: 令牌采用JWT 格式即可以解决上面的问题,用户认证通过会得到一个JWT令牌,JWT 令牌中已经包含了用户相关的信息,客户端只需要携带JWT 访问资源服务, 资源服务根据事先约定好的算法自行完成令牌校验,无需每次都请求认证服务完成授权. 5.1.1 什么是JWTJSON Web Token（JWT） 是一个开放的行业标准(RFC 7519), 它定义了一种简洁、自包含的协议格式,用于通信双方传递json 数据,传递的信息经过数据签名可以被验证和信任,JWT 可以使用HMAC 算法或者使用RSA 的公钥/私钥 来对加密签名,防止防止被篡改. 官网: https://jwt.io/ 标准: https://tools.ietf.org/html/rfc7519 JWT 令牌的优点： jwt 基于json,非常方便解析 可以在令牌中自定义丰富的内容,易扩展. 通过非对称加密算法以及数字签名,JWT防止被篡改,安全性高. 资源服务使用JWT可以不依赖认证服务就可以完成授权. 缺点: JWT 令牌较长,占存储空间较大。 5.1.2 JWT令牌结构通过学习JWT 令牌结构为自定义jwt 令牌打好基础. jwt 令牌由三部分组成, 每个部分中间使用(.) ,比如xxxx.yyyy.zzzzz Header 头部包含令牌的类型(即jwt) 以及使用的哈希算法(如HMAC SHA256或RSA) 一个例子如下： 下面是Header 部分的内容: &amp;#123; \"alg\": \"HS256\", \"typ\": \"JWT\" &amp;#125; 将上面的内容使用Base64Url 编码, 得到一个字符串就是jwt 令牌的一部分. Payload 第二部分是负载, 内容也是一个json 对象,内容也是一个json对象,她是存放有效信息的地方,它可以存放jwt 现成的字段,比如iss(签发者),exp(过期时间戳),sub(面向的用户)等, 也可以自定义字段. 最后将第二部分负载使用Base64Url 编码,得到一个字符串就是JWT 令牌的第二部分 一个例子: &amp;#123; \"sub\": \"1234567890\", \"name\": \"456\", \"admin\": true &amp;#125; Signature 第三部分是签名,此部分用于防止jwt 内容被篡改的, 这个部分使用Base64Url 将前面两部分进行编码,编码后使用点(.) 连接组成字符串,最后使用header 中声明签名算法进行签名 一个例子: HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) base64UrlEncode(header): jwt 令牌的第一部分 base64UrlEncode(payload): jwt 令牌的第二部分 secret: 签名所使用的密钥 5.2 配置jwt 令牌服务在uaa 中配置JWT 令牌服务,即可简单实现生成jwt 格式的令牌 TokenConfig @Configuration public class TokenConfig &amp;#123; private String SIGNING_KEY = \"uaa123\"; @Bean public TokenStore tokenStore() &amp;#123; // 使用内存存储令牌 return new JwtTokenStore(accessTokenConverter()); &amp;#125; @Bean public JwtAccessTokenConverter accessTokenConverter() &amp;#123; JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); //对称密钥,资源服务器使用改密钥进行验证 converter.setSigningKey(SIGNING_KEY); return converter; &amp;#125; &amp;#125; 定义Jwt 令牌服务 修改AuthorizationServer @Autowired private JwtAccessTokenConverter accessTokenConverter; public AuthorizationServerTokenServices authorizationServerTokenServices() &amp;#123; DefaultTokenServices tokenServices = new DefaultTokenServices(); tokenServices.setClientDetailsService(clientDetailsService); tokenServices.setSupportRefreshToken(true); tokenServices.setTokenStore(tokenStore); TokenEnhancerChain tokenEnhancerChain = new TokenEnhancerChain(); tokenEnhancerChain.setTokenEnhancers(Arrays.asList(accessTokenConverter)); tokenServices.setTokenEnhancer(tokenEnhancerChain); tokenServices.setAccessTokenValiditySeconds(7200);//令牌的默认有效时间 2小时 tokenServices.setRefreshTokenValiditySeconds(259200); //刷新令牌的默认有效时间3天 return tokenServices; &amp;#125; 5.3 生成jwt 令牌 生成的结果: &amp;#123; \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbImFsbCJdLCJleHAiOjE1OTYxOTE1ODIsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6Ijc5ODYwMTI2LWFmNDItNGY4NC1hNzI5LTRjYzU0MDQ4NDVlNCIsImNsaWVudF9pZCI6ImMxIn0.K9dyhBgEfQvH4hcixhU4r0eo8iV9WVZhL8q_WbpCRWE\", \"token_type\": \"bearer\", \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbImFsbCJdLCJhdGkiOiI3OTg2MDEyNi1hZjQyLTRmODQtYTcyOS00Y2M1NDA0ODQ1ZTQiLCJleHAiOjE1OTY0NDM1ODIsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6IjI0N2ZiNWM4LTBhYzUtNDY4OS1iYTUwLTA2MDMyNThlYjk4ZSIsImNsaWVudF9pZCI6ImMxIn0.1qm0fluVqht7VpvaLYohL0zs6bUuQKqXJfhg9tlFeXo\", \"expires_in\": 7198, \"scope\": \"all\", \"jti\": \"79860126-af42-4f84-a729-4cc5404845e4\" &amp;#125; 5.4 校验jwt 令牌资源服务需要和授权服务拥有一样的签名,令牌服务 将授权服务中的TokenConfig 复制到资源服务中 屏蔽资源服务原来的令牌服务类 @Autowired private TokenStore tokenStore; public static final String RESOURCE_ID = \"res1\"; /** * 资源服务令牌解析服务 * * @return */ // @Bean // public ResourceServerTokenServices tokenServices() &amp;#123; // // //使用远程服务请求授权服务器校验token , 必须指定校验token 的url,client_id,client_secret // RemoteTokenServices services = new RemoteTokenServices(); // services.setCheckTokenEndpointUrl(\"http://localhost:8000/uaa/oauth/check_token\"); // // services.setClientId(\"c1\"); // services.setClientSecret(\"secret\"); // return services; // &amp;#125; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &amp;#123; resources.resourceId(RESOURCE_ID) .tokenStore(tokenStore) .stateless(true); &amp;#125; 测试 申请jwt 令牌 使用 令牌请求资源 令牌申请成功后可以使用 /uaa/oauth/check_token 查询令牌的有效期,并查询令牌的内容, 例如如下： 6. 完善环境配置截至目前客户端信息和授权码信息都是存储到内存中的,生成环境中通常都会存储在数据库中,下面完善环境的配置 6.1 创建表oauth_client_details 表用来存储客户端信息 DROP TABLE IF EXISTS `oauth_client_details`; CREATE TABLE `oauth_client_details` ( `client_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '客户端标 识', `resource_ids` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '接入资源列表', `client_secret` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '客户端秘钥', `scope` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `authorized_grant_types` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `web_server_redirect_uri` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `authorities` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `access_token_validity` int(11) NULL DEFAULT NULL, `refresh_token_validity` int(11) NULL DEFAULT NULL, `additional_information` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL, `create_time` timestamp(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) ON UPDATE CURRENT_TIMESTAMP(0), `archived` tinyint(4) NULL DEFAULT NULL, `trusted` tinyint(4) NULL DEFAULT NULL, `autoapprove` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`client_id`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '接入客户端信息' ROW_FORMAT = Dynamic; INSERT INTO `oauth_client_details` VALUES ('c1', 'res1', '$2a$10$NlBC84MVb7F95EXYTXwLneXgCca6/GipyWR5NHm8K0203bSQMLpvm', 'ROLE_ADMIN,ROLE_USER,ROLE_API', 'client_credentials,password,authorization_code,implicit,refresh_token', 'http://www.baidu.com', NULL, 7200, 259200, NULL, '2019‐09‐09 16:04:28', 0, 0, 'false'); INSERT INTO `oauth_client_details` VALUES ('c2', 'res2', '$2a$10$NlBC84MVb7F95EXYTXwLneXgCca6/GipyWR5NHm8K0203bSQMLpvm', 'ROLE_API', 'client_credentials,password,authorization_code,implicit,refresh_token', 'http://www.baidu.com', NULL, 31536000, 2592000, NULL, '2019‐09‐09 21:48:51', 0, 0, 'false'); oauth_code 表 用来存储授权码: DROP TABLE IF EXISTS `oauth_code`; CREATE TABLE `oauth_code` ( `create_time` timestamp(0) NOT NULL DEFAULT CURRENT_TIMESTAMP, `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `authentication` blob NULL, INDEX `code_index`(`code`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact; 6.2 配置授权服务6.2.1 修改修改AuthorizationServerClientDetailsService和AuthorizationCodeServices 从数据库中读取 @Configuration @EnableAuthorizationServer public class AuthorizationServer extends AuthorizationServerConfigurerAdapter &amp;#123; @Autowired private TokenStore tokenStore; @Autowired private ClientDetailsService clientDetailsService; @Bean public AuthorizationServerTokenServices authorizationServerTokenServices() &amp;#123; DefaultTokenServices services = new DefaultTokenServices(); services.setClientDetailsService(clientDetailsService); services.setSupportRefreshToken(true); services.setTokenStore(tokenStore); services.setAccessTokenValiditySeconds(7200);//令牌默认的有效时间为2小时 services.setRefreshTokenValiditySeconds(259200);//刷新令牌默认有效期为3天 return services; &amp;#125; @Autowired private AuthenticationManager authenticationManager; @Autowired private AuthorizationCodeServices authorizationCodeServices; /** * &lt;p>令牌访问端点&lt;/p> * * @param endpoints * @author luyanan * @since 2020/7/30 */ @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &amp;#123; endpoints.authenticationManager(authenticationManager) .authorizationCodeServices(authorizationCodeServices) .tokenServices(authorizationServerTokenServices()) .allowedTokenEndpointRequestMethods(HttpMethod.POST); &amp;#125; @Bean public AuthorizationCodeServices authorizationCodeServices() &amp;#123; // 设置授权码模式的授权码如何存储, 暂时采用内存存储的方式 return new InMemoryAuthorizationCodeServices(); &amp;#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &amp;#123; // clients.withClientDetails(clientDetailsService); clients.inMemory()// 使用in‐memory存储 .withClient(\"c1\")// client_id .secret(new BCryptPasswordEncoder().encode(\"secret\")) .resourceIds(\"res1\") .authorizedGrantTypes(\"authorization_code\", \"password\", \"client_credentials\", \"implicit\", \"refresh_token\")// 该client允许的授权类型 authorization_code,password,refresh_token,implicit,client_credentials .scopes(\"all\")// 允许的授权范围 .autoApprove(false) //加上验证回调地址 .redirectUris(\"http://www.baidu.com\"); &amp;#125; //令牌端点安全约束 @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &amp;#123; security.tokenKeyAccess(\"permitAll()\") //(1) .checkTokenAccess(\"permitAll()\") //(2) .allowFormAuthenticationForClients();//(3) &amp;#125; &amp;#125; 6.3 测试6.3.1 测试申请令牌使用密码模式申请令牌,客户端信息需要和数据库中的信息一致 6.3.2 测试授权码模式生成的授权码存在数据库中 访问http://localhost:8000/uaa/oauth/authorize?client_id=c1&amp;response_type=code&amp;scope=all&amp;redirect_uri=http://www.baidu.com,输入账号密码以及授权之后, 可以看到重定向后的url 为https://www.baidu.com/?code=iTtRVv,授权码为iTtRVv 这个时候我们看数据库oauth_code 这个表, 同样插入了一条数据, 这样就实现了授权码保存在了数据库中. 而不是像我们之前的保存在内存中. 7. 附录HttpSecurityHttpSecurity的配置列表 方法 说明 openidLogin() 用于基于Openid的验证 headers() 将安全头添加到响应中 cors() 配置跨域资源共享(cors()) sessionManagement() 允许配置会话管理 portMapper() 允许配置一个PortMapper(HttpSecurity#(getSharedObject(class)))，其他提供SecurityConfigurer的对象使用 PortMapper 从 HTTP 重定 向到 HTTPS 或者从 HTTPS 重定向到 HTTP。默认情况下，Spring Security使用一个PortMapperImpl映射 HTTP 端口8080到 HTTPS 端口 8443，HTTP 端口80到 HTTPS 端口443 jee() 配置基于容器的预认证,在这种情况下,认证由Servlet 容器管理 x509() 配置基于x509 rememberMe 允许配置”记住我”的验证 authorizeRequests() 允许基于使用HttpServletRequests 限制访问 requestCache() 允许配置请求缓存 exceptionHandling() 允许配置错误处理 securityContext() 在HttpServletRequest之间的SecurotyContextHolder上设置SecurotyContext的管理,当使用WebSecurityConfigurerAdapte时, 这才自动应用 servletApi() 将HttpServletRequest方法与在其上找到的值集成到SecurityContext中。 当使用 WebSecurityConfigurerAdapter时，这将自动应用 csrf() 添加csrf 的支持, 当使用WebSecurityConfigurerAdapter的时候默认启用 logout() 添加退出登录支持,当使用WebSecurityConfigurerAdapter的时候, 自动应用,默认情况是,访问URL /logout, 使HTTP Session 无效来清除用户,请求已配置的任何#rememberMe() 身份验证,清除SecurityContextHolder, 然后重定向到/login?success anonymous() 允许配置匿名用户的标识方法,当与WebSecurityConfigurerAdapter 结合使用的时候,将自动应用,默认情况下,匿名用户使用org.springframework.security.authentication.AnonymousAuthenticationToken,并包含角色 ROLE_ANONYMOUS formLogin() 支持基于表单的身份验证, 如果为指定 定FormLoginConfigurer#loginPage(String),则将生成默认登录页面 oauth2Login() 根据外部Oauth2.0 或者OpenId Connect 1.0 提供程序配置身份验证 requiresChannel() 配置通道安全,为了使该配置有效,必须提供至少一个所需信道的映射 httpBasic() 配置http Basic的验证 addFilterAt() 在指定的Filter类的位置添加过滤器","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"Spring Security的工作原理(4)","slug":"Security/Spring Security的工作原理(4)","date":"2022-01-04T02:42:07.237Z","updated":"2022-01-04T02:42:07.237Z","comments":true,"path":"2022/01/04/security/spring-security-de-gong-zuo-yuan-li-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/security/spring-security-de-gong-zuo-yuan-li-4/","excerpt":"","text":"Spring Security的工作原理1 结构总览Spring Security 所解决的问题就是安全访问控制, 而安全访问控制其实就是对所有进入系统的请求进行拦截,校验每个请求是否能够访问它所期望的资源,我们可以通过Filter 或者AOP 等技术进行实现,Spring Security 对Web 资源的保护是通过Filter 实现的,所以从这个Filter 来入手,逐步深入Spring Security 的原理. 当初始化Spring Security的时候, 会创建一个名为org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration#springSecurityFilterChain的Servlet 过滤器, 类型为org.springframework.security.web.FilterChainProxy,它实现了javax.servlet.Filter, 因此外部的请求会经过此类,下图是Spring Security 的过滤器链结构图 FilterChainProxy是一个代理, 真正起到作用的是FilterChainProxy 中的SecurityFilterChain 中包含的各个Filter, 同时这些Filter 被Spring 管理, 他们是Spring Security的核心, 各有各的职责,但是他们并不直接处理用户的认证,也不直接处理用户的授权,而是把他们交给了认证管理器AuthenticationManager和决策管理器AccessDecisionManager 进行处理, 下图是FilterChainProxy 相关类的UML 图示 Spring Security 功能的实现主要是由一系列的过滤器链相互配合完成. 下面介绍过滤器链中几个主要的过滤器以及作用 SecurityContextPersistenceFilter 这个Filter 是整个拦截过程的入口和出口(也就是第一个拦截和最后一个拦截器), 会在请求开始时从配置好的SecurityContextRepository 中获取SecurityContext, 然后把它设置给SecurityContextHolder. 在请求完成后将SecurityContextHolder 持有的SecurityContext 再保存到配置好的SecurityContextRepository ,同时清除 securityContextHolder 所持有的SecurityContext. UsernamePasswordAuthenticationFilter 用于处理来自表单提交的认证, 该表单必须提供对应的用户名和密码,其内部还有登陆成功或者失败后进行处理的AuthenticationSuccessHandler 和 AuthenticationFailureHandler,这些都可以根据需求进行做出相应的改变. FilterSecurityInterceptor 是用于保护web 资源的,使用AccessDecisionManager 对当前用户进行授权访问,全面已经详细介绍过了. ExceptionTranslationFilter 能够捕获来自FilterChain 的所有的异常,并进行处理. 但是他只会处理两类异常: AuthenticationException 和AccessDeniedException, 其他的异常会继续抛出. 2. 认证流程2.1 认证流程 让我们仔细的分析一下认证过程 用户提交用户名、密码被SecurityFilterChain 中的UsernamePasswordAuthenticationFilter 过滤器获取到, 封装为请求Authentication, 通常情况下是UsernamePasswordAuthenticationToken 这个实现类. 然后过滤器将Authentication 提交至认证管理器AuthenticationManager 进行认证 认证成功后,AuthenticationManager 身份管理器返回一个被填充满了信息的(包括上面提到的权限信息、身份信息、细节信息、但密码通常会被移除)的Authentication 实例 SecurityContextHolder 安全上下文容器将第3步填充了信息的Authentication 实例,通过SecurityContextHolder.getContext().setAuthentication(…) 方法设置到其中. 可以看出AuthenticationManager 接口(认证管理器)是认证相关的核心接口,也是发起认证的出发点,他的实现类为ProviderManager. 而Spring Security 支持多种认证方式,因为ProviderManager 维护着一个List&lt;AuthenticationProvider&gt; 列表,存放多种认证方式,最终实际的认证工作是由AuthenticationProvider 完成的. 咱们知道web 表单的对应的AuthenticationProvider 实现类为DaoAuthenticationProvider,他的内部维护着一个 UserDetailsService 负责UserDetails的获取, 最终AuthenticationProvider 把UserDetails 填充至Authentication. 认证核心组件的大体关系如下: 2.2 AuthenticationProvider通过前面的Spring Security 认证流程我们知道,认证管理器AuthenticationManager 委托AuthenticationProvider 完成认证工作. public interface AuthenticationProvider &amp;#123; Authentication authenticate(Authentication var1) throws AuthenticationException; boolean supports(Class&lt;?> var1); &amp;#125; authenticate 方法定义了认证的实现过程,他的参数是一个Authentication, 里面包含了登陆用户所提交的用户、密码等. 而返回值也是一个Authentication, 这个Authentication是在认证成功后,将用户的权限以及其他信息重新组装后生成的. Spring Security 中维护着一个List&lt;AuthenticationProvider&gt; 列表, 存放多种认证方式, 不同的认证方式使用不同的AuthenticationProvider. 如使用用户名密码的登陆的时候,会使用AuthenticationProvider1, 使用短信登陆的时候使用AuthenticationProvider2 等等这样的例子. 每个AuthenticationProvider 需要实现supports 方法来表明自己支持的认证方式,如我们使用表单方式认证,在提交请求的时候,Spring Security 会生成UsernamePasswordAuthenticationToken, 它是一个Authentication,它里面封装着用户提交的用户名、密码信息, 而对应的哪个AuthenticationProvider 来处理它? 我们在DaoAuthenticationProvider 的基类 AbstractUserDetailsAuthenticationProvider 发现以下代码, public boolean supports(Class&lt;?> authentication) &amp;#123; return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication); &amp;#125; 也就是说, 当web 表单提交用户名、密码的时候,Spring Security 由DaoAuthenticationProvider 处理. 最后我们来看一下Authentication(认证信息)的结构, 它是一个接口,我们之前提到的UsernamePasswordAuthenticationToken 就是它的实现之一. public interface Authentication extends Principal, Serializable &amp;#123; Collection&lt;? extends GrantedAuthority> getAuthorities(); Object getCredentials(); Object getDetails(); Object getPrincipal(); boolean isAuthenticated(); void setAuthenticated(boolean var1) throws IllegalArgumentException; &amp;#125; Authentication 是Spring Security 包中的接口, 直接继承自Principal 类,而Principal 是java.security.Principal 包中的,它是表示一个抽象的主体身份,任何主体都有一个名称,所以包含一个getName 方法. getAuthorities 权限信息列表,默认是GrantedAuthority 接口的一些实现类,通常是代表权限信息的一系列字符串. getCredentials 凭证信息,用户输入的密码字符串,在认证过后通常会被移除,用户保证安全. getDetails(), 细节信息,web 应用中的实现接口通常为 WebAuthenticationDetails,它记录了访问者的ip地址和sessionId 信息. getPrincipal() 身份信息,大部分情况下返回的是UserDetails 接口的实现类,UserDetail 代表用户的详细信息,拿从Authentication 中取出来的UserDetails 就是当前登陆的用户信息,它也是框架中常用的接口之一. 2.3 UserDetailsService2.3.1 认识UserDetailsService我们知道DaoAuthenticationProvider 处理了web 表单的认证逻辑,认证成功后得到一个 Authentication(UsernamePasswordAuthenticationToken实现),里面包含了身份信息(Principal).这个身份信息是一个Object, 大多数情况下它可以被强转为UserDetails 对象. DaoAuthenticationProvider 中包含了一个UserDetailsService实例, 它负责根据用户名提出用户信息UserDetail(包含密码), 而后DaoAuthenticationProvide 会去对比UserDetailsService 提取的用户密码与用户提交的密码是否匹配作为认证成功的依据,因此可以通过将自定义的UserDetailsService 作为Spring Bean 来自定义身份验证. public interface UserDetailsService &amp;#123; UserDetails loadUserByUsername(String var1) throws UsernameNotFoundException; &amp;#125; 很多人把 把DaoAuthenticationProvider 和UserDetailsService 的职责搞混淆, 其实 UserDetailsService 只负责从特定的地方(通常是数据库)加载用户信息,仅此而已. 而 DaoAuthenticationProvider 的职责更大,它完成完整的认证流程, 并且会把UserDetails 填充到Authentication. 上面一直提到的UserDetails 是用户信息 public interface UserDetails extends Serializable &amp;#123; Collection&lt;? extends GrantedAuthority> getAuthorities(); String getPassword(); String getUsername(); boolean isAccountNonExpired(); boolean isAccountNonLocked(); boolean isCredentialsNonExpired(); boolean isEnabled(); &amp;#125; 它和Authentication 接口很类似,比如他们都拥有username、authorities。 Authentication 的getCredentials() 与UserDetails 中的getPassword() 需要被区别对待,前者是用户提交的密码凭证,后者是用户实际存储的密码,认证其实就是这两者的对比. Authentication 中的getAuthorties() 实际上的由UserDetails 的getAuthories() 传递而形成的. 还记得Authentication 接口中的getDetails() 方法吗? 其中的UserDetails 用户详细信息便是经过了AuthenticationProvider 认证之后被填充的. 通过实现UserDetailsService 和UserDetails,我们可以完成对用户信息以及用户信息字段的扩展. Spring Security 提供的 InMemoryUserDetailsManager(内存认证), JdbcUserDetailsManager(jdbc认证) 就是UserDetailsService 的实现类,主要区别无非是从内存还是从数据库加载用户. 2.4 测试自定义UserDetailsService @Service public class ConsumerUserDetailsService implements UserDetailsService &amp;#123; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException &amp;#123; // 这里使用静态数据 return User.withUsername(\"zhangsan\").password(\"123456\").authorities(\"p1\").build(); &amp;#125; &amp;#125; 2.5 PasswordEncoder2.5.1 认识PasswordEncoderDaoAuthenticationProvider 认证处理器 通过UserDetailsService 获取到UserDetails 后, 它是如何与请求Authentication 中的密码做对比呢? Spring Security 为了适应多种多样的加密类型, 做了抽象,DaoAuthenticationProvider 通过PasswordEncoder 接口的matchers 方法进行密码的对比,而具体的密码对比细节取决于实现. public interface PasswordEncoder &amp;#123; String encode(CharSequence var1); boolean matches(CharSequence var1, String var2); default boolean upgradeEncoding(String encodedPassword) &amp;#123; return false; &amp;#125; &amp;#125; 而Spring Security 内置了很多的PasswordEncoder,能够开箱即用,使用某种PasswordEncoder 只需要进行如下配置即可 // 密码编码器 @Bean public PasswordEncoder passwordEncoder() &amp;#123; return NoOpPasswordEncoder.getInstance(); &amp;#125; NoOpPasswordEncoder 采用字符串匹配法, 不对密码做加密比较处理. 密码比较流程如下： 用户输入密码(明文) DaoAuthencationProvider 获取UserDetails(其中存储了用户的正确密码) DaoAuthencationProvider 使用passwordEncoder 对输入的密码和正确的密码进行校验,密码一致则通过, 否则则校验失败. NoOpPasswordEncoder 的校验规则就是那输入的用户和UserDetails 中的正确的密码进行字符串对比,字符串内容一致则校验通过, 否则校验失败. 实际项目中, 推荐使用 BCryptPasswordEncoder, Pbkdf2PasswordEncoder, SCryptPasswordEncoder 等. 2.5.2 使用 BCryptPasswordEncoder 配置 BCryptPasswordEncoder @Bean public PasswordEncoder passwordEncoder() &amp;#123; return new BCryptPasswordEncoder(); &amp;#125; 生成 BCrypt 格式的密码 添加依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;/dependency> 测试代码 @Test public void test() &amp;#123; String hashpw = BCrypt.hashpw(\"123\", BCrypt.gensalt()); System.out.println(hashpw); //校验原始密码和BCrypt 是否一致 System.out.println(BCrypt.checkpw(\"123\", hashpw)); &amp;#125; 结果 $2a$10$Z0lpyLYr3DYWdpRQPr3i5eVx3Q1LolIz7QUDCcq5aFePUh5IahaEa true 修改安全配置类 将UserDetaiuls 中的原始密码修改为BCrypt 格式的 // 配置用户信息 @Bean public UserDetailsService userDetailsService() &amp;#123; InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(\"zhangsan\").password(\"$2a$10$Z0lpyLYr3DYWdpRQPr3i5eVx3Q1LolIz7QUDCcq5aFePUh5IahaEa\").authorities(\"p1\").build()); manager.createUser(User.withUsername(\"lisi\").password(\"$2a$10$Z0lpyLYr3DYWdpRQPr3i5eVx3Q1LolIz7QUDCcq5aFePUh5IahaEa\").authorities(\"p2\").build()); return manager; &amp;#125; 在我们的实际项目中, 数据库中存储的密码并不是原始密码,都是经过加密处理的. 3. 授权流程3.1 授权流程我们知道,Spring Security 可以通过http.authorizeRequests() 对web 请求进行授权保护,Spring Security 使用标准的Filter 建立了对web 请求的拦截,最终实现对资源的授权访问. Spring Security 的授权流程如下: 分析授权流程: 拦截请求: 已认证用户访问受保护的web 资源将被SecurityFilterChain 中的FilterSecurityInterceptor子类拦截, 获取资源访问策略: FilterSecurityInterceptor 会从 SecurityMetadataSource 的子类DefaultFilterInvocationSecurityMetadataSource 获取要访问当前资源所需要的权限Collection&lt;ConfigAttribute&gt;. SecurityMetadataSource 其实就是读取访问策略的抽象,而读取的内容,其实就是我们配置的访问规则,读取访问策略如: http.authorizeRequests() //访问/r/r1资源的 url需要拥有p1权限。 .antMatchers(\"/r/r1\").hasAuthority(\"p1\") //访问/r/r2资源的 url需要拥有p2权限。 .antMatchers(\"/r/r2\").hasAuthority(\"p2\") .antMatchers(\"/r/**\").authenticated() ...... 最后, FilterSecurityInterceptor 会调用AccessDecisionManager 进行授权决策,若决策通过,则允许访问资源,否则不允许. AccessDecisionManager(访问决策管理器) 的核心接口如下: public interface AccessDecisionManager &amp;#123; void decide(Authentication var1, Object var2, Collection&lt;ConfigAttribute> var3) throws AccessDeniedException, InsufficientAuthenticationException; boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?> var1); &amp;#125; 这里着重说一下decide的参数 authentication: 要访问资源的访问者的身份 object: 要访问的受保护资源,web 请求对应的FilterInvocation configAttributes: 是受保护资源的访问策略,通过SercurotyMetadataSource 获取 decide 接口就是用来鉴定当前用户是否有访问对应受保护资源的权限的. 3.2 授权决策AccessDecisionManager 采用投票的方式来确定是否能够访问受保护资源. 通过上图可以看出,AccessDecisionManager 包含了一系列AccessDecisionVoter 将会被用来对Authencation 是否有权访问受保护对象进行投票,AccessDecisionManager 根据投票的结果,做出最终的决策. AccessDecisionVoter 是一个接口,其中定义了三个方法,具体结构如下所示: public interface AccessDecisionVoter&lt;S> &amp;#123; int ACCESS_GRANTED = 1; int ACCESS_ABSTAIN = 0; int ACCESS_DENIED = -1; boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?> var1); int vote(Authentication var1, S var2, Collection&lt;ConfigAttribute> var3); &amp;#125; vote() 方法的返回结果会是AccessDecisionVoter 定义好的三个常量之一,ACCESS_GRANTED 表示同意,ACCESS_DENIED 表示拒绝, ACCESS_ABSTAIN 表示弃权. 如果一个 AccessDecisionVoter 不能判断当前Authentication 是否拥有了访问受保护对象的权限,则其vote() 方法的返回值应当为 弃权. Spring Security 内置了三个基于投票的 AccessDecisionManage 实现类如下,他们分别是 AffirmativeBased、ConsensusBased和UnanimousBased. **AffirmativeBased**的逻辑是: 只要有AccessDecisionVoter的投票结果为 ACCESS_GRANTED,则同意用户进行访问 如果全部弃权也表示通过 如果没有一个人投赞成票,但是有人投反对票, 则将抛出 AccessDeniedException. Spring Security 默认使用的是 AffirmativeBased ConsensusBased的逻辑是: 如果赞成票多于反对票则表示通过. 反过来, 如果反对票多于赞同票则将抛出 AccessDeniedException 如果赞同票和反对票相同且不等于0, 并且属性 allowIfEqualGrantedDeniedDecisions的值为true. 则表示通过, 否则将抛出AccessDeniedException, 参数 allowIfEqualGrantedDeniedDecisions的默认值为true. 如果所有的AccessDecisionVoter 都弃权了, 则将视参数 allowIfAllAbstainDecisions的值而定, 如果该值为true 则表示通过,否则将抛出异常AccessDeniedExeception. 参数 allowIfAllAbstainDecisions 的值默认为false. UnanimousBased的逻辑与另外两种实现有种不太一样,另外两种 会一次性把受保护的对象的配置属性全部传递给AccessDecisionVoter 进行投票, 而 UnanimousBased 一次只会传递一个 ConfigAttribute 给AccessDecisionVoter 进行投票 , 也就是意味着 我们的AccessDecisionVoter 的逻辑是只要传递进来的 ``ConfigAttribute 中有一个能够匹配则投赞成票,但是放到 UnanimousBased` 中其投票结果就不一定是赞成了, UnanimousBased的逻辑具体来说是这样的: 如果受保护的对象配置的某一个 ConfigAttribute 被任意的 AccessDecisionVoter 反对了,则 抛出AccessDeniedException. 如果没有反对票,但是有赞成票,则通过. 如果全部弃权了, 则将视参数 allowIfAllAbstainDecisions的值而定,如果为true 则表示通过,false 则抛出AccessDeniedException. Spring Security也内置一些投票者实现类如RoleVoter、AuthenticatedVoter和WebExpressionVoter等，可以 自行查阅资料进行学习","categories":[{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"}],"tags":[]},{"title":"揭开ServerBootstrap的神秘面纱(8)","slug":"Netty/揭开ServerBootstrap的神秘面纱(8)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/jie-kai-serverbootstrap-de-shen-mi-mian-sha-8/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/jie-kai-serverbootstrap-de-shen-mi-mian-sha-8/","excerpt":"","text":"揭开ServerBootstrap 的神秘面纱1. 简介我们首先来看一下 ServerBootstrap 服务端的启动代码 public void start(int port) &amp;#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &amp;#123; ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.channel(NioServerSocketChannel.class) .group(bossGroup, workerGroup) .childHandler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; &amp;#125; &amp;#125;) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); // 绑定端口, 开始接受进来的请求 ChannelFuture future = bootstrap.bind(port).sync(); future.channel().closeFuture().sync(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &amp;#125; &amp;#125; public static void main(String[] args) &amp;#123; new NIOChatServer().start(8080); &amp;#125; 服务端基本写法和客户端的代码相比, 没有很大的差别, 基本上也是进行了如下几个部分的初始化： EventLoopGroup: 不论是服务端代码还是客户端, 都必须指定 EventLoopGroup. 在上面的代码中, 指定了NioEventLoopGroup, 表示一个 NIO的EventLoopGroup, 不过服务端需要指定两个 EventLoopGroup, 一个是bossGroup, 用于处理客户端的连接请求， 另一个是 workGroup, 用于处理与各个客户端连接的IO操作 ChannalType: 指定channel的类型, 因为是服务器端, 因此用到了NioServerSocketChannel handler : 设置数据处理器 2. NioServerSocketChannel 的创建我们在分析客户端channel 初始化过程已经提到, Channal 是对Java 底层Socket 连接的抽象, 并且知道了客户端Channel 的具体类型是 NioServerSocketChannel . 那么, 自然的服务端的Channel 类型就是NioServerSocketChannel . 那么接下来我们按照分析客户端的流程对服务端的代码也同样的分析一遍, 通过前面的分析, 我们已经知道了, Chanel的类型的指定是在初始化时 , 通过Bootstrap 的channel 方法设置的, 服务端也是同样的方式. 再看服务端代码, 我们调用了 ServerBootystrap 的channel(NioSocketChannel.class) 方法, 传的参数是 NioSocketChannel 对象 如此， 按照客户端代码同样的流程, 我们可以确定 NioSocketChannel的实例化也是通过 ReflectiveChannelFactory 来创建的., 而ReflectiveChannelFactory 中的clazz 字段被 赋值为 NioServerSocketChannel.class, 因此当调用 NioServerSocketChannel 的 newChannel 方法, 就能获取到一个 NioServerSocketChannel的 实例. newChannel() 方法的源码如下： @Override public T newChannel() &amp;#123; try &amp;#123; return clazz.newInstance(); &amp;#125; catch (Throwable t) &amp;#123; throw new ChannelException(\"Unable to create Channel from class \" + clazz, t); &amp;#125; &amp;#125; 最后, 我们来总结一下: ServerBootstrap 中 的channelFactory 的实现类是ReflectiveChannelFactory类 创建的Channel 具体类型是NioServerSocketChannel channel 实例化过程, 其实就是调用chanellFactory 的 newChannel() 方法， 而实例化的Channel 具体类型就是初始化 ServerBootstrap 时传给 chanel() 方法的实参, 因此, 上面代码案例中的服务端 ServerBootstrap , 创建的 Channel 实例就是 NioServerSocketChannel 的实例。 3. 服务端Channel 的初始化接下来我们来分析一下 NioServerSocketChannel 的实例化过程, 先看一下 NioServerSocketChannel 的 类层次结构图: 首先, 我们来追踪一下 NioServerSocketChannel 的默认构造, 和 NioSocketChannel 类似, 构造器都是调用 newSocket() 来打来一个Java 的NIO Socket. 不过需要注意的是, 客户端的 newSocket 方法调用的是openSocketChannel()，而 服务端的 newSocket() 调用的是 openServerSocketChannel(). 顾名思义, 一个是客户端是 java SocketChannel, 一个是服务端的 Java ServerSocketChannel, 来看代码 private static ServerSocketChannel newSocket(SelectorProvider provider) &amp;#123; try &amp;#123; /** * Use the &amp;#123;@link SelectorProvider&amp;#125; to open &amp;#123;@link SocketChannel&amp;#125; and so remove condition in * &amp;#123;@link SelectorProvider#provider()&amp;#125; which is called by each ServerSocketChannel.open() otherwise. * * See &lt;a href=\"https://github.com/netty/netty/issues/2308\">#2308&lt;/a>. */ return provider.openServerSocketChannel(); &amp;#125; catch (IOException e) &amp;#123; throw new ChannelException( \"Failed to open a server socket.\", e); &amp;#125; &amp;#125; /** * Create a new instance */ public NioServerSocketChannel() &amp;#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER)); &amp;#125; 接下来会调用重载的方法 public NioServerSocketChannel(ServerSocketChannel channel) &amp;#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); &amp;#125; 这个构造方法中, 调用父类构造方法时传入的参数是 SelectionKey.OP_ACCEPT. 作为对比, 我们回复一下, 在 客户端的Channel 初始化的时候, 传入的参数为 SelectionKey.OP_READ。在服务启动后需要监听客户端的连接请求, 因此这里我们设置为 SelectionKey.OP_ACCEPT, 也就是通知 selector 对客户端的连接请求感兴趣. 接着和客户端对比分析一下, 会逐层的调用父类的构造器 NioServerSocketChannel -&gt; AbstractNioMessageChannel -&gt; AbstractNioChannel -&gt; AbstractChannel。同样在 AbstractChannel 中实例化一个unsafe 和 pipeline. protected AbstractChannel(Channel parent) &amp;#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline(); &amp;#125; 不过, 这里需要注意的是, 客户端的unsafe 是 AbstractNioByteChannel#NioByteUnsafe 的实例, 而服务端的unsafe 的实例是 AbstractNioMessageChannel.AbstractNioUnsafe 的实例。 因为 AbstractNioMessageChannel 重写了 newUnsafe() 方法, 其源代码如下： @Override protected AbstractNioUnsafe newUnsafe() &amp;#123; return new NioMessageUnsafe(); &amp;#125; 最后再总结一下 NioServerSocketChannel 实例化过程的执行逻辑 调用 NioServerSocketChannel.newSocket(DEFAULT_SELECTOR_PROVIDER) 方法打开一个新的 Java Nio ServerSocketChannel AbstractChannel 初始化被赋值的属性: parent: 设置为 null unsafe: 通过 newUnsafe() 实例化 一个 unsafe 对象, 类型是 AbstractNioMessageChannel#AbstractNioUnsafe pipeline : DefaultChannelPipeline 实例 AbstractNioChannel 中被赋值的属性: ch: 赋值为 Java Nio 的ServerSocketChannel, 调用NioSocketChannel 的 newSocket() 获取 readInterstOp: 默认赋值为 SelectionKey.OP_ACCEPT ch: 设置为非阻塞, 调用 ch.configureBlocking(false)方法 NioServerSocketChannel: config: new NioServerSocketChannelConfig(this, javaChannel().socket()); 4. ChannelPipeline 初始化服务端ChannelPipeline 的初始化跟 客户端的一样 5. 服务端Channel 注册到Selector服务端Channel 的注册过程跟客户端的一样 6. bossGroup 和workGroup在客户端的时候,我们初始化了一个 EventLoopGroup 对象, 而在服务端初始化时, 我们设置了两个EventLoopGroup. 一个是 bossGroup, 一个是 workGroup, 那么这两个 EventLoopGroup 都是干什么的呢? 接下来我们来详细探究一下. 其实 , bossGroup 只用于服务端的 accept, 也就是用于处理客户端新连接接入请求, 我们可以将Netty 比喻为一个餐馆, bossGroup 就像一个大堂经理, 当客户来到餐馆吃饭的时候, 大堂经理就会引导顾客就坐, 为顾客端茶送水等. 而workGroup 就是实际上干活的厨师. 他们负责客户端连接通道的IO操作, 当大堂尽力接待顾客后, 就可以稍作休息, 而此时厨师们(workGroup) 就开始忙碌的准备饭菜 ， 关于bossGroup和workerGroup 的关系, 我们可以用下图来表示, 首先, 服务端的 bossGroup 不断监听是否有客户端的连接, 当发现有新的客户端连接到来时 , bossGroup 就会为此连接初始化各种资源, 然后从 workerGroup 中选出一个EventLoop 绑定到此客户端连接中, 那么接下来服务器和客户端的交互过程就全在此分配的 EventLoop 中完成, 首先在ServerBootstrap 初始化时, 调用了 bootstrap.group(bossGroup,workGroup) 设置了两个EventLoop, 我们跟踪进去就会发现： public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) &amp;#123; super.group(parentGroup); if (childGroup == null) &amp;#123; throw new NullPointerException(\"childGroup\"); &amp;#125; if (this.childGroup != null) &amp;#123; throw new IllegalStateException(\"childGroup set already\"); &amp;#125; this.childGroup = childGroup; return this; &amp;#125; 显然, 这个方法初始化了两个字段, 一个是 group = parentGroup, 它是在 super.group(parentGroup); 中完成初始化的, 另一个是 this.childGroup = childGroup; 接着从 应用程序的启动代码来看调用了 bootstrap.bind() 方法来监听一个本地端口, bing() 方法会触发如下调用链 AbstractBootstrap.bind() -&gt; AbstractBootstrap.doBind() -&gt; AbstractBootstrap.initAndRegister() 源码看到这里为止，我们发现 AbstractBootstrap 的 initAndRegister()方法已经分析过了, 再来回顾一下这个方法 final ChannelFuture initAndRegister() &amp;#123; Channel channel = null; try &amp;#123; channel = channelFactory.newChannel(); init(channel); &amp;#125; catch (Throwable t) &amp;#123; if (channel != null) &amp;#123; // channel can be null if newChannel crashed (eg SocketException(\"too many open files\")) channel.unsafe().closeForcibly(); &amp;#125; // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &amp;#125; ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &amp;#123; if (channel.isRegistered()) &amp;#123; channel.close(); &amp;#125; else &amp;#123; channel.unsafe().closeForcibly(); &amp;#125; &amp;#125; return regFuture; &amp;#125; 这里 group() 方法返回的是上面我们提到的 bossGroup, 而这里的channel 其实就是 NioServerSocketChannel. 的实例， 因此我们可以猜测到 group().register(channel) 将 bossGroup 和NioSocketChannel 就关联起来了, 那么 workerGroup 具体是在哪里与 NioSocketChannel 关联起来的呢 ? 我们继续往下看 init(channel ) 方法 @Override void init(Channel channel) throws Exception &amp;#123; final Map&lt;ChannelOption&lt;?>, Object> options = options0(); synchronized (options) &amp;#123; channel.config().setOptions(options); &amp;#125; final Map&lt;AttributeKey&lt;?>, Object> attrs = attrs0(); synchronized (attrs) &amp;#123; for (Entry&lt;AttributeKey&lt;?>, Object> e: attrs.entrySet()) &amp;#123; @SuppressWarnings(\"unchecked\") AttributeKey&lt;Object> key = (AttributeKey&lt;Object>) e.getKey(); channel.attr(key).set(e.getValue()); &amp;#125; &amp;#125; ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?>, Object>[] currentChildOptions; final Entry&lt;AttributeKey&lt;?>, Object>[] currentChildAttrs; synchronized (childOptions) &amp;#123; currentChildOptions = childOptions.entrySet().toArray(newOptionArray(childOptions.size())); &amp;#125; synchronized (childAttrs) &amp;#123; currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(childAttrs.size())); &amp;#125; p.addLast(new ChannelInitializer&lt;Channel>() &amp;#123; @Override public void initChannel(Channel ch) throws Exception &amp;#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &amp;#123; pipeline.addLast(handler); &amp;#125; // We add this handler via the EventLoop as the user may have used a ChannelInitializer as handler. // In this case the initChannel(...) method will only be called after this method returns. Because // of this we need to ensure we add our handler in a delayed fashion so all the users handler are // placed in front of the ServerBootstrapAcceptor. ch.eventLoop().execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; pipeline.addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &amp;#125; &amp;#125;); &amp;#125; &amp;#125;); &amp;#125; 实际上init() 方法在ServerBootstrap 被重写了, 从上面的代码来看, 它为pipeline 添加了一个 ChannelInitializer, 而这个 ChannelInitializer 中添加了一个非常关键的 ServerBootstrapAcceptor 的 handler, 在ServerBootstrapAcceptor 中 重写了channelRead() 方法 . 其主要代码如下: @Override @SuppressWarnings(\"unchecked\") public void channelRead(ChannelHandlerContext ctx, Object msg) &amp;#123; final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); for (Entry&lt;ChannelOption&lt;?>, Object> e: childOptions) &amp;#123; try &amp;#123; if (!child.config().setOption((ChannelOption&lt;Object>) e.getKey(), e.getValue())) &amp;#123; logger.warn(\"Unknown channel option: \" + e); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Failed to set a channel option: \" + child, t); &amp;#125; &amp;#125; for (Entry&lt;AttributeKey&lt;?>, Object> e: childAttrs) &amp;#123; child.attr((AttributeKey&lt;Object>) e.getKey()).set(e.getValue()); &amp;#125; try &amp;#123; childGroup.register(child).addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; if (!future.isSuccess()) &amp;#123; forceClose(child, future.cause()); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; catch (Throwable t) &amp;#123; forceClose(child, t); &amp;#125; &amp;#125; ServerBootstrapAcceptor 中的 childGroup 是构造此对象 传入的currentChildGroup, 也就是 workerGroup, 而这里的 channel 是NioSocketChannel 的实例. 因此这里的 childGroup 的 regster() 方法就是将 workerGroup 中的某个EventLoop 和NioSocketChannel 关联上了 . 既然这样, 那么现在的问题是 ServerBootstrapAcceptor 的channelRead() 是在哪里被调用的呢? 其实, 当一个client 连接到server 的时候, Java 底层Nio ServerSocketChannel 就会有一个 SelectionKey.OP_ACCEPT 事件就绪 , 接着会调用到 NioServerSocketChannel 的 doReadMessages() 方法: @Override protected int doReadMessages(List&lt;Object> buf) throws Exception &amp;#123; SocketChannel ch = javaChannel().accept(); try &amp;#123; if (ch != null) &amp;#123; buf.add(new NioSocketChannel(this, ch)); return 1; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Failed to create a new channel from an accepted socket.\", t); try &amp;#123; ch.close(); &amp;#125; catch (Throwable t2) &amp;#123; logger.warn(\"Failed to close a socket.\", t2); &amp;#125; &amp;#125; return 0; &amp;#125; 在 doReadMessages() 方法中, 通过调用 JavaChannel().accept() 方法获取到 客户端新连接的 SocketChannel 对象, 紧接着就实例化一个 NioSocketChannal,并且传入NioServerSocketChannel 对象 , 即this. 由此可知, 我们创建的这个NioSocketChannel 的父类 channel 就是 NioServerSocketChnanel 的实例. 接下来就经由 Netty的Pipelint 机制将读取事件逐个发送到各个handler 中, 于是就会触发我们前面提到的ServerBootstrapAcceptor 的 channelRead()方法。 7. 服务端Selector 事件轮询再回到服务端的 ServerBootstrap 的启动代码,是从bind() 方法开始的, ServerBootstrap 的bind() 方法实际上就是其父类的 AbstractBootstrap的 bind() 方法, 来看代码 public ChannelFuture bind() &amp;#123; validate(); SocketAddress localAddress = this.localAddress; if (localAddress == null) &amp;#123; throw new IllegalStateException(\"localAddress not set\"); &amp;#125; return doBind(localAddress); &amp;#125; private ChannelFuture doBind(final SocketAddress localAddress) &amp;#123; final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &amp;#123; return regFuture; &amp;#125; if (regFuture.isDone()) &amp;#123; // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; &amp;#125; else &amp;#123; // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; Throwable cause = future.cause(); if (cause != null) &amp;#123; // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); &amp;#125; else &amp;#123; // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); &amp;#125; &amp;#125; &amp;#125;); return promise; &amp;#125; &amp;#125; private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &amp;#123; // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. channel.eventLoop().execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; if (regFuture.isSuccess()) &amp;#123; channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &amp;#125; else &amp;#123; promise.setFailure(regFuture.cause()); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; 在doBind0() 方法中,调用的是 EventLoop的execute() 方法, 我们继续跟进去 @Override public void execute(Runnable task) &amp;#123; if (task == null) &amp;#123; throw new NullPointerException(\"task\"); &amp;#125; boolean inEventLoop = inEventLoop(); if (inEventLoop) &amp;#123; addTask(task); &amp;#125; else &amp;#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &amp;#123; reject(); &amp;#125; &amp;#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &amp;#123; wakeup(inEventLoop); &amp;#125; &amp;#125; 在 execute() 中主要是创建线程, 将线程添加到 EventLoop 的无锁化串行任务队列. 我们重点关注一下 startThread() 方法, 继续看代码: private void startThread() &amp;#123; if (STATE_UPDATER.get(this) == ST_NOT_STARTED) &amp;#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &amp;#123; doStartThread(); &amp;#125; &amp;#125; &amp;#125; private void doStartThread() &amp;#123; assert thread == null; executor.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; thread = Thread.currentThread(); if (interrupted) &amp;#123; thread.interrupt(); &amp;#125; boolean success = false; updateLastExecutionTime(); try &amp;#123; SingleThreadEventExecutor.this.run(); success = true; &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Unexpected exception from an event executor: \", t); &amp;#125; finally &amp;#123; for (;;) &amp;#123; int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this); if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet( SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) &amp;#123; break; &amp;#125; &amp;#125; // Check if confirmShutdown() was called at the end of the loop. if (success &amp;&amp; gracefulShutdownStartTime == 0) &amp;#123; logger.error(\"Buggy \" + EventExecutor.class.getSimpleName() + \" implementation; \" + SingleThreadEventExecutor.class.getSimpleName() + \".confirmShutdown() must be called \" + \"before run() implementation terminates.\"); &amp;#125; try &amp;#123; // Run all remaining tasks and shutdown hooks. for (;;) &amp;#123; if (confirmShutdown()) &amp;#123; break; &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; try &amp;#123; cleanup(); &amp;#125; finally &amp;#123; STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED); threadLock.release(); if (!taskQueue.isEmpty()) &amp;#123; logger.warn( \"An event executor terminated with \" + \"non-empty task queue (\" + taskQueue.size() + ')'); &amp;#125; terminationFuture.setSuccess(null); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125;); &amp;#125; 我们发现 startThread() 最终调用的是 SingleThreadEventExecutor.this.run() 方法, 这个this 就是 NioEventLoop 对象: @Override protected void run() &amp;#123; for (;;) &amp;#123; try &amp;#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &amp;#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); // 'wakenUp.compareAndSet(false, true)' is always evaluated // before calling 'selector.wakeup()' to reduce the wake-up // overhead. (Selector.wakeup() is an expensive operation.) // // However, there is a race condition in this approach. // The race condition is triggered when 'wakenUp' is set to // true too early. // // 'wakenUp' is set to true too early if: // 1) Selector is waken up between 'wakenUp.set(false)' and // 'selector.select(...)'. (BAD) // 2) Selector is waken up between 'selector.select(...)' and // 'if (wakenUp.get()) &amp;#123; ... &amp;#125;'. (OK) // // In the first case, 'wakenUp' is set to true and the // following 'selector.select(...)' will wake up immediately. // Until 'wakenUp' is set to false again in the next round, // 'wakenUp.compareAndSet(false, true)' will fail, and therefore // any attempt to wake up the Selector will fail, too, causing // the following 'selector.select(...)' call to block // unnecessarily. // // To fix this problem, we wake up the selector again if wakenUp // is true immediately after selector.select(...). // It is inefficient in that it wakes up the selector for both // the first case (BAD - wake-up required) and the second case // (OK - no wake-up required). if (wakenUp.get()) &amp;#123; selector.wakeup(); &amp;#125; default: // fallthrough &amp;#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &amp;#123; try &amp;#123; processSelectedKeys(); &amp;#125; finally &amp;#123; // Ensure we always run tasks. runAllTasks(); &amp;#125; &amp;#125; else &amp;#123; final long ioStartTime = System.nanoTime(); try &amp;#123; processSelectedKeys(); &amp;#125; finally &amp;#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &amp;#125; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; handleLoopException(t); &amp;#125; // Always handle shutdown even if the loop processing threw an exception. try &amp;#123; if (isShuttingDown()) &amp;#123; closeAll(); if (confirmShutdown()) &amp;#123; return; &amp;#125; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; handleLoopException(t); &amp;#125; &amp;#125; &amp;#125; 终于看到似曾相似的代码, 上面的代码主要就是用一个死循环, 在不断的轮询 SelectionKey,select() 方法 主要用来解决JDK 的空轮训Bug, 而 processSelectedKeys() 就是针对不同的轮询事件 进行处理. 如果客户端有数据写入, 最终也会调用 AbstractNioMessageChannel 的 doReadMessages()方法, 总结一下: Netty 的selector 事件轮询 是从EventLoop 的 execute() 方法开始的 在EventLoop 的 execute() 方法中, 会为每个任务创建一个线程, 并保存到无锁化串行任务队列 线程任务队列的每个任务实际调用的是EventLoop 的 run() 方法 在 run() 中 调用 processSelectedKeys() 处理轮询事件 8 Netty 解决JDK 空轮训Bug各位应该早有耳闻 臭名昭著的 Java NIO epoll的bug, 它会导致 selector 空轮训, 最终导致CPU 100%. 官方声称在 JDK1.6 版本的 update18 修复了此问题, 但是知道JDK1.7 版本该问题仍然存在, 只不过该Bug 发生概率降低了一些而已, 它并没有被 根本解决。出现此bug 是因为当Selector 的轮询结果为空, 也没有 wakeup 或者新消息处理, 则发现空轮训, CPU使用率达到了100%. 我们来看下这个问题在issus的原始描述 This is an issue with poll (and epoll) on Linux. If a file descriptor for a connected socket is polled with a requestevent mask of 0, and if the connection is abruptly terminated (RST) then the poll wakes up with the POLLHUP (andmaybe POLLERR) bit set in the returned event set. The implication of this behaviour is that Selector will wakeup andas the interest set for the SocketChannel is 0 it means there aren’t any selected events and the select methodreturns 0. 具体解释为: 在部分Linux的2.6的 kernel 中, poll 和epoll 对于突然中断的连接 socket 会对返回的 eventSet事件集合置为 POLLHUP，也可能是 POLLERR。 eventSet 事件集合发生了变化, 这就可能导致Selector 会被唤醒. 这是与操作系统机制有关系的, JDK 虽然仅仅是一个兼容各个操作系统平台的软件。但很遗憾在JDK5和JDK6 最初的版本中(严格意义上来讲, JDK版本都是) , 这个问题并没有解决，而将这个帽子抛给了操作系统方, 这也就是这个bug 最终一直到2013 年才最终修复的原因. 在Netty 中 最终的解决办法是: 创建一个新的Selector, 将可用的事件重新注册到新的Selector 中来终止空轮训. 回顾事件轮询的关键代码: protected void run() &amp;#123; for (;;) &amp;#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &amp;#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); //省略 select 的唤醒逻辑 default: &amp;#125; //事件轮询处理逻辑 &amp;#125; &amp;#125; 前面我们有提到了 select() 方法解决JDK 空轮训的bug ,它到底是如何解决的呢? 下来我们来一探究竟, 进入select() 方法的源码 private void select(boolean oldWakenUp) throws IOException &amp;#123; Selector selector = this.selector; try &amp;#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &amp;#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &amp;#123; if (selectCnt == 0) &amp;#123; selector.selectNow(); selectCnt = 1; &amp;#125; break; &amp;#125; // If a task was submitted when wakenUp value was true, the task didn't get a chance to call // Selector#wakeup. So we need to check task queue again before executing select operation. // If we don't, the task might be pended until select operation was timed out. // It might be pended until idle timeout if IdleStateHandler existed in pipeline. if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) &amp;#123; selector.selectNow(); selectCnt = 1; break; &amp;#125; int selectedKeys = selector.select(timeoutMillis); selectCnt ++; if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &amp;#123; // - Selected something, // - waken up by user, or // - the task queue has a pending task. // - a scheduled task is ready for processing break; &amp;#125; if (Thread.interrupted()) &amp;#123; // Thread was interrupted so reset selected keys and break so we not run into a busy loop. // As this is most likely a bug in the handler of the user or it's client library we will // also log it. // // See https://github.com/netty/netty/issues/2426 if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Selector.select() returned prematurely because \" + \"Thread.currentThread().interrupt() was called. Use \" + \"NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.\"); &amp;#125; selectCnt = 1; break; &amp;#125; long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) >= currentTimeNanos) &amp;#123; // timeoutMillis elapsed without anything selected. selectCnt = 1; &amp;#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD > 0 &amp;&amp; selectCnt >= SELECTOR_AUTO_REBUILD_THRESHOLD) &amp;#123; // The selector returned prematurely many times in a row. // Rebuild the selector to work around the problem. logger.warn( \"Selector.select() returned prematurely &amp;#123;&amp;#125; times in a row; rebuilding Selector &amp;#123;&amp;#125;.\", selectCnt, selector); rebuildSelector(); selector = this.selector; // Select again to populate selectedKeys. selector.selectNow(); selectCnt = 1; break; &amp;#125; currentTimeNanos = time; &amp;#125; if (selectCnt > MIN_PREMATURE_SELECTOR_RETURNS) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"Selector.select() returned prematurely &amp;#123;&amp;#125; times in a row for Selector &amp;#123;&amp;#125;.\", selectCnt - 1, selector); &amp;#125; &amp;#125; &amp;#125; catch (CancelledKeyException e) &amp;#123; if (logger.isDebugEnabled()) &amp;#123; logger.debug(CancelledKeyException.class.getSimpleName() + \" raised by a Selector &amp;#123;&amp;#125; - JDK bug?\", selector, e); &amp;#125; // Harmless exception - log anyway &amp;#125; &amp;#125; 从上面的代码中可以看到, Selector 每一次轮询都计数 selectCnt ++, 开始轮询会计时并赋值给 timeoutMillis, 轮询完成后悔计时赋值给 time. 这两个时间差会有一个时间差, 而这个时间差就是每次轮询所消耗的时间, 从上面的逻辑看出， 如果每次轮询消耗的时间为0 ，且重复次数超过512次， 则调用rebuildSelector();, 则重构Selector, 我们跟进到源码中就会发现 public void rebuildSelector() &amp;#123; if (!inEventLoop()) &amp;#123; execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; rebuildSelector(); &amp;#125; &amp;#125;); return; &amp;#125; final Selector oldSelector = selector; final Selector newSelector; if (oldSelector == null) &amp;#123; return; &amp;#125; try &amp;#123; newSelector = openSelector(); &amp;#125; catch (Exception e) &amp;#123; logger.warn(\"Failed to create a new Selector.\", e); return; &amp;#125; // Register all channels to the new Selector. int nChannels = 0; for (;;) &amp;#123; try &amp;#123; for (SelectionKey key: oldSelector.keys()) &amp;#123; Object a = key.attachment(); try &amp;#123; if (!key.isValid() || key.channel().keyFor(newSelector) != null) &amp;#123; continue; &amp;#125; int interestOps = key.interestOps(); key.cancel(); SelectionKey newKey = key.channel().register(newSelector, interestOps, a); if (a instanceof AbstractNioChannel) &amp;#123; // Update SelectionKey ((AbstractNioChannel) a).selectionKey = newKey; &amp;#125; nChannels ++; &amp;#125; catch (Exception e) &amp;#123; logger.warn(\"Failed to re-register a Channel to the new Selector.\", e); if (a instanceof AbstractNioChannel) &amp;#123; AbstractNioChannel ch = (AbstractNioChannel) a; ch.unsafe().close(ch.unsafe().voidPromise()); &amp;#125; else &amp;#123; @SuppressWarnings(\"unchecked\") NioTask&lt;SelectableChannel> task = (NioTask&lt;SelectableChannel>) a; invokeChannelUnregistered(task, key, e); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (ConcurrentModificationException e) &amp;#123; // Probably due to concurrent modification of the key set. continue; &amp;#125; break; &amp;#125; selector = newSelector; try &amp;#123; // time to close the old selector as everything else is registered to the new one oldSelector.close(); &amp;#125; catch (Throwable t) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn(\"Failed to close the old Selector.\", t); &amp;#125; &amp;#125; logger.info(\"Migrated \" + nChannels + \" channel(s) to the new Selector.\"); &amp;#125; 在rebuildSelector() 方法中, 主要做了三件事情: 创建一个新的Selector 将原来的Selector中的注册事件全部取消 将可用的事件重新注册到Selector 中, 并激活 9. Netty 对Selector 中 KeySet 的优化分析完Netty 对JDK 空轮训bug 的解决方案, 接下来我们再来看看一个很有意思的细节, Netty 对Selector 中存储SelectionKey 的HashSet 也做了优化。 在前面的Netty分析中, Netty 对Selector 有重构, 创建一个新的Selector 其实就是调用 openSelector() 方法, 来看代码: public void rebuildSelector() &amp;#123; if (!inEventLoop()) &amp;#123; execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; rebuildSelector(); &amp;#125; &amp;#125;); return; &amp;#125; final Selector oldSelector = selector; final Selector newSelector; if (oldSelector == null) &amp;#123; return; &amp;#125; try &amp;#123; newSelector = openSelector(); // 省略其他代码 &amp;#125; 下面我们来进入 openSelector() private Selector openSelector() &amp;#123; final Selector selector; try &amp;#123; selector = provider.openSelector(); &amp;#125; catch (IOException e) &amp;#123; throw new ChannelException(\"failed to open a new selector\", e); &amp;#125; if (DISABLE_KEYSET_OPTIMIZATION) &amp;#123; return selector; &amp;#125; final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet(); Object maybeSelectorImplClass = AccessController.doPrivileged(new PrivilegedAction&lt;Object>() &amp;#123; @Override public Object run() &amp;#123; try &amp;#123; return Class.forName( \"sun.nio.ch.SelectorImpl\", false, PlatformDependent.getSystemClassLoader()); &amp;#125; catch (ClassNotFoundException e) &amp;#123; return e; &amp;#125; catch (SecurityException e) &amp;#123; return e; &amp;#125; &amp;#125; &amp;#125;); if (!(maybeSelectorImplClass instanceof Class) || // ensure the current selector implementation is what we can instrument. !((Class&lt;?>) maybeSelectorImplClass).isAssignableFrom(selector.getClass())) &amp;#123; if (maybeSelectorImplClass instanceof Exception) &amp;#123; Exception e = (Exception) maybeSelectorImplClass; logger.trace(\"failed to instrument a special java.util.Set into: &amp;#123;&amp;#125;\", selector, e); &amp;#125; return selector; &amp;#125; final Class&lt;?> selectorImplClass = (Class&lt;?>) maybeSelectorImplClass; Object maybeException = AccessController.doPrivileged(new PrivilegedAction&lt;Object>() &amp;#123; @Override public Object run() &amp;#123; try &amp;#123; Field selectedKeysField = selectorImplClass.getDeclaredField(\"selectedKeys\"); Field publicSelectedKeysField = selectorImplClass.getDeclaredField(\"publicSelectedKeys\"); selectedKeysField.setAccessible(true); publicSelectedKeysField.setAccessible(true); selectedKeysField.set(selector, selectedKeySet); publicSelectedKeysField.set(selector, selectedKeySet); return null; &amp;#125; catch (NoSuchFieldException e) &amp;#123; return e; &amp;#125; catch (IllegalAccessException e) &amp;#123; return e; &amp;#125; catch (RuntimeException e) &amp;#123; // JDK 9 can throw an inaccessible object exception here; since Netty compiles // against JDK 7 and this exception was only added in JDK 9, we have to weakly // check the type if (\"java.lang.reflect.InaccessibleObjectException\".equals(e.getClass().getName())) &amp;#123; return e; &amp;#125; else &amp;#123; throw e; &amp;#125; &amp;#125; &amp;#125; &amp;#125;); if (maybeException instanceof Exception) &amp;#123; selectedKeys = null; Exception e = (Exception) maybeException; logger.trace(\"failed to instrument a special java.util.Set into: &amp;#123;&amp;#125;\", selector, e); &amp;#125; else &amp;#123; selectedKeys = selectedKeySet; logger.trace(\"instrumented a special java.util.Set into: &amp;#123;&amp;#125;\", selector); &amp;#125; return selector; &amp;#125; 上面的代码的主要功能就是利用反射机制, 获取到JDK底层的 Selector 的 class 对象, 用反射方法从 class 对象中获取两个字段selectedKeys 和publicSelectedKeys, 这两个字段就是用来存储已注册事件的, 然后,将这两个对象 重新复制为Netty 创建的 SelectedSelectionKeySet, 是不是有种偷梁换柱的感觉呢? 我们先来看一下 selectedKeys 和publicSelectedKeys 到底是什么类型? 打开SelectorImpl 的源码, 看其构造方法: protected Set&lt;SelectionKey> selectedKeys = new HashSet(); protected HashSet&lt;SelectionKey> keys = new HashSet(); private Set&lt;SelectionKey> publicKeys; private Set&lt;SelectionKey> publicSelectedKeys; protected SelectorImpl(SelectorProvider var1) &amp;#123; super(var1); if (Util.atBugLevel(\"1.4\")) &amp;#123; this.publicKeys = this.keys; this.publicSelectedKeys = this.selectedKeys; &amp;#125; else &amp;#123; this.publicKeys = Collections.unmodifiableSet(this.keys); this.publicSelectedKeys = Util.ungrowableSet(this.selectedKeys); &amp;#125; &amp;#125; 我们发现 selectedKeys 和publicSelectedKeys 就是HashSet, 下面我们再来看一下 Netty 创建 的 SelectedSelectionKeySet 对象的源代码: final class SelectedSelectionKeySet extends AbstractSet&lt;SelectionKey> &amp;#123; private SelectionKey[] keysA; private int keysASize; private SelectionKey[] keysB; private int keysBSize; private boolean isA = true; SelectedSelectionKeySet() &amp;#123; keysA = new SelectionKey[1024]; keysB = keysA.clone(); &amp;#125; @Override public boolean add(SelectionKey o) &amp;#123; if (o == null) &amp;#123; return false; &amp;#125; if (isA) &amp;#123; int size = keysASize; keysA[size ++] = o; keysASize = size; if (size == keysA.length) &amp;#123; doubleCapacityA(); &amp;#125; &amp;#125; else &amp;#123; int size = keysBSize; keysB[size ++] = o; keysBSize = size; if (size == keysB.length) &amp;#123; doubleCapacityB(); &amp;#125; &amp;#125; return true; &amp;#125; private void doubleCapacityA() &amp;#123; SelectionKey[] newKeysA = new SelectionKey[keysA.length &lt;&lt; 1]; System.arraycopy(keysA, 0, newKeysA, 0, keysASize); keysA = newKeysA; &amp;#125; private void doubleCapacityB() &amp;#123; SelectionKey[] newKeysB = new SelectionKey[keysB.length &lt;&lt; 1]; System.arraycopy(keysB, 0, newKeysB, 0, keysBSize); keysB = newKeysB; &amp;#125; SelectionKey[] flip() &amp;#123; if (isA) &amp;#123; isA = false; keysA[keysASize] = null; keysBSize = 0; return keysA; &amp;#125; else &amp;#123; isA = true; keysB[keysBSize] = null; keysASize = 0; return keysB; &amp;#125; &amp;#125; @Override public int size() &amp;#123; if (isA) &amp;#123; return keysASize; &amp;#125; else &amp;#123; return keysBSize; &amp;#125; &amp;#125; @Override public boolean remove(Object o) &amp;#123; return false; &amp;#125; @Override public boolean contains(Object o) &amp;#123; return false; &amp;#125; @Override public Iterator&lt;SelectionKey> iterator() &amp;#123; throw new UnsupportedOperationException(); &amp;#125; &amp;#125; 源码篇幅不长, 但很精辟, SelectedSelectionKeySet 同样继承了 AbstractSet, 因此复制给 selectedKeys 和publicSelectedKeys 不存在类型转换异常的问题. 我们看到在 SelectedSelectionKeySet 中禁用了 remove(),contails()方法和iterator() 方法, 只保留了 add() 方法, 而且底层存储结构用的是数组 SelectionKey[] keys. 那么Netty 为什么这样设计呢? 主要目的还是简化我们在轮询事件时的操作, 不需要每次轮询时都要移除key. 10 .Handler 的添加过程服务端handler 的添加过程和客户端的有点区别, 跟 EventLoopGroup 一样服务端的handler 也有两个, 一个是通过 handler() 方法设置的handler, 一个是通过 childHandler() 方法设置的 childHandler() ,通过前面的 bossGroup 和workerGroup 的分析, 其实我们可以大胆的猜测, handler 与 accept 过程有关, 即handler 负责处理客户端新连接接入的请求, 而 childHandler 就是负责和客户端连接的IO交互. 那么实际上是不是这样的呢？ 我们继续用代码来证明? 在前面我们已经了解到ServerBootstrap 中 重写了init() 方法, 在这个方法中也添加了 hanlder @Override void init(Channel channel) throws Exception &amp;#123; final Map&lt;ChannelOption&lt;?>, Object> options = options0(); synchronized (options) &amp;#123; channel.config().setOptions(options); &amp;#125; final Map&lt;AttributeKey&lt;?>, Object> attrs = attrs0(); synchronized (attrs) &amp;#123; for (Entry&lt;AttributeKey&lt;?>, Object> e: attrs.entrySet()) &amp;#123; @SuppressWarnings(\"unchecked\") AttributeKey&lt;Object> key = (AttributeKey&lt;Object>) e.getKey(); channel.attr(key).set(e.getValue()); &amp;#125; &amp;#125; ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?>, Object>[] currentChildOptions; final Entry&lt;AttributeKey&lt;?>, Object>[] currentChildAttrs; synchronized (childOptions) &amp;#123; currentChildOptions = childOptions.entrySet().toArray(newOptionArray(childOptions.size())); &amp;#125; synchronized (childAttrs) &amp;#123; currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(childAttrs.size())); &amp;#125; p.addLast(new ChannelInitializer&lt;Channel>() &amp;#123; @Override public void initChannel(Channel ch) throws Exception &amp;#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &amp;#123; pipeline.addLast(handler); &amp;#125; // We add this handler via the EventLoop as the user may have used a ChannelInitializer as handler. // In this case the initChannel(...) method will only be called after this method returns. Because // of this we need to ensure we add our handler in a delayed fashion so all the users handler are // placed in front of the ServerBootstrapAcceptor. ch.eventLoop().execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; pipeline.addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &amp;#125; &amp;#125;); &amp;#125; &amp;#125;); &amp;#125; 在上面的initChannel() 方法中, 首先通过 handler() 方法获取一个 handler, 如果获取到的hanlder 不为空, 则添加到 pipeline中, 然后接着, 添加了一个ServerBootstrapAcceptor 的实力。 那么这里的handler() 方法 返回的是哪个对象呢？其实它返回的 handler 字段, 而这个对象就是我们在服务端的启动代码中设置的 .group(bossGroup, workerGroup) 那么这个时候, pipeline 中的hanlder 情况如下: 根据我们原来客户端代码的分析来, 我们指定 chanel 绑定到 eventLoop(在这里是指 NioServerSocketChanel 绑定到bossGroup) 后， 会在pipeline 中触发 fireChannelRegistered 事件 ,接着就会触发 对ChannelInitializer的 initChannel()方法的调用. 因为在绑定完成后， 此时的 pipeline 的内容如下: 在前面我们分析 bossGroup 和workerGroup 时, 已经知道了 ServerBootstrapAcceptor 的channelRead() 方法会为新建的Channel 设置handler 并注册到一个 eventLoop 中., 即 @Override @SuppressWarnings(\"unchecked\") public void channelRead(ChannelHandlerContext ctx, Object msg) &amp;#123; final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); for (Entry&lt;ChannelOption&lt;?>, Object> e: childOptions) &amp;#123; try &amp;#123; if (!child.config().setOption((ChannelOption&lt;Object>) e.getKey(), e.getValue())) &amp;#123; logger.warn(\"Unknown channel option: \" + e); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Failed to set a channel option: \" + child, t); &amp;#125; &amp;#125; for (Entry&lt;AttributeKey&lt;?>, Object> e: childAttrs) &amp;#123; child.attr((AttributeKey&lt;Object>) e.getKey()).set(e.getValue()); &amp;#125; try &amp;#123; childGroup.register(child).addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; if (!future.isSuccess()) &amp;#123; forceClose(child, future.cause()); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; catch (Throwable t) &amp;#123; forceClose(child, t); &amp;#125; &amp;#125; 而这里的handler 就是我们在服务端启动代码中设置的handler .childHandler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; &amp;#125; &amp;#125;) 后续的步骤我们基本上清楚了, 当客户端连接Channel 注册后, 就会触发 ChannelInitializer 的 initChannel()方法的调用, 最后我们来总结一下 服务端handler 和childHandler 的区别和联系 在服务端 NioSocketChannel 的 pipeline 中添加的是 hanlder 和 ServerBootstrapAcceptor。 当有新的客户端连接请求时, 调用 用 ServerBootstrapAcceptor 的 channelRead()方法创建此连接的NioSocketChannel 并 添加 childHandler 到NioSocketChannel 对应的pileline 中, 并为此channel 绑定到 workerGroup 中的某个 eventLoop 中. handler 是在 accept 阶段起作用的, 它处理客户端的连接请求. childHandler 是在客户端连接建立后起作用, 他负责客户端连接的IO交互. 最后来看一张图, 加深理解。 下图描述了服务端从启动初始化到有新连接接入的变化过程:","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"大名鼎鼎的EventLoop(9)","slug":"Netty/大名鼎鼎的EventLoop(9)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/da-ming-ding-ding-de-eventloop-9/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/da-ming-ding-ding-de-eventloop-9/","excerpt":"","text":"大名鼎鼎的EventLoop1. EventLoopGroup 和Reactor一个Netty 在启动的时候, 至少要指定一个EventLoopGroup(如果使用的是Nio, 一般指定的是NioEventLoopGroup),那么, 这回NioEventLoopGroup 在Netty中 到底扮演着什么样的角色呢? 我们知道, Netty 是Reactor 模型的一个实现, 我们就从Reactor 的线程模型开始 1. 浅谈Reactor 线程模型Reactor 线程模型有三种: 单线程模型、多线程模型、主从线程模型. 首先来看一下单线程模型, 如下图所示: 所以单线程, 即Acceptor 处理的和 handler处理都在同一个线程中处理. 这个模型的坏处显而易见, 当其中的某个handler 阻塞时, 会导致其他所有的Client 的handler 都得不到执行, 并且更严重的是Handler的阻塞会导致整个服务不能接受新的client 请求,(因为Accepor 也被阻塞了). 因为有这么多的缺陷，所以单线程Reactor 模型应用场景比较少. 那么, 什么是多线程模型呢? Reactor 的多线程模型与单线程模型的区别就是Acceptor 是一个单独的线程处理, 并且有一组特定的NIO线程来负责各个客户端连接的IO操作,Reactor 的多线程模型如下图所示: Reactor 多线程模型有如下特点: 有一个专门的线程, 即Acceptor 线程用于监听客户端的TCP 连接请求. 客户端连接的IO操作都由一个特定的NIO线程负责, 每个客户端连接都要与一个特定的NIO线程绑定, 因此在这个客户端连接中的所有IO操作都是在同一个线程中完成的. 客户端连接有很多, 但是NIO线程数是比较少的, 因此一个Nio线程可以同时绑定到多个客户端连接中. 接下来我们再来看看 Reactor 主从多线程模型. 一般情况下,Reactor 的多线程模型已经可以很好的工作了, 但是我们想象这样一个场景, 如果我们的服务器需要同时处理大量的客户端连接请求, 或者我们需要在客户端连接的时候进行一些权限的校验, 那么单线程的Acceptor 很有可能就处理不过来了, 造成了大量的客户端不能连接到服务端, Reactor 的主从多线程模型就是在这样的情况下提出的, 他的特点是: 服务端接受客户端的连接请求不再是一个线程, 而是由一个独立的线程池组成, 其线程模型如下图所示： 可以看到, Reactor 的主从多线程模型和Reactor 多线程模型很类似, 只不过Reactor 的主从多线程模型的Acceptor 使用了线程池来处理大量的客户端请求. 2. EventLoopGroup 与Reactor关联我们介绍了三种Reactor 的线程模型, 那么他们和NioEventLoopGroup 又有什么关系呢?其实, 不同的设置NioEventLoopGroup 的方式就对应了不同的Reactor 的线程模型. 单线程模型,来看下面的应用代码: EventLoopGroup group = new NioEventLoopGroup(1); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(group); 注意, 我们实例化了一个 NioEventLoopGroup ,然后接着我们调用 bootstrap.group(group)设置服务端的EventLoopGroup .有人可能会有疑惑, 我记得在启动服务端的Netty程序的时候, 需要设置 bossGroup 和 workerGroup, 为何这里只设置一个 bossGroup ? 其实原因很简单, ServerBootstrap 重写了 group 方法. @Override public ServerBootstrap group(EventLoopGroup group) &amp;#123; return group(group, group); &amp;#125; 因此当传入一个group的时候, 那么bossGroup和workerGroup 就是同一个 NioEventLoopGroup了. 这是, 因为bossGroup 和workerGroup 就是同一个NioEventLoopGroup,并且这个NioEventLoopGroup 线程池数量只设置了1个线程, 也就是 Netty中的Acceptor 与后续的所有客户端连接的IO 操作都是在同一个线程中处理的. 那么对应的Reactor 的线程模型中, 我们这样设置 NioEventLoopGroup时, 就相当于Reactor 的单线程模型. 多线程模型, 再来看下面的应用代码 EventLoopGroup bossGroup = new NioEventLoopGroup(128); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup) 从上面的代码来看, 我们只需要将 bossGroup 的参数设置为大于1的数,其实就是Reactor 多线程模型. 主从线程模型, 实现主从线程模型的代码如下： EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup) bossGroup 为主线程, 而 workerGroup 中的线程是CPU 核心数乘以2, 因此对应的到Reactor 线程模型中, 我们知道, 这样设置的NioEventLoopGroup 其实就是Reactor 主从线程模型. 3. EventLoopGroup 实例化首先, 我们先纵览一下 EventLoopGroup 的l类结构图， 如下所示: 我们先来看一下EventLoopGroup 初始化的时序图 基本步骤如下： EventLoopGroup(其实是 MultithreadEventExecutorGroup) 内部维护了一个类为 EventExecutor children 数组, 其大小为nThreads，这样就初始化了一个线程池。 如果我们在实例化NioEventLoopGroup 时, 如果指定线程池大小 , 则 nThreads 为指定值, 否则为 CPU核心数*2 在MultithreadEventExecutorGroup会调用 newChild() 抽象方法来初始化 children数组 抽象方法 newChild() 其实是在 NioEventLoopGroup 中实现的，由它返回一个NioEventLoop 实例. 初始化NioEventLoop 主要属性: provider: 在 NioEventLoopGroup 构造器中通过 SelectorProvider 的 provider()方法获取 SelectorProvider。 selector:在 NioEventLoop 构造器中调用 selector = provider.openSelector()方法获取 Selector 对象。 2. 任务执行者EventLoopNioEventLoop 继承自SingleThreadEventLoop, 而SingleThreadEventLoop 又继承自 SingleThreadEventExecutor。而SingleThreadEventExecutor 是Netty 对本地线程的封装, 它内部有一个 Thread thread 属性, 存储了一个Java 本地线程. 因此我们可以简单的认为, 一个 NioEventLoop 就是和一个特定的线程绑定, 并且在其生命周期内 ，绑定的线程都不会发生改变. NioEventLoop 的类层次结构图还是有些复杂的，不过我们只需要关注几个重要点即可。首先来看 NioEventLoop 的继承链：NioEventLoop-&gt;SingleThreadEventLoop-&gt;SingleThreadEventExecutor-&gt;AbstractScheduledEventExecutor。在 AbstractScheduledEventExecutor 中, Netty 实现了 NioEventLoop 的 schedule 功能，即我们可以通过调用一个NioEventLoop 实例的 schedule 方法来运行一些定时任务。而在 SingleThreadEventLoop 中，又实现了任务队列的功能，通过它，我们可以调用一个 NioEventLoop 实例的 execute()方法来向任务队列中添加一个 task,并由 NioEventLoop进行调度执行。 通常来说, NioEventLoop 负责执行两个任务, 第一个任务是作为IO 线程, 执行与Channel 相关的IO 操作， 包括调用Selector 等待就绪的Io事件等、读写数据与数据的处理等. 而第二个任务是作为任务队列, 执行 taskQueue 中的任务, 例如用户调用 eventLoop.schedule 提交的定时任务也是这个线程执行的。 2.1 NioEventLoop 的初始化先看一下 NioEventLoop 实例化的运行时序图 从上图看到, SingleThreadEventExecutor 有一个名为 thread 的Thread 类型字段, 这个字段就是与SingleThreadEventExecutor 关联的本地线程 , 我们看看 thread 是在哪里被赋值的? private void doStartThread() &amp;#123; assert thread == null; executor.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; thread = Thread.currentThread(); if (interrupted) &amp;#123; thread.interrupt(); &amp;#125; boolean success = false; updateLastExecutionTime(); try &amp;#123; SingleThreadEventExecutor.this.run(); success = true; &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Unexpected exception from an event executor: \", t); &amp;#125; finally &amp;#123; for (;;) &amp;#123; int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this); if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet( SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) &amp;#123; break; &amp;#125; &amp;#125; // Check if confirmShutdown() was called at the end of the loop. if (success &amp;&amp; gracefulShutdownStartTime == 0) &amp;#123; logger.error(\"Buggy \" + EventExecutor.class.getSimpleName() + \" implementation; \" + SingleThreadEventExecutor.class.getSimpleName() + \".confirmShutdown() must be called \" + \"before run() implementation terminates.\"); &amp;#125; try &amp;#123; // Run all remaining tasks and shutdown hooks. for (;;) &amp;#123; if (confirmShutdown()) &amp;#123; break; &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; try &amp;#123; cleanup(); &amp;#125; finally &amp;#123; STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED); threadLock.release(); if (!taskQueue.isEmpty()) &amp;#123; logger.warn( \"An event executor terminated with \" + \"non-empty task queue (\" + taskQueue.size() + ')'); &amp;#125; terminationFuture.setSuccess(null); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125;); &amp;#125; SingleThreadEventExecutor 启动时会调用 doStartThread() 方法, 然后调用 executor.execute() 方法，将当前线程赋值给thread, 在这个线程中所作的主要的事情就是调用 SingleThreadEventExecutor .this.run() 方法, 而因为 NioEventLoop 实现了这个方法, 因此根据多态性, 调用的是 NioEventLoop 的 run() 方法. 2.2 EventLoop 与Channel 的关联在Netty中, 每个Channel 都有且仅有一个EventLoop与之关联, 他们的关联过程如下： 从上图中我们可以看到, 当调用AbstractChannel$AbstractUnsafe.register()方法后, 就完成了 Channel 与EventLoop的关联, register 方法的具体实现如下: @Override public final void register(EventLoop eventLoop, final ChannelPromise promise) &amp;#123; if (eventLoop == null) &amp;#123; throw new NullPointerException(\"eventLoop\"); &amp;#125; if (isRegistered()) &amp;#123; promise.setFailure(new IllegalStateException(\"registered to an event loop already\")); return; &amp;#125; if (!isCompatible(eventLoop)) &amp;#123; promise.setFailure( new IllegalStateException(\"incompatible event loop type: \" + eventLoop.getClass().getName())); return; &amp;#125; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &amp;#123; register0(promise); &amp;#125; else &amp;#123; try &amp;#123; eventLoop.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; register0(promise); &amp;#125; &amp;#125;); &amp;#125; catch (Throwable t) &amp;#123; logger.warn( \"Force-closing a channel whose registration task was not accepted by an event loop: &amp;#123;&amp;#125;\", AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &amp;#125; &amp;#125; &amp;#125; 在io.netty.channel.AbstractChannel.AbstractUnsafe.register()方法中, 就将一个EventLoop 赋值给AbstractChannel内部的eventLoop 字段, 这段代码就是完成Channel 与EventLoop的关联. 2.3 EventLoop的启动在前面已经知道, NioEventLoop 其实就是一个SingleThreadEventExecutor，因此NioEventLoop 的启动就是 NioEventLoop 所绑定的本地线程的启动. 按照这个思路,我们只需要找到在哪里调用了SingleThreadEventExecutor的thread字段的start() 方法就知道是在哪里启动这个线程了, 从前面中的分析来看, 我们已经知道了 thread.start() 被封装到了 SingleThreadEventExecutor的startThread()方法中, 来看代码: private void startThread() &amp;#123; if (STATE_UPDATER.get(this) == ST_NOT_STARTED) &amp;#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &amp;#123; doStartThread(); &amp;#125; &amp;#125; &amp;#125; STATE_UPDATER 是 SingleThreadEventExecutor 内部维护的一个属性, 它的作用是标识当前的thread 状态, 在初始的时候, ，STATE_UPDATER == ST_NOT_STARTED，因此第一次调用 startThread() 方法时, 就会进入到if 语句, 进而调用到 thread.start() 方法, 而这个关键的 startThread() 方法又是在哪里被调用的呢? 用方法调用关系反向查找功能, 我们发现 statrThread 是在SingleThreadEventExecutor的 execute 方法中调用 @Override public void execute(Runnable task) &amp;#123; if (task == null) &amp;#123; throw new NullPointerException(\"task\"); &amp;#125; boolean inEventLoop = inEventLoop(); if (inEventLoop) &amp;#123; addTask(task); &amp;#125; else &amp;#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &amp;#123; reject(); &amp;#125; &amp;#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &amp;#123; wakeup(inEventLoop); &amp;#125; &amp;#125; 既然如此, 那现在我们的工作就变为了寻找在哪里第一次调用了SingleThreadEventExecutor的 execute() 方法, 在AbstractChannel$AbstractUnsafe 的 register()中调用 eventLoop.execute()方法，在 EventLoop 中进行 Channel 注册代码的执行，AbstractChannel$AbstractUnsafe 的 register()部分代码如下 @Override public final void register(EventLoop eventLoop, final ChannelPromise promise) &amp;#123; if (eventLoop == null) &amp;#123; throw new NullPointerException(\"eventLoop\"); &amp;#125; if (isRegistered()) &amp;#123; promise.setFailure(new IllegalStateException(\"registered to an event loop already\")); return; &amp;#125; if (!isCompatible(eventLoop)) &amp;#123; promise.setFailure( new IllegalStateException(\"incompatible event loop type: \" + eventLoop.getClass().getName())); return; &amp;#125; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &amp;#123; register0(promise); &amp;#125; else &amp;#123; try &amp;#123; eventLoop.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; register0(promise); &amp;#125; &amp;#125;); &amp;#125; catch (Throwable t) &amp;#123; logger.warn( \"Force-closing a channel whose registration task was not accepted by an event loop: &amp;#123;&amp;#125;\", AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &amp;#125; &amp;#125; &amp;#125; 很显然, 一路从Bootstrap 的bind() 方法跟踪到AbstractChannel$AbstractUnsafe 的 register()方法，整个代码都是在主线程中运行的. 因为上面的 eventLoop.inEventLoop() 返回为false. 于是进入到 else 分支， 在这个分支中调用了 eventLoop.execute() 方法 , 而NioEventLoop 没有实现 execute() 方法, 因此调用的是 SingleThreadEventExecutor的execute() @Override public void execute(Runnable task) &amp;#123; if (task == null) &amp;#123; throw new NullPointerException(\"task\"); &amp;#125; boolean inEventLoop = inEventLoop(); if (inEventLoop) &amp;#123; addTask(task); &amp;#125; else &amp;#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &amp;#123; reject(); &amp;#125; &amp;#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &amp;#123; wakeup(inEventLoop); &amp;#125; &amp;#125; 我们已经分析过了，inEventLoop == false，因此执行到 else 分支，在这里就调用 startThread()方法来启动SingleThreadEventExecutor 内部关联的 Java 本地线程了。总结一句话：当 EventLoop 的 execute()第一次被调用时，就会触发 startThread()方法的调用，进而导致 EventLoop所对应的 Java 本地线程启动。 我们总结一下EventLoop启动过程完整的时序图","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"基于Netty重构RPC框架(4)","slug":"Netty/基于Netty重构RPC框架(4)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/ji-yu-netty-chong-gou-rpc-kuang-jia-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/ji-yu-netty-chong-gou-rpc-kuang-jia-4/","excerpt":"","text":"基于Netty 重构RPC框架1. RPC 概述下面的这张图, 大概很多人都见到过, 这是Dubbo 官网中的一张图描述了项目架构的演进过程: 他描述了每一种架构需要的具体配置和组织形态. 当网站流量很小时， 只需一个应用, 将所有的功能都部署到一起, 以减少部署节点和成本，我们通常会采用单一应用架构,之后出现了ORM框架，主要用于简化增删改查工作流的,数据访问框架ORM是关键. 随着用户量增加, 当访问量逐渐增加, 单一应用增加机器, 带来的加速度越来越小 , 我们需要将应用超分成互相不干扰的几个应用, 以提升效率 。 于是出现了垂直应用架构. MVC架构就是一种非常经典的用于加速前端页面开发的架构. 当垂直应用越来越多, 应用之间交互不可避免, 将核心业务抽取出来, 作为独立的服务逐渐形成稳定的服务中心, 使前端应用能够更快速的响应, 多变的市场需求, 就出现了分布式服务架构, 分布式架构下服务数量逐渐增加, 为了提高管理效率, PRC 框架应运而生, PRC 用于提高业务复用以及整合的, 分布式服务框架下RPC 是关键, 下一代框架, 将会是流动计算架构占据主流, 当服务越来越多,容量的评估, 小服务的资源浪费等问题，逐渐明显. 此时, 需要增加一个调度中心, 基于访问压力实时管理集群容量, 提高集群利用率, SOA 架构就是用于提高及其利用率的, 资源调度和治理中心SOA是关键. Netty 基本上是作为架构的技术底层而存在的, 主要完成高性能的网络通信. 2. 环境预设1. 先将项目环境搭建起来, 创建项目, 在pom.xml 中添加 &lt;dependency> &lt;groupId>io.netty&lt;/groupId> &lt;artifactId>netty-all&lt;/artifactId> &lt;version>4.1.6.Final&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.16.10&lt;/version> &lt;/dependency> 2. 创建项目结构在没有RPC框架之前,我们的服务调用是这样的, 如下图: 从上图可以看出接口的调用完成没有规律可寻, 想怎么调就怎么调, 这导致业务发展到一定阶段后, 对接口的维护变得非常困难, 于是有人提出了服务治理的概念, 所有服务间不允许直接调用, 而是先到注册中心进行登记, 再由注册中心统一协调和管理所有的服务状态并对外发布, 调用者只需要记住服务名称， 去找注册中心获取服务即可. 这样极大的规范了服务的管理, 可以题号了所有服务端可控性, 整个设计思想其实在我们生活中也能找到活生生的例子. 例如 : 我们平时工作交流, 大多都是用IM工具, 而不是面对面吼. 大家只需要相互记住运行商(也就是注册中心) 提供的号码(如: 腾讯QQ) 即可, 再比如: 我们打电话, 所有电话号码由运营商分配, 我们需要和某一个人通话 , 只需要拨通对方的号码,运营商(注册中心,如中国联通、移动、电信) 就会帮我们将信号转接过去. 目前流行的RPC 服务治理框架主要有Dubbo 和Spring Cloud , 下面我们以比较经典的Dubbo 为例,. Dubbo 核心模块主要有四个: Registry 注册中心 Priovider 服务端 Consumer 消费端 Monitor 监控中心 为了方便, 我们将所有的模块全部都放到同一个项目中,主要模块包括 api: 主要用来定义对外开放的功能与服务接口 protocol: 主要定义自定义传输协议的内容 registry: 主要负责保存所有可用的服务名和服务地址 provider: 实现对外提供的所有服务的具体功能 constomer: 客户端调用 monitor： 完成调用链监控 下面, 我们先将项目结构搭建好, 具体的项目结构截图如下: 3. 代码实战1. 创建API 模块首先创建API模块, prodiver 和consumer 都遵循API模块的规范, 为了简化,创建两个Service 接口, 分别是IHelloService 接口, 实现一个hello() 方法, 主要目的是用来确认服务是否可用, 具体代码如下: package com.formula.netty.rpc.api; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public interface IHelloService &amp;#123; String hello(String name); &amp;#125; 创建 ICalculationService 接口， 完成模拟业务 加、减、乘、除 运算， 具体代码如下: package com.formula.netty.rpc.api; /** * @author luyanan * @since 2019/9/20 * &lt;p>计算的service&lt;/p> **/ public interface ICalculationService &amp;#123; /** * &lt;p>加&lt;/p> * * @param a * @param b * @return &amp;#123;@link int&amp;#125; * @author luyanan * @since 2019/9/20 */ int add(int a, int b); /** * &lt;p>减&lt;/p> * * @param a * @param b * @return &amp;#123;@link int&amp;#125; * @author luyanan * @since 2019/9/20 */ int sub(int a, int b); /** * &lt;p>乘&lt;/p> * * @param a * @param b * @return &amp;#123;@link int&amp;#125; * @author luyanan * @since 2019/9/20 */ int mult(int a, int b); /** * &lt;p>除&lt;/p> * * @param a * @param b * @return &amp;#123;@link int&amp;#125; * @author luyanan * @since 2019/9/20 */ int div(int a, int b); &amp;#125; 至此, API模块就定义完成了,非常简单, 接下来我们要确定传输规则, 也就是传输协议. 协议内容当然要自己定义才能显出Netty的优势. 2. 创建自定义协议在Netty中要完成一个自定义协议, 其实非常简单, 只需要定义一个普通的Java类即可. 我们现在手写PRC 主要完成对Java代码的远程调用(类似于RMI)，远程调用Java代码哪些内容是必须由网络来传输的呢? 比如: 服务名称？需要调用该服务的哪个方法？方法的实参是什么? 这些信息都需要通过客户端传送到服务端去. 下面我们来看一下具体的代码实现, 定义 InvokerProtocol package com.formula.netty.rpc.protocol; import lombok.Data; import java.io.Serializable; /** * @author luyanan * @since 2019/9/20 * &lt;p>自定义传输协议&lt;/p> **/ @Data public class InvokerProtocol implements Serializable &amp;#123; /** * &lt;p>类名&lt;/p> * * @author luyanan * @since 2019/9/20 */ private String className; /** * &lt;p>方法名&lt;/p> * * @author luyanan * @since 2019/9/20 */ private String method; /** * &lt;p>形参列表&lt;/p> * * @author luyanan * @since 2019/9/20 */ private Class&lt;?>[] paramsType; /** * &lt;p>参数列表&lt;/p> * * @author luyanan * @since 2019/9/20 */ private Object[] params; &amp;#125; 从上面的代码来看, 协议中主要包含类名、函数名、形参列表和实参列表， 通过这些信息可以定位到一个具体的业务逻辑实现. 3. 实现Provider 服务端业务逻辑我们将API中定义的所有功能在provider 中实现, 分别创建两个实现类: HelloServiceImpl package com.formula.netty.rpc.provider; import com.formula.netty.rpc.api.IHelloService; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public class HelloServiceImpl implements IHelloService &amp;#123; @Override public String hello(String name) &amp;#123; return \"Hello:\" + name; &amp;#125; &amp;#125; CalculationServiceImpl package com.formula.netty.rpc.provider; import com.formula.netty.rpc.api.ICalculationService; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public class CalculationServiceImpl implements ICalculationService &amp;#123; @Override public int add(int a, int b) &amp;#123; return a + b; &amp;#125; @Override public int sub(int a, int b) &amp;#123; return a - b; &amp;#125; @Override public int mult(int a, int b) &amp;#123; return a * b; &amp;#125; @Override public int div(int a, int b) &amp;#123; return a / b; &amp;#125; &amp;#125; 4 . 完成Registry 服务注册Registry 注册中心主要功能就是将所有Provider 的服务名称和服务引用地址都注册到一个容器中, 并对外发布。Registry 应该要启动一个对外的服务, 很明显应该作为服务端, 并提供一个对外可以访问的接口, 先启动一个Netty, 创建Registry 类, 具体代码如下: package com.formula.netty.rpc.registry; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.LengthFieldBasedFrameDecoder; import io.netty.handler.codec.LengthFieldPrepender; import io.netty.handler.codec.serialization.ClassResolver; import io.netty.handler.codec.serialization.ClassResolvers; import io.netty.handler.codec.serialization.ObjectDecoder; import io.netty.handler.codec.serialization.ObjectEncoder; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public class Registry &amp;#123; private int port; public Registry(int port) &amp;#123; this.port = port; &amp;#125; public void start() &amp;#123; EventLoopGroup boosGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &amp;#123; ServerBootstrap strap = new ServerBootstrap(); strap.group(boosGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; ChannelPipeline pipeline = ch.pipeline(); //自定义协议解码器 /** 入参有5个，分别解释如下 maxFrameLength：框架的最大长度。如果帧的长度大于此值，则将抛出TooLongFrameException。 lengthFieldOffset：长度字段的偏移量：即对应的长度字段在整个消息数据中得位置 lengthFieldLength：长度字段的长度。如：长度字段是int型表示，那么这个值就是4（long型就是8） lengthAdjustment：要添加到长度字段值的补偿值 initialBytesToStrip：从解码帧中去除的第一个字节数 */ pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); //自定义协议编码器 pipeline.addLast(new LengthFieldPrepender(4)); //对象参数类型编码器 pipeline.addLast(\"encoder\",new ObjectEncoder()); //对象参数类型解码器 pipeline.addLast(\"decoder\",new ObjectDecoder(Integer.MAX_VALUE,ClassResolvers.cacheDisabled(null))); pipeline.addLast(new RegistryHandler()); &amp;#125; &amp;#125;) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture future = strap.bind(port).sync(); System.out.println(\"RPC Registry listen : \" + this.port); future.channel().closeFuture().sync(); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; boosGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &amp;#125; &amp;#125; public static void main(String[] args) &amp;#123; new Registry(8080).start(); &amp;#125; &amp;#125; 在RegistryHandler 中实现注册的具体逻辑，上面的代码主要实现服务注册和服务调用的功能, 因为所有模块都创建在同一个项目中, 为了简化，服务端没有实现远程调用, 而是直接扫描本地的class,然后利用反射调用. 代码实现如下： package com.formula.netty.rpc.registry; import com.formula.netty.rpc.protocol.InvokerProtocol; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import java.io.File; import java.lang.reflect.Method; import java.net.URL; import java.util.ArrayList; import java.util.List; import java.util.Map; import java.util.concurrent.ConcurrentHashMap; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public class RegistryHandler extends ChannelInboundHandlerAdapter &amp;#123; /** * &lt;p>用来保存所有可用的服务&lt;/p> * * @author luyanan * @since 2019/9/20 */ public static Map&lt;String, Object> registryMap = new ConcurrentHashMap&lt;>(); /** * &lt;p>保存所有相关服务类&lt;/p> * * @author luyanan * @since 2019/9/20 */ private static List&lt;String> classNames = new ArrayList&lt;>(); public RegistryHandler() &amp;#123; // 递归扫描 scannerClass(\"com.formula.netty.rpc.provider\"); doRegistry(); &amp;#125; private void doRegistry() &amp;#123; if (classNames.size() == 0) &amp;#123; return; &amp;#125; try &amp;#123; for (String className : classNames) &amp;#123; Class&lt;?> clazz = Class.forName(className); Class&lt;?> i = clazz.getInterfaces()[0]; registryMap.put(i.getName(), clazz.newInstance()); &amp;#125; &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (IllegalAccessException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (InstantiationException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; private void scannerClass(String pkg) &amp;#123; URL url = this.getClass().getClassLoader().getResource(pkg.replaceAll(\"\\\\.\", \"/\")); File dir = new File(url.getFile()); for (File file : dir.listFiles()) &amp;#123; if (file.isDirectory()) &amp;#123; scannerClass(pkg + \".\" + file.getName()); &amp;#125; else &amp;#123; classNames.add(pkg + \".\" + file.getName().replaceAll(\".class\", \"\").trim()); &amp;#125; &amp;#125; &amp;#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; Object result = new Object(); InvokerProtocol protocol = (InvokerProtocol) msg; // 当客户端建立连接时, 需要从自定义协议中获取信息， 拿到具体的服务和实参 // 使用反射调用 if (registryMap.containsKey(protocol.getClassName())) &amp;#123; Object clazz = registryMap.get(protocol.getClassName()); Method method = clazz.getClass().getMethod(protocol.getMethod(), protocol.getParamsType()); result = method.invoke(clazz, protocol.getParams()); &amp;#125; ctx.write(result); ctx.flush(); ctx.close(); &amp;#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &amp;#123; cause.printStackTrace(); ctx.close(); &amp;#125; &amp;#125; 至此, 注册中心的功能就基于完成, 接下来来看一下客户端的代码实现. 5. 实现Consumer 远程调用梳理一下基本的实现思路, 主要完成这样一个功能, API模块中的接口功能主要在服务端实现(没有在在客户端实现), 因此, 客户端调用API接口中定义的某一个方法的时候, 实际上是要发起一次网络情况去调用服务端的某一个服务, 而这个网络服务首先被注册中心接收, 由注册中心先确定要调用的服务的位置, 再将请求转发至真正的服务实现, 最终调用服务端代码. 将返回值通过网络传输给客户端. 整个过程对于客户端而言是完成无感知的, 就像调用本地方法一样, 下面我们来看具体的代码实现. RpcProxy package com.formula.netty.rpc.consumer.proxy; import com.formula.netty.rpc.protocol.InvokerProtocol; import io.netty.bootstrap.Bootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.sctp.nio.NioSctpChannel; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.LengthFieldBasedFrameDecoder; import io.netty.handler.codec.LengthFieldPrepender; import io.netty.handler.codec.serialization.ClassResolvers; import io.netty.handler.codec.serialization.ObjectDecoder; import io.netty.handler.codec.serialization.ObjectEncoder; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public class RpcProxy &amp;#123; /** * &lt;p>使用反射创建&lt;/p> * * @param clazz * @return &amp;#123;@link T&amp;#125; * @author luyanan * @since 2019/9/20 */ public static &lt;T> T create(Class&lt;T> clazz) &amp;#123; Class[] interfaces = clazz.isInterface() ? new Class[]&amp;#123;clazz&amp;#125; : clazz.getInterfaces(); return (T) Proxy.newProxyInstance(clazz.getClassLoader(), interfaces, new ProxyHandler(clazz)); &amp;#125; static class ProxyHandler implements InvocationHandler &amp;#123; private Class clazz; public ProxyHandler(Class clazz) &amp;#123; this.clazz = clazz; &amp;#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; if (Object.class.equals(method.getDeclaringClass())) &amp;#123; try &amp;#123; return method.invoke(this, args); &amp;#125; catch (Throwable t) &amp;#123; t.printStackTrace(); &amp;#125; &amp;#125; else &amp;#123; return rpcinvoke(proxy, method, args); &amp;#125; return null; &amp;#125; private Object rpcinvoke(Object proxy, Method method, Object[] args) &amp;#123; // 传输协议封装 InvokerProtocol protocol = new InvokerProtocol(); protocol.setClassName(this.clazz.getName()); protocol.setMethod(method.getName()); protocol.setParams(args); protocol.setParamsType(method.getParameterTypes()); final RpcProxyHandler handler = new RpcProxyHandler(); EventLoopGroup group = new NioEventLoopGroup(); try &amp;#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; ChannelPipeline pipeline = ch.pipeline(); //自定义协议解码器 /** 入参有5个，分别解释如下 maxFrameLength：框架的最大长度。如果帧的长度大于此值，则将抛出TooLongFrameException。 lengthFieldOffset：长度字段的偏移量：即对应的长度字段在整个消息数据中得位置 lengthFieldLength：长度字段的长度：如：长度字段是int型表示，那么这个值就是4（long型就是8） lengthAdjustment：要添加到长度字段值的补偿值 initialBytesToStrip：从解码帧中去除的第一个字节数 */ pipeline.addLast(\"frameDecoder\", new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); //自定义协议编码器 pipeline.addLast(\"frameEncoder\", new LengthFieldPrepender(4)); //对象参数类型编码器 pipeline.addLast(\"encoder\", new ObjectEncoder()); //对象参数类型解码器 pipeline.addLast(\"decoder\", new ObjectDecoder(Integer.MAX_VALUE, ClassResolvers.cacheDisabled(null))); pipeline.addLast(\"handler\", handler); &amp;#125; &amp;#125;); ChannelFuture future = bootstrap.connect(\"localhost\", 8080).sync(); future.channel().writeAndFlush(protocol).sync(); future.channel().closeFuture().sync(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; group.shutdownGracefully(); &amp;#125; return handler.getResponse(); &amp;#125; &amp;#125; &amp;#125; 接收网络调用的返回值 package com.formula.netty.rpc.consumer.proxy; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import org.omg.CORBA.OBJ_ADAPTER; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public class RpcProxyHandler extends ChannelInboundHandlerAdapter &amp;#123; private Object response; public Object getResponse() &amp;#123; return response; &amp;#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; response = msg; &amp;#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &amp;#123; System.out.println(\"client exception is general\"); &amp;#125; &amp;#125; 完成客户端调用的代码 package com.formula.netty.rpc.consumer; import com.formula.netty.rpc.api.ICalculationService; import com.formula.netty.rpc.api.IHelloService; import com.formula.netty.rpc.consumer.proxy.RpcProxy; /** * @author luyanan * @since 2019/9/20 * &lt;p>&lt;/p> **/ public class RpcCustomer &amp;#123; public static void main(String[] args) &amp;#123; IHelloService helloService = RpcProxy.create(IHelloService.class); String hello = helloService.hello(\"张三\"); System.out.println(hello); ICalculationService calculationService = RpcProxy.create(ICalculationService.class); System.out.println(calculationService.add(8, 2)); System.out.println(calculationService.sub(8, 2)); System.out.println(calculationService.mult(8, 2)); System.out.println(calculationService.div(8, 2)); &amp;#125; &amp;#125;","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Netty高性能之道(6)","slug":"Netty/Netty高性能之道(6)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/netty-gao-xing-neng-zhi-dao-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/netty-gao-xing-neng-zhi-dao-6/","excerpt":"","text":"Netty高性能之道1. 背景介绍1. Netty惊人的性能数据通过使用Netty(NIO框架) 相比于传统基于Java 序列化+ BIO(同步阻塞IO)的通信框架， 性能提升了8倍多. 2. 传统RPC 调用性能差的三宗罪网络传输方式问题: 传统的RPC框架或者基于RMI等方式的远程服务(过程) 调用采用了同步阻塞IO,当客户端的并发压力或者网络时延增大后, 同步阻塞IO 会由于频繁的wait 导致IO线程经常性的阻塞, 由于线程无法高效的工作，io处理能力自然下降. 下面, 我们通过BIO 通信模型看下BIO通信的弊端. 采用BIO通信模型的服务端，通常由一个独立的Acceptor 线程负责客户端的连接, 接收到客户端连接后, 为客户端连接创建一个新的线程处理请求消息. 处理完成后, 返回应答消息给客户端, 线程销毁。 这就是典型的一线程一应答模型. 该架构最大的问题就是不具备弹性伸缩能力, 当并发访问量增加后, 服务端的线程个数和并发访问数呈线性正比, 由于线程是JAVA 虚拟机非常宝贵的资源, 当线程数膨胀后，系统的性能急剧下降, 随着并发量的继续增加，可能会发生句柄溢出、线程堆栈溢出等问题, 并最终导致服务端宕机. 序列化方式问题: Java 序列化存在如下几个典型的问题: Java 序列化机制是Java内部的一种对象编解码技术, 无法跨语言使用, 例如对于异构系统之间的对接,Java序列化后的码流需要能过够通过其他语言反序列化成原始对象(副本),目前很难支持. 相比于其他开源的序列化框架，Java序列化后的码流太大, 无论是网络传输还是持久化到磁盘, 都会导致额外的资源占用. 序列化性能差(CPU资源占用高) 线程模型问题: 由于采用同步阻塞IO，这会导致每个TCP 连接都占用一个线程, 由于线程资源是JVM 虚拟机最宝贵的资源, 当IO读写阻塞导致线程无法及时释放时, 会导致系统性能急剧下降, 严重的甚至会导致虚拟机无法创建新的线程. 3. 高性能的三个主题 传输: 用什么样的通道将数据发送给对方, BIO、NIO 或者AIO,IO模型在很大程度上决定了框架的性能. 协议: 采用什么样的通信协议, HTTP或者内部私有协议. 协议的选择不同,性能模型也不同, 相比于公有协议, 内部私有协议的性能通常可以被设计的更优. 线程: 数据包如何读取, 读取之后的百年编解码在哪个线程进行, 编解码后的消息如何派发, Peactor 线程模型的不同, 对性能的影响也非常大. 2. Netty 高性能之道1 异步非阻塞通信在IO编写过程中, 当需要同时处理多个客户端接入请求时， 可以利用多线程或者IO多路复用技术进行处理。 IO多路复用通过把多个IO阻塞复用到同一个select 的阻塞上, 从而使得系统在单线程的情况下可以同时处理多个客户端请求. 与传统的多线程/多进程模型相比, io 多路复用的最大优势是系统开销小. 系统不需要创建新的额外的进程或者线程, 也不需要维护这些进程和线程的运行, 降低了系统的维护工作量, 节省了系统资源。 JDK1.4 提供了对非阻塞IO(NIO)的支持, JDK1.5_update10 版本使用epoll 替代了传统的 select/poll , 极大的提升了NIO通信的性能. JDK NIO 通信模型如下所示： 于Socket类和ServerSocket类相比, NIO 也提供了SocketChannel 和ServerSocketChannel 两种不同的套接字通道实现, 这两种新增的通道都支持阻塞和非阻塞两种模式, 阻塞模式使用非常简单, 但是性能和可靠性都不好, 非阻塞模型正好相反. 开发人员一般可以根据自己的需要来选择合适的开发模型, 一般来说, 低负载、低并发的应用程序可以选择同步阻塞IO 以降低编程复杂度. 但是对于高负载、高并发的网络应用, 需要使用NIO的非阻塞模型进行开发, Netty 架构按照Reactor模式设计和实现, 他的服务端通信序列图如下: 客户端通信序列图如下: Netty的IO线程 NioEventLoop 聚合了多路复用器 Selector, 可以同时并发处理成百上千个客户端 Channel, 由于读写操作都是非阻塞的, 这就可以充分提升IO线程的运行效率, 避免由于频繁IO阻塞导致的线程挂起. 另外， 由于Netty 采用了异步通信模型, 一个IO线程可以并发处理N个客户端连接和读写操作， 这就从根据上解决了传统同步IO阻塞 一连接一线程 模型, 架构的性能, 弹性伸缩能力和可靠性都得到了极大的提升. 2. 零拷贝Netty的零拷贝 主要体现在如下三个方面: Netty的接收和发送ByteBuffer 采用 DIRECT BUFFERS, 使用堆外直接内存进行Socket 读写， 不需要进行字节缓存区的二次拷贝, 如果使用传统的堆内存(HEAP BUFFERS) 使用Socket读写, JVM 会将堆内存Buffer 拷贝一份到直接内存中, 然后才写入到Socket, 相比于堆外直接内存, 消息在发送过程中多了一次缓冲区的内存拷贝。 Netty 提供了组合Buffer对象, 可以聚合多个ByteBuffer 对象, 用户可以像操作一个Buffer 那样方便的对组合Buffer 进行操作, 避免了传统使用内存拷贝的方式将几个小Buffer 合并成一个大的Buffer . Netty 的文件传输采用了 transferTo() 方法, 它可以直接将文件缓冲区的数据发送到目标Channel, 避免了传统通过 循环 write() 方式导致的内存拷贝问题. 下面, 我们对上述的三种零拷贝 进行说明, 先看Netty 接受Buffer的创建 打开 AbstractNioByteChannel的 NioByteUnsafe @Override public final void read() &amp;#123; final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try &amp;#123; do &amp;#123; byteBuf = allocHandle.allocate(allocator); allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) &amp;#123; // nothing was read. release the buffer. byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; break; &amp;#125; allocHandle.incMessagesRead(1); readPending = false; pipeline.fireChannelRead(byteBuf); byteBuf = null; &amp;#125; while (allocHandle.continueReading()); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (close) &amp;#123; closeOnRead(pipeline); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; handleReadException(pipeline, byteBuf, t, close, allocHandle); &amp;#125; finally &amp;#123; // Check if there is a readPending which was not processed yet. // This could be for two reasons: // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method // // See https://github.com/netty/netty/issues/2254 if (!readPending &amp;&amp; !config.isAutoRead()) &amp;#123; removeReadOp(); &amp;#125; &amp;#125; &amp;#125; 再找到 do while 中的 allocHandle.allocate(allocator) 方法, 实际上调用的是 DefaultMaxMessagesRecvByteBufAllocator中的MaxMessageHandle的 allocate 方法 @Override public ByteBuf allocate(ByteBufAllocator alloc) &amp;#123; return alloc.ioBuffer(guess()); &amp;#125; 相当于每次循环读取一次消息, 就通过 AbstractByteBufAllocator的 ioBuffer 方法获取 ByteBuf 对象， 下面继续看他的接口定义 public abstract class ByteBuf implements ReferenceCounted, Comparable&lt;ByteBuf> &amp;#123; &amp;#125; 当进行 Socket IO 读写的时候, 为了避免从堆内存拷贝一份副本到直接内存, Netty的ByteBuf 分配器直接创建非堆内存避免缓冲区的二次拷贝, 通过零拷贝 来提升读写性能. 下面我们继续看第二种 零拷贝 的 实现 CompositeByteBuf, 他对外将多个 ByteBuf 封装成一个ByteBuf, 对外提供统一封装后的 ByteBuf接口, 他的类定义如下: 通过继承关系我们可以看出CompositeByteBuf 实际上就是个 ByteBuf的包装器, 它将多个 ByteBuf 的包装器, 他将多个ByteBuf 组合成一个集合, 然后对外提供统一的ByteBuf 接口, 相关定义如下: private static final ByteBuffer EMPTY_NIO_BUFFER = Unpooled.EMPTY_BUFFER.nioBuffer(); private static final Iterator&lt;ByteBuf> EMPTY_ITERATOR = Collections.&lt;ByteBuf>emptyList().iterator(); private final ByteBufAllocator alloc; private final boolean direct; private final List&lt;Component> components; private final int maxNumComponents; private boolean freed; 添加ByteBuf , 不需要做内存拷贝, 相关代码如下： private int addComponent0(boolean increaseWriterIndex, int cIndex, ByteBuf buffer) &amp;#123; assert buffer != null; boolean wasAdded = false; try &amp;#123; checkComponentIndex(cIndex); int readableBytes = buffer.readableBytes(); // No need to consolidate - just add a component to the list. @SuppressWarnings(\"deprecation\") Component c = new Component(buffer.order(ByteOrder.BIG_ENDIAN).slice()); if (cIndex == components.size()) &amp;#123; wasAdded = components.add(c); if (cIndex == 0) &amp;#123; c.endOffset = readableBytes; &amp;#125; else &amp;#123; Component prev = components.get(cIndex - 1); c.offset = prev.endOffset; c.endOffset = c.offset + readableBytes; &amp;#125; &amp;#125; else &amp;#123; components.add(cIndex, c); wasAdded = true; if (readableBytes != 0) &amp;#123; updateComponentOffsets(cIndex); &amp;#125; &amp;#125; if (increaseWriterIndex) &amp;#123; writerIndex(writerIndex() + buffer.readableBytes()); &amp;#125; return cIndex; &amp;#125; finally &amp;#123; if (!wasAdded) &amp;#123; buffer.release(); &amp;#125; &amp;#125; &amp;#125; 最后, 我们看一下文件传输的 零拷贝 @Override public long transferTo(WritableByteChannel target, long position) throws IOException &amp;#123; long count = this.count - position; if (count &lt; 0 || position &lt; 0) &amp;#123; throw new IllegalArgumentException( \"position out of range: \" + position + \" (expected: 0 - \" + (this.count - 1) + ')'); &amp;#125; if (count == 0) &amp;#123; return 0L; &amp;#125; if (refCnt() == 0) &amp;#123; throw new IllegalReferenceCountException(0); &amp;#125; // Call open to make sure fc is initialized. This is a no-oop if we called it before. open(); long written = file.transferTo(this.position + position, count, target); if (written > 0) &amp;#123; transferred += written; &amp;#125; return written; &amp;#125; Netty文件传输 DefaultFileRegion 通过 transferTo 方法将文件 发送到目标Channel, 下面重点看 FileChannel 的 transferTo 方法， 它的API DOC 说明如下: /** * Transfers bytes from this channel's file to the given writable byte * channel. * * &lt;p> An attempt is made to read up to &lt;tt>count&lt;/tt> bytes starting at * the given &lt;tt>position&lt;/tt> in this channel's file and write them to the * target channel. An invocation of this method may or may not transfer * all of the requested bytes; whether or not it does so depends upon the * natures and states of the channels. Fewer than the requested number of * bytes are transferred if this channel's file contains fewer than * &lt;tt>count&lt;/tt> bytes starting at the given &lt;tt>position&lt;/tt>, or if the * target channel is non-blocking and it has fewer than &lt;tt>count&lt;/tt> * bytes free in its output buffer. * * &lt;p> This method does not modify this channel's position. If the given * position is greater than the file's current size then no bytes are * transferred. If the target channel has a position then bytes are * written starting at that position and then the position is incremented * by the number of bytes written. * * &lt;p> This method is potentially much more efficient than a simple loop * that reads from this channel and writes to the target channel. Many * operating systems can transfer bytes directly from the filesystem cache * to the target channel without actually copying them. &lt;/p> * * @param position * The position within the file at which the transfer is to begin; * must be non-negative * * @param count * The maximum number of bytes to be transferred; must be * non-negative * * @param target * The target channel * * @return The number of bytes, possibly zero, * that were actually transferred * * @throws IllegalArgumentException * If the preconditions on the parameters do not hold * * @throws NonReadableChannelException * If this channel was not opened for reading * * @throws NonWritableChannelException * If the target channel was not opened for writing * * @throws ClosedChannelException * If either this channel or the target channel is closed * * @throws AsynchronousCloseException * If another thread closes either channel * while the transfer is in progress * * @throws ClosedByInterruptException * If another thread interrupts the current thread while the * transfer is in progress, thereby closing both channels and * setting the current thread's interrupt status * * @throws IOException * If some other I/O error occurs */ public abstract long transferTo(long position, long count, WritableByteChannel target) throws IOException; 对于很多操作系统它直接将文件缓冲区的内容发送到目标Channel, 而不需要通过拷贝的方式, 这是一种更加高效的传输方式, 它实现了文件传输的零拷贝 3. 内存池随着JVM 虚拟机和JIT 及时编译技术的发展, 对象的分配和回收是个非常轻量级的工作. 但是对于缓存区Buffer,情况却稍有不同, 特别是对于堆外内存的分配和回收， 是一件耗时的操作. 为了尽量重用缓冲区, Netty 提供了基于内存池的缓冲区重用机制, 下面我们一起看下Netty ByteBuf 的实现 Netty 提供了多种内存管理策略, 通过在启动辅助类中配置相关参数, 可以实现差异化的定制， 下面通过性能测试, 我们看下基于内存池循环利用的ByteBuf 和普通的 ByteBuf 的性能差异 package com.formula.netty.base.buffer; import io.netty.buffer.ByteBuf; import io.netty.buffer.PooledByteBufAllocator; import io.netty.buffer.Unpooled; /** * @author luyanan * @since 2019/9/23 * &lt;p> 基于内存池循环利用的 ByteBuf 和普通 ByteBuf 的性能差异&lt;/p> **/ public class ByteBufDemo &amp;#123; public static void main(String[] args) &amp;#123; final byte[] CONTENT = new byte[1024]; int loop = 1800000; long startTime = System.currentTimeMillis(); ByteBuf poolBuffer = null; for (int i = 0; i &lt; loop; i++) &amp;#123; poolBuffer = PooledByteBufAllocator.DEFAULT.directBuffer(1024); poolBuffer.writeBytes(CONTENT); poolBuffer.release(); &amp;#125; long endTime = System.currentTimeMillis(); System.out.println(\"内存池分配缓冲区耗时：\" + (endTime - startTime) + \"ms\"); long startTime2 = System.currentTimeMillis(); ByteBuf buf = null; for (int i = 0; i &lt; loop; i++) &amp;#123; buf = Unpooled.directBuffer(1024); buf.writeBytes(CONTENT); &amp;#125; long endTime2 = System.currentTimeMillis(); System.out.println(\"非内存池分配缓冲区耗时: \" + (endTime2 - startTime2) + \"ms\"); &amp;#125; &amp;#125; 各执行 180万次, 性能对比结果如下: 内存池分配缓冲区耗时：773ms 非内存池分配缓冲区耗时: 1705ms 性能测试表明, 采用内存池的ByteBuf 相比于 于朝生夕灭的ByteBuf,性能高了23倍左右(性能数据与使用场景强相关), 下面我们一起简单分析下 Netty 内存池的内存分配 @Override public ByteBuf directBuffer(int initialCapacity, int maxCapacity) &amp;#123; if (initialCapacity == 0 &amp;&amp; maxCapacity == 0) &amp;#123; return emptyBuf; &amp;#125; validate(initialCapacity, maxCapacity); return newDirectBuffer(initialCapacity, maxCapacity); &amp;#125; 继续看 newDirectBuffer 方法, 我们发现他是一个抽象方法, 由 AbstractByteBufAllocator的子类 负责具体实现. 代码如下: 代码跳转到 PooledByteBufAllocator的 newDirectBuffer 方法. 从Cache 中获取内存区域 PoolArena, 调用它的 allocate 方法进行内存分配 @Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &amp;#123; PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer> directArena = cache.directArena; ByteBuf buf; if (directArena != null) &amp;#123; buf = directArena.allocate(cache, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; if (PlatformDependent.hasUnsafe()) &amp;#123; buf = UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; buf = new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; &amp;#125; return toLeakAwareBuffer(buf); &amp;#125; PoolArena的 allocate 方法如下： PooledByteBuf&lt;T> allocate(PoolThreadCache cache, int reqCapacity, int maxCapacity) &amp;#123; PooledByteBuf&lt;T> buf = newByteBuf(maxCapacity); allocate(cache, buf, reqCapacity); return buf; &amp;#125; 我们重点分析newByteBuf 的实现, 他同样是个抽象方法, 由子类 DirectArena 和 HeapArena 来实现不同类型的缓冲区分配, 由于测试用例使用的是 堆外内存 因此重点分析 DirectArena 的实现, 如果没有开启使用 sun的 unsafe ,则 @Override protected PooledByteBuf&lt;ByteBuffer> newByteBuf(int maxCapacity) &amp;#123; if (HAS_UNSAFE) &amp;#123; return PooledUnsafeDirectByteBuf.newInstance(maxCapacity); &amp;#125; else &amp;#123; return PooledDirectByteBuf.newInstance(maxCapacity); &amp;#125; &amp;#125; 执行 PooledDirectByteBuf.newInstance 的方法，代码如下: static PooledDirectByteBuf newInstance(int maxCapacity) &amp;#123; PooledDirectByteBuf buf = RECYCLER.get(); buf.reuse(maxCapacity); return buf; &amp;#125; 通过 RECYCLER的get 方法循环使用ByteBuf 对象， 如果是非内存池实现, 则直接创建一个新的ByteBuf 对象, 从缓冲池中获取ByteBuf 之后, 调用 AbstractReferenceCountedByteBuf的 setRefCnt 方法设置引用计数器, 用于对象的引用计数和内存回收(类似于JVM垃圾回收机制) 4. 高效的Reactor 线程模型常见的Reactor模型有三种, 分别如下: Reactor 单线程模型 Reactor 单线程模型,指的是所有的IO操作都在同一个NIO 线程上面完成, NIO线程的职责如下: 作为NIO服务端， 接受客户端的TCP连接 作为NIO客户端, 想服务端发起TCP连接 读取通信对端的请求或者应答消息 想通信对端发送消息请求或者应答请求. Reactor 单线程模型示意图如下所示 由于Reactor 模式使用的是异步非阻塞IO， 所有的IO操作都不会导致阻塞, 理论上一个线程可以独立处理所有的IO相关的操作. 从架构层面上, 一个NIO线程确实可以完成其承担的职责, 例如, 通过Accepter 接受客户端的TCP 连接请求消息, 链路 建立成功后,通过Dispatch 将对用的ByteBuf 派发到指定的 Handler 上进行消息解码. 用户的Handler 可以通过NIO线程 将消息发送至客户端. 对于一个小容量应用场景, 可以使用单线程模型. 但是对于高负载、大并发的应用却不合适, 主要原因如下： 一个NIO线程同时处理成百上千的链路, 性能上无法支持, 及时NIO的线程的CPU负荷达到100%, 也无法满足海量消息的解码、编码、读取和发送, 当NIO 线程负载过重后， 处理速度将变慢,这会导致大量客户端连接超时, 超时之后往往会进行重发， 这更加重了NIO线程的负载, 最终会导致大量消息积压和处理超时, NIO线程会成为系统的性能瓶颈, 可靠性问题: 一旦NIO线程 意外跑飞, 或者进入死循环, 会导致整个系统通信模块不可用, 不能接受和处理外部消息， 造成节点故障. 为了解决这些问题, 演进出了 Reactor 多线程模型, 接下来我们一起来学习一下Reactor 多线程模型 Reactor 多线程模型 Reactor 多线程模型与单线程模型最大的区别就是有一组NIO线程处理IO操作, 它的原理图如下： Reactor 多线程模型的特点如下： 专门有一个NIO线程 Acceptor 线程用于监听服务端, 接受客户端TCP连接请求. 网络IO操作-读、写等由一个NIO线程池负责, 线程池可以采用标准的JDK 线程池实现, 它包含了一个任务队列和N个可用的线程, 由这些线程负责消息的读取、解码、编码和发送. 1个NIO线程可以同时处理N个链路, 但是1个链路只对用1个线程, 防止发生并发操作问题. ​ 在绝大数场景下, Reactor 多线程模型都可以满足性能需求, 但是, 在极特殊应用场景中, 一个NIO 线程负责监听和处理所有的客户端连接可能会存在性能问题, 例如百万客户端并发链接，或者服务端需要对客户端的握手消息进行安全认证, 认证本身非常耗损性能, 这这些场景下， 单独一个Accepter 线程可能会存在性能不足问题, 为了解决性能问题, 产生了第三种Reactor线程模型 - 主从Reactor 多线程模型. 主从Reactor 多线程模型 主从Reactor 线程模型的特点是: 服务端用于接收客户端连接的不再是一个单独的NIO线程, 而是一个独立的NIO线程池, Acceptor 接收到客户端TCP 连接请求处理完成后(可能包含接入认证), 将新创建的 SocketChannel 注册到IO线程池(sub reactor 线程池) 的某个IO 线程上, 由他负责 SocketChannel 的读写和编解码工作. Acceptor 线程池仅仅只用于客户端的登录、握手和安全认证, 一旦链路建立成功, 就将链路注册到后端 subReactor 线程池的IO线程上, 由IO线程负责后续的IO操作. 它的线程模型如下图所示: 利用主从IO线程模型, 可以解决1 个服务端监听线程无法有效处理所有客户端连接的性能不足问题, 因此, 在Netty 的官方demo中, 推荐使用该线程模型. 事实上, Netty的线程模型并非固定不变, 通过在启动辅助类中创建不同的EventLoopGroup 实例并通过适当的参数配置， 就可以支持上述三种Reactor 线程模型, 正是因为Netty 对Reactor 线程模型的支持提供了灵活的定制能力, 所以可以满足不同业务场景的性能诉求. 5. 无锁化的串行设计理念. 在大多数场景下, 并行多线程处理可以提升系统的并发性能. 但是, 如果对于共享资源的并发访问处理不当, 会带来严重的锁竞争, 这最终会导致性能的下降. 为了尽可能的避免锁竞争带来的性能损耗，可以通过串行化设计, 即消息的处理尽可能在同一个线程内完成, 期间不进行线程切换, 这样就避免了多线程竞争和同步锁。 为了尽可能的提升性能, Netty采用了串行无锁化设计, 在IO线程内部进行串行操作, 避免多线程竞争导致的性能下降, 表面上看, 串行化设计似乎CPU利用率不高， 并发程度不够, 但是, 通过调整NIO线程池的线程参数, 可以同时启动多个串行化的线程并行运行, 这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优. Netty 的串行化设计工作原理如下: Netty的 NioEventLoop 读取到消息后, 直接调用 ChannelPipeline 的 fireChannelRead(Object msg)，只要用户不主动切换线程, 一直会由 NioEventLoop 调用到用户的handler, 期间不进行线程切换, 这种串行化处理方式避免了多线程操作导致的锁的竞争, 从性能角度看是最优的. 6. 高效的并发编程.Netty的高效并发编程主要体现在如下几点: volatile 的大量、正确使用 CAS 和原子类的广泛使用 线程安全容器的使用 通过读写锁提升并发性能. 7. 高性能的序列化框架影响序列化性能的关键因素总结如下: 序列化后的码流大小(网络带宽的占用) 序列化&amp;反序列化的性能(CPU资源占用) 是否支持跨语言(异构系统的对接和开发语言切换) Netty 默认提供了对Google Protobuf的支持， 通过扩展 Netty的编解码接口, 用户可以实现其他的高性能序列化框架, 例如 Thrift 的压缩二进制编解码框架, 下面我们一起来看一下 不同序列化&amp;反序列化框架序列化后的字节数组大小. 从上图可以看出, Protobuf 序列化后的码流只有Java 序列化后的1/4左右, 正是由于Java原生序列化性能表现太差, 才催生了各种高性能的开源序列化技术和框架(性能差只是其中的一个原因, 还有跨语言、IDL定义等其他因素) 8. 灵活的TCP参数配置能力合理设置TCP参数在某些场景下对于性能的提升可以起到显著的效果, 例如SO_RCVBUF 和 SO_SNDBUF。如果设置不当, 对性能的影响是非常大的, 下面我们总结一下对性能影响比较大的几个配置项. SO_RCVBUF 和 SO_SNDBUF : 通常建议值设置为128K 或者256K SO_TCPNODELAY：NAGLE算法通过将缓冲区内的小封包自动相连. 组成较大的封包, 阻止大量小封包的发送阻塞网络, 从而提高网络应用效率. 但是对于时延敏感的应用场景来说需要关闭该优化算法. 软中断: 如果linux 内核版本支持 RPS(2.6.35 以上版本),开启 RPS 后可以实现软中断, 提升网络吞吐量, RPS 根据数据包的源地址, 目的地址,以及目的源地址和端口,计算出一个hash值, 然后根据这个hash值来选择软中断 运行的CPU， 从上层来看, 也就是将每个链接和cpu绑定, 并通过这个hash值, 来均衡软中断在多个cpu上, 提升网络并行处理性能. Netty在启动辅助类中可以灵活的配置TCP参数, 满足不同的用户场景, 相关配置接口定义如下：","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"使用Netty手写tomcat(3)","slug":"Netty/使用Netty手写tomcat(3)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/shi-yong-netty-shou-xie-tomcat-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/shi-yong-netty-shou-xie-tomcat-3/","excerpt":"","text":"使用Netty手写Tomcat容器前面学了一下netty的使用，我们知道Tomcat的底层也是使用的Netty, 这里使用Netty手写一个麻雀虽小五脏俱全的Tomcat容器 请求类封装 Requestpackage com.formula.netty.tomcat.http; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.http.HttpRequest; /** * @author luyanan * @since 2019/9/19 * 请求封装 **/ public class Request &#123; private ChannelHandlerContext chc; private HttpRequest httpRequest; public Request(ChannelHandlerContext chc, HttpRequest httpRequest) &#123; this.chc = chc; this.httpRequest = httpRequest; &#125; public String getUrl() &#123; return this.httpRequest.uri(); &#125; public String getMethod() &#123; return httpRequest.method().name(); &#125; &#125; 返回封装package com.formula.netty.tomcat.http; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.http.*; import java.io.UnsupportedEncodingException; /** * @author luyanan * @since 2019/9/19 * &lt;p>返回封装&lt;/p> **/ public class Response &amp;#123; private ChannelHandlerContext chc; private HttpRequest httpRequest; public Response(ChannelHandlerContext chc, HttpRequest httpRequest) &amp;#123; this.chc = chc; this.httpRequest = httpRequest; &amp;#125; public void write(String out) throws UnsupportedEncodingException &amp;#123; if (out == null || out.length() == 0) &amp;#123; return; &amp;#125; try &amp;#123; // 设置http协议以及请求头协议 FullHttpResponse response = new DefaultFullHttpResponse( // 设置http版本为1.1 HttpVersion.HTTP_1_1, // 设置响应状态码 HttpResponseStatus.OK, // 将输出值写出 编码为UTF-8 Unpooled.wrappedBuffer(out.getBytes(\"UTF-8\"))); response.headers().set(\"Content-Type\", \"text/html;\"); // 当前是否支持长连接 // if (HttpUtil.isKeepAlive(r)) &amp;#123; // // 设置连接内容为长连接 // response.headers().set(CONNECTION, HttpHeaderValues.KEEP_ALIVE); // &amp;#125; chc.write(response); chc.flush(); &amp;#125; finally &amp;#123; chc.close(); &amp;#125; &amp;#125; &amp;#125; servlet 封装package com.formula.netty.tomcat.http; /** * @author luyanan * @since 2019/9/19 * &lt;p>&lt;/p> **/ public abstract class Servlet &amp;#123; public void service(Request request, Response response) throws Exception &amp;#123; if (\"GET\".equalsIgnoreCase(request.getMethod())) &amp;#123; doGet(request, response); &amp;#125; else &amp;#123; doPost(request, response); &amp;#125; &amp;#125; public abstract void doPost(Request request, Response response) throws Exception; public abstract void doGet(Request request, Response response) throws Exception; &amp;#125; 这里我们创建两个servletFirstServlet package com.formula.netty.tomcat.servlet; import com.formula.netty.tomcat.http.Request; import com.formula.netty.tomcat.http.Response; import com.formula.netty.tomcat.http.Servlet; import java.io.UnsupportedEncodingException; /** * @author luyanan * @since 2019/9/19 * &lt;p>&lt;/p> **/ public class FirstServlet extends Servlet &amp;#123; @Override public void doPost(Request request, Response response) throws Exception &amp;#123; response.write(\"FirstServlet\"); &amp;#125; @Override public void doGet(Request request, Response response) throws Exception &amp;#123; this.doPost(request, response); &amp;#125; &amp;#125; SecondServlet package com.formula.netty.tomcat.servlet; import com.formula.netty.tomcat.http.Request; import com.formula.netty.tomcat.http.Response; import com.formula.netty.tomcat.http.Servlet; /** * @author luyanan * @since 2019/9/19 * &lt;p>&lt;/p> **/ public class SecondServlet extends Servlet &amp;#123; @Override public void doPost(Request request, Response response) throws Exception&amp;#123; response.write(\"SecondServlet\"); &amp;#125; @Override public void doGet(Request request, Response response) throws Exception&amp;#123; this.doPost(request, response); &amp;#125; &amp;#125; Tomcat 主启动类package com.formula.netty.tomcat; import com.formula.netty.tomcat.http.Servlet; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.sctp.nio.NioSctpServerChannel; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.http.HttpRequestDecoder; import io.netty.handler.codec.http.HttpResponseDecoder; import io.netty.handler.codec.http.HttpResponseEncoder; import javax.sound.midi.Track; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; import java.util.HashMap; import java.util.Map; import java.util.Properties; /** * @author luyanan * @since 2019/9/19 * &lt;p>&lt;/p> **/ public class Tomcat &amp;#123; /** * &lt;p>端口号&lt;/p> * * @author luyanan * @since 2019/9/19 */ private int port = 8080; private Map&lt;String, Servlet> servletMap = new HashMap&lt;String, Servlet>(); private Properties webxml = new Properties(); /** * &lt;p>初始化方法&lt;/p> * * @author luyanan * @since 2019/9/19 */ private void init() &amp;#123; // 加载配置文件并初始化servletMap try &amp;#123; String path = this.getClass().getResource(\"/\").getPath(); FileInputStream fis = new FileInputStream(path + \"web.properties\"); webxml.load(fis); // 初始化 servletMap for (Object o : webxml.keySet()) &amp;#123; String key = o.toString(); if (key.endsWith(\".url\")) &amp;#123; String servletName = key.replaceAll(\"\\\\.url$\", \"\"); String url = webxml.getProperty(key); // className String className = webxml.getProperty(servletName + \".className\"); Servlet servlet = (Servlet) Class.forName(className).newInstance(); servletMap.put(url, servlet); &amp;#125; &amp;#125; &amp;#125; catch (FileNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (IllegalAccessException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (InstantiationException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; public void start() &amp;#123; init(); // netty 封装了NIO, Reactor模型. BOss Worker, // Boss 线程 EventLoopGroup bossGroup = new NioEventLoopGroup(); // Worker 线程 EventLoopGroup workerGroup = new NioEventLoopGroup(); try &amp;#123; ServerBootstrap bootstrap = new ServerBootstrap(); //链路式编程 bootstrap.group(bossGroup, workerGroup) //主线程处理类， 底层使用反射 .channel(NioServerSocketChannel.class) // 子线程处理类 .childHandler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &amp;#123; // 无锁化串行编程 // Netty 对Http协议的封装,顺序有要求 // HttpResponseEncoder 编码器 socketChannel.pipeline().addLast(new HttpResponseEncoder()); //HttpRequestDecoder 解码器 socketChannel.pipeline().addLast(new HttpRequestDecoder()); // 业务处理类 socketChannel.pipeline().addLast(new TomcatHandler(servletMap)); &amp;#125; &amp;#125;) // 针对主线程的配置,分配线程最大数量 128 .option(ChannelOption.SO_BACKLOG, 128) //针对子线程的配置, 保持长连接 .childOption(ChannelOption.SO_KEEPALIVE, true); // 启动服务区 ChannelFuture channelFuture = bootstrap.bind(port).sync(); System.out.println(\"Tomcat 启动成功, 端口号为: \" + this.port); channelFuture.channel().closeFuture().sync(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; // 关闭线程池 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &amp;#125; &amp;#125; public static void main(String[] args) &amp;#123; new Tomcat().start(); &amp;#125; &amp;#125; TomcatHandler 处理类package com.formula.netty.tomcat; import com.formula.netty.tomcat.http.Request; import com.formula.netty.tomcat.http.Response; import com.formula.netty.tomcat.http.Servlet; import com.sun.org.apache.regexp.internal.RE; import io.netty.channel.ChannelHandler; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.handler.codec.http.HttpRequest; import io.netty.util.concurrent.EventExecutorGroup; import java.util.Map; /** * @author luyanan * @since 2019/9/19 * &lt;p>&lt;/p> **/ public class TomcatHandler extends ChannelInboundHandlerAdapter &amp;#123; private Map&lt;String, Servlet> servletMap = null; public TomcatHandler(Map&lt;String, Servlet> servletMap) &amp;#123; this.servletMap = servletMap; &amp;#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; if (msg instanceof HttpRequest) &amp;#123; HttpRequest httpRequest = (HttpRequest) msg; Request request = new Request(ctx, httpRequest); Response response = new Response(ctx, httpRequest); String url = request.getUrl(); if (servletMap.containsKey(url)) &amp;#123; servletMap.get(url).service(request, response); &amp;#125; else &amp;#123; response.write(\"404 - Not Found\"); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 配置文件 web.propertiesservlet.one.url=/firstServlet.do servlet.one.className=com.formula.netty.tomcat.servlet.FirstServlet servlet.two.url=/secondServlet.do servlet.two.className=com.formula.netty.tomcat.servlet.SecondServlet 我们启动Tomcat类下的main 方法后, 可以看到","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"使用NIO实现一个聊天室功能(5)","slug":"Netty/使用NIO实现一个聊天室功能(5)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/shi-yong-nio-shi-xian-yi-ge-liao-tian-shi-gong-neng-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/shi-yong-nio-shi-xian-yi-ge-liao-tian-shi-gong-neng-5/","excerpt":"","text":"使用NIO实现一个聊天室公共功能主要实现功能: 功能1: 客户端通过Java NIO 连接到服务端, 支持多客户端的连接 功能2: 客户端初次连接的时候, 服务端提示输入昵称, 如果昵称已经有人使用, 则提示重新输入, 如果昵称唯一, 则登录成功, 之后发送消息都需要按照规定格式带着昵称发送消息 功能3: 客户端登录后, 发送已经设置好的欢迎信息和在线人数给客户端, 并且通知其他客户端该客户端已经上线 功能4: 服务端收到已登录客户端输入内容, 转发至其他客户端 服务端代码package com.formula.netty.chat; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.nio.charset.Charset; import java.util.HashSet; import java.util.Iterator; import java.util.Set; /** * @author luyanan * @since 2019/9/21 * &lt;p>网络多客户端聊天室 * 功能1: 客户端通过Java NIO 连接到服务端, 支持多客户端的连接 * 功能2: 客户端初次连接的时候, 服务端提示输入昵称, 如果昵称已经有人使用, 则提示重新输入, 如果昵称唯一, 则登录成功, * 之后发送消息都需要按照规定格式带着昵称发送消息 * 功能3: 客户端登录后, 发送已经设置好的欢迎信息和在线人数给客户端, 并且通知其他客户端该客户端已经上线 * 功能4: 服务端收到已登录客户端输入内容, 转发至其他客户端 * &lt;/p> **/ public class NIOChatServer &amp;#123; private int port = 8080; //相当于自定义协议格式，与客户端协商好 private static String USER_CONTENT_SPILIT = \"#@#\"; private Charset charset = Charset.forName(\"utf-8\"); private Selector selector; private static String USER_EXIST = \"系统提示：该昵称已经存在，请换一个昵称\"; /** * &lt;p>用来记录在线人数, 以及昵称&lt;/p> * * @author luyanan * @since 2019/9/21 */ private static HashSet&lt;String> users = new HashSet&lt;>(); public NIOChatServer(int port) throws IOException &amp;#123; this.port = port; ServerSocketChannel server = ServerSocketChannel.open(); // 绑定端口号 server.bind(new InetSocketAddress(this.port)); // 设置为非阻塞 server.configureBlocking(false); // 初始化轮询器 this.selector = Selector.open(); // 注册事件 server.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\"服务已经启动, 端口号为: \" + this.port); &amp;#125; /** * &lt;p>开始监听&lt;/p> * * @return &amp;#123;@link&amp;#125; * @author luyanan * @since 2019/9/21 */ public void listen() throws IOException &amp;#123; while (true) &amp;#123; int wait = selector.select(); if (wait == 0) &amp;#123; continue; &amp;#125; Set&lt;SelectionKey> selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey> iterator = selectionKeys.iterator(); while (iterator.hasNext()) &amp;#123; SelectionKey selectionKey = iterator.next(); iterator.remove(); process(selectionKey); &amp;#125; &amp;#125; &amp;#125; private void process(SelectionKey selectionKey) throws IOException &amp;#123; if (selectionKey.isAcceptable()) &amp;#123; ServerSocketChannel server = (ServerSocketChannel) selectionKey.channel(); SocketChannel client = server.accept(); // 设置为非阻塞模式 client.configureBlocking(false); //注册选择器, 并设置为读取模式, 收到一个连接请求, 然后起一个 socketChannel , 并注册到selector 上, 之后这个连接的数据, 就由这个 socketCHannel 处理 client.register(selector, SelectionKey.OP_READ); // 将此对应的 channel 设置为准备接受其他客户端请求 selectionKey.interestOps(SelectionKey.OP_ACCEPT); System.out.println(\"有客户端连接: IP地址为: \" + client.getRemoteAddress()); client.write(charset.encode(\"请输入您的昵称\")); &amp;#125; // 处理来自客户端的数据读取请求 if (selectionKey.isReadable()) &amp;#123; // 返回该 selectionKey 对应的channel, 其中有数据需要读取 SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); StringBuffer content = new StringBuffer(); try &amp;#123; while (client.read(buffer) > 0) &amp;#123; buffer.flip(); content.append(charset.decode(buffer)); &amp;#125; // 将此对应的channel 设置为准备下一次接受数据 selectionKey.interestOps(SelectionKey.OP_READ); &amp;#125; catch (IOException e) &amp;#123; selectionKey.cancel(); if (selectionKey.channel() != null) &amp;#123; selectionKey.channel().close(); &amp;#125; &amp;#125; if (content.length() > 0) &amp;#123; String[] arrayContent = content.toString().split(USER_CONTENT_SPILIT); // 注册用户 if (arrayContent != null &amp;&amp; arrayContent.length == 1) &amp;#123; String nickName = arrayContent[0]; if (users.contains(nickName)) &amp;#123; client.write(charset.encode(USER_EXIST)); &amp;#125; else &amp;#123; users.add(nickName); int onlineCount = onlineCount(); String message = \"欢迎: \" + nickName + \"进入聊天室！当前在线人数: \" + onlineCount; message = nickName + \" 说\" + message; if (users.contains(nickName)) &amp;#123; // 不会发送给此内容的客户端 broadCase(client, message); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; private void broadCase(SocketChannel client, String message) throws IOException &amp;#123; // 广播数据到所有的 SocketChannel for (SelectionKey key : selector.keys()) &amp;#123; Channel channel = key.channel(); // 如果client 不为空, 不会发给此内容的客户端 if (channel instanceof SocketChannel &amp;&amp; channel != client) &amp;#123; SocketChannel socketChannel = (SocketChannel) channel; socketChannel.write(charset.encode(message)); &amp;#125; &amp;#125; &amp;#125; public int onlineCount() &amp;#123; int res = 0; for (SelectionKey key : selector.keys()) &amp;#123; Channel channel = key.channel(); // 如果client 不为空, 不会发给此内容的客户端 if (channel instanceof SocketChannel) &amp;#123; res++; &amp;#125; &amp;#125; return res; &amp;#125; public static void main(String[] args) throws IOException &amp;#123; new NIOChatServer(8080).listen(); &amp;#125; &amp;#125; 客户端代码package com.formula.netty.chat; import java.io.IOException; import java.io.Reader; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.SocketChannel; import java.nio.charset.Charset; import java.util.Iterator; import java.util.Scanner; import java.util.Set; /** * @author luyanan * @since 2019/9/21 * &lt;p>&lt;/p> **/ public class NIOChatClient &amp;#123; private final InetSocketAddress socketAddress = new InetSocketAddress(\"localhost\", 8080); private Selector selector; private SocketChannel client; private String nickName; private Charset charset = Charset.forName(\"UTF-8\"); private static String USER_EXIST = \"系统提示：该昵称已经存在，请换一个昵称\"; private static String USER_CONTENT_SPILIT = \"#@#\"; public NIOChatClient() throws IOException &amp;#123; selector = Selector.open(); // 连接远程主机的IP和端口 client = SocketChannel.open(socketAddress); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); &amp;#125; public void session() &amp;#123; // 开辟一个新的线程从服务器端读数据 new Reader().start(); // 开辟一个新的线程往服务端写数据 new Write().start(); &amp;#125; private class Reader extends Thread &amp;#123; @Override public void run() &amp;#123; try &amp;#123; while (true) &amp;#123; int select = selector.select(); if (select == 0) &amp;#123; continue; &amp;#125; Set&lt;SelectionKey> selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey> iterator = selectionKeys.iterator(); while (iterator.hasNext()) &amp;#123; SelectionKey selectionKey = iterator.next(); iterator.remove(); process(selectionKey); &amp;#125; &amp;#125; &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; private void process(SelectionKey selectionKey) &amp;#123; if (selectionKey.isReadable()) &amp;#123; // 使用NIO Server 读取Channel的数据, 这个和全局变量client是一样的, 只是因为注册了一个 socketChannel SocketChannel socketChannel = (SocketChannel) selectionKey.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); String content = \"\"; try &amp;#123; while (socketChannel.read(buffer) > 0) &amp;#123; buffer.flip(); content = content + charset.decode(buffer); &amp;#125; &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; // 若系统发送通知名字已经存在， 则需要换个昵称 if (USER_EXIST.endsWith(content)) &amp;#123; nickName = \"\"; &amp;#125; System.out.println(content); selectionKey.interestOps(SelectionKey.OP_READ); &amp;#125; &amp;#125; &amp;#125; private class Write extends Thread &amp;#123; @Override public void run() &amp;#123; // 在主线程中, 从键盘读取数据输入到服务器端 Scanner scanner = new Scanner(System.in); try &amp;#123; while (scanner.hasNextLine()) &amp;#123; String nextLine = scanner.nextLine(); if (\"\".equals(nextLine)) &amp;#123; continue; &amp;#125; if (\"\".equals(nickName)) &amp;#123; nickName = nextLine; nextLine = nickName + USER_CONTENT_SPILIT + nextLine; &amp;#125; client.write(charset.encode(nextLine)); &amp;#125; scanner.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; public static void main(String[] args) throws IOException &amp;#123; new NIOChatClient().session(); &amp;#125; &amp;#125;","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Promise 与 Future 双子星的秘密(11)","slug":"Netty/Promise 与 Future 双子星的秘密(11)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/promise-yu-future-shuang-zi-xing-de-mi-mi-11/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/promise-yu-future-shuang-zi-xing-de-mi-mi-11/","excerpt":"","text":"Promise 与 Future 双子星的秘密1. 异步结果Futurejava.util.concurrent.Future 是java 提供的接口, 表示异步执行的状态, Future 的get() 方法会判断任务是否执行完成,如果完成就返回结果, 否则阻塞线程, 直到任务完成. Netty 扩展了Java 的Future , 最主要的改进就是增加了监听器Listener 接口, 通过监听可以让异步执行的更加有效率, 不需要通过get 来等待异步执行结束, 而是通过监听器回调来精确的控制异步执行结束的时间点. public interface Future&lt;V> extends java.util.concurrent.Future&lt;V> &amp;#123; /** * Returns &amp;#123;@code true&amp;#125; if and only if the I/O operation was completed * successfully. */ boolean isSuccess(); /** * returns &amp;#123;@code true&amp;#125; if and only if the operation can be cancelled via &amp;#123;@link #cancel(boolean)&amp;#125;. */ boolean isCancellable(); /** * Returns the cause of the failed I/O operation if the I/O operation has * failed. * * @return the cause of the failure. * &amp;#123;@code null&amp;#125; if succeeded or this future is not * completed yet. */ Throwable cause(); /** * Adds the specified listener to this future. The * specified listener is notified when this future is * &amp;#123;@linkplain #isDone() done&amp;#125;. If this future is already * completed, the specified listener is notified immediately. */ Future&lt;V> addListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener); /** * Adds the specified listeners to this future. The * specified listeners are notified when this future is * &amp;#123;@linkplain #isDone() done&amp;#125;. If this future is already * completed, the specified listeners are notified immediately. */ Future&lt;V> addListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners); /** * Removes the first occurrence of the specified listener from this future. * The specified listener is no longer notified when this * future is &amp;#123;@linkplain #isDone() done&amp;#125;. If the specified * listener is not associated with this future, this method * does nothing and returns silently. */ Future&lt;V> removeListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener); /** * Removes the first occurrence for each of the listeners from this future. * The specified listeners are no longer notified when this * future is &amp;#123;@linkplain #isDone() done&amp;#125;. If the specified * listeners are not associated with this future, this method * does nothing and returns silently. */ Future&lt;V> removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners); /** * Waits for this future until it is done, and rethrows the cause of the failure if this future * failed. */ Future&lt;V> sync() throws InterruptedException; /** * Waits for this future until it is done, and rethrows the cause of the failure if this future * failed. */ Future&lt;V> syncUninterruptibly(); /** * Waits for this future to be completed. * * @throws InterruptedException * if the current thread was interrupted */ Future&lt;V> await() throws InterruptedException; /** * Waits for this future to be completed without * interruption. This method catches an &amp;#123;@link InterruptedException&amp;#125; and * discards it silently. */ Future&lt;V> awaitUninterruptibly(); /** * Waits for this future to be completed within the * specified time limit. * * @return &amp;#123;@code true&amp;#125; if and only if the future was completed within * the specified time limit * * @throws InterruptedException * if the current thread was interrupted */ boolean await(long timeout, TimeUnit unit) throws InterruptedException; /** * Waits for this future to be completed within the * specified time limit. * * @return &amp;#123;@code true&amp;#125; if and only if the future was completed within * the specified time limit * * @throws InterruptedException * if the current thread was interrupted */ boolean await(long timeoutMillis) throws InterruptedException; /** * Waits for this future to be completed within the * specified time limit without interruption. This method catches an * &amp;#123;@link InterruptedException&amp;#125; and discards it silently. * * @return &amp;#123;@code true&amp;#125; if and only if the future was completed within * the specified time limit */ boolean awaitUninterruptibly(long timeout, TimeUnit unit); /** * Waits for this future to be completed within the * specified time limit without interruption. This method catches an * &amp;#123;@link InterruptedException&amp;#125; and discards it silently. * * @return &amp;#123;@code true&amp;#125; if and only if the future was completed within * the specified time limit */ boolean awaitUninterruptibly(long timeoutMillis); /** * Return the result without blocking. If the future is not done yet this will return &amp;#123;@code null&amp;#125;. * * As it is possible that a &amp;#123;@code null&amp;#125; value is used to mark the future as successful you also need to check * if the future is really done with &amp;#123;@link #isDone()&amp;#125; and not relay on the returned &amp;#123;@code null&amp;#125; value. */ V getNow(); /** * &amp;#123;@inheritDoc&amp;#125; * * If the cancellation was successful it will fail the future with an &amp;#123;@link CancellationException&amp;#125;. */ @Override boolean cancel(boolean mayInterruptIfRunning); &amp;#125; ChannelFuture 接口扩展了Netty的 Future 接口, 表示一种没有返回值的异步调用，同时和一个Channel 进行绑定. public interface ChannelFuture extends Future&lt;Void> &amp;#123; /** * Returns a channel where the I/O operation associated with this * future takes place. */ Channel channel(); @Override ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener); @Override ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners); @Override ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener); @Override ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners); @Override ChannelFuture sync() throws InterruptedException; @Override ChannelFuture syncUninterruptibly(); @Override ChannelFuture await() throws InterruptedException; @Override ChannelFuture awaitUninterruptibly(); /** * Returns &amp;#123;@code true&amp;#125; if this &amp;#123;@link ChannelFuture&amp;#125; is a void future and so not allow to call any of the * following methods: * &lt;ul> * &lt;li>&amp;#123;@link #addListener(GenericFutureListener)&amp;#125;&lt;/li> * &lt;li>&amp;#123;@link #addListeners(GenericFutureListener[])&amp;#125;&lt;/li> * &lt;li>&amp;#123;@link #await()&amp;#125;&lt;/li> * &lt;li>&amp;#123;@link #await(long, TimeUnit)&amp;#125; ()&amp;#125;&lt;/li> * &lt;li>&amp;#123;@link #await(long)&amp;#125; ()&amp;#125;&lt;/li> * &lt;li>&amp;#123;@link #awaitUninterruptibly()&amp;#125;&lt;/li> * &lt;li>&amp;#123;@link #sync()&amp;#125;&lt;/li> * &lt;li>&amp;#123;@link #syncUninterruptibly()&amp;#125;&lt;/li> * &lt;/ul> */ boolean isVoid(); &amp;#125; 2. 异步执行PromisePromise 接口 也扩展了Future 接口, 表示他是一种可写的 Future, 就是可以设置异步执行的结果. public interface Promise&lt;V> extends Future&lt;V> &amp;#123; /** * Marks this future as a success and notifies all * listeners. * * If it is success or failed already it will throw an &amp;#123;@link IllegalStateException&amp;#125;. */ Promise&lt;V> setSuccess(V result); /** * Marks this future as a success and notifies all * listeners. * * @return &amp;#123;@code true&amp;#125; if and only if successfully marked this future as * a success. Otherwise &amp;#123;@code false&amp;#125; because this future is * already marked as either a success or a failure. */ boolean trySuccess(V result); /** * Marks this future as a failure and notifies all * listeners. * * If it is success or failed already it will throw an &amp;#123;@link IllegalStateException&amp;#125;. */ Promise&lt;V> setFailure(Throwable cause); /** * Marks this future as a failure and notifies all * listeners. * * @return &amp;#123;@code true&amp;#125; if and only if successfully marked this future as * a failure. Otherwise &amp;#123;@code false&amp;#125; because this future is * already marked as either a success or a failure. */ boolean tryFailure(Throwable cause); /** * Make this future impossible to cancel. * * @return &amp;#123;@code true&amp;#125; if and only if successfully marked this future as uncancellable or it is already done * without being cancelled. &amp;#123;@code false&amp;#125; if this future has been cancelled already. */ boolean setUncancellable(); @Override Promise&lt;V> addListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener); @Override Promise&lt;V> addListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners); @Override Promise&lt;V> removeListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener); @Override Promise&lt;V> removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners); @Override Promise&lt;V> await() throws InterruptedException; @Override Promise&lt;V> awaitUninterruptibly(); @Override Promise&lt;V> sync() throws InterruptedException; @Override Promise&lt;V> syncUninterruptibly(); &amp;#125; ChannelPromise 接口扩展了 ChannelFuture 和 Promise, 绑定了Channel. 即可以写成异步执行结构, 又具备了监听者 的功能, 是Netty实际编程使用的表示异步执行的接口. public interface ChannelPromise extends ChannelFuture, Promise&lt;Void> &amp;#123; @Override Channel channel(); @Override ChannelPromise setSuccess(Void result); ChannelPromise setSuccess(); boolean trySuccess(); @Override ChannelPromise setFailure(Throwable cause); @Override ChannelPromise addListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener); @Override ChannelPromise addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners); @Override ChannelPromise removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void>> listener); @Override ChannelPromise removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners); @Override ChannelPromise sync() throws InterruptedException; @Override ChannelPromise syncUninterruptibly(); @Override ChannelPromise await() throws InterruptedException; @Override ChannelPromise awaitUninterruptibly(); /** * Returns a new &amp;#123;@link ChannelPromise&amp;#125; if &amp;#123;@link #isVoid()&amp;#125; returns &amp;#123;@code true&amp;#125; otherwise itself. */ ChannelPromise unvoid(); &amp;#125; DefaultChannelPromise 是ChannelPromise 的实现类, 它是实际运行的 Promise 实例, Netty使用addListener() 方法来回调异步执行的结果, 看一下 DefaultPromise的 addListener() 方法的源码 @Override public Promise&lt;V> addListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener) &amp;#123; checkNotNull(listener, \"listener\"); synchronized (this) &amp;#123; addListener0(listener); &amp;#125; if (isDone()) &amp;#123; notifyListeners(); &amp;#125; return this; &amp;#125; private void addListener0(GenericFutureListener&lt;? extends Future&lt;? super V>> listener) &amp;#123; if (listeners == null) &amp;#123; listeners = listener; &amp;#125; else if (listeners instanceof DefaultFutureListeners) &amp;#123; ((DefaultFutureListeners) listeners).add(listener); &amp;#125; else &amp;#123; listeners = new DefaultFutureListeners((GenericFutureListener&lt;? extends Future&lt;V>>) listeners, listener); &amp;#125; &amp;#125; private void notifyListeners() &amp;#123; EventExecutor executor = executor(); if (executor.inEventLoop()) &amp;#123; final InternalThreadLocalMap threadLocals = InternalThreadLocalMap.get(); final int stackDepth = threadLocals.futureListenerStackDepth(); if (stackDepth &lt; MAX_LISTENER_STACK_DEPTH) &amp;#123; threadLocals.setFutureListenerStackDepth(stackDepth + 1); try &amp;#123; notifyListenersNow(); &amp;#125; finally &amp;#123; threadLocals.setFutureListenerStackDepth(stackDepth); &amp;#125; return; &amp;#125; &amp;#125; safeExecute(executor, new Runnable() &amp;#123; @Override public void run() &amp;#123; notifyListenersNow(); &amp;#125; &amp;#125;); &amp;#125; private static void safeExecute(EventExecutor executor, Runnable task) &amp;#123; try &amp;#123; executor.execute(task); &amp;#125; catch (Throwable t) &amp;#123; rejectedExecutionLogger.error(\"Failed to submit a listener notification task. Event loop shut down?\", t); &amp;#125; &amp;#125; 他会判断异步任务执行的状态, 如果执行完成, 就立即通知监听者, 否则加入到 监听者队列, 通知监听者就是找一个线程来执行调用监听的回调函数, 再来看监听者的接口, 就一个方法, 即等异步任务执行完成后, 拿到Future 结果, 执行回调的逻辑. public interface GenericFutureListener&lt;F extends Future&lt;?>> extends EventListener &amp;#123; /** * Invoked when the operation associated with the &amp;#123;@link Future&amp;#125; has been completed. * * @param future the source &amp;#123;@link Future&amp;#125; which called this callback */ void operationComplete(F future) throws Exception; &amp;#125;","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Netty大动脉Pipeline(10)","slug":"Netty/Netty大动脉Pipeline(10)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/netty-da-dong-mai-pipeline-10/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/netty-da-dong-mai-pipeline-10/","excerpt":"","text":"Netty 大动脉Pileline1. Pepeline 设计原理1.1 Channel 与 ChannelPipeline相信大家已经知道了, 在Netty中每个Channel 都有且仅有一个ChannelPipeline 与之对应, 他们的组成关系如下: 通过上图我们可以看到, 一个Cannel 包含了一个ChannelPipeline,而ChanelPipeline 中又维护了一个由ChannelHandlerContext 组成的双向链表, 这个链表的头是HeadContext, 链表的尾是 TailContext, 并且每个ChannelHandlerContext 中又关联着一个ChannelHandler. 上面的图示给了我们一个对 ChannelPipeline 的直观认识, 但是实际上Netty 实现的 Channel 是否真是这样的呢? 我们继续用源码来说话, 在前我们已经知道了一个Channel 的初始化的基本过程. 下面我们再回顾一下, 下面的代码 AbstractChannel构造器: protected AbstractChannel(Channel parent) &amp;#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline(); &amp;#125; AbstractChannel 有一个pipeline 字段, 在构造器中会初始化它为DefaultChannelPipeline的实例, 这里的代码就印证了一点: 每个Channel 都有一个 ChannelPipeline. 接着我们追踪一下 DefaultChannelPipeline的初始化过程. 首先进入到 DefaultChannelPipeline 构造器中 protected DefaultChannelPipeline(Channel channel) &amp;#123; this.channel = ObjectUtil.checkNotNull(channel, \"channel\"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head; &amp;#125; 在 DefaultChannelPipeline构造器中, 首先将与之关联的 Channel 保存到 字段 chanel 中, 然后实例化两个 ChannelHandlerContext：一个是HeadContext 的实例head, 另一个 TailContext 实例tail.接着将head和tail 互相指向,构成一个双向链表. 特别注意点是: 我们在开始的示意图中head和tail 并没有包含ChannelHandler, 这里因为 tail 并没有包含 ChannelHandler，这是因为 HeadContext 和 TailContext继承于 AbstractChannelHandlerContext 的同时也实现了 ChannelHandler 接口了，因此它们有 Context 和 Handler的双重属性。 1.2 再谈ChannelPileline 的初始化前面我们已经对ChannelPipeline 的初始化有了一个大致的了解, 不过当时重点没有关注ChannelPipeline,因为没有深入的分析它的初始化过程。 那么下面我们就来看一下具体的ChannelPipeline 的初始化都做了哪些工作吧. 先回顾一下, 在实例化一个Channel 时,会伴随着一个ChannelPipeline 的实例化, 并且次Channel 会与这个ChannelPipeline 相互关联, 这一点可以通过 NioSocketChannel 的父类 AbstractChannel的构造器予以佐证 protected AbstractChannel(Channel parent) &amp;#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline(); &amp;#125; 当实例化一个NioSocketChannel 时, 其pipeline 字段就是我们创建的 DefaultChannelPipeline 对象, 那么我们就来看一下 DefaultChannelPipeline的构造方法 protected DefaultChannelPipeline(Channel channel) &amp;#123; this.channel = ObjectUtil.checkNotNull(channel, \"channel\"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head; &amp;#125; 可以看到, 在 DefaultChannelPipeline 的构造方法中，将传入的channel 赋值给字段 this.channel, 接着又实例化了两个特殊的字段, tail与head.这两个字段是一个双向链表的头和尾. 其实在DefaultChannelPipeline 中, 维护了一个以 AbstractChannelHandlerContext 为节点的双向链表, 这个链表是Netty 实现Pipeline 机制的关键, 再回顾一下 head和tail 的类层次结构: 从类层次结构图中可以很清楚的看到, head 实现了 ChannelInboundHandler，而tail实现了ChannelOutboundHandler 接口, 并且他们都实现了 ChannelHandlerContext接口, 因此可以说head和tail 即是一个 ChannelHandler，又是一个ChannelHandlerContext. 接着看 HeadContext 构造器的代码 HeadContext(DefaultChannelPipeline pipeline) &amp;#123; super(pipeline, null, HEAD_NAME, false, true); unsafe = pipeline.channel().unsafe(); setAddComplete(); &amp;#125; 它调用了 父类 AbstractChannelHandlerContext 的构造器, 并传入参数 inbound = false，outbound = true。 而TailContext 的构造器与HeadContext 正好相反 ， 它调用了父类 AbstractChannelHandlerContext的构造器, 并传入参数 inbound = true，outbound = false。 也就是说 header 是一个 OutBoundHandler，而tail是一个 InboundHandler， 关于这一点, 大家要特别注意， 因为在后面的分析中, 我们会反复用到 inbound 和 outbound 这两个属性。 1.3 ChannelInitializer的添加前面我们已经分析过了Channel 的组成, 其中我们已经了解过了, 最开始的时候 ChannelPipeline 中含有两个 ChannelHandlerContext（同时也是ChannelHandler),但是这个Pipeline 并不能实现什么特殊的功能, 因为我们还没有给它添加自定义的Channel, 通常来说, 我们在初始化Bootstrap 的时候, 会添加自定义的 ChannelHandler, 就以我们具体的客户端启动代码来举例 Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .handler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); pipeline.addLast(new ChatClientHandler(nickName)); &amp;#125; &amp;#125;); 上面代码的初始化过程， 相信大家都不陌生, 在调用handler时， 传入了ChannelInitializer 对象，它提供了一个initChannel 方法给我们初始化 ChannelHandler, 那么这个初始化过程是怎样的呢? 下面我们来揭开它的神秘面纱, ChannelInitializer 实现了 ChannelHandler，那么它是在什么时候添加到ChannelPipeline 中的呢? 通过代码追踪,我们发现他是在Bootstrap 的init() 方法中添加到ChannelPipeline 中的, 其代码如下： @Override @SuppressWarnings(\"unchecked\") void init(Channel channel) throws Exception &amp;#123; ChannelPipeline p = channel.pipeline(); p.addLast(config.handler()); final Map&lt;ChannelOption&lt;?>, Object> options = options0(); synchronized (options) &amp;#123; for (Entry&lt;ChannelOption&lt;?>, Object> e: options.entrySet()) &amp;#123; try &amp;#123; if (!channel.config().setOption((ChannelOption&lt;Object>) e.getKey(), e.getValue())) &amp;#123; logger.warn(\"Unknown channel option: \" + e); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Failed to set a channel option: \" + channel, t); &amp;#125; &amp;#125; &amp;#125; final Map&lt;AttributeKey&lt;?>, Object> attrs = attrs0(); synchronized (attrs) &amp;#123; for (Entry&lt;AttributeKey&lt;?>, Object> e: attrs.entrySet()) &amp;#123; channel.attr((AttributeKey&lt;Object>) e.getKey()).set(e.getValue()); &amp;#125; &amp;#125; &amp;#125; 从上面的代码来看, 将handler() 返回的 ChannelHandler 添加到 Pipeline 中, 而 handler() 返回的其实就是我们在初始化Bootstrap 时通过 handler() 方法设置的 ChannelInitializer 实例, 因为这里就是将 ChannelInitializer 插入到了 Pipeline 的末端, 此时Pipeline 的结构如下图所示： 这时候,有的小伙伴可能就有疑惑了, 我明明插入的是一个 ChannelInitializer 实例, 为什么在 ChannelPipeline 中的双向链表中的元素却是ChannelHandlerContext 呢? 我们继续去源码中寻找答案. 刚才, 我们提到, 在Bootstrap 的init() 方法中会调用p.addLast() 方法,将ChannelInitializer 插入到链表的末端. @Override public final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) &amp;#123; final AbstractChannelHandlerContext newCtx; synchronized (this) &amp;#123; checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) &amp;#123; newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; &amp;#125; EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) &amp;#123; newCtx.setAddPending(); executor.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; callHandlerAdded0(newCtx); &amp;#125; &amp;#125;); return this; &amp;#125; &amp;#125; callHandlerAdded0(newCtx); return this; &amp;#125; private AbstractChannelHandlerContext newContext(EventExecutorGroup group, String name, ChannelHandler handler) &amp;#123; return new DefaultChannelHandlerContext(this, childExecutor(group), name, handler); &amp;#125; addLast() 有很多重载的方法,我们只需要关心这个重要的方法就行. 上面的addLast() 方法中, 首先检查 Channelhandler 的名字是否重复, 如果不重复, 则调用 newContext() 方法为这个Handler 创建一个对应的 DefaultChannelHandlerContext 实例. 并与之关联起来(Contxt 中有一个handler 属性保存着对应的handler 实例). 为了添加一个 handler 到pipeline 中, 必须把此 handler 包装成 ChannelHandlerContext。因此在上面的代码中我们看到新实例化了一个 newCtx 对象,并将handler 作为参数传递到构造方法中,。 那么我们来看一下实例化 DefaultChannelHandlerContext 到底有什么玄机吧, 首先来看一下他的构造器. DefaultChannelHandlerContext( DefaultChannelPipeline pipeline, EventExecutor executor, String name, ChannelHandler handler) &amp;#123; super(pipeline, executor, name, isInbound(handler), isOutbound(handler)); if (handler == null) &amp;#123; throw new NullPointerException(\"handler\"); &amp;#125; this.handler = handler; &amp;#125; 在 DefaultChannelHandlerContext 的构造器中, 调用了两个很有意思的方法, isInbound()与 isOutbound()，这两个方法是做什么呢? private static boolean isInbound(ChannelHandler handler) &amp;#123; return handler instanceof ChannelInboundHandler; &amp;#125; private static boolean isOutbound(ChannelHandler handler) &amp;#123; return handler instanceof ChannelOutboundHandler; &amp;#125; 从源码中可以看到, 当一个hanler 实现了 ChannelInboundHandler 接口, 则 isInbound 返回true,类似的当一个 handler 实现了 ChannelOutboundHandler 接口, 则 isOutbound 就返回true. 而这两个 boolean 变量会传递到父类 AbstractChannelHandlerContext 中, 并初始化父类的这两个字段：inbound 与 outbound。 那么这里的 ChannelInitializer 所对应的 的DefaultChannelHandlerContext的inbound与inbound字段分别是什么呢? 那就看一下 ChannelInitializer 到底实现了哪个接口不就行了? 如下是 ChannelInitializer 的类结构图 从类图中可以清楚的看到, ChannelInitializer 仅仅实现了 ChannelInboundHandler 接口，因此这里实例化的 DefaultChannelHandlerContext 的 inbound = true，outbound = false。 兜了这么大一圈, 不就是 是 inbound 和 outbound 两个字段嘛， 为什么需要这么大费周折的去分析一番? 其实这两个字段关系到 pipeline 的事件的流向和分类, 因为是十分关键的. 至此, 我们 先记住一个结论. ChannelInitializer 所对应的 DefaultChannelHandlerContext 的 inbound = true，outbound = false。 当创建好 Context 之后, 就将这个Context 插入到 Pipeline的双向链表中, private void addLast0(AbstractChannelHandlerContext newCtx) &amp;#123; AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx; &amp;#125; 1.4 自定义ChannelHandler 的添加过程前面我们已经分析过 ChannelInitializer 是如何添加到Pipeline 中的, 接下来就来探究 ChannelInitializer 在哪里被调用? ChannelInitializer 的作用以及我们自定义的ChannelInitializer 是如何插入到Pipeline 中的. 先简单来复习一下 Channel 的注册过程: 首先在AbstractBootstrap 的 initAndRegister() 中, 通过group().register(channel) , 调用 MultithreadEventLoopGroup 的 register() 方法. 在 MultithreadEventLoopGroup 的register() 中调用 next() 获取一个可用的 SingleThreadEventLoop，然后调用他的 register() 方法. 在 SingleThreadEventLoop 的 register() 方法中, 通过 channel.unsafe().register(this.promise) 方法获取channel 的 unsafe 底层的IO操作对象, 然后调用它的 register() 方法. 在 AbstractUnsafe 的register() 方法中, 调用 register0() 方法注册channel 对象 在AbstractUnsafe的 register0() 方法中, 调用 AbstractNioChannel 的doRegister() 方法. AbstractNioChannel 的 doRegister()方法调用 javaChannel().register(eventLoop().selector, 0, this)将 Channel对应的 Java NIO 的 SockerChannel 对象注册到一个 eventLoop 的 Selector 中，并且将当前 Channel 作为 attachment。 而我们自定义的ChannelHandler 的添加过程, 发生在 AbstractUnsafe的 register0() 方法中, 在这个方法中调用了 pipeline.fireChannelRegistered()方法, 其代码实现如下： @Override public final ChannelPipeline fireChannelRegistered() &amp;#123; AbstractChannelHandlerContext.invokeChannelRegistered(head); return this; &amp;#125; 再看 AbstractChannelHandlerContext.invokeChannelRegistered(head); 方法: static void invokeChannelRegistered(final AbstractChannelHandlerContext next) &amp;#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &amp;#123; next.invokeChannelRegistered(); &amp;#125; else &amp;#123; executor.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; next.invokeChannelRegistered(); &amp;#125; &amp;#125;); &amp;#125; &amp;#125; 很显然, 这个代码会从head开始遍历Pipeline 的双向链表, 然后找到第一个属性 为 true 的ChannelHandlerContext 实例. 想起来没, 我们在前面分析 ChannelInitializer 时， 花费了大量的篇幅来分析了inbound和 outbound 属性 , 现在这里就用上了. 回想一下, ChannelInitializer 实现了 ChannelInboudHandler ,因此他对应的 ChannelHandlerContext 的inbound 属性就是true. 因此这里返回的就是 ChannelInitializer 实例所对应的 ChannelHandlerContext 对象. 如下图所示： 当获取到 inbound 的Context时，就调用它的 invokeChannelRegistered() private void invokeChannelRegistered() &amp;#123; if (invokeHandler()) &amp;#123; try &amp;#123; ((ChannelInboundHandler) handler()).channelRegistered(this); &amp;#125; catch (Throwable t) &amp;#123; notifyHandlerException(t); &amp;#125; &amp;#125; else &amp;#123; fireChannelRegistered(); &amp;#125; &amp;#125; 我们已经知道, 每个ChannelHandler 都和一个ChannelHandlerContext 相关联.我们可以通过ChannelHandlerContext 获取到对应的ChannelHandler.因此很明显, 这里的handler() 发那会的对象其实就是一开始我们就实例化的 ChannelInitializer 对象, 并接着调用了 ChannelInitializer 的 channelRegistered() 方法. 看到这里, 应该就会觉得眼熟了. ChannelInitializer 的 channelRegistered()这个方法我们一开始就已经接触到了, 但是我么么并没有深入的分析这个方法的调用过程, 下来我们俩看看这个方法中到底有什么玄机？ 继续看代码: @Override @SuppressWarnings(\"unchecked\") public final void channelRegistered(ChannelHandlerContext ctx) throws Exception &amp;#123; // Normally this method will never be called as handlerAdded(...) should call initChannel(...) and remove // the handler. if (initChannel(ctx)) &amp;#123; // we called initChannel(...) so we need to call now pipeline.fireChannelRegistered() to ensure we not // miss an event. ctx.pipeline().fireChannelRegistered(); &amp;#125; else &amp;#123; // Called initChannel(...) before which is the expected behavior, so just forward the event. ctx.fireChannelRegistered(); &amp;#125; &amp;#125; @SuppressWarnings(\"unchecked\") private boolean initChannel(ChannelHandlerContext ctx) throws Exception &amp;#123; if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) &amp;#123; // Guard against re-entrance. try &amp;#123; initChannel((C) ctx.channel()); &amp;#125; catch (Throwable cause) &amp;#123; // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...). // We do so to prevent multiple calls to initChannel(...). exceptionCaught(ctx, cause); &amp;#125; finally &amp;#123; remove(ctx); &amp;#125; return true; &amp;#125; return false; &amp;#125; initChannel((C) ctx.channel()) 这个方法我们也很熟悉, 他就是在我们初始化Bootstrap 的时候, 调用handler 方法传入的匿名内部类所实现的方法: .handler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); pipeline.addLast(new ChatClientHandler(nickName)); &amp;#125; 当调用这个方法后,我们自定义的ChannelHandler 就插入到Pipeline中了, 此时Pipeline 的状态如下图所示： 当添加完自定义的ChannelHandler 后, 在 finally 代码块中就会删除自定义的 ChannelInitializer，也就是 remove(ctx); 最终调用 ctx.pipeline.remove(this); 因此最后的Pipeline 的状态如下: 至此, 自定义的ChannelHandler 的添加过程就分析的差不多了. 1.5. 给ChannelHandler 命令不知道大家注意到没, pipeline.addXXX 都有一个重载的方法, 例如 addLast() 它有一个重载的版本是: ChannelPipeline addLast(String name, ChannelHandler handler); 第一个参数指定添加的 handler 的名字,(更加准确的是ChannelHandlerContext的名字),那么handler的名字有什么用呢? 如果我们不设置name, 那么handler默认的名字是怎样的呢? 带着这些疑问? 我们依旧去源代码去找答案, 还是以addLast() 方法为例. @Override public final ChannelPipeline addFirst(String name, ChannelHandler handler) &amp;#123; return addFirst(null, name, handler); &amp;#125; 这个方法会调用重载的 addLast() 方法 @Override public final ChannelPipeline addFirst(EventExecutorGroup group, String name, ChannelHandler handler) &amp;#123; final AbstractChannelHandlerContext newCtx; synchronized (this) &amp;#123; checkMultiplicity(handler); name = filterName(name, handler); newCtx = newContext(group, name, handler); addFirst0(newCtx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) &amp;#123; newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; &amp;#125; EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) &amp;#123; newCtx.setAddPending(); executor.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; callHandlerAdded0(newCtx); &amp;#125; &amp;#125;); return this; &amp;#125; &amp;#125; callHandlerAdded0(newCtx); return this; &amp;#125; 第一个参数被设置为null, 我们不需要去关心它, 第二个参数就是这个handler的名字, 看代码可知, 在添加一个handler之前, 需要调用 checkMultiplicity(handler) 方法来确定新添加的handler 名字是否与已经添加的handler 的名字重复. 1.6 ChannelHandler 默认命名规则如果我们调用的是如下的addLast() 方法 ChannelPipeline addLast(ChannelHandler... handlers); 那么Netty 就会调用 private String filterName(String name, ChannelHandler handler) &amp;#123; if (name == null) &amp;#123; return generateName(handler); &amp;#125; checkDuplicateName(name); return name; &amp;#125; private String generateName(ChannelHandler handler) &amp;#123; Map&lt;Class&lt;?>, String> cache = nameCaches.get(); Class&lt;?> handlerType = handler.getClass(); String name = cache.get(handlerType); if (name == null) &amp;#123; name = generateName0(handlerType); cache.put(handlerType, name); &amp;#125; // It's not very likely for a user to put more than one handler of the same type, but make sure to avoid // any name conflicts. Note that we don't cache the names generated here. if (context0(name) != null) &amp;#123; String baseName = name.substring(0, name.length() - 1); // Strip the trailing '0'. for (int i = 1;; i ++) &amp;#123; String newName = baseName + i; if (context0(newName) == null) &amp;#123; name = newName; break; &amp;#125; &amp;#125; &amp;#125; return name; &amp;#125; 而 generateName() 方法会接着调用 generateName0() 方法来实际生成一个新的handler 名字: private static String generateName0(Class&lt;?> handlerType) &amp;#123; return StringUtil.simpleClassName(handlerType) + \"#0\"; &amp;#125; 默认的命名规则很简单, 就是反射获取handler 的simpleClassName 加上 “#0”, 因为我们的自定义ChatClientHandler 的名字就是 “ChatClientHandler#0” 2. Pipeline 的事件传播机制我们已经知道 AbstractChannelHandlerContext 中有 inbound 和 outbound 两个 boolean 变量,分别用于标识 Context 所对应的handler 类型, 即: inbound 为true时表示其对应的 ChannelHandler 是 ChannelInboundHandler的子类. outbound 为true时，表示对应的ChannelHandler 是 ChannelOutboundHandler 的子类. 这里大家肯定还有很多疑惑 , 不知道这两个字段到底有什么用? 这还要从ChannelPipeline 的事件传播机制说起， Netty 的事件传播机制可以分为两种: inbound 事件和outbound 事件, 如下是从Netty 对这两个事件的说明;‘ * &lt;pre> * I/O Request * via &amp;#123;@link Channel&amp;#125; or * &amp;#123;@link ChannelHandlerContext&amp;#125; * | * +---------------------------------------------------+---------------+ * | ChannelPipeline | | * | \\|/ | * | +---------------------+ +-----------+----------+ | * | | Inbound Handler N | | Outbound Handler 1 | | * | +----------+----------+ +-----------+----------+ | * | /|\\ | | * | | \\|/ | * | +----------+----------+ +-----------+----------+ | * | | Inbound Handler N-1 | | Outbound Handler 2 | | * | +----------+----------+ +-----------+----------+ | * | /|\\ . | * | . . | * | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()| * | [ method call] [method call] | * | . . | * | . \\|/ | * | +----------+----------+ +-----------+----------+ | * | | Inbound Handler 2 | | Outbound Handler M-1 | | * | +----------+----------+ +-----------+----------+ | * | /|\\ | | * | | \\|/ | * | +----------+----------+ +-----------+----------+ | * | | Inbound Handler 1 | | Outbound Handler M | | * | +----------+----------+ +-----------+----------+ | * | /|\\ | | * +---------------+-----------------------------------+---------------+ * | \\|/ * +---------------+-----------------------------------+---------------+ * | | | | * | [ Socket.read() ] [ Socket.write() ] | * | | * | Netty Internal I/O Threads (Transport Implementation) | * +-------------------------------------------------------------------+ 从上图可以看出, inbound 事件和outbound 事件 的流向是不一样的, inbound 事件的流行是从下往上的, 而 outbound 刚好相反, 是从上到下的. 并且 inbound 的传递方式是通过调用相应的ChannelHandlerContext.fireIN_EVT()方法，而 outbound 方法的传递方式是调用 ChannelHandlerContext.OUT_EVT()方法。例如：ChannelHandlerContext的 fireChannelRegistered()调用会发送一个 ChannelRegistered 的 inbound 给下一个 ChannelHandlerContext，而ChannelHandlerContext 的 bind()方法调用时会发送一个 bind 的 outbound 事件给下一个 ChannelHandlerContext inbound 事件传播的方法有： public interface ChannelInboundHandler extends ChannelHandler &amp;#123; /** * The &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelHandlerContext&amp;#125; was registered with its &amp;#123;@link EventLoop&amp;#125; */ void channelRegistered(ChannelHandlerContext ctx) throws Exception; /** * The &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelHandlerContext&amp;#125; was unregistered from its &amp;#123;@link EventLoop&amp;#125; */ void channelUnregistered(ChannelHandlerContext ctx) throws Exception; /** * The &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelHandlerContext&amp;#125; is now active */ void channelActive(ChannelHandlerContext ctx) throws Exception; /** * The &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelHandlerContext&amp;#125; was registered is now inactive and reached its * end of lifetime. */ void channelInactive(ChannelHandlerContext ctx) throws Exception; /** * Invoked when the current &amp;#123;@link Channel&amp;#125; has read a message from the peer. */ void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception; /** * Invoked when the last message read by the current read operation has been consumed by * &amp;#123;@link #channelRead(ChannelHandlerContext, Object)&amp;#125;. If &amp;#123;@link ChannelOption#AUTO_READ&amp;#125; is off, no further * attempt to read an inbound data from the current &amp;#123;@link Channel&amp;#125; will be made until * &amp;#123;@link ChannelHandlerContext#read()&amp;#125; is called. */ void channelReadComplete(ChannelHandlerContext ctx) throws Exception; /** * Gets called if an user event was triggered. */ void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception; /** * Gets called once the writable state of a &amp;#123;@link Channel&amp;#125; changed. You can check the state with * &amp;#123;@link Channel#isWritable()&amp;#125;. */ void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception; /** * Gets called if a &amp;#123;@link Throwable&amp;#125; was thrown. */ @Override @SuppressWarnings(\"deprecation\") void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception; &amp;#125; outbound 事件传播方法有： public interface ChannelOutboundHandler extends ChannelHandler &amp;#123; /** * Called once a bind operation is made. * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; for which the bind operation is made * @param localAddress the &amp;#123;@link SocketAddress&amp;#125; to which it should bound * @param promise the &amp;#123;@link ChannelPromise&amp;#125; to notify once the operation completes * @throws Exception thrown if an error accour */ void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception; /** * Called once a connect operation is made. * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; for which the connect operation is made * @param remoteAddress the &amp;#123;@link SocketAddress&amp;#125; to which it should connect * @param localAddress the &amp;#123;@link SocketAddress&amp;#125; which is used as source on connect * @param promise the &amp;#123;@link ChannelPromise&amp;#125; to notify once the operation completes * @throws Exception thrown if an error accour */ void connect( ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception; /** * Called once a disconnect operation is made. * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; for which the disconnect operation is made * @param promise the &amp;#123;@link ChannelPromise&amp;#125; to notify once the operation completes * @throws Exception thrown if an error accour */ void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception; /** * Called once a close operation is made. * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; for which the close operation is made * @param promise the &amp;#123;@link ChannelPromise&amp;#125; to notify once the operation completes * @throws Exception thrown if an error accour */ void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception; /** * Called once a deregister operation is made from the current registered &amp;#123;@link EventLoop&amp;#125;. * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; for which the close operation is made * @param promise the &amp;#123;@link ChannelPromise&amp;#125; to notify once the operation completes * @throws Exception thrown if an error accour */ void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception; /** * Intercepts &amp;#123;@link ChannelHandlerContext#read()&amp;#125;. */ void read(ChannelHandlerContext ctx) throws Exception; /** * Called once a write operation is made. The write operation will write the messages through the * &amp;#123;@link ChannelPipeline&amp;#125;. Those are then ready to be flushed to the actual &amp;#123;@link Channel&amp;#125; once * &amp;#123;@link Channel#flush()&amp;#125; is called * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; for which the write operation is made * @param msg the message to write * @param promise the &amp;#123;@link ChannelPromise&amp;#125; to notify once the operation completes * @throws Exception thrown if an error accour */ void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception; /** * Called once a flush operation is made. The flush operation will try to flush out all previous written messages * that are pending. * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; for which the flush operation is made * @throws Exception thrown if an error accour */ void flush(ChannelHandlerContext ctx) throws Exception; &amp;#125; 大家应该发现了规律, inbound 类似于的事件回调(响应请求的事件),而outbound 类似于主动触发(发起请求的事件) . 注意,如果我们捕获了一个事件, 并想让这个事件继续传递下去, 那么需要调用Context 对应的传播方法 fireXX, public class MyInboundHandler extends ChannelInboundHandlerAdapter &amp;#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &amp;#123; System.out.println(\"连接成功\"); ctx.fireChannelActive(); &amp;#125; &amp;#125; 如上面的代码, MyInboundHandler 收到了一个 channelActive 事件, 他在处理完成后, 如果希望将事件继续传播下去, 那么需要接着调用 ctx.fireChannelActive();方法. 2.1 Outbound 事件传播方式outbound 事件都是请求事件(request event), 即请求某些事件的发生, 然后通过Outbound 事件进行通知, outbound 事件的传播方向是: tail -&gt;customContext -&gt;head. 我们接下来以 connect事件为例, 分析一下 Outbound 事件的传播机制。 首先, 当用户调用了 Bootstrap 的 connect() 方法时, 就会触发一个Connect 请求事件, 此调用会出发如下调用链: 继续追踪, 我们就会发现 AbstractChannel的connect() 其实调用了 DefaultChannelPipeline 的connect() 方法 @Override public ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) &amp;#123; return pipeline.connect(remoteAddress, localAddress, promise); &amp;#125; 而 pipeline.connect(remoteAddress, localAddress, promise） 方法的实现如下： @Override public final ChannelFuture connect( SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) &amp;#123; return tail.connect(remoteAddress, localAddress, promise); &amp;#125; 可以看到, 当outbound(这里是 connect事件) 传递到Pipeline 后, 它其实是以tail 为起点开始传播的. 而 tail.connect 其实调用的是 AbstractChannelHandlerContext 的 connect()方法： @Override public ChannelFuture connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) &amp;#123; if (remoteAddress == null) &amp;#123; throw new NullPointerException(\"remoteAddress\"); &amp;#125; if (!validatePromise(promise, false)) &amp;#123; // cancelled return promise; &amp;#125; final AbstractChannelHandlerContext next = findContextOutbound(); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &amp;#123; next.invokeConnect(remoteAddress, localAddress, promise); &amp;#125; else &amp;#123; safeExecute(executor, new Runnable() &amp;#123; @Override public void run() &amp;#123; next.invokeConnect(remoteAddress, localAddress, promise); &amp;#125; &amp;#125;, promise, null); &amp;#125; return promise; &amp;#125; findContextOutbound() 方法顾名思义, 他的作用是以当前Context 为起点, 想Pipeline 中的Context 双向链表的前端寻找第一个 outbound 属性为true 的Context(即关联ChannelOutboundHandler的Context), 然后返回. findContextOutbound 的方法的代码如下: private AbstractChannelHandlerContext findContextOutbound() &amp;#123; AbstractChannelHandlerContext ctx = this; do &amp;#123; ctx = ctx.prev; &amp;#125; while (!ctx.outbound); return ctx; &amp;#125; 当我们找到一个 outbound 的Context后， 就调用它的 invokeConnect() 方法, 这个方法中会调用Context 其关联的ChannelHandler 的connect() 方法: private void invokeConnect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) &amp;#123; if (invokeHandler()) &amp;#123; try &amp;#123; ((ChannelOutboundHandler) handler()).connect(this, remoteAddress, localAddress, promise); &amp;#125; catch (Throwable t) &amp;#123; notifyOutboundHandlerException(t, promise); &amp;#125; &amp;#125; else &amp;#123; connect(remoteAddress, localAddress, promise); &amp;#125; &amp;#125; 如果用户没有重写 ChannelHandler 的 connect() 方法, 那么就会调用 ChannelOutboundHandlerAdapter 的 connect()实现： @Override public void connect(ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception &amp;#123; ctx.connect(remoteAddress, localAddress, promise); &amp;#125; 我们看到， ChannelOutboundHandlerAdapter 的connect() 仅仅调用了 ctx.connect , 而这个又调回到了Context.connect -&gt; Connect.findContextOutbound -&gt; next.invokeConnect -&gt; handler.connect -&gt; Context.connect这样的循环中，直到connect() 事件传递到了 DefaultChannelPipeline 的双向链表的头节点, 即head中,为什么会传递到head中呢? 回想一下, head实现了 ChannelOutboundHandler，因此它的outbound 的属性是true 因为head本身即是一个 ChannelHandlerContext，又实现了ChannelOutboundHandler 接口, 因此当 connect() 消息传递到head后, 会将消息转传递到对应的ChannelHandler 中处理, 而head的 handler() 方法返回的就是head本身. @Override public ChannelHandler handler() &amp;#123; return this; &amp;#125; 因此 最终 connect() 事件是在head中被处理的, head的 connect() 事件处理逻辑如下: @Override public void connect( ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception &amp;#123; unsafe.connect(remoteAddress, localAddress, promise); &amp;#125; 到这里, 整个connect() 请求事件就结束了, 下图中描述了整个 connect() 请求事件的处理过程. 我们仅仅以 connect() 请求事件为例, 分析了 outbound 事件的传播过程, 但是其实所有的 outbound 事件的传播都遵循一样的传播规律, 2.2 inbound 事件传播方式inbound 事件和 outbound 事件的处理过程是类似的, 只不过传播方向不同. inbound 事件是一个通知事件,即某事件已经发生了, 然后通过inbound 事件进行通知， inbound 通常发生在Channel 的状态的改变或者IO事件就绪. inboud 的特点是它的传播方向 是 head -&gt; customContext -&gt; tail。 上面我们分析了 connect() 这个outbound 事件, 那么接着分析 connect() 事件后会发生什么 inbound 事件, 并最终找到 inbound 和outbound 事件的联系. 当 connect() 这个outbound 传播到 unsafe 后, 其实是在 AbstractNioUnsafe 的connect() 方法中进行处理的. @Override public final void connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) &amp;#123; if (!promise.setUncancellable() || !ensureOpen(promise)) &amp;#123; return; &amp;#125; try &amp;#123; if (connectPromise != null) &amp;#123; // Already a connect in process. throw new ConnectionPendingException(); &amp;#125; boolean wasActive = isActive(); if (doConnect(remoteAddress, localAddress)) &amp;#123; fulfillConnectPromise(promise, wasActive); &amp;#125; else &amp;#123; connectPromise = promise; requestedRemoteAddress = remoteAddress; // Schedule connect timeout. int connectTimeoutMillis = config().getConnectTimeoutMillis(); if (connectTimeoutMillis > 0) &amp;#123; connectTimeoutFuture = eventLoop().schedule(new Runnable() &amp;#123; @Override public void run() &amp;#123; ChannelPromise connectPromise = AbstractNioChannel.this.connectPromise; ConnectTimeoutException cause = new ConnectTimeoutException(\"connection timed out: \" + remoteAddress); if (connectPromise != null &amp;&amp; connectPromise.tryFailure(cause)) &amp;#123; close(voidPromise()); &amp;#125; &amp;#125; &amp;#125;, connectTimeoutMillis, TimeUnit.MILLISECONDS); &amp;#125; promise.addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; if (future.isCancelled()) &amp;#123; if (connectTimeoutFuture != null) &amp;#123; connectTimeoutFuture.cancel(false); &amp;#125; connectPromise = null; close(voidPromise()); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; promise.tryFailure(annotateConnectException(t, remoteAddress)); closeIfClosed(); &amp;#125; &amp;#125; 在 AbstractNioUnsafe 的 connect() 方法中, 首先调用doConnect() 方法进行实际上的Socket连接, 当连接上后会调用 fulfillConnectPromise() 方法 private void fulfillConnectPromise(ChannelPromise promise, boolean wasActive) &amp;#123; if (promise == null) &amp;#123; // Closed via cancellation and the promise has been notified already. return; &amp;#125; // Get the state as trySuccess() may trigger an ChannelFutureListener that will close the Channel. // We still need to ensure we call fireChannelActive() in this case. boolean active = isActive(); // trySuccess() will return false if a user cancelled the connection attempt. boolean promiseSet = promise.trySuccess(); // Regardless if the connection attempt was cancelled, channelActive() event should be triggered, // because what happened is what happened. if (!wasActive &amp;&amp; active) &amp;#123; pipeline().fireChannelActive(); &amp;#125; // If a user cancelled the connection attempt, close the channel, which is followed by channelInactive(). if (!promiseSet) &amp;#123; close(voidPromise()); &amp;#125; &amp;#125; 我们看到,在fulfillConnectPromise() 中, 会通过调用 pipeline().fireChannelActive() 方法将通道激活的消息(即Socket 连接成功) 发送出去, 而这里, 当调用 pipeline.fireXXX 后, 就是 inbound 事件的起点, 因此当调用 pipeline().fireChannelActive(); 后， 就产生了一个 ChannelActive inbound 事件, 我们就从这里看这个 inbound 事件是怎么传播的? @Override public final ChannelPipeline fireChannelActive() &amp;#123; AbstractChannelHandlerContext.invokeChannelActive(head); return this; &amp;#125; 果然在 fireChannelActive 方法中, 调用的是 head.invokeChannelActive() , 因此可以证明 inbound 事件在Pipeline 中的传输的起点是 head,那么在 head.invokeChannelActive() 中又做了什么呢? static void invokeChannelActive(final AbstractChannelHandlerContext next) &amp;#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &amp;#123; next.invokeChannelActive(); &amp;#125; else &amp;#123; executor.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; next.invokeChannelActive(); &amp;#125; &amp;#125;); &amp;#125; &amp;#125; 上面的代码应该很熟悉了, 回想一下, 在outbound 事件(例如connect() 事假 )的传输过程 中, 我们也有类似的操作. 首先调用 findContextInbound() , 从Pipeline 的双向链表中找到第一个属性inbound 为true 的Context, 然后将其返回. 调用Context的invokeChannelActive() 方法, invokeChannelActive 方法的源码如下： private void invokeChannelActive() &amp;#123; if (invokeHandler()) &amp;#123; try &amp;#123; ((ChannelInboundHandler) handler()).channelActive(this); &amp;#125; catch (Throwable t) &amp;#123; notifyHandlerException(t); &amp;#125; &amp;#125; else &amp;#123; fireChannelActive(); &amp;#125; &amp;#125; 这个方法和Outbound 的对应方法(如：invokeConnect()方法) 如出一辙, 与outbound 一样, 如果用户没有重写channelActive() 方法,那么就会调用 ChannelInboundHandlerAdapter 的 channelActive()方法： @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &amp;#123; ctx.fireChannelActive(); &amp;#125; 同样地, 在 ChannelInboundHandlerAdapter 的 channelActive()中，仅仅调用了 ctx.fireChannelActive()方法，因此就会进入 Context.fireChannelActive() -&gt; Connect.findContextInbound() -&gt; nextContext.invokeChannelActive() -&gt;nextHandler.channelActive() -&gt; nextContext.fireChannelActive()这样的循环中。同理，tail 本身既实现了ChannelInboundHandler 接口，又实现了 ChannelHandlerContext 接口，因此当 channelActive()消息传递到 tail 后，会将消息转递到对应的 ChannelHandler 中处理，而 tail 的 handler()返回的就是 tail 本身： @Override public ChannelHandler handler() &amp;#123; return this; &amp;#125; 因此， channelActive 的 inbound 事件最终是在tail 中处理的， 我们看一下他的处理方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &amp;#123; &amp;#125; TailContext 的 channelActive() 方法是空的, 如果大家自行查看 TailContext 的inbound 处理方法的时候就会发现，他们的实现都是空的, 可见, 如果是inbound, 当用户没有实现自定义的处理器时, 那么默认是不处理的. 下图描述了inbound 事件的传输过程. 2.3 Pipeline 事件传播小结outbound 事件总结: OutBound 事件是请求事件(由 connect() 发起一个请求, 并最终由 unsafe 处理这个请求) outbound 事件的发起者是 Channel Outbound 事件的处理者是 unsafe outbound 事件在Pipeline 中的传播方向是 tail -&gt; head. 在ChannelHandler 中处理事件时,如果这个handler 不是最后一个handler, 则需要调用 ctx 的方法(如ctx.connect()) 将此事件继续传播下去. 如果不这样做, 那么此事件的传播就会提前终止. Outbound 事件流：Context.OUT_EVT() -&gt; Connect.findContextOutbound() -&gt; nextContext.invokeOUT_EVT() -&gt; nextHandler.OUT_EVT() -&gt; nextContext.OUT_EVT() inbound 事件总结 inbound 事件是通知事件, 当某件事情已经就绪后, 通知上层. inbound 事件发起者是 unsafe inbound 事件处理者是Channel, 如果没有实现自定义的处理方法, 那么inbound 事件默认的处理者是TailContext, 并且其处理方法是空实现. inbound 事件在 pipeline 中传输方向是head -&gt;tail 在 ChannelHandler 中处理事件时，如果这个 Handler 不是最后一个 Handler，则需要调用 ctx.fireIN_EVT()事件（如：ctx.fireChannelActive()方法）将此事件继续传播下去。如果不这样做，那么此事件的传播会提前终止。 Outbound 事件流：Context.fireIN_EVT() -&gt; Connect.findContextInbound() -&gt; nextContext.invokeIN_EVT() -&gt;nextHandler.IN_EVT() -&gt; nextContext.fireIN_EVT(). outbound 和inbound 事件设计上十分相似, 并且Context 与Handler 直接的调用关系也容易混淆,因此我们在阅读这里的源码时, 需要特别的注意. 3. Handler 的各种姿势1. ChannelHandlerContext每个ChannelHandler 被添加到ChannelPipeline 后,都会创建一个 ChannelHandlerContext 并与之创建的ChannelHandler 关联绑定, ChannelHandlerContext 允许 ChannelHandler 与其他的 ChannelHander 实现进行交互, ChannelHandlerContext 不会改变添加到其中的 ChannelHandler, 因此它是安全的. 下图描述了 ChannelHandlerContext、ChannelHandler、ChannelPipeline 的关系. 2. Channel 的生命周期Netty 有一个简单但很强大的状态模型, 并完美映射到 ChannelInboundHandler 的各个方法上, 下面是Channel 的生命周期中的四个不同的状态. 状态 描述 channelUnregistered() Channel 已创建, 还未注册到一个EventLoop channelRegistered() Channel 已经注册到一个EventLoop channelActive() Channel 是活跃状态(连接到某个远端) 可以收发数据 channelInactive() Channel 未连接到远端 一个Channel 正常的生命周期如下图所示, 随着状态发生变化相应的事件产生, 这些事件被转发到ChannePipeline 中的ChannelHandler 来触发相应的操作. 3. ChannelHandler 常用的API先看一个Netty 中整个Handler 体系的类关系图 Netty 定义了良好的类型层次结构来标识不同的处理程序类型, 所有的类型的父类是ChannelHandler. ChannelHandler 提供了在其生命周期中添加或从ChannelPipeline 中删除的方法. 状态 描述 handlerAdded() ChannelHandler 添加到实际上下文汇中准备处理事件 handlerRemoved() 将ChannelHandler 从实际上下文中删除, 不在处理事件 exceptionCaught() 处理抛出的异常 Netty 还提供了一个实现了ChannelHandler 的抽象类ChannelHandlerAdapter。ChannelHandlerAdapter 实现了父类的所有方法, 基本上就是传递事件到ChannelPipeline 中的下一个ChannelHandler 直到结束. 我们也可以直接继承于ChannelHandlerAdapter ,然后重写里面的方法. 4 ChannelInboundHandlerChannelInboundHandler 提供了一些方法再接受或者Channel 状态改变时被调用, 下面是 ChannelInboundHandler 的一些方法: 状态 描述 channelRegistered() ChannelHandlerContext的Channel被注册到EventLoop channelUnregistered() ChannelHandlerContext的Channel从EventLoop中注销 channelActive() ChannelHandlerContext的Channel已激活 channelInactive ChannelHanderContxt的Channel结束生命周期 channelRead 从当前Channel的对端读取消息 channelReadComplete 消息读取完成后执行 userEventTriggered 一个用户事件被触发 channelWritabilityChanged 改变通道的可写状态，可以使用Channel.isWritable()检查 exceptionCaught 重写父类ChannelHandler的方法，处理异常 Netty 提供了一个实现了 ChannelInboundHandler 接 口 并 继 承 ChannelHandlerAdapter 的 类 ：ChannelInboundHandlerAdapter。ChannelInboundHandlerAdapter 实现了 ChannelInboundHandler 的所有方法，作用就是处理消息并将消息转发到 ChannelPipeline 中的下一个 ChannelHandler。ChannelInboundHandlerAdapter的 channelRead() 方 法 处 理 完 消 息 后 不 会 自 动 释 放 消 息 ， 若 想 自 动 释 放 收 到 的 消 息 ， 可 以 使 用SimpleChannelInboundHandler，看下面的代码： public class UnreleaseHandler extends ChannelInboundHandlerAdapter &amp;#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; //手动释放消息 ReferenceCountUtil.release(msg); &amp;#125; &amp;#125; SimpleChannelInboundHandler 会自动释放消息： public class ReleaseHandler extends SimpleChannelInboundHandler&lt;Object> &amp;#123; @Override protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; //不需要手动释放 &amp;#125; &amp;#125; ChannelInitializer 用来初始化 ChannelHandler，将自定义的各种 ChannelHandler 添加到 ChannelPipeline 中。","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"揭开Bootstrap的神秘面纱(7)","slug":"Netty/揭开Bootstrap的神秘面纱(7)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/jie-kai-bootstrap-de-shen-mi-mian-sha-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/jie-kai-bootstrap-de-shen-mi-mian-sha-7/","excerpt":"","text":"揭开Bootstrap 的神秘面纱1. 客户端Bootstrap1. Channel简介在Netty中,Channel是一个Socket的抽象, 它为用户提升了关于Socket状态(是否是连接还是断开) 以及对Socket的读写等操作, 每当Netty 建立一个连接后， 都创建一个对应的Channel 实例. 除了TCP协议外, Netty 还支持很多的其他的连接协议, 并且每种协议还有NIO(非阻塞IO) 和OLO( Old - io,即传统的IO ）版本的区别. 不同 协议不同的阻塞类型的连接都有不同的Channel 类型与之对应. 下面是一些常见的Channel 类型 类名 解释 NioSocketChannel 异步非阻塞的客户端TCP Socket连接 NioServerSocketChannel 异步非阻塞的服务端TCP socket连接 NioDatagramChannel 异步非阻塞的UDP 连接 NioSctpChannel 异步的客户端Sctp(Stream Control Transmission Protocol,流控制传输协议) 连接 NioSctpServerChannel 异步的服务端连接 OioSocketChannel 同步阻塞的客户端 TCP Socket连接 OioServerSocketChannel 同步阻塞的服务端 TCP Socket连接 OioDatagramChannel 同步阻塞的UDP连接 OioSctpChannel 同步的Sctp连接 OioSctpServerChannel 同步的客户端 TCP Socket 连接 下面我们来看一下Channel的总体类图： 2. NioSocketChannel的创建Bootstrap是Netty 提供了一个便利的工厂类, 我们可以通过它来完成Netty的客户端或者服务端的Netty的初始化, 下面我先来看一个例子, 从客户端和服务端的角度来分别分析一下Netty的程序是如何启动的, 首先, 首先我们从客户端的代码片段开始 public void connect(String hostName, int port, String nickName) &amp;#123; EventLoopGroup group = new NioEventLoopGroup(); try &amp;#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .handler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; &amp;#125; &amp;#125;); // 发起同步连接操作 ChannelFuture future = bootstrap.connect(hostName, port).sync(); future.channel().closeFuture().sync(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; group.shutdownGracefully(); &amp;#125; &amp;#125; 上面的客户端代码虽然简单, 却展示了Netty 客户端初始化所需的内容. EventLoopGroup : 不论是服务端还是客户端, 都必须指定EventLoopGroup. 在这个例子中, 指定了NioEventLoopGroup, 表示一个NIO的EventLoopGroup . ChannelType: 指定Channel的类型， 因为是客户端, 因此使用了NioSocketChannel. Handler: 设置处理数据的handler 下面我们继续深入代码, 看一下客户端通过 Bootstrap 启动后, 都做了哪些工作? 我们看一下NioSocketChannel的类层次结构如下: 回到我们在客户端连接代码的初始化Bootstrap 中调用channel() 方法, 传入的参数为 NioSocketChannel.class , 在这个方法中 其实就是初始化了一个ReflectiveChannelFactory 的对象 public B channel(Class&lt;? extends C> channelClass) &amp;#123; if (channelClass == null) &amp;#123; throw new NullPointerException(\"channelClass\"); &amp;#125; return channelFactory(new ReflectiveChannelFactory&lt;C>(channelClass)); &amp;#125; 而ReflectiveChannelFactory 实现了ChannelFactory 接口, 它提供了唯一的方法, 即newChannel() 方法, 我们看到其实现代码如下: public T newChannel() &amp;#123; try &amp;#123; return clazz.newInstance(); &amp;#125; catch (Throwable t) &amp;#123; throw new ChannelException(\"Unable to create Channel from class \" + clazz, t); &amp;#125; &amp;#125; 根据上面代码提示, 我们可以得出 Bootstrap中的 ChannelFactory 的实现类是 ReflectiveChannelFactory 通过channel() 方法创建的Channel 具体类型是 NioSocketChannel Channel 的实例化过程就是调用 ChannelFactory 的newChannel() 方法, 而实例化的Channel 具体类型又是和初始化Bootstrap 时传入的channel() 方法的参数相关. 因此对于客户端的Bootstrap而言, 创建的Channel 实例就是NioSocketChannel 3.客户端Channel 的初始化前面我们已经知道了如何设置一个Channel的类型, 并且了解到Channel是通过 ChannelFactory 的newChannel() 方法来实例化的, 那么ChannelFactory 的newChannel()方法又是在哪里被调用的呢? 继续追踪, 我们发现其调用链如下: 在AbstractBootstrap 的 initAndRegister() 中调用了ChannelFactory 的newChannel() 来创建一个NioSocketChannel 的实例, 具体代码如下： final ChannelFuture initAndRegister() &amp;#123; Channel channel = null; try &amp;#123; channel = channelFactory.newChannel(); init(channel); &amp;#125; catch (Throwable t) &amp;#123; if (channel != null) &amp;#123; // channel can be null if newChannel crashed (eg SocketException(\"too many open files\")) channel.unsafe().closeForcibly(); &amp;#125; // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &amp;#125; ........ &amp;#125; 在newChannel() 方法中, 利用反射机制调用类对象的newInstance() 方法来创建一个新的Channel 实例, 相当于调用 NioSocketChannel的默认构造器, NioSocketChannel的默认构造器代码如下: public NioSocketChannel() &amp;#123; this(DEFAULT_SELECTOR_PROVIDER); &amp;#125; public NioSocketChannel(SelectorProvider provider) &amp;#123; this(newSocket(provider)); &amp;#125; 这里的代码比较关键, 我们看到, 这个构造器中会调用newSocket) 来打开一个新的Java NIO 的 SocketChannel ： private static SocketChannel newSocket(SelectorProvider provider) &#123; try &#123; /** * Use the &#123;@link SelectorProvider&#125; to open &#123;@link SocketChannel&#125; and so remove condition in * &#123;@link SelectorProvider#provider()&#125; which is called by each SocketChannel.open() otherwise. * * See #2308. */ return provider.openSocketChannel(); &#125; catch (IOException e) &#123; throw new ChannelException(\"Failed to open a socket.\", e); &#125; &#125; 接下来会调用父类, 即 AbstractNioByteChannel的构造器 public NioSocketChannel(SocketChannel socket) &amp;#123; this(null, socket); &amp;#125; public NioSocketChannel(Channel parent, SocketChannel socket) &amp;#123; super(parent, socket); config = new NioSocketChannelConfig(this, socket.socket()); &amp;#125; 并传入参数 parent = null,ch 为刚才 newSocket() 常见的 Java NIO 的SocketChannel 对象, 因此新创建的NioSocketChannel 对象中, parent 暂时为 null protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &amp;#123; super(parent, ch, SelectionKey.OP_READ); &amp;#125; 继续调用 父类的 AbstractNioChannel的构造器, 并传入参数 readInterestOp = SelectionKey.OP_READ, protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &amp;#123; super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try &amp;#123; ch.configureBlocking(false); &amp;#125; catch (IOException e) &amp;#123; try &amp;#123; ch.close(); &amp;#125; catch (IOException e2) &amp;#123; if (logger.isWarnEnabled()) &amp;#123; logger.warn( \"Failed to close a partially initialized socket.\", e2); &amp;#125; &amp;#125; throw new ChannelException(\"Failed to enter non-blocking mode.\", e); &amp;#125; &amp;#125; 然后继续调用父类 AbstractChannel 的构造器 protected AbstractChannel(Channel parent) &amp;#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline(); &amp;#125; 至此, NioSocketChannel 就初始化结束了, 我们可以稍微总结一下 NioSocketChannel 初始化所做的工作内容： 调用NioSocketChannel 的 newSocket(DEFAULT_SELECTOR_PROVIDER) 打开一个新的Java NioSocketChannel, AbstractChannel (Channel parent) 中需要初始化的属性: id: 每一个Channel 都拥有的一个唯一的id parent: 属性值为 null unsafe: 通过 Unsafe() 实例化一个 unsafe 对象, 他的类型是AbstractNioByteChannel.NioByteUnsafe 内部类. pipeline: 是通过DefaultChannelPipeline 新创建的实力 AbstractNioChannel 的属性 ch: 赋值为 Java SocketChannel, 即NioSocketChannel 的newSocket() 方法返回的Java Nio SocketChannel, readInterestOp： 赋值为SelectionKey.OP_READ ch:被配置为非阻塞, 即调用ch.configureBlocking(false)。 4. Unsafe 字段的变化我们简单提到了, 在实例化NioSocketChannel 的过程中, 会在父类 AbstractChannel 的构造方法中调用newUnsafe() 来获取一个 unsafe 实力,那么unsafe 是怎么初始化的, 他的作用是什么? 其实 unsafe 特别关键, 它封装了对Java 底层的Socket 的操作, 因此实际上是通过 Netty的上层 和Java 底层的重要的桥梁. 那么下面我们来看一下它提供的方法 interface Unsafe &amp;#123; /** * Return the assigned &amp;#123;@link RecvByteBufAllocator.Handle&amp;#125; which will be used to allocate &amp;#123;@link ByteBuf&amp;#125;'s when * receiving data. */ RecvByteBufAllocator.Handle recvBufAllocHandle(); /** * Return the &amp;#123;@link SocketAddress&amp;#125; to which is bound local or * &amp;#123;@code null&amp;#125; if none. */ SocketAddress localAddress(); /** * Return the &amp;#123;@link SocketAddress&amp;#125; to which is bound remote or * &amp;#123;@code null&amp;#125; if none is bound yet. */ SocketAddress remoteAddress(); /** * Register the &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelPromise&amp;#125; and notify * the &amp;#123;@link ChannelFuture&amp;#125; once the registration was complete. */ void register(EventLoop eventLoop, ChannelPromise promise); /** * Bind the &amp;#123;@link SocketAddress&amp;#125; to the &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelPromise&amp;#125; and notify * it once its done. */ void bind(SocketAddress localAddress, ChannelPromise promise); /** * Connect the &amp;#123;@link Channel&amp;#125; of the given &amp;#123;@link ChannelFuture&amp;#125; with the given remote &amp;#123;@link SocketAddress&amp;#125;. * If a specific local &amp;#123;@link SocketAddress&amp;#125; should be used it need to be given as argument. Otherwise just * pass &amp;#123;@code null&amp;#125; to it. * * The &amp;#123;@link ChannelPromise&amp;#125; will get notified once the connect operation was complete. */ void connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise); /** * Disconnect the &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelFuture&amp;#125; and notify the &amp;#123;@link ChannelPromise&amp;#125; once the * operation was complete. */ void disconnect(ChannelPromise promise); /** * Close the &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelPromise&amp;#125; and notify the &amp;#123;@link ChannelPromise&amp;#125; once the * operation was complete. */ void close(ChannelPromise promise); /** * Closes the &amp;#123;@link Channel&amp;#125; immediately without firing any events. Probably only useful * when registration attempt failed. */ void closeForcibly(); /** * Deregister the &amp;#123;@link Channel&amp;#125; of the &amp;#123;@link ChannelPromise&amp;#125; from &amp;#123;@link EventLoop&amp;#125; and notify the * &amp;#123;@link ChannelPromise&amp;#125; once the operation was complete. */ void deregister(ChannelPromise promise); /** * Schedules a read operation that fills the inbound buffer of the first &amp;#123;@link ChannelInboundHandler&amp;#125; in the * &amp;#123;@link ChannelPipeline&amp;#125;. If there's already a pending read operation, this method does nothing. */ void beginRead(); /** * Schedules a write operation. */ void write(Object msg, ChannelPromise promise); /** * Flush out all write operations scheduled via &amp;#123;@link #write(Object, ChannelPromise)&amp;#125;. */ void flush(); /** * Return a special ChannelPromise which can be reused and passed to the operations in &amp;#123;@link Unsafe&amp;#125;. * It will never be notified of a success or error and so is only a placeholder for operations * that take a &amp;#123;@link ChannelPromise&amp;#125; as argument but for which you not want to get notified. */ ChannelPromise voidPromise(); /** * Returns the &amp;#123;@link ChannelOutboundBuffer&amp;#125; of the &amp;#123;@link Channel&amp;#125; where the pending write requests are stored. */ ChannelOutboundBuffer outboundBuffer(); &amp;#125; 从源码中可以看出, 这些方法其实都是对应到相关的Java 底层的Socket 的操作 继续回到 AbstractChannel 的构造方法, 在这里调用了 newUnsafe() 获取了一个新的 Unsafe 对象, 而newUnsafe 方法在NioSocketChannel 中被重写了, 来看代码 @Override protected AbstractNioUnsafe newUnsafe() &amp;#123; return new NioSocketChannelUnsafe(); &amp;#125; NioSocketChannel 的 newUnsafe 方法会返回一个 NioSocketChannelUnsafe 实例, 从这里我们可以确定了, 在实例化中的NioSocketChannel 中的unsafe 字段, 其实是一个 NioSocketChannelUnsafe 的实例. 5. Pipeline 的实例化上面我们分析了 NioSocketChannel 的大体初始化过程, 但是我们漏掉了一个关键的过程. 即ChannelPipeline 的初始化. 在Pipeline 的 注释说明中写到 “Each channel has its own pipeline and it is created automatically when a new channel is created.” , 我们知道在实例化一个Channel 时， 需要都要实例化一个ChannelPipeline, 而我们确定在 AbstractChannel 的构造器中看到了 pipeline 字段被初始化为 DefaultChannelPipeline 的实例, 接下来我们就来看一下 protected DefaultChannelPipeline(Channel channel) &amp;#123; this.channel = ObjectUtil.checkNotNull(channel, \"channel\"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head; &amp;#125; DefaultChannelPipeline 的构造器需要传入一个channel, 而这个channel 就是我们实例化的NioSocketChannel . DefaultChannelPipeline 会将这个 NioSocketChannel 对象保存在 channel 字段中, DefaultChannelPipeline 中还有两个特殊的字段, 即 head 和tail .这两个字段是双向链表的头和尾. 其实在DefaultChannelPipeline 中, 维护了一个以 AbstractChannelHandlerContext 为节点元素的双向链表, 这个链表是Netty 实现Pipeline 的关键. 关于DefaultChannelPipeline 中的双向链表以及它所起的作用, 我们暂时先不讲解, 先看看 HeadContext 的类继承层次结构如下所示： TailContext的类继承层次如下所示： 我们可以看到, 链表中head 是一个 AbstractChannelHandlerContext 的构造器， 并传入参数 inbound = false, outbound = true. 而 TailContext 的构造器 与 HeadContext 的相反, 他调用了父类的AbstractChannelHandlerContext 的构造器, 并传入参数 inbound = true, outbound = false. 即 head 是一个 OutBoundHandler，而tail 是一个InBoundHandler. 6. EventLoop的初始化回到最开始的 ChatClient 代码, 我们在一开始就实例化了一个NioEventLoopGroup 对象, 因为我们就从构造器中追踪一下 EventLoop 的初始化过程, 首先来看一下 NioEventLoopGroup 的类继承层次. NioEventLoop 有几个重载的构造器, 不过内容都没有太大的区别, 最终都是调用 父类的MultithreadEventLoopGroup的构造器 /** * @see &amp;#123;@link MultithreadEventExecutorGroup#MultithreadEventExecutorGroup(int, Executor, Object...)&amp;#125; */ protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) &amp;#123; super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args); &amp;#125; 其实有个意思的地方是, 如果我们传入的线程数 nThreads 是0, 那么Netty 会为我们设置默认的线程数 DEFAULT_EVENT_LOOP_THREADS, 这个默认的线程数是怎么确定的呢? 其实很简单, 在静态代码中, 会首先确定 DEFAULT_EVENT_LOOP_THREADS的值 static &amp;#123; DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt( \"io.netty.eventLoopThreads\", Runtime.getRuntime().availableProcessors() * 2)); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"-Dio.netty.eventLoopThreads: &amp;#123;&amp;#125;\", DEFAULT_EVENT_LOOP_THREADS); &amp;#125; &amp;#125; Netty 首先会从系统属性中读取 io.netty.eventLoopThreads 的值, 如果我们没有设置的话, 那么就返回默认的值, 即处理器核心数*2, 回到 MultithreadEventLoopGroup 构造器中继续调用 父类MultithreadEventLoopGroup 的构造器 /** * Create a new instance. * * @param nThreads the number of threads that will be used by this instance. * @param executor the Executor to use, or &amp;#123;@code null&amp;#125; if the default should be used. * @param chooserFactory the &amp;#123;@link EventExecutorChooserFactory&amp;#125; to use. * @param args arguments which will passed to each &amp;#123;@link #newChild(Executor, Object...)&amp;#125; call */ protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &amp;#123; if (nThreads &lt;= 0) &amp;#123; throw new IllegalArgumentException(String.format(\"nThreads: %d (expected: > 0)\", nThreads)); &amp;#125; if (executor == null) &amp;#123; executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); &amp;#125; children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) &amp;#123; boolean success = false; try &amp;#123; children[i] = newChild(executor, args); success = true; &amp;#125; catch (Exception e) &amp;#123; // TODO: Think about if this is a good exception type throw new IllegalStateException(\"failed to create a child event loop\", e); &amp;#125; finally &amp;#123; if (!success) &amp;#123; for (int j = 0; j &lt; i; j ++) &amp;#123; children[j].shutdownGracefully(); &amp;#125; for (int j = 0; j &lt; i; j ++) &amp;#123; EventExecutor e = children[j]; try &amp;#123; while (!e.isTerminated()) &amp;#123; e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); &amp;#125; &amp;#125; catch (InterruptedException interrupted) &amp;#123; // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object> terminationListener = new FutureListener&lt;Object>() &amp;#123; @Override public void operationComplete(Future&lt;Object> future) throws Exception &amp;#123; if (terminatedChildren.incrementAndGet() == children.length) &amp;#123; terminationFuture.setSuccess(null); &amp;#125; &amp;#125; &amp;#125;; for (EventExecutor e: children) &amp;#123; e.terminationFuture().addListener(terminationListener); &amp;#125; Set&lt;EventExecutor> childrenSet = new LinkedHashSet&lt;EventExecutor>(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); &amp;#125; 我们可以继续追踪到newChooser 方法里面看看其实现逻辑, 具体代码如下: public final class DefaultEventExecutorChooserFactory implements EventExecutorChooserFactory &amp;#123; public static final DefaultEventExecutorChooserFactory INSTANCE = new DefaultEventExecutorChooserFactory(); private DefaultEventExecutorChooserFactory() &amp;#123; &amp;#125; @SuppressWarnings(\"unchecked\") @Override public EventExecutorChooser newChooser(EventExecutor[] executors) &amp;#123; if (isPowerOfTwo(executors.length)) &amp;#123; return new PowerOfTowEventExecutorChooser(executors); &amp;#125; else &amp;#123; return new GenericEventExecutorChooser(executors); &amp;#125; &amp;#125; private static boolean isPowerOfTwo(int val) &amp;#123; return (val &amp; -val) == val; &amp;#125; private static final class PowerOfTowEventExecutorChooser implements EventExecutorChooser &amp;#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; PowerOfTowEventExecutorChooser(EventExecutor[] executors) &amp;#123; this.executors = executors; &amp;#125; @Override public EventExecutor next() &amp;#123; return executors[idx.getAndIncrement() &amp; executors.length - 1]; &amp;#125; &amp;#125; private static final class GenericEventExecutorChooser implements EventExecutorChooser &amp;#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) &amp;#123; this.executors = executors; &amp;#125; @Override public EventExecutor next() &amp;#123; return executors[Math.abs(idx.getAndIncrement() % executors.length)]; &amp;#125; &amp;#125; &amp;#125; 上面的代码逻辑 主要表达的意思是: 即如果nThreads 是2的幂, 即使用 PowerOfTowEventExecutorChooser,否则使用 GenericEventExecutorChooser, 这两个 chooser 方法都重写了next() 方法, next() 方法的主要功能就是将数组索引循环位移, 如下图所示： 当索引移动最后一个位置的时候， 再调用 next() 方法就会将索引位置重新指向0 这个运算逻辑其实很简单, 就是每次让索引自增后和数据长度取模 , idx.getAndIncrement() % executors.length . 但是就连一个非常简单的数组索引运算, Netty 都帮我们做了优化, 因为在计算机底层, &amp;与 比% 运算效率更高。 好了, 分析到这里我们就应该非常清楚MultithreadEventExecutorGroup 中的处理逻辑了., 简单做一个总结: 创建一个 大小为 nThreads 的SingleThreadEventExecutor 数组 根据nThreads 的大小, 创建不同的 Chooser,即 如果 nThreads 是2的幂, 则使用 PowerOfTowEventExecutorChooser, 反之则使用GenericEventExecutorChooser, 不论使用哪个Chooser,他们的功能都是一样的, 即从 children 数组中 选出一个合适的EventExecutor 实例. 调用 newChild方法初始化 children 数组 根据上面的代码. 我们也能知道， MultithreadEventLoopGroup 内部维护了一个 EventExecutor 数组, 而Netty EventLoopGroup的实现机制就是建立在 MultithreadEventLoopGroup之上的, 每当一个Netty 需要一个EventLoop 时， 会调用next() 方法获取一个可用的EventLoop . 上面代码的最后一部分是 newChild() 方法, 这是一个抽象方法, 它的任务是 实例化EventLoop 对象, 我们跟踪一下它的代码, 可以发现, 这个方法在 NioEventLoopGroup类中有实现, 其实内容很简单. @Override protected EventLoop newChild(Executor executor, Object... args) throws Exception &amp;#123; return new NioEventLoop(this, executor, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]); &amp;#125; 其实逻辑很简单 就是实例化一个 NioEventLoop 对象, 然后返回NioEventLoop 对象 最后总结一下 整个NioEventLoop 的初始化过程. EventLoopGroup(其实是MultithreadEventLoopGroup) 内部维护了一个类型为 EventExecutor children 数组, 其大小是nThreads , 这样就构成了一个线程池.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 如果我们在实例化 NioEventLoopGroup时, 如果指定了线程池大小, 则nThreads 就是指定的值, 反之是处理器核心数 * 2 oba 如果我们在实例化 NioEventLoopGroup时, 如果指定了线程池大小, 则nThreads 就是指定的值, 反之是处理器核心数 * 2 MultithreadEventLoopGroup 中会调用 newChild 抽象方法来初始化children 数组 抽象方法newChild 是在NioEventLoopGroup 中实现的, 它返回一个NioEventLoop 实例 NioEventLoop 属性赋值 provider：在NioEventLoopGroup 构造器中通过SelectorProvider.provider()获取一个 SelectorProvider。 selector: 在 NioEventLoop 构造器中通过调用provider.openSelector()方法 获取一个selector 对象 7. Channel 注册到Selector 在前面的分析中, 我们提到Channel 会在Bootstrap 的initAndRegister() 中进行初始化, 但是这个方法还会将初始化好的channel 注册到NioEventLoop 的selector中, 接下来我们分析一下Channel的注册过程. 在回顾一下AbstractBootstrap的 initAndRegister 方法 final ChannelFuture initAndRegister() &amp;#123; Channel channel = null; try &amp;#123; channel = channelFactory.newChannel(); init(channel); &amp;#125; catch (Throwable t) &amp;#123; if (channel != null) &amp;#123; // channel can be null if newChannel crashed (eg SocketException(\"too many open files\")) channel.unsafe().closeForcibly(); &amp;#125; // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &amp;#125; ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &amp;#123; if (channel.isRegistered()) &amp;#123; channel.close(); &amp;#125; else &amp;#123; channel.unsafe().closeForcibly(); &amp;#125; &amp;#125; // If we are here and the promise is not failed, it's one of the following cases: // 1) If we attempted registration from the event loop, the registration has been completed at this point. // i.e. It's safe to attempt bind() or connect() now because the channel has been registered. // 2) If we attempted registration from the other thread, the registration request has been successfully // added to the event loop's task queue for later execution. // i.e. It's safe to attempt bind() or connect() now: // because bind() or connect() will be executed *after* the scheduled registration task is executed // because register(), bind(), and connect() are all bound to the same thread. return regFuture; &amp;#125; 当channel 初始化后, 紧接着会调用config().group().register() 方法来向 selector 中注册Channel, 我们继续追踪的话, 会发现其调用链如下: 通过追踪调用链 , 最终我们发现是调用到了 unsafe 的 register 方法, 那么接下来我们仔细看一下 AbstractChannel$AbstractUnsafe.register() 方法中到底做了什么? public final void register(EventLoop eventLoop, final ChannelPromise promise) &amp;#123; if (eventLoop == null) &amp;#123; throw new NullPointerException(\"eventLoop\"); &amp;#125; if (isRegistered()) &amp;#123; promise.setFailure(new IllegalStateException(\"registered to an event loop already\")); return; &amp;#125; if (!isCompatible(eventLoop)) &amp;#123; promise.setFailure( new IllegalStateException(\"incompatible event loop type: \" + eventLoop.getClass().getName())); return; &amp;#125; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &amp;#123; register0(promise); &amp;#125; else &amp;#123; try &amp;#123; eventLoop.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; register0(promise); &amp;#125; &amp;#125;); &amp;#125; catch (Throwable t) &amp;#123; logger.warn( \"Force-closing a channel whose registration task was not accepted by an event loop: &amp;#123;&amp;#125;\", AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &amp;#125; &amp;#125; &amp;#125; 首先, 将 eventLoop 赋值给Channel的 eventLoop 属性, 而我们直到其实这个 eventLoop 对象其实是MultithreadEventLoopGroup 的next() 方法生成的. 根据我们前面的分析, 我们可以确定next() 方法返回的eventLoop 对象是 NioEventLoop 实例, register 方法接着调用了register0 方法 private void register0(ChannelPromise promise) &amp;#123; try &amp;#123; // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) &amp;#123; return; &amp;#125; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) &amp;#123; if (firstRegistration) &amp;#123; pipeline.fireChannelActive(); &amp;#125; else if (config().isAutoRead()) &amp;#123; // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); &amp;#125; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &amp;#125; &amp;#125; register0() 方法又调用了AbstractNioChannel.doRegister() 方法, @Override protected void doRegister() throws Exception &amp;#123; boolean selected = false; for (;;) &amp;#123; try &amp;#123; selectionKey = javaChannel().register(eventLoop().selector, 0, this); return; &amp;#125; catch (CancelledKeyException e) &amp;#123; if (!selected) &amp;#123; // Force the Selector to select now as the \"canceled\" SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; &amp;#125; else &amp;#123; // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 看到javaChannel 这个方法我们前面已经已经知道了, 它返回的是一个Java Nio 的 SocketChannel 对象, 这里我们将这个SocketChannel 注册到与EventLoop 关联的 selector 上. 我们总结一下Channel的注册过程 首先在AbstractChannel 的 initAndRegister() 方法中, 通过group().register(channel) 调用MultithreadEventLoopGroup的 register() 方法. 在MultithreadEventLoopGroup 的register() 方法中, 调用next() 方法 获取一个可用的 SingleThreadEventLoop,然后调用它的 register() 方法. 在 SingleThreadEventLoop 的 register() 方法中, 调用channel.unsafe().register(this, promise) 方法来获取 channel 的unsafe() 底层操作对象, 然后调用 unsafe的 register 方法. 在AbstractUnsafe 的register() 中, 调用 register0() 方法注册Channel 对象. 在AbstractUnsafe的 register0() 方法中, 调用 AbstractNioChannel 的 doRegister() 方法 AbstractNioChannel的 doRegister() 方法通过javaChannel().register(eventLoop().selector, 0, this); 将channel 对应的Java NIO 的Socket Channel 注册到 eventLoop 的 selector 中 ,并且将当前channel 作为attachment 与SocketChannel 关联. 总的来说, Channel 注册过程所作的工作就是将Chanel 与对应的EventLoop 关联, 这因此体现出了, 在Netty中, 每个Channel 都会关联一个特定的EventLoop , 并且这个Channel 中的所有操作都是在这个EventLoop 中执行的. 当关联好Channel 和EventLoop 后, 会继续调用底层Java Nio 的SocketChannel 对象的register() 方法, 将底层Java NIO 的SocketChannel 注册到指定的 selector 中, 通过这两步就完成了Netty 对Channel 的注册. 8. Handler 的添加过程Netty 有一个强大和灵活的地方就是基于 Pipeline 的自定义header 机制. 基于此, 我们可以像添加插件一样自由组合各种各样的handler来完成业务逻辑。例如我们需要处理http 数据, 那么就可以在 pipeline 之前添加一个针对HTTP 编解码的Handler, 接着添加我们的业务逻辑handler, 这样网络上的数据流就像通过一个管道一样, 从不同的headler 中流过并进行编解码, 最终再到达我们自己的handler中。 我们先从体验一下自定义handler是如何以及何时添加到ChannelPipeline 中的, 首先我们看一下我们的用户代码 public void connect(String hostName, int port, String nickName) &amp;#123; EventLoopGroup group = new NioEventLoopGroup(); try &amp;#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .handler(new ChannelInitializer&lt;SocketChannel>() &amp;#123; @Override protected void initChannel(SocketChannel ch) throws Exception &amp;#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); pipeline.addLast(new ChatClientHandler(nickName)); &amp;#125; &amp;#125;); // 发起同步连接操作 ChannelFuture future = bootstrap.connect(hostName, port).sync(); future.channel().closeFuture().sync(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; group.shutdownGracefully(); &amp;#125; &amp;#125; 这个代码片段就是实现了handler 的添加功能, 我们看到 , Bootstrap 的 handler 方法接收一个ChannelInitializer,而我们传的参数是一个派生于抽象类 ChannelInitializer的 匿名类, 它当然也实现了ChannelHandler 接口, 我们来看一下, ChannelInitializer类内到底有什么玄机. @Sharable public abstract class ChannelInitializer&lt;C extends Channel> extends ChannelInboundHandlerAdapter &amp;#123; private static final InternalLogger logger = InternalLoggerFactory.getInstance(ChannelInitializer.class); // We use a ConcurrentMap as a ChannelInitializer is usually shared between all Channels in a Bootstrap / // ServerBootstrap. This way we can reduce the memory usage compared to use Attributes. private final ConcurrentMap&lt;ChannelHandlerContext, Boolean> initMap = PlatformDependent.newConcurrentHashMap(); /** * This method will be called once the &amp;#123;@link Channel&amp;#125; was registered. After the method returns this instance * will be removed from the &amp;#123;@link ChannelPipeline&amp;#125; of the &amp;#123;@link Channel&amp;#125;. * * @param ch the &amp;#123;@link Channel&amp;#125; which was registered. * @throws Exception is thrown if an error occurs. In that case it will be handled by * &amp;#123;@link #exceptionCaught(ChannelHandlerContext, Throwable)&amp;#125; which will by default close * the &amp;#123;@link Channel&amp;#125;. */ protected abstract void initChannel(C ch) throws Exception; @Override @SuppressWarnings(\"unchecked\") public final void channelRegistered(ChannelHandlerContext ctx) throws Exception &amp;#123; // Normally this method will never be called as handlerAdded(...) should call initChannel(...) and remove // the handler. if (initChannel(ctx)) &amp;#123; // we called initChannel(...) so we need to call now pipeline.fireChannelRegistered() to ensure we not // miss an event. ctx.pipeline().fireChannelRegistered(); &amp;#125; else &amp;#123; // Called initChannel(...) before which is the expected behavior, so just forward the event. ctx.fireChannelRegistered(); &amp;#125; &amp;#125; /** * Handle the &amp;#123;@link Throwable&amp;#125; by logging and closing the &amp;#123;@link Channel&amp;#125;. Sub-classes may override this. */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &amp;#123; logger.warn(\"Failed to initialize a channel. Closing: \" + ctx.channel(), cause); ctx.close(); &amp;#125; /** * &amp;#123;@inheritDoc&amp;#125; If override this method ensure you call super! */ @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &amp;#123; if (ctx.channel().isRegistered()) &amp;#123; // This should always be true with our current DefaultChannelPipeline implementation. // The good thing about calling initChannel(...) in handlerAdded(...) is that there will be no ordering // suprises if a ChannelInitializer will add another ChannelInitializer. This is as all handlers // will be added in the expected order. initChannel(ctx); &amp;#125; &amp;#125; @SuppressWarnings(\"unchecked\") private boolean initChannel(ChannelHandlerContext ctx) throws Exception &amp;#123; if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) &amp;#123; // Guard against re-entrance. try &amp;#123; initChannel((C) ctx.channel()); &amp;#125; catch (Throwable cause) &amp;#123; // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...). // We do so to prevent multiple calls to initChannel(...). exceptionCaught(ctx, cause); &amp;#125; finally &amp;#123; remove(ctx); &amp;#125; return true; &amp;#125; return false; &amp;#125; private void remove(ChannelHandlerContext ctx) &amp;#123; try &amp;#123; ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) &amp;#123; pipeline.remove(this); &amp;#125; &amp;#125; finally &amp;#123; initMap.remove(ctx); &amp;#125; &amp;#125; &amp;#125; ChannelInitializer 是一个抽象类, 它有一个抽象方法initChannel(), 我们看到的匿名类正是实现了这个方法, 并在这个方法中添加自定义的 handler的. 那么 initChannel() 是在哪里被调用的呢？ 其实是在 ChannelInitializer 的channelRegistered() 方法中. 接下来关注一下 channelRegistered 方法, 从上面的源码中, 我们可以看到, 在channelRegistered() 方法中, 会调用 initChannel() 方法, 将自定义的 handler 添加到 ChannelPipeline 中, 然后调用 ctx.pipeline().remove(this) 将自己从 ChannelPipeline 中删除, 上面的分析过程, 如下图所示： 接着 initChannle() 方法调用了后, 添加了自定义的 handler 最后将ChannelInitializer 删除 分析到这里, 我们已经简单了解自定义的 handler 是如何添加到 ChannelPipeline 中的了, 9. 客户端发起连接请求.经过上面的分析后, 我们大致了解了Netty 客户端初始化时, 所做的工作, 那么接下来直奔主题分析一下客户端是如何发起TCP 连接的. 首先, 客户端通过调用Bootstrap.connect() 方法进行连接, 在 connect() 方法中, 会进行一些参数检查后, 最终调用的是doConnect() 方法. 其代码实现如下: private static void doConnect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise connectPromise) &amp;#123; // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. final Channel channel = connectPromise.channel(); channel.eventLoop().execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; if (localAddress == null) &amp;#123; channel.connect(remoteAddress, connectPromise); &amp;#125; else &amp;#123; channel.connect(remoteAddress, localAddress, connectPromise); &amp;#125; connectPromise.addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &amp;#125; &amp;#125;); &amp;#125; 在doConnect() 中,会有 eventLoop 线程中调用 Channel的 connect() 方法, 而这个Channel的具体类型实际上就是NioSocketChannel, 前面已经分析过了., 继续追踪到到 channel.connect() 方法中, 我们发现它调用的是DefaultChannelPipeline.connect() 方法, pipeline的 connect() 方法如下： @Override public final ChannelFuture connect( SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) &amp;#123; return tail.connect(remoteAddress, localAddress, promise); &amp;#125; tail 我们已经分析过了, 是一个TailContext 的实例 , 而TailContext 又是 AbstractChannelHandlerContext 的子类, 并且没有实现 connect() 方法, 因此这里调用的其实是 AbstractChannelHandlerContext的connect() 方法, 我们看一下这个方法的实现 @Override public ChannelFuture connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) &amp;#123; if (remoteAddress == null) &amp;#123; throw new NullPointerException(\"remoteAddress\"); &amp;#125; if (!validatePromise(promise, false)) &amp;#123; // cancelled return promise; &amp;#125; final AbstractChannelHandlerContext next = findContextOutbound(); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &amp;#123; next.invokeConnect(remoteAddress, localAddress, promise); &amp;#125; else &amp;#123; safeExecute(executor, new Runnable() &amp;#123; @Override public void run() &amp;#123; next.invokeConnect(remoteAddress, localAddress, promise); &amp;#125; &amp;#125;, promise, null); &amp;#125; return promise; &amp;#125; 上面的代码中有一个关键的地方, 即final AbstractChannelHandlerContext next = findContextOutbound(); 这里调用 findContextOutbound() 方法, 从DefaultChannelPipeline 内的双向链表的tail 开始， 不断的向前找到第一个outbound为 true的AbstractChannelHandlerContext, 然后调用它的invokeConnect() 方法, 其代码如下： private void invokeConnect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) &amp;#123; if (invokeHandler()) &amp;#123; try &amp;#123; ((ChannelOutboundHandler) handler()).connect(this, remoteAddress, localAddress, promise); &amp;#125; catch (Throwable t) &amp;#123; notifyOutboundHandlerException(t, promise); &amp;#125; &amp;#125; else &amp;#123; connect(remoteAddress, localAddress, promise); &amp;#125; &amp;#125; 前面我们有提到, 在DefaultChannelPipeline 的构造器中 , 实例化了 两个对象, head 和 tail . 并形成了双向链表的头和尾. head 是HeadContext是实例, 它实现了ChannelOutboundHandler接口, 并且它的outbound设置为 true, 因此在findContextOutbound() 方法中, 找到的AbstractChannelHandlerContext 对象其实就是head, 进而在invokeConnect() 方法中,我们向上转换为 ChannelOutboundHandler 就是没问题的了. 而又因为 HeadContext 重写了 connect() 方法, 因此实际调用的是HeadContext的connect() 方法, 我们接着追踪到HeadContext的 connect() 方法, 其代码如下： @Override public void connect( ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception &amp;#123; unsafe.connect(remoteAddress, localAddress, promise); &amp;#125; 这个 connect() 方法非常简单, 只是调用了 unsafe的connect() 方法, 回顾一下 HeadContext 的构造器. 我们发现这个 unsafe 其实就是 pipeline.channel().unsafe() 返回的Channel 的 unsafe 字段, 到此为止， 我们应该已经知道, 其实是AbstractNioByteChannel.NioByteUnsafe 内部类. 最后, 我们找到创建 Socket 连接的关键代码继续追踪， 其实就是调用AbstractNioUnsafe的 connect() 方法, @Override public final void connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) &amp;#123; if (!promise.setUncancellable() || !ensureOpen(promise)) &amp;#123; return; &amp;#125; try &amp;#123; if (connectPromise != null) &amp;#123; // Already a connect in process. throw new ConnectionPendingException(); &amp;#125; boolean wasActive = isActive(); if (doConnect(remoteAddress, localAddress)) &amp;#123; fulfillConnectPromise(promise, wasActive); &amp;#125; else &amp;#123; connectPromise = promise; requestedRemoteAddress = remoteAddress; // Schedule connect timeout. int connectTimeoutMillis = config().getConnectTimeoutMillis(); if (connectTimeoutMillis > 0) &amp;#123; connectTimeoutFuture = eventLoop().schedule(new Runnable() &amp;#123; @Override public void run() &amp;#123; ChannelPromise connectPromise = AbstractNioChannel.this.connectPromise; ConnectTimeoutException cause = new ConnectTimeoutException(\"connection timed out: \" + remoteAddress); if (connectPromise != null &amp;&amp; connectPromise.tryFailure(cause)) &amp;#123; close(voidPromise()); &amp;#125; &amp;#125; &amp;#125;, connectTimeoutMillis, TimeUnit.MILLISECONDS); &amp;#125; promise.addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; if (future.isCancelled()) &amp;#123; if (connectTimeoutFuture != null) &amp;#123; connectTimeoutFuture.cancel(false); &amp;#125; connectPromise = null; close(voidPromise()); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; promise.tryFailure(annotateConnectException(t, remoteAddress)); closeIfClosed(); &amp;#125; &amp;#125; 在这个 conect() 中, 又调用了 doConnect() 方法, 注意，这个方法并不是AbstractNioUnsafe 的方法, 而是AbstractNioChannel的抽象方法, doConnect() 方法是在 NioSocketChannel 中实现的, 因为进入NioSocketChannel的 doConnect() 方法中 @Override protected boolean doConnect(SocketAddress remoteAddress, SocketAddress localAddress) throws Exception &amp;#123; if (localAddress != null) &amp;#123; doBind0(localAddress); &amp;#125; boolean success = false; try &amp;#123; boolean connected = javaChannel().connect(remoteAddress); if (!connected) &amp;#123; selectionKey().interestOps(SelectionKey.OP_CONNECT); &amp;#125; success = true; return connected; &amp;#125; finally &amp;#123; if (!success) &amp;#123; doClose(); &amp;#125; &amp;#125; &amp;#125; 我们终于看到的最关键的代码, 首先是获取Java NIO 的SocketChannel , 获取 NioSocketChannel的 newSocket 返回的SocketChannel 对象, 最后调用 SocketChannel 的connect() 方法完成java NIO 底层的Socket 连接, 最后总结一下, 客户端Bootstrap 发起连接请求的的流程: 14e9bd67a584e759133295239250bed1a61e7204","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Netty编解码的艺术(13)","slug":"Netty/Netty编解码的艺术(13)","date":"2022-01-04T02:42:07.217Z","updated":"2022-01-04T02:42:07.217Z","comments":true,"path":"2022/01/04/netty/netty-bian-jie-ma-de-yi-zhu-13/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/netty-bian-jie-ma-de-yi-zhu-13/","excerpt":"","text":"Netty 编解码的艺术1. 什么是拆包/粘包1. TCP 粘包/拆包TCP 是一个”流”协议, 所谓流, 就是没有界限的一长串二进制数据, TCP 作为传输协议并不了解业务数据的具体含义, 它会根据TCP缓冲区的实际情况进行数据包的划分, 所以在业务上认为是一个完整的包, 可能会被TCP 拆分成多个包进行发送, 也有可能把多个小的包封装成一个大的数据包发送, 这就是所谓的TCP 粘包和拆包问题. 同样, 在Netty 的编码器中, 也会对半包和粘包问题做相应的处理. 什么是半包? 顾名思义就是不完整的数据包, 因为Netty 在轮询读事件的时候, 每次将channel 中读取的数据, 不一定是一个完整的数据包, 这种情况下, 就叫半包。 粘包同样也不难理解, 如果Client 往Server 发送数据包, 如果发送频繁很有可能会将多个数据都发送到通道中, 如果在server 在读取的时候可能会读取到超过一个完整数据包的长度, 这种情况叫粘包. 有关半包和粘包, 如下图所示： 2. 粘包问题的解决策略由于底层的TCP 无法理解上层的业务数据, 所以在底层生物法保证数据包不被拆分和重组的, 这个问题只能通过上层的应用协议栈设计来解决. 业界的主流协议的解决方案, 可以归纳如下: 消息定义: 报文大小固定长度, 例如每个报文的长度固定为200字节, 如果不够空位补空格. 包尾添加特殊分隔符, 例如每条报文结束都添加回车换行符(例如FTP协议)或者指定特殊字符作为报文分隔符, 接收方通过特殊分隔符切分报文区分. 将消息分为消息头和消息体, 消息头中包含信息的总长度(或者消息体长度) 的字段. 更复杂的自定义应用层协议. Netty 对半包或者粘包的处理其实也非常简单, 我们知道, 每个handler 是和channel 唯一绑定的, 一个handler 只对应一个channel. 所以将channel 中的数据读取时候经过解析, 如果不是一个完整的数据包, 则解析失败，将这块数据包进行保存, 等下次解析的时候再和这个数据包进行组装解析, 知道解析到完整的数据包, 才会将数据包进行往下传递. 2. 什么是编码和解码1. 编解码技术通常我们也喜欢将编码(Encode) 称为序列化(serialization), 它将对象序列化为字节数组, 用于网络传输、数据持久化或者其他用途. 反之, 解码(Decode) 称为反序列化(deserialization) 把从网络、磁盘等读取的字节数组还原成原始对象(通常是原始对象的拷贝), 以方便后续的业务逻辑操作. 进行远程跨进程服务调用时(例如RPC调用) , 需要使用特定的编解码技术, 对需要进行网络传输的对象做编码或者解码， 以便完成远程调用. 2. Netty 为什么要提供编解码框架?作为一个高性能的异步、NIO 通信框架， 编解码框架是Netty 的重要组成部分. 尽管站在微内核的角度看, 编解码框架并不是Netty 微内核的组成部分, 但是通过ChannelHandler 定制扩展出的编解码框架却是不可或缺的. 然后, 我们已经知道在Netty 中, 从网络读取的inbound 消息, 需要经过解码, 将二进制的数据转换成应用协议消息或者业务消息, 才能够被上层的应用逻辑识别和处理. 同理,用户发送方到网络的outbound 业务消息, 需要经过编码转换成二进制字节数组(对于Netty来说就是ByteBuf) 才能够发送到网络对端。 编码和解码功能是NIO框架的有机组成部分,无论是由业务定制扩展实现, 还是NIO框架内置编解码能力, 该功能是必不可少的. 为了降低用户的开发难度, Netty 对常用的功能和API 做了装饰, 以屏蔽底层的实现细节, 编解码功能的定制, 对于熟悉Netty 底层实现的开发者而言， 直接基于ChannelHandler 扩展开发, 难度并不是很大。 但是对于大部分初学者或者不愿意去了解底层实现细节的用户, 需要提供给他们更简单的类库和API，而不是ChannelHandler. Netty 在这方面做的非常出色, 针对编解码功能, 他即提供了通用的编码吗框架供用户扩展, 又提供了常用的编解码类库供用户直接使用, 在保证定制扩展性的基础上, 尽量降低用户的开发工作量和开发门槛, 提升开发效率. Netty 预置的编解码功能列表如下: Base64、Protobuf、JBoss Marshalling、Spdy等. 3. Netty 中常用的编码器Netty 默认提供了多个解码器, 可以进行分包的操作, 满足99%的编码需求. 1. ByteToMessageDecoder 抽象解码器使用NIO 进行网络编程时, 往往需要将读取到的字节数组或者字节缓冲区解码为业务可以使用的POJO对象. 为了方便业务将ByteBuf 解码成业务域POJO 对象, Netty 提供了ByteToMessageDecoder 抽象工具解码类. 用户自定义解码器继承ByteToMessageDecoder, 只需要实现 void decode（ChannelHandler Context ctx, ByteBuf in,List&lt;Object&gt; out） 抽象方法即可完成 ByteBuf 到POJO 对象的解码. 由于ByteToMessageDecoder 并没有考虑TCP 粘包和拆包等场景, 用户自定义解码器的时候需要自己处理”读半包” 的问题. 正因为如此, 大部分场景不会直接继承 ByteToMessageDecoder , 而是继承另外一些更高级的解码器来屏蔽半包的处理。 实际项目中,通常将LengthFieldBasedFrameDecoder 和 ByteToMessageDecoder 组合使用, 前者负责将网络读取的数据报解码为整包消息, 后者负责将整包消息解码成最终的业务对象. 除了和其他解码器组合形成新的解码器之外, ByteToMessageDecoder 也是很多基础解码器的父类, 它的继承关系如下图所示: 下面我们来看源码, ByteToMessageDecoder 类的定义: public abstract class ByteToMessageDecoder extends ChannelInboundHandlerAdapter &amp;#123; &amp;#125; 从源码中可以看出, ByteToMessageDecoder 继承了ChannelInboundHandlerAdapter , 这是一个inbound 类型的handler, 也就是处理流向自身事件的handler, 其次, 该类通过abstract 关键字修饰, 说明是个抽象类, 在我们实际使用的时候, 并不是直接使用这个类, 而是使用其子类, 类定义了解码器的骨架方法, 具体实现逻辑交给子类, 同样, 在半包处理中也是由该类实进行实现的, Netty 中很多解码器都实现了这个类, 并且， 我们也可以通过实现该类进行自定义解码器. 我们重点关注一下该类的cumulation 的这个属性, 它就是有关半包处理的关键属性,从概述中我们知道,Netty 会将不完整的数据包进行保存, 这个数据包就是保存在这个属性中。我们知道ByteBuf 读取完数据会传递channelRead 事件, 传播过程中会调用handler 的channelRead 方法, ByteToMessageDecoder 的channelRead 方法就是编码的关键部分, 我们来看看 channelRead() 方法： @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; if (msg instanceof ByteBuf) &amp;#123; // 简单当分成一个arrayList 对象, 用于盛放解析到的对象 CodecOutputList out = CodecOutputList.newInstance(); try &amp;#123; ByteBuf data = (ByteBuf) msg; // 当前累加器为空, 说明这是第一次从IO流中读取数据 first = cumulation == null; if (first) &amp;#123; // 如果是第一次, 则将累加器赋值为刚读进来的对象. cumulation = data; &amp;#125; else &amp;#123; // 如果不是, 则把当前累加的数据和读进来的数据进行累加. cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data); &amp;#125; // 调用子类的方法进行解析 callDecode(ctx, cumulation, out); &amp;#125; catch (DecoderException e) &amp;#123; throw e; &amp;#125; catch (Throwable t) &amp;#123; throw new DecoderException(t); &amp;#125; finally &amp;#123; if (cumulation != null &amp;&amp; !cumulation.isReadable()) &amp;#123; numReads = 0; cumulation.release(); cumulation = null; &amp;#125; else if (++ numReads >= discardAfterReads) &amp;#123; // We did enough reads already try to discard some bytes so we not risk to see a OOME. // See https://github.com/netty/netty/issues/4275 numReads = 0; discardSomeReadBytes(); &amp;#125; // 记录list 长度 int size = out.size(); decodeWasNull = !out.insertSinceRecycled(); // 向下传播 fireChannelRead(ctx, out, size); out.recycle(); &amp;#125; &amp;#125; else &amp;#123; // 不是ByteBuf 类型的往下传播 ctx.fireChannelRead(msg); &amp;#125; &amp;#125; 这方法比较长, 我带大家一步步剖析, 首先判断如果传来的数据是ByteBuf , 则进入if 块中, CodecOutputList out = CodecOutputList.newInstance(); 这里将当成一个ArrayList 就好, 用于保存解码完成的数据 ByteBuf data = (ByteBuf) msg; 这步将数据转换为 ByteBuf. first = cumulation == null; 表示如果 cumulation == null 则说明没有存储半包数据, 则将当前的数据保存到数据 cumulation 中, 如果 cumulation !=null.说明存储了半包数据, 则通过cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data) 将读取到的数据和原来的数据进行累加, 保存在属性 cumulation 中. 我们看 cumulation 属性的定义: private Cumulator cumulator = MERGE_CUMULATOR; 这里调用了其静态属性 MERGE_CUMULATOR, 我们跟进去: public static final Cumulator MERGE_CUMULATOR = new Cumulator() &amp;#123; @Override public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) &amp;#123; ByteBuf buffer; if (cumulation.writerIndex() > cumulation.maxCapacity() - in.readableBytes() || cumulation.refCnt() > 1) &amp;#123; // Expand cumulation (by replace it) when either there is not more room in the buffer // or if the refCnt is greater then 1 which may happen when the user use slice().retain() or // duplicate().retain(). // // See: // - https://github.com/netty/netty/issues/2327 // - https://github.com/netty/netty/issues/1764 buffer = expandCumulation(alloc, cumulation, in.readableBytes()); &amp;#125; else &amp;#123; buffer = cumulation; &amp;#125; buffer.writeBytes(in); in.release(); return buffer; &amp;#125; &amp;#125;; 这里创建了Cumulator 类型的静态对象, 并重写了cumulate 方法, 这个cumulate 方法 , 就是用于将 ByteBuf 进行拼接的方法. 在方法中, 首先判断 cumulation 是写指针 +in 的可读字节数是否超过了cumulation 的最大长度, 如果超过,则对cumulation 进行扩容, 如果没有超过, 则将其赋值到局部变量 buffer 中。 然后将in 的数据写到buffer 中 , 将in 进行释放, 返回写入数据后的ByteBuf. 回到channelRead 方法, 最后调用callDecode(ctx, cumulation, out) : protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object> out) &amp;#123; try &amp;#123; // 只要累加器中有数据 while (in.isReadable()) &amp;#123; int outSize = out.size(); // 判断当前list 中是否有对象 if (outSize > 0) &amp;#123; // 如果有对象, 则往下传播 fireChannelRead(ctx, out, outSize); // 清空list out.clear(); // Check if this handler was removed before continuing with decoding. // If it was removed, it is not safe to continue to operate on the buffer. // // See: // - https://github.com/netty/netty/issues/4635 // 解码过程中如ctx 被removed 掉就break if (ctx.isRemoved()) &amp;#123; break; &amp;#125; outSize = 0; &amp;#125; // 当前可读数据的长度 int oldInputLength = in.readableBytes(); // 子类实现 // 子类解析, 解析完对象放到out 中 decode(ctx, in, out); // Check if this handler was removed before continuing the loop. // If it was removed, it is not safe to continue to operate on the buffer. // // See https://github.com/netty/netty/issues/1664 if (ctx.isRemoved()) &amp;#123; break; &amp;#125; // list 解析前大小和解析后长度一样(什么都没有解析出来) if (outSize == out.size()) &amp;#123; // 原来可读的长度 == 解析后的可读长度 // 说明没有可读数据(当前累加的数据并没有拼成一个完整的数据包) if (oldInputLength == in.readableBytes()) &amp;#123; // 跳出循环(下次在读取数据才进行后续的解析) break; &amp;#125; else &amp;#123; // 没有解析到数据, 但是进行读取了 continue; &amp;#125; &amp;#125; // out 里面有数据, 但是没有从累加器中读取数据 if (oldInputLength == in.readableBytes()) &amp;#123; throw new DecoderException( StringUtil.simpleClassName(getClass()) + \".decode() did not read anything but decoded a message.\"); &amp;#125; if (isSingleDecode()) &amp;#123; break; &amp;#125; &amp;#125; &amp;#125; catch (DecoderException e) &amp;#123; throw e; &amp;#125; catch (Throwable cause) &amp;#123; throw new DecoderException(cause); &amp;#125; &amp;#125; 首先循环判断传入的ByteBuf 是否有可读的字节, 如果还有可读字节说明没有解码完成, 则循环解析解码, 然后判断集合out 的大小, 如果大小小于1, 说明out 中盛放了解码完成之后的数据, 然后将事件往下传播, 并清空out. 因为我们第一次解码out 是空的, 所以这里并不会进入if 块, 这部分我们稍后分析, 所以继续往下看. 通过int oldInputLength = in.readableBytes() 获取当前的ByteBuf, 其实也就是属性 cumulation 的可读字节数, 这里就是一个备份, 用于比较. 我们继续往下看, decode(ctx, in, out) 方法是最终的解码操作, 这步会读取 cumulation 并且将解码后的数据放入到集合out 中, 在ByteToMessageDecoder 中这个方法是一个抽象方法, 让子类去实现. 我们使用的netty 很多的解码都是继承了ByteToMessageDecoder 并且实现了 decode 方法从而完成了解码操作,同样我们也可以遵循相应的规则进行自定义解码器. 在之后的小节中会讲解netty 定义的解码器, 并剖析相关的实现细节. 继续往下看 if (outSize == out.size()) 这个判断表示解析之前的out 大小和解析之后的out 大小进行比较,如果相同则说明并没有解析出数据， 我们进入到if 块中. if (oldInputLength == in.readableBytes()) 表示cumulation 的可读字节数在解析之前和解析之后是相同的. 说明解码方法中并没有解析数据, 也就是当前的数据并不是一个完整的数据包, 则跳出循环,留给下次解析。 否则说明没有解析出数据, 但是读取了, 所以跳出该次循环进入下次循环. 最后判断if (oldInputLength == in.readableBytes()) 这里代表out 中有数据, 但是并没有从 cumulation 读数据, 说明这个out 的内容是非法的, 直接排除异常. 现在回到chanelRead方法, 我们来关注一下finally 代码块中的内容: if (cumulation != null &amp;&amp; !cumulation.isReadable()) &amp;#123; numReads = 0; cumulation.release(); cumulation = null; &amp;#125; else if (++ numReads >= discardAfterReads) &amp;#123; // We did enough reads already try to discard some bytes so we not risk to see a OOME. // See https://github.com/netty/netty/issues/4275 numReads = 0; discardSomeReadBytes(); &amp;#125; int size = out.size(); decodeWasNull = !out.insertSinceRecycled(); fireChannelRead(ctx, out, size); out.recycle(); 首先判断 cumulation 不为null, 并且没有可读字节, 则将累加器进行释放, 并设置为null. 之后记录out的长度,通过fireChannelRead 将channelRead 事件进行向下传播, 并回收out 对象, 我们跟到fireChannelRead(ctx, out, size) 方法来看代码: static void fireChannelRead(ChannelHandlerContext ctx, CodecOutputList msgs, int numElements) &amp;#123; for (int i = 0; i &lt; numElements; i ++) &amp;#123; ctx.fireChannelRead(msgs.getUnsafe(i)); &amp;#125; &amp;#125; 这里遍历out 集合,并将里面的元素逐个往下传递, 以上就是有关解码的骨架逻辑. 2. LineBasedFrameDecoder 行解码器LineBasedFrameDecoder 是回车换行解码器, 如果用户发送的消息以回车换行符(以\\r\\n 或者直接以\\n 结尾)作为消息结束的标识, 则可以直接使用Netty 的LineBasedFrameDecoder 对消息进行解码, 只需要在进行初始化Netty 服务端或者客户端时将LineBasedFrameDecoder 正确的添加到ChanenlPipeline 中即可, 不需要自己实现一套换行解码器. LineBasedFrameDecoder 的工作原理是它依次遍历ByteBuf 中的可读字节，判断看是否有“\\n”或者“\\r\\n”, 如果有, 就以此位置为结束位置, 从可读索引到结束位置区间的字节就组成了一行. 它是以换行符为结束标识的解码器， 支持携带结束符或者不携带结束符两种解码方式, 同时支持配置单行的最大长度. 如果连续读取到最大长度后仍然没有发现换行符, 就会抛出异常. 同时忽略到之前读取到的异常码流. 防止由于数据报没有携带换行符导致接受到的ByteBuf 无限制积压, 引起系统内存溢出. 它的使用效果如下: 解码之前: 通常情况下，LineBasedFrameDecoder 会和 StringDecoder 配合使用, 组合成按行切换的文本解码器. 对于文本类协议的解析, 文本换行解码器非常实用. 例如对HTTP 消息头的解析、FTP 协议消息的解析等. 下面我们简单给出文本换行符解码器的简单示例: pipeline.addLast(new LineBasedFrameDecoder(1024)); pipeline.addLast(new StringDecoder()); 初始化Channel 的时候,首先将LineBasedFrameDecoder 添加到ChannelPipeline 中, 然后再依次添加字符串解码器StringDecoder,业务handler. 接下来,我们来看 LineBasedFrameDecoder 的源码, LineBasedFrameDecoder 也继承了ByteToMessageDecoder, 首先看其参数定义: public class LineBasedFrameDecoder extends ByteToMessageDecoder &amp;#123; /** Maximum length of a frame we're willing to decode. */ // 数据包的最大长度, 超过该长度会进行丢弃模式 private final int maxLength; /** Whether or not to throw an exception as soon as we exceed maxLength. */ // 超过最大长度是否要抛出异常 private final boolean failFast; // 最终解析的数据包是否带有换行符 private final boolean stripDelimiter; /** True if we're discarding input because we're already over maxLength. */ // 为true 说明当前解码过程为丢弃模式 private boolean discarding; // 丢了多少字节 private int discardedBytes; &amp;#125; 其中的丢弃模式,我们会在源码中看到其中的含义, 我们看其decode() 方法: @Override protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object> out) throws Exception &amp;#123; Object decoded = decode(ctx, in); if (decoded != null) &amp;#123; out.add(decoded); &amp;#125; &amp;#125; 这里的decode() 方法会调用重载的decode() 方法,并将解码后的内容放到out 集合中. 我们跟到 重载的decode() 方法中: protected Object decode(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception &amp;#123; // 找这行的结尾 final int eol = findEndOfLine(buffer); if (!discarding) &amp;#123; if (eol >= 0) &amp;#123; final ByteBuf frame; // 计算从换行到可读字符之间的长度 final int length = eol - buffer.readerIndex(); // 拿到分割长度, 如果是\\r\\n 结尾, 分隔符长度为2 final int delimLength = buffer.getByte(eol) == '\\r'? 2 : 1; // 如果长度大于最大长度 if (length > maxLength) &amp;#123; // 指向换行符之后的可读字符(这段数据完全丢弃) buffer.readerIndex(eol + delimLength); // 传播异常事件 fail(ctx, length); return null; &amp;#125; // 如果这次解析的数据是有效的 // 分隔符是否算在完整的数据包里 // true 为丢弃分隔符 if (stripDelimiter) &amp;#123; // 截取有效长度 frame = buffer.readRetainedSlice(length); // 跳出分隔符的字节 buffer.skipBytes(delimLength); &amp;#125; else &amp;#123; // 包含分隔符 frame = buffer.readRetainedSlice(length + delimLength); &amp;#125; return frame; &amp;#125; else &amp;#123; // 如果没有找到分隔符(非丢弃模式) // 可读字节长度 final int length = buffer.readableBytes(); if (length > maxLength) &amp;#123; // 将当前长度标记为可丢弃的 discardedBytes = length; // 直接将读指针移动到写指针 buffer.readerIndex(buffer.writerIndex()); // 标记为丢弃模式 discarding = true; // 超过最大长度抛出异常 if (failFast) &amp;#123; fail(ctx, \"over \" + discardedBytes); &amp;#125; &amp;#125; // 没有超过, 则直接返回. return null; &amp;#125; &amp;#125; else &amp;#123; // 丢弃模式 if (eol >= 0) &amp;#123; // 找到分隔符 // 当前丢弃的字节(前面已经丢弃的+ 现在丢弃的位置 =写指针) final int length = discardedBytes + eol - buffer.readerIndex(); // 当前换行符长度为多少 final int delimLength = buffer.getByte(eol) == '\\r'? 2 : 1; // 读指针直接移到换行符 + 换行符的长度 buffer.readerIndex(eol + delimLength); // 当前丢弃的字节为0 discardedBytes = 0; // 设置为未丢弃模式 discarding = false; // 丢弃完字节之后触发异常 if (!failFast) &amp;#123; fail(ctx, length); &amp;#125; &amp;#125; else &amp;#123; // 累计已丢弃的字节个数 + 当前可读的长度 discardedBytes += buffer.readableBytes(); // 移动 buffer.readerIndex(buffer.writerIndex()); &amp;#125; return null; &amp;#125; &amp;#125; final int eol = findEndOfLine(buffer) 这里是找当前行的结尾的索引值, 也就 是\\r\\n 或者是\\n： 从上图中不难看出, 如果是以\\n 结尾的, 返回的索引值是\\n 的索引值, 如果是\\n\\r 结尾的, 返回的索引值是\\r 的索引值. 我们看 findEndOfLine(buffer) 方法: private static int findEndOfLine(final ByteBuf buffer) &amp;#123; int i = buffer.forEachByte(ByteProcessor.FIND_LF); if (i > 0 &amp;&amp; buffer.getByte(i - 1) == '\\r') &amp;#123; i--; &amp;#125; return i; &amp;#125; 从上面的代码看到, 通过一个 forEachByte() 方法找到\\n 这个字节, 如果找到了, 并且前面是\\r, 则返回\\r的索引值,否则返回\\n的索引值. 回到重载的decode() 方法, if (!discarding) 判断是否为非丢弃模式, 所以进入if中, if (eol &gt;= 0) 如果找到了换行符， 我们看非丢弃模式下找到换行符的相关逻辑。 final ByteBuf frame; final int length = eol - buffer.readerIndex(); final int delimLength = buffer.getByte(eol) == '\\r'? 2 : 1; if (length > maxLength) &amp;#123; buffer.readerIndex(eol + delimLength); fail(ctx, length); return null; &amp;#125; if (stripDelimiter) &amp;#123; frame = buffer.readRetainedSlice(length); buffer.skipBytes(delimLength); &amp;#125; else &amp;#123; frame = buffer.readRetainedSlice(length + delimLength); &amp;#125; return frame; 首先获取换行符到可读字节之间的长度, 然后拿到换行符的长度, 如果是\\n结尾，那么长度是1, 如果是\\r 结尾, 长度为2. if (length &gt; maxLength) 代表如果长度超过最大长度, 则直接通过 buffer.readerIndex(eol + delimLength) 这种方式, 将读指针指向换行符之后的字节,说明换行符之前的字节需要完全丢弃. 丢弃之后通过fail 方法传播异常, 并返回null, 继续往下看, 走到下一步, 说明解析出来的数据长度没有超过最大长度, 说明是有效数据包. if (stripDelimiter) 表示是否要将分隔符放在完整的数据包里面, 如果是true, 则说明要丢弃分隔符. 然后截取有效长度, 并跳出分隔符长度, 将包含分隔符进行截取. 以上就是非丢弃模式下找到换行符的相关逻辑, 我们再看非丢弃模式下没有找到换行符的相关逻辑. 也就是非丢弃模式下, if (eol &gt;= 0) 中的else 块: final int length = buffer.readableBytes(); if (length > maxLength) &amp;#123; discardedBytes = length; buffer.readerIndex(buffer.writerIndex()); discarding = true; if (failFast) &amp;#123; fail(ctx, \"over \" + discardedBytes); &amp;#125; &amp;#125; return null; 首先通过final int length = buffer.readableBytes() 获取所有的可读字节数, 然后判断可读字节数是否超过了最大值, 如果超过了最大值, 则属性 discardedBytes 标记为这个长度, 代表这段内容要进行丢弃. buffer.readerIndex(buffer.writerIndex()) 这里直接将读指针移动到写指针, 并且将discarding 设置为true, 就是丢弃模式. 如果可读字节没有超过最大长度, 则返回null, 表示什么都没有解析出来. 等着下次解析. 我们再看丢弃模式的处理逻辑, 也就是 if (!discarding) 中的else 块, 首先这里也分为两种情况, 根据if (eol &gt;= 0) 判断是否找到了分隔符, 我们首先来看找到分隔符的解码逻辑。 final int length = buffer.readableBytes(); if (length > maxLength) &amp;#123; discardedBytes = length; buffer.readerIndex(buffer.writerIndex()); discarding = true; if (failFast) &amp;#123; fail(ctx, \"over \" + discardedBytes); &amp;#125; &amp;#125; return null; 如果找到换行符, 则需要将换行符之前的数据全部丢弃掉. final int length = buffer.readableBytes() 这里获取丢弃的字节总数, 也就是之前丢弃的字节数 + 现在需要丢弃的字节数. 然后计算换行符的长度, 如果是\\n 则是1,\\r\\n 则是2. buffer.readerIndex(buffer.writerIndex()) 这里将读指针移动到换行符之后的位置, 然后将discarding 设置为false, 表示当前是非丢弃状态.我们再来看丢弃模式未找到换行符的情况, 也就是丢弃模式下, if (eol &gt;= 0) 中的else块 if (length > maxLength) &amp;#123; discardedBytes = length; buffer.readerIndex(buffer.writerIndex()); discarding = true; if (failFast) &amp;#123; fail(ctx, \"over \" + discardedBytes); &amp;#125; &amp;#125; return null; 首先通过final int length = buffer.readableBytes() 获取所有可读的字节数, 然后判断可读字节数是否超过了最大值, 如果超过最大值, 则属性discardedBytes 标记为这个程度, 代表这段内容要进行丢弃. buffer.readerIndex(buffer.writerIndex()) 这里直接将读指针移动到写指针, 并且将discarding 设置为true, 就是丢弃模式. 如果可读字节没有超过最大长度, 则返回null, 表示什么也没有解析出来,等着下次解析. 我们再看看丢弃模式的处理逻辑,也就是if (!discarding) 的else块, 首先这里也分为两种情况, 根据if (eol &gt;= 0) 判断是否找到了分隔符, 我们首先看找到分隔符的解码逻辑。 final int length = discardedBytes + eol - buffer.readerIndex(); final int delimLength = buffer.getByte(eol) == '\\r'? 2 : 1; buffer.readerIndex(eol + delimLength); discardedBytes = 0; discarding = false; if (!failFast) &amp;#123; fail(ctx, length); &amp;#125; 如果找到换行符, 则需要将换行符之前的数据全部丢弃掉. final int length = discardedBytes + eol - buffer.readerIndex() 这里获取丢弃的字节总数, 也就是之前丢弃的字节数 + 现在丢弃的字节数. 然后计算换行符的长度, 如果是\\n 则是 1, \\r\\n 就是 2。buffer.readerIndex(eol + delimLength) 这里将指针移动到换行符之后的位置, 然后将discarding 设置为false, 表示当前是非丢弃状态，我们再看丢弃模式下未找到换行符的情况, 也就是丢弃模式, if (eol &gt;= 0) 中的else 块: discardedBytes += buffer.readableBytes(); buffer.readerIndex(buffer.writerIndex()); 这里做的事情非常简单, 就是累计丢弃的字节数, 并将读指针移动到写指针, 也就是将数据全部丢弃. 最后在丢弃模式下, decode() 方法返回为null, 代表本次没有解析出任何数据, 以上就是行解析器的相关逻辑. 3. DelimiterBasedFrameDecoder 分隔符解码器DelimiterBasedFrameDecoder 分隔符解码器, 是按照指定分隔符进行解码的解码器, 通过分隔符, 可以将二进制流拆分成完整的数据包，回车换行解码器其实就是一种特殊的DelimiterBasedFrameDecoder 解码器. 分隔符解码器在实际工作中也有实际的应用, 在电信行业,很多简单的文本私有协议, 都是以特殊的分隔符作为消息结束的标识， 特殊是对于那些使用长连接的基于文本的私有协议. 分隔符的指定: 与大家的习惯不同, 分隔符并非以char 或者string 作为构造参数的, 而是ByteBuf,下面我们就结合实际例子给出它的用法。 假设消息是以”$_” 作为分隔符, 服务端或者客户端初始化ChannelPipeline 的代码示例如下: ChannelPipeline pipeline = ch.pipeline(); ByteBuf delimter = Unpooled.copiedBuffer(\"$_\".getBytes()); pipeline.addLast(new DelimiterBasedFrameDecoder(1024, delimter)); pipeline.addLast(new StringDecoder()); 首先将 “$_” 转换为ByteBuf 对象, 作为参数构造器 DelimiterBasedFrameDecoder , 将其添加到ChannelPepeline中, 然后依次添加到字符串解码器(通常用于文本解码)和用户handler, 请注意解码器和Handler 的添加顺序, 如果顺序颠倒, 会导致消息解码失败. DelimiterBasedFrameDecoder 同样继承了ByteToMessageDecoder, 并重写了 decode() 方法, 我们来看其中的一个构造方法: public DelimiterBasedFrameDecoder(int maxFrameLength, ByteBuf delimiter) &amp;#123; this(maxFrameLength, true, delimiter); &amp;#125; 这里参数 maxFrameLength 代表最长长度, delimiter 是个可变参数, 可以说可以支持多个分隔符进行解码,我们进入 decode() 方法： @Override protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object> out) throws Exception &amp;#123; Object decoded = decode(ctx, in); if (decoded != null) &amp;#123; out.add(decoded); &amp;#125; &amp;#125; 这样同样调用了其重载的 decode() 并将其解析好的数据添加到集合list中, 其父类就可以遍历out, 并将内容传播.我们跟到重载 decode() 方法里面: protected Object decode(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception &amp;#123; // 行处理器 if (lineBasedDecoder != null) &amp;#123; return lineBasedDecoder.decode(ctx, buffer); &amp;#125; // Try all delimiters and choose the delimiter which yields the shortest frame. int minFrameLength = Integer.MAX_VALUE; ByteBuf minDelim = null; // 找到最小长度的分隔符(2) for (ByteBuf delim: delimiters) &amp;#123; int frameLength = indexOf(buffer, delim); if (frameLength >= 0 &amp;&amp; frameLength &lt; minFrameLength) &amp;#123; minFrameLength = frameLength; minDelim = delim; &amp;#125; &amp;#125; // 解码(3) // 已经找到分隔符 if (minDelim != null) &amp;#123; int minDelimLength = minDelim.capacity(); ByteBuf frame; // 当前分隔符处于丢弃模式 if (discardingTooLongFrame) &amp;#123; // We've just finished discarding a very large frame. // Go back to the initial state. // 首先设置为非丢弃模式 discardingTooLongFrame = false; // 丢弃 buffer.skipBytes(minFrameLength + minDelimLength); int tooLongFrameLength = this.tooLongFrameLength; this.tooLongFrameLength = 0; if (!failFast) &amp;#123; fail(tooLongFrameLength); &amp;#125; return null; &amp;#125; // 处于非丢弃模式 // 当前找到的数据包, 大于允许的数据包 if (minFrameLength > maxFrameLength) &amp;#123; // Discard read frame. // 当前数据包 + 最小分隔符长度 全部丢弃 buffer.skipBytes(minFrameLength + minDelimLength); // 传递异常信息 fail(minFrameLength); return null; &amp;#125; // 如果是正常的长度 // 解析出来的数据包是否忽略分隔符 if (stripDelimiter) &amp;#123; // 如果不包含分隔符 // 截取 frame = buffer.readRetainedSlice(minFrameLength); // 跳过分隔符 buffer.skipBytes(minDelimLength); &amp;#125; else &amp;#123; // 截取包含分隔符的长度 frame = buffer.readRetainedSlice(minFrameLength + minDelimLength); &amp;#125; return frame; &amp;#125; else &amp;#123; // 如果没有找到分隔符 // 非丢弃模式 if (!discardingTooLongFrame) &amp;#123; // 可读字节大于允许的解析出来的长度 if (buffer.readableBytes() > maxFrameLength) &amp;#123; // Discard the content of the buffer until a delimiter is found. // 将这个长度记下 tooLongFrameLength = buffer.readableBytes(); // 跳过这段长度 buffer.skipBytes(buffer.readableBytes()); // 标记当前处于丢弃状态 discardingTooLongFrame = true; if (failFast) &amp;#123; fail(tooLongFrameLength); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; // Still discarding the buffer since a delimiter is not found. tooLongFrameLength += buffer.readableBytes(); buffer.skipBytes(buffer.readableBytes()); &amp;#125; return null; &amp;#125; &amp;#125; 这里的方法也比较长, 这里通过拆分进行剖析: 行处理器 找到最小长度分隔符 解码 首先来看第一步行处理器: if (lineBasedDecoder != null) &amp;#123; return lineBasedDecoder.decode(ctx, buffer); &amp;#125; 这里首先判断成员变量 lineBasedDecoder 是否为空,如果不为空则直接调用lineBasedDecoder 的decode 方法进行解码, lineBasedDecoder 实际上 LineBasedFrameDecoder 解码器. 这个成员变量, 会在分隔符是\\n 和\\r\\n 的 时候进行初始化, 我们看初始化该属性的构造方法: public DelimiterBasedFrameDecoder( int maxFrameLength, boolean stripDelimiter, boolean failFast, ByteBuf... delimiters) &amp;#123; validateMaxFrameLength(maxFrameLength); if (delimiters == null) &amp;#123; throw new NullPointerException(\"delimiters\"); &amp;#125; if (delimiters.length == 0) &amp;#123; throw new IllegalArgumentException(\"empty delimiters\"); &amp;#125; // 如果是基于行的分割 if (isLineBased(delimiters) &amp;&amp; !isSubclass()) &amp;#123; // 初始化行 处理器 lineBasedDecoder = new LineBasedFrameDecoder(maxFrameLength, stripDelimiter, failFast); this.delimiters = null; &amp;#125; else &amp;#123; this.delimiters = new ByteBuf[delimiters.length]; for (int i = 0; i &lt; delimiters.length; i ++) &amp;#123; ByteBuf d = delimiters[i]; validateDelimiter(d); this.delimiters[i] = d.slice(d.readerIndex(), d.readableBytes()); &amp;#125; lineBasedDecoder = null; &amp;#125; this.maxFrameLength = maxFrameLength; this.stripDelimiter = stripDelimiter; this.failFast = failFast; &amp;#125; 这里 isLineBased(delimiters) 会判断是否是基于行的分割, 跟到isLineBased(delimiters) 方法中: private static boolean isLineBased(final ByteBuf[] delimiters) &amp;#123; // 分隔符长度不为2 if (delimiters.length != 2) &amp;#123; return false; &amp;#125; // 拿到第一个分隔符 ByteBuf a = delimiters[0]; // 拿到第二个分隔符 ByteBuf b = delimiters[1]; if (a.capacity() &lt; b.capacity()) &amp;#123; a = delimiters[1]; b = delimiters[0]; &amp;#125; // 确保 a是/r/n 分割成. 确保b是/n分隔符 return a.capacity() == 2 &amp;&amp; b.capacity() == 1 &amp;&amp; a.getByte(0) == '\\r' &amp;&amp; a.getByte(1) == '\\n' &amp;&amp; b.getByte(0) == '\\n'; &amp;#125; 首先判断长度等于2, 直接返回false. 然后那字额第一个分隔符a 和第二个分隔符b, 然后判断a 的第一个分隔符是不是\\r,a 的第二个分隔符是不是\\n, b 的第一个分隔符是不是\\n，如果都为true, 则条件成立,我们回到decode() 方法中, 看第二步, 找到最小长度的分隔符, 这里最小长度的分隔符, 意思就是从读指针开始, 找到最近的分隔符: for (ByteBuf delim: delimiters) &amp;#123; int frameLength = indexOf(buffer, delim); if (frameLength >= 0 &amp;&amp; frameLength &lt; minFrameLength) &amp;#123; minFrameLength = frameLength; minDelim = delim; &amp;#125; &amp;#125; 这里会遍历所有的分隔符, 然后找到每个分隔符到读指针到数据包长度, 然后通过if 判断, 找到长度最小的数据包的长度, 然后保存当前数据包的分隔符, 如下图: 这里假设A 和B 同为分隔符, A 分隔符到读指针的长度小于B 分隔符到读指针的长度, 这里会找到最小的分隔符A , 分隔符的最小长度, 就是 readIndex 到A 的长度, 我们继续看第三步, 解码. if (minDelim != null) 表示已经找到最小长度分隔符, 我们继续看if 块中的逻辑. int minDelimLength = minDelim.capacity(); ByteBuf frame; if (discardingTooLongFrame) &amp;#123; // We've just finished discarding a very large frame. // Go back to the initial state. discardingTooLongFrame = false; buffer.skipBytes(minFrameLength + minDelimLength); int tooLongFrameLength = this.tooLongFrameLength; this.tooLongFrameLength = 0; if (!failFast) &amp;#123; fail(tooLongFrameLength); &amp;#125; return null; &amp;#125; if (minFrameLength > maxFrameLength) &amp;#123; // Discard read frame. buffer.skipBytes(minFrameLength + minDelimLength); fail(minFrameLength); return null; &amp;#125; if (stripDelimiter) &amp;#123; frame = buffer.readRetainedSlice(minFrameLength); buffer.skipBytes(minDelimLength); &amp;#125; else &amp;#123; frame = buffer.readRetainedSlice(minFrameLength + minDelimLength); &amp;#125; return frame; if (discardingTooLongFrame) 表示当前是否处于非丢弃模式, 如果是丢弃模式, 则进入if 块, 因为第一个不是丢弃模式, 所这里先分析if 块后面的逻辑, if (minFrameLength &gt; maxFrameLength) 这里是判断当前找到的数据包的长度大于最大长度, 这里的最大长度使我们创建解码器的时候设置的, 如果超过了最大长度, 就通过buffer.skipBytes(minFrameLength + minDelimLength) 方法, 跳过数据包 + 分隔符的长度, 也就是将这部分数据进行完全丢弃, 继续往下看,如果长度不超过最大允许长度, 就通过if (stripDelimiter) 判断解析出来的数据包是否包含分隔符, 如果不包含分隔符， 则截取数据包的长度,跳过分隔符. 我们回头看if (discardingTooLongFrame) 中的if 块中的逻辑, 也就是丢弃模式. 首先将 discardingTooLongFrame 设置为false, 标记为非丢弃模式. 然后通过buffer.skipBytes(minFrameLength + minDelimLength) 将数据包 + 分隔符长度的字节数跳过, 也就是进行丢弃. 之后在进行抛出异常. 分析完成了找到分隔符之后的丢弃模式和非丢弃模式之后的逻辑处理. 我们在分析没找到分隔符的逻辑处理, 也就是if (minDelim != null) 中的else 块: if (!discardingTooLongFrame) &amp;#123; if (buffer.readableBytes() > maxFrameLength) &amp;#123; // Discard the content of the buffer until a delimiter is found. tooLongFrameLength = buffer.readableBytes(); buffer.skipBytes(buffer.readableBytes()); discardingTooLongFrame = true; if (failFast) &amp;#123; fail(tooLongFrameLength); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; // Still discarding the buffer since a delimiter is not found. tooLongFrameLength += buffer.readableBytes(); buffer.skipBytes(buffer.readableBytes()); &amp;#125; return null; 首先通过if (!discardingTooLongFrame) 判断是否为丢弃模式, 如果是, 则进入if 块. 在if 块中, 首先通过if (buffer.readableBytes() &gt; maxFrameLength) 判断当前可读字节是否大于最大允许的长度, 如果大于最大允许的长度, 则将可读字节数设置到tooLongFrameLength 的属性中, 代表丢弃的字节数 , 然后通过 buffer.skipBytes(buffer.readableBytes()) 将累计器中的所有的可读的字节进行丢弃, 最后将discardingTooLongFrame 设置为true, 也就是丢弃模式, 之后抛出异常. 如果if (!discardingTooLongFrame) 为false , 也就是当前处于丢弃模式, 则追加tooLongFrameLength 也就是丢弃的字节数的长度, 并通过buffer.skipBytes(buffer.readableBytes()) 将所有的字节进行丢弃. 以上就是分隔符解码的相关逻辑. 4. FixedLengthFrameDecoder 固定长度解码器FixedLengthFrameDecoder 固定长度解码器, 他能够按照指定的长度对消息进行自动解码，开发者不需要考虑TCP 的粘包/拆包 等问题, 非常实用. 对于定长长度, 如果消息实际长度小于定长, 则往往会进行补位操作,它在一定程度上导致了空间和资源的浪费。 但是它的优点也非常明显， 编解码比较简单, 因此在实际项目中有一定的应用场景. 利用FixedLengthFrameDecoder 解码器, 无论一次接收到多少数据报, 它都会按照构造函数中的设置的固定长度进行解码，如果是半包消息, FixedLengthFrameDecoder 会缓存半包消息并等到下个包到达后进行拼包, 直到读取完第一个完整的包. 假设单条消息的长度为20字节，使用FixedLengthFrameDecoder 解码器的效果如下： 来看其类的定义: public class FixedLengthFrameDecoder extends ByteToMessageDecoder &amp;#123; // 长度大小 private final int frameLength; /** * Creates a new instance. * * @param frameLength the length of the frame */ public FixedLengthFrameDecoder(int frameLength) &amp;#123; if (frameLength &lt;= 0) &amp;#123; throw new IllegalArgumentException( \"frameLength must be a positive integer: \" + frameLength); &amp;#125; // 保存当前 frameLength this.frameLength = frameLength; &amp;#125; @Override protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object> out) throws Exception &amp;#123; // 通过ByteBuf 去解码, 解码到对象后添加到out 上 Object decoded = decode(ctx, in); if (decoded != null) &amp;#123; // 将解析到的ByteBuf 添加到对象里面 out.add(decoded); &amp;#125; &amp;#125; /** * Create a frame out of the &amp;#123;@link ByteBuf&amp;#125; and return it. * * @param ctx the &amp;#123;@link ChannelHandlerContext&amp;#125; which this &amp;#123;@link ByteToMessageDecoder&amp;#125; belongs to * @param in the &amp;#123;@link ByteBuf&amp;#125; from which to read data * @return frame the &amp;#123;@link ByteBuf&amp;#125; which represent the frame or &amp;#123;@code null&amp;#125; if no frame could * be created. */ protected Object decode( @SuppressWarnings(\"UnusedParameters\") ChannelHandlerContext ctx, ByteBuf in) throws Exception &amp;#123; // 字节是否小于这个固定长度 if (in.readableBytes() &lt; frameLength) &amp;#123; return null; &amp;#125; else &amp;#123; // 当前累计器中截取这个长度的数值 return in.readRetainedSlice(frameLength); &amp;#125; &amp;#125; &amp;#125; 我们看到FixedLengthFrameDecoder 类继承了ByteToMessageDecoder , 重写了 decode() 方法,这个类只有一个属性叫 frameLength, 并在构造器中初始化了这个属性。 再看decode() 方法, 在 decode() 方法中又调用了自身另一个重载的 decode() 方法进行解析, 解析出来后的数据放在集合out 中. 再看重载的decode()方法, 重载的decode() 方法中首先判断垒机器的字节数是否小于固定长度, 如果小于固定长度则返回null, 代表不是一个完整的数据包. 直接返回null. 如果大于等于固定长度, 则直接从累加器中截取这个长度的数值in.readRetainedSlice(frameLength) 会返回一个新的截取后的ByteBuf, 并将原来的累计器读指针后移frameLength 字节. 如果累加器中还有数据, 则会通过ByteToMessageDecoder 中的callDecode() 方法里while 循环的方式, 继续进行解码。 这样, 就是实现了固定长度的解码工作. 5. LengthFieldBasedFrameDecoder 通用解码器了解TCP 通信机制的都知道TCP底层的粘包和拆包, 当我们在接收消息的时候, 显示不能认为读取到的报文就是个整包消息, 热别是对于采用非阻塞IO 和长连接通信的程序. 如何区分一个整包消息, 通常有如下4种做法: 规定长度: 例如每120个字节代表一个整包消息, 不足的前面补位.解码器在处理这类定长消息的时候比较简单, 每次读取到指定的长度的字节后再进行解码。 通过回车换行符区分消息,例如HTTP协议. 这类区分消息的方式多用于文本协议. 通过特定的分隔符区分整包消息 通过在协议头/消息头 中设置长度字段来标识整包消息. 前三种解码器之前我们已经做了详细介绍, 下面让我们来一起学习一下最后的一种通用解码器 LengthFieldBasedFrameDecoder . 大多数的协议(私有/公有) ,协议头中会携带长度字段, 用于标识消息体或者整包消息的长度， 例如SMPP、HTTP协议. 由于基于长度解码需求的通用性, 以及为了降低用户的协议开发难度, Netty 提供了LengthFieldBasedFrameDecoder , 自动屏蔽了TCP底层的粘包/拆包问题, 只需要传入正确的参数, 即可轻松解决”读半包”问题. 下面我们看看如何通过参数组合的不同来实现不同的”半包”读取策略. 第一种常用的方式是消息的第一个字段是长度字段, 后面是消息体, 消息头中只包含一个长度字段.它的消息结构定义如图所示： 使用以下参数组合进行解码: lengthFieldOffset = 0 lengthFieldLength = 2 lengthAdjustment = 0 initialBytesToStrip = 0 解码后的字段缓冲区内容如图所示: 通过 ByteBuf.readableBytes() 方法我们可以获取当前消息的长度, 所以解码后的字节缓冲区可以不携带长度字段, 由于长度字段在起始位置并且长度为2, 所以将initialBytesToStrip 设置为2, 参数组合修改为: lengthFieldOffset = 0 lengthFieldLength = 2 lengthAdjustment = 0 initialBytesToStrip = 2 解码后的字节缓冲区内容如下图所示: 解码后的字节缓冲区丢弃了长度字段, 仅仅包含消息体,对于大多数的协议, 解码之后消息长度没有用户,因此可以丢弃. 在大多数的应用场景中，长度字段仅用来标识消息体的长度,这类协议通常由消息长度字段 + 消息体组成, 如上图所示的几个例子. 但是, 对于某些协议,长度字段还包含了消息头的长度。 在这种应用场景中, 往往需要使用lengthAdjustment 进行修正. 由于整个消息(包含消息头) 的长度往往大于消息体的长度, 所以lengthAdjustment 为负数 . 下图展示了通过指定的lengthAdjustment 字段来包含消息头的长度. lengthFieldOffset = 0 lengthFieldLength = 2 lengthAdjustment = -2 initialBytesToStrip = 0 解码之前的码流: 解码之后的码流: 由于协议种类繁多, 并不是所有的协议都将长度字段放在消息头的首位, 当标识消息长度的字段位于消息头的中间或者尾部的时候, 需要使用lengthFieldOffset 字段进行标识, 下面的参数组合给出来了如何解决消息长度字段不在首位的问题: lengthFieldOffset = 2 lengthFieldLength = 3 lengthAdjustment = 0 initialBytesToStrip = 0 lengthFieldOffset 表示长度字段在消息头中偏移的字节数, lengthFieldLength 表示长度字段自身的长度,解码效果如下: 解码之前: 解码之后: 由于消息头1的长度为2, 所以长度字段的偏移量为2 . 消息长度字段Length 为3, 所以lengthFieldLength 值为3. 由于长度字段仅仅标识消息体的长度, 所以lengthAdjustment 和initialBytesToStrip 都为0 最后一种场景是长度字段夹在两个消息头之间或者长度字段位于消息头的中间,前后都有其他消息头字段, 在这种场景下如果想忽略长度字段以及其前面的其他消息头字段， 则可以通过initialBytesToStrip 参数来跳过要忽略的字节长度, 它的组合配置示意如下: lengthFieldOffset = 1 lengthFieldLength = 2 lengthAdjustment = 1 initialBytesToStrip = 3 解码之前的码流(16字节)： 解码之后的码流(13字节): 由于HDR1的长度为1, 所以字段长度的偏移量lengthFieldOffset 为1 , 长度字段为2个字节, 所以lengthFieldLength 为2. 由于字段长度为消息体的长度, 解码后如果携带消息头中的字段, 则需要使用lengthAdjustment 进行调整, 此处它的值为1 , 代表的是HDR2的长度, 最后由于解码后的长度要忽略长度字段和HDR1部分, 所以lengthAdjustment 为3. 解码后的结果为13个字节, HDR1和Length 字段都被忽略. 事实上, 通过4个参数的组合， 可以达到不同的解码效果, 用户在使用过程中可以通过业务的实际情况灵活的进行调整. 由于TCP存在粘包和组包问题, 所以通常i情况下需要用户自己处理半包问题，利用LengthFieldBasedFrameDecoder 解码器可以自动解决半包问题， 它的习惯用户如下: pipeline.addLast(\"frameDecoder\", new LengthFieldBasedFrameDecoder(65536,0,2)); 在pipeline 中增加 LengthFieldBasedFrameDecoder 解码器, 指定正确的参数组合， 它可以将Netty的ByteBuf 解码成整包消息, 后面的用户解码器拿到的就是完整的包, 按照正常的逻辑进行解码就可以. 不再需要考虑额外的 “读半包”问题, 降低了用户的开发难度. 4. Netty 编码器原理和数据输出Netty 默认提供了丰富的编解码框架供用户集成使用, 我们只对较常用的Java 序列化编码器进行分析, 其他的编码器实现大同小异. 其实编码器和解码器比较类似, 编码器也是一个handler, 并且属于outbounfHandle , 就是将准备发出来的数据进行拦截, 拦截之后进行相应的处理之后再进行再次发送处理, 如果理解了解码器， 那么编码器的相关内容理解器来就比较容易了. 1. writeAndFlush 事件传播在学习pipeline 的时候, 学到了write事件的传播过程, 但是在实际使用过程中, 我们通常不会调用channel 的write方法, 因为该方法只会写入到发送数据的缓存中, 并不会直接写入到channel, 如果想写入到channel , 还需要调用flush方法. 在实际使用过程中, 我们用的更多的还是writeAndFlush 方法，这方法既能将数据写入到发送缓冲区中, 还能刷新到channe中, 我们看一个简单的使用场景: public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; ctx.channel().writeAndFlush(\"test data\"); &amp;#125; 这个地方大家肯定不陌生， 通过这种方式, 可以将数据发送到channel中, 对方可以收到响应. 简单回顾一下跟到 writeAndFlush 方法中, 首先会走到AbstractChannel 的writeAndFlush 方法 @Override public ChannelFuture writeAndFlush(Object msg) &amp;#123; return pipeline.writeAndFlush(msg); &amp;#125; 继续跟到DefaultChannelPipeline 的writeAndFlush(）方法: @Override public final ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) &amp;#123; return tail.writeAndFlush(msg, promise); &amp;#125; 我们看到writeAndFlush 是从tail 节点开始传播的, 继续跟到AbstractChannelHandlerContext 的 writeAndFlush()中： @Override public ChannelFuture writeAndFlush(Object msg) &amp;#123; return writeAndFlush(msg, newPromise()); &amp;#125; 继续跟: @Override public ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) &amp;#123; if (msg == null) &amp;#123; throw new NullPointerException(\"msg\"); &amp;#125; if (!validatePromise(promise, true)) &amp;#123; ReferenceCountUtil.release(msg); // cancelled return promise; &amp;#125; write(msg, true, promise); return promise; &amp;#125; 继续跟进write() 方法: private void write(Object msg, boolean flush, ChannelPromise promise) &amp;#123; AbstractChannelHandlerContext next = findContextOutbound(); final Object m = pipeline.touch(msg, next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &amp;#123; if (flush) &amp;#123; next.invokeWriteAndFlush(m, promise); &amp;#125; else &amp;#123; next.invokeWrite(m, promise); &amp;#125; &amp;#125; else &amp;#123; AbstractWriteTask task; if (flush) &amp;#123; task = WriteAndFlushTask.newInstance(next, m, promise); &amp;#125; else &amp;#123; task = WriteTask.newInstance(next, m, promise); &amp;#125; safeExecute(executor, task, promise, m); &amp;#125; &amp;#125; 这里的逻辑是找到下一个节点, 因为 writeAndFlush 是从tail 节点开始的, 并且是outBound 的事件, 所以这里会找到tail、节点的上一个 outBoundHandler, 有可能是编码器, 也有可能是我们自己业务处理的handler. if (executor.inEventLoop()) 判断是否为eventLoop 线程, 如果不是, 则封装成task 通过NioEventLoop 异步执行, 我们这里按照eventLoop线程分析。 首先, 这里通过flush 判断是否调用了flush, 这里显然是true, 因为我们调用的方法是writeAndFlush (), 我们跟到invokeWriteAndFlush中:、 private void invokeWriteAndFlush(Object msg, ChannelPromise promise) &amp;#123; if (invokeHandler()) &amp;#123; invokeWrite0(msg, promise); invokeFlush0(); &amp;#125; else &amp;#123; writeAndFlush(msg, promise); &amp;#125; &amp;#125; 这里就真相大白了, 其实在writeAndFlush () 方法中, 首先调用write , write 完成之后会再调用flush方法进行刷新,首先跟到invokeWrite0() 方法中: private void invokeWrite0(Object msg, ChannelPromise promise) &amp;#123; try &amp;#123; ((ChannelOutboundHandler) handler()).write(this, msg, promise); &amp;#125; catch (Throwable t) &amp;#123; notifyOutboundHandlerException(t, promise); &amp;#125; &amp;#125; 该方法就是调用当前handler 的write 方法，如果当前handler 中write 方法是继续往下传播, 会在继续传播写事件, 直到传播到head节点，最后会走到HeadContext 的write 方法， 跟到HeadContext 的write 方法: @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &amp;#123; unsafe.write(msg, promise); &amp;#125; 这里通过当前channel 的unsafe方法将当前消息写到缓存中, 回到 invokeWriteAndFlush() 方法中:、 private void invokeWriteAndFlush(Object msg, ChannelPromise promise) &amp;#123; if (invokeHandler()) &amp;#123; invokeWrite0(msg, promise); invokeFlush0(); &amp;#125; else &amp;#123; writeAndFlush(msg, promise); &amp;#125; &amp;#125; 我们再看invokeFlush0() 方法：、 private void invokeFlush0() &amp;#123; try &amp;#123; ((ChannelOutboundHandler) handler()).flush(this); &amp;#125; catch (Throwable t) &amp;#123; notifyHandlerException(t); &amp;#125; &amp;#125; 同样这里会调用当前handler的flush方法, 如果当前的handler的flush方法是继续传播flush事件, 则flush事件会继续往下传播, 直到之后调用head节点的flush事件. 跟到HeadContext 的flush方法中： @Override public void flush(ChannelHandlerContext ctx) throws Exception &amp;#123; unsafe.flush(); &amp;#125; 这里同样会通过当前channel 的unsafe对象通过调用flush方法将缓存的数据刷新到channel中。 以上就是writeAndFlush 的相关逻辑. 2. MessageToByteEncoder 抽象编码器同解码器一样, 编码器中也有一个抽象类MessageToByteEncoder,其中定义了编码器的骨架方法, 具体编码逻辑交给子类实现,解码器同样有个handler, 将写入的数据进行截取处理. 我们将学习pipelie的时候知道，写数据的时候会传递write 事件, 传递过程中会调用handler 的write方法, 所以编码器可以重写write方法, 将数据编码成二进制字节流然后再传递write事件, 首先来看MessageToByteEncoder 的类声明: MessageToByteEncoder 负责将POJO 对象编码成ByteBuf, 用户的编码器继承MessageToByteEncoder, 实现void encode(ChannelHandlerContext ctx, I msg, ByteBuf out) 接口, 示例代码如下: public class IntegerEncoder extends MessageToByteEncoder&lt;Integer> &amp;#123; @Override protected void encode(ChannelHandlerContext ctx, Integer msg, ByteBuf out) throws Exception &amp;#123; out.writeInt(msg); &amp;#125; &amp;#125; 它的实现原理如下: 调用write操作的时候，首先判断当前编码器是否支持需要发送的消息，如果不支持则直接透传, 如果支持则判断缓冲区的类型, 对于直接内存分配ioBuffer（堆外内存），对于堆内存通过headBuffer 方法分配, 源码如下： @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &amp;#123; ByteBuf buf = null; try &amp;#123; if (acceptOutboundMessage(msg)) &amp;#123; @SuppressWarnings(\"unchecked\") I cast = (I) msg; buf = allocateBuffer(ctx, cast, preferDirect); try &amp;#123; encode(ctx, cast, buf); &amp;#125; finally &amp;#123; ReferenceCountUtil.release(cast); &amp;#125; if (buf.isReadable()) &amp;#123; ctx.write(buf, promise); &amp;#125; else &amp;#123; buf.release(); ctx.write(Unpooled.EMPTY_BUFFER, promise); &amp;#125; buf = null; &amp;#125; else &amp;#123; ctx.write(msg, promise); &amp;#125; &amp;#125; catch (EncoderException e) &amp;#123; throw e; &amp;#125; catch (Throwable e) &amp;#123; throw new EncoderException(e); &amp;#125; finally &amp;#123; if (buf != null) &amp;#123; buf.release(); &amp;#125; &amp;#125; &amp;#125; 编码使用的缓冲区分配完成后, 调用encode() 抽象方法进行编码, 它的子类负责具体实现: protected abstract void encode(ChannelHandlerContext ctx, I msg, ByteBuf out) throws Exception; 编码完成后, 调用ReferenceCountUtil 的release(cast) 方法释放编码对象msg, 对编码后的ByteBuf 进行以下判断: 如果缓冲区包含可发送的字节，则调用ChannelHandlerContext 的write方法发送ByteBuf. 如果缓冲区中没有包含可写的字节, 则需要释放编码后的ByteBuf, 写入一个空的ByteBuf 到ChannelHandlerContext 中. 发送操作完成后, 在方法退出之前释放编码缓冲区中的ByteBuf 对象. 3. 写入Buffer 队列我们知道， writeAndFlush 方法其实最终会调用到write和flush方法， write方法最终会传递到head节点，调用HeadContext 的write方法: @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &amp;#123; unsafe.write(msg, promise); &amp;#125; 这里通过unsafe 的write方法, 将消息写入到缓存中, 我们跟到AbstractUnsafe 的write方法: @Override public final void write(Object msg, ChannelPromise promise) &amp;#123; assertEventLoop(); // 负责缓冲进来的ByteBuf ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null) &amp;#123; // If the outboundBuffer is null we know the channel was closed and so // need to fail the future right away. If it is not null the handling of the rest // will be done in flush0() // See https://github.com/netty/netty/issues/2362 safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION); // release message now to prevent resource-leak ReferenceCountUtil.release(msg); return; &amp;#125; int size; try &amp;#123; // 非堆外内存转换为堆外内存 msg = filterOutboundMessage(msg); size = pipeline.estimatorHandle().size(msg); if (size &lt; 0) &amp;#123; size = 0; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; safeSetFailure(promise, t); ReferenceCountUtil.release(msg); return; &amp;#125; // 插入写队列 outboundBuffer.addMessage(msg, size, promise); &amp;#125; 首先看ChannelOutboundBuffer outboundBuffer = this.outboundBuffer ChannelOutboundBuffer 的功能就是缓存写入的ByteBuf, 我们继续看 try块中的 msg = filterOutboundMessage(msg) , 这步的意思就是将非堆外内存转换为堆内内存, filterOutboundMessage 方法最终会调用到AbstractNioByteChannel的 filterOutboundMessage方法 : @Override protected final Object filterOutboundMessage(Object msg) &amp;#123; if (msg instanceof ByteBuf) &amp;#123; ByteBuf buf = (ByteBuf) msg; if (buf.isDirect()) &amp;#123; return msg; &amp;#125; return newDirectBuffer(buf); &amp;#125; if (msg instanceof FileRegion) &amp;#123; return msg; &amp;#125; throw new UnsupportedOperationException( \"unsupported message type: \" + StringUtil.simpleClassName(msg) + EXPECTED_TYPES); &amp;#125; 首先判断msg 是否为ByteBuf 对象, 如果是, 判断是否为堆外内存, 如果是堆外内存, 则直接返回. 否则通过return newDirectBuffer(buf) 这种方式转化为堆外内存。 回到write 方法中, outboundBuffer.addMessage(msg, size, promise) 将已经转换为堆外内存的msg 插入到写队列, 我们跟到addMessage() 方法当中,这是 ChannelOutboundBuffer 中的方法： public void addMessage(Object msg, int size, ChannelPromise promise) &amp;#123; Entry entry = Entry.newInstance(msg, size, total(msg), promise); if (tailEntry == null) &amp;#123; flushedEntry = null; tailEntry = entry; &amp;#125; else &amp;#123; Entry tail = tailEntry; tail.next = entry; tailEntry = entry; &amp;#125; if (unflushedEntry == null) &amp;#123; unflushedEntry = entry; &amp;#125; // increment pending bytes after adding message to the unflushed arrays. // See https://github.com/netty/netty/issues/1619 incrementPendingOutboundBytes(size, false); &amp;#125; 首先通过Entry entry = Entry.newInstance(msg, size, total(msg), promise) 的方式将msg 封装成entry, 然后通过调整tailEntry, flushedEntry, unflushedEntry 这三个指针, 完成entry 的添加。 这三个指针均为ChannelOutboundBuffer 的成员变量: flushedEntry 指向第一个被flush 的entry unflushedEntry 指向第一个未被flush 的entry 也就是说, 从 flushedEntry 到unflushedEntry 之前的entry, 都是被已经被flush的entry. tailEntry 指向最后一个entry, 也就是从unflushedEntry 到tailEntry 之间的entry 都是没flush 的entry. 我们回到代码中, 创建了entry 之后首先判断尾指针是否为空, 在第一个添加的时候, 均是空, 所以会将flushedEntry 设置为null, 并且将尾指针设置为当前创建的entry, 最后判断unflushedEntry 是否为空, 如果第一个添加这里为空, 所以这里将unflushedEntry 设置为新创建的entry, 第一次添加如下图所示: 如果不是第一次调用write 方法, 则会进入if (tailEntry == null) 中的else 块 Entry tail = tailEntry 这里tail 就是当前尾节点 tail.next = entry 代表尾节点的下一个节点指向新的创建的entry tailEntry = entry 将尾节点也指向entry 这样就完成了添加操作, 其实就是将新创建的节点追加到原来的尾节点之后, 第二次添加if (unflushedEntry == null) 会返回false, 所以不会进入if 块. 第二次添加之后指针的指向情况如下图所示: 以后每次调用write, 如果没有调用flush的话都会在尾节点之后进行追加. 回到代码中, 看这一步incrementPendingOutboundBytes(size, false); 这步时统计当前有多少字节需要被写出, 我们跟到这个方法中: private void incrementPendingOutboundBytes(long size, boolean invokeLater) &amp;#123; if (size == 0) &amp;#123; return; &amp;#125; long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size); if (newWriteBufferSize > channel.config().getWriteBufferHighWaterMark()) &amp;#123; setUnwritable(invokeLater); &amp;#125; &amp;#125; 看这一步 long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size); TOTAL_PENDING_SIZE_UPDATER 表示当前缓冲区还有多少戴写的字节， addAndGet 就是将当前的ByteBuf 的长度进行累加， 累加到newWriteBufferSize 中, 在继续看判断if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) 表示写buffer 的高水位值, 默认为64 KB,也就是说些buffer 的最大长度不能超过64KB,如果超过了64KB， 则会调用setUnwritable(invokeLater); 方法中: private void setUnwritable(boolean invokeLater) &amp;#123; for (;;) &amp;#123; final int oldValue = unwritable; final int newValue = oldValue | 1; if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) &amp;#123; if (oldValue == 0 &amp;&amp; newValue != 0) &amp;#123; fireChannelWritabilityChanged(invokeLater); &amp;#125; break; &amp;#125; &amp;#125; &amp;#125; 这里通过自旋和cas操作, 传播一个ChannelWritabilityChanged 事件, 最终会调用 handler 的ChannelWritabilityChanged 方法进行处理, 以上就是写buffer 的相关逻辑. 4. 刷新buffer 队列我们知道flush方法通过事件传递, 最终会传递到HeadContext 的flush 方法: @Override public void flush(ChannelHandlerContext ctx) throws Exception &amp;#123; unsafe.flush(); &amp;#125; 这里最终会调用AbstractUnsafe 的 flush方法： @Override public final void flush() &amp;#123; assertEventLoop(); ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null) &amp;#123; return; &amp;#125; outboundBuffer.addFlush(); flush0(); &amp;#125; 这里首先也是拿到ChannelOutboundBuffer对象，然后我们看这一步: outboundBuffer.addFlush(); 这一步同样是调整了ChannelOutboundBuffer 的指针, 跟进addFlush方法: public void addFlush() &amp;#123; // There is no need to process all entries if there was already a flush before and no new messages // where added in the meantime. // // See https://github.com/netty/netty/issues/2577 Entry entry = unflushedEntry; if (entry != null) &amp;#123; if (flushedEntry == null) &amp;#123; // there is no flushedEntry yet, so start with the entry flushedEntry = entry; &amp;#125; do &amp;#123; flushed ++; if (!entry.promise.setUncancellable()) &amp;#123; // Was cancelled so make sure we free up memory and notify about the freed bytes int pending = entry.cancel(); decrementPendingOutboundBytes(pending, false, true); &amp;#125; entry = entry.next; &amp;#125; while (entry != null); // All flushed so reset unflushedEntry unflushedEntry = null; &amp;#125; &amp;#125; 首先声明一个entry 指向unflushedEntry, 也就是第一个未flush 的entry. 通常情况下, unflushedEntry 是不为空的, 所以进入if, 再次刷新前flushedEntry通常为空, 所以会执行到flushedEntry = entry;, 也就是 flushedEntry 指向entry, 经过上述操作， 缓存区的指针情况如图所示: 然后通过do-while 不断寻找unflushedEntry 后面的节点, 直到没有节点为止, flushed 自增代表需要刷新多少节点.循环中我们关注这一步: decrementPendingOutboundBytes(pending, false, true); 这一步也是统计缓存区中 的字节数, 这里要减掉刷新后的字节数, 我们跟到方法中: private void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) &amp;#123; if (size == 0) &amp;#123; return; &amp;#125; long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size); if (notifyWritability &amp;&amp; newWriteBufferSize &lt; channel.config().getWriteBufferLowWaterMark()) &amp;#123; setWritable(invokeLater); &amp;#125; &amp;#125; 同样 TOTAL_PENDING_SIZE_UPDATER 代表缓冲区的字节数, 这里的addAndGet 中参数是-size, 也就是减掉size 的长度, 再看if (notifyWritability &amp;&amp; newWriteBufferSize &lt; channel.config().getWriteBufferLowWaterMark()) getWriteBufferLowWaterMark() 代表写buffer 的第几位值, 也就是32. 如果写buffer 的长度小于这个数, 就通过setWritable 方法设置写状态, 也就是通道由原来的不可写改成可写. 回到addFlush() 方法，遍历do-while 循环结束后, 将unflushedEntry 指为空, 代表所有的entry 都是可写的, 经过上述操作, 缓冲区的指针情况如下图所示: 回到AbstractUnsafe 的flush 方法, 指针调整完之后, 我们回到flush0 方法中: protected void flush0() &amp;#123; if (inFlush0) &amp;#123; // Avoid re-entrance return; &amp;#125; final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null || outboundBuffer.isEmpty()) &amp;#123; return; &amp;#125; inFlush0 = true; // Mark all pending write requests as failure if the channel is inactive. if (!isActive()) &amp;#123; try &amp;#123; if (isOpen()) &amp;#123; outboundBuffer.failFlushed(FLUSH0_NOT_YET_CONNECTED_EXCEPTION, true); &amp;#125; else &amp;#123; // Do not trigger channelWritabilityChanged because the channel is closed already. outboundBuffer.failFlushed(FLUSH0_CLOSED_CHANNEL_EXCEPTION, false); &amp;#125; &amp;#125; finally &amp;#123; inFlush0 = false; &amp;#125; return; &amp;#125; try &amp;#123; doWrite(outboundBuffer); &amp;#125; catch (Throwable t) &amp;#123; if (t instanceof IOException &amp;&amp; config().isAutoClose()) &amp;#123; /** * Just call &amp;#123;@link #close(ChannelPromise, Throwable, boolean)&amp;#125; here which will take care of * failing all flushed messages and also ensure the actual close of the underlying transport * will happen before the promises are notified. * * This is needed as otherwise &amp;#123;@link #isActive()&amp;#125; , &amp;#123;@link #isOpen()&amp;#125; and &amp;#123;@link #isWritable()&amp;#125; * may still return &amp;#123;@code true&amp;#125; even if the channel should be closed as result of the exception. */ close(voidPromise(), t, FLUSH0_CLOSED_CHANNEL_EXCEPTION, false); &amp;#125; else &amp;#123; outboundBuffer.failFlushed(t, true); &amp;#125; &amp;#125; finally &amp;#123; inFlush0 = false; &amp;#125; &amp;#125; if (inFlush0) 表示判断当前flush 是否在进行中, 如果在进行中, 则返回. 避免重复进入. 我们重点关注 doWrite(outboundBuffer) 方法, 跟到AbstractNioByteChannel 的doWrite() 方法: protected void doWrite(ChannelOutboundBuffer in) throws Exception &amp;#123; int writeSpinCount = -1; boolean setOpWrite = false; for (;;) &amp;#123; // 每次拿到当前节点 Object msg = in.current(); if (msg == null) &amp;#123; // Wrote all messages. clearOpWrite(); // Directly return here so incompleteWrite(...) is not called. return; &amp;#125; if (msg instanceof ByteBuf) &amp;#123; // 转换成ByteBuf ByteBuf buf = (ByteBuf) msg; // 如果没有可写的值 int readableBytes = buf.readableBytes(); if (readableBytes == 0) &amp;#123; // 移除 in.remove(); continue; &amp;#125; boolean done = false; long flushedAmount = 0; if (writeSpinCount == -1) &amp;#123; writeSpinCount = config().getWriteSpinCount(); &amp;#125; for (int i = writeSpinCount - 1; i >= 0; i --) &amp;#123; // 将buf 写入到socket中 // localFlushedAmount 代表向jdk 底层写了多少字节 int localFlushedAmount = doWriteBytes(buf); //如果一个字节没写, 直接break if (localFlushedAmount == 0) &amp;#123; setOpWrite = true; break; &amp;#125; // 统计总共写了多少字节 flushedAmount += localFlushedAmount; if (!buf.isReadable()) &amp;#123; // 标记全写道 done = true; break; &amp;#125; &amp;#125; in.progress(flushedAmount); if (done) &amp;#123; // 移除当前对象 in.remove(); &amp;#125; else &amp;#123; // Break the loop and so incompleteWrite(...) is called. break; &amp;#125; &amp;#125; else if (msg instanceof FileRegion) &amp;#123; FileRegion region = (FileRegion) msg; boolean done = region.transferred() >= region.count(); if (!done) &amp;#123; long flushedAmount = 0; if (writeSpinCount == -1) &amp;#123; writeSpinCount = config().getWriteSpinCount(); &amp;#125; for (int i = writeSpinCount - 1; i >= 0; i--) &amp;#123; long localFlushedAmount = doWriteFileRegion(region); if (localFlushedAmount == 0) &amp;#123; setOpWrite = true; break; &amp;#125; flushedAmount += localFlushedAmount; if (region.transferred() >= region.count()) &amp;#123; done = true; break; &amp;#125; &amp;#125; in.progress(flushedAmount); &amp;#125; if (done) &amp;#123; in.remove(); &amp;#125; else &amp;#123; // Break the loop and so incompleteWrite(...) is called. break; &amp;#125; &amp;#125; else &amp;#123; // Should not reach here. throw new Error(); &amp;#125; &amp;#125; incompleteWrite(setOpWrite); &amp;#125; 首先是一个无限for 循环Object msg = in.current() 这一步是拿到 flushedEntry 指向的entry 中的msg, 跟到current 方法中: public Object current() &amp;#123; Entry entry = flushedEntry; if (entry == null) &amp;#123; return null; &amp;#125; return entry.msg; &amp;#125; 这里直接拿到flushedEntry 指向的entry 中关联的msg, 也就是一个ByteBuf. 回到 doWrite 方法: 如果msg 为null,说明没有可以刷新的entry, 则调用clearOpWrite() 方法清除写标识. 如果msg 不为null, 则会判断是否为是ByteBuf 类型, 如果是ByteBuf , 就进入if 块中的逻辑. if 块中首先将msg 转换为ByteBuf, 然后判断ByteBuf 是否可读, 如果不可读, 则通过in.remove() 将当前的ByteBuf 所关联的entry 移除, 然后跳出这次循环进入下次循环。 remove方法稍后分析. 这里我们先继续往下看, boolean done = false 这里设置一个标识, 标识刷新操作是否执行完成, 这里默认值为false, 代表走到这里没有执行完. writeSpinCount = config().getWriteSpinCount() 这里获取一个写操作的循环次数, 默认是16. 然后根据这个循环次数, 进行循环的写操作, 在循环中, 关注这一步: int localFlushedAmount = doWriteBytes(buf); 这一步就是将buf 的内容写到channel 中, 并返回写到字节数, 这里会调用NioSocketChannel 的doWriteBytes() , 我们跟到doWriteBytes 方法中: @Override protected int doWriteBytes(ByteBuf buf) throws Exception &amp;#123; final int expectedWrittenBytes = buf.readableBytes(); return buf.readBytes(javaChannel(), expectedWrittenBytes); &amp;#125; 这里首先拿到buf 的可读字节数, 然后通过readBytes 将可读字节写入到jdk底层的channel 中.回到doWrite 方法, 将内容写到jdk底层的channel 之后, 如果一个字节都没写, 说明现在channel 可能不可写,将setOpWrite 设置为true, 用于标识写操作位, 并退出循环. 如果已经写出字节， 则通过 flushedAmount += localFlushedAmount 累加写出的字节数,然后根据是buf是否没有可读字节数判断是否buf 的数据已经写完, 如果写完, 将done 设置为true, 说明写操作完成, 并退出循环. 因为有时候不一定一次就能将ByteBuf 所有的字节写完, 所以这里会继续通过循环进行写出, 直到循环到16次。 如果ByteBuf 内容完全写完, 会通过in.remove() 将当前entry 移除掉, 我们跟到remove方法： public boolean remove() &amp;#123; Entry e = flushedEntry; if (e == null) &amp;#123; clearNioBuffers(); return false; &amp;#125; Object msg = e.msg; ChannelPromise promise = e.promise; int size = e.pendingSize; removeEntry(e); if (!e.cancelled) &amp;#123; // only release message, notify and decrement if it was not canceled before. ReferenceCountUtil.safeRelease(msg); safeSuccess(promise); decrementPendingOutboundBytes(size, false, true); &amp;#125; // recycle the entry e.recycle(); return true; &amp;#125; 首先拿到当前的flushedEntry, 我们重点关注一下removeEntry() 这一步,跟进去: private void removeEntry(Entry e) &amp;#123; if (-- flushed == 0) &amp;#123; // processed everything flushedEntry = null; if (e == tailEntry) &amp;#123; tailEntry = null; unflushedEntry = null; &amp;#125; &amp;#125; else &amp;#123; flushedEntry = e.next; &amp;#125; &amp;#125; if (-- flushed == 0) 表示当前节点是否为需要刷新的最后一个节点, 如果是, 则flushedEntry 指针设置为空。 如果当前节点是tailEntry 节点, 说明当前节点是最后一个节点, 将tailEntry 和unflushedEntry 两个指针全部设置为空。如果当前节点不是需要刷新的最后的一个节点, 则通过flushedEntry = e.next 这步将 flushedEntry 指针移动到下一个节点, 以上就是flush 操作的相关逻辑. 5. 数据输出回调首先我们看一段在handler 中的业务逻辑: @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; ChannelFuture future = ctx.writeAndFlush(\"test data\"); future.addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; if (future.isSuccess()) &amp;#123; System.out.println(\"写出成功\"); &amp;#125; else &amp;#123; System.out.println(\"写出失败\"); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; 这种写法小伙伴们已经不陌生了, 首先调用writeAndFlush 将数据写出, 然后返回的future 进行添加listener, 并且重写回调函数. 这只是一个简单的示例,在回调函数中判断future 的状态成功与否, 成功的话则打印出”写出成功”, 否则打印出”写出失败”. 这里如果写在handler 中通过是在NioEventLoop 线程执行的, 在future 返回之后才会执行添加listener 的操作, 如果在用户线程中 writeAndFlush 是异步执行的, 在添加监听的时候有可能写出操作没有执行完毕, 等写出操作执行完毕之后才会执行回调. 以上逻辑在代码中如何体现呢? 我们首先跟到writeAndFlush 方法中, 会走到AbstractChannelHandlerContext 的writeAndFlush 方法： @Override public ChannelFuture writeAndFlush(Object msg) &amp;#123; return writeAndFlush(msg, newPromise()); &amp;#125; 我们重点关注newPromise() 方法, 跟进去: @Override public ChannelPromise newPromise() &amp;#123; return new DefaultChannelPromise(channel(), executor()); &amp;#125; 这里直接创建了DefaultChannelPromise 这个对象并传入了当前的channel 和当前channel 绑定的NioEventLoop 对象, 在DefaultChannelPromise 的构造方法中, 也就将channel 和NioEventLoop 对象绑定在自身的成员变量中.回到writeAndFlush () 方法中,继续跟: @Override public ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) &amp;#123; if (msg == null) &amp;#123; throw new NullPointerException(\"msg\"); &amp;#125; if (!validatePromise(promise, true)) &amp;#123; ReferenceCountUtil.release(msg); // cancelled return promise; &amp;#125; write(msg, true, promise); return promise; &amp;#125; 这里最后返回了promise ,其实就是我们上一步创建的DefaultChannelPromise 对象, DefaultChannelPromise 实现了ChannelFuture 接口,所以方法如果返回该对象可以被ChannelFuture 类型接收, 我们继续跟write() 方法: private void write(Object msg, boolean flush, ChannelPromise promise) &amp;#123; AbstractChannelHandlerContext next = findContextOutbound(); final Object m = pipeline.touch(msg, next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &amp;#123; if (flush) &amp;#123; next.invokeWriteAndFlush(m, promise); &amp;#125; else &amp;#123; next.invokeWrite(m, promise); &amp;#125; &amp;#125; else &amp;#123; AbstractWriteTask task; if (flush) &amp;#123; task = WriteAndFlushTask.newInstance(next, m, promise); &amp;#125; else &amp;#123; task = WriteTask.newInstance(next, m, promise); &amp;#125; safeExecute(executor, task, promise, m); &amp;#125; &amp;#125; 如果nioEventLoop 线程, 继续调用invokeWriteAndFlush 方法, 如果不是nioEventLoop 线程则将 writeAndFlush 事件封装成task, 交给 nioEventLoop 线程异步执行。 这里如果是异步执行, 则到这一步之后, 我们的业务代码中, writeAndFlush 就会返回并添加监听 。走到这里无论同步异步, 都会执行invokeWriteAndFlush 方法: private void invokeWriteAndFlush(Object msg, ChannelPromise promise) &amp;#123; if (invokeHandler()) &amp;#123; invokeWrite0(msg, promise); invokeFlush0(); &amp;#125; else &amp;#123; writeAndFlush(msg, promise); &amp;#125; &amp;#125; private void invokeWrite0(Object msg, ChannelPromise promise) &amp;#123; try &amp;#123; ((ChannelOutboundHandler) handler()).write(this, msg, promise); &amp;#125; catch (Throwable t) &amp;#123; notifyOutboundHandlerException(t, promise); &amp;#125; &amp;#125; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &amp;#123; unsafe.write(msg, promise); &amp;#125; 这里最终会调用unsafe 的write 方法, 并传入promise 对象, 跟到AbstractUnsafe 的write 方法: @Override public final void write(Object msg, ChannelPromise promise) &amp;#123; assertEventLoop(); ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null) &amp;#123; // If the outboundBuffer is null we know the channel was closed and so // need to fail the future right away. If it is not null the handling of the rest // will be done in flush0() // See https://github.com/netty/netty/issues/2362 safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION); // release message now to prevent resource-leak ReferenceCountUtil.release(msg); return; &amp;#125; int size; try &amp;#123; msg = filterOutboundMessage(msg); size = pipeline.estimatorHandle().size(msg); if (size &lt; 0) &amp;#123; size = 0; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; safeSetFailure(promise, t); ReferenceCountUtil.release(msg); return; &amp;#125; outboundBuffer.addMessage(msg, size, promise); &amp;#125; 这里我们首先关注两个部分, 首先看在catch 中safeSetFailure 这步, 因为是catch 块, 说明发生了异常, 写到缓冲区不成功, safeSetFailure 就是设置写出失败的状态, 我们跟到 safeSetFailure() 方法中: protected final void safeSetFailure(ChannelPromise promise, Throwable cause) &amp;#123; if (!(promise instanceof VoidChannelPromise) &amp;&amp; !promise.tryFailure(cause)) &amp;#123; logger.warn(\"Failed to mark a promise as failure because it's done already: &amp;#123;&amp;#125;\", promise, cause); &amp;#125; &amp;#125; 这里看if 判断, 首先判断的是promise 是DefaultChannelPromise, 所以promise instanceof VoidChannelPromise 为true. 重点分析 promise.tryFailure(cause) , 这里是设置失败状态, 这里会调用DefaultPromise的 tryFailure() 方法: @Override public boolean tryFailure(Throwable cause) &amp;#123; if (setFailure0(cause)) &amp;#123; notifyListeners(); return true; &amp;#125; return false; &amp;#125; 再跟到 setFailure0() 方法中: private boolean setFailure0(Throwable cause) &amp;#123; return setValue0(new CauseHolder(checkNotNull(cause, \"cause\"))); &amp;#125; private boolean setValue0(Object objResult) &amp;#123; if (RESULT_UPDATER.compareAndSet(this, null, objResult) || RESULT_UPDATER.compareAndSet(this, UNCANCELLABLE, objResult)) &amp;#123; checkNotifyWaiters(); return true; &amp;#125; return false; &amp;#125; 这里在if 块中的cas操作, 会将参数objResult 的值设置到DefaultPromise 的成员变量 result 中, 表示当前操作为异常状态. 回到tryFailure() 方法, 我们关注 notifyListeners() 这个方法, 这个方法是执行添加监听的回调方法, 当writeAndFlush 和addListene 是异步执行的时候, 这个有可能已经添加, 所以通过这个方法可以调用添加监听后的回调. 如果writeAndFlush 和addListene 是同步执行的时候, 也就是都是在NioEventLoop 线程中执行, 那么走到这里addListener 还没执行, 所以这里不能回调添加监听的回调函数, 那么回调是什么时候执行的呢? 我们剖析addListener 步骤的时候会具体给大家分析. 具体执行回调我们在讲解添加监听 的时候具体再分析. 以上就是记录异常状态的大概逻辑. 回到AbstractUnsafe 的write 方法, 我们在关注这一步: outboundBuffer.addMessage(msg, size, promise) 跟到addMessage() 方法中: public void addMessage(Object msg, int size, ChannelPromise promise) &amp;#123; Entry entry = Entry.newInstance(msg, size, total(msg), promise); if (tailEntry == null) &amp;#123; flushedEntry = null; tailEntry = entry; &amp;#125; else &amp;#123; Entry tail = tailEntry; tail.next = entry; tailEntry = entry; &amp;#125; if (unflushedEntry == null) &amp;#123; unflushedEntry = entry; &amp;#125; // increment pending bytes after adding message to the unflushed arrays. // See https://github.com/netty/netty/issues/1619 incrementPendingOutboundBytes(size, false); &amp;#125; 我们只需要关注包装Entry 的newInstance 方法, 该方法传入promise 对象, 跟到newInstance () 方法: static Entry newInstance(Object msg, int size, long total, ChannelPromise promise) &amp;#123; Entry entry = RECYCLER.get(); entry.msg = msg; entry.pendingSize = size; entry.total = total; entry.promise = promise; return entry; &amp;#125; 这里将 promise 设置到Entry 的成员变量中了, 也就是说, 每个Entry 都关联了唯一的一个promise, 我们回到AbstractChannelHandlerContext 的invokeWriteAndFlush 方法中: private void invokeWriteAndFlush(Object msg, ChannelPromise promise) &amp;#123; if (invokeHandler()) &amp;#123; invokeWrite0(msg, promise); invokeFlush0(); &amp;#125; else &amp;#123; writeAndFlush(msg, promise); &amp;#125; &amp;#125; 我们刚才分析了write操作中promise 对象的传递以及状态设置的大概过程, 我们继续看在flush中promise 的操作过程， 这里invokeFlush0() 并没有传入promise 对象, 因为我们刚才分析过, promise 对象会绑定在缓存区中entry 的成员变量中, 可以通过其成员变量拿到promise 对象, 通过事件传递, 最终会调到HeadContext 的flush方法: @Override public void flush(ChannelHandlerContext ctx) throws Exception &amp;#123; unsafe.flush(); &amp;#125; 最后跟到AbstractUnsafe 的flush 方法:l @Override public final void flush() &amp;#123; assertEventLoop(); ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null) &amp;#123; return; &amp;#125; outboundBuffer.addFlush(); flush0(); &amp;#125; @SuppressWarnings(\"deprecation\") protected void flush0() &amp;#123; if (inFlush0) &amp;#123; // Avoid re-entrance return; &amp;#125; final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null || outboundBuffer.isEmpty()) &amp;#123; return; &amp;#125; inFlush0 = true; // Mark all pending write requests as failure if the channel is inactive. if (!isActive()) &amp;#123; try &amp;#123; if (isOpen()) &amp;#123; outboundBuffer.failFlushed(FLUSH0_NOT_YET_CONNECTED_EXCEPTION, true); &amp;#125; else &amp;#123; // Do not trigger channelWritabilityChanged because the channel is closed already. outboundBuffer.failFlushed(FLUSH0_CLOSED_CHANNEL_EXCEPTION, false); &amp;#125; &amp;#125; finally &amp;#123; inFlush0 = false; &amp;#125; return; &amp;#125; try &amp;#123; doWrite(outboundBuffer); &amp;#125; catch (Throwable t) &amp;#123; if (t instanceof IOException &amp;&amp; config().isAutoClose()) &amp;#123; /** * Just call &amp;#123;@link #close(ChannelPromise, Throwable, boolean)&amp;#125; here which will take care of * failing all flushed messages and also ensure the actual close of the underlying transport * will happen before the promises are notified. * * This is needed as otherwise &amp;#123;@link #isActive()&amp;#125; , &amp;#123;@link #isOpen()&amp;#125; and &amp;#123;@link #isWritable()&amp;#125; * may still return &amp;#123;@code true&amp;#125; even if the channel should be closed as result of the exception. */ close(voidPromise(), t, FLUSH0_CLOSED_CHANNEL_EXCEPTION, false); &amp;#125; else &amp;#123; outboundBuffer.failFlushed(t, true); &amp;#125; &amp;#125; finally &amp;#123; inFlush0 = false; &amp;#125; &amp;#125; 我们继续跟进 AbstractNioByteChannel 的doWrite() 方法: @Override protected void doWrite(ChannelOutboundBuffer in) throws Exception &amp;#123; int writeSpinCount = -1; boolean setOpWrite = false; for (;;) &amp;#123; Object msg = in.current(); if (msg == null) &amp;#123; // Wrote all messages. clearOpWrite(); // Directly return here so incompleteWrite(...) is not called. return; &amp;#125; if (msg instanceof ByteBuf) &amp;#123; ByteBuf buf = (ByteBuf) msg; int readableBytes = buf.readableBytes(); if (readableBytes == 0) &amp;#123; in.remove(); continue; &amp;#125; boolean done = false; long flushedAmount = 0; if (writeSpinCount == -1) &amp;#123; writeSpinCount = config().getWriteSpinCount(); &amp;#125; for (int i = writeSpinCount - 1; i >= 0; i --) &amp;#123; int localFlushedAmount = doWriteBytes(buf); if (localFlushedAmount == 0) &amp;#123; setOpWrite = true; break; &amp;#125; flushedAmount += localFlushedAmount; if (!buf.isReadable()) &amp;#123; done = true; break; &amp;#125; &amp;#125; in.progress(flushedAmount); if (done) &amp;#123; in.remove(); &amp;#125; else &amp;#123; // Break the loop and so incompleteWrite(...) is called. break; &amp;#125; &amp;#125; else if (msg instanceof FileRegion) &amp;#123; FileRegion region = (FileRegion) msg; boolean done = region.transferred() >= region.count(); if (!done) &amp;#123; long flushedAmount = 0; if (writeSpinCount == -1) &amp;#123; writeSpinCount = config().getWriteSpinCount(); &amp;#125; for (int i = writeSpinCount - 1; i >= 0; i--) &amp;#123; long localFlushedAmount = doWriteFileRegion(region); if (localFlushedAmount == 0) &amp;#123; setOpWrite = true; break; &amp;#125; flushedAmount += localFlushedAmount; if (region.transferred() >= region.count()) &amp;#123; done = true; break; &amp;#125; &amp;#125; in.progress(flushedAmount); &amp;#125; if (done) &amp;#123; in.remove(); &amp;#125; else &amp;#123; // Break the loop and so incompleteWrite(...) is called. break; &amp;#125; &amp;#125; else &amp;#123; // Should not reach here. throw new Error(); &amp;#125; &amp;#125; incompleteWrite(setOpWrite); &amp;#125; 我们重点关注 in.remove() 这里, 如果done 为true, 说明刷新事件已经完成, 则移除当前entry 节点, 我们跟到remove 方法中: public boolean remove() &amp;#123; Entry e = flushedEntry; if (e == null) &amp;#123; clearNioBuffers(); return false; &amp;#125; Object msg = e.msg; ChannelPromise promise = e.promise; int size = e.pendingSize; removeEntry(e); if (!e.cancelled) &amp;#123; // only release message, notify and decrement if it was not canceled before. ReferenceCountUtil.safeRelease(msg); safeSuccess(promise); decrementPendingOutboundBytes(size, false, true); &amp;#125; // recycle the entry e.recycle(); return true; &amp;#125; 这里我们看这一步: ChannelPromise promise = e.promise; 之前我们剖析过promise 对象会绑定在entry 中, 而这步就是从entry 中 获取promise 对象, 等remove 操作完成后, 会执行到这一步: safeSuccess(promise); 这一步正好和我们刚才分析的safeSetFailure 相反, 这里设置成功状态, 跟到safeSuccess() 方法中: private static void safeSuccess(ChannelPromise promise) &amp;#123; if (!(promise instanceof VoidChannelPromise)) &amp;#123; PromiseNotificationUtil.trySuccess(promise, null, logger); &amp;#125; &amp;#125; public static &lt;V> void trySuccess(Promise&lt;? super V> p, V result, InternalLogger logger) &amp;#123; if (!p.trySuccess(result) &amp;&amp; logger != null) &amp;#123; Throwable err = p.cause(); if (err == null) &amp;#123; logger.warn(\"Failed to mark a promise as success because it has succeeded already: &amp;#123;&amp;#125;\", p); &amp;#125; else &amp;#123; logger.warn( \"Failed to mark a promise as success because it has failed already: &amp;#123;&amp;#125;, unnotified cause:\", p, err); &amp;#125; &amp;#125; &amp;#125; 这里继续跟进if 中的trySuccess 方法, 最后会跟进到DefaultPromise的trySuccess: @Override public boolean trySuccess(V result) &amp;#123; if (setSuccess0(result)) &amp;#123; notifyListeners(); return true; &amp;#125; return false; &amp;#125; 跟到setSuccess0() 方法中: private boolean setSuccess0(V result) &amp;#123; return setValue0(result == null ? SUCCESS : result); &amp;#125; private boolean setValue0(Object objResult) &amp;#123; if (RESULT_UPDATER.compareAndSet(this, null, objResult) || RESULT_UPDATER.compareAndSet(this, UNCANCELLABLE, objResult)) &amp;#123; checkNotifyWaiters(); return true; &amp;#125; return false; &amp;#125; 这里的逻辑我们刚才也剖析过了, 这里传入一个参数信号SUCCESS, 表示设置成功状态, 在跟进setValue方法中: private boolean setValue0(Object objResult) &amp;#123; if (RESULT_UPDATER.compareAndSet(this, null, objResult) || RESULT_UPDATER.compareAndSet(this, UNCANCELLABLE, objResult)) &amp;#123; checkNotifyWaiters(); return true; &amp;#125; return false; &amp;#125; 同样, 在if 判断中,通过cas操作将参数传入的SUCCESS 对象赋值到DefaultPromise 的属性 result 的, 我们看这个属性: private volatile Object result; 这里是Object 类型, 也就是可以赋值成任何类型。 SUCCESS 是一个signal 类型的对象, 这里我们可以简单为一种状态, SUCCESS 表示一种成功的的状态.通过上述cas 操作, result 的值将赋值成SUCCESS , 我们回到trySuccess 方法: @Override public boolean trySuccess(V result) &amp;#123; if (setSuccess0(result)) &amp;#123; notifyListeners(); return true; &amp;#125; return false; &amp;#125; 设置完成功后, 则会通过notifyListeners() 执行监听中的回调, 我们看用户代码: @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &amp;#123; ChannelFuture future = ctx.writeAndFlush(\"test data\"); future.addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; if (future.isSuccess()) &amp;#123; System.out.println(\"写出成功\"); &amp;#125; else &amp;#123; System.out.println(\"写出失败\"); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; 在回调中会判断 future.isSuccess()promise 设置为成功状态这里会返回true, 从而打印成功”写出成功”, 跟到isSuccess() 方法中, 这里会调用 DefaultPromise 的 isSuccess 方法： @Override public boolean isSuccess() &amp;#123; Object result = this.result; return result != null &amp;&amp; result != UNCANCELLABLE &amp;&amp; !(result instanceof CauseHolder); &amp;#125; 我们这里首先会拿到result 对象, 然后判断result 不为空, 并不是UNCANCELLABLE, 并且不属于CauseHolder 对象。 我们刚才分析如果 promise 设置为成功装载, 则result 为SUCCESS,所以这里条件成立, 可以执行if (future.isSuccess()) 中if 块的逻辑. 和设置错误状态的逻辑一样, 这里也有同样的问题, 如果writeAndFlush 是和addListener 是异步操作, 那么执行到回调的时候,可能addListener 已经添加完成了,所以可以正常的执行回调. 那么如果writeAndFlush 是和addListener是 同步操作, 那么回调方法是可以执行的呢? 我们看 addListener 这个方法，addListener 传入一个ChannelFutureListener 对象， 并重写了operationComplete 方法, 也就是执行回调的方法, 会执行到DefaultChannelPromise的addListener 方法, 点进去: @Override public ChannelPromise addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void>>... listeners) &amp;#123; super.addListeners(listeners); return this; &amp;#125; 跟到父类的addListeners 方法: public Promise&lt;V> addListeners(GenericFutureListener&lt;? extends Future&lt;? super V>>... listeners) &amp;#123; checkNotNull(listeners, \"listeners\"); synchronized (this) &amp;#123; for (GenericFutureListener&lt;? extends Future&lt;? super V>> listener : listeners) &amp;#123; if (listener == null) &amp;#123; break; &amp;#125; addListener0(listener); &amp;#125; &amp;#125; if (isDone()) &amp;#123; notifyListeners(); &amp;#125; return this; &amp;#125; 这里通过addListener0() 方法添加listener, 因为添加listener 有可能会在不同的线程中操作, 比如用户线程和NioEventLoop 线程, 所以为了防止线程并发,这里简单粗暴的加了个synchronized 关键字, 跟到addListener0() 中 private void addListener0(GenericFutureListener&lt;? extends Future&lt;? super V>> listener) &amp;#123; if (listeners == null) &amp;#123; listeners = listener; &amp;#125; else if (listeners instanceof DefaultFutureListeners) &amp;#123; ((DefaultFutureListeners) listeners).add(listener); &amp;#125; else &amp;#123; listeners = new DefaultFutureListeners((GenericFutureListener&lt;? extends Future&lt;V>>) listeners, listener); &amp;#125; &amp;#125; 如果是第一次添加 listeners,则成员变量listeners为null, 这样就把参数传入的GenericFutureListener 赋值到成员变量listeners . 如果是第二次添加listeners, 则listeners 不为空， 会走到else判断, 因为第一次添加的listeners 是GenericFutureListener 类型,并不是DefaultFutureListeners 类型, 所以else if 判断返回false, 进入else块, else 块中通过new 方式创建一个 DefaultFutureListeners 对象并赋值到成员变量 listeners 中. 中。DefaultFutureListeners 的构造方法中, 第一个参数传入DefaultPromise 中的成员变量listeners, 也就是第一次添加的GenericFutureListener 对象, 第二个参数为第二次添加的GenericFutureListener 对象, 这里通过两个GenericFutureListener 对象包装成一个DefaultFutureListeners 对象, 我们看listeners 的定义: private Object listeners; 这里是个Object类型, 所以可以保存任意类型的对象. 再看 DefaultFutureListeners 的构造方法: DefaultFutureListeners( GenericFutureListener&lt;? extends Future&lt;?>> first, GenericFutureListener&lt;? extends Future&lt;?>> second) &amp;#123; listeners = new GenericFutureListener[2]; listeners[0] = first; listeners[1] = second; size = 2; if (first instanceof GenericProgressiveFutureListener) &amp;#123; progressiveSize ++; &amp;#125; if (second instanceof GenericProgressiveFutureListener) &amp;#123; progressiveSize ++; &amp;#125; &amp;#125; 在 DefaultFutureListeners 类中也定义了一个成员变量 listeners, 类型为GenericFutureListener 数组。构造方法中初始化 listeners 这个数组, 并且数组中第一个值赋值为我们第一次添加的GenericFutureListener, 第二次赋值为我们第二次添加的GenericFutureListener. 回到addListener0 方法中: private void addListener0(GenericFutureListener&lt;? extends Future&lt;? super V>> listener) &amp;#123; if (listeners == null) &amp;#123; listeners = listener; &amp;#125; else if (listeners instanceof DefaultFutureListeners) &amp;#123; ((DefaultFutureListeners) listeners).add(listener); &amp;#125; else &amp;#123; listeners = new DefaultFutureListeners((GenericFutureListener&lt;? extends Future&lt;V>>) listeners, listener); &amp;#125; &amp;#125; 经过两次添加listener, 属性listener 的值就变成了DefaultFutureListeners 类型的对象, 如果第三次添加listener , 则会走到else if 块中, DefaultFutureListeners 对象通过调用add方法继续添加listener , 跟到add方法中: public void add(GenericFutureListener&lt;? extends Future&lt;?>> l) &amp;#123; GenericFutureListener&lt;? extends Future&lt;?>>[] listeners = this.listeners; final int size = this.size; if (size == listeners.length) &amp;#123; this.listeners = listeners = Arrays.copyOf(listeners, size &lt;&lt; 1); &amp;#125; listeners[size] = l; this.size = size + 1; if (l instanceof GenericProgressiveFutureListener) &amp;#123; progressiveSize ++; &amp;#125; &amp;#125; 这里的逻辑也比较简单, 就是为当前数组对象 listeners 中追加新的 GenericFutureListener 对象, 如果listeners 容量不足则进行扩容操作, 根据以上逻辑, 就完成了listener 的逻辑添加. 那么再看我们刚才遗留的问题, 如果writeAndFlush 和 addListener 是同步进行的, writeAndFlush 执行回调时还没有 addListener 还没有执行回调, 那么回调是如何执行的呢?回到 DefaultPromise 的 addListener 中： @Override public Promise&lt;V> addListener(GenericFutureListener&lt;? extends Future&lt;? super V>> listener) &amp;#123; checkNotNull(listener, \"listener\"); synchronized (this) &amp;#123; addListener0(listener); &amp;#125; if (isDone()) &amp;#123; notifyListeners(); &amp;#125; return this; &amp;#125; 我们分析完了addListener0(listener), 再往下看. 这里有个if判断if (isDone()), isDone() 方法就是程序执行到这一步, 判断刷新事件是否执行完成, 跟到isDone() 方法中: @Override public boolean isDone() &amp;#123; return isDone0(result); &amp;#125; private static boolean isDone0(Object result) &amp;#123; return result != null &amp;&amp; result != UNCANCELLABLE; &amp;#125; 这里判断result 不为null, 并且不为UNCANCELLABLE, 则就表示完成. 因为成功的状态是SUCCESS, 所以flush 成功这里会返回true.回到 addListener 中, 如果执行完成, 就通过 notifyListeners() 方法执行回调 , 这也解释刚才的问题. 在同步操作中, writeAndFlush 在执行回调时并没有添加listener, 所以添加listener 的时候会判断 writeAndFlush 的执行状态, 如果状态是完成, 则这里会执行回调.同样, 在异步操作中, 走到这里 writeAndFlush 可能还没有完成, 所以这里不会执行回调,由 writeAndFlush 方法执行回调. 首先, 无论 writeAndFlush 和 addListener 谁先完成,都可以执行到回调方法中。跟到notifyListeners() 方法中: private void notifyListeners() &amp;#123; EventExecutor executor = executor(); if (executor.inEventLoop()) &amp;#123; final InternalThreadLocalMap threadLocals = InternalThreadLocalMap.get(); final int stackDepth = threadLocals.futureListenerStackDepth(); if (stackDepth &lt; MAX_LISTENER_STACK_DEPTH) &amp;#123; threadLocals.setFutureListenerStackDepth(stackDepth + 1); try &amp;#123; notifyListenersNow(); &amp;#125; finally &amp;#123; threadLocals.setFutureListenerStackDepth(stackDepth); &amp;#125; return; &amp;#125; &amp;#125; safeExecute(executor, new Runnable() &amp;#123; @Override public void run() &amp;#123; notifyListenersNow(); &amp;#125; &amp;#125;); &amp;#125; 这里首先判断是否是eventLoop 线程, 如果是 eventLoop 线程则执行if 块中的逻辑, 如果不是eventLoop 线程, 则把执行回调的函数封装成task 丢到EventLoop 的任务队列中异步执行. 我们重点关注 notifyListenersNow() 方法,跟进去: private void notifyListenersNow() &amp;#123; Object listeners; synchronized (this) &amp;#123; // Only proceed if there are listeners to notify and we are not already notifying listeners. if (notifyingListeners || this.listeners == null) &amp;#123; return; &amp;#125; notifyingListeners = true; listeners = this.listeners; this.listeners = null; &amp;#125; for (;;) &amp;#123; if (listeners instanceof DefaultFutureListeners) &amp;#123; notifyListeners0((DefaultFutureListeners) listeners); &amp;#125; else &amp;#123; notifyListener0(this, (GenericFutureListener&lt;? extends Future&lt;V>>) listeners); &amp;#125; synchronized (this) &amp;#123; if (this.listeners == null) &amp;#123; // Nothing can throw from within this method, so setting notifyingListeners back to false does not // need to be in a finally block. notifyingListeners = false; return; &amp;#125; listeners = this.listeners; this.listeners = null; &amp;#125; &amp;#125; &amp;#125; 在无限for 循环中， 首先判断listeners 是不是 DefaultFutureListeners 类型, 根据我们之前的逻辑, 如果只添加了一个listeners , 则listeners 是DefaultFutureListeners 类型。通常在添加的时候只会添加一个listeners , 所以我们跟到else块中的notifyListener0() 方法: private static void notifyListener0(Future future, GenericFutureListener l) &amp;#123; try &amp;#123; l.operationComplete(future); &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"An exception was thrown by \" + l.getClass().getName() + \".operationComplete()\", t); &amp;#125; &amp;#125; 我们这里, 这里执行了 GenericFutureListener 中我们重写的回调函数 operationComplete。以上就是执行回调的相关函数. 5. 自定义编解码尽管Netty 预置了丰富的编解码类库功能, 但是在实际的业务开发过程中, 总是需要对编解码功能做一些定制的. 使用Netty 的编解码框架，可以非常方便的进行协议定制。本章节将对常用的支持定制的编解码类库进行讲解. 1. MessageToMessageDecoder 抽象解码器MessageToMessageDecoder 实际上是Netty 的二次解码器, 它的职责是将一个对象进行二次解码为其他对象。为什么称它为二次解码呢? 我们知道,从SocketChannel 读取到的TCP数据报是ByteBuf, 实际就是字节数组. 我们首先需要将ByteBuf 缓冲区中的数据报读取出来, 并将其解码为Java对象,然后对Java 对象根据某些规则做二次解码, 将其解码为另一个POJO对象. 因为SocketChannel 在ByteToMessageDecoder 之后, 所以称为二次解码器. 二次解码器在实际的商业项目中非常有用, 以HTTP +XML 协议栈为例, 第一次解码往往是将字节数组解码成HttpRequest 对象, 然后对 HttpRequest 消息中的消息体字符进行二次解码, 将XML 格式的字符串解码为POJO对象，这就用到了二次解码器. 类似这样的场景还有很多. 事实上,做一个超级复杂的解码器将多个解码器组合成一个大而全的MessageToMessageDecoder 解码器似乎也能解决多次解码的问题, 但是采用这种方式的代码可维护性就会变得非常差. 例如, 加入我们打算在HTTP + XML 协议栈中增加一个打印码流的功能, 即首次解码获取HttpRequest 对象之后打印XML 格式的码流。 如果采用多个解码器, 在中间插入一个打印消息体的headler 即可, 不需要修改原有的代码.如果做一个大而全的解码器, 就需要在解码的方法中增加打印码流的代码, 可扩展性和可维护性就会变差. 用户的解码器只需要实现 void decode(ChannelHandlerContext ctx, I msg, List out) 抽象方法即可, 由于它是将一个POJO 解码为另一个POJO,所以一般不会涉及到半包的处理, 相当于ByteToMessageDecoder 更加简单些. 它的继承关系图下图所示: 2. MessageToMessageEncoder 抽象编码器将一个POJO 对象编码成另一个对象, 以HTTP + XML 为例, 它的一种实现方式是: 先将POJO 对象编码成XML 字符串, 再将字符串编码为HTTP请求或者应答消息。对于复杂协议,往往需要经历多次编码, 为了便于功能扩展,可以通过多个编码器组合来实现相关功能. 用户的解码器继承MessageToMessageEncoder 解码器, 实现 void encode(Channel HandlerContext ctx, I msg, List out) 方法即可. 注意, 它与MessageToByteEncoder 的区别是 输出是对象列表而不是ByteBuf, 实例代码如下: public class IntegerToStringEncoder extends MessageToMessageEncoder&lt;Integer> &amp;#123; @Override protected void encode(ChannelHandlerContext ctx, Integer msg, List&lt;Object> out) throws Exception &amp;#123; out.add(msg.toString()); &amp;#125; &amp;#125; MessageToMessageEncoder 编码器的实现原理与之前分析的 MessageToByteEncoder 相似, 唯一的差别就是它编码后的输出是个中间对象, 并非最终可传输的ByteBuf. 简单看下它的源码实现, 创建RecyclableArrayList 对象，判断当前需要编码的对象是否是编码器可处理的类型,如果不是, 则忽略,执行下一个 ChannelHandler 的write 方法. 具体的编码方式实现由用户子类编码器负责完成, 如果编码后的RecyclableArrayList 为空, 说明编码没有成功, 释放RecyclableArrayList 引用。 如果编码成功, 则通过遍历 RecyclableArrayList 对象, 循环发送编码后的POJO 对象, 代码如下图所示: @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &amp;#123; CodecOutputList out = null; try &amp;#123; if (acceptOutboundMessage(msg)) &amp;#123; out = CodecOutputList.newInstance(); @SuppressWarnings(\"unchecked\") I cast = (I) msg; try &amp;#123; encode(ctx, cast, out); &amp;#125; finally &amp;#123; ReferenceCountUtil.release(cast); &amp;#125; if (out.isEmpty()) &amp;#123; out.recycle(); out = null; throw new EncoderException( StringUtil.simpleClassName(this) + \" must produce at least one message.\"); &amp;#125; &amp;#125; else &amp;#123; ctx.write(msg, promise); &amp;#125; &amp;#125; catch (EncoderException e) &amp;#123; throw e; &amp;#125; catch (Throwable t) &amp;#123; throw new EncoderException(t); &amp;#125; finally &amp;#123; if (out != null) &amp;#123; final int sizeMinusOne = out.size() - 1; if (sizeMinusOne == 0) &amp;#123; ctx.write(out.get(0), promise); &amp;#125; else if (sizeMinusOne > 0) &amp;#123; // Check if we can use a voidPromise for our extra writes to reduce GC-Pressure // See https://github.com/netty/netty/issues/2525 ChannelPromise voidPromise = ctx.voidPromise(); boolean isVoidPromise = promise == voidPromise; for (int i = 0; i &lt; sizeMinusOne; i ++) &amp;#123; ChannelPromise p; if (isVoidPromise) &amp;#123; p = voidPromise; &amp;#125; else &amp;#123; p = ctx.newPromise(); &amp;#125; ctx.write(out.getUnsafe(i), p); &amp;#125; ctx.write(out.getUnsafe(sizeMinusOne), promise); &amp;#125; out.recycle(); &amp;#125; &amp;#125; &amp;#125; 3. ObjectEncoder 序列化编码器ObjectEncoder 是java 序列化编码器, 它负责将实现Serializable 接口的对象序列化为 byte[] ,然后写入到ByteBuf 中用于消息的网络传输。 下面我们一起分析下它的实现, 首先, 我们发现它集成自 MessageToByteEncoder，它的作用就是将对象编码成ByteBuf. public class ObjectEncoder extends MessageToByteEncoder&lt;Serializable&gt; &#123; 如果要使用java 序列化，对象必须实现 Serializable 接口, 所以它的泛型类型为Serializable. MessageToByteEncoder 的子类只需要实现 encode(ChannelHandlerContext ctx, I msg, ByteBuf out) 方法即可, 下面我们重点关注 encode () 方法的实现: @Override protected void encode(ChannelHandlerContext ctx, Serializable msg, ByteBuf out) throws Exception &amp;#123; int startIdx = out.writerIndex(); ByteBufOutputStream bout = new ByteBufOutputStream(out); bout.write(LENGTH_PLACEHOLDER); ObjectOutputStream oout = new CompactObjectOutputStream(bout); oout.writeObject(msg); oout.flush(); oout.close(); int endIdx = out.writerIndex(); out.setInt(startIdx, endIdx - startIdx - 4); &amp;#125; 首先创建ByteBufOutputStream 和 ObjectOutputStream，用于将Object 对象序列化到ByteBuf,值得注意的在writeObject 之前需要先将长度(4个字节) 预留, 用于后续长度字段的更新. 依次写入长度占位符(4字节) , 序列化之后的Object 对象, 之后根据ByteBuf 的writeIndex 计算序列化之后的码流长度, 最后调用ByteBuf 的setInt(int index, int value) 更新长度占位符为实际的码流长度. 有个细节需要注意, 更新码流长度字段使用了 setInt 方法而不是writeInt, 原因就是setInt 方法只更新内容, 并不修改readerIndex 和 writerIndex 4. LengthFieldPrepender 通用编码器如果协议中的第一个字段为长度字段,Netty 提供了LengthFieldPrepender 编码器, 它可以计算当前待发送消息的二进制字段长度, 将该程度添加到ByteBuf 的缓冲区头, 如图所示: 通过LengthFieldPrepender 可以将待发送消息的长度写入到ByteBuf 的前2个字节, 编码后的消息组成为长度字段 + 原消息的方式. 通过设置 LengthFieldPrepender 为true , 消息长度将包含长度本身占用的字节数, 打开 LengthFieldPrepender 后, 上图示例中的编码结果如下图所示: LengthFieldPrepender 的工作原理分析如下: 首先对长度字段进行设置, 如果需要包含消息长度字段本身， 则在原来长度基础上再加上 LengthFieldPrepender 的长度. 如果调整后的消息长度小于0, 则抛出参数非法异常. 对消息长度自身所占的字节数进行判断, 以便采用正确的方法将长度字段写入到ByteBuf, 共有以下6 种可能: 长度字段所占字节为1, 如果使用1个Byte字节代表消息长度, 则最大长度需要小于256个字节。对长度进行校验, 如果校验失败则抛出参数非法异常； 若校验通过,则创建新的ByteBuf 并通过writeByte 将长度值写入到ByteBuf 中; 长度字段所占字节为2: 如果使用2个Byte 字节代表消息长度, 则最大消息长度需要小于65536个字节, 对长度进行校验. 如果校验失败则抛出参数非法异常；若校验通过则创建新的ByteBuf 并通过writeShort 将长度写入到ByteBuf 中. 长度字节所占字符为3: 如果使用3个Byte 字节代表消息长度, 则最大长度需要小于16777216 个字节, 对长度进行校验, 如果校验失败则抛出参数非法异常. 若校验通过则创建新的ByteBuf 并通过writeMedium 将长度值写入到ByteBuf 中. 长度字节所占字符为4: 创建新的ByteBuf 并通过writeInt 将长度值写入到ByteBuf 中. 长度字节所占字符为8: 创建新的ByteBuf 并通过writeLong 将长度值写入到ByteBuf 中. 其他长度: 直接抛出Error 相关代码如下: @Override protected void encode(ChannelHandlerContext ctx, ByteBuf msg, List&lt;Object> out) throws Exception &amp;#123; int length = msg.readableBytes() + lengthAdjustment; if (lengthIncludesLengthFieldLength) &amp;#123; length += lengthFieldLength; &amp;#125; if (length &lt; 0) &amp;#123; throw new IllegalArgumentException( \"Adjusted frame length (\" + length + \") is less than zero\"); &amp;#125; switch (lengthFieldLength) &amp;#123; case 1: if (length >= 256) &amp;#123; throw new IllegalArgumentException( \"length does not fit into a byte: \" + length); &amp;#125; out.add(ctx.alloc().buffer(1).order(byteOrder).writeByte((byte) length)); break; case 2: if (length >= 65536) &amp;#123; throw new IllegalArgumentException( \"length does not fit into a short integer: \" + length); &amp;#125; out.add(ctx.alloc().buffer(2).order(byteOrder).writeShort((short) length)); break; case 3: if (length >= 16777216) &amp;#123; throw new IllegalArgumentException( \"length does not fit into a medium integer: \" + length); &amp;#125; out.add(ctx.alloc().buffer(3).order(byteOrder).writeMedium(length)); break; case 4: out.add(ctx.alloc().buffer(4).order(byteOrder).writeInt(length)); break; case 8: out.add(ctx.alloc().buffer(8).order(byteOrder).writeLong(length)); break; default: throw new Error(\"should not reach here\"); &amp;#125; out.add(msg.retain()); &amp;#125;","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Netty中的设计模式(14)","slug":"Netty/Netty中的设计模式(14)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/netty/netty-zhong-de-she-ji-mo-shi-14/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/netty-zhong-de-she-ji-mo-shi-14/","excerpt":"","text":"Netty中的设计模式1. 单例模式1. 特点: 一个类在任何情况下只有一个对象,并提供一个全局访问点. 可延迟创建 避免线程安全问题. 2. 案例分析:@ChannelHandler.Sharable public final class MqttEncoder extends MessageToMessageEncoder&lt;MqttMessage> &amp;#123; public static final MqttEncoder INSTANCE = new MqttEncoder(); private MqttEncoder() &amp;#123; &amp;#125; @Override protected void encode(ChannelHandlerContext ctx, MqttMessage msg, List&lt;Object> out) throws Exception &amp;#123; out.add(doEncode(ctx.alloc(), msg)); &amp;#125; &amp;#125; 2. 策略模式1. 特点: 封装一系列可相互替换的算法家族 动态选择某一个策略 2. 代码案例:/* * Copyright 2016 The Netty Project * * The Netty Project licenses this file to you under the Apache License, * version 2.0 (the \"License\"); you may not use this file except in compliance * with the License. You may obtain a copy of the License at: * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations * under the License. */ package io.netty.util.concurrent; import io.netty.util.internal.UnstableApi; import java.util.concurrent.atomic.AtomicInteger; /** * Default implementation which uses simple round-robin to choose next &amp;#123;@link EventExecutor&amp;#125;. */ @UnstableApi public final class DefaultEventExecutorChooserFactory implements EventExecutorChooserFactory &amp;#123; public static final DefaultEventExecutorChooserFactory INSTANCE = new DefaultEventExecutorChooserFactory(); private DefaultEventExecutorChooserFactory() &amp;#123; &amp;#125; @SuppressWarnings(\"unchecked\") @Override public EventExecutorChooser newChooser(EventExecutor[] executors) &amp;#123; if (isPowerOfTwo(executors.length)) &amp;#123; return new PowerOfTowEventExecutorChooser(executors); &amp;#125; else &amp;#123; return new GenericEventExecutorChooser(executors); &amp;#125; &amp;#125; private static boolean isPowerOfTwo(int val) &amp;#123; return (val &amp; -val) == val; &amp;#125; private static final class PowerOfTowEventExecutorChooser implements EventExecutorChooser &amp;#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; PowerOfTowEventExecutorChooser(EventExecutor[] executors) &amp;#123; this.executors = executors; &amp;#125; @Override public EventExecutor next() &amp;#123; return executors[idx.getAndIncrement() &amp; executors.length - 1]; &amp;#125; &amp;#125; private static final class GenericEventExecutorChooser implements EventExecutorChooser &amp;#123; private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) &amp;#123; this.executors = executors; &amp;#125; @Override public EventExecutor next() &amp;#123; return executors[Math.abs(idx.getAndIncrement() % executors.length)]; &amp;#125; &amp;#125; &amp;#125; 3. 装饰者模式1. 特点 装饰者和非装饰者实现同一个接口 装饰者通常继承被装饰者, 同宗同源 动态修改、重载被装饰者的方法 2. 源码:WrappedByteBuf class WrappedByteBuf extends ByteBuf &amp;#123; protected final ByteBuf buf; protected WrappedByteBuf(ByteBuf buf) &amp;#123; if (buf == null) &amp;#123; throw new NullPointerException(\"buf\"); &amp;#125; this.buf = buf; &amp;#125; ... &amp;#125; UnreleasableByteBuf final class UnreleasableByteBuf extends WrappedByteBuf &amp;#123; private SwappedByteBuf swappedBuf; UnreleasableByteBuf(ByteBuf buf) &amp;#123; super(buf); &amp;#125; @Override public ByteBuf order(ByteOrder endianness) &amp;#123; if (endianness == null) &amp;#123; throw new NullPointerException(\"endianness\"); &amp;#125; if (endianness == order()) &amp;#123; return this; &amp;#125; SwappedByteBuf swappedBuf = this.swappedBuf; if (swappedBuf == null) &amp;#123; this.swappedBuf = swappedBuf = new SwappedByteBuf(this); &amp;#125; return swappedBuf; &amp;#125; ... SimpleLeakAwareByteBuf final class SimpleLeakAwareByteBuf extends WrappedByteBuf &amp;#123; private final ResourceLeak leak; SimpleLeakAwareByteBuf(ByteBuf buf, ResourceLeak leak) &amp;#123; super(buf); this.leak = leak; &amp;#125; @Override public ByteBuf touch() &amp;#123; return this; &amp;#125; ... 4. 观察者模式1. 特点 两个角色,观察者和被观察者 观察者订阅消息,被观察者发布消息 订阅能收到消息,取消订阅则收不到 2. 代码:channel.writeAndFlush()方法： public abstract class AbstractChannel extends DefaultAttributeMap implements Channel &amp;#123; ... @Override public ChannelFuture writeAndFlush(Object msg) &amp;#123; return pipeline.writeAndFlush(msg); &amp;#125; @Override public ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) &amp;#123; return pipeline.writeAndFlush(msg, promise); &amp;#125; ... &amp;#125; 5. 迭代器1. 特点 实现迭代器接口 实现对容器中的各个对象的访问的方法 2. 代码:public class CompositeByteBuf extends AbstractReferenceCountedByteBuf implements Iterable&lt;ByteBuf> &amp;#123; private static final ByteBuffer EMPTY_NIO_BUFFER = Unpooled.EMPTY_BUFFER.nioBuffer(); private static final Iterator&lt;ByteBuf> EMPTY_ITERATOR = Collections.&lt;ByteBuf>emptyList().iterator(); &amp;#125; 6. 责任链模式1. 概念:责任链是指多个对象都有机会处理同一个请求, 从而避免请求的发送者和接收者之间的耦合关系. 然后, 将这些对象连成一条链, 并且沿着这条链往下传递请求, 直到有一个对象可以处理它为止. 在每个对象处理过程中, 每个对象只处理它自己关心的那一部分,不相关的可以继续往下传递,直到链中的某个对象不想处理,可以将请求终止或者丢弃. 2. 特点 需要有一个顶层责任处理接口(ChannelHandler) 需要有动态创建链,添加和删除责任处理器的接口(ChannelPipeline) 需要有上下文机制(ChannelHandlerContext) 需要有责任终止机制(不调用ctx.fireXXX方法, 则终止传播) 3. 代码AbstractChannelHandlerContext abstract class AbstractChannelHandlerContext extends DefaultAttributeMap implements ChannelHandlerContext, ResourceLeakHint &amp;#123; &amp;#125; 7.工厂模式1. 特点 将创建对象的逻辑封装器来 2. 代码:/* * Copyright 2014 The Netty Project * * The Netty Project licenses this file to you under the Apache License, * version 2.0 (the \"License\"); you may not use this file except in compliance * with the License. You may obtain a copy of the License at: * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations * under the License. */ package io.netty.channel; import io.netty.util.internal.StringUtil; /** * A &amp;#123;@link ChannelFactory&amp;#125; that instantiates a new &amp;#123;@link Channel&amp;#125; by invoking its default constructor reflectively. */ public class ReflectiveChannelFactory&lt;T extends Channel> implements ChannelFactory&lt;T> &amp;#123; private final Class&lt;? extends T> clazz; public ReflectiveChannelFactory(Class&lt;? extends T> clazz) &amp;#123; if (clazz == null) &amp;#123; throw new NullPointerException(\"clazz\"); &amp;#125; this.clazz = clazz; &amp;#125; @Override public T newChannel() &amp;#123; try &amp;#123; return clazz.newInstance(); &amp;#125; catch (Throwable t) &amp;#123; throw new ChannelException(\"Unable to create Channel from class \" + clazz, t); &amp;#125; &amp;#125; @Override public String toString() &amp;#123; return StringUtil.simpleClassName(clazz) + \".class\"; &amp;#125; &amp;#125;","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Window子系统ubuntu 开启2375 端口","slug":"Docker/Window子系统ubuntu 开启2375 端口","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/window-zi-xi-tong-ubuntu-kai-qi-2375-duan-kou/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/window-zi-xi-tong-ubuntu-kai-qi-2375-duan-kou/","excerpt":"","text":"Window子系统ubuntu 开启2375 端口1）查看配置文件 [root@docker-server ~]# systemctl show docker | grep FragmentPath= FragmentPath=/usr/lib/systemd/system/docker.service 然后修改/lib/systemd/system/docker.service文件 [root@docker-server ~]# cp /lib/systemd/system/docker.service /lib/systemd/system/docker.service.bak [root@docker-server ~]# vim /lib/systemd/system/docker.service ....... ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:4243 #添加这一行 #ExecStart=/usr/bin/dockerd-current \\ #注释掉默认的这一行 --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current \\ --default-runtime=docker-runc \\ --exec-opt native.cgroupdriver=systemd \\ --userland-proxy-path=/usr/libexec/docker/docker-proxy-current \\ --seccomp-profile=/etc/docker/seccomp.json \\ $OPTIONS \\ $DOCKER_STORAGE_OPTIONS \\ $DOCKER_NETWORK_OPTIONS \\ $ADD_REGISTRY \\ $BLOCK_REGISTRY \\ $INSECURE_REGISTRY \\ $REGISTRIES 2）修改/etc/default/docker文件 [root@docker-server ~]# cp /etc/default/docker /etc/default/docker.bak [root@docker-server ~]# vim /etc/sysconfig/docker ...... DOCKER_OPTS=&quot;-H tcp://localhost:4243 -H unix:///var/run/docker.sock&quot; #添加这一行 3）DOCKER_HOST的环境变量设置 [root@docker-server ~]# vim ~/.bashrc ........ export DOCKER_HOST=tcp://localhost:4243 4）重启docker服务 [root@docker-server ~]# systemctl daemon-reload [root@docker-server ~]# systemctl restart docker 5）检查发现4243端口已启动 [root@docker-server ~]# netstat -ant ....... tcp6 0 0 :::4243 :::* LISTEN [root@docker-server ~]# lsof -i:4243 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME dockerd-c 15400 root 6u IPv6 59175 0t0 TCP *:4243 (LISTEN)","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]},{"title":"Docker-Compose(6)","slug":"Docker/Docker-Compose(6)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/docker-compose-6/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/docker-compose-6/","excerpt":"","text":"Docker之Docker-Compose 官网：https://docs.docker.com/compose/ 1.业务背景2 Docker传统方式实现2.1 写Python代码&amp;build image (1)创建文件夹 mkdir -p /tmp/composetest cd /tmp/composetest (2)创建app.py文件，写业务内容 import time import redis from flask import Flask app = Flask(__name__) cache = redis.Redis(host='redis', port=6379) def get_hit_count(): retries = 5 while True: try: return cache.incr('hits') except redis.exceptions.ConnectionError as exc: if retries == 0: raise exc retries -= 1 time.sleep(0.5) @app.route('/') def hello(): count = get_hit_count() return 'Hello World! I have been seen &amp;#123;&amp;#125; times.\\n'.format(count) (3)新建requirements.txt文件 flask redis (4)编写Dockerfile FROM python:3.7-alpine WORKDIR /code ENV FLASK_APP app.py ENV FLASK_RUN_HOST 0.0.0.0 RUN apk add --no-cache gcc musl-dev linux-headers COPY requirements.txt requirements.txt RUN pip install -r requirements.txt COPY . . CMD [\"flask\", \"run\"] (5)根据Dockerfile生成image docker build -t python-app-image . (6)查看images：docker images python-app-image latest 7e1d81f366b7 3 minutes ago 213MB 2.2 获取Redis的imagedocker pull redis:alpine 2.3 创建两个container (1)创建网络 docker network ls docker network create --subnet=172.20.0.0/24 app-net (1)创建python程序的container，并指定网段和端口 docker run -d --name web -p 5000:5000 --network app-net python-app-image (2)创建redis的container，并指定网段 docker run -d --name redis --network app-net redis:alpine 2.4 访问测试ip[centos]:5000 3 简介和安装3.1 简介 官网：https://docs.docker.com/compose/ Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration. 3.2 安装 Linux环境中需要单独安装 官网：https://docs.docker.com/compose/install/ sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 4 docker compose实现 reference：https://docs.docker.com/compose/gettingstarted/ 4.1 同样的前期准备新建目录，比如composetest 进入目录，编写app.py代码 创建requirements.txt文件 编写Dockerfile 4.2 编写docker-compose.yaml文件默认名称，当然也可以指定，docker-compose.yaml version: '3' services: web: build: . ports: - \"5000:5000\" networks: - app-net redis: image: \"redis:alpine\" networks: - app-net networks: app-net: driver: bridge (1)通过docker compose创建容器 docker-compose up -d (2)访问测试 5 详解docker-compose.yml文件 (1)version: &#39;3&#39; 表示docker-compose的版本 (2)services 一个service表示一个container (3)networks 相当于docker network create app-net (4)volumes 相当于-v v1:/var/lib/mysql (5)image 表示使用哪个镜像，本地build则用build，远端则用image (6)ports 相当于-p 8080:8080 (7)environment 相当于-e 6 docker-compose常见操作(1)查看版本 docker-compose version (2)根据yml创建service docker-compose up 指定yaml：docker-compose up -f xxx.yaml 后台运行：docker-compose up (3)查看启动成功的service docker-compose ps 也可以使用docker ps (4)查看images docker-compose images (5)停止/启动service docker-compose stop/start (6)删除service[同时会删除掉network和volume] docker-compose down (7)进入到某个service docker-compose exec redis sh 7 scale扩缩容 (1)修改docker-compose.yaml文件，主要是把web的ports去掉，不然会报错 version: '3' services: web: build: . networks: - app-net redis: image: \"redis:alpine\" networks: - app-net networks: app-net: driver: bridge (2)创建service docker-compose up -d (3)若要对python容器进行扩缩容 docker-compose up --scale web=5 -d docker-compose ps docker-compose logs web","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]},{"title":"Docker持久化(4)","slug":"Docker/Docker持久化(4)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/docker-chi-jiu-hua-4/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/docker-chi-jiu-hua-4/","excerpt":"","text":"Docker 数据持久化1. Volume 创建mysql 数据库的contailer docker run -d --name mysql01 -e MYSQL_ROOT_PASSWORD=jack123 mysql 查看volume docker volume ls 具体查看该volume docker volume inspect 48507d0e7936f94eb984adf8177ec50fc6a7ecd8745ea0bc165ef485371589e8 名字不好看,name太长, 修改一下 -v mysql01_volume:/var/lib/mysql 表示给上述的vloume 起一个能够识别的名字 docker run -d --name mysql01 -v mysql01_volume:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=jack123 mysql 查看volume docker volume ls docker volume inspect mysql01 vloume 真的能够持久化保存数据吗? 不妨做个试验 ## 进入容器 docker exec -it mysql01 bash ## 登录mysql服务 mysql -uroot -pjack123 ## 创建测试库 create database db_test ## 退出mysql, 退出`contailer` ## 删除mysql 容器 docker rm -f mysql01 ## 查看`volume` docker volume ls ## 发现`volume` 还在 DRIVER VOLUME NAME local mysql01_volume # 新建一个mysql container，并且指定使用\"mysql01_volume\" docker run -d --name test-mysql -v mysql01_volume:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=jack123 mysql # 进入容器,登录mysql 服务,查看数据库 docker exec -it test-mysql bash mysql -uroot -pjack123 show database; # 可以发现db_test仍然在 可以发现db_test仍然在 | information_schema | | db_test | | mysql | | performance_schema | | sys 2. Bing Mounting 创建tomcat 容器 docker run -d --name tomcat01 -p 9090:8080 -v /tmp/test:/usr/local/tomcat/webapps/test tomcat 查看两个目录 centos：cd /tmp/test tomcat容器：cd /usr/local/tomcat/webapps/test 在centos的/tmp/test 中新建一个1.html并且也有内容 在centos7 上访问该路径,curl localhost:9090/test/1.html 在wim 浏览器上通过ip 访问","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]},{"title":"Docker实战(5)","slug":"Docker/Docker实战(5)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/docker-shi-zhan-5/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/docker-shi-zhan-5/","excerpt":"","text":"Docker实战1. Mysql 高可用集群1. 拉取pxc镜像docker pull percona/percona-xtradb-cluster:5.7.21 2. 复制pxc 镜像(实则重命名)docker tag percona/percona-xtradb-cluster:5.7.21 pxc 3. 删除pxc 原来的镜像docker rmi percona/percona-xtradb-cluster:5.7.21 4. 创建一个单独的网段,给mysql 数据库集群使用(1)docker network create --subnet=172.18.0.0/24 pxc-net (2)docket network inspect pxc-net [查看详情] (3)docker network rm pxc-net [删除] 5. 创建和删除volume创建：docker volume create --name v1 删除：docker volume rm v1 查看详情：docker volume inspect v1 6. 创建单个pxc 容器demo[CLUSTER_NAME PXC集群名字] [XTRABACKUP_PASSWORD数据库同步需要用到的密码] docker run -d -p 3301:3306 -v v1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=jack123 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=jack123 --privileged --name=node1 --net=pxc-net --ip 172.18.0.2 pxc 7. 搭建pxc 集群7.1 准备三个数据卷docker volume create --name v1 docker volume create --name v2 docker volume create --name v3 7.2 运行三个pxc 容器docker run -d -p 3301:3306 -v v1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=jack123 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=jack123 --privileged --name=node1 --net=pxc-net --ip 172.18.0.2 pxc [CLUSTER_JOIN将该数据库加入到某个节点上组成集群] docker run -d -p 3302:3306 -v v2:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=jack123 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=jack123 -e CLUSTER_JOIN=node1 --privileged --name=node2 --net=pxc-net --ip 172.18.0.3 pxc docker run -d -p 3303:3306 -v v3:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=jack123 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=jack123 -e CLUSTER_JOIN=node1 --privileged --name=node3 --net=pxc-net --ip 172.18.0.4 pxc 7.3 MYSQL工具连接测试一下8. 数据库的负载均衡 拉取haproxy镜像 docker pull haproxy 创建harproxy 配置文件,这里使用 bind mounting 的方式 touch /tmp/haproxy/haproxy.cfg haproxy.cfg global #工作目录，这边要和创建容器指定的目录对应 chroot /usr/local/etc/haproxy #日志文件 log 127.0.0.1 local5 info #守护进程运行 daemon defaults log global mode http #日志格式 option httplog #日志中不记录负载均衡的心跳检测记录 option dontlognull #连接超时（毫秒） timeout connect 5000 #客户端超时（毫秒） timeout client 50000 #服务器超时（毫秒） timeout server 50000 #监控界面 listen admin_stats #监控界面的访问的IP和端口 bind 0.0.0.0:8888 #访问协议 mode http #URI相对地址 stats uri /dbs_monitor #统计报告格式 stats realm Global\\ statistics #登陆帐户信息 stats auth admin:admin #数据库负载均衡 listen proxy-mysql #访问的IP和端口，haproxy开发的端口为3306 #假如有人访问haproxy的3306端口，则将请求转发给下面的数据库实例 bind 0.0.0.0:3306 #网络协议 mode tcp #负载均衡算法（轮询算法） #轮询算法：roundrobin #权重算法：static-rr #最少连接算法：leastconn #请求源IP算法：source balance roundrobin #日志格式 option tcplog #在MySQL中创建一个没有权限的haproxy用户，密码为空 #Haproxy使用这个账户对MySQL数据库心跳检测 option mysql-check user haproxy server MySQL_1 172.18.0.2:3306 check weight 1 maxconn 2000 server MySQL_2 172.18.0.3:3306 check weight 1 maxconn 2000 server MySQL_3 172.18.0.4:3306 check weight 1 maxconn 2000 #使用keepalive检测死链 option tcpka 创建haproxy容器 docker run -it -d -p 8888:8888 -p 3306:3306 -v /tmp/haproxy:/usr/local/etc/haproxy --name haproxy01 --privileged --net=pxc-net haproxy 根据haproxy.cfg 文件启动haproxy docker exec -it haproxy01 bash haproxy -f /usr/local/etc/haproxy/haproxy.cfg 在MYSQL数据库上创建用户,用于心跳检测 CREATE USER 'haproxy'@'%' IDENTIFIED BY ''; [小技巧[如果创建失败，可以先输入一下命令]: drop user 'haproxy'@'%'; flush privileges; CREATE USER 'haproxy'@'%' IDENTIFIED BY ''; ] win 浏览器访问 http://centos_ip:8888/dbs_monitor 用户名密码都是:admin 在win 上的mysql 客户端连接haproxy1 ip:centos_ip port:3306 user:root password:jack123 在haproxy 连接上进行数据操作,然后查看数据库集群各个节点 2. Nginx 和Spring Boot 项目+MYSQL2.1 网络2.1.1 网络创建一个单独的网段 docker network create --subnet=172.18.0.0/24 pro-net 2.1.2 网络划分mysql -&gt; 172.18.0.6 springboot-&gt;172.18.0.11/12/13 nginx -&gt; 172.18.0.10 2.2. MYSQL2.2.1 创建volumedocker volume create v1 2.2.2 创建mysql 容器docker run -d --name my-mysql -v v1:/var/lib/mysql -p 3301:3306 -e MYSQL_ROOT_PASSWORD=jack123 --net=pro-net --ip 172.18.0.6 mysql 2.2.3 客户端连接, 执行mysql文件name:my-mysql ip:centos-ip 端口:3301 user:root password:jack123 create schema db_test_springboot collate utf8mb4_0900_ai_ci; use db_test_springboot; create table t_user ( id int not null primary key, username varchar(50) not null, password varchar(50) not null, number varchar(100) not null ); 2.3 SpringBoot 项目 SpringBoot + Mybatis 实现CRUD 操作,名称为springboot-mybatis 在本地测试该项目的功能 主要是修改application.yml 文件中数据库的相关配置 在项目根目录下执行mvn clean package 打成一个jar 包 记得修改一下application.yml 文件数据库的配置 mvn clean package -Dmaven.test.skip=true 在target 目录下找到springboot-mybatis-0.0.1-SNAPSHOT.jar 3 在docker 环境中新建一个目录springboot-mybatis 4 上传springboot-mybatis-0.0.1-SNAPSHOT.jar 到该目录下,并且在此目录下创建Dockerfile FROM openjdk:8-jre-alpine MAINTAINER luyanan0718 LABEL name=\"springboot-mybatis\" version=\"1.0\" author=\"luyanan0718\" COPY springboot-mybatis-0.0.1-SNAPSHOT.jar springboot-mybatis.jar CMD [\"java\",\"-jar\",\"springboot-mybatis.jar\"] 5 基于Dockerfile 构建镜像 docker build -t sbm-image . 6 基于image 创建contailer docker run -d --name sb01 -p 8081:8080 --net=pro-net --ip 172.18.0.11 sbm-image 7 查看日志 docker logs sb01 8 验证 在浏览器中访问http://192.168.8.118:8081/user/listall 2.3.1 网络问题因为sb01 和my-mysql 在同一个bridge 的网段上, 所以是可以互相ping 通的,比如: docker exec -it sb01 ping 172.18.0.6 or docker exec -it sb01 ping my-mysql so? application.yml 文件不妨这样修改一下, 也就是把ip地址直接换成容器的名字 url: jdbc:mysql://my-mysql/db_test_springboot? 2.3.2 创建多个项目容器docker run -d --name sb01 -p 8081:8080 --net=pro-net --ip 172.18.0.11 sbm-image docker run -d --name sb02 -p 8082:8080 --net=pro-net --ip 172.18.0.12 sbm-image docker run -d --name sb03 -p 8083:8080 --net=pro-net --ip 172.18.0.13 sbm-image 2.4 Nginx 在centos 的/tmp/nginx 下新建nginx.conf 文件,并进行相应的配置 user nginx; worker_processes 1; events &amp;#123; worker_connections 1024; &amp;#125; http &amp;#123; include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &amp;#123; listen 80; location / &amp;#123; proxy_pass http://balance; &amp;#125; &amp;#125; upstream balance&amp;#123; server 172.18.0.11:8080; server 172.18.0.12:8080; server 172.18.0.13:8080; &amp;#125; include /etc/nginx/conf.d/*.conf; &amp;#125; 创建nginx 容器 注意: 先在centos7上创建/tmp/nginx目录，并且创建nginx.conf文件，写上内容 docker run -d --name my-nginx -p 80:80 -v /tmp/nginx/nginx.conf:/etc/nginx/nginx.conf --network=pro-net --ip 172.18.0.10 nginx win 浏览器访问: ip/user/install","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]},{"title":"Docker基础(二)(2)","slug":"Docker/Docker基础(二)(2)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/docker-ji-chu-er-2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/docker-ji-chu-er-2/","excerpt":"","text":"Docker基础(二)2.1 继续探讨Image说白了.image 就是由一层一层的layer组成的. 2.1.1 官方imagehttps://github.com/docker-library mysql https://github.com/docker-library/tomcat/blob/master/8.5/jdk8/openjdk/Dockerfile 2.1.2 Dockerfile不妨我们也来制作一个自己的image镜像, 顺便来学习一下Dockerfile 文件中常用的语法. 2.1.2.1 FROM指定基础的镜像,比如 FROM ubuntu:14.04 2.1.2.2 RUN在镜像内部执行一些命令,比如安装软件、配置环境等 换行可以使用 “” RUN groupadd -r mysql && useradd -r -g mysql mysql 2.1.2.3 ENV设置变量的值,ENV MYSQL_MAJOR 5.7,通过 过docker run --e key=value 修改, 后面可以直接使用$&#123;MYSQL_MAJOR&#125; ENV MYSQL_MAJOR 5.7 2.1.2.4 LABEL设置镜像标签 LABEL email=\"luyanan0718@163.com\" LABEL name=\"luyanan\" 2.1.2.5 VOLUME指定数据的挂载目录 VOLUME /var/lib/mysql 2.1.2.6 COPY将主机内的文件复制到镜像内,如果目录不存在,会自动创建所需要的目录, 注意只是复制, 不会提取和解压. COPY docker-entrypoint.sh /usr/local/bin/ 2.1.2.7 ADD将主机的文件复制到镜像中,和COPY 类似,只是ADD 会对压缩文件提取和解压. 2.1.2.8 WORKDIR指定镜像的工作目录, 之后的命令都是基于此目录工作,如不存在则创建. WORKDIR /usr/local WORKDIR tomcat RUN touch test.txt 会在在/usr/local/tomcat 下创建test.txt 文件 WORKDIR /root ADD app.yml test/ 会在/root/test 下多出一个app.yml 文件 2.1.2.9 CMD容器启动的时候会默认执行的命令, 若有多个CMD 命令,则最后一个生效. CMD [\"mysqld\"] 或 CMD mysqld 2.1.2.10 ENTRYPOINT跟CMD 的使用类似 ENTRYPOINT [\"docker-entrypoint.sh\"] 跟CMD的不同 docker run 执行时, 会覆盖CMD的命令, 而ENTRYPOINT 不会 2.1.2.11 EXPOSE指定镜像要暴漏的端口， 启动镜像时,可以使用-p 将该端口映射给宿主机 EXPOSE 3306 2.1.3 Dockerfile 实战Spring Boot 项目2.1.3.1 创建一个Spring Boot 项目1.2.3.2 写一个controller@RestController public class DockerController &amp;#123; @GetMapping(\"/dockerfile\") @ResponseBody String dockerfile() &amp;#123; return \"hello docker\" ; &amp;#125; &amp;#125; 2.1.3.3 打包mvn clean package 打成一个jar 包,在target 下找到dockerfile-demo-0.0.1-SNAPSHOT.jar 2.1.3.4 新建目录在docker 环境中创建一个first-dockerfile 2.1.3.5 上传上传 dockerfile-demo-0.0.1-SNAPSHOT.jar 到该目录下, 并且在此目录创建Dockerfile 2.1.3.6 编写DockerfileFROM openjdk:8 MAINTAINER luyanan0718@163.com LABEL name=\"dockerfile-demo\" version=\"1.0\" author=\"luyanan\" COPY dockerfile-demo-0.0.1-SNAPSHOT.jar dockerfile-image.jar CMD [\"java\",\"-jar\",\"dockerfile-image.jar\"] 2.1.3.7 构建基于Dockerfile 构建镜像 docker build -t test-docker-image . 2.1.3.8 基于image 创建contailerdocker run -d --name user01 -p 6666:8080 test-docker-image 2.1.3.9 查看启动日志docker logs user01 2.1.3.10 访问测试宿主机上访问curl localhost:6666/dockerfile 返回 hello docker 2.1.4 镜像仓库2.1.4.1 docker hub 我们在机器上登陆 docker login 输入用户名和密码 docker push luyanan0718/test-docker-image 注意镜像名称和docker id 一致, 不然push不成功 给image 重命名, 并删除掉原来的 docker tag test-docker-image luyanan0718/test-docker-image docker rmi -f test-docker-image 再次推送,刷新 hub.docker.com 后台,发现成功. 别人下载,并且运行 docker pull luyanan0718/test-docker-image docker run -d --name user01 -p 6661:8080 luyanan0718/test-docker-image 2.1.4.2 阿里云docker hub阿里云仓库 参考手册 登陆到阿里云仓库 sudo docker login --username=luyanan0718@163.com registry.cnhangzhou.aliyuncs.com 输入密码 创建命名空间 给image打tag sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/luyanan0718/testdocker-image:v1.0 推送镜像到docker 阿里云仓库 sudo docker push registry.cn-hangzhou.aliyuncs.com/luyanan0718/test-dockerimage:v1.0 别人下载, 并且运行 docker pull registry.cn-hangzhou.aliyuncs.com/luyanan0718/test-dockerimage:v1.0 docker run -d --name user01 -p 6661:8080 registry.cnhangzhou.aliyuncs.com/luyanan0718/test-docker-image:v1.0 2.1.4.3 搭建自己的Docker Harbor 访问github上的harbor 项目 https://github.com/goharbor/harbor 下班版本,比如1.7.1 https://github.com/goharbor/harbor/releases 找一台安装了 docker-compose的服务器, 上传并解压 tar -zxvf xxx.tar.gz 进入到 harbor 目录 需要harbor.cfg 文件,主要是ip地址修改为当前机器的ip地址 同时也可以看到Harbor的密码,默认是 Harbor12345 安装Harbor,需要一些时间 sh install.sh 浏览器访问,输入ip地址, 输入用户名和密码即可. 2.1.5 image常见操作 查看本地的image 列表 docker image docker image ls 获取远端镜像 dokcer pull 删除镜像[注意此镜像如果正在使用,或者有关联的镜像,则需要先处理完] docker image rm imageid docker rmi -f imageid docker rmi -f $(docker image ls) 删除所有镜像 运行镜像 docker run image 发布镜像 docker push 2.2 深入探讨Contailer 既然contailer 是由image 运行起来的,那么是否可以理解为contailer 与image有某种关系呢? 理解: 其实可以理解为contailer 只是基于image 之后的layer 而已, 也就是可以通过docker run image 创建出一个contailer 2.2.1 contailer 到image 既然contailer是基于image 之上的,想想是否能够基于一个contailer 反推出一个image 呢？ 肯定是可以的,比如通过docker run运行一个contailer出来,这时候对contailer 对一些修改,然后再生成一个image, 这时候image的由来就不仅仅只能通过Dockerfile了. 实验: 拉取一个centos image docker pull centos 根据centos的镜像创建出一个contailer docker run -d -it --name my-centos centos 进入my-centos容器中 docker exec -it my-centos bash 输入vim 命令 bash: vim: command not found 我们要做的是, 对该centos 进行修改,也就是安装一下vim 命令,然后将其生成一个新的centos 在centos 的contailer 中安装vim yum install -y vim 退出容器,将其生成一个新的centos, 名称为vim-centos-image docker commit my-centos vim-centos-image 查看镜像列表,并且基于vim-centos-image 创建新的容器 docker run -d -it --name my-vim-centos vim-centos-image 进入到my-vim-centos 容器中, 检查vim 命令是否存在. docker exec -it my-vim-centos bash vim 结论: 可以通过docker commit 命令基于一个contailer 重新生成一个iimage, 但是一般得到image 方式不建议这样做,不然image 怎么来的就全然不知了. 2.2.2 contailer 资源限制如果不对container 的资源做限制,他就会无限制的使用物理机的资源, 这样显然是不合适的, 查看资源情况: docker status 2.2.2.1 内存限制--memory Memory limit 如果不设置 --memory-swap，其大小和memory一样 docker run -d --memory 100M --name tomcat1 tomcat 2.2.2.2 CPU限制--cpu-shares 权重 docker run -d --cpu-shares 10 --name tomcat2 tomcat 2.2.2.3 图形化资源监控https://github.com/weaveworks/scope sudo curl -L git.io/scope -o /usr/local/bin/scope sudo chmod a+x /usr/local/bin/scope scope launch 39.100.39.63 # 停止scope scope stop # 同时监控两台机器，在两台机器中分别执行如下命令 scope launch ip1 ip2 2.2.3 contailer 常见操作 根据镜像创建容器 ```bashdocker run -d –name -p 9090:8080 my-tomcat tomcat 2. 查看运行中的`contailer` ```bash docker ps 查看所有的contailer(包含退出的) docker ps -a 删除contailer docker rm containerid docker rm -f $(docker ps -a) 删除所有container 根据contailer 生成image docker commit 进入到一个contailer 中 docker exec -it contailer bash 查看某个contailer的日志 docker logs contailer 查看容器资源使用情况 docker status 查看容器详情信息 docker inspect container 停止/启动容器 docker stop/start contailer 2.3 底层技术支持contailer 是一种轻量级的虚拟化技术, 不用模拟硬件创建虚拟机 Docker 是基于Linux Kernel的Namespace、CGroups、UnionFileSystem等技术封装成的一种自 定义容器格式，从而提供一套虚拟运行环境。 Namespace：用来做隔离的，比如pid[进程]、net[网络]、mnt[挂载点]等 CGroups: Controller Groups用来做资源限制，比如内存和CPU等 Union file systems：用来做image和container分层","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]},{"title":"Docker初介绍(1)","slug":"Docker/Docker初介绍(1)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/docker-chu-jie-shao-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/docker-chu-jie-shao-1/","excerpt":"","text":"Docker初介绍1. What is Docker1.1 官网首页 Modernize your applications, accelerate innovation Securely build, share and run modern applications anywhere 1.2 Docs Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is. 1.3 由来(演进过程)刚开始我们部署一个jar的时候 问题: 成本高, 部署满,浪费资源,硬件限制,不利于迁移扩展. 接下来进入虚拟化时代 优点: 相对利用资源, 相对容易扩展. 缺点: 容器太重了, 一上来占用较多的物理资源,移植性差,资源利用率低. 容器时代 1.4 再次理解Docker Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is. 发现还是比较容易理解的, 但是这一句Containers are not new ,也就是容器化技术在很早之前就出现了,比较常见的容器化技术有OpenVZ、LXC、RKT 等. 1.5 Docker 的优势和应用场景 http://www.docker.com/ —&gt; Solutions 有助于Microservices的落地和部署 充分利用物理机资源, 同时能够整合服务器资源 提高开发效率,测试效率,部署效率,有利于DevOps的落地 云原生落地, 应用能够更好的迁移. 2. 容器(Container)和镜像(image)2.1 image A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. 2.2 containerWhy is docker?-&gt;What is a container A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. 2.3 Relation between image and container Container images become containers at runtime and in the case of Docker containers- images become containers when they run on Docker Engine 2.4 View from Docs从帮助文档的角度看: docker官网-&gt;Resources-&gt;Docs-&gt;Get started-&gt;Get started with Docker-&gt;Orientation-&gt;Images and containers A container is launched by running an image. An image is an executable package that includes everything needed to run an application–the code, a runtime, libraries, environment variables, and configuration files. A container is a runtime instance of an image–what the image becomes in memory when executed (that is, an image with state, or a user process). You can see a list of your running containers with the command, docker ps, just as you would in Linux. 3. Containers and virtual machinesdocker官网-&gt;Resources-&gt;Docs-&gt;Get started-&gt;Get started with Docker- &gt;Orientation-&gt;Containers and virtual machines A container runs natively on Linux and shares the kernel of the host machine with other containers. It runs a discrete process, taking no more memory than any other executable, making it lightweight. By contrast, a virtual machine (VM) runs a full-blown “guest” operating system with virtual access to host resources through a hypervisor. In general, VMs provide an environment with more resources than most applications need. 4. Docker Engine and Architecturehttps://docs.docker.com/engine/docker-overview/ 4.1 Docker EngineDocker Engine is a client-server application with these major components: A server which is a type of long-running program called a daemon process (the dockerd command). A REST API which specifies interfaces that programs can use to talk to the daemon and instruct it what to do. A command line interface (CLI)client (the docker command). 4.2 Docker Architecture Docker uses a client-server architecture. The Docker client talks to the Docker daemon, which does the heavy lifting of building, running, and distributing your Docker containers. The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]},{"title":"Docker之网络篇(3)","slug":"Docker/Docker之网络篇(3)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/docker-zhi-wang-luo-pian-3/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/docker-zhi-wang-luo-pian-3/","excerpt":"","text":"Docker 之网络篇3.1 计算机网络模型 3.2 Linux网卡3.2.1 查看网卡(网络接口) ip link show ls /sys/class/net ip a 3.2.2 网卡3.2.2.1 ip a 解读 状态：UP/DOWN/UNKOWN等 link/ether：MAC地址 inet：绑定的IP地址 3.2.2.2 配置文件在linux 中网卡对应的其实就是文件, 所以找到对应的网卡文件即可. 比如 cat /etc/sysconfig/network-scripts/ifcfg-eth0 3.2.2.3 给网卡添加ip地址当然, 这块也可以直接修改ifcfg.* 文件, 但是我们通过命令添加试试 ip addr add 192.168.0.100/24 dev eth0 删除ip地址 ip addr delete 192.168.0.100/24 dev eth0 3.2.2.4 网卡的启动和关闭重启网卡 service network restart / systemctl restart network 启动/关闭某个网卡 ifup/ifdown eth0 or ip link set eth0 up/down 3.3 Network Namespace在linux上,网络的隔离通过network workspace 来管理,不同的Network Namespace是相互隔离的, ip netns list: 可以查看机器上的的network namespace ip netns list #查看 ip netns add ns1 #添加 ip netns delete ns1 #删除 3.3.1 namespace 实战 创建一个 network namespace ip netns add ns1 查看该namespace 下网卡的情况 ip netns exec ns1 ip a 启动ns1 上的lo 网卡 ip netns exec ns1 ifup lo or ip netns exec ns1 ip link set lo up 再次查看,可以发现state 已经变成了UNKOWN ip netns exec ns1 ip a 再次创建一个network namespace 此时想让两个namespace 网络连通起来 veth pair: Virtual Ethernet Pair,是一个成对的端口,可以实现上述功能. 创建一对link, 也就是接下来要通过过veth pair 连接的link ip link add veth-ns1 type veth peer name veth-ns2 查看link 情况 ip link 将veth-ns1 加入到ns1,将veth-ns2 加入到ns2 ip link set veth-ns1 netns ns1 ip link set veth-ns2 netns ns2 查看宿主机和ns1、ns2的link 情况 ip link ip netns exec ns1 ip link ip netns exec ns2 ip link 此时veth-ns1 和veth-ns2 还没有ip地址,显然通讯还缺少点条件 ip netns exec ns1 ip addr add 192.168.0.11/24 dev veth-ns1 ip netns exec ns2 ip addr add 192.168.0.12/24 dev veth-ns2 再次查看,发现state 是DOWN,并且还是没有ip地址 ip netns exec ns1 ip link ip netns exec ns2 ip link 启动veth-ns1和veth-ns2 ip netns exec ns1 ip link set veth-ns1 up ip netns exec ns2 ip link set veth-ns2 up 再次查看, 发现state是UP,同时有ip ip netns exec ns1 ip a ip netns exec ns2 ip a 此时两次 network namespace 互相ping 一下,发现是可以ping通 ip netns exec ns1 ping 192.168.0.12 ip netns exec ns2 ping 192.168.0.11 3.3.2 Contailer的NS按照上面的描述,实际上每一个contailer,都会有自己的network namespace,并且是独立的,我们可以进入到容器中进行验证 不妨创建两个contailer 看看? docker run -d --name tomcat01 -p 8081:8080 tomcat docker run -d --name tomcat02 -p 8082:8080 tomcat 进入到两个容器中, 分别查看ip docker exec -it tomcat01 ip a docker exec -it tomcat02 ip a 互相ping 一下是可以ping通的 值得我们思考的是,此时tomcat01和tomcat02 属于两个network namespace, 是如何能够ping通的, 有些小伙伴可能会想, 不就跟上面的namespace 实战是一样的吗? 注意这里并没有veth-pair 技术 3.4 深入分析contailer 网络-Bridge3.4.1 docker0 默认bridge 查看centos的网络, ip a , 可以发现 查看tomcat01的网络, docker exec -it tomcat01 ip a, 可以发现 [root@bogon ~]# docker exec -it tomcat01 ip a 1: lo: &lt;LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 7: eth0@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 在centos 中ping 一下tomcat01的网络, 发现可以ping 通 ping 172.17.0.2 [root@bogon ~]# ping 172.17.0.2 PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data. 64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.120 ms 64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.060 ms 64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.056 ms 既然可以ping 通, 而且centos 和tomcat01 又属于不同的netrwork namespace,是怎么连接的? 很显然,跟之前的实战是一样的, 画个图 也就是说,在tomcat01 中有一个eth0和centos的docker0 中有一个veth3是成对的,类似于之前实战中的veth-ns1和veth-ns2,不妨再通过一个命令确认一下brctl 安装一下：yum install bridge-utils brctl show 那为什么tomcat01 和tomcat02是可以互通的呢? 不多说, 直接上图 这种网络连接方式我们称之为bridge,其实也可以通过命令查看docker 中的网络模式,docker network ls. bridge 也是docker 默认的网络模式. 不妨检查一下bridge: docker network inspect bridge &amp;#123; \"Containers\": &amp;#123; \"6ad312b32f62b48935f3c95c58ae061df710bfebbd3d721b467507b9516eeb81\": &amp;#123; \"EndpointID\": \"aa9c612c79f867e874d0cae1aab45374373b61e9cdbe79925d07ae2e89a1cca0\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\", \"MacAddress\": \"02:42:ac:11:00:03\", \"Name\": \"tomcat02\" &amp;#125;, \"f49fc396d8e04f2b330163d91bb5d1482715202b4e2fd0c7f42833722787742a\": &amp;#123; \"EndpointID\": \"c5440b063e8fc0c9c44f3f61bf68f577283417eb23cfa9a361d37973d01a8ba5\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\", \"MacAddress\": \"02:42:ac:11:00:02\", \"Name\": \"tomcat01\" &amp;#125; &amp;#125; &amp;#125; 在tomcat01 容器中是可以访问互联网的, 顺便把这张图画一下,NAT是通过iptable 实现 3.4.2 创建自己的network 创建自己的network, 类型为bridge docker network create tomcat-net or docker network create --subnet=172.18.0.0/24 tomcat-net 查看已有的network: docker network ls 查看tomcat-net 详细信息 docker network inspect tomcat-net 创建tomcat的容器, 并且指定使用tomcat-net docker run -d --name custom-net-tomcat --network tomcat-net tomcat 查看custom-net-tomcat 的网络信息 docker exec -it custom-net-tomcat ip a 查看网卡信息 ip a 查看网卡接口 brctl show bridge name bridge id STP enabled interfaces br-3012e3afd264 8000.02429780e75d no vethf223a4b docker0 8000.0242437b1bbd no veth3b72761 veth9d8c470 此时, 在custom-net-tomcat 容器中ping 一下tomcat01的ip 会如何? 发现无法ping 通 docker exec -it custom-net-tomcat ping 172.17.0.2 PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data. ^C --- 172.17.0.2 ping statistics --- 4 packets transmitted, 0 received, 100% packet loss, time 3000ms 此时如果tomcat01 容器能够连接到tomcat-net 上应该就可以 docker network connect tomcat-net tomcat01 查看tomcat-net 网络,可以发现tomcat01 这个容器也在其中 此时进入到tomcat01 或者custom-net-tomcat中, 不仅可以通过ping 通, 而且可以通过名字ping到, 这时候因为连接到了用户自定义的 tomcat-net bridge 上. docker exec -it tomcat01 bash root@f49fc396d8e0:/usr/local/tomcat# ping 172.18.0.2 PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. 64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.048 ms 64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.040 ms root@f49fc396d8e0:/usr/local/tomcat# ping custom-net-tomcat PING custom-net-tomcat (172.18.0.2) 56(84) bytes of data. 64 bytes from custom-net-tomcat.tomcat-net (172.18.0.2): icmp_seq=1 ttl=64 time=0.030 ms 64 bytes from custom-net-tomcat.tomcat-net (172.18.0.2): icmp_seq=2 ttl=64 time=0.264 ms 但是ping tomcat02 是不通的 root@f49fc396d8e0:/usr/local/tomcat# ping 172.17.0.3 PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data. 64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.045 ms 64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.066 ms root@f49fc396d8e0:/usr/local/tomcat# ping tomcat02 PING tomcat02 (220.250.64.26) 56(84) bytes of data. 3.5 深入分析Contailer 网络-Host &amp; None3.5.1 Host 创建一个tomcat 容器,并且指定网络为host docker run -d --name my-tomcat-host --network host tomcat 查看ip地址 docker exec -it my-tomcat-host ip a 可以发现和centos 是一样的 检查host 网络 &amp;#123; \"Containers\": &amp;#123; \"e1f00d47db344b6688e99c0f5b393e232309fbe1a4d9c3fc3e1ce7c107f3312d\": &amp;#123; \"EndpointID\": \"f08456d9dca024cf6f911f8d32329ba2587ea89554c96b77c32698ace6998525\", \"IPv4Address\": \"\", \"IPv6Address\": \"\", \"MacAddress\": \"\", \"Name\": \"my-tomcat-host\" &amp;#125; &amp;#125; &amp;#125; 3.5.2 None 创建一个tomcat 容器, 并且指定网络为none docker run -d --name my-tomcat-none --network none tomcat 查看ip 地址 docker exec -it my-tomcat-none ip a 1: lo: &lt;LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 检查None 网络 &amp;#123; \"Containers\": &amp;#123; \"bb3f0db4fa76a25b5377da9c3bbf087ac7ef0de0a3f9c37a4ae959983d33105c\": &amp;#123; \"EndpointID\": \"26055c08c968f9d6d03d10b3b66dfea004c35f5d2bd4067a2306566973e92f9e\", \"IPv4Address\": \"\", \"IPv6Address\": \"\", \"MacAddress\": \"\", \"Name\": \"my-tomcat-none\" &amp;#125; &amp;#125; &amp;#125; 3.6 端口映射以及折腾3.6.1 端口映射 创建一个tomcat 容器,名字为port-tomcat docker run -d --name port-tomcat tomcat 思考一下要访问该tomcat 怎么办? 肯定是通过ip:port的方式 docker exec -it port-tomcat bash curl localhost:8080 那如果是在centos7 访问呢? docker exec -it port-tomcat ip a ---->得到其ip地址，比如172.17.0.4 curl 172.17.0.4:8080 小结: 之所以能够访问成功,是因为centos 上的docker0 连接了port-tomcat的network namespace 那如果还要在centos7通过curl localhost方式访问呢? 显然要将port-tomcat 的8080端口映射到centos 上. docker rm -f port-tomcat docker run -d --name port-tomcat -p 8090:8080 tomcat curl localhost:8090 3.6.2 折腾 centos7 是运行在win10 上的虚拟机上, 如果想要在win10 上通过ip:port 方式访问呢? #此时需要centos和win网络在同一个网段，所以在Vagrantfile文件中 #这种方式等同于桥接网络。也可以给该网络指定使用物理机哪一块网卡，比如 #config.vm.network\"public_network\",:bridge=>'en1: Wi-Fi (AirPort)' config.vm.network\"public_network\" centos7: ip a --->192.168.8.118 win10:浏览器访问 192.168.8.118:9080 如果也想要把centos7 上的8090映射到win10的某个端口上呢? 然后浏览器访问localhost:port #此时需要将centos7上的端口和win10上的端口做映射 config.vm.network\"forwarded_port\",guest:8098,host:8090 #记得vagrant reload生效一下 win10：浏览器访问 localhost：8098 3.6.3 画个图强化一下 3.7 多机之间的contailer 通信在同一台centos7 机器上, 发现无论怎么折腾, 我们一定有办法让两个contailer 通信. 那如果是在两台centos7 机器上的呢? 使得两边的etho 能够通信 前提要确保两边的ip 地址不一样 将一边的所有信息当成etho 传输给另外一端的信息 具体通过vxlan 技术实现 http://www.evoila.de/2015/11/06/what-is-vxlan-and-how-it-works 处在vxlan的底层:underlay 处在xxlan的上层:overlay","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]},{"title":"Netty内存分配ByteBuf(12","slug":"Netty/Netty内存分配ByteBuf(12.2)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/netty/netty-nei-cun-fen-pei-bytebuf-12.2/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/netty-nei-cun-fen-pei-bytebuf-12.2/","excerpt":"","text":"4. Pooled 池化内存分配1. PooledByteBufAllocator 简述现在开始, 我们来分析Pooled 池化内存的分配原理, 我们首先还是先找到 AbstractByteBufAllocator 的子类 PooledByteBufAllocator 实现的分配内存的两个方法. newDirectBuffer()方法和 newHeapBuffer()方法： @Override protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) &amp;#123; PoolThreadCache cache = threadCache.get(); PoolArena&lt;byte[]> heapArena = cache.heapArena; ByteBuf buf; if (heapArena != null) &amp;#123; buf = heapArena.allocate(cache, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; buf = new UnpooledHeapByteBuf(this, initialCapacity, maxCapacity); &amp;#125; return toLeakAwareBuffer(buf); &amp;#125; @Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &amp;#123; PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer> directArena = cache.directArena; ByteBuf buf; if (directArena != null) &amp;#123; buf = directArena.allocate(cache, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; if (PlatformDependent.hasUnsafe()) &amp;#123; buf = UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; buf = new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; &amp;#125; return toLeakAwareBuffer(buf); &amp;#125; 我们发现这两个方法大体结构上是一样的. 我们以newDirectBuffer 为例简单的分析一下： @Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &amp;#123; PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer> directArena = cache.directArena; ByteBuf buf; if (directArena != null) &amp;#123; buf = directArena.allocate(cache, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; if (PlatformDependent.hasUnsafe()) &amp;#123; buf = UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; buf = new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; &amp;#125; return toLeakAwareBuffer(buf); &amp;#125; 首先,我们看到它是通过 threadCache.get() 拿到一个类型为PoolThreadCache 的cache 对象, 然后, 通过 cache 拿到 PoolArena 对象, 最终会调用 directArena.allocate() 方法分配 ByteBuf. 这个地方大家可能会看的比较懵, 我们来详细分析一下，我们跟进到 threadCache 对象其实是PoolThreadLocalCache 类型的变量, 跟进到 PoolThreadLocalCache 的源码: final class PoolThreadLocalCache extends FastThreadLocal&lt;PoolThreadCache> &amp;#123; @Override protected synchronized PoolThreadCache initialValue() &amp;#123; final PoolArena&lt;byte[]> heapArena = leastUsedArena(heapArenas); final PoolArena&lt;ByteBuffer> directArena = leastUsedArena(directArenas); return new PoolThreadCache( heapArena, directArena, tinyCacheSize, smallCacheSize, normalCacheSize, DEFAULT_MAX_CACHED_BUFFER_CAPACITY, DEFAULT_CACHE_TRIM_INTERVAL); &amp;#125; @Override protected void onRemoval(PoolThreadCache threadCache) &amp;#123; threadCache.free(); &amp;#125; private &lt;T> PoolArena&lt;T> leastUsedArena(PoolArena&lt;T>[] arenas) &amp;#123; if (arenas == null || arenas.length == 0) &amp;#123; return null; &amp;#125; PoolArena&lt;T> minArena = arenas[0]; for (int i = 1; i &lt; arenas.length; i++) &amp;#123; PoolArena&lt;T> arena = arenas[i]; if (arena.numThreadCaches.get() &lt; minArena.numThreadCaches.get()) &amp;#123; minArena = arena; &amp;#125; &amp;#125; return minArena; &amp;#125; &amp;#125; 从名字上来看, 我们发现PoolThreadLocalCache 的initialValue() 方法就是用来初始化PoolThreadLocalCache 的, 首先就调用了leastUsedArena() 方法分别获取类型为 PoolArena 的 heapArena 对象和directArena 对象. 然后把heapArena 对象和directArena 对象 当做参数出传递到了 PoolThreadLocalCache 的构造器中, 那么 heapArena 对象和directArena 对象 是在哪里被初始化的呢? 我们查找一下发现在PooledByteBufAllocator 的 构造器中调用 newArenaArray() 方法给heapArenas 和directArenas 赋值了。 public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder, int tinyCacheSize, int smallCacheSize, int normalCacheSize) &amp;#123; super(preferDirect); threadCache = new PoolThreadLocalCache(); this.tinyCacheSize = tinyCacheSize; this.smallCacheSize = smallCacheSize; this.normalCacheSize = normalCacheSize; final int chunkSize = validateAndCalculateChunkSize(pageSize, maxOrder); if (nHeapArena &lt; 0) &amp;#123; throw new IllegalArgumentException(\"nHeapArena: \" + nHeapArena + \" (expected: >= 0)\"); &amp;#125; if (nDirectArena &lt; 0) &amp;#123; throw new IllegalArgumentException(\"nDirectArea: \" + nDirectArena + \" (expected: >= 0)\"); &amp;#125; int pageShifts = validateAndCalculatePageShifts(pageSize); if (nHeapArena > 0) &amp;#123; heapArenas = newArenaArray(nHeapArena); List&lt;PoolArenaMetric> metrics = new ArrayList&lt;PoolArenaMetric>(heapArenas.length); for (int i = 0; i &lt; heapArenas.length; i ++) &amp;#123; PoolArena.HeapArena arena = new PoolArena.HeapArena(this, pageSize, maxOrder, pageShifts, chunkSize); heapArenas[i] = arena; metrics.add(arena); &amp;#125; heapArenaMetrics = Collections.unmodifiableList(metrics); &amp;#125; else &amp;#123; heapArenas = null; heapArenaMetrics = Collections.emptyList(); &amp;#125; if (nDirectArena > 0) &amp;#123; directArenas = newArenaArray(nDirectArena); List&lt;PoolArenaMetric> metrics = new ArrayList&lt;PoolArenaMetric>(directArenas.length); for (int i = 0; i &lt; directArenas.length; i ++) &amp;#123; PoolArena.DirectArena arena = new PoolArena.DirectArena( this, pageSize, maxOrder, pageShifts, chunkSize); directArenas[i] = arena; metrics.add(arena); &amp;#125; directArenaMetrics = Collections.unmodifiableList(metrics); &amp;#125; else &amp;#123; directArenas = null; directArenaMetrics = Collections.emptyList(); &amp;#125; &amp;#125; 进去到newArenaArray() 方法: private static &lt;T> PoolArena&lt;T>[] newArenaArray(int size) &amp;#123; return new PoolArena[size]; &amp;#125; 其实就是创建一个固定大小的 PoolArena 数组, 数组大小由传入的参数 数 nHeapArena 和 nDirectArena 来决定, 我们再回到PooledByteBufAllocator 的构造器源码, 看 nHeapArena 和 nDirectArena 是怎么初始化的, 我们找到了PooledByteBufAllocator 的重载构造器: public PooledByteBufAllocator(boolean preferDirect) &amp;#123; this(preferDirect, DEFAULT_NUM_HEAP_ARENA, DEFAULT_NUM_DIRECT_ARENA, DEFAULT_PAGE_SIZE, DEFAULT_MAX_ORDER); &amp;#125; 我们发现, nHeapArena 和 nDirectArena 是通过 DEFAULT_NUM_HEAP_ARENA, DEFAULT_NUM_DIRECT_ARENA 这两个常量默认赋值的, 再继续跟进常量的定义: DEFAULT_NUM_HEAP_ARENA = Math.max(0, SystemPropertyUtil.getInt( \"io.netty.allocator.numHeapArenas\", (int) Math.min( defaultMinNumArena, runtime.maxMemory() / defaultChunkSize / 2 / 3))); DEFAULT_NUM_DIRECT_ARENA = Math.max(0, SystemPropertyUtil.getInt( \"io.netty.allocator.numDirectArenas\", (int) Math.min( defaultMinNumArena, PlatformDependent.maxDirectMemory() / defaultChunkSize / 2 / 3))); 到这里为止 , 我们才知道 nHeapArena 和 nDirectArena 的默认赋值, 默认是分配CPU 核数*2, 也就是把 defaultMinNumArena的值赋值给 nHeapArena 和 nDirectArena . 那么Netty 为什么这样设计呢? 其实主要目的就是为了保证Netty 中的每一个线程任务都可以有一个独享的 Arena, 保证在每个线程分配内存的是是不用加锁的. 基于上面的分析, 我们知道 Arena 有HeapArena 和 DirectArena , 这里我们统称为Arena . 假设我们有四个线程, 那么对应会分配四个 Arena , 在创建ByteBuf 的时候, 首先通过 PoolThreadCache 获取Arena 对象并 赋值给其成员变量, 然后, 每个线程通过PoolThreadCache 调用get 方法的时候会拿到它底层的Arena , 也就是说 EventLoop1 拿到 Arena1, EventLoop2拿到 Arena2, 以此类推, 如下图所示： 那么PoolThreadCache 除了可以只在Arena 上进行内存分配，还可以在他底层维护ByteBuf 缓存列表进行分配.举个例子: 我们通过PooledByteBufAllocator 去创建了一个1024字节大小的ByteBuf, 当我们用完释放之后, 我们可能会在其他地方继续分配1024 字节大小的ByteBuf. 这个时候, 其实不需要要在 Arena 上进行内存分配, 而是直接通过 PoolThreadCache 中维护的ByteBuf 的缓存列表直接拿过来返回, 那么, 在 PooledByteBufAllocator 中维护三种规定大小的缓存列表, 分别是三个值 tinyCacheSize、smallCacheSize、normalCacheSize： public class PooledByteBufAllocator extends AbstractByteBufAllocator &amp;#123; private static final InternalLogger logger = InternalLoggerFactory.getInstance(PooledByteBufAllocator.class); private static final int DEFAULT_NUM_HEAP_ARENA; private static final int DEFAULT_NUM_DIRECT_ARENA; private static final int DEFAULT_PAGE_SIZE; private static final int DEFAULT_MAX_ORDER; // 8192 &lt;&lt; 11 = 16 MiB per chunk private static final int DEFAULT_TINY_CACHE_SIZE; private static final int DEFAULT_SMALL_CACHE_SIZE; private static final int DEFAULT_NORMAL_CACHE_SIZE; private static final int DEFAULT_MAX_CACHED_BUFFER_CAPACITY; private static final int DEFAULT_CACHE_TRIM_INTERVAL; private static final int MIN_PAGE_SIZE = 4096; private static final int MAX_CHUNK_SIZE = (int) (((long) Integer.MAX_VALUE + 1) / 2); static &amp;#123; int defaultPageSize = SystemPropertyUtil.getInt(\"io.netty.allocator.pageSize\", 8192); Throwable pageSizeFallbackCause = null; try &amp;#123; validateAndCalculatePageShifts(defaultPageSize); &amp;#125; catch (Throwable t) &amp;#123; pageSizeFallbackCause = t; defaultPageSize = 8192; &amp;#125; DEFAULT_PAGE_SIZE = defaultPageSize; int defaultMaxOrder = SystemPropertyUtil.getInt(\"io.netty.allocator.maxOrder\", 11); Throwable maxOrderFallbackCause = null; try &amp;#123; validateAndCalculateChunkSize(DEFAULT_PAGE_SIZE, defaultMaxOrder); &amp;#125; catch (Throwable t) &amp;#123; maxOrderFallbackCause = t; defaultMaxOrder = 11; &amp;#125; DEFAULT_MAX_ORDER = defaultMaxOrder; // Determine reasonable default for nHeapArena and nDirectArena. // Assuming each arena has 3 chunks, the pool should not consume more than 50% of max memory. final Runtime runtime = Runtime.getRuntime(); // Use 2 * cores by default to reduce condition as we use 2 * cores for the number of EventLoops // in NIO and EPOLL as well. If we choose a smaller number we will run into hotspots as allocation and // deallocation needs to be synchronized on the PoolArena. // See https://github.com/netty/netty/issues/3888 final int defaultMinNumArena = runtime.availableProcessors() * 2; final int defaultChunkSize = DEFAULT_PAGE_SIZE &lt;&lt; DEFAULT_MAX_ORDER; DEFAULT_NUM_HEAP_ARENA = Math.max(0, SystemPropertyUtil.getInt( \"io.netty.allocator.numHeapArenas\", (int) Math.min( defaultMinNumArena, runtime.maxMemory() / defaultChunkSize / 2 / 3))); DEFAULT_NUM_DIRECT_ARENA = Math.max(0, SystemPropertyUtil.getInt( \"io.netty.allocator.numDirectArenas\", (int) Math.min( defaultMinNumArena, PlatformDependent.maxDirectMemory() / defaultChunkSize / 2 / 3))); // cache sizes DEFAULT_TINY_CACHE_SIZE = SystemPropertyUtil.getInt(\"io.netty.allocator.tinyCacheSize\", 512); DEFAULT_SMALL_CACHE_SIZE = SystemPropertyUtil.getInt(\"io.netty.allocator.smallCacheSize\", 256); DEFAULT_NORMAL_CACHE_SIZE = SystemPropertyUtil.getInt(\"io.netty.allocator.normalCacheSize\", 64); // 32 kb is the default maximum capacity of the cached buffer. Similar to what is explained in // 'Scalable memory allocation using jemalloc' DEFAULT_MAX_CACHED_BUFFER_CAPACITY = SystemPropertyUtil.getInt( \"io.netty.allocator.maxCachedBufferCapacity\", 32 * 1024); // the number of threshold of allocations when cached entries will be freed up if not frequently used DEFAULT_CACHE_TRIM_INTERVAL = SystemPropertyUtil.getInt( \"io.netty.allocator.cacheTrimInterval\", 8192); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"-Dio.netty.allocator.numHeapArenas: &amp;#123;&amp;#125;\", DEFAULT_NUM_HEAP_ARENA); logger.debug(\"-Dio.netty.allocator.numDirectArenas: &amp;#123;&amp;#125;\", DEFAULT_NUM_DIRECT_ARENA); if (pageSizeFallbackCause == null) &amp;#123; logger.debug(\"-Dio.netty.allocator.pageSize: &amp;#123;&amp;#125;\", DEFAULT_PAGE_SIZE); &amp;#125; else &amp;#123; logger.debug(\"-Dio.netty.allocator.pageSize: &amp;#123;&amp;#125;\", DEFAULT_PAGE_SIZE, pageSizeFallbackCause); &amp;#125; if (maxOrderFallbackCause == null) &amp;#123; logger.debug(\"-Dio.netty.allocator.maxOrder: &amp;#123;&amp;#125;\", DEFAULT_MAX_ORDER); &amp;#125; else &amp;#123; logger.debug(\"-Dio.netty.allocator.maxOrder: &amp;#123;&amp;#125;\", DEFAULT_MAX_ORDER, maxOrderFallbackCause); &amp;#125; logger.debug(\"-Dio.netty.allocator.chunkSize: &amp;#123;&amp;#125;\", DEFAULT_PAGE_SIZE &lt;&lt; DEFAULT_MAX_ORDER); logger.debug(\"-Dio.netty.allocator.tinyCacheSize: &amp;#123;&amp;#125;\", DEFAULT_TINY_CACHE_SIZE); logger.debug(\"-Dio.netty.allocator.smallCacheSize: &amp;#123;&amp;#125;\", DEFAULT_SMALL_CACHE_SIZE); logger.debug(\"-Dio.netty.allocator.normalCacheSize: &amp;#123;&amp;#125;\", DEFAULT_NORMAL_CACHE_SIZE); logger.debug(\"-Dio.netty.allocator.maxCachedBufferCapacity: &amp;#123;&amp;#125;\", DEFAULT_MAX_CACHED_BUFFER_CAPACITY); logger.debug(\"-Dio.netty.allocator.cacheTrimInterval: &amp;#123;&amp;#125;\", DEFAULT_CACHE_TRIM_INTERVAL); &amp;#125; &amp;#125; public static final PooledByteBufAllocator DEFAULT = new PooledByteBufAllocator(PlatformDependent.directBufferPreferred()); private final PoolArena&lt;byte[]>[] heapArenas; private final PoolArena&lt;ByteBuffer>[] directArenas; private final int tinyCacheSize; private final int smallCacheSize; private final int normalCacheSize; private final List&lt;PoolArenaMetric> heapArenaMetrics; private final List&lt;PoolArenaMetric> directArenaMetrics; private final PoolThreadLocalCache threadCache; public PooledByteBufAllocator() &amp;#123; this(false); &amp;#125; public PooledByteBufAllocator(boolean preferDirect) &amp;#123; this(preferDirect, DEFAULT_NUM_HEAP_ARENA, DEFAULT_NUM_DIRECT_ARENA, DEFAULT_PAGE_SIZE, DEFAULT_MAX_ORDER); &amp;#125; public PooledByteBufAllocator(int nHeapArena, int nDirectArena, int pageSize, int maxOrder) &amp;#123; this(false, nHeapArena, nDirectArena, pageSize, maxOrder); &amp;#125; public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder) &amp;#123; this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder, DEFAULT_TINY_CACHE_SIZE, DEFAULT_SMALL_CACHE_SIZE, DEFAULT_NORMAL_CACHE_SIZE); &amp;#125; .............. &amp;#125; 我们看到, 在 PooledByteBufAllocator 的构造器中, 分 别 赋 值 了 tinyCacheSize=512 ， smallCacheSize=256 ，normalCacheSize=64。通过这样一种方式，Netty 中给我们预创建固定规格的内存池，大大提高了内存分配的性能。 2. DirectArena 内存分配流程Arena 分配内存的基本流程有三个步骤: 从对象池中拿到 PooledByteBuf 进行复用 从缓存中进行内存分配 从内存堆中进行内存分配 我们以directBuff 为例, 首先来看从对象池中拿到 PooledByteBuf 对象进行复用的情况, 我们依旧跟进到 PooledByteBufAllocator 的 newDirectBuffer()方法 @Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &amp;#123; PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer> directArena = cache.directArena; ByteBuf buf; if (directArena != null) &amp;#123; buf = directArena.allocate(cache, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; if (PlatformDependent.hasUnsafe()) &amp;#123; buf = UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; else &amp;#123; buf = new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); &amp;#125; &amp;#125; return toLeakAwareBuffer(buf); &amp;#125; 上面的PoolArena 我们已经清楚, 现在我们直接跟进到 PoolArena 的allocate() 方法: PooledByteBuf&lt;T> allocate(PoolThreadCache cache, int reqCapacity, int maxCapacity) &amp;#123; PooledByteBuf&lt;T> buf = newByteBuf(maxCapacity); allocate(cache, buf, reqCapacity); return buf; &amp;#125; 在这个地方其实就非常清晰了, 首先调用 newByteBuf() 方法拿到一个PooledByteBuf 对象, 接下来通过 allocate() 方法在线程私有的 PoolThreadCache 中分配一块内存, 然后buf 里面的内存地址之类的值进行初始化,我们跟进到 newByteBuf() 看一下, 选择 DirectArena 对象： @Override protected PooledByteBuf&lt;ByteBuffer> newByteBuf(int maxCapacity) &amp;#123; if (HAS_UNSAFE) &amp;#123; return PooledUnsafeDirectByteBuf.newInstance(maxCapacity); &amp;#125; else &amp;#123; return PooledDirectByteBuf.newInstance(maxCapacity); &amp;#125; &amp;#125; 我们发现首先判断是否支持 Unsafe, 默认情况下一般是支持 Unsafe 的, 虽然我们继续进入到 PooledUnsafeDirectByteBuf 的 newInstance()方法： final class PooledUnsafeDirectByteBuf extends PooledByteBuf&lt;ByteBuffer> &amp;#123; private static final Recycler&lt;PooledUnsafeDirectByteBuf> RECYCLER = new Recycler&lt;PooledUnsafeDirectByteBuf>() &amp;#123; @Override protected PooledUnsafeDirectByteBuf newObject(Handle&lt;PooledUnsafeDirectByteBuf> handle) &amp;#123; return new PooledUnsafeDirectByteBuf(handle, 0); &amp;#125; &amp;#125;; static PooledUnsafeDirectByteBuf newInstance(int maxCapacity) &amp;#123; PooledUnsafeDirectByteBuf buf = RECYCLER.get(); buf.reuse(maxCapacity); return buf; &amp;#125; &amp;#125; 顾名思义, 我看到首先就是从 RECYCLER (也就是内存回收站) 对象的 get() 方法中拿到一个buf, 从上面的代码片段来看, RECYCLER 对象实现了一个newObject() 方法, 当回收站里面没有可用的buf时就会去创建一个新的buf. 因为创建的buf 可能是从回收站拿出来的 , 复用前需要重置,因此继续往下看就会调用buf 的reuse() 方法. /** * Method must be called before reuse this &amp;#123;@link PooledByteBufAllocator&amp;#125; */ final void reuse(int maxCapacity) &amp;#123; maxCapacity(maxCapacity); setRefCnt(1); setIndex0(0, 0); discardMarks(); &amp;#125; 我们发现 reuse() 就是对所有的参数重新归为初始状态, 到这里我们已经清楚从内存池获取buf 对象的全过程. 那么接下来, 再回到PoolArena 的 allocate()方法. 看看真实的内存是如何分配出来的, buf 的内存分配主要有两种情况: 分别是:从缓存中进行内存分配和从内存堆中进行内存分配, 我们来看代码, 进入 allocate() 方法具体逻辑： private void allocate(PoolThreadCache cache, PooledByteBuf&lt;T> buf, final int reqCapacity) &amp;#123; final int normCapacity = normalizeCapacity(reqCapacity); if (isTinyOrSmall(normCapacity)) &amp;#123; // capacity &lt; pageSize int tableIdx; PoolSubpage&lt;T>[] table; boolean tiny = isTiny(normCapacity); if (tiny) &amp;#123; // &lt; 512 if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; tableIdx = tinyIdx(normCapacity); table = tinySubpagePools; &amp;#125; else &amp;#123; if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; tableIdx = smallIdx(normCapacity); table = smallSubpagePools; &amp;#125; final PoolSubpage&lt;T> head = table[tableIdx]; /** * Synchronize on the head. This is needed as &amp;#123;@link PoolChunk#allocateSubpage(int)&amp;#125; and * &amp;#123;@link PoolChunk#free(long)&amp;#125; may modify the doubly linked list as well. */ synchronized (head) &amp;#123; final PoolSubpage&lt;T> s = head.next; if (s != head) &amp;#123; assert s.doNotDestroy &amp;&amp; s.elemSize == normCapacity; long handle = s.allocate(); assert handle >= 0; s.chunk.initBufWithSubpage(buf, handle, reqCapacity); if (tiny) &amp;#123; allocationsTiny.increment(); &amp;#125; else &amp;#123; allocationsSmall.increment(); &amp;#125; return; &amp;#125; &amp;#125; allocateNormal(buf, reqCapacity, normCapacity); return; &amp;#125; if (normCapacity &lt;= chunkSize) &amp;#123; if (cache.allocateNormal(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; allocateNormal(buf, reqCapacity, normCapacity); &amp;#125; else &amp;#123; // Huge allocations are never served via the cache so just call allocateHuge allocateHuge(buf, reqCapacity); &amp;#125; &amp;#125; 这段代码逻辑看起来非常复杂, 其实大部分的逻辑基本上都是判断不同的规格大小, 从其对应的缓存中获取内存, 如果所有的规格都不满足, 那就直接调用allocateHuge() 方法进行真实的内存分配. 3. 内存池的内存规格在前面的源码分析中, 关于内存规格大小我们应该还有些印象, 其实在Netty 内存池中主要设置了四种规格大小的内存: tiny 是指0-512byte 之间的规格大小 small 是指512byte - 8kb 之间的规格大小 normal 是指8kb - 16MB 之间的规格大小 buge 是指16MB 以上的 为什么Netty 会选择这些值作为一个分界点呢? 其实在Netty 底层还有一个内存单位的封装. 为了更高效的管理内存, 避免内存浪费, 把每一个区间的内存规格都做了细分. 默认情况下, Netty 将内存规格分为四个部分. Netty 中所有的内存申请是以Chunk 为单位向内存申请的, 大小为16M， 后续的内存分配都是在这个Chunk里面的操作. 8KB 对应的是一个Page, 一个Chunk 会以Page 为单位进行切分. 8KB 对应的Chunk 被划分为2048个Page. 小于8K的对应的是SubPage. 例如: 我们申请的是一段内存空间只有1K , 却给我们分配了一个Page, 显然另外7K 就会被浪费, 所以继续把Page 进行划分, 节省空间 . 如下图所示: 至此, 小伙伴应该已经非常清楚Netty的内存池缓存管理机制了. 4. 命中缓存的分配前面我们简单分析了directArena 内容分配大概流程, 知道其先命中缓存, 如果命中不到, 则去分配一款连续内存. 现在带大家剖析命中缓存的相关逻辑. 前面我们也讲到 PoolThreadCache 中维护了三个缓存数组(实际上是六个, 这里 仅 仅 以 Direct 为 例 , Heap 类 型 的 逻 辑 是 一 样 的 ): tinySubPageDirectCaches, smallSubPageDirectCaches, 和normalDirectCaches 分别代表 tiny 类型, small 类型和 normal 类型的缓存数组）。这三个数组保存在 PoolThreadCache的成员变量中: final class PoolThreadCache &amp;#123; ... private final MemoryRegionCache&lt;ByteBuffer>[] tinySubPageDirectCaches; private final MemoryRegionCache&lt;ByteBuffer>[] smallSubPageDirectCaches; private final MemoryRegionCache&lt;ByteBuffer>[] normalDirectCaches; ... &amp;#125; 其实是在构造方法中进行了初始化: PoolThreadCache(PoolArena&lt;byte[]> heapArena, PoolArena&lt;ByteBuffer> directArena, int tinyCacheSize, int smallCacheSize, int normalCacheSize, int maxCachedBufferCapacity, int freeSweepAllocationThreshold) &amp;#123; ... if (directArena != null) &amp;#123; tinySubPageDirectCaches = createSubPageCaches( tinyCacheSize, PoolArena.numTinySubpagePools, SizeClass.Tiny); smallSubPageDirectCaches = createSubPageCaches( smallCacheSize, directArena.numSmallSubpagePools, SizeClass.Small); numShiftsNormalDirect = log2(directArena.pageSize); normalDirectCaches = createNormalCaches( normalCacheSize, maxCachedBufferCapacity, directArena); directArena.numThreadCaches.getAndIncrement(); &amp;#125; ... &amp;#125; 我们以tiny 类型为例 跟到createSubPageCaches 方法中: private static &lt;T> MemoryRegionCache&lt;T>[] createSubPageCaches( int cacheSize, int numCaches, SizeClass sizeClass) &amp;#123; if (cacheSize > 0) &amp;#123; @SuppressWarnings(\"unchecked\") MemoryRegionCache&lt;T>[] cache = new MemoryRegionCache[numCaches]; for (int i = 0; i &lt; cache.length; i++) &amp;#123; // TODO: maybe use cacheSize / cache.length cache[i] = new SubPageMemoryRegionCache&lt;T>(cacheSize, sizeClass); &amp;#125; return cache; &amp;#125; else &amp;#123; return null; &amp;#125; &amp;#125; 从代码来看, 其实就是创建了一个缓存数组, 这个缓存数组的长度, 也就是 numCaches, 在不同的类型, 这个长度不一样 . tiny类型长度是32,small 类型长度为4, normal 类型长度为3.我们知道， 缓存数组中每个节点代表一个缓存对象, 里面维护一个队列. 队列大小由PooledByteBufAllocator 类 中 的 tinyCacheSize, smallCacheSize, normalCacheSize 属性决定的。其中每个缓存对象, 队列中缓存的ByteBuf 大小的固定的. netty 将每种缓存区类型分为了不同的长度规格 ,而每个缓存中的队列缓存的Bytebuf的长度, 都是同一个规格的长度, 而缓冲区数组的长度, 就是规格的数量. 比如: 在 tiny 类型中, Netty将其长度为了32个规格, 每个规格都是16的整数倍, 也就是包含0Byte、16Byte、32Byte、48Byte、64Byte，96Byte…总共32种规格. 而在其缓存数组tinySubPageDirectCaches 中, 这每一种规格代表数组中的一个缓存对象缓存的ByteBuf的大小, 我们以tinySubPageDirectCaches[1]为例,(这里下标选择1是因为下标为0的规格是0Byte, 其实就代表一个空的缓存, 这里不进行举例). 在 tinySubPageDirectCaches[1] 的缓存对象中所缓存的ByteBuf的缓存长度是16Byte, tinySubPageDirectCaches[2] 中缓存的ByteBuf 长度为32Byte. 以此类推, tinySubPageDirectCaches[31]中缓存的 ByteBuf 长度为 496Byte。其具体类型规则的配置如下:tiny:总共 32 个规格, 均是 16 的整数倍, 0Byte, 16Byte, 32Byte, 48Byte, 64Byte, 80Byte, 96Byte……496Byte； small:4 种规格, 512Byte, 1KB, 2KB, 4KB； normal: 3种规格, 8KB、16KB、32KB; 如此我们得出结论PoolThreadCache 中缓存数组的数据结构如下图所示: 在基本了解缓存数组的数据结构后, 我们再继续剖析在缓存中分配内存的逻辑. 回到到 PoolArena 的 allocate() 方法中: private void allocate(PoolThreadCache cache, PooledByteBuf&lt;T> buf, final int reqCapacity) &amp;#123; final int normCapacity = normalizeCapacity(reqCapacity); // 规格化 if (isTinyOrSmall(normCapacity)) &amp;#123; // capacity &lt; pageSize int tableIdx; PoolSubpage&lt;T>[] table; // 判断是不是tiny boolean tiny = isTiny(normCapacity); if (tiny) &amp;#123; // &lt; 512 // 缓存分配 if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; // 通过tinyIdx 拿到tableIdx tableIdx = tinyIdx(normCapacity); // subpage 的数组 table = tinySubpagePools; &amp;#125; else &amp;#123; if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; tableIdx = smallIdx(normCapacity); table = smallSubpagePools; &amp;#125; // 拿到对应的节点 final PoolSubpage&lt;T> head = table[tableIdx]; /** * Synchronize on the head. This is needed as &amp;#123;@link PoolChunk#allocateSubpage(int)&amp;#125; and * &amp;#123;@link PoolChunk#free(long)&amp;#125; may modify the doubly linked list as well. */ synchronized (head) &amp;#123; final PoolSubpage&lt;T> s = head.next; // 默认情况下head的next 也是自身 if (s != head) &amp;#123; assert s.doNotDestroy &amp;&amp; s.elemSize == normCapacity; long handle = s.allocate(); assert handle >= 0; s.chunk.initBufWithSubpage(buf, handle, reqCapacity); if (tiny) &amp;#123; allocationsTiny.increment(); &amp;#125; else &amp;#123; allocationsSmall.increment(); &amp;#125; return; &amp;#125; &amp;#125; allocateNormal(buf, reqCapacity, normCapacity); return; &amp;#125; if (normCapacity &lt;= chunkSize) &amp;#123; // 首先在缓存上进行内存分配 if (cache.allocateNormal(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on // 分配成功. 返回 return; &amp;#125; // 分配不成功, 做实际的内存分配 allocateNormal(buf, reqCapacity, normCapacity); &amp;#125; else &amp;#123; // Huge allocations are never served via the cache so just call allocateHuge // 大于这个值, 就不在缓存上分配 allocateHuge(buf, reqCapacity); &amp;#125; &amp;#125; 首先是通过normalizeCapacity() 方法进行内存规格化, 我们跟到normalizeCapacity 方法中: int normalizeCapacity(int reqCapacity) &amp;#123; if (reqCapacity &lt; 0) &amp;#123; throw new IllegalArgumentException(\"capacity: \" + reqCapacity + \" (expected: 0+)\"); &amp;#125; if (reqCapacity >= chunkSize) &amp;#123; return reqCapacity; &amp;#125; // 如果 > tiny if (!isTiny(reqCapacity)) &amp;#123; // >= 512 // Doubled // 找一个2的幂次方数值, 确保数值大小等于reqCapacity int normalizedCapacity = reqCapacity; normalizedCapacity --; normalizedCapacity |= normalizedCapacity >>> 1; normalizedCapacity |= normalizedCapacity >>> 2; normalizedCapacity |= normalizedCapacity >>> 4; normalizedCapacity |= normalizedCapacity >>> 8; normalizedCapacity |= normalizedCapacity >>> 16; normalizedCapacity ++; if (normalizedCapacity &lt; 0) &amp;#123; normalizedCapacity >>>= 1; &amp;#125; return normalizedCapacity; &amp;#125; // Quantum-spaced // 如果是16 的倍数 , if ((reqCapacity &amp; 15) == 0) &amp;#123; return reqCapacity; &amp;#125; // 如果不是16的倍数, 变成最大小于当前值的值+ 16 return (reqCapacity &amp; ~15) + 16; &amp;#125; 上面代码中 if (!isTiny(reqCapacity)) 代表如果大于tiny 类型的大小，也就是512, 则会找一个2的幂次方的数值, 确保这个数值大小等于reqCapacity。如果是tiny , 则继续往下 if ((reqCapacity &amp; 15) == 0), 这里判断如果是16 的倍数, 则直接返回 . 如果不是16的倍数, 则返回(reqCapacity &amp; ~15) + 16 , 也就是变成最小大于当前值的16 的倍数值。从上面规格化逻辑看出, 这里将缓存大小规格化成固定大小, 确保每个缓存对象缓存的ByteBuf 容量统一. 回到allocate() 方法, ： if(isTinyOrSmall(normCapacity)) 这里是根据规格化后的大小判断是否是tiny 或者small类型, 我们跟进去: // capacity &lt; pageSize boolean isTinyOrSmall(int normCapacity) &amp;#123; return (normCapacity &amp; subpageOverflowMask) == 0; &amp;#125; 这个方法是判断如果normCapacity 小于一个page 的大小, 则就是8KB 代表其是tiny 或者small. 继续看allocate() 方法，如果当前大小是tiny 或者small, 则 isTiny(normCapacity)判断是否是 tiny 类型,跟进去: // normCapacity &lt; 512 static boolean isTiny(int normCapacity) &amp;#123; return (normCapacity &amp; 0xFFFFFE00) == 0; &amp;#125; 这个方法是判断如果小于512, 就认为是tiny. 再继续看 allocate() 方法, 如果是tiny, 则通过 cache.allocateTiny(this, buf, reqCapacity, normCapacity)在缓存上分配. 我们就以tiny 类型为例, 分析在缓存上分配ByteBuf 的流, allocateTiny 是缓存分配的入口. 我们跟进去: 进入到了PoolThreadCache 的 allocateTiny()方法中: boolean allocateTiny(PoolArena&lt;?> area, PooledByteBuf&lt;?> buf, int reqCapacity, int normCapacity) &amp;#123; return allocate(cacheForTiny(area, normCapacity), buf, reqCapacity); &amp;#125; 这里有个方法cacheForTiny(area, normCapacity), 这个方法的作用是根据normCapacity 找到tiny类型缓存数组中的一个缓存对象, 我们跟进去cacheForTiny方法: private MemoryRegionCache&lt;?> cacheForTiny(PoolArena&lt;?> area, int normCapacity) &amp;#123; int idx = PoolArena.tinyIdx(normCapacity); if (area.isDirect()) &amp;#123; return cache(tinySubPageDirectCaches, idx); &amp;#125; return cache(tinySubPageHeapCaches, idx); &amp;#125; PoolArena.tinyIdx(normCapacity)是找到tiny类型缓存数组的下标, 继续跟进到 tinyIdx 方法: static int tinyIdx(int normCapacity) &amp;#123; return normCapacity >>> 4; &amp;#125; 这里相当于直接将 normCapacity 除以16, 通过前面的内容我们知道， tiny 类型缓存数组中的每个元素规格化的数据都是16的倍数, 所以通过这种方式可以找到其下标, 如果是16Byte 会拿到下标为1的元素， 如果是32Byte 会拿到下标为2的元素. 回到acheForTiny()方法中： if (area.isDirect()) 这里是判断是否分配堆外内存, 因为我们是按照堆外内存进行举例的, 所以这里是true, 再继续跟到到 cache(tinySubPageDirectCaches, idx)方法： private static &lt;T> MemoryRegionCache&lt;T> cache(MemoryRegionCache&lt;T>[] cache, int idx) &amp;#123; if (cache == null || idx > cache.length - 1) &amp;#123; return null; &amp;#125; return cache[idx]; &amp;#125; 这里我们看到直接通过下标的方式拿到了缓存数组中的对象, 回到到 PoolThreadCache 的 allocateTiny()方法中： boolean allocateTiny(PoolArena&lt;?> area, PooledByteBuf&lt;?> buf, int reqCapacity, int normCapacity) &amp;#123; return allocate(cacheForTiny(area, normCapacity), buf, reqCapacity); &amp;#125; 拿到了缓存对象后, 我们跟到 allocate(cacheForTiny(area, normCapacity), buf, reqCapacity) 方法中: private boolean allocate(MemoryRegionCache&lt;?> cache, PooledByteBuf buf, int reqCapacity) &amp;#123; if (cache == null) &amp;#123; // no cache found so just return false here return false; &amp;#125; boolean allocated = cache.allocate(buf, reqCapacity); if (++ allocations >= freeSweepAllocationThreshold) &amp;#123; allocations = 0; trim(); &amp;#125; return allocated; &amp;#125; 分析上面的代码, 看到cache.allocate(buf, reqCapacity) 进行继续分配, 再继续往里跟, 来到内部类MemoryRegionCache 的 allocate(PooledByteBuf buf, int reqCapacity)方法： /** * Allocate something out of the cache if possible and remove the entry from the cache. */ public final boolean allocate(PooledByteBuf&lt;T> buf, int reqCapacity) &amp;#123; Entry&lt;T> entry = queue.poll(); if (entry == null) &amp;#123; return false; &amp;#125; initBuf(entry.chunk, entry.handle, buf, reqCapacity); entry.recycle(); // allocations is not thread-safe which is fine as this is only called from the same thread all time. ++ allocations; return true; &amp;#125; 这个方法, 首先通过 queue.poll()这种方式弹出一个Entry, 我们之前分析过MemoryRegionCache 维护这一个队列, 而队列中的每一个值是一个entry, 我们简单来看一下Entry 这个类 static final class Entry&lt;T> &amp;#123; final Handle&lt;Entry&lt;?>> recyclerHandle; PoolChunk&lt;T> chunk; long handle = -1; Entry(Handle&lt;Entry&lt;?>> recyclerHandle) &amp;#123; this.recyclerHandle = recyclerHandle; &amp;#125; void recycle() &amp;#123; chunk = null; handle = -1; recyclerHandle.recycle(this); &amp;#125; &amp;#125; 我们重点关注 chunk 和handler 这两个属性, chunk 代表一块连续的内存, 我们之前简单介绍过, Netty 是通过chunk 为单位进行内存分配的. handler 相当于一个指针, 可以唯一定位到chunk 里面的一块连续的内存. 这样, 通过chunk和handler 就可以定位到ByteBuf 中的指定的一块连续的内存, 有关ByteBuf 相关的读写， 都会在这块内存中进行, 现在再回到MemoryRegionCache 的 allocate(PooledByteBuf buf,int reqCapacity)方法： /** * Allocate something out of the cache if possible and remove the entry from the cache. */ public final boolean allocate(PooledByteBuf&lt;T> buf, int reqCapacity) &amp;#123; Entry&lt;T> entry = queue.poll(); if (entry == null) &amp;#123; return false; &amp;#125; initBuf(entry.chunk, entry.handle, buf, reqCapacity); entry.recycle(); // allocations is not thread-safe which is fine as this is only called from the same thread all time. ++ allocations; return true; &amp;#125; 弹出entry后, 通过initBuf(entry.chunk, entry.handle, buf, reqCapacity) 这种方式给ByteBuf 初始化， 这里参数传入我们刚才分析过的 当前的entry的chunk 和handler, 因为我们分析的 tiny 类型的缓存对象是SubPageMemoryRegionCache 类型, 所以继续回到SubPageMemoryRegionCache 类的initBuf(entry.chunk, entry.handle, buf, reqCapacity)方法中： @Override protected void initBuf( PoolChunk&lt;T> chunk, long handle, PooledByteBuf&lt;T> buf, int reqCapacity) &amp;#123; chunk.initBufWithSubpage(buf, handle, reqCapacity); &amp;#125; 这里的chunk 调用了了 initBufWithSubpage(buf, handle, reqCapacity)方法, 其实就是PoolChunk 类中的方法, 我们继续initBufWithSubpage() 方法: void initBufWithSubpage(PooledByteBuf&lt;T> buf, long handle, int reqCapacity) &amp;#123; initBufWithSubpage(buf, handle, bitmapIdx(handle), reqCapacity); &amp;#125; 上面代码中, 调用了 bitmapIdx()方法, 有关 bitmapIdx()方法相关的逻辑, 会再后面进行剖析,这里继续往里看, 看 initBufWithSubpage 的逻辑: private void initBufWithSubpage(PooledByteBuf&lt;T> buf, long handle, int bitmapIdx, int reqCapacity) &amp;#123; assert bitmapIdx != 0; int memoryMapIdx = memoryMapIdx(handle); PoolSubpage&lt;T> subpage = subpages[subpageIdx(memoryMapIdx)]; assert subpage.doNotDestroy; assert reqCapacity &lt;= subpage.elemSize; buf.init( this, handle, runOffset(memoryMapIdx) + (bitmapIdx &amp; 0x3FFFFFFF) * subpage.elemSize, reqCapacity, subpage.elemSize, arena.parent.threadCache()); &amp;#125; 我们先关注 init() 方法, 因为我们是以PooledUnsafeDirectByteBuf 为例,所以这里走的是PooledUnsafeDirectByteBuf 的 init() 方法, 进入init() 方法： @Override void init(PoolChunk&lt;ByteBuffer> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache) &amp;#123; super.init(chunk, handle, offset, length, maxLength, cache); initMemoryAddress(); &amp;#125; 首先调用了父类的init() 方法，继续跟进去: void init(PoolChunk&lt;T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache) &amp;#123; assert handle >= 0; assert chunk != null; this.chunk = chunk; this.handle = handle; memory = chunk.memory; this.offset = offset; this.length = length; this.maxLength = maxLength; tmpNioBuf = null; this.cache = cache; &amp;#125; 上面的代码就是将PooledUnsafeDirectByteBuf 的各个属性进行了初始化: this.chunk = chunk 这里初始化了 chunk, 代表当前的 ByteBuf 是在哪一块内存中分配的。 this.handle = handle 这里初始化了 handle, 代表当前的 ByteBuf 是这块内存的哪个连续内存。 有关 offset 和 length, 我们会在之后再分析, 在这里我们只需要知道, 通过缓存分配 ByteBuf, 我们只需要通过一个chunk 和 handle, 就可以确定一块内存，以上就是通过缓存分配 ByteBuf 对象的全过程。 现在，我们回到 MemoryRegionCache 的 allocate(PooledByteBuf buf, int reqCapacity)方法： public final boolean allocate(PooledByteBuf&lt;T> buf, int reqCapacity) &amp;#123; Entry&lt;T> entry = queue.poll(); if (entry == null) &amp;#123; return false; &amp;#125; initBuf(entry.chunk, entry.handle, buf, reqCapacity); entry.recycle(); // allocations is not thread-safe which is fine as this is only called from the same thread all time. ++ allocations; return true; &amp;#125; 分析完了initBuf() 方法，再继续往下看, entry.recycle() 这步是将 entry 对象进行回收, 因为entry 对象弹出后没有在被引用，可能gc 会将entry 对象进行回收, netty为了将对象进行循环利用, 就将其对象放在回收站进行回收,我们跟进到recycle() 方法: void recycle() &amp;#123; chunk = null; handle = -1; recyclerHandle.recycle(this); &amp;#125; chunk = null 和handler = -1 表示当前entry 不指向任何一块内存,recyclerHandle.recycle(this) 将当前entry 回收, 以上就是命中缓存的流程, 因为这里我们是假设缓存中有值的情况下， 如果第一次分配, 缓存中是没有值的, 那么在缓存中没有值的i情况下, Netty 是如何进行分配的呢? 我们在后面再详细分析： 最后, 我们简单总结一下MemoryRegionCache 对象的基本结构, 如下图所示: 5. Page 级别的内存分配之前我们介绍过,Netty 内存分配的单位是chunk, 一个chunk 的大小是16MB,实际上每个chunk都以双向链表的形式保存在一个chunkList中, 而多个chunkList 同样也是双向链表进行关联的, 大概结构如下: 在chunkList 中, 是根据chunk 的内存使用率归到一个chunkList中, 这样, 在内存分配时, 会根据百分比找到相应的chunkList, 在chunkList 中选择一个chunk 进行内存分配, 我们来看PoolArena 有关 chunkList 的成员变量: q100 = new PoolChunkList&lt;T>(null, 100, Integer.MAX_VALUE, chunkSize); q075 = new PoolChunkList&lt;T>(q100, 75, 100, chunkSize); q050 = new PoolChunkList&lt;T>(q075, 50, 100, chunkSize); q025 = new PoolChunkList&lt;T>(q050, 25, 75, chunkSize); q000 = new PoolChunkList&lt;T>(q025, 1, 50, chunkSize); qInit = new PoolChunkList&lt;T>(q000, Integer.MIN_VALUE, 25, chunkSize); 这里总共定义了6个chunkList, 并在构造方法中将其进行初始化, 我们跟到其构造方法: protected PoolArena(PooledByteBufAllocator parent, int pageSize, int maxOrder, int pageShifts, int chunkSize) &amp;#123; this.parent = parent; this.pageSize = pageSize; this.maxOrder = maxOrder; this.pageShifts = pageShifts; this.chunkSize = chunkSize; subpageOverflowMask = ~(pageSize - 1); tinySubpagePools = newSubpagePoolArray(numTinySubpagePools); for (int i = 0; i &lt; tinySubpagePools.length; i ++) &amp;#123; tinySubpagePools[i] = newSubpagePoolHead(pageSize); &amp;#125; numSmallSubpagePools = pageShifts - 9; smallSubpagePools = newSubpagePoolArray(numSmallSubpagePools); for (int i = 0; i &lt; smallSubpagePools.length; i ++) &amp;#123; smallSubpagePools[i] = newSubpagePoolHead(pageSize); &amp;#125; q100 = new PoolChunkList&lt;T>(null, 100, Integer.MAX_VALUE, chunkSize); q075 = new PoolChunkList&lt;T>(q100, 75, 100, chunkSize); q050 = new PoolChunkList&lt;T>(q075, 50, 100, chunkSize); q025 = new PoolChunkList&lt;T>(q050, 25, 75, chunkSize); q000 = new PoolChunkList&lt;T>(q025, 1, 50, chunkSize); qInit = new PoolChunkList&lt;T>(q000, Integer.MIN_VALUE, 25, chunkSize); q100.prevList(q075); q075.prevList(q050); q050.prevList(q025); q025.prevList(q000); q000.prevList(null); qInit.prevList(qInit); List&lt;PoolChunkListMetric> metrics = new ArrayList&lt;PoolChunkListMetric>(6); metrics.add(qInit); metrics.add(q000); metrics.add(q025); metrics.add(q050); metrics.add(q075); metrics.add(q100); chunkListMetrics = Collections.unmodifiableList(metrics); &amp;#125; 首先通过new PoolChunkList() 这种方式将每个chunkList 进行创建,我们以q050 = new PoolChunkList(q075, 50, 100, chunkSize) 为例进行简单介绍, q075 表示当前q50 的下一个节点是q075, 刚才我们讲过ChunkList 是通过双向链表进行关联的. 所以这里不难理解, 参数50 和100 表示当前chunkList 中存储的chunk 的内存使用率都在50% 到100% 之间. 最后chunkSize 为其设置大小, 创建完ChunkList 之后, 再设置其上一个节点,, q050.prevList(q025) 为例, 这里代表当前chunkList 的上一个节点是q025, 以这种方式创建完成之后, chunkList 的节点关系就变成了如下图所示: Netty中,chunk 又包含了多个Page, 每个page 的大小为8KB, 如果要分配16KB的内存, 就要在chunk 汇总找到连续的两个page就可以分配, 对应关系如下: 很多场景下,为缓冲区分配8KB的内存也是一种浪费, 比如只需要分配2KB的缓存区, 如果使用8KB的就会造成6KB的浪费, 这种情况下，Netty 又会将page 切分成多个subpage, 每个subpage 大小要根据分配的缓冲区大小而指定, 比如要分配2KB 的内存, 就会将一个page切分成4个subpage, 每个subpage 的大小为2KB, 如下图: 来看看PoolSubpage 的基本结构: final class PoolSubpage&lt;T> implements PoolSubpageMetric &amp;#123; final PoolChunk&lt;T> chunk; private final int memoryMapIdx; private final int runOffset; private final int pageSize; private final long[] bitmap; PoolSubpage&lt;T> prev; PoolSubpage&lt;T> next; boolean doNotDestroy; int elemSize; private int maxNumElems; private int bitmapLength; private int nextAvail; private int numAvail; &amp;#125; chunk 代表其子页属于哪个chunk, bitmap 用于记录子页的内存分配情况, prev和 next, 代表子页是按照双向链表进行关联的, 这里分别指向上一个和下一个节点, elemSize 属性代表就是这个子页是按照多大内存进行划分的, 如果按照1KB 进行划分, 则可以划分出8个子页, 简单介绍了内存分配的数据结构. 我们开始剖析Netty 级别上分配内存的流程, 还是回到PoolArena 的 allocate 方法： private void allocate(PoolThreadCache cache, PooledByteBuf&lt;T> buf, final int reqCapacity) &amp;#123; final int normCapacity = normalizeCapacity(reqCapacity); if (isTinyOrSmall(normCapacity)) &amp;#123; // capacity &lt; pageSize int tableIdx; PoolSubpage&lt;T>[] table; boolean tiny = isTiny(normCapacity); if (tiny) &amp;#123; // &lt; 512 if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; tableIdx = tinyIdx(normCapacity); table = tinySubpagePools; &amp;#125; else &amp;#123; if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; tableIdx = smallIdx(normCapacity); table = smallSubpagePools; &amp;#125; final PoolSubpage&lt;T> head = table[tableIdx]; /** * Synchronize on the head. This is needed as &amp;#123;@link PoolChunk#allocateSubpage(int)&amp;#125; and * &amp;#123;@link PoolChunk#free(long)&amp;#125; may modify the doubly linked list as well. */ synchronized (head) &amp;#123; final PoolSubpage&lt;T> s = head.next; if (s != head) &amp;#123; assert s.doNotDestroy &amp;&amp; s.elemSize == normCapacity; long handle = s.allocate(); assert handle >= 0; s.chunk.initBufWithSubpage(buf, handle, reqCapacity); if (tiny) &amp;#123; allocationsTiny.increment(); &amp;#125; else &amp;#123; allocationsSmall.increment(); &amp;#125; return; &amp;#125; &amp;#125; allocateNormal(buf, reqCapacity, normCapacity); return; &amp;#125; if (normCapacity &lt;= chunkSize) &amp;#123; if (cache.allocateNormal(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; allocateNormal(buf, reqCapacity, normCapacity); &amp;#125; else &amp;#123; // Huge allocations are never served via the cache so just call allocateHuge allocateHuge(buf, reqCapacity); &amp;#125; &amp;#125; 我们之前讲过, 如果在缓存中分配不成功, 则会开辟一块连续的内存进行缓冲区分配, 这里我们先跳过isTinyOrSmall(normCapacity)往后的代码, 之后再来分析。 首先if (normCapacity &lt;= chunkSize) 说明其小于16KB , 然后首先在缓存中分配, 以为最初缓存中没有值, 所以会走到 allocateNormal(buf, reqCapacity, normCapacity), 这里实际上就是在page级别上进行分配, 分配一个或者多个page 的空间, 我们跟进到 allocateNormal() 方法: private synchronized void allocateNormal(PooledByteBuf&lt;T> buf, int reqCapacity, int normCapacity) &amp;#123; // 首先在原来的chunk 上进行内存分配(1) if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) || q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) || q075.allocate(buf, reqCapacity, normCapacity)) &amp;#123; ++allocationsNormal; return; &amp;#125; // Add a new chunk. // 创建chunk 进行内存分配(2) PoolChunk&lt;T> c = newChunk(pageSize, maxOrder, pageShifts, chunkSize); long handle = c.allocate(normCapacity); ++allocationsNormal; assert handle > 0; // 初始化 byteBuf(3) c.initBuf(buf, handle, reqCapacity); qInit.add(c); &amp;#125; 这里主要拆解了如下步骤: 在原有的chunk 中进行分配 创建chunk 进行分配 初始化byteBuf 首先我们来看第一步, 在原有的chunk 中进行分配: if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) || q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) || q075.allocate(buf, reqCapacity, normCapacity)) &amp;#123; ++allocationsNormal; return; &amp;#125; 我们之前讲过, chunkList 是存储不同内存使用量的chunk 集合,每个chunkList 通过双向链表的形式进行关联, 这里的 q050.allocate(buf, reqCapacity, normCapacity) 就代表首先在q050 这个chunkList 进行内存分配, 我们以q050 为例进行分析, 跟到q050.allocate(buf, reqCapacity, normCapacity)方法中： boolean allocate(PooledByteBuf&lt;T> buf, int reqCapacity, int normCapacity) &amp;#123; if (head == null || normCapacity > maxCapacity) &amp;#123; // Either this PoolChunkList is empty or the requested capacity is larger then the capacity which can // be handled by the PoolChunks that are contained in this PoolChunkList. return false; &amp;#125; // 从head 节点往下遍历 for (PoolChunk&lt;T> cur = head;;) &amp;#123; long handle = cur.allocate(normCapacity); if (handle &lt; 0) &amp;#123; cur = cur.next; if (cur == null) &amp;#123; return false; &amp;#125; &amp;#125; else &amp;#123; cur.initBuf(buf, handle, reqCapacity); if (cur.usage() >= maxUsage) &amp;#123; remove(cur); nextList.add(cur); &amp;#125; return true; &amp;#125; &amp;#125; &amp;#125; 首先会从head节点进行往下遍历, ong handle = cur.allocate(normCapacity) 表示对于每个chunk 都尝试去分配, if (handle &lt; 0) 说明没有分配到, 则通过 cur = cur.next 找到下一个节点继续进行分配, 我们讲过chunk 也是通过双向链表进行关联的. 所以对这块逻辑应该不会陌生, 如果handler 大于0 说明已经分配到内存, 则通过cur.initBuf(buf, handle, reqCapacity)对 byteBuf 进行初始化；if (cur.usage() &gt;= maxUsage) 代表当前 chunk 的内存使用率大于其最大使用率, 则通过 remove(cur)从当前的 chunkList 中移除, 再通过 nextList.add(cur)添加到下一个 chunkList 中。我们再回到 PoolArena 的 allocateNormal()方法中： 看第二步 PoolChunk c = newChunk(pageSize, maxOrder, pageShifts, chunkSize)，这里的参数 pageSize 是 8192, 也就是 8KB。 maxOrder 为11; pageShifts 为 13, 2 的 13 次方正好是 8192, 也就是 8KB；chunkSize 为 16777216, 也就是 16MB。 因为我们分析的是堆外内存, newChunk(pageSize, maxOrder, pageShifts, chunkSize)所以会走到 DirectArena 的 ()方法： @Override protected PoolChunk&lt;ByteBuffer> newChunk(int pageSize, int maxOrder, int pageShifts, int chunkSize) &amp;#123; return new PoolChunk&lt;ByteBuffer>( this, allocateDirect(chunkSize), pageSize, maxOrder, pageShifts, chunkSize); &amp;#125; 这里直接通过构造函数创建了一个chunk , allocateDirect(chunkSize) 这里是通过JDK 的api 申请一块直接内存, 我们跟到 PoolChunk 的构造函数: PoolChunk(PoolArena&lt;T> arena, T memory, int pageSize, int maxOrder, int pageShifts, int chunkSize) &amp;#123; unpooled = false; this.arena = arena; // memory 为一个ByteBuf this.memory = memory; // 8KB this.pageSize = pageSize; // 13 this.pageShifts = pageShifts; // 11 this.maxOrder = maxOrder; this.chunkSize = chunkSize; unusable = (byte) (maxOrder + 1); log2ChunkSize = log2(chunkSize); subpageOverflowMask = ~(pageSize - 1); freeBytes = chunkSize; assert maxOrder &lt; 30 : \"maxOrder should be &lt; 30, but is: \" + maxOrder; maxSubpageAllocs = 1 &lt;&lt; maxOrder; // Generate the memory map. // 节点数量为4096 memoryMap = new byte[maxSubpageAllocs &lt;&lt; 1]; // 也就是4096个节点 depthMap = new byte[memoryMap.length]; int memoryMapIndex = 1; // d 相当于一个深度, 赋值的内容代表当前节点的深度 for (int d = 0; d &lt;= maxOrder; ++ d) &amp;#123; // move down the tree one level at a time int depth = 1 &lt;&lt; d; for (int p = 0; p &lt; depth; ++ p) &amp;#123; // in each level traverse left to right and set value to the depth of subtree memoryMap[memoryMapIndex] = (byte) d; depthMap[memoryMapIndex] = (byte) d; memoryMapIndex ++; &amp;#125; &amp;#125; subpages = newSubpageArray(maxSubpageAllocs); &amp;#125; 首先将传入的参数的值进行赋值 this.memory = memory 就是将参数中创建的堆外内存进行保存, 就是chunk 所指向的那块连续的内存, 在这个chunk 中所分配的BteBuf, 都会在这块内存中进行读写. 我们重点关注 memoryMap = new byte[maxSubpageAllocs &lt;&lt; 1] 和 depthMap = new byte[memoryMap.length]这两步：首先看 memoryMap = new byte[maxSubpageAllocs &lt;&lt; 1]；这里初始化了一个字节数组 memoryMap, 大小为 maxSubpageAllocs &lt;&lt; 1, 也就是 4096；depthMap = new byte[memoryMap.length] 同样也是初始化了一个字节数组, 大小为 memoryMap 的大小, 也就是 4096。继续往下分析之前, 我们看 chunk 的一个层级关系。 这是一个二叉树的结构，左侧的数字代表层级, 右侧代表一块连续的内存, 每个父节下又拆分成多个子节点, 最顶层表示的内存范围为0-16KB， 其下又分为两层, 范围为0-8MB，8-16MB, 以此类推, 最后到11层, 以8KB 的大小划分, 也就是一个page 的大小. 如果我们分配一个8MB 的缓冲区, 则会将第二层的第一个节点, 也就是0-8 这样连续的内存进行分配, 分配完成后会将这个节点设置为不可用, 结合上面的图, 我们再看构造函数中的for 循环： for (int d = 0; d &lt;= maxOrder; ++ d) &amp;#123; // move down the tree one level at a time int depth = 1 &lt;&lt; d; for (int p = 0; p &lt; depth; ++ p) &amp;#123; // in each level traverse left to right and set value to the depth of subtree memoryMap[memoryMapIndex] = (byte) d; depthMap[memoryMapIndex] = (byte) d; memoryMapIndex ++; &amp;#125; &amp;#125; 实际上这个for循环就是将上面的结构包装成一个字节数组memoryMap, 外层循环用于控制层数, 内层循环用于控制里面每层的节点, 这里经过循环后， memoryMap 和depthMap 内容为以下表现形式： [0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4………..] 这里注意一下, 因为程序汇总数组的下标是从1开始设置的, 所以第零个节点元素为默认值0. 这里数字代表层级, 同时也代表了当前层级的节点, 相同的数字个数就是这一层级的节点数. 其中0 为2(因为这里分配时下标是从1开始的, 所以第0个位置的默认是0, 实际上第0层元素只有一个, 就是头节点), 1为2, 2为4, 3为8, 4为16, n 为2的n次方个, 也及时11有2 的11次方个. 我们再回到PoolArena 的 allocateNormal()方法： private synchronized void allocateNormal(PooledByteBuf&lt;T> buf, int reqCapacity, int normCapacity) &amp;#123; if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) || q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) || q075.allocate(buf, reqCapacity, normCapacity)) &amp;#123; ++allocationsNormal; return; &amp;#125; // Add a new chunk. PoolChunk&lt;T> c = newChunk(pageSize, maxOrder, pageShifts, chunkSize); long handle = c.allocate(normCapacity); ++allocationsNormal; assert handle > 0; c.initBuf(buf, handle, reqCapacity); qInit.add(c); &amp;#125; 我们继续剖析 long handle = c.allocate(normCapacity) 这步，跟到 allocate(normCapacity)中： long allocate(int normCapacity) &amp;#123; if ((normCapacity &amp; subpageOverflowMask) != 0) &amp;#123; // >= pageSize return allocateRun(normCapacity); &amp;#125; else &amp;#123; return allocateSubpage(normCapacity); &amp;#125; &amp;#125; 如果分配的以page 为单位, 则走到allocateRun(normCapacity) 方法中, 跟进去 private long allocateRun(int normCapacity) &amp;#123; int d = maxOrder - (log2(normCapacity) - pageShifts); int id = allocateNode(d); if (id &lt; 0) &amp;#123; return id; &amp;#125; freeBytes -= runLength(id); return id; &amp;#125; int d = maxOrder - (log2(normCapacity) - pageShifts) 表示根据 normCapacity 计算出第几层； int id = allocateNode(d) 表示根据层级关系, 去分配一个节点, 其中 id 代表 memoryMap 中的下标。 我们跟到 allocateNode()方法中： private int allocateNode(int d) &amp;#123; // 下标初始值为1 int id = 1; // 代表 当前层级第一个节点的初始下标 int initial = - (1 &lt;&lt; d); // has last d bits = 0 and rest all = 1 // 获取第一个节点的值 byte val = value(id); // 如果值大于层级, 说明chunk 不可用 if (val > d) &amp;#123; // unusable return -1; &amp;#125; // 当前下标对应的节点值如果小于层级,或者当前下标小于层级的初始下标 while (val &lt; d || (id &amp; initial) == 0) &amp;#123; // id &amp; initial == 1 &lt;&lt; d for all ids at depth d, for &lt; d it is 0 // 当前下标乘以2, 代表当前节点的子节点的初始位置 id &lt;&lt;= 1; // 获取id 位置的值 val = value(id); // 如果当前节点值大于层数(节点不可用) if (val > d) &amp;#123; // id 为偶数则+1, id 为奇数则-1(拿的是其兄弟节点) id ^= 1; // 获取id 的值 val = value(id); &amp;#125; &amp;#125; byte value = value(id); assert value == d &amp;&amp; (id &amp; initial) == 1 &lt;&lt; d : String.format(\"val = %d, id &amp; initial = %d, d = %d\", value, id &amp; initial, d); // 将找到的节点设置为不可用 setValue(id, unusable); // mark as unusable // 逐层往上标记被使用 updateParentsAlloc(id); return id; &amp;#125; 这里是实际上从一个节点往下找, 找到层级为d 未被使用的节点，我们可以通过注释体会其逻辑, 找到相关节点后通过setValue 将当前节点设置为不可用, 其中id 是当前节点的下标, unusable 代表一个不可用的值, 这里是12, 以为我们的层级只有12层, 所以设置为12之后就相当于标记不可用,设置成不可用之后, 通过updateParentsAlloc(id) 逐层设置为被使用, 我们跟进 updateParentsAlloc() 方法: private void updateParentsAlloc(int id) &amp;#123; while (id > 1) &amp;#123; // 取到当前节点的父节点id int parentId = id >>> 1; // 获取当前节点的值 byte val1 = value(id); // 找到当前节点的兄弟节点 byte val2 = value(id ^ 1); // 如果当前节点值大小兄弟节点,则保存当前节点值到val,否则, 保存兄弟节点值到val. // 如果当前节点是不可用的, 则当前节点值是12, 大于兄弟节点的值,所以这里将兄弟节点的值进行保存 byte val = val1 &lt; val2 ? val1 : val2; // 将val 的值设置为父节点下标所对应的值 setValue(parentId, val); // id 设置为父节点id, 继续循环 id = parentId; &amp;#125; &amp;#125; 这里其实是循环将兄弟节点的值替换成父节点的值, 我们可以通过注释仔细的进行逻辑分析, 如果实在理解有困难, 我通过画图帮助大家理解, 简单起见, 我们这里只设置为三层： 我们模拟其分配场景, 假设只有三层, 其中 index 代表数组 memoryMap 的下标, value 代表其值, memoryMap 中的值就为[0, 0, 1, 1, 2, 2, 2, 2]。我们要分配一个 4MB 的 byteBuf, 在我们调用 allocateNode(int d)中传入的 d 是 2, 也就是第二层。根据我们上面分分析的逻辑这里会找到第二层的第一个节点, 也就是 0-4mb 这个节点, 找到之后将其设置为 不可用, 这样 memoryMap 中的值就为[0, 0, 1, 1, 12, 2, 2, 2]，二叉树的结构就会变为： 注意标红部分, 将 index 为 4 的节点设置为了不可用。将这个节点设置为不可用之后, 则会将进行向上设置不可用, 循环将兄弟节点数值较小的节点替换到父节点, 也就是将 index 为 2 的节点的值替换成了 index 的为 5 的节点的值, 这样数组的值就会变为[0, 1, 2, 1, 12, 2, 2, 2]，二叉树的结构变为： 注意: 这里节点标红仅仅代表节点变化,并不是当前节点为不可用状态, 真正不可用状态的判断依据是value 的值为12 这样, 如果再次分配一个 4MB 内存的 ByteBuf, 根据其逻辑, 则会找到第二层的第二个节点, 也就是 4-8MB。再根据我们的逻辑, 通过向上设置不可用, index为2就会设置成不可用状态, 将value的值设置为12, 数组数值变为[0, 1, 12, 1, 12, 12, 2, 2]二叉树如下图所示： 这样我们看到, 通过分配两个4mb 的ByteBuf 之后, 当前节点和其父节点都会设置成不可用状态, 当index =2 的节点设置为不可用之后, 将不会再找到这个节点下的子节点. 以此类推, 直到所有的内存分配完毕的时候, index 为1 的节点也会变成不可用状态, 这样所有的page 就分配完毕, chunk 中再无可用的节点. 现在再回到 PoolArena的allocateNormal()方法： private synchronized void allocateNormal(PooledByteBuf&lt;T> buf, int reqCapacity, int normCapacity) &amp;#123; if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) || q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) || q075.allocate(buf, reqCapacity, normCapacity)) &amp;#123; ++allocationsNormal; return; &amp;#125; // Add a new chunk. PoolChunk&lt;T> c = newChunk(pageSize, maxOrder, pageShifts, chunkSize); long handle = c.allocate(normCapacity); ++allocationsNormal; assert handle > 0; c.initBuf(buf, handle, reqCapacity); qInit.add(c); &amp;#125; 通过以上的逻辑我们知道ong handle = c.allocate(normCapacity) 这一步其实返回的就是 memoryMap 的一个下标, 通过这个下标我们能唯一的定义一块内存, 继续往下跟, 通过过 c.initBuf(buf, handle, reqCapacity)初始化 ByteBuf 之后, 通过 qInit.add(c)将新创建的 chunk 添加到 chunkList 中，我们跟到 initBuf 方法中去： void initBuf(PooledByteBuf&lt;T> buf, long handle, int reqCapacity) &amp;#123; int memoryMapIdx = memoryMapIdx(handle); int bitmapIdx = bitmapIdx(handle); if (bitmapIdx == 0) &amp;#123; byte val = value(memoryMapIdx); assert val == unusable : String.valueOf(val); buf.init(this, handle, runOffset(memoryMapIdx), reqCapacity, runLength(memoryMapIdx), arena.parent.threadCache()); &amp;#125; else &amp;#123; initBufWithSubpage(buf, handle, bitmapIdx, reqCapacity); &amp;#125; &amp;#125; 从上面的代码中, 看出通过memoryMapIdx(handle)找到 memoryMap 的下标, 其实就是 handle 的值。bitmapIdx(handle)是有关 subPage 中使用到的逻辑, 如果是 page 级别的分配, 这里只返回 0, 所以进入到 if 块中。if 中首先断言当前节点是不是不可用状态, 然后通过 init 方法进行初始化。其中 runOffset(memoryMapIdx)表示偏移量, 偏移量相当于分配给缓冲区的这块内存相对于 chunk 中申请的内存的首地址偏移了多少。参数 runLength(memoryMapIdx), 表示根据下标获取可分配的最大长度。我们跟到 init()方法中, 这里会走到 PooledByteBuf 的 init()方法： void init(PoolChunk&lt;T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache) &amp;#123; assert handle >= 0; assert chunk != null; this.chunk = chunk; this.handle = handle; memory = chunk.memory; this.offset = offset; this.length = length; this.maxLength = maxLength; tmpNioBuf = null; this.cache = cache; &amp;#125; 这段代码又是我们熟悉的, 将属性进行了初始化, 以上就是完整的DirectUnsafePooledByteBuf 在Page 级别的完整分配的流程, 逻辑也是复杂的. 6. SubPage 级别的内存分配.通过之前的学习我们知道,如果我们分配一个缓冲区大小远小于page, 则直接在一个page 上进行分配则会造成内存浪费, 所以需要将page 继续进行切分成多个子块进行分配, 子块分配的个数根据你要分配的缓冲区大小而定, 比如只需要分配1KB的内存, 就会将一个page 分为8等分. 简单起见, 我们这里仅仅以16字节为例, 讲解其分配逻辑, 在分析其逻辑前, 首先看 PoolArean 的一个属性: private final PoolSubpage&lt;T&gt;[] tinySubpagePools; 这个属性是一个PoolSubpage 的数组, 有点类似于一个 subpage 的缓存, 我们创建一个subpage 之后, 会将创建的subpage 与该属性其中的每个关联, 下次在分配的的时候可以直接通过该属性的元素去找关联的subpage, 我们其中是在构造方法中初始化的, 看构造方法中其初始化的代码: tinySubpagePools = newSubpagePoolArray(numTinySubpagePools); 这里的 numTinySubpagePools 为32, 跟到 newSubpagePoolArray(numTinySubpagePools) 方法中: @SuppressWarnings(\"unchecked\") private PoolSubpage&lt;T>[] newSubpagePoolArray(int size) &amp;#123; return new PoolSubpage[size]; &amp;#125; 这里直接创建了一个 PoolSubpage 数组, 长度为32, 在构造方法中创建完毕后, 会通过循环为其赋值: for (int i = 0; i &lt; tinySubpagePools.length; i ++) &amp;#123; tinySubpagePools[i] = newSubpagePoolHead(pageSize); &amp;#125; 继续跟进到 newSubpagePoolHead(pageSize); 方法中: private PoolSubpage&lt;T> newSubpagePoolHead(int pageSize) &amp;#123; PoolSubpage&lt;T> head = new PoolSubpage&lt;T>(pageSize); head.prev = head; head.next = head; return head; &amp;#125; 在 newSubpagePoolHead 方法中创建了一个 PoolSubpage 对象head. head.prev = head; head.next = head; 这种写法我们知道SubPage 其实也是个双向链表,这里的将head的上一个节点和下一个节点设置为自身,有关PoolSubpage 的关联关系, 我们稍后分析, 这样通过循环创建 PoolSubpage, 总共会创建出来32个subpage, 其中每个subpage 实际代表一块内存大小。 tinySubpagePools 的结构就有点类似之前的缓存数据 tinySubPageDirectCaches 的结构, 了解了tinySubpagePools 属性, 我们看 看 PoolArean 的 allocate 方法, 也就是缓冲区的入口方法: private void allocate(PoolThreadCache cache, PooledByteBuf&lt;T> buf, final int reqCapacity) &amp;#123; final int normCapacity = normalizeCapacity(reqCapacity); if (isTinyOrSmall(normCapacity)) &amp;#123; // capacity &lt; pageSize int tableIdx; PoolSubpage&lt;T>[] table; boolean tiny = isTiny(normCapacity); if (tiny) &amp;#123; // &lt; 512 if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; tableIdx = tinyIdx(normCapacity); table = tinySubpagePools; &amp;#125; else &amp;#123; if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; tableIdx = smallIdx(normCapacity); table = smallSubpagePools; &amp;#125; final PoolSubpage&lt;T> head = table[tableIdx]; /** * Synchronize on the head. This is needed as &amp;#123;@link PoolChunk#allocateSubpage(int)&amp;#125; and * &amp;#123;@link PoolChunk#free(long)&amp;#125; may modify the doubly linked list as well. */ synchronized (head) &amp;#123; final PoolSubpage&lt;T> s = head.next; if (s != head) &amp;#123; assert s.doNotDestroy &amp;&amp; s.elemSize == normCapacity; long handle = s.allocate(); assert handle >= 0; s.chunk.initBufWithSubpage(buf, handle, reqCapacity); if (tiny) &amp;#123; allocationsTiny.increment(); &amp;#125; else &amp;#123; allocationsSmall.increment(); &amp;#125; return; &amp;#125; &amp;#125; allocateNormal(buf, reqCapacity, normCapacity); return; &amp;#125; if (normCapacity &lt;= chunkSize) &amp;#123; if (cache.allocateNormal(this, buf, reqCapacity, normCapacity)) &amp;#123; // was able to allocate out of the cache so move on return; &amp;#125; allocateNormal(buf, reqCapacity, normCapacity); &amp;#125; else &amp;#123; // Huge allocations are never served via the cache so just call allocateHuge allocateHuge(buf, reqCapacity); &amp;#125; &amp;#125; 之前我们在这个方法剖析过page级别相关内存分配逻辑, 现在我们来看subpage 级别分配的相关逻辑, 假设我们分配16字节的缓存区, isTinyOrSmall(normCapacity) 就会返回true, 进入if块, 同样 if (tiny) 这里会返回true. 继续跟进到 if (tiny) 的逻辑, 首先会在缓存中分配缓冲区, 如果分配不到, 就开辟一块内存进行内存分配, 先看着一步: tableIdx = tinyIdx(normCapacity); 这是通过 normCapacity 拿到tableIdx, 我们跟进去: static int tinyIdx(int normCapacity) &amp;#123; return normCapacity >>> 4; &amp;#125; 这里将 normCapacity 除以16, 其实也就是1, 我们回到 到 PoolArena 的 allocate()方法继续看： table = tinySubpagePools; 这里将tinySubpagePools 赋值到局部变量table, 继续往下看: final PoolSubpage head = table[tableIdx] 这步时通过下标拿到一个 PoolSubpage, 因为我们以16字节为例, 所以我们拿到下标为1的PoolSubpage, 对应的内存大小也就是16Byte, 再看 final PoolSubpage head = table[tableIdx] 这一步, 跟我们刚才了解到了tinySubpagePools 属性, 默认情况下 head.next 也是自身, 所以if (s != head) 会返回false, 我们继续往下看, 会走到 allocateNormal(buf, reqCapacity, normCapacity) 这个方法: private synchronized void allocateNormal(PooledByteBuf&lt;T> buf, int reqCapacity, int normCapacity) &amp;#123; if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) || q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) || q075.allocate(buf, reqCapacity, normCapacity)) &amp;#123; ++allocationsNormal; return; &amp;#125; // Add a new chunk. PoolChunk&lt;T> c = newChunk(pageSize, maxOrder, pageShifts, chunkSize); long handle = c.allocate(normCapacity); ++allocationsNormal; assert handle > 0; c.initBuf(buf, handle, reqCapacity); qInit.add(c); &amp;#125; 这里的逻辑我们之前已经剖析过了, 首先在原来的chunk 中分配, 如果分配不成功, 则会创建chunk 进行分配, 我们看这一步long handle = c.allocate(normCapacity); 跟到 allocate(normCapacity); 这个方法: long allocate(int normCapacity) &amp;#123; if ((normCapacity &amp; subpageOverflowMask) != 0) &amp;#123; // >= pageSize return allocateRun(normCapacity); &amp;#125; else &amp;#123; return allocateSubpage(normCapacity); &amp;#125; &amp;#125; 前面我们分析page级别的时候, 剖析的是 allocateRun(normCapacity) 方法, 因为这里我们是以16字节举例, 所以这次我们剖析 allocateSubpage(normCapacity) 方法, 也就是在 subpage级别进行内存分配的. private long allocateSubpage(int normCapacity) &amp;#123; // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it. // This is need as we may add it back and so alter the linked-list structure. PoolSubpage&lt;T> head = arena.findSubpagePoolHead(normCapacity); synchronized (head) &amp;#123; int d = maxOrder; // subpages are only be allocated from pages i.e., leaves int id = allocateNode(d); if (id &lt; 0) &amp;#123; return id; &amp;#125; final PoolSubpage&lt;T>[] subpages = this.subpages; final int pageSize = this.pageSize; freeBytes -= pageSize; int subpageIdx = subpageIdx(id); PoolSubpage&lt;T> subpage = subpages[subpageIdx]; if (subpage == null) &amp;#123; subpage = new PoolSubpage&lt;T>(head, this, id, runOffset(id), pageSize, normCapacity); subpages[subpageIdx] = subpage; &amp;#125; else &amp;#123; subpage.init(head, normCapacity); &amp;#125; return subpage.allocate(); &amp;#125; &amp;#125; 首先, 通过PoolSubpage head = arena.findSubpagePoolHead(normCapacity) 这种方式找到head节点, 实际上这里head 就是我们分析的tinySubpagePools 属性的第一个节点, 也就是对应16KB的那个节点, int d = maxOrder 是将11赋值给d, 也就是在内存树的第11层取值, 这部分前面剖析过了,。int id = allocateNode(d) 这个也是前面分析过的, 字节数组 memoryMap 的下标, 这里指向一个page, 如果第一次分配, 指向的是0-8KB 的那个page, 前面已经对此进行详细的剖析了, final PoolSubpage[] subpages = this.subpages 这一步, 是拿到PoolChunk 中成员变量subpage的值, 也就是 PoolSubpage 数组, 在PoolChunk 进行初始化的时候， 也会初始化该数组, 长度为2048, 也就是每个chunk 都维护着一个subpage 的列表, 如果每一个page 级别的内存都需要被切分成子page, 则会将这个page 放入该列表中, 专门用于分配子page, 所以这个列表中的subpage 其实就是一个用于切分的page. int subpageIdx = subpageIdx(id) 这一步是通过id 拿到这个 PoolSubpage 数组的下标, 如果id 对应的page 是0-8KB 的节点, 这里拿到的下标就是0, 在 if (subpage == null) 中, 因为默认 subpages 只是创建一个数组, 并没有数组中赋值, 所以第一次走到这里会返回true, 跟到if 块中: subpage = new PoolSubpage&lt;T&gt;(head, this, id, runOffset(id), pageSize, normCapacity); 这里通过 new PoolSubpage 创建一个新的subpage 之后, 通过subpages[subpageIdx] = subpage 这种方式将新创建的subpage 根据下表赋值到subpages 中的元素中, 在new PoolSubpage 的构造方法中, 传入head, 就是我们刚才提到过的tinySubpagePools 属性中的节点, 如果我们分配的16字节的缓冲区, 则这里对应的就是第一个节点, 我们跟到PoolSubpage 的构造方法中 PoolSubpage(PoolSubpage&lt;T> head, PoolChunk&lt;T> chunk, int memoryMapIdx, int runOffset, int pageSize, int elemSize) &amp;#123; this.chunk = chunk; this.memoryMapIdx = memoryMapIdx; this.runOffset = runOffset; this.pageSize = pageSize; bitmap = new long[pageSize >>> 10]; // pageSize / 16 / 64 init(head, elemSize); &amp;#125; 这里重点关注属性 bitmap, 这是一个long类型的数组, 初始大小为8, 这里只是初始化的大小, 真正的大小要根据将page 切分多少块而确定的, 这里将属性进行了赋值, 我们跟到init() 方法: void init(PoolSubpage&lt;T> head, int elemSize) &amp;#123; doNotDestroy = true; this.elemSize = elemSize; if (elemSize != 0) &amp;#123; maxNumElems = numAvail = pageSize / elemSize; nextAvail = 0; bitmapLength = maxNumElems >>> 6; if ((maxNumElems &amp; 63) != 0) &amp;#123; bitmapLength ++; &amp;#125; for (int i = 0; i &lt; bitmapLength; i ++) &amp;#123; bitmap[i] = 0; &amp;#125; &amp;#125; addToPool(head); &amp;#125; this.elemSize = elemSize 表示保存当前分配的缓存区大小, 这里我们以16字节举例, maxNumElems = numAvail = pageSize / elemSize 这里初始化了两个属性 性 maxNumElems, numAvail, 值都为 pageSize / elemSize, 表示一个 page 大小除以分配的缓冲区大小, 也就是表示当前 page 被划分了多少分。 nextAvail 则表示剩余可用的块数, 由于第一次分配都是可用的, 所以 numAvail=maxNumElems； bitmapLength 表示bitmap 的实际大小, 刚才我们分析过, bitmap 初始化的大小为8, 但实际上并不一定需要8个元素, 元素个数要根据page切分的子块而定, 这里的大小是所切分的子块数除以64. 再往下看, if ((maxNumElems &amp; 63) != 0) 判断maxNumElems 也就是当前配置所切分的子块是不是64的倍数, 如果不是, 则bigmapLength 加1 , 最后通过循环, 将其分配的大小中的元素赋值为0. 这里详细分析一下bitmap, 这里是个long 类型的数组, long 数组中的每一个值, 也就是long 类型的数字, 其中的每一个比特位, 都标记着page 中每一个子块的内存是否已分配, 如果比特位是1, 表示该快已经分配, 如果比特位是0, 表示该子块未分配. 标记顺序是其二进制数从低位到高位进行排列的, 我们应该知道为什么bitmap 大小要设置为子块数量乘以64, 因为long类型的数字是64位, 每一个元素能记录64个子块的数量, 这样就可以通过 子page 个数除以64 的方式决定bitmap中元素的数量, 如果子块不能整除64, 则通过元素数量+1 方式, 除以64之后剩余的子块通过long中比特位由低到高进行排列记录, 其逻辑结构如下图所示： 进入到 PoolSubpage 的addToPool(head) 方法: private void addToPool(PoolSubpage&lt;T> head) &amp;#123; assert prev == null &amp;&amp; next == null; prev = head; next = head.next; next.prev = this; head.next = this; &amp;#125; 这里的head我们刚才讲过, 是Arena 中数组 tinySubpagePools 中的元素, 通过以上逻辑, 就会将新创建的Subpage 通过双向链表的方式关联到 tinySubpagePools 中的元素, 我们以16字节为例, 关联关系如下图所示： 这样, 下次如果还需要分配16字节的内存, 就可以通过tinySubpagePools 找到其元素关联的subpage 进行分配了, 我们再回到PoolChunk 的 allocateSubpage()方法： private long allocateSubpage(int normCapacity) &amp;#123; // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it. // This is need as we may add it back and so alter the linked-list structure. PoolSubpage&lt;T> head = arena.findSubpagePoolHead(normCapacity); synchronized (head) &amp;#123; int d = maxOrder; // subpages are only be allocated from pages i.e., leaves int id = allocateNode(d); if (id &lt; 0) &amp;#123; return id; &amp;#125; final PoolSubpage&lt;T>[] subpages = this.subpages; final int pageSize = this.pageSize; freeBytes -= pageSize; int subpageIdx = subpageIdx(id); PoolSubpage&lt;T> subpage = subpages[subpageIdx]; if (subpage == null) &amp;#123; subpage = new PoolSubpage&lt;T>(head, this, id, runOffset(id), pageSize, normCapacity); subpages[subpageIdx] = subpage; &amp;#125; else &amp;#123; subpage.init(head, normCapacity); &amp;#125; return subpage.allocate(); &amp;#125; &amp;#125; 创建完一个subpage， 我们就可以通过subpage.allocate() 方法进行内存分配, 我们跟到allocate() 方法： long allocate() &amp;#123; if (elemSize == 0) &amp;#123; return toHandle(0); &amp;#125; if (numAvail == 0 || !doNotDestroy) &amp;#123; return -1; &amp;#125; final int bitmapIdx = getNextAvail(); int q = bitmapIdx >>> 6; int r = bitmapIdx &amp; 63; assert (bitmap[q] >>> r &amp; 1) == 0; bitmap[q] |= 1L &lt;&lt; r; if (-- numAvail == 0) &amp;#123; removeFromPool(); &amp;#125; return toHandle(bitmapIdx); &amp;#125; 其中 bitmapIdx 表示从 bitmap 中找到一个可用的bit 位的下标, 注意, 这里是bit的下标, 并不是数组的下标, 我们之前分析过，因为每一个比特位代表一个子块的内存分配情况, 通过这个下标就可以知道哪个比特位是未分配状态, 我们跟进去： private int getNextAvail() &amp;#123; int nextAvail = this.nextAvail; if (nextAvail >= 0) &amp;#123; this.nextAvail = -1; return nextAvail; &amp;#125; return findNextAvail(); &amp;#125; 上述代表片段中的nextAvail 表示下一个可用的bitmapIdx, 在释放的时候就会被标记, 标记被释放的子块对应 bitmapIdx的下标, 如果&lt; 0 则代表没有被释放的子块, 则通过findNextAvail() 方法进行查找, 继续跟进 findNextAvail() 方法: private int findNextAvail() &amp;#123; final long[] bitmap = this.bitmap; final int bitmapLength = this.bitmapLength; for (int i = 0; i &lt; bitmapLength; i ++) &amp;#123; long bits = bitmap[i]; if (~bits != 0) &amp;#123; return findNextAvail0(i, bits); &amp;#125; &amp;#125; return -1; &amp;#125; 这里会遍历bitmap 中的每一个元素, 如果当前元素中所有的比特位并没有全部标记被使用, 则通过findNextAvail() 方法一个一个往后找标记未使用的比特位, 再继续跟findNextAvail0 private int findNextAvail0(int i, long bits) &amp;#123; final int maxNumElems = this.maxNumElems; final int baseVal = i &lt;&lt; 6; for (int j = 0; j &lt; 64; j ++) &amp;#123; if ((bits &amp; 1) == 0) &amp;#123; int val = baseVal | j; if (val &lt; maxNumElems) &amp;#123; return val; &amp;#125; else &amp;#123; break; &amp;#125; &amp;#125; bits >>>= 1; &amp;#125; return -1; &amp;#125; 这里从当前元素的第一个比特位开始查找, 知道找到一个标记位0的比特位, 并返回当前比特位的下标,大致流程如下图所示: 我们回到allocate() 方法中: long allocate() &amp;#123; if (elemSize == 0) &amp;#123; return toHandle(0); &amp;#125; if (numAvail == 0 || !doNotDestroy) &amp;#123; return -1; &amp;#125; // 取一个bitmap 中可用的id(绝对id) final int bitmapIdx = getNextAvail(); // 除以64 (bitmap 的相对下标) int q = bitmapIdx >>> 6; // 除以64 取余, 其实就是当前绝对id 的偏移量 int r = bitmapIdx &amp; 63; assert (bitmap[q] >>> r &amp; 1) == 0; // 当前位标记位1 bitmap[q] |= 1L &lt;&lt; r; // 如果可用的page 为0 // 可用的子page -1 if (-- numAvail == 0) &amp;#123; removeFromPool(); &amp;#125; // 将bitmapIdx 转换为handler return toHandle(bitmapIdx); &amp;#125; 找到可用的bitmapIdx , 通过 int q = bitmapIdx &gt;&gt;&gt;6 获取bitmap 中 bitmapIdx 所属元素的数组下标, int r = bitmapIdx &amp; 63 表示获取bitmapIdx 的位置是从当前元素最低开始的第几个比特位, bitmap[q] |= 1L &lt;&lt; r 是将bitmap 的位置设置为不可用, 特就是比特位设置为1, 表示已占用, 然后将可用子配置的数量numAvail 减1. 如果没有可用子page 的数量, 则会将 PoolArena 中的数组 tinySubpagePools 所关联的 subpage 进行移除。最后通过toHandle(bitmapIdx) 获取当前子块的handle, 上一小节我们知道handler 指向的是当前chunk 中的唯一的一块内存, 我们跟进toHandle(bitmapIdx) 中： private long toHandle(int bitmapIdx) &amp;#123; return 0x4000000000000000L | (long) bitmapIdx &lt;&lt; 32 | memoryMapIdx; &amp;#125; (long) bitmapIdx &lt;&lt; 32 是将 bitmapIdx 右移 32 位, 而 32 位正好是一个 int 的长度, 这样, 通过 (long) bitmapIdx &lt;&lt;32 | memoryMapIdx 计算, 就可以将 memoryMapIdx, 也就是 page 所属的下标的二进制数保存在 (long) bitmapIdx&lt;&lt; 32 的低 32 位中。0x4000000000000000L 是一个最高位是 1 并且所有低位都是 0 的二进制数, 这样通过按位或的方式可以将 (long) bitmapIdx &lt;&lt; 32 | memoryMapIdx 计算出来的结果保存在 0x4000000000000000L 的所有低位中, 这样, 返回对的数字就可以指向 chunk 中唯一的一块内存，我们回到 PoolArena 的 allocateNormal 方法中： private synchronized void allocateNormal(PooledByteBuf&lt;T> buf, int reqCapacity, int normCapacity) &amp;#123; if (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) || q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) || q075.allocate(buf, reqCapacity, normCapacity)) &amp;#123; ++allocationsNormal; return; &amp;#125; // Add a new chunk. PoolChunk&lt;T> c = newChunk(pageSize, maxOrder, pageShifts, chunkSize); long handle = c.allocate(normCapacity); ++allocationsNormal; assert handle > 0; c.initBuf(buf, handle, reqCapacity); qInit.add(c); &amp;#125; 分析完了 long handle = c.allocate(normCapacity) 这步, 这里返回的handle 就指向 chunk 中的某个page 中的某个子块所对应的连续内存, 最后, 通过 initBuf() 初始化后， 将创建的chunk 加到chunkList 里面, 我们跟进到initBuf 方法里面 void initBuf(PooledByteBuf&lt;T> buf, long handle, int reqCapacity) &amp;#123; int memoryMapIdx = memoryMapIdx(handle); int bitmapIdx = bitmapIdx(handle); if (bitmapIdx == 0) &amp;#123; byte val = value(memoryMapIdx); assert val == unusable : String.valueOf(val); buf.init(this, handle, runOffset(memoryMapIdx), reqCapacity, runLength(memoryMapIdx), arena.parent.threadCache()); &amp;#125; else &amp;#123; initBufWithSubpage(buf, handle, bitmapIdx, reqCapacity); &amp;#125; &amp;#125; 这部分在前面已经剖析过, 相信大家不会陌生, 这里有区别是的if (bitmapIdx == 0) 的判断, 这里的bitmapIdx 不会是0, 这样, 就会走到 initBufWithSubpage(buf, handle, bitmapIdx, reqCapacity)方法中，跟到 initBufWithSubpage()方法： private void initBufWithSubpage(PooledByteBuf&lt;T> buf, long handle, int bitmapIdx, int reqCapacity) &amp;#123; assert bitmapIdx != 0; int memoryMapIdx = memoryMapIdx(handle); PoolSubpage&lt;T> subpage = subpages[subpageIdx(memoryMapIdx)]; assert subpage.doNotDestroy; assert reqCapacity &lt;= subpage.elemSize; buf.init( this, handle, runOffset(memoryMapIdx) + (bitmapIdx &amp; 0x3FFFFFFF) * subpage.elemSize, reqCapacity, subpage.elemSize, arena.parent.threadCache()); &amp;#125; 首先拿到memoryMapIdx , 这里会将我们之前计算的 handle 传入, 跟进去: private static int memoryMapIdx(long handle) &amp;#123; return (int) handle; &amp;#125; 这里将其强制转换为一个int 类型, 也就是去掉高32位, 这样就能得到memoryMapIdx, 回到initBufWithSubpage() 方法中:我们注意在buf 调用init() 方法中的一个参数 runOffset(memoryMapIdx) + (bitmapIdx &amp; 0x3FFFFFFF) * subpage.elemSize 这里的偏移量就是原来page 的偏移量 + 子块的偏移量: bitmapIdx &amp; 0x3FFFFFFF 代表当前分配的子 page 是属于第几个子 page。(bitmapIdx &amp; 0x3FFFFFFF) * subpage.elemSize 表示在当前 page 的偏移量。这样, 分配的 ByteBuf 在内存读写的时候, 就会根据偏移量进行读写。最后，我们跟到 init()方法中： void init(PoolChunk&lt;T> chunk, long handle, int offset, int length, int maxLength, PoolThreadCache cache) &amp;#123; assert handle >= 0; assert chunk != null; this.chunk = chunk; this.handle = handle; memory = chunk.memory; this.offset = offset; this.length = length; this.maxLength = maxLength; tmpNioBuf = null; this.cache = cache; &amp;#125; 这里又是我们熟悉的逻辑, 初始化属性之后, 一个缓冲区分配完成, 以上就是SubPage 级别的缓冲区分配逻辑。 7. 内存池ByteBuf 内存回收我们知道,堆外内存是不受JVM 垃圾回收机制控制的, 所以我们分配一块堆外内存进行ByteBuf 操作时, 使用完毕要对对象进行回收, 本节就以 PooledUnsafeDirectByteBuf 为例讲解有关内存分配的相关逻辑, PooledUnsafeDirectByteBuf 中内存释放的入口方法是其父类 AbstractReferenceCountedByteBuf 中的release() 方法: @Override public boolean release(int decrement) &amp;#123; return release0(checkPositive(decrement, \"decrement\")); &amp;#125; private boolean release0(int decrement) &amp;#123; for (;;) &amp;#123; int refCnt = this.refCnt; if (refCnt &lt; decrement) &amp;#123; throw new IllegalReferenceCountException(refCnt, -decrement); &amp;#125; if (refCntUpdater.compareAndSet(this, refCnt, refCnt - decrement)) &amp;#123; if (refCnt == decrement) &amp;#123; deallocate(); return true; &amp;#125; return false; &amp;#125; &amp;#125; &amp;#125; if (refCnt == decrement) 中判断当前ByteBuf 是否没有被引用了, 如果没有被引用, 则通过deallocate() 方法进行释放 ,因为我们是以因为我们是以 PooledUnsafeDirectByteBuf 为例, 所以这里会调用其父类 PooledByteBuf 的 deallocate()方法： @Override protected final void deallocate() &amp;#123; if (handle >= 0) &amp;#123; final long handle = this.handle; this.handle = -1; memory = null; chunk.arena.free(chunk, handle, maxLength, cache); recycle(); &amp;#125; &amp;#125; 我们首先来分析 free() 方法: void free(PoolChunk&lt;T> chunk, long handle, int normCapacity, PoolThreadCache cache) &amp;#123; if (chunk.unpooled) &amp;#123; int size = chunk.chunkSize(); destroyChunk(chunk); activeBytesHuge.add(-size); deallocationsHuge.increment(); &amp;#125; else &amp;#123; SizeClass sizeClass = sizeClass(normCapacity); if (cache != null &amp;&amp; cache.add(this, chunk, handle, normCapacity, sizeClass)) &amp;#123; // cached so not free it. return; &amp;#125; freeChunk(chunk, handle, sizeClass); &amp;#125; &amp;#125; 首先判断是不是unpooled, 我们这里是 Pooled, 所以会走到else 块中： sizeClass(normCapacity) 计算是哪种级别的size, 我们按照tiny 级别进行分析 cache.add(this, chunk, handle, normCapacity, sizeClass) 是将当前ByteBuf 进行缓存. 我们之前讲过, 在分配ByteBuf 时首先在缓存上分配, 而这步, 就是将其缓存的过程, 继续跟进去: boolean add(PoolArena&lt;?> area, PoolChunk chunk, long handle, int normCapacity, SizeClass sizeClass) &amp;#123; MemoryRegionCache&lt;?> cache = cache(area, normCapacity, sizeClass); if (cache == null) &amp;#123; return false; &amp;#125; return cache.add(chunk, handle); &amp;#125; 首先根据类型拿到相关类型的缓存节点, 这里会根据不同的内存规格去找不同的对象, 我们简单回顾一下, 每个缓存对象都包含一个queue, queue 中每个节点是entry, 每一个entry 中包含一个chunk 和handle, 可以指向唯一的连续的内存, 我们跟到cache中: private MemoryRegionCache&lt;?> cache(PoolArena&lt;?> area, int normCapacity, SizeClass sizeClass) &amp;#123; switch (sizeClass) &amp;#123; case Normal: return cacheForNormal(area, normCapacity); case Small: return cacheForSmall(area, normCapacity); case Tiny: return cacheForTiny(area, normCapacity); default: throw new Error(); &amp;#125; &amp;#125; 假设我们是tiny类型, 这里就会走到 cacheForTiny(area, normCapacity) 方法中, 跟进去: private MemoryRegionCache&lt;?> cacheForTiny(PoolArena&lt;?> area, int normCapacity) &amp;#123; int idx = PoolArena.tinyIdx(normCapacity); if (area.isDirect()) &amp;#123; return cache(tinySubPageDirectCaches, idx); &amp;#125; return cache(tinySubPageHeapCaches, idx); &amp;#125; 这个方法我们之前剖析过, 就是根据大小找到第几个缓存中的第几个缓存, 拿到下标后, 通过cache 去找相对应的缓存对象. private static &lt;T> MemoryRegionCache&lt;T> cache(MemoryRegionCache&lt;T>[] cache, int idx) &amp;#123; if (cache == null || idx > cache.length - 1) &amp;#123; return null; &amp;#125; return cache[idx]; &amp;#125; 我们这里看到, 是直接通过下标拿到的缓存对象, 回到 add() 方法: @SuppressWarnings(&amp;#123; \"unchecked\", \"rawtypes\" &amp;#125;) boolean add(PoolArena&lt;?> area, PoolChunk chunk, long handle, int normCapacity, SizeClass sizeClass) &amp;#123; MemoryRegionCache&lt;?> cache = cache(area, normCapacity, sizeClass); if (cache == null) &amp;#123; return false; &amp;#125; return cache.add(chunk, handle); &amp;#125; 这里的cache 对象调用了一个add方法, 这个方法就是将chunk 和handle 封装成一个 entry 加到queue, 我们跟到add() 方法中: public final boolean add(PoolChunk&lt;T> chunk, long handle) &amp;#123; Entry&lt;T> entry = newEntry(chunk, handle); boolean queued = queue.offer(entry); if (!queued) &amp;#123; // If it was not possible to cache the chunk, immediately recycle the entry entry.recycle(); &amp;#125; return queued; &amp;#125; 我们之前介绍过, 从在缓存对象中分配的时候从queue 弹出一个entry, 会放到一个对象池里面, 而这里的 Entry&lt;T&gt; entry = newEntry(chunk, handle); 就是从对象池中去取一个entry 对象, 然后将chunk 和handle 进行赋值, 然后通过queue.offer(entry) 加到queue, 我们回到free() 方法: void free(PoolChunk&lt;T> chunk, long handle, int normCapacity, PoolThreadCache cache) &amp;#123; if (chunk.unpooled) &amp;#123; int size = chunk.chunkSize(); destroyChunk(chunk); activeBytesHuge.add(-size); deallocationsHuge.increment(); &amp;#125; else &amp;#123; SizeClass sizeClass = sizeClass(normCapacity); if (cache != null &amp;&amp; cache.add(this, chunk, handle, normCapacity, sizeClass)) &amp;#123; // cached so not free it. return; &amp;#125; freeChunk(chunk, handle, sizeClass); &amp;#125; &amp;#125; 这里加到缓存之后, 如果成功, 就会return, 如果不成功, 就会调用 freeChunk(chunk, handle, sizeClass); 方法, 这个方法的意思是： 将原来给ByteBuf 分配的内存区段标记位未使用,跟进到 ` freeChunk() 方法： void freeChunk(PoolChunk&lt;T> chunk, long handle, SizeClass sizeClass) &amp;#123; final boolean destroyChunk; synchronized (this) &amp;#123; switch (sizeClass) &amp;#123; case Normal: ++deallocationsNormal; break; case Small: ++deallocationsSmall; break; case Tiny: ++deallocationsTiny; break; default: throw new Error(); &amp;#125; destroyChunk = !chunk.parent.free(chunk, handle); &amp;#125; if (destroyChunk) &amp;#123; // destroyChunk not need to be called while holding the synchronized lock. destroyChunk(chunk); &amp;#125; &amp;#125; 我们在跟到free() 方法中： boolean free(PoolChunk&lt;T> chunk, long handle) &amp;#123; chunk.free(handle); if (chunk.usage() &lt; minUsage) &amp;#123; remove(chunk); // Move the PoolChunk down the PoolChunkList linked-list. return move0(chunk); &amp;#125; return true; &amp;#125; chunk.free(handle); 的意思是通过chunk 释放一段连续的内存, 再跟回到free() 方法中： void free(long handle) &amp;#123; int memoryMapIdx = memoryMapIdx(handle); int bitmapIdx = bitmapIdx(handle); if (bitmapIdx != 0) &amp;#123; // free a subpage PoolSubpage&lt;T> subpage = subpages[subpageIdx(memoryMapIdx)]; assert subpage != null &amp;&amp; subpage.doNotDestroy; // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it. // This is need as we may add it back and so alter the linked-list structure. PoolSubpage&lt;T> head = arena.findSubpagePoolHead(subpage.elemSize); synchronized (head) &amp;#123; if (subpage.free(head, bitmapIdx &amp; 0x3FFFFFFF)) &amp;#123; return; &amp;#125; &amp;#125; &amp;#125; freeBytes += runLength(memoryMapIdx); setValue(memoryMapIdx, depth(memoryMapIdx)); updateParentsFree(memoryMapIdx); &amp;#125; if (bitmapIdx != 0) 这里判断是当前缓存区分配的级别是page 还是subpage, 如果是subpage , 则会找到相关的subpage 将其位标记为0， 如果不是subpage, 这里通过分配内存的反向标记, 将该内存标记为未使用. 回 到 PooledByteBuf 的 deallocate方法中： @Override protected final void deallocate() &amp;#123; if (handle >= 0) &amp;#123; final long handle = this.handle; this.handle = -1; memory = null; chunk.arena.free(chunk, handle, maxLength, cache); recycle(); &amp;#125; &amp;#125; 最后, 通过recycle() 将释放的ByteBuf 放入对象回收站 8. SocketChannel 读取ByteBuf 的过程我们首先看NioEventLoop 的processSelectedKey 方法: private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &amp;#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) &amp;#123; final EventLoop eventLoop; try &amp;#123; eventLoop = ch.eventLoop(); &amp;#125; catch (Throwable ignored) &amp;#123; // If the channel implementation throws an exception because there is no event loop, we ignore this // because we are only trying to determine if ch is registered to this event loop and thus has authority // to close ch. return; &amp;#125; // Only close ch if ch is still registerd to this EventLoop. ch could have deregistered from the event loop // and thus the SelectionKey could be cancelled as part of the deregistration process, but the channel is // still healthy and should not be closed. // See https://github.com/netty/netty/issues/5125 if (eventLoop != this || eventLoop == null) &amp;#123; return; &amp;#125; // close the channel if the key is not valid anymore unsafe.close(unsafe.voidPromise()); return; &amp;#125; try &amp;#123; int readyOps = k.readyOps(); // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise // the NIO JDK channel implementation may throw a NotYetConnectedException. if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &amp;#123; // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &amp;#125; // Process OP_WRITE first as we may be able to write some queued buffers and so free memory. if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &amp;#123; // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush(); &amp;#125; // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead // to a spin loop if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &amp;#123; unsafe.read(); if (!ch.isOpen()) &amp;#123; // Connection already closed - no need to handle write. return; &amp;#125; &amp;#125; &amp;#125; catch (CancelledKeyException ignored) &amp;#123; unsafe.close(unsafe.voidPromise()); &amp;#125; &amp;#125; if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) 这里的判断表示轮询到大事件是OP_READ 或者 OP_ACCEPT 事件. 如果当前 NioEventLoop 是work 线程的话, 那么这里就是OP_READ 事件, 也就是读事件, 表示客户端发来了数据流, 这里会调用 unsafe 的redis() 方法进行读取， 如果是work 线程, 那么这里的channel 是NioServerSocketChannel, 其绑定的 unsafe 是NioByteUnsafe, 这里会走到 NioByteUnsafe 的 read()方法中： @Override public final void read() &amp;#123; final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try &amp;#123; do &amp;#123; byteBuf = allocHandle.allocate(allocator); allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) &amp;#123; // nothing was read. release the buffer. byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; break; &amp;#125; allocHandle.incMessagesRead(1); readPending = false; pipeline.fireChannelRead(byteBuf); byteBuf = null; &amp;#125; while (allocHandle.continueReading()); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (close) &amp;#123; closeOnRead(pipeline); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; handleReadException(pipeline, byteBuf, t, close, allocHandle); &amp;#125; finally &amp;#123; // Check if there is a readPending which was not processed yet. // This could be for two reasons: // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method // // See https://github.com/netty/netty/issues/2254 if (!readPending &amp;&amp; !config.isAutoRead()) &amp;#123; removeReadOp(); &amp;#125; &amp;#125; &amp;#125; 首先获取SocketChannel 的 config, pipeline 等相关属性，final ByteBufAllocator allocator = config.getAllocator(); 这一步是获取一个 ByteBuf 的内存分配器, 用于分配 ByteBuf。这里会走到 DefaultChannelConfig 的 getAllocator 方法中: @Override public ByteBufAllocator getAllocator() &amp;#123; return allocator; &amp;#125; 这里返回的 DefaultChannelConfig 的成员变量, 我们看这个成员变量： private volatile ByteBufAllocator allocator = ByteBufAllocator.DEFAULT; 这里调用的 ByteBufAllocator 的DEFAULT属性, 跟进去: ByteBufAllocator DEFAULT = ByteBufUtil.DEFAULT_ALLOCATOR; 看到这里又调用了ByteBufUtil 的静态属性DEFAULT_ALLOCATOR, 再跟进去 static final ByteBufAllocator DEFAULT_ALLOCATOR; DEFAULT_ALLOCATOR 这个属性是在static 块中初始化的, 我们跟到static 块中： static &amp;#123; String allocType = SystemPropertyUtil.get( \"io.netty.allocator.type\", PlatformDependent.isAndroid() ? \"unpooled\" : \"pooled\"); allocType = allocType.toLowerCase(Locale.US).trim(); ByteBufAllocator alloc; if (\"unpooled\".equals(allocType)) &amp;#123; alloc = UnpooledByteBufAllocator.DEFAULT; logger.debug(\"-Dio.netty.allocator.type: &amp;#123;&amp;#125;\", allocType); &amp;#125; else if (\"pooled\".equals(allocType)) &amp;#123; alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\"-Dio.netty.allocator.type: &amp;#123;&amp;#125;\", allocType); &amp;#125; else &amp;#123; alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\"-Dio.netty.allocator.type: pooled (unknown: &amp;#123;&amp;#125;)\", allocType); &amp;#125; DEFAULT_ALLOCATOR = alloc; THREAD_LOCAL_BUFFER_SIZE = SystemPropertyUtil.getInt(\"io.netty.threadLocalDirectBufferSize\", 64 * 1024); logger.debug(\"-Dio.netty.threadLocalDirectBufferSize: &amp;#123;&amp;#125;\", THREAD_LOCAL_BUFFER_SIZE); MAX_CHAR_BUFFER_SIZE = SystemPropertyUtil.getInt(\"io.netty.maxThreadLocalCharBufferSize\", 16 * 1024); logger.debug(\"-Dio.netty.maxThreadLocalCharBufferSize: &amp;#123;&amp;#125;\", MAX_CHAR_BUFFER_SIZE); &amp;#125; 首先判断运行环境是不是安卓, 如果不是安卓, 在返回”pooled” 字符串保存到 allocType 中, 然后通过if 判断, 最后局部变量alloc = PooledByteBufAllocator.DEFAULT; 最后将alloc 赋值到成员变量 DEFAULT_ALLOCATOR, 我们跟到PooledByteBufAllocator 的 DEFAULT 属性中： public static final PooledByteBufAllocator DEFAULT = new PooledByteBufAllocator(PlatformDependent.directBufferPreferred()); 我们看到这里直接通过new 的方式, 创建了一个PooledByteBufAllocator 对象， 也就是基于申请一块连续内存进行缓冲区分配的缓存区分配器, 回到NioByteUnsafe 的 read() 方法中： @Override public final void read() &amp;#123; final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try &amp;#123; do &amp;#123; byteBuf = allocHandle.allocate(allocator); allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) &amp;#123; // nothing was read. release the buffer. byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; break; &amp;#125; allocHandle.incMessagesRead(1); readPending = false; pipeline.fireChannelRead(byteBuf); byteBuf = null; &amp;#125; while (allocHandle.continueReading()); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (close) &amp;#123; closeOnRead(pipeline); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; handleReadException(pipeline, byteBuf, t, close, allocHandle); &amp;#125; finally &amp;#123; // Check if there is a readPending which was not processed yet. // This could be for two reasons: // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method // // See https://github.com/netty/netty/issues/2254 if (!readPending &amp;&amp; !config.isAutoRead()) &amp;#123; removeReadOp(); &amp;#125; &amp;#125; &amp;#125; 这里ByteBufAllocator allocator = config.getAllocator()中的 allocator , 就是 PooledByteBufAllocator。final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle() 是创建一个 handle,handle是对RecvByteBufAllocator 进行实际操作的对象, 我们跟进recvBufAllocHandle： @Override public RecvByteBufAllocator.Handle recvBufAllocHandle() &amp;#123; if (recvHandle == null) &amp;#123; recvHandle = config().getRecvByteBufAllocator().newHandle(); &amp;#125; return recvHandle; 这里是我们之前剖析过的逻辑, 如果不存在, 则创建handle 的实例. 同样, allocHandle.reset(config) 是将配置重置, 重置完配置后, 进行 do-while 循环, 有关循环终止条件 allocHandle.continueReading(). 在 do-while 循环中, 首先看 byteBuf = allocHandle.allocate(allocator) 这一步, 这里传入了刚才创建的allocate 对象 , 也就是PooledByteBufAllocator，这里会进入 DefaultMaxMessagesRecvByteBufAllocator 类的 allocate()方法中： @Override public ByteBuf allocate(ByteBufAllocator alloc) &amp;#123; return alloc.ioBuffer(guess()); &amp;#125; 这里的guess() 方法, 会调用AdaptiveRecvByteBufAllocator 的 guess() 方法： @Override public int guess() &amp;#123; return nextReceiveBufferSize; &amp;#125; 这里会返回AdaptiveRecvByteBufAllocator 的成员变量nextReceiveBufferSize, 也就是下次所分配的缓冲区的大小,第一个分配的时候u也会分配初始大小, 也就是1024字节, 这样, alloc.ioBuffer(guess()) 就会分配一个PooledByteBuf，我们跟到AbstractByteBufAllocator 的 ioBuffer 方法中： public ByteBuf ioBuffer() &amp;#123; if (PlatformDependent.hasUnsafe()) &amp;#123; return directBuffer(DEFAULT_INITIAL_CAPACITY); &amp;#125; return heapBuffer(DEFAULT_INITIAL_CAPACITY); &amp;#125; 这里首先判断是否能够获取jdk 的unsafe 对象, 默认为true, 所以会走到directBuffer(initialCapacity) 中, 这里最终会分配一个 PooledUnsafeDirectByteBuf 对象 , 回到NioByteUnsafe 的read(） 方法中, 分配完了ByteBuf 之后, 再看这一步 allocHandle.lastBytesRead(doReadBytes(byteBuf))。 首先看参数doReadBytes(byteBuf)方法, 这步是将channel 中的数据读取到我们刚分配到了ByteBuf 中, 并返回读取到的字节数, 这里会调用NioSocketChannel 的 doReadBytes()方法： @Override protected int doReadBytes(ByteBuf byteBuf) throws Exception &amp;#123; final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.attemptedBytesRead(byteBuf.writableBytes()); return byteBuf.writeBytes(javaChannel(), allocHandle.attemptedBytesRead()); &amp;#125; 首先拿到绑定在channel 中的handle, 因为我们已经创建了handle,所以这里会直接拿到, 再看allocHandle.attemptedBytesRead(byteBuf.writableBytes()) 这步, , byteBuf.writableBytes() 返回的是ByteBuf 可写的字节数, 也就是最多能从channel 中读取多少字节写到ByteBuf, allocate 的 attemptedBytesRead 会把可写字节数设置到DefaultMaxMessagesRecvByteBufAllocator 类 的 attemptedBytesRead 属 性 中 ， 跟 到DefaultMaxMessagesRecvByteBufAllocator 中的 attemptedBytesRead 我们会看到： @Override public void attemptedBytesRead(int bytes) &amp;#123; attemptedBytesRead = bytes; &amp;#125; 继续看doReadBytes() 方法, 往下看到最后, 通过byteBuf.writeBytes(javaChannel(), allocHandle.attemptedBytesRead()) 将JDK 底层的channel 数据写入到我们创建的ByteBuf 中, 并返回实际写入的字节数. 回到 NioByteUnsafe 的 read() 方法中继续看allocHandle.lastBytesRead(doReadBytes(byteBuf)) 这一步, 刚才我们剖析过 doReadBytes(byteBuf) 返回的是刚才写入的ByteBuf 的字节数, 再看 lastBytesRead() 方法, 跟到DefaultMaxMessagesRecvByteBufAllocator 的lastBytesRead() 方法中: public final void lastBytesRead(int bytes) &amp;#123; lastBytesRead = bytes; // Ignore if bytes is negative, the interface contract states it will be detected externally after call. // The value may be \"invalid\" after this point, but it doesn't matter because reading will be stopped. totalBytesRead += bytes; if (totalBytesRead &lt; 0) &amp;#123; totalBytesRead = Integer.MAX_VALUE; &amp;#125; &amp;#125; 这里会赋值两个属性, lastBytesRead 代表最后读取的字节数, 这里赋值为我们刚才写入ByteBuf 的字节数, totalBytesRead 代表总共读取的字节数, 这里将写入的字节数相加。继续来到 NioByteUnsafe 的read(） 方法, 如果最后一次性读取数据为0, 说明已经将channel 中的数据全部读取完毕, 将新创建的ByteBuf 释放循环使用, 并跳出循环, allocHandle.incMessagesRead(1); 这步是增加消息的读取次数, 因为我们这里循环最多16次, 所以当消息增加次数增加到16 会结束循环。 读取完毕后, 会通过pipeline.fireChannelReadComplete() 将传入 channelRead 事件. 至此, 小伙伴应该有个疑问, 如果一次读取不完, 就传递channelRead 事件. 那么server 接受到的数据就有可能不是完整的, 其实关于这点, Netty 也做了相应的处理, 循环结束后, 会执行到allocHandle.readComplete(); 这一步. 其实我们知道第一次分配ByteBuf 的初始容量是1024, 但是初始容量不一定一定满足所有的业务场景, netty 中, 将每次读取数据的字节数进行记录, 然后之后分配ByteBuf 的时候, 容量会尽可能的符合业务场景所需要的大小, 具体实现方式在 allocHandle.readComplete(）这一步体现的, 我们跟到 AdaptiveRecvByteBufAllocator 的 readComplete() 方法中: @Override public void readComplete() &amp;#123; record(totalBytesRead()); &amp;#125; 这里调用了record() 方法, 并传入了这一次所读取的字节总数, 跟到record() 方法: private void record(int actualReadBytes) &amp;#123; if (actualReadBytes &lt;= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) &amp;#123; if (decreaseNow) &amp;#123; index = Math.max(index - INDEX_DECREMENT, minIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; &amp;#125; else &amp;#123; decreaseNow = true; &amp;#125; &amp;#125; else if (actualReadBytes >= nextReceiveBufferSize) &amp;#123; index = Math.min(index + INDEX_INCREMENT, maxIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; &amp;#125; &amp;#125; 首先看判断条件 if (actualReadBytes &lt;= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) . 这里index 是当前分配的缓存区大小所在的SIZE_TABLE 的索引, 将这个索引进行缩进, 然后根据缩进后的索引找出 SIZE_TABLE 所存储的内存值, 再判断是否大于等于这次读取的最大字节数， 如果条件成立, 说明分配的内存过大, 需要缩容操作, 我们看if 块中缩容相关的逻辑, 首先 if (decreaseNow) 会判断是否立即进行收缩操作, 通常第一次不会进行收缩操作, 然后会将 decreaseNow 设置为true, 代表下一次直接进行收缩操作, 假设需要立即进行收缩操作,我们看收缩操作的相关逻辑。 index = Math.max(index - INDEX_DECREMENT, minIndex); 这一步将索引缩进一步, 但不能小于最小索引值, 然后通过nextReceiveBufferSize = SIZE_TABLE[index] 获取设置索引之后的内存, 赋值在nextReceiveBufferSize , 也就是下次需要分配的大小, 下次就会根据这个大小分配ByteBuf了, 这样就实现了缩容操作. 再看 else if (actualReadBytes &gt;= nextReceiveBufferSize) 这里判断这次读取字节的总量比上次分配的大小还要大, 则进行扩容操作. 扩容操作也非常简单, 索引步进 , 然后拿到步进后的索引锁对应的内存值, 作为下次所需要的分配的大小在NioByteUnsafe 的 read() 方法， 经过了缩容或者扩容操作后， 通过pipeline.fireChannelReadComplete()传播ChannelReadComplete()事件 , 以上就是读取客户端消息的相关流程.","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Java IO   演进之路(1)","slug":"Netty/Java IO   演进之路(1)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/netty/java-io-yan-jin-zhi-lu-1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/java-io-yan-jin-zhi-lu-1/","excerpt":"","text":"Java IO 演进之路在此之前, 必须要了解几个概念 概念阻塞(Block) 和非阻塞(Non-Block)阻塞和非阻塞是进程在访问数据的时候,数据是否准备就绪的一种处理方式,当数据没有准备的时候 阻塞: 往往需要等待缓冲区中的数据准备好了之后才处理其他的事情， 否则一直卡在那里. **非阻塞:**当我们的进程访问我们的数据缓冲区的时候,如果数据还没有准备好就直接返回, 不会等待. 如果数据已经准备好,也直接返回。 同步(Synchronization)和 异步(Asynchronous)同步和异步都是基于应用程序和操作系统处于IO事件所采用的方式, 比如: 同步: 是应用程序要直接参与IO读写的操作. **异步:**所有的IO读写交给操作系统去处理,应用程序只需要等待通知。 同步方式在处理IO事件的时候，必须阻塞在某个方法上面等到我们的IO事件完成(阻塞IO事件或者通过轮询IO事件的方式),对于异步来说,所有的IO读写都交给了操作系统. 这个时候,我们就可以做其他的事情,并不需要完成真正的IO操作,当操作完成IO后, 会给我们的应用程序一个通知, 同步: 阻塞到IO事件, 阻塞到read或者write,这个时候我们就完全不能做自己的事情,让读写方法加入到线程里面, 然后阻塞线程实现, 对线程的性能开销毕竟大. BIO与NIO对比下表总结了Java BIO(Block IO)和NIO(Non-Block IO) 之间的差异 IO模型 BIO NIO 通信 面向流 面向缓冲区(多路复用) 处理 阻塞IO(多线程) 非阻塞IO(反应堆Reactor) 触发 无 选择器(轮询机制) 面向流与面向缓冲java NIO和BIO之间第一个最大的区别是,BIO是面向流的,NIO的面向缓冲区的.Java BIO面向流意味着每次从流中读一个或者多个字节,直至读取所有字节, 他们没有被缓存在任何地方. 此外,他不能前后移动流中的数据. 如果需要前后移动从流中读取数据,需要先将他们缓存到一个缓冲区. Java NIO的缓冲导向方法略有不同, 数据读取到一个它稍后处理的缓冲区, 需要时可以在缓冲区中前后移动, 这就增加了处理过程的灵活性, 但是, 还需要检查是否该缓冲区中包含所有需要处理的数据, 而且, 需确保当更多的数据读入到缓冲区的时候, 不会覆盖缓冲区里面尚未处理的数据. 阻塞与非阻塞Java BIO的各种流是阻塞的. 这意味着,当一个线程调用 read()或者 write() 时,该线程被阻塞,直到有一些数据被读取或者数据完全写入, 该线程再次期间不能在干任何是事情了. Java NIO的非阻塞模式,使一个线程从某通道发送请求读取数据, 但是它仅能够得到目前可用的数据, 如果目前没有数据可用时，就什么都不会获取. 而不是保持线程阻塞, 所以直至数据变的可以读取之前,该线程可以继续做其他的事情, 非阻塞写也是如此, 一个线程请求写入一些数据到某通道,但不需要等待它完全写入, 这个线程同时可以去做别的事情,线程通常将非阻塞IO的空闲时间用于在其他通道上执行IO操作, 所以一个单独的线程现在可以管理多个输入和输出通道(channel) 选择器的问世Java NIO 的选择器(Selector) 允许一个单独的线程来监视多个输入通道, 你可以注册多个通道使用一个选择器,然后使用一个单独的线程来选择通道, 这些通道里已经可以处理的输入,或者选择已准备写入的通道,这种选择机制,使得一个单独的线程很容易的来管理多个通道. NIO和BIO 如何影响应用程序的设计无论是选择NIO还是BIO工具, 可能会响应你应用程序设计的以下几个方面: 对NIO或者BIO类的AIP的调用 数据处理逻辑 用来处理数据的线程数 1. API调用当然,使用NIO掉的调用时看起来与使用BIO时有所不同,但这并不意外，以为并不是仅从一个InputStream 逐字节读取,而是数据必须先读取缓冲区再处理、。 2. 数据处理使用纯粹的NIO 设计相较BIO设计,数据处理也收到影响 在BIO设计中, 我们从 inputstream 或者Reader 逐字节读取数据, 假设你正在处理一基于行的文本数据流,例如有如下一段文本: Name:Tom Age:18 Email: tom@qq.com Phone:13888888888 该文本行的流可以这样处理: FileInputStream fis = new FileInputStream(\"D:/info.txt\"); BufferedReader reader = new BufferedReader(new InputStreamReader(fis)); String nameLine = reader.readLine(); String ageLine = reader.readLine(); String emailLine = reader.readLine(); String phoneLine = reader.readLine(); 请注意处理状态 由程序执行多久决定. 换句话来说,一旦readLine() 方法返回,你就知道肯定文本行已经读完了, readline() 阻塞直到整行读完, 这就是原因. 你也知道此行包含名称; 同样,第二个readline() 调用返回的时候, 你知道这行包含年龄. 正如你可以看到.该处理程序仅在有新数据读取的时候运行, 并知道每步的数据是什么. 一旦正在运行的线程已处理过读取的某些数据, 该线程不会再回退数据(大多如此). 下图也说明了这条原则: (java BIO: 从一个阻塞的流中读取数据),而NIO的实现会有所不同,下面是一个简单的例子 ByteBuffer buffer = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buffer); 注意 第二行,从通道读取字节到ByteBuffer . 当这个方法调用返回时,你不知道你所需的所有数据是否在缓冲区. 你所知道的是, 该缓冲区包含一些字节, 这使得处理有点困难. 假设第一次 read(buffer) 调用后, 读取缓冲区的数据只有半行,例如 “Name:An”, 你能处理吗? 显然不能, 需要等到. 直到整行数据读取缓存, 在此之前, 对数据的任何处理毫无意义. 所以, 你怎么知道是否该缓冲区中包含了足够的数据可以处理了呢? 好了, 你不知道, 发现的方法只能查看缓冲区中的数据. 其结果是,在你知道所有数据都在缓冲区里之前,你必须检查几次缓冲区的数据, 这不仅效率低下,而且可能使得线程设计方案杂乱不堪。 例如: ByteBuffer buffer = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buffer); while(!bufferFull(bytesRead)) &amp;#123; bytesRead = inChannel.read(buffer); &amp;#125; bufferFull() 方法必须跟踪有多少数据读入缓冲区, 并返回真或者假, 这取决于缓冲区是否已满。 换句话来说, 如果缓冲区准备好被处理了,那么表示缓冲区满了. bufferFull(） 方法扫描缓冲区, 但必须保持在bufferFull() 方法被调用之前状态相同，如果没有, 下一个读取缓冲区的数据可能无法读取到正确的位置, 这是不可能的 这确实需要注意的又一问题. 如果缓冲区已满, 他可以被处理,如果它不满, 并且在你的实际案例中有意义. 你或者能处理其中的部分数据, 但是许多情况下,并非如此. 下图展示了”缓冲区数据循环就绪“ 3. 设置处理线程数NIO 可让你只使用一个(或几个)单线程管理多个通道(网络连接或文件), 但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。 如果需要管理同时打开的成千上万的连接, 这些连接每次只是发送少量的数据, 例如聊天服务器, 实现NIO的服务器可能是一个优势. 同样, 如果你需要维持许多打开的连接到其他计算机上, 如P2P网络中, 使用一个单独的线程来管理你所有出站连接, 可能是一个优势, 一个线程多个连接的设计方案如: Java NIO: 单线程管理多个连接。 如果你有少量的连接使用非常高的带宽, 一次发送大量的数据, 必须典型的IO 服务器实现非常契合. 下图说明了一个典型的IO服务器设计: Java BIO: 一个典型的IO服务器设计- 一个连接通过一个线程处理.， NIO 服务端代码示例package com.notes.io.nio; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.ServerSocketChannel; import java.nio.channels.SocketChannel; import java.util.Iterator; import java.util.Set; /** * @author luyanan * @since 2019/9/9 * &lt;p>NIO 服务端&lt;/p> **/ public class NIOServerDemo &amp;#123; private int port; /** * &lt;p>轮询器&lt;/p> * * @author luyanan * @since 2019/9/9 */ private Selector selector; /** * &lt;p>缓冲区&lt;/p> * * @author luyanan * @since 2019/9/9 */ private ByteBuffer buffer = ByteBuffer.allocate(1024); public NIOServerDemo(int port) &amp;#123; this.port = port; // 绑定ip/端口号 try &amp;#123; ServerSocketChannel server = ServerSocketChannel.open(); server.bind(new InetSocketAddress(port)); // BIO 升级版本NIO。 为了兼容BIO,NIO模型默认是采用阻塞 server.configureBlocking(false); selector = Selector.open(); server.register(selector, SelectionKey.OP_ACCEPT); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; public void listen() throws IOException &amp;#123; System.out.println(\"listen on :\" + this.port); // 轮询主线程 while (true) &amp;#123; selector.select(); Set&lt;SelectionKey> selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey> iterator = selectionKeys.iterator(); // 不断的迭代,就叫轮询 // 同步体现在这里, 因为每次只能拿到一个Key, 每次只能处理一种状态 while (iterator.hasNext()) &amp;#123; SelectionKey key = iterator.next(); iterator.remove(); process(key); &amp;#125; &amp;#125; &amp;#125; private void process(SelectionKey key) throws IOException &amp;#123; // 针对每一种状态给一个反应 if (key.isAcceptable()) &amp;#123; ServerSocketChannel server = (ServerSocketChannel) key.channel(); // 这个方法体现非阻塞, 不管你数据有没有准备好, 你都要给我一个状态和反馈 SocketChannel channel = server.accept(); channel.configureBlocking(false); // 当数据准备就绪的时候, 将状态设置为可读 key = channel.register(selector, SelectionKey.OP_READ); &amp;#125; else if (key.isReadable()) &amp;#123; SocketChannel socketChannel = (SocketChannel) key.channel(); int len = socketChannel.read(buffer); while (len > 0) &amp;#123; buffer.flip(); String content = new String(buffer.array(), 0, len); key = socketChannel.register(selector, SelectionKey.OP_WRITE); key.attach(content); System.out.println(\"读取内容:\" + content); &amp;#125; &amp;#125; else if (key.isWritable()) &amp;#123; SocketChannel channel = (SocketChannel) key.channel(); String content = (String) key.attachment(); channel.write(ByteBuffer.wrap((\"输出:\" + content).getBytes())); channel.close(); &amp;#125; &amp;#125; public static void main(String[] args) &amp;#123; try &amp;#123; new NIOServerDemo(8080).listen(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; Java AIO 详解JDK1.7(NIO2) 才是实现真正的异步AIO, 把IO读写操作完全交给了操作系统, 1. AIO(Asynchronout IO) 基本原理服务端:AsynchronousServerSocketChannel 客户端: AsynchronousSocketChannel 用户处理器: CompletionHandler 接口, 这个接口实现应用程序向操作系统发起IO请求, 当完成后处理具体逻辑,否则做自己该做的事情. “真正”的异步IO 需要操作系统更强的支持,在IO多路复用模型中 事件循环将文件句柄的状态事件通知给用户线程, 由用户线程自行读取数据、处理数据 . 而在异步IO模型中， 当用户线程收到通知时, 数据已经被内核读取完毕了, 并放在了用户线程指定的缓冲区内, 内核在IO完成后通知用户线程直接使用即可. 异步IO模型使用了Proactor 设计模式实现了这一机制, 如下图所示： 2. AOP 初体验服务端代码package com.notes.io.aio; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.AsynchronousChannelGroup; import java.nio.channels.AsynchronousServerSocketChannel; import java.nio.channels.AsynchronousSocketChannel; import java.nio.channels.CompletionHandler; import java.util.concurrent.ExecutionException; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; /** * @author luyanan * @since 2019/9/9 * &lt;p>AIO 服务端&lt;/p> **/ public class AIOServer &amp;#123; private int port; public AIOServer(int port) &amp;#123; this.port = port; &amp;#125; public static void main(String[] args) &amp;#123; new AIOServer(8080).listen(); &amp;#125; public void listen() &amp;#123; try &amp;#123; ExecutorService executorService = Executors.newCachedThreadPool(); AsynchronousChannelGroup channelGroup = AsynchronousChannelGroup.withCachedThreadPool(executorService, 1); // 工作线程, 用于监听回调的, 事件响应的时候需要回调. AsynchronousServerSocketChannel serverSocketChannel = AsynchronousServerSocketChannel.open(channelGroup); // 设置端口号 serverSocketChannel.bind(new InetSocketAddress(this.port)); System.out.println(\"服务已经启动, 端口号为:\" + this.port); serverSocketChannel.accept(null, new CompletionHandler&lt;AsynchronousSocketChannel, Object>() &amp;#123; // 实现 completed 方法来回调 // 由操作系统出发, 回调有两个状态, 成功/ 失败 ByteBuffer buffer = ByteBuffer.allocateDirect(1024); @Override public void completed(AsynchronousSocketChannel result, Object attachment) &amp;#123; System.out.println(\"IO操作开始, 开始获取数据\"); try &amp;#123; buffer.clear(); result.read(buffer).get(); buffer.flip(); result.write(buffer); buffer.flip(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ExecutionException e) &amp;#123; e.printStackTrace(); &amp;#125; finally &amp;#123; try &amp;#123; result.close(); serverSocketChannel.accept(null, this); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; System.out.println(\"操作完成\"); &amp;#125; @Override public void failed(Throwable exc, Object attachment) &amp;#123; System.err.println(\"操作失败:\" + exc); &amp;#125; &amp;#125;); Thread.sleep(Integer.MAX_VALUE); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 客户端代码package com.notes.io.aio; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.AsynchronousSocketChannel; import java.nio.channels.CompletionHandler; import java.util.concurrent.ExecutionException; /** * @author luyanan * @since 2019/9/9 * &lt;p>AIO 客户端&lt;/p> **/ public class AIOClient &amp;#123; private AsynchronousSocketChannel asynchronousSocketChannel; public AIOClient() throws IOException &amp;#123; asynchronousSocketChannel = AsynchronousSocketChannel.open(); &amp;#125; public void connect(String host, int port) throws InterruptedException &amp;#123; asynchronousSocketChannel.connect(new InetSocketAddress(host, port), null, new CompletionHandler&lt;Void, Object>() &amp;#123; @Override public void completed(Void result, Object attachment) &amp;#123; try &amp;#123; asynchronousSocketChannel.write(ByteBuffer.wrap(\"这是一条测试数据\".getBytes())).get(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; catch (ExecutionException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; @Override public void failed(Throwable exc, Object attachment) &amp;#123; exc.printStackTrace(); &amp;#125; &amp;#125;); ByteBuffer bb = ByteBuffer.allocate(1024); asynchronousSocketChannel.read(bb, null, new CompletionHandler&lt;Integer, Object>() &amp;#123; @Override public void completed(Integer result, Object attachment) &amp;#123; System.out.println(\"IO 操作完成\"); System.out.println(\"获取反馈结果:\" + new String(bb.array())); &amp;#125; @Override public void failed(Throwable exc, Object attachment) &amp;#123; exc.printStackTrace(); &amp;#125; &amp;#125;); Thread.sleep(Integer.MAX_VALUE); &amp;#125; public static void main(String[] args) throws IOException, InterruptedException &amp;#123; new AIOClient().connect(\"localhost\", 8080); &amp;#125; &amp;#125; 结果 服务端 服务已经启动, 端口号为:8080IO操作开始, 开始获取数据操作完成 客户端 IO 操作完成获取反馈结果:这是一条测试数据 各IO 模型对比和总结 属性 同步阻塞IO(BIO) 伪异步IO 非阻塞IO(NIO) 异步IO(AIO) 客户端数:IO线程数 1:1 M:N(M&gt;=1) M:1 M:0 阻塞类型 阻塞 阻塞 非阻塞 非阻塞 同步 同步 同步 同步(多路复用) 异步 API使用难度 检点 简单 复杂 一般 调试难度 简单 简单 复杂 复杂 可靠性 非常差 差 高 高 吞吐量 低 中 高 高","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Netty内存分配ByteBuf(12","slug":"Netty/Netty内存分配ByteBuf(12.1)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/netty/netty-nei-cun-fen-pei-bytebuf-12.1/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/netty/netty-nei-cun-fen-pei-bytebuf-12.1/","excerpt":"","text":"Netty 内存分配ByteBuf1. 初始ByteBufByteBuf 是Netty 整个结构里面最为底层的模块,主要负责把数据从底层IO里面读到ByteBuf.然后传递给应用程序. 应用程序出了完成后再把数据封装成ByteBuf 写回到IO. 所以, ByteBuf 是直接与底层打交道的一层抽象. 这块内容, 相对于Netty 其他模块来说,是非常复杂的. 但是没关系, 我会把这部分内容分别拆解, 从不同的角度来分析ByteBuf的分配和回收. 本章主要从内存与内存管理的抽象、不同规格大小和不同类型的内存的分配策略以及内存的回收过程来展开. 1. ByteBuf 的基本结构我们可以首先来看一下Netty 官方对ByteBuf 的描述如下： * +-------------------+------------------+------------------+ * | discardable bytes | readable bytes | writable bytes | * +-------------------+------------------+------------------+ * | | | | * 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity 从上面的byteBuf 结构来看, 我们发现 ByteBuf 有三个非常的指针, 分别是readerIndex (记录读指针的开始位置)、 writerIndex(记录写指针的开始位置)和 capacity(缓冲区的总长度) , 三者的关系是 readerIndex&lt;=writerIndex&lt;=capacity。然后, 从0到 readerIndex 为discardable bytes 表示是无效的. 从 readerIndex 到 writerIndex 为 readable bytes 表示可读数据区. 从 writerIndex 到 capacity 为 writable bytes 表示这段区间 空闲可以往里面写输入, 除了这三个指针, 其实 ByteBuf 里面还有一个maxCapacity，这就相当于是ByteBuf 扩容后的最大阈值. 我们看它的源码中有定义: /** * Returns the maximum allowed capacity of this buffer. If a user attempts to increase the * capacity of this buffer beyond the maximum capacity using &amp;#123;@link #capacity(int)&amp;#125; or * &amp;#123;@link #ensureWritable(int)&amp;#125;, those methods will raise an * &amp;#123;@link IllegalArgumentException&amp;#125;. */ public abstract int maxCapacity(); 这个指针可以看做是Capacity 之后的这段, 当Netty 发现 writable bytes 写数据 超出空间大小, ByteBuf 会提前帮我们进行自动扩容, 扩容之后就有了足够的空间来写数据, 同时 Capacity 也会同步更新, maxCapacity 就是扩容后的 capacity 的最大值. 1.2 ByteBuf 的重要API接下来我们来看一下 ByteBuf 的基本API, 主要包括 read()、write()、set() 以及mark()、reset() 方法. 我们用下面的表格对ByteBuf 最重要的API 做一个详细的说明. 方法 解释 readByte() 从当前 readerindex 指针开始往后读一个字节的数据并移动readerindex 将数据转换为byte readUnsignedByte() 读取一个无符号的byte 数据 readShort() 从当前 readerIndex 指针开始往后读2个字节的数据并移动 readerIndex , 将数据转换为Short readInt() 从当前 readerIndex 指针开始往后读取4个字节的数据并移动readerIndex, 将数据转换为Int readLong() 从当前 readerIndex 指针开始往后读取8个字节的数据并移动 readerIndex,将数据转换为Long writeByte() 将当前 writerIndex 指针开始往后写一个字节的数据, 并移动 writerIndex setByte() 将byte 数据写入到指定的位置, 不移动 writerIndex markReaderIndex() 在读数据之前, 将readerIndex 的状态保存起来, 方便在读取数据之后将 readerIndex 复原 resetReaderIndex() 将 readerIndex 复原到调用markReaderIndex() 之后的状态 markWriterIndex() 在写数据之前,将 writerIndex的状态保存起来,方便在读取完数据后阿静 writerIndex 复原 resetWriterIndex() 将writerIndex 复原到调用 markWriterIndex() 之后的状态 readableBytes() 获取可读数据区大小, 相当于获取当前 writerIndex 减去 readerIndex 的值 writableBytes() 获取可写数据区大小, 相当于获取当前 capactiy 减去 writerIndex 的值。 maxWritableBytes() 获取最大可写数据区的大小, 相当于获取当前 maxCapactiy 减去 writerIndex 的值。 在Netty中,ByteBuf 的大部分功能是在AbstractByteBuf 中实现的, 我们先进去AbstractByteBuf的源码看看 public abstract class AbstractByteBuf extends ByteBuf &amp;#123; int readerIndex; // 读指针 int writerIndex; // 写指针 private int markedReaderIndex; // mark 之后的读指针 private int markedWriterIndex; // mark 之后的写指针 private int maxCapacity; // 最大容量 &amp;#125; 最重要的几个属性 readerIndex、writerIndex、markedReaderIndex、markedWriterIndex、maxCapacity 被定义在 AbstractByteBuf 这个抽象类中, 下面我们可以看看基本读写的骨架代码实现。例如: 几个基本的判断读写区间的API，我们来看一下它的具体实现. public abstract class AbstractByteBuf extends ByteBuf &amp;#123; private static final InternalLogger logger = InternalLoggerFactory.getInstance(AbstractByteBuf.class); private static final String PROP_MODE = \"io.netty.buffer.bytebuf.checkAccessible\"; private static final boolean checkAccessible; static &amp;#123; checkAccessible = SystemPropertyUtil.getBoolean(PROP_MODE, true); if (logger.isDebugEnabled()) &amp;#123; logger.debug(\"-D&amp;#123;&amp;#125;: &amp;#123;&amp;#125;\", PROP_MODE, checkAccessible); &amp;#125; &amp;#125; static final ResourceLeakDetector&lt;ByteBuf> leakDetector = ResourceLeakDetectorFactory.instance().newResourceLeakDetector(ByteBuf.class); int readerIndex; int writerIndex; private int markedReaderIndex; private int markedWriterIndex; private int maxCapacity; protected AbstractByteBuf(int maxCapacity) &amp;#123; if (maxCapacity &lt; 0) &amp;#123; throw new IllegalArgumentException(\"maxCapacity: \" + maxCapacity + \" (expected: >= 0)\"); &amp;#125; this.maxCapacity = maxCapacity; &amp;#125; @Override public boolean isReadOnly() &amp;#123; return false; &amp;#125; @SuppressWarnings(\"deprecation\") @Override public ByteBuf asReadOnly() &amp;#123; if (isReadOnly()) &amp;#123; return this; &amp;#125; return Unpooled.unmodifiableBuffer(this); &amp;#125; @Override public int maxCapacity() &amp;#123; return maxCapacity; &amp;#125; protected final void maxCapacity(int maxCapacity) &amp;#123; this.maxCapacity = maxCapacity; &amp;#125; @Override public int readerIndex() &amp;#123; return readerIndex; &amp;#125; @Override public ByteBuf readerIndex(int readerIndex) &amp;#123; if (readerIndex &lt; 0 || readerIndex > writerIndex) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"readerIndex: %d (expected: 0 &lt;= readerIndex &lt;= writerIndex(%d))\", readerIndex, writerIndex)); &amp;#125; this.readerIndex = readerIndex; return this; &amp;#125; @Override public int writerIndex() &amp;#123; return writerIndex; &amp;#125; @Override public ByteBuf writerIndex(int writerIndex) &amp;#123; if (writerIndex &lt; readerIndex || writerIndex > capacity()) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"writerIndex: %d (expected: readerIndex(%d) &lt;= writerIndex &lt;= capacity(%d))\", writerIndex, readerIndex, capacity())); &amp;#125; this.writerIndex = writerIndex; return this; &amp;#125; @Override public ByteBuf setIndex(int readerIndex, int writerIndex) &amp;#123; if (readerIndex &lt; 0 || readerIndex > writerIndex || writerIndex > capacity()) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"readerIndex: %d, writerIndex: %d (expected: 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity(%d))\", readerIndex, writerIndex, capacity())); &amp;#125; setIndex0(readerIndex, writerIndex); return this; &amp;#125; @Override public ByteBuf clear() &amp;#123; readerIndex = writerIndex = 0; return this; &amp;#125; @Override public boolean isReadable() &amp;#123; return writerIndex > readerIndex; &amp;#125; @Override public boolean isReadable(int numBytes) &amp;#123; return writerIndex - readerIndex >= numBytes; &amp;#125; @Override public boolean isWritable() &amp;#123; return capacity() > writerIndex; &amp;#125; @Override public boolean isWritable(int numBytes) &amp;#123; return capacity() - writerIndex >= numBytes; &amp;#125; @Override public int readableBytes() &amp;#123; return writerIndex - readerIndex; &amp;#125; @Override public int writableBytes() &amp;#123; return capacity() - writerIndex; &amp;#125; @Override public int maxWritableBytes() &amp;#123; return maxCapacity() - writerIndex; &amp;#125; @Override public ByteBuf markReaderIndex() &amp;#123; markedReaderIndex = readerIndex; return this; &amp;#125; @Override public ByteBuf resetReaderIndex() &amp;#123; readerIndex(markedReaderIndex); return this; &amp;#125; @Override public ByteBuf markWriterIndex() &amp;#123; markedWriterIndex = writerIndex; return this; &amp;#125; @Override public ByteBuf resetWriterIndex() &amp;#123; writerIndex = markedWriterIndex; return this; &amp;#125; @Override public ByteBuf discardReadBytes() &amp;#123; ensureAccessible(); if (readerIndex == 0) &amp;#123; return this; &amp;#125; if (readerIndex != writerIndex) &amp;#123; setBytes(0, this, readerIndex, writerIndex - readerIndex); writerIndex -= readerIndex; adjustMarkers(readerIndex); readerIndex = 0; &amp;#125; else &amp;#123; adjustMarkers(readerIndex); writerIndex = readerIndex = 0; &amp;#125; return this; &amp;#125; @Override public ByteBuf discardSomeReadBytes() &amp;#123; ensureAccessible(); if (readerIndex == 0) &amp;#123; return this; &amp;#125; if (readerIndex == writerIndex) &amp;#123; adjustMarkers(readerIndex); writerIndex = readerIndex = 0; return this; &amp;#125; if (readerIndex >= capacity() >>> 1) &amp;#123; setBytes(0, this, readerIndex, writerIndex - readerIndex); writerIndex -= readerIndex; adjustMarkers(readerIndex); readerIndex = 0; &amp;#125; return this; &amp;#125; protected final void adjustMarkers(int decrement) &amp;#123; int markedReaderIndex = this.markedReaderIndex; if (markedReaderIndex &lt;= decrement) &amp;#123; this.markedReaderIndex = 0; int markedWriterIndex = this.markedWriterIndex; if (markedWriterIndex &lt;= decrement) &amp;#123; this.markedWriterIndex = 0; &amp;#125; else &amp;#123; this.markedWriterIndex = markedWriterIndex - decrement; &amp;#125; &amp;#125; else &amp;#123; this.markedReaderIndex = markedReaderIndex - decrement; markedWriterIndex -= decrement; &amp;#125; &amp;#125; @Override public ByteBuf ensureWritable(int minWritableBytes) &amp;#123; if (minWritableBytes &lt; 0) &amp;#123; throw new IllegalArgumentException(String.format( \"minWritableBytes: %d (expected: >= 0)\", minWritableBytes)); &amp;#125; ensureWritable0(minWritableBytes); return this; &amp;#125; private void ensureWritable0(int minWritableBytes) &amp;#123; if (minWritableBytes &lt;= writableBytes()) &amp;#123; return; &amp;#125; if (minWritableBytes > maxCapacity - writerIndex) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s\", writerIndex, minWritableBytes, maxCapacity, this)); &amp;#125; // Normalize the current capacity to the power of 2. int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); &amp;#125; @Override public int ensureWritable(int minWritableBytes, boolean force) &amp;#123; if (minWritableBytes &lt; 0) &amp;#123; throw new IllegalArgumentException(String.format( \"minWritableBytes: %d (expected: >= 0)\", minWritableBytes)); &amp;#125; if (minWritableBytes &lt;= writableBytes()) &amp;#123; return 0; &amp;#125; if (minWritableBytes > maxCapacity - writerIndex) &amp;#123; if (force) &amp;#123; if (capacity() == maxCapacity()) &amp;#123; return 1; &amp;#125; capacity(maxCapacity()); return 3; &amp;#125; &amp;#125; // Normalize the current capacity to the power of 2. int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); return 2; &amp;#125; @Override public ByteBuf order(ByteOrder endianness) &amp;#123; if (endianness == null) &amp;#123; throw new NullPointerException(\"endianness\"); &amp;#125; if (endianness == order()) &amp;#123; return this; &amp;#125; return newSwappedByteBuf(); &amp;#125; /** * Creates a new &amp;#123;@link SwappedByteBuf&amp;#125; for this &amp;#123;@link ByteBuf&amp;#125; instance. */ protected SwappedByteBuf newSwappedByteBuf() &amp;#123; return new SwappedByteBuf(this); &amp;#125; @Override public byte getByte(int index) &amp;#123; checkIndex(index); return _getByte(index); &amp;#125; protected abstract byte _getByte(int index); @Override public boolean getBoolean(int index) &amp;#123; return getByte(index) != 0; &amp;#125; @Override public short getUnsignedByte(int index) &amp;#123; return (short) (getByte(index) &amp; 0xFF); &amp;#125; @Override public short getShort(int index) &amp;#123; checkIndex(index, 2); return _getShort(index); &amp;#125; protected abstract short _getShort(int index); @Override public short getShortLE(int index) &amp;#123; checkIndex(index, 2); return _getShortLE(index); &amp;#125; protected abstract short _getShortLE(int index); @Override public int getUnsignedShort(int index) &amp;#123; return getShort(index) &amp; 0xFFFF; &amp;#125; @Override public int getUnsignedShortLE(int index) &amp;#123; return getShortLE(index) &amp; 0xFFFF; &amp;#125; @Override public int getUnsignedMedium(int index) &amp;#123; checkIndex(index, 3); return _getUnsignedMedium(index); &amp;#125; protected abstract int _getUnsignedMedium(int index); @Override public int getUnsignedMediumLE(int index) &amp;#123; checkIndex(index, 3); return _getUnsignedMediumLE(index); &amp;#125; protected abstract int _getUnsignedMediumLE(int index); @Override public int getMedium(int index) &amp;#123; int value = getUnsignedMedium(index); if ((value &amp; 0x800000) != 0) &amp;#123; value |= 0xff000000; &amp;#125; return value; &amp;#125; @Override public int getMediumLE(int index) &amp;#123; int value = getUnsignedMediumLE(index); if ((value &amp; 0x800000) != 0) &amp;#123; value |= 0xff000000; &amp;#125; return value; &amp;#125; @Override public int getInt(int index) &amp;#123; checkIndex(index, 4); return _getInt(index); &amp;#125; protected abstract int _getInt(int index); @Override public int getIntLE(int index) &amp;#123; checkIndex(index, 4); return _getIntLE(index); &amp;#125; protected abstract int _getIntLE(int index); @Override public long getUnsignedInt(int index) &amp;#123; return getInt(index) &amp; 0xFFFFFFFFL; &amp;#125; @Override public long getUnsignedIntLE(int index) &amp;#123; return getIntLE(index) &amp; 0xFFFFFFFFL; &amp;#125; @Override public long getLong(int index) &amp;#123; checkIndex(index, 8); return _getLong(index); &amp;#125; protected abstract long _getLong(int index); @Override public long getLongLE(int index) &amp;#123; checkIndex(index, 8); return _getLongLE(index); &amp;#125; protected abstract long _getLongLE(int index); @Override public char getChar(int index) &amp;#123; return (char) getShort(index); &amp;#125; @Override public float getFloat(int index) &amp;#123; return Float.intBitsToFloat(getInt(index)); &amp;#125; @Override public double getDouble(int index) &amp;#123; return Double.longBitsToDouble(getLong(index)); &amp;#125; @Override public ByteBuf getBytes(int index, byte[] dst) &amp;#123; getBytes(index, dst, 0, dst.length); return this; &amp;#125; @Override public ByteBuf getBytes(int index, ByteBuf dst) &amp;#123; getBytes(index, dst, dst.writableBytes()); return this; &amp;#125; @Override public ByteBuf getBytes(int index, ByteBuf dst, int length) &amp;#123; getBytes(index, dst, dst.writerIndex(), length); dst.writerIndex(dst.writerIndex() + length); return this; &amp;#125; @Override public CharSequence getCharSequence(int index, int length, Charset charset) &amp;#123; // TODO: We could optimize this for UTF8 and US_ASCII return toString(index, length, charset); &amp;#125; @Override public CharSequence readCharSequence(int length, Charset charset) &amp;#123; CharSequence sequence = getCharSequence(readerIndex, length, charset); readerIndex += length; return sequence; &amp;#125; @Override public ByteBuf setByte(int index, int value) &amp;#123; checkIndex(index); _setByte(index, value); return this; &amp;#125; protected abstract void _setByte(int index, int value); @Override public ByteBuf setBoolean(int index, boolean value) &amp;#123; setByte(index, value? 1 : 0); return this; &amp;#125; @Override public ByteBuf setShort(int index, int value) &amp;#123; checkIndex(index, 2); _setShort(index, value); return this; &amp;#125; protected abstract void _setShort(int index, int value); @Override public ByteBuf setShortLE(int index, int value) &amp;#123; checkIndex(index, 2); _setShortLE(index, value); return this; &amp;#125; protected abstract void _setShortLE(int index, int value); @Override public ByteBuf setChar(int index, int value) &amp;#123; setShort(index, value); return this; &amp;#125; @Override public ByteBuf setMedium(int index, int value) &amp;#123; checkIndex(index, 3); _setMedium(index, value); return this; &amp;#125; protected abstract void _setMedium(int index, int value); @Override public ByteBuf setMediumLE(int index, int value) &amp;#123; checkIndex(index, 3); _setMediumLE(index, value); return this; &amp;#125; protected abstract void _setMediumLE(int index, int value); @Override public ByteBuf setInt(int index, int value) &amp;#123; checkIndex(index, 4); _setInt(index, value); return this; &amp;#125; protected abstract void _setInt(int index, int value); @Override public ByteBuf setIntLE(int index, int value) &amp;#123; checkIndex(index, 4); _setIntLE(index, value); return this; &amp;#125; protected abstract void _setIntLE(int index, int value); @Override public ByteBuf setFloat(int index, float value) &amp;#123; setInt(index, Float.floatToRawIntBits(value)); return this; &amp;#125; @Override public ByteBuf setLong(int index, long value) &amp;#123; checkIndex(index, 8); _setLong(index, value); return this; &amp;#125; protected abstract void _setLong(int index, long value); @Override public ByteBuf setLongLE(int index, long value) &amp;#123; checkIndex(index, 8); _setLongLE(index, value); return this; &amp;#125; protected abstract void _setLongLE(int index, long value); @Override public ByteBuf setDouble(int index, double value) &amp;#123; setLong(index, Double.doubleToRawLongBits(value)); return this; &amp;#125; @Override public ByteBuf setBytes(int index, byte[] src) &amp;#123; setBytes(index, src, 0, src.length); return this; &amp;#125; @Override public ByteBuf setBytes(int index, ByteBuf src) &amp;#123; setBytes(index, src, src.readableBytes()); return this; &amp;#125; @Override public ByteBuf setBytes(int index, ByteBuf src, int length) &amp;#123; checkIndex(index, length); if (src == null) &amp;#123; throw new NullPointerException(\"src\"); &amp;#125; if (length > src.readableBytes()) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"length(%d) exceeds src.readableBytes(%d) where src is: %s\", length, src.readableBytes(), src)); &amp;#125; setBytes(index, src, src.readerIndex(), length); src.readerIndex(src.readerIndex() + length); return this; &amp;#125; @Override public ByteBuf setZero(int index, int length) &amp;#123; if (length == 0) &amp;#123; return this; &amp;#125; checkIndex(index, length); int nLong = length >>> 3; int nBytes = length &amp; 7; for (int i = nLong; i > 0; i --) &amp;#123; _setLong(index, 0); index += 8; &amp;#125; if (nBytes == 4) &amp;#123; _setInt(index, 0); // Not need to update the index as we not will use it after this. &amp;#125; else if (nBytes &lt; 4) &amp;#123; for (int i = nBytes; i > 0; i --) &amp;#123; _setByte(index, (byte) 0); index ++; &amp;#125; &amp;#125; else &amp;#123; _setInt(index, 0); index += 4; for (int i = nBytes - 4; i > 0; i --) &amp;#123; _setByte(index, (byte) 0); index ++; &amp;#125; &amp;#125; return this; &amp;#125; @Override public int setCharSequence(int index, CharSequence sequence, Charset charset) &amp;#123; if (charset.equals(CharsetUtil.UTF_8)) &amp;#123; ensureWritable(ByteBufUtil.utf8MaxBytes(sequence)); return ByteBufUtil.writeUtf8(this, index, sequence, sequence.length()); &amp;#125; if (charset.equals(CharsetUtil.US_ASCII)) &amp;#123; int len = sequence.length(); ensureWritable(len); return ByteBufUtil.writeAscii(this, index, sequence, len); &amp;#125; byte[] bytes = sequence.toString().getBytes(charset); ensureWritable(bytes.length); setBytes(index, bytes); return bytes.length; &amp;#125; @Override public byte readByte() &amp;#123; checkReadableBytes0(1); int i = readerIndex; byte b = _getByte(i); readerIndex = i + 1; return b; &amp;#125; @Override public boolean readBoolean() &amp;#123; return readByte() != 0; &amp;#125; @Override public short readUnsignedByte() &amp;#123; return (short) (readByte() &amp; 0xFF); &amp;#125; @Override public short readShort() &amp;#123; checkReadableBytes0(2); short v = _getShort(readerIndex); readerIndex += 2; return v; &amp;#125; @Override public short readShortLE() &amp;#123; checkReadableBytes0(2); short v = _getShortLE(readerIndex); readerIndex += 2; return v; &amp;#125; @Override public int readUnsignedShort() &amp;#123; return readShort() &amp; 0xFFFF; &amp;#125; @Override public int readUnsignedShortLE() &amp;#123; return readShortLE() &amp; 0xFFFF; &amp;#125; @Override public int readMedium() &amp;#123; int value = readUnsignedMedium(); if ((value &amp; 0x800000) != 0) &amp;#123; value |= 0xff000000; &amp;#125; return value; &amp;#125; @Override public int readMediumLE() &amp;#123; int value = readUnsignedMediumLE(); if ((value &amp; 0x800000) != 0) &amp;#123; value |= 0xff000000; &amp;#125; return value; &amp;#125; @Override public int readUnsignedMedium() &amp;#123; checkReadableBytes0(3); int v = _getUnsignedMedium(readerIndex); readerIndex += 3; return v; &amp;#125; @Override public int readUnsignedMediumLE() &amp;#123; checkReadableBytes0(3); int v = _getUnsignedMediumLE(readerIndex); readerIndex += 3; return v; &amp;#125; @Override public int readInt() &amp;#123; checkReadableBytes0(4); int v = _getInt(readerIndex); readerIndex += 4; return v; &amp;#125; @Override public int readIntLE() &amp;#123; checkReadableBytes0(4); int v = _getIntLE(readerIndex); readerIndex += 4; return v; &amp;#125; @Override public long readUnsignedInt() &amp;#123; return readInt() &amp; 0xFFFFFFFFL; &amp;#125; @Override public long readUnsignedIntLE() &amp;#123; return readIntLE() &amp; 0xFFFFFFFFL; &amp;#125; @Override public long readLong() &amp;#123; checkReadableBytes0(8); long v = _getLong(readerIndex); readerIndex += 8; return v; &amp;#125; @Override public long readLongLE() &amp;#123; checkReadableBytes0(8); long v = _getLongLE(readerIndex); readerIndex += 8; return v; &amp;#125; @Override public char readChar() &amp;#123; return (char) readShort(); &amp;#125; @Override public float readFloat() &amp;#123; return Float.intBitsToFloat(readInt()); &amp;#125; @Override public double readDouble() &amp;#123; return Double.longBitsToDouble(readLong()); &amp;#125; @Override public ByteBuf readBytes(int length) &amp;#123; checkReadableBytes(length); if (length == 0) &amp;#123; return Unpooled.EMPTY_BUFFER; &amp;#125; ByteBuf buf = alloc().buffer(length, maxCapacity); buf.writeBytes(this, readerIndex, length); readerIndex += length; return buf; &amp;#125; @Override public ByteBuf readSlice(int length) &amp;#123; ByteBuf slice = slice(readerIndex, length); readerIndex += length; return slice; &amp;#125; @Override public ByteBuf readRetainedSlice(int length) &amp;#123; ByteBuf slice = retainedSlice(readerIndex, length); readerIndex += length; return slice; &amp;#125; @Override public ByteBuf readBytes(byte[] dst, int dstIndex, int length) &amp;#123; checkReadableBytes(length); getBytes(readerIndex, dst, dstIndex, length); readerIndex += length; return this; &amp;#125; @Override public ByteBuf readBytes(byte[] dst) &amp;#123; readBytes(dst, 0, dst.length); return this; &amp;#125; @Override public ByteBuf readBytes(ByteBuf dst) &amp;#123; readBytes(dst, dst.writableBytes()); return this; &amp;#125; @Override public ByteBuf readBytes(ByteBuf dst, int length) &amp;#123; if (length > dst.writableBytes()) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"length(%d) exceeds dst.writableBytes(%d) where dst is: %s\", length, dst.writableBytes(), dst)); &amp;#125; readBytes(dst, dst.writerIndex(), length); dst.writerIndex(dst.writerIndex() + length); return this; &amp;#125; @Override public ByteBuf readBytes(ByteBuf dst, int dstIndex, int length) &amp;#123; checkReadableBytes(length); getBytes(readerIndex, dst, dstIndex, length); readerIndex += length; return this; &amp;#125; @Override public ByteBuf readBytes(ByteBuffer dst) &amp;#123; int length = dst.remaining(); checkReadableBytes(length); getBytes(readerIndex, dst); readerIndex += length; return this; &amp;#125; @Override public int readBytes(GatheringByteChannel out, int length) throws IOException &amp;#123; checkReadableBytes(length); int readBytes = getBytes(readerIndex, out, length); readerIndex += readBytes; return readBytes; &amp;#125; @Override public int readBytes(FileChannel out, long position, int length) throws IOException &amp;#123; checkReadableBytes(length); int readBytes = getBytes(readerIndex, out, position, length); readerIndex += readBytes; return readBytes; &amp;#125; @Override public ByteBuf readBytes(OutputStream out, int length) throws IOException &amp;#123; checkReadableBytes(length); getBytes(readerIndex, out, length); readerIndex += length; return this; &amp;#125; @Override public ByteBuf skipBytes(int length) &amp;#123; checkReadableBytes(length); readerIndex += length; return this; &amp;#125; @Override public ByteBuf writeBoolean(boolean value) &amp;#123; writeByte(value ? 1 : 0); return this; &amp;#125; @Override public ByteBuf writeByte(int value) &amp;#123; ensureAccessible(); ensureWritable0(1); _setByte(writerIndex++, value); return this; &amp;#125; @Override public ByteBuf writeShort(int value) &amp;#123; ensureAccessible(); ensureWritable0(2); _setShort(writerIndex, value); writerIndex += 2; return this; &amp;#125; @Override public ByteBuf writeShortLE(int value) &amp;#123; ensureAccessible(); ensureWritable0(2); _setShortLE(writerIndex, value); writerIndex += 2; return this; &amp;#125; @Override public ByteBuf writeMedium(int value) &amp;#123; ensureAccessible(); ensureWritable0(3); _setMedium(writerIndex, value); writerIndex += 3; return this; &amp;#125; @Override public ByteBuf writeMediumLE(int value) &amp;#123; ensureAccessible(); ensureWritable0(3); _setMediumLE(writerIndex, value); writerIndex += 3; return this; &amp;#125; @Override public ByteBuf writeInt(int value) &amp;#123; ensureAccessible(); ensureWritable0(4); _setInt(writerIndex, value); writerIndex += 4; return this; &amp;#125; @Override public ByteBuf writeIntLE(int value) &amp;#123; ensureAccessible(); ensureWritable0(4); _setIntLE(writerIndex, value); writerIndex += 4; return this; &amp;#125; @Override public ByteBuf writeLong(long value) &amp;#123; ensureAccessible(); ensureWritable0(8); _setLong(writerIndex, value); writerIndex += 8; return this; &amp;#125; @Override public ByteBuf writeLongLE(long value) &amp;#123; ensureAccessible(); ensureWritable0(8); _setLongLE(writerIndex, value); writerIndex += 8; return this; &amp;#125; @Override public ByteBuf writeChar(int value) &amp;#123; writeShort(value); return this; &amp;#125; @Override public ByteBuf writeFloat(float value) &amp;#123; writeInt(Float.floatToRawIntBits(value)); return this; &amp;#125; @Override public ByteBuf writeDouble(double value) &amp;#123; writeLong(Double.doubleToRawLongBits(value)); return this; &amp;#125; @Override public ByteBuf writeBytes(byte[] src, int srcIndex, int length) &amp;#123; ensureAccessible(); ensureWritable(length); setBytes(writerIndex, src, srcIndex, length); writerIndex += length; return this; &amp;#125; @Override public ByteBuf writeBytes(byte[] src) &amp;#123; writeBytes(src, 0, src.length); return this; &amp;#125; @Override public ByteBuf writeBytes(ByteBuf src) &amp;#123; writeBytes(src, src.readableBytes()); return this; &amp;#125; @Override public ByteBuf writeBytes(ByteBuf src, int length) &amp;#123; if (length > src.readableBytes()) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"length(%d) exceeds src.readableBytes(%d) where src is: %s\", length, src.readableBytes(), src)); &amp;#125; writeBytes(src, src.readerIndex(), length); src.readerIndex(src.readerIndex() + length); return this; &amp;#125; @Override public ByteBuf writeBytes(ByteBuf src, int srcIndex, int length) &amp;#123; ensureAccessible(); ensureWritable(length); setBytes(writerIndex, src, srcIndex, length); writerIndex += length; return this; &amp;#125; @Override public ByteBuf writeBytes(ByteBuffer src) &amp;#123; ensureAccessible(); int length = src.remaining(); ensureWritable(length); setBytes(writerIndex, src); writerIndex += length; return this; &amp;#125; @Override public int writeBytes(InputStream in, int length) throws IOException &amp;#123; ensureAccessible(); ensureWritable(length); int writtenBytes = setBytes(writerIndex, in, length); if (writtenBytes > 0) &amp;#123; writerIndex += writtenBytes; &amp;#125; return writtenBytes; &amp;#125; @Override public int writeBytes(ScatteringByteChannel in, int length) throws IOException &amp;#123; ensureAccessible(); ensureWritable(length); int writtenBytes = setBytes(writerIndex, in, length); if (writtenBytes > 0) &amp;#123; writerIndex += writtenBytes; &amp;#125; return writtenBytes; &amp;#125; @Override public int writeBytes(FileChannel in, long position, int length) throws IOException &amp;#123; ensureAccessible(); ensureWritable(length); int writtenBytes = setBytes(writerIndex, in, position, length); if (writtenBytes > 0) &amp;#123; writerIndex += writtenBytes; &amp;#125; return writtenBytes; &amp;#125; @Override public ByteBuf writeZero(int length) &amp;#123; if (length == 0) &amp;#123; return this; &amp;#125; ensureWritable(length); int wIndex = writerIndex; checkIndex(wIndex, length); int nLong = length >>> 3; int nBytes = length &amp; 7; for (int i = nLong; i > 0; i --) &amp;#123; _setLong(wIndex, 0); wIndex += 8; &amp;#125; if (nBytes == 4) &amp;#123; _setInt(wIndex, 0); wIndex += 4; &amp;#125; else if (nBytes &lt; 4) &amp;#123; for (int i = nBytes; i > 0; i --) &amp;#123; _setByte(wIndex, (byte) 0); wIndex++; &amp;#125; &amp;#125; else &amp;#123; _setInt(wIndex, 0); wIndex += 4; for (int i = nBytes - 4; i > 0; i --) &amp;#123; _setByte(wIndex, (byte) 0); wIndex++; &amp;#125; &amp;#125; writerIndex = wIndex; return this; &amp;#125; @Override public int writeCharSequence(CharSequence sequence, Charset charset) &amp;#123; int written = setCharSequence(writerIndex, sequence, charset); writerIndex += written; return written; &amp;#125; @Override public ByteBuf copy() &amp;#123; return copy(readerIndex, readableBytes()); &amp;#125; @Override public ByteBuf duplicate() &amp;#123; return new UnpooledDuplicatedByteBuf(this); &amp;#125; @Override public ByteBuf retainedDuplicate() &amp;#123; return duplicate().retain(); &amp;#125; @Override public ByteBuf slice() &amp;#123; return slice(readerIndex, readableBytes()); &amp;#125; @Override public ByteBuf retainedSlice() &amp;#123; return slice().retain(); &amp;#125; @Override public ByteBuf slice(int index, int length) &amp;#123; return new UnpooledSlicedByteBuf(this, index, length); &amp;#125; @Override public ByteBuf retainedSlice(int index, int length) &amp;#123; return slice(index, length).retain(); &amp;#125; @Override public ByteBuffer nioBuffer() &amp;#123; return nioBuffer(readerIndex, readableBytes()); &amp;#125; @Override public ByteBuffer[] nioBuffers() &amp;#123; return nioBuffers(readerIndex, readableBytes()); &amp;#125; @Override public String toString(Charset charset) &amp;#123; return toString(readerIndex, readableBytes(), charset); &amp;#125; @Override public String toString(int index, int length, Charset charset) &amp;#123; return ByteBufUtil.decodeString(this, index, length, charset); &amp;#125; @Override public int indexOf(int fromIndex, int toIndex, byte value) &amp;#123; return ByteBufUtil.indexOf(this, fromIndex, toIndex, value); &amp;#125; @Override public int bytesBefore(byte value) &amp;#123; return bytesBefore(readerIndex(), readableBytes(), value); &amp;#125; @Override public int bytesBefore(int length, byte value) &amp;#123; checkReadableBytes(length); return bytesBefore(readerIndex(), length, value); &amp;#125; @Override public int bytesBefore(int index, int length, byte value) &amp;#123; int endIndex = indexOf(index, index + length, value); if (endIndex &lt; 0) &amp;#123; return -1; &amp;#125; return endIndex - index; &amp;#125; @Override public int forEachByte(ByteProcessor processor) &amp;#123; ensureAccessible(); try &amp;#123; return forEachByteAsc0(readerIndex, writerIndex, processor); &amp;#125; catch (Exception e) &amp;#123; PlatformDependent.throwException(e); return -1; &amp;#125; &amp;#125; @Override public int forEachByte(int index, int length, ByteProcessor processor) &amp;#123; checkIndex(index, length); try &amp;#123; return forEachByteAsc0(index, index + length, processor); &amp;#125; catch (Exception e) &amp;#123; PlatformDependent.throwException(e); return -1; &amp;#125; &amp;#125; private int forEachByteAsc0(int start, int end, ByteProcessor processor) throws Exception &amp;#123; for (; start &lt; end; ++start) &amp;#123; if (!processor.process(_getByte(start))) &amp;#123; return start; &amp;#125; &amp;#125; return -1; &amp;#125; @Override public int forEachByteDesc(ByteProcessor processor) &amp;#123; ensureAccessible(); try &amp;#123; return forEachByteDesc0(writerIndex - 1, readerIndex, processor); &amp;#125; catch (Exception e) &amp;#123; PlatformDependent.throwException(e); return -1; &amp;#125; &amp;#125; @Override public int forEachByteDesc(int index, int length, ByteProcessor processor) &amp;#123; checkIndex(index, length); try &amp;#123; return forEachByteDesc0(index + length - 1, index, processor); &amp;#125; catch (Exception e) &amp;#123; PlatformDependent.throwException(e); return -1; &amp;#125; &amp;#125; private int forEachByteDesc0(int rStart, final int rEnd, ByteProcessor processor) throws Exception &amp;#123; for (; rStart >= rEnd; --rStart) &amp;#123; if (!processor.process(_getByte(rStart))) &amp;#123; return rStart; &amp;#125; &amp;#125; return -1; &amp;#125; @Override public int hashCode() &amp;#123; return ByteBufUtil.hashCode(this); &amp;#125; @Override public boolean equals(Object o) &amp;#123; if (this == o) &amp;#123; return true; &amp;#125; if (o instanceof ByteBuf) &amp;#123; return ByteBufUtil.equals(this, (ByteBuf) o); &amp;#125; return false; &amp;#125; @Override public int compareTo(ByteBuf that) &amp;#123; return ByteBufUtil.compare(this, that); &amp;#125; @Override public String toString() &amp;#123; if (refCnt() == 0) &amp;#123; return StringUtil.simpleClassName(this) + \"(freed)\"; &amp;#125; StringBuilder buf = new StringBuilder() .append(StringUtil.simpleClassName(this)) .append(\"(ridx: \").append(readerIndex) .append(\", widx: \").append(writerIndex) .append(\", cap: \").append(capacity()); if (maxCapacity != Integer.MAX_VALUE) &amp;#123; buf.append('/').append(maxCapacity); &amp;#125; ByteBuf unwrapped = unwrap(); if (unwrapped != null) &amp;#123; buf.append(\", unwrapped: \").append(unwrapped); &amp;#125; buf.append(')'); return buf.toString(); &amp;#125; protected final void checkIndex(int index) &amp;#123; checkIndex(index, 1); &amp;#125; protected final void checkIndex(int index, int fieldLength) &amp;#123; ensureAccessible(); checkIndex0(index, fieldLength); &amp;#125; final void checkIndex0(int index, int fieldLength) &amp;#123; if (isOutOfBounds(index, fieldLength, capacity())) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"index: %d, length: %d (expected: range(0, %d))\", index, fieldLength, capacity())); &amp;#125; &amp;#125; protected final void checkSrcIndex(int index, int length, int srcIndex, int srcCapacity) &amp;#123; checkIndex(index, length); if (isOutOfBounds(srcIndex, length, srcCapacity)) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"srcIndex: %d, length: %d (expected: range(0, %d))\", srcIndex, length, srcCapacity)); &amp;#125; &amp;#125; protected final void checkDstIndex(int index, int length, int dstIndex, int dstCapacity) &amp;#123; checkIndex(index, length); if (isOutOfBounds(dstIndex, length, dstCapacity)) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"dstIndex: %d, length: %d (expected: range(0, %d))\", dstIndex, length, dstCapacity)); &amp;#125; &amp;#125; /** * Throws an &amp;#123;@link IndexOutOfBoundsException&amp;#125; if the current * &amp;#123;@linkplain #readableBytes() readable bytes&amp;#125; of this buffer is less * than the specified value. */ protected final void checkReadableBytes(int minimumReadableBytes) &amp;#123; if (minimumReadableBytes &lt; 0) &amp;#123; throw new IllegalArgumentException(\"minimumReadableBytes: \" + minimumReadableBytes + \" (expected: >= 0)\"); &amp;#125; checkReadableBytes0(minimumReadableBytes); &amp;#125; private void checkReadableBytes0(int minimumReadableBytes) &amp;#123; ensureAccessible(); if (readerIndex > writerIndex - minimumReadableBytes) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"readerIndex(%d) + length(%d) exceeds writerIndex(%d): %s\", readerIndex, minimumReadableBytes, writerIndex, this)); &amp;#125; &amp;#125; /** * Should be called by every method that tries to access the buffers content to check * if the buffer was released before. */ protected final void ensureAccessible() &amp;#123; if (checkAccessible &amp;&amp; refCnt() == 0) &amp;#123; throw new IllegalReferenceCountException(0); &amp;#125; &amp;#125; final void setIndex0(int readerIndex, int writerIndex) &amp;#123; this.readerIndex = readerIndex; this.writerIndex = writerIndex; &amp;#125; final void discardMarks() &amp;#123; markedReaderIndex = markedWriterIndex = 0; &amp;#125; &amp;#125; 我们看到,上面的代码中readByte() 和getByte() 方法中都调用了一个抽象的_getByte() 方法, 这个方法在AbstractByteBuf 的子类中实现, 在 writeByte() 方法中有一个调用抽象的 _setByte() 方法, 这个方法同样也是在子类中实现. 1.3 ByteBuf 的基本分类AbstractByteBuf 之下有众多的子类, 大致可以从三个维度来进行分类, 分别如下: Pooled: 池化内存, 就是从预先分配好的内存空间中提取一段连续内存封装成一个ByteBuf 分给应用程序使用. Unsafe: 是JDK底层的一个负责IO操作的对象, 可以知道拿到对象的内存地址, 基于内存地址进行读写操作. Direct: 堆外内存, 是直接调用JDK底层的API 进行物理内存分配, 不在JVM 的堆内存中, 需要手动释放. 综上所示, 其实ByteBuf 有六种组合, Pooled 池化内存和 Unpooled 非池化内存、Unsafe 和非Unsafe、Heap堆内存和Direct 堆外内存. 下图是ByteBuf 最重要的继承关系类结构图, 通过命令就能一目了然. ByteBuf 最基本读写API 操作都在 AbstractByteBuf 中已经实现了, 其众多的子类采用不同的策略来分配内存空间, 下面对重要的几个子类总结如下: 类 描述 PooledHeapByteBuf 池化的堆内缓冲区 PooledUnsafeHeapByteBuf 池化的Unsafe 堆内缓冲区 PooledDirectByteBuf 池化的直接(堆外)缓冲区 PooledUnsafeDirectByteBuf 池化的Unsafe直接(堆外)缓冲区 UnpooledHeapByteBuf 非池化的堆内缓冲区 UnpooledUnsafeHeapByteBuf 非池化的Unsafe 堆内缓冲区 UnpooledDirectByteBuf 非池化的直接(堆外) 缓冲区 UnpooledUnsafeDirectByteBuf 非池化的Unsafe直接(堆外)缓冲区 2. ByteBufAllocator 内存管理器Netty 中内存分配有一个最顶层的抽象就是 ByteBufAllocator, 负责分配所有的byteBuf 类型的内存, 功能其实不是很多, 主要有一下几个API 方法 解释 buffer() 分配一块内存, 自动判断是否分配堆内内存或者堆外内存 ioBuffer() 尽可能的分配一块堆外直接内存, 如果系统不支持则分配堆内内存 heapBuffer() 分配一块堆内内存 directBuffer() 分配一块堆外内存 compositionBuffer() 组合分配,把多个ByteBuf 组合到一起变成一个整体 到这里有些小伙伴可能会有疑问, 以上API 中为什么没有提到的8中类型的内存分配API? 下面我们来看 ByteBufAllocator 的基本实现类 AbstractByteBufAllocator , 重点分析主要API的基本实现, 比如buffer() 方法的源码如下： @Override public ByteBuf buffer(int initialCapacity) &amp;#123; if (directByDefault) &amp;#123; return directBuffer(initialCapacity); &amp;#125; return heapBuffer(initialCapacity); &amp;#125; @Override public ByteBuf buffer(int initialCapacity, int maxCapacity) &amp;#123; if (directByDefault) &amp;#123; return directBuffer(initialCapacity, maxCapacity); &amp;#125; return heapBuffer(initialCapacity, maxCapacity); &amp;#125; 我们发现 buffer() 方法中做了判断, 是否默认支持 directBuffer, 如果支持分配 directBuffer, 否则分配heapBuffer, 下面分别来看一下 directBuffer()和 heapBuffer() 方法的实现, 先来看一下 directBuffer() 方法: @Override public ByteBuf directBuffer() &amp;#123; return directBuffer(DEFAULT_INITIAL_CAPACITY, Integer.MAX_VALUE); &amp;#125; @Override public ByteBuf directBuffer(int initialCapacity) &amp;#123; return directBuffer(initialCapacity, Integer.MAX_VALUE); &amp;#125; @Override public ByteBuf directBuffer(int initialCapacity, int maxCapacity) &amp;#123; if (initialCapacity == 0 &amp;&amp; maxCapacity == 0) &amp;#123; return emptyBuf; &amp;#125; validate(initialCapacity, maxCapacity); return newDirectBuffer(initialCapacity, maxCapacity); &amp;#125; directBuffe() 方法有很多重载方法, 最终会调用 newDirectBuffer() 方法, 我们继续跟进到 newDirectBuffer() 方法中, : /** * Create a direct &amp;#123;@link ByteBuf&amp;#125; with the given initialCapacity and maxCapacity. */ protected abstract ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity); 我们发现 newDirectBuffer() 方法其实是一个抽象方法, 最终, 会交给AbstractByteBufAllocator 的子类来实现, 同理, 我们再来看一下 heapBuffer() 方法的源码: @Override public ByteBuf heapBuffer() &amp;#123; return heapBuffer(DEFAULT_INITIAL_CAPACITY, Integer.MAX_VALUE); &amp;#125; @Override public ByteBuf heapBuffer(int initialCapacity) &amp;#123; return heapBuffer(initialCapacity, Integer.MAX_VALUE); &amp;#125; @Override public ByteBuf heapBuffer(int initialCapacity, int maxCapacity) &amp;#123; if (initialCapacity == 0 &amp;&amp; maxCapacity == 0) &amp;#123; return emptyBuf; &amp;#125; validate(initialCapacity, maxCapacity); return newHeapBuffer(initialCapacity, maxCapacity); &amp;#125; 我们发现 heapBuffer() 方法最终会是调用 newHeapBuffer() 方法, 而newHeapBuffer 方法也是抽象方法, 具体交给AbstractByteBufAllocator 的子类来实现. AbstractByteBufAllocator 的子类主要有两个: PooledByteBufAllocator 和UnpooledByteBufAllocator，下面我们来看 AbstractByteBufAllocator 子类实现的类结构图： 分析到这里, 其实我们还只知道道 directBuffer、heapBuffer 和 pooled、unpooled 的分配规则, 那 unsafe 和非unsafe 是如何判别的呢? 其实, 是Netty 自动帮我们判别的. 如果操作系统底层支持 unsafe 那就采用 unsafe 读写, 否则采用非 unsafe 读写. 我们可以从 UnpooledByteBufAllocator 的源码中验证一下, 来看源码: @Override protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) &amp;#123; return PlatformDependent.hasUnsafe() ? new UnpooledUnsafeHeapByteBuf(this, initialCapacity, maxCapacity) : new UnpooledHeapByteBuf(this, initialCapacity, maxCapacity); &amp;#125; @Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &amp;#123; ByteBuf buf = PlatformDependent.hasUnsafe() ? UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) : new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); return disableLeakDetector ? buf : toLeakAwareBuffer(buf); &amp;#125; 我们发现, 在newHeapBuffer () 方法和newDirectBuffer() 方法中, 分配内存判断 PlatformDependent 是否支持 Unsafe, 如果支持则创建Unsafe类型的Buffer, 否则创建非Unsafe 类型的Buffer, 由Netty 帮我们自动判断了. 3. Unpooled 非池化内存分配1. 堆内内存的分配现在我们来看 UnpooledByteBufAllocator 的内存分配原理, 首先,来看 heapBuffer 的分配逻辑, 进入 newHeapBuffer() 方法源码: @Override protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) &amp;#123; return PlatformDependent.hasUnsafe() ? new UnpooledUnsafeHeapByteBuf(this, initialCapacity, maxCapacity) : new UnpooledHeapByteBuf(this, initialCapacity, maxCapacity); &amp;#125; 通过调用PlatformDependent.hasUnsafe() 方法来判断操作系统是否支持 Unsafe, 如果支持Unsafe 则创建 UnpooledUnsafeHeapByteBuf 类, 否则创建 UnpooledHeapByteBuf 类, 我们进入到 UnpooledUnsafeHeapByteBuf 的构造器中看看会进行哪些操作? final class UnpooledUnsafeHeapByteBuf extends UnpooledHeapByteBuf &amp;#123; /** * Creates a new heap buffer with a newly allocated byte array. * * @param initialCapacity the initial capacity of the underlying byte array * @param maxCapacity the max capacity of the underlying byte array */ UnpooledUnsafeHeapByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) &amp;#123; super(alloc, initialCapacity, maxCapacity); &amp;#125; &amp;#125; 我们发现 UnpooledUnsafeHeapByteBuf 继承了UnpooledHeapByteBuf , 并且在 UnpooledUnsafeHeapByteBuf 的构造器中直接调用了 super 也就是 UnpooledHeapByteBuf 的构造方法, 我们进入到 UnpooledHeapByteBuf 的构造器代码: public class UnpooledHeapByteBuf extends AbstractReferenceCountedByteBuf &amp;#123; private final ByteBufAllocator alloc; byte[] array; private ByteBuffer tmpNioBuf; /** * Creates a new heap buffer with a newly allocated byte array. * * @param initialCapacity the initial capacity of the underlying byte array * @param maxCapacity the max capacity of the underlying byte array */ protected UnpooledHeapByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) &amp;#123; this(alloc, new byte[initialCapacity], 0, 0, maxCapacity); &amp;#125; /** * Creates a new heap buffer with an existing byte array. * * @param initialArray the initial underlying byte array * @param maxCapacity the max capacity of the underlying byte array */ protected UnpooledHeapByteBuf(ByteBufAllocator alloc, byte[] initialArray, int maxCapacity) &amp;#123; this(alloc, initialArray, 0, initialArray.length, maxCapacity); &amp;#125; private UnpooledHeapByteBuf( ByteBufAllocator alloc, byte[] initialArray, int readerIndex, int writerIndex, int maxCapacity) &amp;#123; super(maxCapacity); if (alloc == null) &amp;#123; throw new NullPointerException(\"alloc\"); &amp;#125; if (initialArray == null) &amp;#123; throw new NullPointerException(\"initialArray\"); &amp;#125; if (initialArray.length > maxCapacity) &amp;#123; throw new IllegalArgumentException(String.format( \"initialCapacity(%d) > maxCapacity(%d)\", initialArray.length, maxCapacity)); &amp;#125; this.alloc = alloc; setArray(initialArray); setIndex(readerIndex, writerIndex); &amp;#125; ....... &amp;#125; 有一段关键的代码就是 setArray() 方法， 里面的实现也非常简单, 就是把默认分配的数据 new byte[initialCapacity]赋值给全局变量 array private void setArray(byte[] initialArray) &amp;#123; array = initialArray; tmpNioBuf = null; &amp;#125; 紧接着就是调用了 setIndex() 方法: @Override public ByteBuf setIndex(int readerIndex, int writerIndex) &amp;#123; if (readerIndex &lt; 0 || readerIndex > writerIndex || writerIndex > capacity()) &amp;#123; throw new IndexOutOfBoundsException(String.format( \"readerIndex: %d, writerIndex: %d (expected: 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity(%d))\", readerIndex, writerIndex, capacity())); &amp;#125; setIndex0(readerIndex, writerIndex); return this; &amp;#125; 最终在 setIndex0() 方法中初始化 readerIndex、writerIndex 既然, UnpooledUnsafeHeapByteBuf 和 UnpooledHeapByteBuf 调用的都是 UnpooledHeapByteBuf 的构造方法，那么它们之间到底有什么区别呢? 其实根据区别在于IO的读写, 我们可以分别来看一下它们的 getByte() 方法 了解两者的区别. 先来看看 UnpooledHeapByteBuf的 getByte() 方法的实现: @Override public byte getByte(int index) &amp;#123; ensureAccessible(); return _getByte(index); &amp;#125; @Override protected byte _getByte(int index) &amp;#123; return HeapByteBufUtil.getByte(array, index); &amp;#125; 我们可以看到最终调用的是 HeapByteBufUtil 的 getByte() 方法, 继续跟进去: static byte getByte(byte[] memory, int index) &amp;#123; return memory[index]; &amp;#125; 这个操作非常简单,直接用数组索引取值, 再来看看 UnpooledUnsafeHeapByteBuf 的 getByte() 方法实现: @Override public byte getByte(int index) &amp;#123; checkIndex(index); return _getByte(index); &amp;#125; @Override protected byte _getByte(int index) &amp;#123; return UnsafeByteBufUtil.getByte(array, index); &amp;#125; 我们可以看到最终调用的是 UnsafeByteBufUtil.getByte() 方法， 继续跟进去: static byte getByte(byte[] array, int index) &amp;#123; return PlatformDependent.getByte(array, index); &amp;#125; 通过这样一对比我们基本已经了解 解 UnpooledUnsafeHeapByteBuf 和 UnpooledHeapByteBuf 的区别了. 2. 堆外内存的分配我们还是回到 UnpooledByteBufAllocator 的 newDirectBuffer() 方法: @Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &amp;#123; ByteBuf buf = PlatformDependent.hasUnsafe() ? UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) : new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); return disableLeakDetector ? buf : toLeakAwareBuffer(buf); &amp;#125; 从上面的代码来看, 如果支持Unsafe 则调用 UnsafeByteBufUtil.newUnsafeDirectByteBuf() 方法, 否则创建 UnpooledDirectByteBuf 类,我们来看一下 UnpooledDirectByteBuf 的构造器 protected UnpooledDirectByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) &amp;#123; super(maxCapacity); if (alloc == null) &amp;#123; throw new NullPointerException(\"alloc\"); &amp;#125; if (initialCapacity &lt; 0) &amp;#123; throw new IllegalArgumentException(\"initialCapacity: \" + initialCapacity); &amp;#125; if (maxCapacity &lt; 0) &amp;#123; throw new IllegalArgumentException(\"maxCapacity: \" + maxCapacity); &amp;#125; if (initialCapacity > maxCapacity) &amp;#123; throw new IllegalArgumentException(String.format( \"initialCapacity(%d) > maxCapacity(%d)\", initialCapacity, maxCapacity)); &amp;#125; this.alloc = alloc; setByteBuffer(ByteBuffer.allocateDirect(initialCapacity)); &amp;#125; 首先调用了ByteBuffer.allocateDirect(initialCapacity) 通过JDK 底层直接分配一个直接缓冲区, 然后传给 setByteBuffer() 方法，我们继续跟进: private void setByteBuffer(ByteBuffer buffer) &amp;#123; ByteBuffer oldBuffer = this.buffer; if (oldBuffer != null) &amp;#123; if (doNotFree) &amp;#123; doNotFree = false; &amp;#125; else &amp;#123; freeDirect(oldBuffer); &amp;#125; &amp;#125; this.buffer = buffer; tmpNioBuf = null; capacity = buffer.remaining(); &amp;#125; 我们可以看到 setByteBuffer() 方法中主要是做了一次赋值 下面我们继续来看 UnsafeByteBufUtil.newUnsafeDirectByteBuf()方法，看它的逻辑： static UnpooledUnsafeDirectByteBuf newUnsafeDirectByteBuf( ByteBufAllocator alloc, int initialCapacity, int maxCapacity) &amp;#123; if (PlatformDependent.useDirectBufferNoCleaner()) &amp;#123; return new UnpooledUnsafeNoCleanerDirectByteBuf(alloc, initialCapacity, maxCapacity); &amp;#125; return new UnpooledUnsafeDirectByteBuf(alloc, initialCapacity, maxCapacity); &amp;#125; 在这个方法中返回了一个UnpooledUnsafeDirectByteBuf 对象. 下面进入 UnpooledUnsafeDirectByteBuf的构造器. protected UnpooledUnsafeDirectByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) &amp;#123; super(maxCapacity); if (alloc == null) &amp;#123; throw new NullPointerException(\"alloc\"); &amp;#125; if (initialCapacity &lt; 0) &amp;#123; throw new IllegalArgumentException(\"initialCapacity: \" + initialCapacity); &amp;#125; if (maxCapacity &lt; 0) &amp;#123; throw new IllegalArgumentException(\"maxCapacity: \" + maxCapacity); &amp;#125; if (initialCapacity > maxCapacity) &amp;#123; throw new IllegalArgumentException(String.format( \"initialCapacity(%d) > maxCapacity(%d)\", initialCapacity, maxCapacity)); &amp;#125; this.alloc = alloc; setByteBuffer(allocateDirect(initialCapacity), false); &amp;#125; 它的逻辑和UnpooledDirectByteBuf 构造器的逻辑是相似的. 所以我们关注一下 setByteBuffer 这个方法， 看跟 UnpooledDirectByteBuf 的setByteBuffer () 方法有什么区别? final void setByteBuffer(ByteBuffer buffer, boolean tryFree) &amp;#123; if (tryFree) &amp;#123; ByteBuffer oldBuffer = this.buffer; if (oldBuffer != null) &amp;#123; if (doNotFree) &amp;#123; doNotFree = false; &amp;#125; else &amp;#123; freeDirect(oldBuffer); &amp;#125; &amp;#125; &amp;#125; this.buffer = buffer; memoryAddress = PlatformDependent.directBufferAddress(buffer); tmpNioBuf = null; capacity = buffer.remaining(); &amp;#125; 同样还是先把创建从JDK 底层创建好的buffer 保存好, 接下来有个很重要的操作就是调用了 PlatformDependent.directBufferAddress(buffer); 方法获取 buffer 的真实内存地址, 并保存到 memoryAddress 变量中, 我们进去到PlatformDependent.directBufferAddress(buffer); 方法一探究竟: public static long directBufferAddress(ByteBuffer buffer) &amp;#123; return PlatformDependent0.directBufferAddress(buffer); &amp;#125; 继续进入到 PlatformDependent0.directBufferAddress(buffer) 方法: static long directBufferAddress(ByteBuffer buffer) &amp;#123; return getLong(buffer, ADDRESS_FIELD_OFFSET); &amp;#125; private static long getLong(Object object, long fieldOffset) &amp;#123; return UNSAFE.getLong(object, fieldOffset); &amp;#125; 可以看到, 调用了UNSAFE的getLong() 方法, 这个方法是一个native 方法, 它是直接通过buffer 的内存地址加上一个偏移量去取数据. 到这里我们已经基本清楚了UnpooledUnsafeDirectByteBuf 和 UnpooledDirectByteBuf 的区别，非unsafe 是通过数组的下标取数据，而 unsafe 是直接操作内存地址，相对于非 unsafe 来说效率当然要更高。","categories":[{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"}],"tags":[]},{"title":"Docker Swarm(7)","slug":"Docker/Docker Swarm(7)","date":"2022-01-04T02:42:07.213Z","updated":"2022-01-04T02:42:07.213Z","comments":true,"path":"2022/01/04/docker/docker-swarm-7/","link":"","permalink":"https://rainsoil.github.io/2022/01/04/docker/docker-swarm-7/","excerpt":"","text":"Docker Swarm 官网：https://docs.docker.com/swarm/ 1 Install Swarm1.1 环境准备 (1)根据Vagrantfile创建3台centos机器 [大家可以根据自己实际的情况准备3台centos机器，不一定要使用vagrant+virtualbox] 新建swarm-docker-centos7文件夹，创建Vagrantfile boxes = [ &amp;#123; :name => \"manager-node\", :eth1 => \"192.168.0.11\", :mem => \"1024\", :cpu => \"1\" &amp;#125;, &amp;#123; :name => \"worker01-node\", :eth1 => \"192.168.0.12\", :mem => \"1024\", :cpu => \"1\" &amp;#125;, &amp;#123; :name => \"worker02-node\", :eth1 => \"192.168.0.13\", :mem => \"1024\", :cpu => \"1\" &amp;#125; ] Vagrant.configure(2) do |config| config.vm.box = \"centos/7\" boxes.each do |opts| config.vm.define opts[:name] do |config| config.vm.hostname = opts[:name] config.vm.provider \"vmware_fusion\" do |v| v.vmx[\"memsize\"] = opts[:mem] v.vmx[\"numvcpus\"] = opts[:cpu] end config.vm.provider \"virtualbox\" do |v| v.customize [\"modifyvm\", :id, \"--memory\", opts[:mem]] v.customize [\"modifyvm\", :id, \"--cpus\", opts[:cpu]] v.customize [\"modifyvm\", :id, \"--name\", opts[:name]] end config.vm.network :public_network, ip: opts[:eth1] end end end (2)进入到对应的centos里面，使得root账户能够登陆，从而使用XShell登陆 vagrant ssh manager-node/worker01-node/worker02-node sudo -i vi /etc/ssh/sshd_config 修改PasswordAuthentication yes passwd 修改密码 systemctl restart sshd (3)在win上ping一下各个主机，看是否能ping通 ping 192.168.0.11/12/13 (4)在每台机器上安装docker engine 小技巧：要想让每个shell窗口一起执行同样的命令”查看–&gt;撰写–&gt;撰写窗口–&gt;全部会话” 1.2 搭建Swarm集群 (1)进入manager 提示：manager node也可以作为worker node提供服务 docker swarm init --advertise-addr=192.168.0.11 注意观察日志，拿到worker node加入manager node的信息 docker swarm join --token SWMTKN-1-0a5ph4nehwdm9wzcmlbj2ckqqso38pkd238rprzwcoawabxtdq-arcpra6yzltedpafk3qyvv0y3 192.168.0.11:2377 (2)进入两个worker docker swarm join --token SWMTKN-1-0a5ph4nehwdm9wzcmlbj2ckqqso38pkd238rprzwcoawabxtdq-arcpra6yzltedpafk3qyvv0y3 192.168.0.11:2377 日志打印 This node joined a swarm as a worker. (3)进入到manager node查看集群状态 docker node ls (4)node类型的转换 可以将worker提升成manager，从而保证manager的高可用 docker node promote worker01-node docker node promote worker02-node #降级可以用demote docker node demote worker01-node 1.3 在线的 http://labs.play-with-docker.com 2 Swarm基本操作2.1 Service (1)创建一个tomcat的service docker service create --name my-tomcat tomcat (2)查看当前swarm的service docker service ls (3)查看service的启动日志 docker service logs my-tomcat (4)查看service的详情 docker service inspect my-tomcat (5)查看my-tomcat运行在哪个node上 docker service ps my-tomcat 日志 ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS u6o4mz4tj396 my-tomcat.1 tomcat:latest worker01-node Running Running 3 minutes ago (6)水平扩展service docker service scale my-tomcat=3 docker service ls docker service ps my-tomcat 日志：可以发现，其他node上都运行了一个my-tomcat的service [root@manager-node ~]# docker service ps my-tomcat ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS u6o4mz4tj396 my-tomcat.1 tomcat:latest worker01-node Running Running 8 minutes ago v505wdu3fxqo my-tomcat.2 tomcat:latest manager-node Running Running 46 seconds ago wpbsilp62sc0 my-tomcat.3 tomcat:latest worker02-node Running Running 49 seconds ago 此时到worker01-node上：docker ps，可以发现container的name和service名称不一样，这点要知道 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bc4b9bb097b8 tomcat:latest &quot;catalina.sh run&quot; 10 minutes ago Up 10 minutes 8080/tcp my-tomcat.1.u6o4mz4tj3969a1p3mquagxok (7)如果某个node上的my-tomcat挂掉了，这时候会自动扩展 [worker01-node] docker rm -f containerid [manager-node] docker service ls docker service ps my-tomcat (8)删除service docker service rm my-tomcat 2.2 多机通信overlay网络[3.7的延续] 业务场景：workpress+mysql实现个人博客搭建 https://hub.docker.com/_/wordpress?tab=description 2.2.1 传统手动方式实现2.2.1.1 一台centos上，分别创建容器01-创建mysql容器[创建完成等待一会，注意mysql的版本] docker run -d --name mysql -v v1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=examplepass -e MYSQL_DATABASE=db_wordpress mysql:5.6 02-创建wordpress容器[将wordpress的80端口映射到centos的8080端口] docker run -d --name wordpress --link mysql -e WORDPRESS_DB_HOST=mysql:3306 -e WORDPRESS_DB_USER=root -e WORDPRESS_DB_PASSWORD=examplepass -e WORDPRESS_DB_NAME=db_wordpress -p 8080:80 wordpress 03-查看默认bridge的网络，可以发现两个容器都在其中 docker network inspect bridge 04-访问测试 win浏览器中输入：ip[centos]:8080，一直下一步 2.2.1.2 使用docker compose创建 docker-compose的方式还是在一台机器中，网络这块很清晰 01-创建wordpress-mysql文件夹 mkdir -p /tmp/wordpress-mysql cd /tmp/wordpress-mysql 02-创建docker-compose.yml文件 文件内容 version: '3.1' services: wordpress: image: wordpress restart: always ports: - 8080:80 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: exampleuser WORDPRESS_DB_PASSWORD: examplepass WORDPRESS_DB_NAME: exampledb volumes: - wordpress:/var/www/html db: image: mysql:5.7 restart: always environment: MYSQL_DATABASE: exampledb MYSQL_USER: exampleuser MYSQL_PASSWORD: examplepass MYSQL_RANDOM_ROOT_PASSWORD: '1' volumes: - db:/var/lib/mysql volumes: wordpress: db: 03-根据docker-compose.yml文件创建service docker-compose up -d 04-访问测试 win10浏览器ip[centos]:8080，一直下一步 05-值得关注的点是网络 docker network ls docker network inspect wordpress-mysql_default 2.2.2 Swarm中实现 还是wordpress+mysql的案例，在docker swarm集群中怎么玩呢？ (1)创建一个overlay网络，用于docker swarm中多机通信 【manager-node】 docker network create -d overlay my-overlay-net docker network ls[此时worker node查看不到] (2)创建mysql的service 【manager-node】 01-创建service docker service create --name mysql --mount type=volume,source=v1,destination=/var/lib/mysql --env MYSQL_ROOT_PASSWORD=examplepass --env MYSQL_DATABASE=db_wordpress --network my-overlay-net mysql:5.6 02-查看service docker service ls docker service ps mysql (3)创建wordpress的service 01-创建service [注意之所以下面可以通过mysql名字访问，也是因为有DNS解析] docker service create --name wordpress --env WORDPRESS_DB_USER=root --env WORDPRESS_DB_PASSWORD=examplepass --env WORDPRESS_DB_HOST=mysql:3306 --env WORDPRESS_DB_NAME=db_wordpress -p 8080:80 --network my-overlay-net wordpress 02-查看service docker service ls docker service ps mysql 03-此时mysql和wordpress的service运行在哪个node上，这时候就能看到my-overlay-net的网络 (4)测试 win浏览器访问ip[manager/worker01/worker02]:8080都能访问成功 (5)查看my-overlay-net docker network inspect my-overlay-net (6)为什么没有用etcd？docker swarm中有自己的分布式存储机制 3 Routing Mesh3.1 Ingress 通过前面的案例我们发现，部署一个wordpress的service，映射到主机的8080端口，这时候通过swarm集群中的任意主机ip:8080都能成功访问，这是因为什么？ 把问题简化：docker service create --name tomcat -p 8080:8080 --network my-overlay-net tomcat (1)记得使用一个自定义的overlay类型的网络 --network my-overlay-net (2)查看service情况 docker service ls docker service ps tomcat (3)访问3台机器的ip:8080测试 发现都能够访问到tomcat的欢迎页 4.2 Internal 之前在实战wordpress+mysql的时候，发现wordpress中可以直接通过mysql名称访问 这样可以说明两点，第一是其中一定有dns解析，第二是两个service的ip是能够ping通的 思考：不妨再创建一个service，也同样使用上述tomcat的overlay网络，然后来实验 docker service create --name whoami -p 8000:8000 --network my-overlay-net -d jwilder/whoami (1)查看whoami的情况 docker service ps whoami (2)在各自容器中互相ping一下彼此，也就是容器间的通信 #tomcat容器中ping whoami docker exec -it 9d7d4c2b1b80 ping whoami 64 bytes from bogon (10.0.0.8): icmp_seq=1 ttl=64 time=0.050 ms 64 bytes from bogon (10.0.0.8): icmp_seq=2 ttl=64 time=0.080 ms #whoami容器中ping tomcat docker exec -it 5c4fe39e7f60 ping tomcat 64 bytes from bogon (10.0.0.18): icmp_seq=1 ttl=64 time=0.050 ms 64 bytes from bogon (10.0.0.18): icmp_seq=2 ttl=64 time=0.080 ms (3)将whoami进行扩容 docker service scale whoami=3 docker service ps whoami #manager,worker01,worker02 (4)此时再``ping whoami service，并且访问whoam`i服务 #ping docker exec -it 9d7d4c2b1b80 ping whoami 64 bytes from bogon (10.0.0.8): icmp_seq=1 ttl=64 time=0.055 ms 64 bytes from bogon (10.0.0.8): icmp_seq=2 ttl=64 time=0.084 ms #访问 docker exec -it 9d7d4c2b1b80 curl whoami:8000 [多访问几次] I&#39;m 09f4158c81ae I&#39;m aebc574dc990 I&#39;m 7755bc7da921 小结：通过上述的实验可以发现什么？whoami服务对其他服务暴露的ip是不变的，但是通过whoami名称访问8000端口，确实访问到的是不同的service，就说明访问其实是像下面这张图。 也就是说whoami service对其他服务提供了一个统一的VIP入口，别的服务访问时会做负载均衡。 5 Stack docker stack deploy：https://docs.docker.com/engine/reference/commandline/stack_deploy/ compose-file：https://docs.docker.com/compose/compose-file/ 有没有发现上述部署service很麻烦？要是能够类似于docker-compose.yml文件那种方式一起管理该多少？这就要涉及到docker swarm中的Stack，我们直接通过前面的wordpress+mysql案例看看怎么使用咯。 (1)新建service.yml文件 version: '3' services: wordpress: image: wordpress ports: - 8080:80 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: exampleuser WORDPRESS_DB_PASSWORD: examplepass WORDPRESS_DB_NAME: exampledb networks: - ol-net volumes: - wordpress:/var/www/html deploy: mode: replicated replicas: 3 restart_policy: condition: on-failure delay: 5s max_attempts: 3 update_config: parallelism: 1 delay: 10s db: image: mysql:5.7 environment: MYSQL_DATABASE: exampledb MYSQL_USER: exampleuser MYSQL_PASSWORD: examplepass MYSQL_RANDOM_ROOT_PASSWORD: '1' volumes: - db:/var/lib/mysql networks: - ol-net deploy: mode: global placement: constraints: - node.role == manager volumes: wordpress: db: networks: ol-net: driver: overlay (2)根据service.yml创建service docker statck deploy -c service.yml my-service (3)常见操作 01-查看stack具体信息 docker stack ls NAME SERVICES ORCHESTRATOR my-service 2 Swarm 02-查看具体的service docker stack services my-service ID NAME MODE REPLICAS IMAGE PORTS icraimlesu61 my-service_db global 1/1 mysql:5.7 iud2g140za5c my-service_wordpress replicated 3/3 wordpress:latest *:8080-&gt;80/tcp 03-查看某个service docker service inspect my-service-db &quot;Endpoint&quot;: &#123; &quot;Spec&quot;: &#123; &quot;Mode&quot;: &quot;vip&quot; &#125;, &quot;VirtualIPs&quot;: [ &#123; &quot;NetworkID&quot;: &quot;kz1reu3yxxpwp1lvnrraw0uq6&quot;, &quot;Addr&quot;: &quot;10.0.1.5/24&quot; &#125; ] &#125; (4)访问测试 win浏览器ip[manager,worker01,worker02]:8080","categories":[{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[]}],"categories":[{"name":"面试题","slug":"面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"面试题","slug":"面试题/面试题","permalink":"https://rainsoil.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"软考-数据库","slug":"软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"软考-数据库","slug":"软考-数据库/软考-数据库","permalink":"https://rainsoil.github.io/categories/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%BD%AF%E8%80%83-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"设计模式","slug":"设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式/设计模式","permalink":"https://rainsoil.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"疑难杂症","slug":"疑难杂症/疑难杂症","permalink":"https://rainsoil.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"数据库","slug":"数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库","slug":"数据库/数据库","permalink":"https://rainsoil.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"zookpeer","slug":"zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/"},{"name":"微服务","slug":"zookpeer/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"zookpeer/微服务/微服务","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"zookpeer","slug":"zookpeer/微服务/微服务/zookpeer","permalink":"https://rainsoil.github.io/categories/zookpeer/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookpeer/"},{"name":"微服务","slug":"微服务","permalink":"https://rainsoil.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"微服务/微服务","permalink":"https://rainsoil.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"kafka","slug":"kafka","permalink":"https://rainsoil.github.io/categories/kafka/"},{"name":"微服务","slug":"kafka/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"kafka/微服务/微服务","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"kafka","slug":"kafka/微服务/微服务/kafka","permalink":"https://rainsoil.github.io/categories/kafka/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/kafka/"},{"name":"dubbo","slug":"dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/"},{"name":"微服务","slug":"dubbo/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"dubbo/微服务/微服务","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"dubbo","slug":"dubbo/微服务/微服务/dubbo","permalink":"https://rainsoil.github.io/categories/dubbo/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/"},{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/"},{"name":"微服务","slug":"rabbitMQ/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"rabbitMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"rabbitMQ","slug":"rabbitMQ/微服务/微服务/rabbitMQ","permalink":"https://rainsoil.github.io/categories/rabbitMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/rabbitMQ/"},{"name":"nacos","slug":"nacos","permalink":"https://rainsoil.github.io/categories/nacos/"},{"name":"微服务","slug":"nacos/微服务","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"nacos/微服务/微服务","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"nacos","slug":"nacos/微服务/微服务/nacos","permalink":"https://rainsoil.github.io/categories/nacos/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/nacos/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/"},{"name":"微服务","slug":"Spring-Cloud/微服务","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"Spring-Cloud/微服务/微服务","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Spring Cloud","slug":"Spring-Cloud/微服务/微服务/Spring-Cloud","permalink":"https://rainsoil.github.io/categories/Spring-Cloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Spring-Cloud/"},{"name":"并发编程","slug":"并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程/并发编程","permalink":"https://rainsoil.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/"},{"name":"微服务","slug":"RocketMQ/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"RocketMQ/微服务/微服务","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"RocketMQ","slug":"RocketMQ/微服务/微服务/RocketMQ","permalink":"https://rainsoil.github.io/categories/RocketMQ/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/RocketMQ/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://rainsoil.github.io/categories/Sentinel/"},{"name":"微服务","slug":"Sentinel/微服务","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"微服务","slug":"Sentinel/微服务/微服务","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Sentinel","slug":"Sentinel/微服务/微服务/Sentinel","permalink":"https://rainsoil.github.io/categories/Sentinel/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Sentinel/"},{"name":"工具","slug":"工具","permalink":"https://rainsoil.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"工具/工具","permalink":"https://rainsoil.github.io/categories/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"},{"name":"安装","slug":"安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/"},{"name":"安装","slug":"安装/安装","permalink":"https://rainsoil.github.io/categories/%E5%AE%89%E8%A3%85/%E5%AE%89%E8%A3%85/"},{"name":"基础","slug":"基础","permalink":"https://rainsoil.github.io/categories/%E5%9F%BA%E7%A1%80/"},{"name":"基础","slug":"基础/基础","permalink":"https://rainsoil.github.io/categories/%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80/"},{"name":"swagger","slug":"swagger","permalink":"https://rainsoil.github.io/categories/swagger/"},{"name":"工具","slug":"swagger/工具","permalink":"https://rainsoil.github.io/categories/swagger/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"swagger/工具/工具","permalink":"https://rainsoil.github.io/categories/swagger/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"},{"name":"swagger","slug":"swagger/工具/工具/swagger","permalink":"https://rainsoil.github.io/categories/swagger/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/swagger/"},{"name":"hexo","slug":"hexo","permalink":"https://rainsoil.github.io/categories/hexo/"},{"name":"工具","slug":"hexo/工具","permalink":"https://rainsoil.github.io/categories/hexo/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"hexo/工具/工具","permalink":"https://rainsoil.github.io/categories/hexo/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"},{"name":"hexo","slug":"hexo/工具/工具/hexo","permalink":"https://rainsoil.github.io/categories/hexo/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/hexo/"},{"name":"github","slug":"github","permalink":"https://rainsoil.github.io/categories/github/"},{"name":"工具","slug":"github/工具","permalink":"https://rainsoil.github.io/categories/github/%E5%B7%A5%E5%85%B7/"},{"name":"工具","slug":"github/工具/工具","permalink":"https://rainsoil.github.io/categories/github/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/"},{"name":"github","slug":"github/工具/工具/github","permalink":"https://rainsoil.github.io/categories/github/%E5%B7%A5%E5%85%B7/%E5%B7%A5%E5%85%B7/github/"},{"name":"vue","slug":"vue","permalink":"https://rainsoil.github.io/categories/vue/"},{"name":"前端","slug":"vue/前端","permalink":"https://rainsoil.github.io/categories/vue/%E5%89%8D%E7%AB%AF/"},{"name":"前端","slug":"vue/前端/前端","permalink":"https://rainsoil.github.io/categories/vue/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/"},{"name":"vue","slug":"vue/前端/前端/vue","permalink":"https://rainsoil.github.io/categories/vue/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/vue/"},{"name":"任务调度","slug":"任务调度","permalink":"https://rainsoil.github.io/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"},{"name":"任务调度","slug":"任务调度/任务调度","permalink":"https://rainsoil.github.io/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"},{"name":"2. 分布式架构基础","slug":"2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"},{"name":"分布式","slug":"2-分布式架构基础/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式","slug":"2-分布式架构基础/分布式/分布式","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"2. 分布式架构基础","slug":"2-分布式架构基础/分布式/分布式/2-分布式架构基础","permalink":"https://rainsoil.github.io/categories/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/2-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"},{"name":"1. 漫谈分布式架构","slug":"1-漫谈分布式架构","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"},{"name":"分布式","slug":"1-漫谈分布式架构/分布式","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式","slug":"1-漫谈分布式架构/分布式/分布式","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"1. 漫谈分布式架构","slug":"1-漫谈分布式架构/分布式/分布式/1-漫谈分布式架构","permalink":"https://rainsoil.github.io/categories/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F/1-%E6%BC%AB%E8%B0%88%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"},{"name":"ES6","slug":"ES6","permalink":"https://rainsoil.github.io/categories/ES6/"},{"name":"前端","slug":"ES6/前端","permalink":"https://rainsoil.github.io/categories/ES6/%E5%89%8D%E7%AB%AF/"},{"name":"前端","slug":"ES6/前端/前端","permalink":"https://rainsoil.github.io/categories/ES6/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/"},{"name":"ES6","slug":"ES6/前端/前端/ES6","permalink":"https://rainsoil.github.io/categories/ES6/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF/ES6/"},{"name":"vpn","slug":"vpn","permalink":"https://rainsoil.github.io/categories/vpn/"},{"name":"vpn","slug":"vpn/vpn","permalink":"https://rainsoil.github.io/categories/vpn/vpn/"},{"name":"window","slug":"window","permalink":"https://rainsoil.github.io/categories/window/"},{"name":"window","slug":"window/window","permalink":"https://rainsoil.github.io/categories/window/window/"},{"name":"spring","slug":"spring","permalink":"https://rainsoil.github.io/categories/spring/"},{"name":"spring","slug":"spring/spring","permalink":"https://rainsoil.github.io/categories/spring/spring/"},{"name":"tomcat","slug":"tomcat","permalink":"https://rainsoil.github.io/categories/tomcat/"},{"name":"tomcat","slug":"tomcat/tomcat","permalink":"https://rainsoil.github.io/categories/tomcat/tomcat/"},{"name":"redis","slug":"redis","permalink":"https://rainsoil.github.io/categories/redis/"},{"name":"redis","slug":"redis/redis","permalink":"https://rainsoil.github.io/categories/redis/redis/"},{"name":"mysql","slug":"mysql","permalink":"https://rainsoil.github.io/categories/mysql/"},{"name":"mysql","slug":"mysql/mysql","permalink":"https://rainsoil.github.io/categories/mysql/mysql/"},{"name":"nginx","slug":"nginx","permalink":"https://rainsoil.github.io/categories/nginx/"},{"name":"nginx","slug":"nginx/nginx","permalink":"https://rainsoil.github.io/categories/nginx/nginx/"},{"name":"mybatis","slug":"mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/"},{"name":"mybatis","slug":"mybatis/mybatis","permalink":"https://rainsoil.github.io/categories/mybatis/mybatis/"},{"name":"maven","slug":"maven","permalink":"https://rainsoil.github.io/categories/maven/"},{"name":"maven","slug":"maven/maven","permalink":"https://rainsoil.github.io/categories/maven/maven/"},{"name":"linux","slug":"linux","permalink":"https://rainsoil.github.io/categories/linux/"},{"name":"linux","slug":"linux/linux","permalink":"https://rainsoil.github.io/categories/linux/linux/"},{"name":"jvm","slug":"jvm","permalink":"https://rainsoil.github.io/categories/jvm/"},{"name":"jvm","slug":"jvm/jvm","permalink":"https://rainsoil.github.io/categories/jvm/jvm/"},{"name":"k8s","slug":"k8s","permalink":"https://rainsoil.github.io/categories/k8s/"},{"name":"k8s","slug":"k8s/k8s","permalink":"https://rainsoil.github.io/categories/k8s/k8s/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/"},{"name":"Spring Boot","slug":"Spring-Boot/Spring-Boot","permalink":"https://rainsoil.github.io/categories/Spring-Boot/Spring-Boot/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/"},{"name":"elasticsearch","slug":"elasticsearch/elasticsearch","permalink":"https://rainsoil.github.io/categories/elasticsearch/elasticsearch/"},{"name":"Service Mesh","slug":"Service-Mesh","permalink":"https://rainsoil.github.io/categories/Service-Mesh/"},{"name":"Service Mesh","slug":"Service-Mesh/Service-Mesh","permalink":"https://rainsoil.github.io/categories/Service-Mesh/Service-Mesh/"},{"name":"git","slug":"git","permalink":"https://rainsoil.github.io/categories/git/"},{"name":"git","slug":"git/git","permalink":"https://rainsoil.github.io/categories/git/git/"},{"name":"ftp","slug":"ftp","permalink":"https://rainsoil.github.io/categories/ftp/"},{"name":"ftp","slug":"ftp/ftp","permalink":"https://rainsoil.github.io/categories/ftp/ftp/"},{"name":"Security","slug":"Security","permalink":"https://rainsoil.github.io/categories/Security/"},{"name":"Security","slug":"Security/Security","permalink":"https://rainsoil.github.io/categories/Security/Security/"},{"name":"Netty","slug":"Netty","permalink":"https://rainsoil.github.io/categories/Netty/"},{"name":"Netty","slug":"Netty/Netty","permalink":"https://rainsoil.github.io/categories/Netty/Netty/"},{"name":"Docker","slug":"Docker","permalink":"https://rainsoil.github.io/categories/Docker/"},{"name":"Docker","slug":"Docker/Docker","permalink":"https://rainsoil.github.io/categories/Docker/Docker/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://rainsoil.github.io/tags/zookeeper/"}]}